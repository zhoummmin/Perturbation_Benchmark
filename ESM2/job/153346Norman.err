Loading compilers/gcc/12.2.0
  ERROR: Module cannot be loaded due to a conflict.
    HINT: Might try "module unload compilers/gcc" first.
cmake-3.27.0 loaded successful
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
['LYL1+IER5L' 'IER5L+ctrl' 'KIAA1804+ctrl']
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:9
combo_seen1:52
combo_seen2:17
unseen_single:27
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/gears_esm/wandb/run-20240923_160216-g8fx05xv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gears_esm_NormanWeissman2019_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/g8fx05xv
  0%|                                                     | 0/3397 [00:00<?, ?it/s]  0%|                                             | 1/3397 [00:00<10:38,  5.32it/s]  0%|                                             | 4/3397 [00:00<03:53, 14.53it/s]  0%|                                             | 8/3397 [00:00<02:54, 19.46it/s]  0%|‚ñè                                           | 12/3397 [00:00<02:28, 22.79it/s]  0%|‚ñè                                           | 15/3397 [00:00<02:26, 23.10it/s]  1%|‚ñè                                           | 18/3397 [00:00<02:39, 21.22it/s]  1%|‚ñé                                           | 22/3397 [00:01<02:20, 24.10it/s]  1%|‚ñé                                           | 25/3397 [00:01<02:20, 23.93it/s]  1%|‚ñç                                           | 32/3397 [00:01<01:39, 33.76it/s]  1%|‚ñç                                           | 37/3397 [00:01<01:33, 35.97it/s]  1%|‚ñå                                           | 41/3397 [00:01<01:35, 35.02it/s]  1%|‚ñå                                           | 45/3397 [00:01<01:36, 34.61it/s]  1%|‚ñã                                           | 49/3397 [00:01<01:38, 33.97it/s]  2%|‚ñã                                           | 53/3397 [00:01<01:38, 33.79it/s]  2%|‚ñã                                           | 57/3397 [00:02<01:53, 29.40it/s]  2%|‚ñä                                           | 62/3397 [00:02<01:42, 32.47it/s]  2%|‚ñä                                           | 66/3397 [00:02<01:42, 32.54it/s]  2%|‚ñâ                                           | 70/3397 [00:02<01:41, 32.73it/s]  2%|‚ñâ                                           | 74/3397 [00:02<01:41, 32.58it/s]  2%|‚ñà                                           | 79/3397 [00:02<01:34, 35.16it/s]  2%|‚ñà                                           | 83/3397 [00:02<01:35, 34.67it/s]  3%|‚ñà‚ñè                                          | 87/3397 [00:02<01:36, 34.34it/s]  3%|‚ñà‚ñè                                          | 91/3397 [00:03<01:38, 33.67it/s]  3%|‚ñà‚ñè                                          | 95/3397 [00:03<01:38, 33.56it/s]  3%|‚ñà‚ñé                                          | 99/3397 [00:03<01:38, 33.32it/s]  3%|‚ñà‚ñé                                         | 103/3397 [00:03<01:46, 30.99it/s]  3%|‚ñà‚ñé                                         | 108/3397 [00:03<01:43, 31.76it/s]  3%|‚ñà‚ñç                                         | 112/3397 [00:03<01:42, 32.03it/s]  3%|‚ñà‚ñç                                         | 117/3397 [00:03<01:41, 32.29it/s]  4%|‚ñà‚ñå                                         | 121/3397 [00:03<01:40, 32.57it/s]  4%|‚ñà‚ñå                                         | 126/3397 [00:04<01:33, 34.88it/s]  4%|‚ñà‚ñã                                         | 130/3397 [00:04<01:35, 34.22it/s]  4%|‚ñà‚ñã                                         | 134/3397 [00:04<01:36, 33.94it/s]  4%|‚ñà‚ñã                                         | 138/3397 [00:04<01:36, 33.61it/s]  4%|‚ñà‚ñä                                         | 142/3397 [00:04<01:37, 33.44it/s]  4%|‚ñà‚ñä                                         | 146/3397 [00:04<01:37, 33.38it/s]  4%|‚ñà‚ñâ                                         | 150/3397 [00:04<01:37, 33.44it/s]  5%|‚ñà‚ñâ                                         | 154/3397 [00:04<01:37, 33.25it/s]  5%|‚ñà‚ñà                                         | 158/3397 [00:05<01:37, 33.38it/s]  5%|‚ñà‚ñà                                         | 162/3397 [00:05<01:44, 31.01it/s]  5%|‚ñà‚ñà                                         | 166/3397 [00:05<01:42, 31.54it/s]  5%|‚ñà‚ñà‚ñè                                        | 170/3397 [00:05<01:40, 32.09it/s]  5%|‚ñà‚ñà‚ñè                                        | 174/3397 [00:05<01:38, 32.58it/s]  5%|‚ñà‚ñà‚ñé                                        | 179/3397 [00:05<01:38, 32.81it/s]  5%|‚ñà‚ñà‚ñé                                        | 184/3397 [00:05<01:31, 35.31it/s]  6%|‚ñà‚ñà‚ñç                                        | 188/3397 [00:05<01:32, 34.72it/s]  6%|‚ñà‚ñà‚ñç                                        | 192/3397 [00:06<01:33, 34.30it/s]  6%|‚ñà‚ñà‚ñç                                        | 196/3397 [00:06<01:34, 34.01it/s]  6%|‚ñà‚ñà‚ñå                                        | 200/3397 [00:06<01:34, 33.82it/s]  6%|‚ñà‚ñà‚ñå                                        | 204/3397 [00:06<01:41, 31.35it/s]  6%|‚ñà‚ñà‚ñã                                        | 209/3397 [00:06<01:33, 34.28it/s]  6%|‚ñà‚ñà‚ñã                                        | 213/3397 [00:06<01:40, 31.64it/s]  6%|‚ñà‚ñà‚ñã                                        | 217/3397 [00:06<01:38, 32.13it/s]  7%|‚ñà‚ñà‚ñä                                        | 222/3397 [00:06<01:31, 34.84it/s]  7%|‚ñà‚ñà‚ñä                                        | 226/3397 [00:07<01:31, 34.48it/s]  7%|‚ñà‚ñà‚ñâ                                        | 230/3397 [00:07<01:33, 33.95it/s]  7%|‚ñà‚ñà‚ñâ                                        | 234/3397 [00:07<01:33, 33.85it/s]  7%|‚ñà‚ñà‚ñà                                        | 238/3397 [00:07<01:33, 33.62it/s]  7%|‚ñà‚ñà‚ñà                                        | 242/3397 [00:07<01:34, 33.52it/s]  7%|‚ñà‚ñà‚ñà                                        | 246/3397 [00:07<01:34, 33.49it/s]  7%|‚ñà‚ñà‚ñà‚ñè                                       | 250/3397 [00:07<01:33, 33.58it/s]  7%|‚ñà‚ñà‚ñà‚ñè                                       | 254/3397 [00:07<01:34, 33.31it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                       | 258/3397 [00:08<01:33, 33.42it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                       | 262/3397 [00:08<01:41, 31.01it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                       | 266/3397 [00:08<01:39, 31.60it/s]  8%|‚ñà‚ñà‚ñà‚ñç                                       | 270/3397 [00:08<01:37, 32.15it/s]  8%|‚ñà‚ñà‚ñà‚ñç                                       | 275/3397 [00:08<01:29, 34.79it/s]  8%|‚ñà‚ñà‚ñà‚ñå                                       | 279/3397 [00:08<01:37, 32.13it/s]  8%|‚ñà‚ñà‚ñà‚ñå                                       | 284/3397 [00:08<01:30, 34.59it/s]  8%|‚ñà‚ñà‚ñà‚ñã                                       | 288/3397 [00:08<01:31, 34.05it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                       | 292/3397 [00:09<01:31, 33.88it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                       | 296/3397 [00:09<01:32, 33.52it/s]  9%|‚ñà‚ñà‚ñà‚ñä                                       | 300/3397 [00:09<01:32, 33.31it/s]  9%|‚ñà‚ñà‚ñà‚ñä                                       | 304/3397 [00:09<01:33, 33.21it/s]  9%|‚ñà‚ñà‚ñà‚ñâ                                       | 308/3397 [00:09<01:40, 30.80it/s]  9%|‚ñà‚ñà‚ñà‚ñâ                                       | 312/3397 [00:09<01:38, 31.21it/s]  9%|‚ñà‚ñà‚ñà‚ñà                                       | 316/3397 [00:09<01:36, 31.93it/s]  9%|‚ñà‚ñà‚ñà‚ñà                                       | 320/3397 [00:09<01:36, 32.02it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                       | 325/3397 [00:10<01:43, 29.75it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 331/3397 [00:10<01:34, 32.45it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 336/3397 [00:10<01:29, 34.25it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 340/3397 [00:10<01:30, 33.90it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 344/3397 [00:10<01:30, 33.63it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 348/3397 [00:10<01:31, 33.25it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 352/3397 [00:10<01:32, 33.06it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 356/3397 [00:11<01:32, 32.89it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 360/3397 [00:11<01:33, 32.60it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 364/3397 [00:11<01:33, 32.56it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 368/3397 [00:11<01:38, 30.69it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 372/3397 [00:11<01:37, 31.03it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 377/3397 [00:11<01:29, 33.81it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 381/3397 [00:11<01:30, 33.38it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 385/3397 [00:11<01:31, 32.90it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 389/3397 [00:12<01:37, 30.94it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 393/3397 [00:12<01:34, 31.71it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 398/3397 [00:12<01:27, 34.19it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 402/3397 [00:12<01:28, 33.95it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 406/3397 [00:12<01:28, 33.92it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 410/3397 [00:12<01:29, 33.29it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 414/3397 [00:12<01:35, 31.13it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 419/3397 [00:12<01:27, 34.00it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 423/3397 [00:13<01:28, 33.50it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 427/3397 [00:13<01:29, 33.27it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 431/3397 [00:13<01:37, 30.52it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 436/3397 [00:13<01:28, 33.30it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 440/3397 [00:13<01:28, 33.24it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 444/3397 [00:13<01:35, 30.92it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 449/3397 [00:13<01:28, 33.38it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 453/3397 [00:14<01:35, 30.93it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 458/3397 [00:14<01:27, 33.58it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 462/3397 [00:14<01:33, 31.38it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 466/3397 [00:14<01:32, 31.74it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 470/3397 [00:14<01:31, 31.86it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 475/3397 [00:14<01:24, 34.48it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 479/3397 [00:14<01:25, 33.94it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 483/3397 [00:14<01:33, 31.14it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 488/3397 [00:15<01:25, 34.03it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 492/3397 [00:15<01:26, 33.69it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 496/3397 [00:15<01:27, 33.23it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 500/3397 [00:15<01:27, 32.94it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 504/3397 [00:15<01:34, 30.52it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 508/3397 [00:15<01:33, 30.85it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 513/3397 [00:15<01:25, 33.75it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 517/3397 [00:16<01:32, 31.22it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 522/3397 [00:16<01:31, 31.39it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 527/3397 [00:16<01:24, 33.93it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 531/3397 [00:16<01:25, 33.33it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 535/3397 [00:16<01:26, 33.05it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 539/3397 [00:16<01:31, 31.15it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 543/3397 [00:16<01:29, 31.80it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 548/3397 [00:16<01:23, 34.02it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 552/3397 [00:17<01:24, 33.75it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 556/3397 [00:17<01:25, 33.33it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 560/3397 [00:17<01:25, 33.18it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 564/3397 [00:17<01:25, 33.26it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 568/3397 [00:17<01:31, 30.84it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 573/3397 [00:17<01:30, 31.18it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 578/3397 [00:17<01:29, 31.64it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 583/3397 [00:18<01:28, 31.93it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 587/3397 [00:18<01:26, 32.32it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 591/3397 [00:18<01:26, 32.44it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 596/3397 [00:18<01:20, 34.71it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 600/3397 [00:18<01:21, 34.12it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 604/3397 [00:18<01:23, 33.60it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 608/3397 [00:18<01:23, 33.25it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 612/3397 [00:18<01:23, 33.32it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 616/3397 [00:19<01:43, 26.99it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 623/3397 [00:19<01:25, 32.46it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 628/3397 [00:19<01:20, 34.51it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 632/3397 [00:19<01:21, 33.84it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 636/3397 [00:19<01:21, 33.69it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 640/3397 [00:19<01:27, 31.38it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 645/3397 [00:19<01:20, 34.23it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 649/3397 [00:20<01:21, 33.62it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 653/3397 [00:20<01:28, 30.98it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 658/3397 [00:20<01:21, 33.61it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 662/3397 [00:20<01:21, 33.61it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 666/3397 [00:20<01:22, 33.29it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 670/3397 [00:20<01:21, 33.29it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 674/3397 [00:20<01:22, 33.00it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 678/3397 [00:20<01:22, 32.78it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 682/3397 [00:21<01:23, 32.61it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 686/3397 [00:21<01:22, 32.95it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 690/3397 [00:21<01:21, 33.05it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 694/3397 [00:21<01:21, 33.09it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 698/3397 [00:21<01:22, 32.87it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 702/3397 [00:21<01:22, 32.82it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 706/3397 [00:21<01:22, 32.76it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 710/3397 [00:21<01:21, 33.03it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 714/3397 [00:22<01:20, 33.17it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 718/3397 [00:22<01:26, 30.87it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 723/3397 [00:22<01:19, 33.48it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 727/3397 [00:22<01:20, 33.09it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 731/3397 [00:22<01:25, 31.01it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 735/3397 [00:22<01:23, 31.72it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 740/3397 [00:22<01:17, 34.45it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 744/3397 [00:22<01:23, 31.69it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 749/3397 [00:23<01:23, 31.72it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 754/3397 [00:23<01:17, 34.14it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 758/3397 [00:23<01:18, 33.80it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 762/3397 [00:23<01:18, 33.58it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 766/3397 [00:23<01:24, 31.01it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 771/3397 [00:23<01:17, 33.69it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 775/3397 [00:23<01:18, 33.20it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 779/3397 [00:24<01:19, 33.01it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 783/3397 [00:24<01:25, 30.72it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 788/3397 [00:24<01:23, 31.39it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 792/3397 [00:24<01:24, 31.00it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 796/3397 [00:24<01:32, 28.22it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 799/3397 [00:24<01:40, 25.94it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 802/3397 [00:24<01:47, 24.21it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 805/3397 [00:25<01:52, 23.06it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 808/3397 [00:25<01:54, 22.65it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 811/3397 [00:25<01:57, 22.09it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 814/3397 [00:25<01:57, 21.95it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 817/3397 [00:25<01:55, 22.38it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 820/3397 [00:25<01:55, 22.24it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 823/3397 [00:25<01:54, 22.46it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 826/3397 [00:26<01:57, 21.82it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 829/3397 [00:26<01:59, 21.45it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 832/3397 [00:26<01:59, 21.40it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 835/3397 [00:26<01:58, 21.62it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 838/3397 [00:26<01:59, 21.46it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 841/3397 [00:26<01:58, 21.48it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 844/3397 [00:26<02:10, 19.59it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 848/3397 [00:27<01:55, 22.04it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 851/3397 [00:27<02:01, 20.92it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 856/3397 [00:27<01:39, 25.57it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 860/3397 [00:27<01:33, 27.09it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 863/3397 [00:27<01:36, 26.17it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 867/3397 [00:27<01:31, 27.74it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 872/3397 [00:27<01:22, 30.72it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 876/3397 [00:28<01:27, 28.71it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 880/3397 [00:28<01:25, 29.27it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 885/3397 [00:28<01:18, 31.99it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 889/3397 [00:28<01:19, 31.70it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 893/3397 [00:28<01:27, 28.74it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 896/3397 [00:28<01:34, 26.59it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 900/3397 [00:28<01:24, 29.62it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 904/3397 [00:28<01:24, 29.51it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 908/3397 [00:29<01:32, 26.99it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 912/3397 [00:29<01:24, 29.51it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 916/3397 [00:29<01:25, 28.90it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 919/3397 [00:29<01:30, 27.27it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 923/3397 [00:29<01:23, 29.76it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 927/3397 [00:29<01:30, 27.17it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 930/3397 [00:29<01:31, 26.93it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 934/3397 [00:30<01:23, 29.43it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 938/3397 [00:30<01:24, 29.19it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 941/3397 [00:30<01:24, 29.16it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 944/3397 [00:30<01:24, 29.19it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 947/3397 [00:30<01:24, 29.08it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 950/3397 [00:30<01:24, 29.13it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 953/3397 [00:30<01:23, 29.11it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 956/3397 [00:30<01:25, 28.54it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 959/3397 [00:30<01:26, 28.30it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 962/3397 [00:31<01:26, 28.21it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 965/3397 [00:31<01:25, 28.46it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 968/3397 [00:31<01:26, 28.07it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 971/3397 [00:31<01:27, 27.77it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 974/3397 [00:31<01:25, 28.24it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 977/3397 [00:31<01:26, 28.04it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 980/3397 [00:31<01:25, 28.43it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 983/3397 [00:31<01:25, 28.25it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 986/3397 [00:31<01:27, 27.69it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 989/3397 [00:31<01:26, 27.68it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 992/3397 [00:32<01:26, 27.74it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 995/3397 [00:32<01:24, 28.26it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 998/3397 [00:32<01:24, 28.32it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1001/3397 [00:32<01:33, 25.74it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1005/3397 [00:32<01:30, 26.39it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1010/3397 [00:32<01:20, 29.81it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1013/3397 [00:32<01:27, 27.38it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1017/3397 [00:32<01:19, 29.88it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1021/3397 [00:33<01:25, 27.84it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1025/3397 [00:33<01:17, 30.49it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1029/3397 [00:33<01:26, 27.33it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1033/3397 [00:33<01:18, 30.09it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1037/3397 [00:33<01:29, 26.38it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1040/3397 [00:33<01:28, 26.60it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1044/3397 [00:33<01:30, 26.06it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1047/3397 [00:34<01:28, 26.45it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1050/3397 [00:34<01:33, 25.23it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1054/3397 [00:34<01:32, 25.47it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1060/3397 [00:34<01:12, 32.07it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1064/3397 [00:34<01:12, 32.19it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1068/3397 [00:34<01:49, 21.25it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1079/3397 [00:35<01:05, 35.43it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1084/3397 [00:35<01:05, 35.12it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1089/3397 [00:35<01:12, 32.03it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1093/3397 [00:35<01:08, 33.56it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1097/3397 [00:35<01:14, 30.86it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1102/3397 [00:35<01:10, 32.67it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1106/3397 [00:35<01:17, 29.48it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1110/3397 [00:36<01:12, 31.55it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1114/3397 [00:36<01:17, 29.60it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1118/3397 [00:36<01:14, 30.63it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1123/3397 [00:36<01:08, 33.31it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1127/3397 [00:36<01:13, 30.83it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1131/3397 [00:36<01:12, 31.13it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1136/3397 [00:36<01:07, 33.61it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1140/3397 [00:37<01:13, 30.79it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1144/3397 [00:37<01:08, 32.91it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1148/3397 [00:37<01:09, 32.14it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1152/3397 [00:37<01:16, 29.53it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1156/3397 [00:37<01:19, 28.27it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1161/3397 [00:37<01:10, 31.66it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1166/3397 [00:37<01:05, 33.95it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1170/3397 [00:37<01:07, 33.00it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1174/3397 [00:38<01:08, 32.61it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1178/3397 [00:38<01:08, 32.19it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1182/3397 [00:38<01:09, 31.66it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1186/3397 [00:38<01:10, 31.46it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1190/3397 [00:38<01:16, 28.69it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1193/3397 [00:38<01:16, 28.72it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1198/3397 [00:38<01:08, 32.13it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1202/3397 [00:39<01:13, 30.00it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1206/3397 [00:39<01:12, 30.38it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1211/3397 [00:39<01:05, 33.41it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1215/3397 [00:39<01:06, 32.67it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1219/3397 [00:39<01:07, 32.37it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1223/3397 [00:39<01:08, 31.91it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1227/3397 [00:39<01:13, 29.53it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1231/3397 [00:39<01:12, 29.91it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1235/3397 [00:40<01:11, 30.34it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1239/3397 [00:40<01:09, 30.91it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1244/3397 [00:40<01:05, 32.98it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1248/3397 [00:40<01:06, 32.49it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1252/3397 [00:40<01:10, 30.29it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1256/3397 [00:40<01:09, 30.71it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1260/3397 [00:40<01:08, 31.17it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1264/3397 [00:41<01:08, 31.35it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1269/3397 [00:41<01:03, 33.57it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1273/3397 [00:41<01:04, 32.99it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1277/3397 [00:41<01:09, 30.53it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1282/3397 [00:41<01:03, 33.05it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1286/3397 [00:41<01:08, 30.75it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1290/3397 [00:41<01:07, 31.34it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1295/3397 [00:41<01:02, 33.48it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1299/3397 [00:42<01:07, 31.23it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1303/3397 [00:42<01:06, 31.26it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1307/3397 [00:42<01:06, 31.49it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1312/3397 [00:42<01:01, 34.06it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1316/3397 [00:42<01:02, 33.53it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1320/3397 [00:42<01:02, 33.08it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1324/3397 [00:42<01:03, 32.75it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1328/3397 [00:43<01:08, 30.22it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1332/3397 [00:43<01:08, 30.34it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1336/3397 [00:43<01:06, 30.87it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1341/3397 [00:43<01:06, 31.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1346/3397 [00:43<01:04, 31.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1351/3397 [00:43<01:04, 31.64it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1355/3397 [00:43<01:09, 29.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1361/3397 [00:44<00:59, 34.51it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1365/3397 [00:44<01:03, 32.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1370/3397 [00:44<00:58, 34.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1374/3397 [00:44<01:00, 33.53it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1378/3397 [00:44<01:00, 33.40it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1382/3397 [00:44<01:05, 30.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1387/3397 [00:44<00:59, 33.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1391/3397 [00:44<01:04, 30.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1396/3397 [00:45<01:03, 31.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1401/3397 [00:45<01:02, 31.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1405/3397 [00:45<01:01, 32.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1410/3397 [00:45<01:00, 32.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1414/3397 [00:45<01:03, 31.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 1420/3397 [00:45<00:55, 35.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 1424/3397 [00:45<00:55, 35.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 1428/3397 [00:46<01:00, 32.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 1433/3397 [00:46<00:55, 35.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 1437/3397 [00:46<00:59, 32.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 1442/3397 [00:46<00:58, 33.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 1446/3397 [00:46<00:57, 33.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 1451/3397 [00:46<00:57, 33.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 1455/3397 [00:46<00:58, 33.43it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 1459/3397 [00:46<00:57, 33.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 1463/3397 [00:47<00:58, 33.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1468/3397 [00:47<00:54, 35.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1472/3397 [00:47<01:00, 31.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1476/3397 [00:47<01:00, 31.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 1481/3397 [00:47<00:59, 31.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 1485/3397 [00:47<00:59, 32.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 1490/3397 [00:47<00:58, 32.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 1494/3397 [00:48<00:58, 32.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 1498/3397 [00:48<00:57, 32.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 1502/3397 [00:48<01:01, 30.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 1507/3397 [00:48<00:56, 33.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 1511/3397 [00:48<00:56, 33.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 1516/3397 [00:48<00:52, 35.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 1520/3397 [00:48<00:53, 34.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 1524/3397 [00:48<00:59, 31.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 1529/3397 [00:49<00:58, 31.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 1533/3397 [00:49<00:58, 32.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 1538/3397 [00:49<00:53, 34.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 1542/3397 [00:49<00:57, 32.03it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 1547/3397 [00:49<00:57, 32.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 1552/3397 [00:49<00:57, 32.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 1556/3397 [00:49<00:56, 32.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 1560/3397 [00:50<00:56, 32.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 1565/3397 [00:50<00:57, 32.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 1569/3397 [00:50<00:57, 32.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 1574/3397 [00:50<00:56, 32.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 1579/3397 [00:50<00:56, 32.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 1583/3397 [00:50<00:55, 32.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 1588/3397 [00:50<00:55, 32.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 1592/3397 [00:51<00:55, 32.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 1597/3397 [00:51<00:55, 32.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 1602/3397 [00:51<00:55, 32.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 1607/3397 [00:51<00:54, 32.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 1612/3397 [00:51<00:51, 34.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 1616/3397 [00:51<00:52, 34.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 1620/3397 [00:51<00:52, 33.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 1624/3397 [00:52<00:53, 33.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 1628/3397 [00:52<00:57, 31.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 1632/3397 [00:52<00:59, 29.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 1638/3397 [00:52<00:54, 32.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 1642/3397 [00:52<00:54, 32.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 1646/3397 [00:52<00:53, 32.50it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 1651/3397 [00:52<00:49, 35.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 1655/3397 [00:53<00:54, 31.90it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 1660/3397 [00:53<00:50, 34.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 1664/3397 [00:53<00:51, 33.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 1668/3397 [00:53<00:55, 31.07it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 1672/3397 [00:53<00:58, 29.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 1678/3397 [00:53<00:49, 34.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 1682/3397 [00:53<00:53, 32.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 1687/3397 [00:53<00:50, 34.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 1691/3397 [00:54<00:50, 33.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 1695/3397 [00:54<00:54, 31.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 1699/3397 [00:54<00:53, 31.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 1704/3397 [00:54<00:57, 29.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 1709/3397 [00:54<00:51, 32.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 1714/3397 [00:54<00:48, 34.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 1718/3397 [00:54<00:52, 31.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 1722/3397 [00:55<00:52, 31.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 1726/3397 [00:55<00:51, 32.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 1730/3397 [00:55<00:51, 32.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 1734/3397 [00:55<01:02, 26.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 1742/3397 [00:55<00:48, 34.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 1746/3397 [00:55<00:48, 33.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 1751/3397 [00:55<00:46, 35.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 1755/3397 [00:56<00:50, 32.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 1759/3397 [00:56<00:50, 32.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 1764/3397 [00:56<00:47, 34.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 1768/3397 [00:56<00:51, 31.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 1773/3397 [00:56<00:47, 34.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 1777/3397 [00:56<00:47, 33.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 1781/3397 [00:56<00:51, 31.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 1785/3397 [00:57<00:50, 31.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 1789/3397 [00:57<00:49, 32.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 1793/3397 [00:57<00:49, 32.56it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 1798/3397 [00:57<00:48, 32.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 1802/3397 [00:57<00:48, 32.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 1807/3397 [00:57<00:48, 32.78it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 1812/3397 [00:57<00:45, 35.21it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 1816/3397 [00:57<00:45, 34.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 1820/3397 [00:58<00:46, 34.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 1824/3397 [00:58<00:46, 34.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 1828/3397 [00:58<00:50, 31.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 1832/3397 [00:58<00:49, 31.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 1837/3397 [00:58<00:45, 34.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 1841/3397 [00:58<00:45, 34.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 1845/3397 [00:58<00:49, 31.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 1850/3397 [00:58<00:45, 34.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 1854/3397 [00:59<00:49, 31.15it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 1859/3397 [00:59<00:45, 33.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 1863/3397 [00:59<00:45, 33.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 1867/3397 [00:59<00:45, 33.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 1871/3397 [00:59<00:49, 31.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 1876/3397 [00:59<00:44, 33.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 1880/3397 [00:59<00:45, 33.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 1884/3397 [00:59<00:45, 33.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 1888/3397 [01:00<00:45, 32.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 1892/3397 [01:00<00:45, 32.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 1896/3397 [01:00<00:49, 30.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 1901/3397 [01:00<00:47, 31.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 1905/3397 [01:00<00:47, 31.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 1910/3397 [01:00<00:43, 34.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 1914/3397 [01:00<00:44, 33.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 1918/3397 [01:01<00:44, 33.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 1922/3397 [01:01<00:47, 31.22it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 1926/3397 [01:01<00:46, 31.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 1930/3397 [01:01<00:45, 31.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 1934/3397 [01:01<00:45, 32.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 1938/3397 [01:01<00:45, 32.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 1942/3397 [01:01<00:48, 30.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 1947/3397 [01:01<00:43, 33.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 1952/3397 [01:02<00:40, 35.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 1956/3397 [01:02<00:44, 32.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 1961/3397 [01:02<00:41, 34.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 1965/3397 [01:02<00:45, 31.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 1970/3397 [01:02<00:41, 34.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 1974/3397 [01:02<00:41, 34.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 1978/3397 [01:02<00:45, 31.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 1982/3397 [01:03<00:44, 31.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 1987/3397 [01:03<00:40, 34.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 1991/3397 [01:03<00:41, 33.98it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 1995/3397 [01:03<00:47, 29.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2000/3397 [01:03<00:42, 32.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2004/3397 [01:03<00:42, 32.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2008/3397 [01:03<00:42, 32.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2012/3397 [01:03<00:42, 32.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2016/3397 [01:04<00:42, 32.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2020/3397 [01:04<00:42, 32.56it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 2024/3397 [01:04<00:41, 32.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 2028/3397 [01:04<00:42, 32.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 2032/3397 [01:04<00:42, 32.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 2037/3397 [01:04<00:45, 30.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 2042/3397 [01:04<00:41, 32.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2046/3397 [01:04<00:41, 32.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2051/3397 [01:05<00:39, 34.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2055/3397 [01:05<00:39, 33.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2059/3397 [01:05<00:40, 33.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 2063/3397 [01:05<00:43, 30.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 2068/3397 [01:05<00:39, 33.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 2072/3397 [01:05<00:39, 33.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2076/3397 [01:05<00:40, 32.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2080/3397 [01:06<00:40, 32.49it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2084/3397 [01:06<00:41, 31.97it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2088/3397 [01:06<00:40, 32.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2092/3397 [01:06<00:43, 30.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 2097/3397 [01:06<00:39, 32.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 2101/3397 [01:06<00:39, 32.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2105/3397 [01:06<00:39, 32.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2109/3397 [01:06<00:39, 32.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2113/3397 [01:07<00:39, 32.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2117/3397 [01:07<00:42, 30.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2121/3397 [01:07<00:41, 30.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2125/3397 [01:07<00:40, 31.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2129/3397 [01:07<00:40, 31.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2134/3397 [01:07<00:39, 31.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2139/3397 [01:07<00:36, 34.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2143/3397 [01:07<00:39, 31.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 2148/3397 [01:08<00:36, 34.03it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 2152/3397 [01:08<00:37, 33.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2156/3397 [01:08<00:37, 33.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2160/3397 [01:08<00:37, 33.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2164/3397 [01:08<00:39, 30.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2168/3397 [01:08<00:39, 31.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2172/3397 [01:08<00:38, 31.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2177/3397 [01:09<00:35, 34.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2181/3397 [01:09<00:36, 33.67it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2185/3397 [01:09<00:39, 31.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2189/3397 [01:09<00:38, 31.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 2194/3397 [01:09<00:35, 33.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 2198/3397 [01:09<00:38, 31.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 2203/3397 [01:09<00:38, 31.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2208/3397 [01:09<00:37, 31.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2213/3397 [01:10<00:36, 32.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 2217/3397 [01:10<00:36, 32.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 2222/3397 [01:10<00:36, 32.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2227/3397 [01:10<00:33, 34.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2231/3397 [01:10<00:33, 34.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 2235/3397 [01:10<00:36, 31.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 2239/3397 [01:10<00:36, 31.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 2243/3397 [01:11<00:35, 32.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2248/3397 [01:11<00:35, 32.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2252/3397 [01:11<00:35, 32.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 2257/3397 [01:11<00:32, 34.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 2261/3397 [01:11<00:35, 31.96it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2265/3397 [01:11<00:35, 32.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2269/3397 [01:11<00:35, 32.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2273/3397 [01:11<00:34, 32.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 2278/3397 [01:12<00:32, 34.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 2282/3397 [01:12<00:33, 33.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 2286/3397 [01:12<00:36, 30.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 2291/3397 [01:12<00:33, 33.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2295/3397 [01:12<00:38, 28.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2301/3397 [01:12<00:34, 31.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2305/3397 [01:12<00:34, 31.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2310/3397 [01:13<00:31, 33.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2314/3397 [01:13<00:36, 29.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 2319/3397 [01:13<00:33, 32.59it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 2323/3397 [01:13<00:32, 32.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2328/3397 [01:13<00:32, 32.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2333/3397 [01:13<00:30, 34.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2337/3397 [01:13<00:31, 33.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2341/3397 [01:14<00:31, 33.50it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2345/3397 [01:14<00:33, 31.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2349/3397 [01:14<00:32, 31.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2354/3397 [01:14<00:30, 34.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2358/3397 [01:14<00:35, 29.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2364/3397 [01:14<00:30, 34.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2368/3397 [01:14<00:30, 33.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2372/3397 [01:15<00:32, 31.64it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2376/3397 [01:15<00:32, 31.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2380/3397 [01:15<00:32, 31.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2385/3397 [01:15<00:31, 31.83it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 2390/3397 [01:15<00:29, 34.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 2394/3397 [01:15<00:29, 33.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2398/3397 [01:15<00:29, 33.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2402/3397 [01:15<00:30, 32.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2406/3397 [01:16<00:32, 30.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 2410/3397 [01:16<00:31, 31.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 2414/3397 [01:16<00:31, 31.46it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2419/3397 [01:16<00:28, 34.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2423/3397 [01:16<00:28, 33.61it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 2427/3397 [01:16<00:29, 33.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 2431/3397 [01:16<00:31, 30.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 2435/3397 [01:16<00:30, 31.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 2440/3397 [01:17<00:27, 34.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 2444/3397 [01:17<00:28, 33.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 2448/3397 [01:17<00:28, 33.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 2452/3397 [01:17<00:28, 32.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 2456/3397 [01:17<00:30, 30.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 2461/3397 [01:17<00:29, 31.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 2466/3397 [01:17<00:29, 32.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 2471/3397 [01:18<00:26, 34.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 2475/3397 [01:18<00:27, 33.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 2479/3397 [01:18<00:35, 26.07it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 2486/3397 [01:18<00:27, 33.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 2491/3397 [01:18<00:25, 35.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 2495/3397 [01:18<00:27, 32.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 2500/3397 [01:18<00:25, 34.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 2504/3397 [01:19<00:27, 31.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2508/3397 [01:19<00:27, 32.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2513/3397 [01:19<00:27, 32.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2517/3397 [01:19<00:26, 32.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 2522/3397 [01:19<00:25, 34.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 2526/3397 [01:19<00:25, 34.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 2530/3397 [01:19<00:27, 31.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 2535/3397 [01:20<00:25, 33.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 2539/3397 [01:20<00:25, 33.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 2543/3397 [01:20<00:27, 31.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 2547/3397 [01:20<00:26, 31.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 2552/3397 [01:20<00:24, 34.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 2556/3397 [01:20<00:26, 31.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 2560/3397 [01:20<00:26, 31.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 2565/3397 [01:20<00:26, 31.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 2569/3397 [01:21<00:25, 32.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 2574/3397 [01:21<00:23, 34.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 2578/3397 [01:21<00:23, 34.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 2582/3397 [01:21<00:25, 31.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 2587/3397 [01:21<00:23, 34.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 2591/3397 [01:21<00:23, 34.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 2595/3397 [01:21<00:23, 33.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 2599/3397 [01:21<00:25, 31.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 2603/3397 [01:22<00:25, 31.71it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 2607/3397 [01:22<00:24, 31.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 2612/3397 [01:22<00:22, 34.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 2616/3397 [01:22<00:24, 31.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 2621/3397 [01:22<00:22, 34.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 2625/3397 [01:22<00:22, 33.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 2629/3397 [01:22<00:24, 31.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 2633/3397 [01:23<00:23, 31.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 2637/3397 [01:23<00:23, 32.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 2641/3397 [01:24<01:29,  8.45it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 2645/3397 [01:25<01:36,  7.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 2701/3397 [01:25<00:14, 49.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 2716/3397 [01:25<00:15, 44.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 2728/3397 [01:26<00:16, 40.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 2737/3397 [01:26<00:17, 38.30it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 2745/3397 [01:26<00:17, 37.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 2752/3397 [01:26<00:17, 36.54it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 2758/3397 [01:26<00:18, 34.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 2763/3397 [01:27<00:18, 33.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 2768/3397 [01:27<00:17, 35.12it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 2773/3397 [01:27<00:19, 32.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 2778/3397 [01:27<00:18, 34.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 2782/3397 [01:27<00:18, 34.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 2786/3397 [01:27<00:18, 33.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 2790/3397 [01:27<00:17, 33.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 2794/3397 [01:28<00:19, 31.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 2799/3397 [01:28<00:18, 31.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 2804/3397 [01:28<00:17, 34.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 2808/3397 [01:28<00:17, 34.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 2812/3397 [01:28<00:18, 31.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 2817/3397 [01:28<00:17, 32.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 2822/3397 [01:28<00:17, 32.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 2826/3397 [01:29<00:17, 32.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2831/3397 [01:29<00:16, 35.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2835/3397 [01:29<00:16, 34.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2839/3397 [01:29<00:16, 34.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 2843/3397 [01:29<00:17, 31.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 2848/3397 [01:29<00:15, 34.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 2852/3397 [01:29<00:15, 34.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 2856/3397 [01:29<00:17, 31.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 2861/3397 [01:30<00:16, 32.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 2865/3397 [01:30<00:16, 32.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 2870/3397 [01:30<00:15, 33.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 2874/3397 [01:30<00:15, 33.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 2879/3397 [01:30<00:15, 33.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 2884/3397 [01:30<00:14, 35.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 2888/3397 [01:30<00:14, 35.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 2892/3397 [01:30<00:14, 34.49it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 2896/3397 [01:31<00:14, 34.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 2900/3397 [01:32<00:52,  9.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 2939/3397 [01:32<00:10, 42.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 2951/3397 [01:32<00:11, 40.03it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 2961/3397 [01:33<00:11, 38.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 2969/3397 [01:34<00:23, 17.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3009/3397 [01:34<00:09, 40.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3021/3397 [01:34<00:09, 39.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3031/3397 [01:35<00:09, 38.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3039/3397 [01:37<00:23, 15.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3082/3397 [01:37<00:11, 27.22it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3108/3397 [01:38<00:10, 28.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3149/3397 [01:38<00:05, 46.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3163/3397 [01:39<00:05, 43.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3174/3397 [01:39<00:05, 41.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3183/3397 [01:39<00:05, 39.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3190/3397 [01:39<00:05, 38.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3196/3397 [01:40<00:05, 38.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3202/3397 [01:40<00:05, 37.94it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3207/3397 [01:40<00:05, 35.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3212/3397 [01:40<00:04, 37.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3217/3397 [01:42<00:17, 10.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3235/3397 [01:42<00:08, 19.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3248/3397 [01:42<00:06, 23.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3265/3397 [01:43<00:04, 26.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3286/3397 [01:44<00:04, 26.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3313/3397 [01:44<00:02, 29.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3325/3397 [01:45<00:03, 23.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3385/3397 [01:45<00:00, 55.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3397/3397 [01:46<00:00, 31.96it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.9982
Epoch 1 Step 51 Train Loss: 0.4876
Epoch 1 Step 101 Train Loss: 0.4917
Epoch 1 Step 151 Train Loss: 0.4806
Epoch 1 Step 201 Train Loss: 0.5151
Epoch 1 Step 251 Train Loss: 0.5052
Epoch 1 Step 301 Train Loss: 0.5340
Epoch 1 Step 351 Train Loss: 0.4943
Epoch 1 Step 401 Train Loss: 0.4738
Epoch 1 Step 451 Train Loss: 0.5237
Epoch 1 Step 501 Train Loss: 0.4884
Epoch 1 Step 551 Train Loss: 0.5089
Epoch 1 Step 601 Train Loss: 0.4688
Epoch 1 Step 651 Train Loss: 0.5284
Epoch 1 Step 701 Train Loss: 0.4916
Epoch 1 Step 751 Train Loss: 0.4617
Epoch 1 Step 801 Train Loss: 0.4591
Epoch 1 Step 851 Train Loss: 0.4946
Epoch 1 Step 901 Train Loss: 0.5151
Epoch 1: Train Overall MSE: 0.0036 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.1367 Validation Top 20 DE MSE: 0.1973. 
Epoch 2 Step 1 Train Loss: 0.4490
Epoch 2 Step 51 Train Loss: 0.4822
Epoch 2 Step 101 Train Loss: 0.4881
Epoch 2 Step 151 Train Loss: 0.4713
Epoch 2 Step 201 Train Loss: 0.4842
Epoch 2 Step 251 Train Loss: 0.4759
Epoch 2 Step 301 Train Loss: 0.4933
Epoch 2 Step 351 Train Loss: 0.4878
Epoch 2 Step 401 Train Loss: 0.4461
Epoch 2 Step 451 Train Loss: 0.4692
Epoch 2 Step 501 Train Loss: 0.4299
Epoch 2 Step 551 Train Loss: 0.5072
Epoch 2 Step 601 Train Loss: 0.4512
Epoch 2 Step 651 Train Loss: 0.4769
Epoch 2 Step 701 Train Loss: 0.4705
Epoch 2 Step 751 Train Loss: 0.4646
Epoch 2 Step 801 Train Loss: 0.4291
Epoch 2 Step 851 Train Loss: 0.4891
Epoch 2 Step 901 Train Loss: 0.4462
Epoch 2: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.1035 Validation Top 20 DE MSE: 0.1560. 
Epoch 3 Step 1 Train Loss: 0.4764
Epoch 3 Step 51 Train Loss: 0.4685
Epoch 3 Step 101 Train Loss: 0.5128
Epoch 3 Step 151 Train Loss: 0.4887
Epoch 3 Step 201 Train Loss: 0.4845
Epoch 3 Step 251 Train Loss: 0.4516
Epoch 3 Step 301 Train Loss: 0.5164
Epoch 3 Step 351 Train Loss: 0.4915
Epoch 3 Step 401 Train Loss: 0.4614
Epoch 3 Step 451 Train Loss: 0.5041
Epoch 3 Step 501 Train Loss: 0.4345
Epoch 3 Step 551 Train Loss: 0.4977
Epoch 3 Step 601 Train Loss: 0.5315
Epoch 3 Step 651 Train Loss: 0.4802
Epoch 3 Step 701 Train Loss: 0.4667
Epoch 3 Step 751 Train Loss: 0.4866
Epoch 3 Step 801 Train Loss: 0.4575
Epoch 3 Step 851 Train Loss: 0.5056
Epoch 3 Step 901 Train Loss: 0.4844
Epoch 3: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0821 Validation Top 20 DE MSE: 0.1396. 
Epoch 4 Step 1 Train Loss: 0.4982
Epoch 4 Step 51 Train Loss: 0.4603
Epoch 4 Step 101 Train Loss: 0.4820
Epoch 4 Step 151 Train Loss: 0.4626
Epoch 4 Step 201 Train Loss: 0.4858
Epoch 4 Step 251 Train Loss: 0.5079
Epoch 4 Step 301 Train Loss: 0.5190
Epoch 4 Step 351 Train Loss: 0.4670
Epoch 4 Step 401 Train Loss: 0.4901
Epoch 4 Step 451 Train Loss: 0.4889
Epoch 4 Step 501 Train Loss: 0.5190
Epoch 4 Step 551 Train Loss: 0.4974
Epoch 4 Step 601 Train Loss: 0.4928
Epoch 4 Step 651 Train Loss: 0.4931
Epoch 4 Step 701 Train Loss: 0.5576
Epoch 4 Step 751 Train Loss: 0.5214
Epoch 4 Step 801 Train Loss: 0.5046
Epoch 4 Step 851 Train Loss: 0.4680
Epoch 4 Step 901 Train Loss: 0.4632
Epoch 4: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0705 Validation Top 20 DE MSE: 0.1207. 
Epoch 5 Step 1 Train Loss: 0.4624
Epoch 5 Step 51 Train Loss: 0.4907
Epoch 5 Step 101 Train Loss: 0.4717
Epoch 5 Step 151 Train Loss: 0.4919
Epoch 5 Step 201 Train Loss: 0.4810
Epoch 5 Step 251 Train Loss: 0.5103
Epoch 5 Step 301 Train Loss: 0.5990
Epoch 5 Step 351 Train Loss: 0.4944
Epoch 5 Step 401 Train Loss: 0.4997
Epoch 5 Step 451 Train Loss: 0.5004
Epoch 5 Step 501 Train Loss: 0.5359
Epoch 5 Step 551 Train Loss: 0.4839
Epoch 5 Step 601 Train Loss: 0.5273
Epoch 5 Step 651 Train Loss: 0.4720
Epoch 5 Step 701 Train Loss: 0.4790
Epoch 5 Step 751 Train Loss: 0.4413
Epoch 5 Step 801 Train Loss: 0.4949
Epoch 5 Step 851 Train Loss: 0.5006
Epoch 5 Step 901 Train Loss: 0.5132
Epoch 5: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0713 Validation Top 20 DE MSE: 0.1335. 
Epoch 6 Step 1 Train Loss: 0.4891
Epoch 6 Step 51 Train Loss: 0.4789
Epoch 6 Step 101 Train Loss: 0.5161
Epoch 6 Step 151 Train Loss: 0.4744
Epoch 6 Step 201 Train Loss: 0.4906
Epoch 6 Step 251 Train Loss: 0.5127
Epoch 6 Step 301 Train Loss: 0.4831
Epoch 6 Step 351 Train Loss: 0.5370
Epoch 6 Step 401 Train Loss: 0.4937
Epoch 6 Step 451 Train Loss: 0.4737
Epoch 6 Step 501 Train Loss: 0.4769
Epoch 6 Step 551 Train Loss: 0.5278
Epoch 6 Step 601 Train Loss: 0.5059
Epoch 6 Step 651 Train Loss: 0.4964
Epoch 6 Step 701 Train Loss: 0.4973
Epoch 6 Step 751 Train Loss: 0.4989
Epoch 6 Step 801 Train Loss: 0.4798
Epoch 6 Step 851 Train Loss: 0.5343
Epoch 6 Step 901 Train Loss: 0.4457
Epoch 6: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0668 Validation Top 20 DE MSE: 0.1275. 
Epoch 7 Step 1 Train Loss: 0.5087
Epoch 7 Step 51 Train Loss: 0.4375
Epoch 7 Step 101 Train Loss: 0.4701
Epoch 7 Step 151 Train Loss: 0.4843
Epoch 7 Step 201 Train Loss: 0.4764
Epoch 7 Step 251 Train Loss: 0.4371
Epoch 7 Step 301 Train Loss: 0.4625
Epoch 7 Step 351 Train Loss: 0.4782
Epoch 7 Step 401 Train Loss: 0.4945
Epoch 7 Step 451 Train Loss: 0.4432
Epoch 7 Step 501 Train Loss: 0.4972
Epoch 7 Step 551 Train Loss: 0.4982
Epoch 7 Step 601 Train Loss: 0.4583
Epoch 7 Step 651 Train Loss: 0.4573
Epoch 7 Step 701 Train Loss: 0.4995
Epoch 7 Step 751 Train Loss: 0.4932
Epoch 7 Step 801 Train Loss: 0.4748
Epoch 7 Step 851 Train Loss: 0.4855
Epoch 7 Step 901 Train Loss: 0.4627
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0620 Validation Top 20 DE MSE: 0.1252. 
Epoch 8 Step 1 Train Loss: 0.4720
Epoch 8 Step 51 Train Loss: 0.5159
Epoch 8 Step 101 Train Loss: 0.4469
Epoch 8 Step 151 Train Loss: 0.5203
Epoch 8 Step 201 Train Loss: 0.5148
Epoch 8 Step 251 Train Loss: 0.4774
Epoch 8 Step 301 Train Loss: 0.4924
Epoch 8 Step 351 Train Loss: 0.4988
Epoch 8 Step 401 Train Loss: 0.4793
Epoch 8 Step 451 Train Loss: 0.4499
Epoch 8 Step 501 Train Loss: 0.4899
Epoch 8 Step 551 Train Loss: 0.4563
Epoch 8 Step 601 Train Loss: 0.5165
Epoch 8 Step 651 Train Loss: 0.4687
Epoch 8 Step 701 Train Loss: 0.4777
Epoch 8 Step 751 Train Loss: 0.4502
Epoch 8 Step 801 Train Loss: 0.4830
Epoch 8 Step 851 Train Loss: 0.4894
Epoch 8 Step 901 Train Loss: 0.4882
Epoch 8: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0593 Validation Top 20 DE MSE: 0.1200. 
Epoch 9 Step 1 Train Loss: 0.5394
Epoch 9 Step 51 Train Loss: 0.4433
Epoch 9 Step 101 Train Loss: 0.4575
Epoch 9 Step 151 Train Loss: 0.5160
Epoch 9 Step 201 Train Loss: 0.5443
Epoch 9 Step 251 Train Loss: 0.5038
Epoch 9 Step 301 Train Loss: 0.4965
Epoch 9 Step 351 Train Loss: 0.4723
Epoch 9 Step 401 Train Loss: 0.5201
Epoch 9 Step 451 Train Loss: 0.5081
Epoch 9 Step 501 Train Loss: 0.5040
Epoch 9 Step 551 Train Loss: 0.4873
Epoch 9 Step 601 Train Loss: 0.4850
Epoch 9 Step 651 Train Loss: 0.4550
Epoch 9 Step 701 Train Loss: 0.4724
Epoch 9 Step 751 Train Loss: 0.4975
Epoch 9 Step 801 Train Loss: 0.5040
Epoch 9 Step 851 Train Loss: 0.4714
Epoch 9 Step 901 Train Loss: 0.4928
Epoch 9: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0583 Validation Top 20 DE MSE: 0.1184. 
Epoch 10 Step 1 Train Loss: 0.4877
Epoch 10 Step 51 Train Loss: 0.4782
Epoch 10 Step 101 Train Loss: 0.5004
Epoch 10 Step 151 Train Loss: 0.4998
Epoch 10 Step 201 Train Loss: 0.4634
Epoch 10 Step 251 Train Loss: 0.5019
Epoch 10 Step 301 Train Loss: 0.4807
Epoch 10 Step 351 Train Loss: 0.4976
Epoch 10 Step 401 Train Loss: 0.4845
Epoch 10 Step 451 Train Loss: 0.5019
Epoch 10 Step 501 Train Loss: 0.5199
Epoch 10 Step 551 Train Loss: 0.4814
Epoch 10 Step 601 Train Loss: 0.5145
Epoch 10 Step 651 Train Loss: 0.4723
Epoch 10 Step 701 Train Loss: 0.4801
Epoch 10 Step 751 Train Loss: 0.4992
Epoch 10 Step 801 Train Loss: 0.4894
Epoch 10 Step 851 Train Loss: 0.5130
Epoch 10 Step 901 Train Loss: 0.5268
Epoch 10: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0586 Validation Top 20 DE MSE: 0.1183. 
Epoch 11 Step 1 Train Loss: 0.5091
Epoch 11 Step 51 Train Loss: 0.5264
Epoch 11 Step 101 Train Loss: 0.4561
Epoch 11 Step 151 Train Loss: 0.4327
Epoch 11 Step 201 Train Loss: 0.5000
Epoch 11 Step 251 Train Loss: 0.4607
Epoch 11 Step 301 Train Loss: 0.5368
Epoch 11 Step 351 Train Loss: 0.4924
Epoch 11 Step 401 Train Loss: 0.5461
Epoch 11 Step 451 Train Loss: 0.4903
Epoch 11 Step 501 Train Loss: 0.5429
Epoch 11 Step 551 Train Loss: 0.4949
Epoch 11 Step 601 Train Loss: 0.4983
Epoch 11 Step 651 Train Loss: 0.5572
Epoch 11 Step 701 Train Loss: 0.4588
Epoch 11 Step 751 Train Loss: 0.4883
Epoch 11 Step 801 Train Loss: 0.5250
Epoch 11 Step 851 Train Loss: 0.4822
Epoch 11 Step 901 Train Loss: 0.5423
Epoch 11: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0578 Validation Top 20 DE MSE: 0.1180. 
Epoch 12 Step 1 Train Loss: 0.4496
Epoch 12 Step 51 Train Loss: 0.4741
Epoch 12 Step 101 Train Loss: 0.4874
Epoch 12 Step 151 Train Loss: 0.4814
Epoch 12 Step 201 Train Loss: 0.4821
Epoch 12 Step 251 Train Loss: 0.4546
Epoch 12 Step 301 Train Loss: 0.4922
Epoch 12 Step 351 Train Loss: 0.4651
Epoch 12 Step 401 Train Loss: 0.4816
Epoch 12 Step 451 Train Loss: 0.5118
Epoch 12 Step 501 Train Loss: 0.4701
Epoch 12 Step 551 Train Loss: 0.4655
Epoch 12 Step 601 Train Loss: 0.5012
Epoch 12 Step 651 Train Loss: 0.4898
Epoch 12 Step 701 Train Loss: 0.4820
Epoch 12 Step 751 Train Loss: 0.5283
Epoch 12 Step 801 Train Loss: 0.4828
Epoch 12 Step 851 Train Loss: 0.5200
Epoch 12 Step 901 Train Loss: 0.4721
Epoch 12: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0597 Validation Top 20 DE MSE: 0.1186. 
Epoch 13 Step 1 Train Loss: 0.4737
Epoch 13 Step 51 Train Loss: 0.4970
Epoch 13 Step 101 Train Loss: 0.4849
Epoch 13 Step 151 Train Loss: 0.4834
Epoch 13 Step 201 Train Loss: 0.4612
Epoch 13 Step 251 Train Loss: 0.4813
Epoch 13 Step 301 Train Loss: 0.4940
Epoch 13 Step 351 Train Loss: 0.5251
Epoch 13 Step 401 Train Loss: 0.4813
Epoch 13 Step 451 Train Loss: 0.4615
Epoch 13 Step 501 Train Loss: 0.5013
Epoch 13 Step 551 Train Loss: 0.4733
Epoch 13 Step 601 Train Loss: 0.4569
Epoch 13 Step 651 Train Loss: 0.5244
Epoch 13 Step 701 Train Loss: 0.4625
Epoch 13 Step 751 Train Loss: 0.5046
Epoch 13 Step 801 Train Loss: 0.4782
Epoch 13 Step 851 Train Loss: 0.4661
Epoch 13 Step 901 Train Loss: 0.4923
Epoch 13: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0562 Validation Top 20 DE MSE: 0.1159. 
Epoch 14 Step 1 Train Loss: 0.5058
Epoch 14 Step 51 Train Loss: 0.4783
Epoch 14 Step 101 Train Loss: 0.4614
Epoch 14 Step 151 Train Loss: 0.5270
Epoch 14 Step 201 Train Loss: 0.5043
Epoch 14 Step 251 Train Loss: 0.4735
Epoch 14 Step 301 Train Loss: 0.4827
Epoch 14 Step 351 Train Loss: 0.4563
Epoch 14 Step 401 Train Loss: 0.4949
Epoch 14 Step 451 Train Loss: 0.4860
Epoch 14 Step 501 Train Loss: 0.4777
Epoch 14 Step 551 Train Loss: 0.4791
Epoch 14 Step 601 Train Loss: 0.5026
Epoch 14 Step 651 Train Loss: 0.4860
Epoch 14 Step 701 Train Loss: 0.4822
Epoch 14 Step 751 Train Loss: 0.4981
Epoch 14 Step 801 Train Loss: 0.4925
Epoch 14 Step 851 Train Loss: 0.4550
Epoch 14 Step 901 Train Loss: 0.4647
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0574 Validation Top 20 DE MSE: 0.1184. 
Epoch 15 Step 1 Train Loss: 0.4693
Epoch 15 Step 51 Train Loss: 0.4591
Epoch 15 Step 101 Train Loss: 0.5074
Epoch 15 Step 151 Train Loss: 0.4651
Epoch 15 Step 201 Train Loss: 0.5378
Epoch 15 Step 251 Train Loss: 0.5218
Epoch 15 Step 301 Train Loss: 0.5106
Epoch 15 Step 351 Train Loss: 0.4768
Epoch 15 Step 401 Train Loss: 0.5233
Epoch 15 Step 451 Train Loss: 0.4816
Epoch 15 Step 501 Train Loss: 0.4706
Epoch 15 Step 551 Train Loss: 0.5281
Epoch 15 Step 601 Train Loss: 0.4858
Epoch 15 Step 651 Train Loss: 0.4861
Epoch 15 Step 701 Train Loss: 0.4937
Epoch 15 Step 751 Train Loss: 0.4804
Epoch 15 Step 801 Train Loss: 0.4640
Epoch 15 Step 851 Train Loss: 0.4674
Epoch 15 Step 901 Train Loss: 0.4904
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0583 Validation Top 20 DE MSE: 0.1174. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1350
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.004708915
test_combo_seen0_pearson: 0.9892566832701236
test_combo_seen0_mse_de: 0.10507342
test_combo_seen0_pearson_de: 0.6462422956556071
test_combo_seen1_mse: 0.0044041956
test_combo_seen1_pearson: 0.9901888609732935
test_combo_seen1_mse_de: 0.14009456
test_combo_seen1_pearson_de: 0.7711298898588781
test_combo_seen2_mse: 0.0033449112
test_combo_seen2_pearson: 0.9929606172506347
test_combo_seen2_mse_de: 0.10551888
test_combo_seen2_pearson_de: 0.9580466527241103
test_unseen_single_mse: 0.0028459367
test_unseen_single_pearson: 0.99351373309359
test_unseen_single_mse_de: 0.15384892
test_unseen_single_pearson_de: 0.908549361886088
test_combo_seen0_pearson_delta: 0.5264548883536456
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.13333333333333333
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.8888888888888888
test_combo_seen0_mse_top20_de_non_dropout: 0.19534257
test_combo_seen1_pearson_delta: 0.5995314024827862
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.12115384615384614
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.8884615384615385
test_combo_seen1_mse_top20_de_non_dropout: 0.17945625
test_combo_seen2_pearson_delta: 0.6554997231085173
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.049999999999999996
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.9470588235294116
test_combo_seen2_mse_top20_de_non_dropout: 0.11139188
test_unseen_single_pearson_delta: 0.38385504040935786
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.29814814814814816
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8944444444444444
test_unseen_single_mse_top20_de_non_dropout: 0.1745814
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.004 MB of 0.028 MB uploadedwandb: / 0.028 MB of 0.028 MB uploadedwandb: - 0.028 MB of 0.028 MB uploadedwandb: \ 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:                                                  val_pearson ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.13333
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.88889
wandb:                                         test_combo_seen0_mse 0.00471
wandb:                                      test_combo_seen0_mse_de 0.10507
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.19534
wandb:                                     test_combo_seen0_pearson 0.98926
wandb:                                  test_combo_seen0_pearson_de 0.64624
wandb:                               test_combo_seen0_pearson_delta 0.52645
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.12115
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.88846
wandb:                                         test_combo_seen1_mse 0.0044
wandb:                                      test_combo_seen1_mse_de 0.14009
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.17946
wandb:                                     test_combo_seen1_pearson 0.99019
wandb:                                  test_combo_seen1_pearson_de 0.77113
wandb:                               test_combo_seen1_pearson_delta 0.59953
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.05
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.94706
wandb:                                         test_combo_seen2_mse 0.00334
wandb:                                      test_combo_seen2_mse_de 0.10552
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.11139
wandb:                                     test_combo_seen2_pearson 0.99296
wandb:                                  test_combo_seen2_pearson_de 0.95805
wandb:                               test_combo_seen2_pearson_delta 0.6555
wandb:                                                  test_de_mse 0.13503
wandb:                                              test_de_pearson 0.82602
wandb:               test_frac_opposite_direction_top20_non_dropout 0.15619
wandb:                          test_frac_sigma_below_1_non_dropout 0.89952
wandb:                                                     test_mse 0.00386
wandb:                                test_mse_top20_de_non_dropout 0.16854
wandb:                                                 test_pearson 0.99141
wandb:                                           test_pearson_delta 0.54687
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.29815
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.89444
wandb:                                       test_unseen_single_mse 0.00285
wandb:                                    test_unseen_single_mse_de 0.15385
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.17458
wandb:                                   test_unseen_single_pearson 0.99351
wandb:                                test_unseen_single_pearson_de 0.90855
wandb:                             test_unseen_single_pearson_delta 0.38386
wandb:                                                 train_de_mse 0.05832
wandb:                                             train_de_pearson 0.92832
wandb:                                                    train_mse 0.00174
wandb:                                                train_pearson 0.9963
wandb:                                                training_loss 0.51721
wandb:                                                   val_de_mse 0.11745
wandb:                                               val_de_pearson 0.83331
wandb:                                                      val_mse 0.00342
wandb:                                                  val_pearson 0.99251
wandb: 
wandb: üöÄ View run gears_esm_NormanWeissman2019_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/g8fx05xv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_160216-g8fx05xv/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:7
combo_seen1:51
combo_seen2:18
unseen_single:27
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/gears_esm/wandb/run-20240923_171110-07ait722
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gears_esm_NormanWeissman2019_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/07ait722
Start Training...
Epoch 1 Step 1 Train Loss: 0.9283
Epoch 1 Step 51 Train Loss: 0.5507
Epoch 1 Step 101 Train Loss: 0.5499
Epoch 1 Step 151 Train Loss: 0.5369
Epoch 1 Step 201 Train Loss: 0.5404
Epoch 1 Step 251 Train Loss: 0.5280
Epoch 1 Step 301 Train Loss: 0.5083
Epoch 1 Step 351 Train Loss: 0.5195
Epoch 1 Step 401 Train Loss: 0.4449
Epoch 1 Step 451 Train Loss: 0.5131
Epoch 1 Step 501 Train Loss: 0.5219
Epoch 1 Step 551 Train Loss: 0.4779
Epoch 1 Step 601 Train Loss: 0.4764
Epoch 1 Step 651 Train Loss: 0.4468
Epoch 1 Step 701 Train Loss: 0.4897
Epoch 1 Step 751 Train Loss: 0.4555
Epoch 1 Step 801 Train Loss: 0.5120
Epoch 1 Step 851 Train Loss: 0.4888
Epoch 1 Step 901 Train Loss: 0.4870
Epoch 1: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.1410 Validation Top 20 DE MSE: 0.1853. 
Epoch 2 Step 1 Train Loss: 0.4669
Epoch 2 Step 51 Train Loss: 0.5381
Epoch 2 Step 101 Train Loss: 0.4575
Epoch 2 Step 151 Train Loss: 0.4498
Epoch 2 Step 201 Train Loss: 0.4601
Epoch 2 Step 251 Train Loss: 0.4899
Epoch 2 Step 301 Train Loss: 0.4811
Epoch 2 Step 351 Train Loss: 0.4564
Epoch 2 Step 401 Train Loss: 0.4739
Epoch 2 Step 451 Train Loss: 0.4502
Epoch 2 Step 501 Train Loss: 0.4998
Epoch 2 Step 551 Train Loss: 0.4450
Epoch 2 Step 601 Train Loss: 0.4593
Epoch 2 Step 651 Train Loss: 0.4909
Epoch 2 Step 701 Train Loss: 0.4364
Epoch 2 Step 751 Train Loss: 0.4970
Epoch 2 Step 801 Train Loss: 0.4863
Epoch 2 Step 851 Train Loss: 0.4491
Epoch 2 Step 901 Train Loss: 0.5059
Epoch 2: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.1010 Validation Top 20 DE MSE: 0.1717. 
Epoch 3 Step 1 Train Loss: 0.4415
Epoch 3 Step 51 Train Loss: 0.4670
Epoch 3 Step 101 Train Loss: 0.4802
Epoch 3 Step 151 Train Loss: 0.5059
Epoch 3 Step 201 Train Loss: 0.4608
Epoch 3 Step 251 Train Loss: 0.4932
Epoch 3 Step 301 Train Loss: 0.4820
Epoch 3 Step 351 Train Loss: 0.4943
Epoch 3 Step 401 Train Loss: 0.5090
Epoch 3 Step 451 Train Loss: 0.5156
Epoch 3 Step 501 Train Loss: 0.4755
Epoch 3 Step 551 Train Loss: 0.4698
Epoch 3 Step 601 Train Loss: 0.4836
Epoch 3 Step 651 Train Loss: 0.5087
Epoch 3 Step 701 Train Loss: 0.5092
Epoch 3 Step 751 Train Loss: 0.4634
Epoch 3 Step 801 Train Loss: 0.4745
Epoch 3 Step 851 Train Loss: 0.4631
Epoch 3 Step 901 Train Loss: 0.4709
Epoch 3: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0881 Validation Top 20 DE MSE: 0.1883. 
Epoch 4 Step 1 Train Loss: 0.4682
Epoch 4 Step 51 Train Loss: 0.4889
Epoch 4 Step 101 Train Loss: 0.5099
Epoch 4 Step 151 Train Loss: 0.4614
Epoch 4 Step 201 Train Loss: 0.4913
Epoch 4 Step 251 Train Loss: 0.4983
Epoch 4 Step 301 Train Loss: 0.5426
Epoch 4 Step 351 Train Loss: 0.5407
Epoch 4 Step 401 Train Loss: 0.4645
Epoch 4 Step 451 Train Loss: 0.4697
Epoch 4 Step 501 Train Loss: 0.4545
Epoch 4 Step 551 Train Loss: 0.4879
Epoch 4 Step 601 Train Loss: 0.5461
Epoch 4 Step 651 Train Loss: 0.4894
Epoch 4 Step 701 Train Loss: 0.4681
Epoch 4 Step 751 Train Loss: 0.5065
Epoch 4 Step 801 Train Loss: 0.4786
Epoch 4 Step 851 Train Loss: 0.5123
Epoch 4 Step 901 Train Loss: 0.4606
Epoch 4: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0658 Validation Top 20 DE MSE: 0.1499. 
Epoch 5 Step 1 Train Loss: 0.4580
Epoch 5 Step 51 Train Loss: 0.4647
Epoch 5 Step 101 Train Loss: 0.5025
Epoch 5 Step 151 Train Loss: 0.4907
Epoch 5 Step 201 Train Loss: 0.4726
Epoch 5 Step 251 Train Loss: 0.4702
Epoch 5 Step 301 Train Loss: 0.5258
Epoch 5 Step 351 Train Loss: 0.5181
Epoch 5 Step 401 Train Loss: 0.4803
Epoch 5 Step 451 Train Loss: 0.4939
Epoch 5 Step 501 Train Loss: 0.4871
Epoch 5 Step 551 Train Loss: 0.5085
Epoch 5 Step 601 Train Loss: 0.5076
Epoch 5 Step 651 Train Loss: 0.4945
Epoch 5 Step 701 Train Loss: 0.4963
Epoch 5 Step 751 Train Loss: 0.4849
Epoch 5 Step 801 Train Loss: 0.4780
Epoch 5 Step 851 Train Loss: 0.5496
Epoch 5 Step 901 Train Loss: 0.4816
Epoch 5: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0679 Validation Top 20 DE MSE: 0.1475. 
Epoch 6 Step 1 Train Loss: 0.4763
Epoch 6 Step 51 Train Loss: 0.5112
Epoch 6 Step 101 Train Loss: 0.5424
Epoch 6 Step 151 Train Loss: 0.5271
Epoch 6 Step 201 Train Loss: 0.5174
Epoch 6 Step 251 Train Loss: 0.4776
Epoch 6 Step 301 Train Loss: 0.4995
Epoch 6 Step 351 Train Loss: 0.4622
Epoch 6 Step 401 Train Loss: 0.5119
Epoch 6 Step 451 Train Loss: 0.4633
Epoch 6 Step 501 Train Loss: 0.5448
Epoch 6 Step 551 Train Loss: 0.4931
Epoch 6 Step 601 Train Loss: 0.5007
Epoch 6 Step 651 Train Loss: 0.5010
Epoch 6 Step 701 Train Loss: 0.5141
Epoch 6 Step 751 Train Loss: 0.4574
Epoch 6 Step 801 Train Loss: 0.4750
Epoch 6 Step 851 Train Loss: 0.4853
Epoch 6 Step 901 Train Loss: 0.4898
Epoch 6: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0573 Validation Top 20 DE MSE: 0.1431. 
Epoch 7 Step 1 Train Loss: 0.5170
Epoch 7 Step 51 Train Loss: 0.4936
Epoch 7 Step 101 Train Loss: 0.4770
Epoch 7 Step 151 Train Loss: 0.4891
Epoch 7 Step 201 Train Loss: 0.4754
Epoch 7 Step 251 Train Loss: 0.5042
Epoch 7 Step 301 Train Loss: 0.4779
Epoch 7 Step 351 Train Loss: 0.4947
Epoch 7 Step 401 Train Loss: 0.4925
Epoch 7 Step 451 Train Loss: 0.4691
Epoch 7 Step 501 Train Loss: 0.4860
Epoch 7 Step 551 Train Loss: 0.5315
Epoch 7 Step 601 Train Loss: 0.4629
Epoch 7 Step 651 Train Loss: 0.5053
Epoch 7 Step 701 Train Loss: 0.5299
Epoch 7 Step 751 Train Loss: 0.5062
Epoch 7 Step 801 Train Loss: 0.5418
Epoch 7 Step 851 Train Loss: 0.4926
Epoch 7 Step 901 Train Loss: 0.4979
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0519 Validation Top 20 DE MSE: 0.1334. 
Epoch 8 Step 1 Train Loss: 0.4743
Epoch 8 Step 51 Train Loss: 0.4798
Epoch 8 Step 101 Train Loss: 0.4596
Epoch 8 Step 151 Train Loss: 0.4715
Epoch 8 Step 201 Train Loss: 0.4850
Epoch 8 Step 251 Train Loss: 0.4695
Epoch 8 Step 301 Train Loss: 0.4674
Epoch 8 Step 351 Train Loss: 0.5015
Epoch 8 Step 401 Train Loss: 0.5226
Epoch 8 Step 451 Train Loss: 0.4566
Epoch 8 Step 501 Train Loss: 0.4865
Epoch 8 Step 551 Train Loss: 0.4703
Epoch 8 Step 601 Train Loss: 0.4932
Epoch 8 Step 651 Train Loss: 0.5020
Epoch 8 Step 701 Train Loss: 0.5054
Epoch 8 Step 751 Train Loss: 0.5176
Epoch 8 Step 801 Train Loss: 0.4910
Epoch 8 Step 851 Train Loss: 0.4747
Epoch 8 Step 901 Train Loss: 0.4961
Epoch 8: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0560 Validation Top 20 DE MSE: 0.1378. 
Epoch 9 Step 1 Train Loss: 0.5074
Epoch 9 Step 51 Train Loss: 0.4942
Epoch 9 Step 101 Train Loss: 0.4861
Epoch 9 Step 151 Train Loss: 0.4832
Epoch 9 Step 201 Train Loss: 0.5213
Epoch 9 Step 251 Train Loss: 0.5076
Epoch 9 Step 301 Train Loss: 0.5110
Epoch 9 Step 351 Train Loss: 0.4755
Epoch 9 Step 401 Train Loss: 0.5292
Epoch 9 Step 451 Train Loss: 0.5450
Epoch 9 Step 501 Train Loss: 0.4968
Epoch 9 Step 551 Train Loss: 0.4454
Epoch 9 Step 601 Train Loss: 0.4961
Epoch 9 Step 651 Train Loss: 0.5084
Epoch 9 Step 701 Train Loss: 0.5024
Epoch 9 Step 751 Train Loss: 0.5031
Epoch 9 Step 801 Train Loss: 0.5370
Epoch 9 Step 851 Train Loss: 0.5144
Epoch 9 Step 901 Train Loss: 0.4637
Epoch 9: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0513 Validation Top 20 DE MSE: 0.1326. 
Epoch 10 Step 1 Train Loss: 0.4821
Epoch 10 Step 51 Train Loss: 0.4849
Epoch 10 Step 101 Train Loss: 0.5617
Epoch 10 Step 151 Train Loss: 0.4940
Epoch 10 Step 201 Train Loss: 0.4561
Epoch 10 Step 251 Train Loss: 0.4989
Epoch 10 Step 301 Train Loss: 0.5167
Epoch 10 Step 351 Train Loss: 0.5436
Epoch 10 Step 401 Train Loss: 0.4990
Epoch 10 Step 451 Train Loss: 0.4844
Epoch 10 Step 501 Train Loss: 0.5694
Epoch 10 Step 551 Train Loss: 0.5252
Epoch 10 Step 601 Train Loss: 0.5127
Epoch 10 Step 651 Train Loss: 0.4889
Epoch 10 Step 701 Train Loss: 0.5320
Epoch 10 Step 751 Train Loss: 0.4692
Epoch 10 Step 801 Train Loss: 0.5120
Epoch 10 Step 851 Train Loss: 0.4805
Epoch 10 Step 901 Train Loss: 0.4949
Epoch 10: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0529 Validation Top 20 DE MSE: 0.1372. 
Epoch 11 Step 1 Train Loss: 0.5154
Epoch 11 Step 51 Train Loss: 0.4687
Epoch 11 Step 101 Train Loss: 0.4890
Epoch 11 Step 151 Train Loss: 0.5373
Epoch 11 Step 201 Train Loss: 0.4912
Epoch 11 Step 251 Train Loss: 0.5033
Epoch 11 Step 301 Train Loss: 0.4907
Epoch 11 Step 351 Train Loss: 0.5056
Epoch 11 Step 401 Train Loss: 0.4906
Epoch 11 Step 451 Train Loss: 0.5341
Epoch 11 Step 501 Train Loss: 0.5089
Epoch 11 Step 551 Train Loss: 0.5491
Epoch 11 Step 601 Train Loss: 0.4799
Epoch 11 Step 651 Train Loss: 0.5156
Epoch 11 Step 701 Train Loss: 0.4747
Epoch 11 Step 751 Train Loss: 0.5152
Epoch 11 Step 801 Train Loss: 0.5111
Epoch 11 Step 851 Train Loss: 0.5004
Epoch 11 Step 901 Train Loss: 0.4860
Epoch 11: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0528 Validation Top 20 DE MSE: 0.1360. 
Epoch 12 Step 1 Train Loss: 0.4690
Epoch 12 Step 51 Train Loss: 0.4821
Epoch 12 Step 101 Train Loss: 0.4500
Epoch 12 Step 151 Train Loss: 0.4932
Epoch 12 Step 201 Train Loss: 0.4578
Epoch 12 Step 251 Train Loss: 0.5090
Epoch 12 Step 301 Train Loss: 0.5163
Epoch 12 Step 351 Train Loss: 0.5135
Epoch 12 Step 401 Train Loss: 0.4782
Epoch 12 Step 451 Train Loss: 0.5483
Epoch 12 Step 501 Train Loss: 0.5965
Epoch 12 Step 551 Train Loss: 0.5048
Epoch 12 Step 601 Train Loss: 0.5077
Epoch 12 Step 651 Train Loss: 0.4930
Epoch 12 Step 701 Train Loss: 0.5273
Epoch 12 Step 751 Train Loss: 0.5194
Epoch 12 Step 801 Train Loss: 0.4816
Epoch 12 Step 851 Train Loss: 0.4803
Epoch 12 Step 901 Train Loss: 0.5158
Epoch 12: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0521 Validation Top 20 DE MSE: 0.1354. 
Epoch 13 Step 1 Train Loss: 0.4918
Epoch 13 Step 51 Train Loss: 0.4935
Epoch 13 Step 101 Train Loss: 0.4992
Epoch 13 Step 151 Train Loss: 0.5575
Epoch 13 Step 201 Train Loss: 0.5169
Epoch 13 Step 251 Train Loss: 0.4773
Epoch 13 Step 301 Train Loss: 0.4765
Epoch 13 Step 351 Train Loss: 0.5381
Epoch 13 Step 401 Train Loss: 0.4848
Epoch 13 Step 451 Train Loss: 0.5026
Epoch 13 Step 501 Train Loss: 0.5629
Epoch 13 Step 551 Train Loss: 0.4836
Epoch 13 Step 601 Train Loss: 0.4980
Epoch 13 Step 651 Train Loss: 0.5015
Epoch 13 Step 701 Train Loss: 0.4868
Epoch 13 Step 751 Train Loss: 0.4898
Epoch 13 Step 801 Train Loss: 0.4920
Epoch 13 Step 851 Train Loss: 0.4888
Epoch 13 Step 901 Train Loss: 0.5384
Epoch 13: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0541 Validation Top 20 DE MSE: 0.1377. 
Epoch 14 Step 1 Train Loss: 0.5259
Epoch 14 Step 51 Train Loss: 0.4837
Epoch 14 Step 101 Train Loss: 0.5227
Epoch 14 Step 151 Train Loss: 0.5037
Epoch 14 Step 201 Train Loss: 0.4965
Epoch 14 Step 251 Train Loss: 0.4995
Epoch 14 Step 301 Train Loss: 0.4763
Epoch 14 Step 351 Train Loss: 0.5391
Epoch 14 Step 401 Train Loss: 0.4515
Epoch 14 Step 451 Train Loss: 0.4763
Epoch 14 Step 501 Train Loss: 0.4705
Epoch 14 Step 551 Train Loss: 0.5026
Epoch 14 Step 601 Train Loss: 0.4907
Epoch 14 Step 651 Train Loss: 0.4995
Epoch 14 Step 701 Train Loss: 0.5034
Epoch 14 Step 751 Train Loss: 0.5030
Epoch 14 Step 801 Train Loss: 0.4905
Epoch 14 Step 851 Train Loss: 0.4913
Epoch 14 Step 901 Train Loss: 0.5044
Epoch 14: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0525 Validation Top 20 DE MSE: 0.1369. 
Epoch 15 Step 1 Train Loss: 0.4928
Epoch 15 Step 51 Train Loss: 0.4973
Epoch 15 Step 101 Train Loss: 0.5053
Epoch 15 Step 151 Train Loss: 0.4751
Epoch 15 Step 201 Train Loss: 0.4998
Epoch 15 Step 251 Train Loss: 0.5378
Epoch 15 Step 301 Train Loss: 0.4894
Epoch 15 Step 351 Train Loss: 0.4835
Epoch 15 Step 401 Train Loss: 0.4676
Epoch 15 Step 451 Train Loss: 0.5159
Epoch 15 Step 501 Train Loss: 0.5010
Epoch 15 Step 551 Train Loss: 0.5142
Epoch 15 Step 601 Train Loss: 0.4996
Epoch 15 Step 651 Train Loss: 0.4504
Epoch 15 Step 701 Train Loss: 0.5000
Epoch 15 Step 751 Train Loss: 0.5003
Epoch 15 Step 801 Train Loss: 0.5125
Epoch 15 Step 851 Train Loss: 0.4973
Epoch 15 Step 901 Train Loss: 0.4977
Epoch 15: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0549 Validation Top 20 DE MSE: 0.1399. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1417
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0055623623
test_combo_seen0_pearson: 0.9872244362868967
test_combo_seen0_mse_de: 0.16184841
test_combo_seen0_pearson_de: 0.8061937868629391
test_combo_seen1_mse: 0.0037932738
test_combo_seen1_pearson: 0.9914849616991781
test_combo_seen1_mse_de: 0.15053673
test_combo_seen1_pearson_de: 0.7958873995088811
test_combo_seen2_mse: 0.0032131497
test_combo_seen2_pearson: 0.9930442404226442
test_combo_seen2_mse_de: 0.07477511
test_combo_seen2_pearson_de: 0.812919133431532
test_unseen_single_mse: 0.0028690519
test_unseen_single_pearson: 0.9933894182817473
test_unseen_single_mse_de: 0.16431452
test_unseen_single_pearson_de: 0.9000491567843987
test_combo_seen0_pearson_delta: 0.5513956919939422
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.15
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.8928571428571429
test_combo_seen0_mse_top20_de_non_dropout: 0.24776462
test_combo_seen1_pearson_delta: 0.6195178484487678
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.11764705882352941
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.8813725490196079
test_combo_seen1_mse_top20_de_non_dropout: 0.1875094
test_combo_seen2_pearson_delta: 0.6566342027593837
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.08611111111111111
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.9500000000000001
test_combo_seen2_mse_top20_de_non_dropout: 0.09073834
test_unseen_single_pearson_delta: 0.38910598174853606
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2388888888888889
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8925925925925925
test_unseen_single_mse_top20_de_non_dropout: 0.19073875
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.009 MB of 0.028 MB uploadedwandb: / 0.009 MB of 0.028 MB uploadedwandb: - 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá
wandb:                                                      val_mse ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:                                                  val_pearson ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.15
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.89286
wandb:                                         test_combo_seen0_mse 0.00556
wandb:                                      test_combo_seen0_mse_de 0.16185
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.24776
wandb:                                     test_combo_seen0_pearson 0.98722
wandb:                                  test_combo_seen0_pearson_de 0.80619
wandb:                               test_combo_seen0_pearson_delta 0.5514
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.11765
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.88137
wandb:                                         test_combo_seen1_mse 0.00379
wandb:                                      test_combo_seen1_mse_de 0.15054
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.18751
wandb:                                     test_combo_seen1_pearson 0.99148
wandb:                                  test_combo_seen1_pearson_de 0.79589
wandb:                               test_combo_seen1_pearson_delta 0.61952
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.08611
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.95
wandb:                                         test_combo_seen2_mse 0.00321
wandb:                                      test_combo_seen2_mse_de 0.07478
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.09074
wandb:                                     test_combo_seen2_pearson 0.99304
wandb:                                  test_combo_seen2_pearson_de 0.81292
wandb:                               test_combo_seen2_pearson_delta 0.65663
wandb:                                                  test_de_mse 0.14168
wandb:                                              test_de_pearson 0.82687
wandb:               test_frac_opposite_direction_top20_non_dropout 0.14612
wandb:                          test_frac_sigma_below_1_non_dropout 0.89709
wandb:                                                     test_mse 0.00357
wandb:                                test_mse_top20_de_non_dropout 0.17554
wandb:                                                 test_pearson 0.99197
wandb:                                           test_pearson_delta 0.56098
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.23889
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.89259
wandb:                                       test_unseen_single_mse 0.00287
wandb:                                    test_unseen_single_mse_de 0.16431
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.19074
wandb:                                   test_unseen_single_pearson 0.99339
wandb:                                test_unseen_single_pearson_de 0.90005
wandb:                             test_unseen_single_pearson_delta 0.38911
wandb:                                                 train_de_mse 0.0549
wandb:                                             train_de_pearson 0.93079
wandb:                                                    train_mse 0.00163
wandb:                                                train_pearson 0.99649
wandb:                                                training_loss 0.50482
wandb:                                                   val_de_mse 0.13987
wandb:                                               val_de_pearson 0.79428
wandb:                                                      val_mse 0.00317
wandb:                                                  val_pearson 0.99308
wandb: 
wandb: üöÄ View run gears_esm_NormanWeissman2019_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/07ait722
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_171110-07ait722/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:2
combo_seen1:39
combo_seen2:23
unseen_single:27
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/gears_esm/wandb/run-20240923_181300-vej4id8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gears_esm_NormanWeissman2019_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/vej4id8f
Start Training...
Epoch 1 Step 1 Train Loss: 1.0313
Epoch 1 Step 51 Train Loss: 0.5447
Epoch 1 Step 101 Train Loss: 0.5492
Epoch 1 Step 151 Train Loss: 0.5237
Epoch 1 Step 201 Train Loss: 0.4831
Epoch 1 Step 251 Train Loss: 0.5201
Epoch 1 Step 301 Train Loss: 0.5026
Epoch 1 Step 351 Train Loss: 0.5147
Epoch 1 Step 401 Train Loss: 0.4912
Epoch 1 Step 451 Train Loss: 0.4984
Epoch 1 Step 501 Train Loss: 0.5798
Epoch 1 Step 551 Train Loss: 0.4663
Epoch 1 Step 601 Train Loss: 0.4742
Epoch 1 Step 651 Train Loss: 0.5327
Epoch 1 Step 701 Train Loss: 0.4923
Epoch 1 Step 751 Train Loss: 0.5040
Epoch 1 Step 801 Train Loss: 0.4909
Epoch 1 Step 851 Train Loss: 0.5185
Epoch 1 Step 901 Train Loss: 0.4798
Epoch 1: Train Overall MSE: 0.0034 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.1009 Validation Top 20 DE MSE: 0.1691. 
Epoch 2 Step 1 Train Loss: 0.5106
Epoch 2 Step 51 Train Loss: 0.4372
Epoch 2 Step 101 Train Loss: 0.5122
Epoch 2 Step 151 Train Loss: 0.4880
Epoch 2 Step 201 Train Loss: 0.4774
Epoch 2 Step 251 Train Loss: 0.4338
Epoch 2 Step 301 Train Loss: 0.4723
Epoch 2 Step 351 Train Loss: 0.5006
Epoch 2 Step 401 Train Loss: 0.4558
Epoch 2 Step 451 Train Loss: 0.4836
Epoch 2 Step 501 Train Loss: 0.4918
Epoch 2 Step 551 Train Loss: 0.4886
Epoch 2 Step 601 Train Loss: 0.4834
Epoch 2 Step 651 Train Loss: 0.4964
Epoch 2 Step 701 Train Loss: 0.4612
Epoch 2 Step 751 Train Loss: 0.4902
Epoch 2 Step 801 Train Loss: 0.5363
Epoch 2 Step 851 Train Loss: 0.5052
Epoch 2 Step 901 Train Loss: 0.5130
Epoch 2: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0957 Validation Top 20 DE MSE: 0.1645. 
Epoch 3 Step 1 Train Loss: 0.5342
Epoch 3 Step 51 Train Loss: 0.5452
Epoch 3 Step 101 Train Loss: 0.4855
Epoch 3 Step 151 Train Loss: 0.5172
Epoch 3 Step 201 Train Loss: 0.4597
Epoch 3 Step 251 Train Loss: 0.5104
Epoch 3 Step 301 Train Loss: 0.4936
Epoch 3 Step 351 Train Loss: 0.5037
Epoch 3 Step 401 Train Loss: 0.4744
Epoch 3 Step 451 Train Loss: 0.5320
Epoch 3 Step 501 Train Loss: 0.4958
Epoch 3 Step 551 Train Loss: 0.4990
Epoch 3 Step 601 Train Loss: 0.5081
Epoch 3 Step 651 Train Loss: 0.5132
Epoch 3 Step 701 Train Loss: 0.5014
Epoch 3 Step 751 Train Loss: 0.5009
Epoch 3 Step 801 Train Loss: 0.5398
Epoch 3 Step 851 Train Loss: 0.4950
Epoch 3 Step 901 Train Loss: 0.4838
Epoch 3: Train Overall MSE: 0.0029 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0893 Validation Top 20 DE MSE: 0.2128. 
Epoch 4 Step 1 Train Loss: 0.4882
Epoch 4 Step 51 Train Loss: 0.5226
Epoch 4 Step 101 Train Loss: 0.4868
Epoch 4 Step 151 Train Loss: 0.4940
Epoch 4 Step 201 Train Loss: 0.4915
Epoch 4 Step 251 Train Loss: 0.4646
Epoch 4 Step 301 Train Loss: 0.4724
Epoch 4 Step 351 Train Loss: 0.4974
Epoch 4 Step 401 Train Loss: 0.4926
Epoch 4 Step 451 Train Loss: 0.4956
Epoch 4 Step 501 Train Loss: 0.5140
Epoch 4 Step 551 Train Loss: 0.4936
Epoch 4 Step 601 Train Loss: 0.4724
Epoch 4 Step 651 Train Loss: 0.5114
Epoch 4 Step 701 Train Loss: 0.4994
Epoch 4 Step 751 Train Loss: 0.4774
Epoch 4 Step 801 Train Loss: 0.4561
Epoch 4 Step 851 Train Loss: 0.5274
Epoch 4 Step 901 Train Loss: 0.5009
Epoch 4: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0609 Validation Top 20 DE MSE: 0.1544. 
Epoch 5 Step 1 Train Loss: 0.5004
Epoch 5 Step 51 Train Loss: 0.5067
Epoch 5 Step 101 Train Loss: 0.5191
Epoch 5 Step 151 Train Loss: 0.4986
Epoch 5 Step 201 Train Loss: 0.5495
Epoch 5 Step 251 Train Loss: 0.5156
Epoch 5 Step 301 Train Loss: 0.5037
Epoch 5 Step 351 Train Loss: 0.4939
Epoch 5 Step 401 Train Loss: 0.5154
Epoch 5 Step 451 Train Loss: 0.4755
Epoch 5 Step 501 Train Loss: 0.4774
Epoch 5 Step 551 Train Loss: 0.4895
Epoch 5 Step 601 Train Loss: 0.5236
Epoch 5 Step 651 Train Loss: 0.4662
Epoch 5 Step 701 Train Loss: 0.5007
Epoch 5 Step 751 Train Loss: 0.5195
Epoch 5 Step 801 Train Loss: 0.5239
Epoch 5 Step 851 Train Loss: 0.5487
Epoch 5 Step 901 Train Loss: 0.5346
Epoch 5: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0589 Validation Top 20 DE MSE: 0.1613. 
Epoch 6 Step 1 Train Loss: 0.5699
Epoch 6 Step 51 Train Loss: 0.5048
Epoch 6 Step 101 Train Loss: 0.4824
Epoch 6 Step 151 Train Loss: 0.5350
Epoch 6 Step 201 Train Loss: 0.4992
Epoch 6 Step 251 Train Loss: 0.5232
Epoch 6 Step 301 Train Loss: 0.5267
Epoch 6 Step 351 Train Loss: 0.4748
Epoch 6 Step 401 Train Loss: 0.5528
Epoch 6 Step 451 Train Loss: 0.5067
Epoch 6 Step 501 Train Loss: 0.5603
Epoch 6 Step 551 Train Loss: 0.5260
Epoch 6 Step 601 Train Loss: 0.5032
Epoch 6 Step 651 Train Loss: 0.5221
Epoch 6 Step 701 Train Loss: 0.5782
Epoch 6 Step 751 Train Loss: 0.5175
Epoch 6 Step 801 Train Loss: 0.5071
Epoch 6 Step 851 Train Loss: 0.4936
Epoch 6 Step 901 Train Loss: 0.5315
Epoch 6: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0555 Validation Top 20 DE MSE: 0.1597. 
Epoch 7 Step 1 Train Loss: 0.5291
Epoch 7 Step 51 Train Loss: 0.4895
Epoch 7 Step 101 Train Loss: 0.5114
Epoch 7 Step 151 Train Loss: 0.4875
Epoch 7 Step 201 Train Loss: 0.5239
Epoch 7 Step 251 Train Loss: 0.5157
Epoch 7 Step 301 Train Loss: 0.4835
Epoch 7 Step 351 Train Loss: 0.5177
Epoch 7 Step 401 Train Loss: 0.5542
Epoch 7 Step 451 Train Loss: 0.5431
Epoch 7 Step 501 Train Loss: 0.5152
Epoch 7 Step 551 Train Loss: 0.5040
Epoch 7 Step 601 Train Loss: 0.4872
Epoch 7 Step 651 Train Loss: 0.5127
Epoch 7 Step 701 Train Loss: 0.5038
Epoch 7 Step 751 Train Loss: 0.4848
Epoch 7 Step 801 Train Loss: 0.5295
Epoch 7 Step 851 Train Loss: 0.5123
Epoch 7 Step 901 Train Loss: 0.5068
Epoch 7: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0549 Validation Top 20 DE MSE: 0.1568. 
Epoch 8 Step 1 Train Loss: 0.5245
Epoch 8 Step 51 Train Loss: 0.5206
Epoch 8 Step 101 Train Loss: 0.4935
Epoch 8 Step 151 Train Loss: 0.5183
Epoch 8 Step 201 Train Loss: 0.4770
Epoch 8 Step 251 Train Loss: 0.5078
Epoch 8 Step 301 Train Loss: 0.5546
Epoch 8 Step 351 Train Loss: 0.4791
Epoch 8 Step 401 Train Loss: 0.5188
Epoch 8 Step 451 Train Loss: 0.4947
Epoch 8 Step 501 Train Loss: 0.5231
Epoch 8 Step 551 Train Loss: 0.4983
Epoch 8 Step 601 Train Loss: 0.4869
Epoch 8 Step 651 Train Loss: 0.5271
Epoch 8 Step 701 Train Loss: 0.4831
Epoch 8 Step 751 Train Loss: 0.4997
Epoch 8 Step 801 Train Loss: 0.5211
Epoch 8 Step 851 Train Loss: 0.4929
Epoch 8 Step 901 Train Loss: 0.4956
Epoch 8: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0552 Validation Top 20 DE MSE: 0.1595. 
Epoch 9 Step 1 Train Loss: 0.5216
Epoch 9 Step 51 Train Loss: 0.5467
Epoch 9 Step 101 Train Loss: 0.5058
Epoch 9 Step 151 Train Loss: 0.5276
Epoch 9 Step 201 Train Loss: 0.4614
Epoch 9 Step 251 Train Loss: 0.5035
Epoch 9 Step 301 Train Loss: 0.4982
Epoch 9 Step 351 Train Loss: 0.4983
Epoch 9 Step 401 Train Loss: 0.4942
Epoch 9 Step 451 Train Loss: 0.5008
Epoch 9 Step 501 Train Loss: 0.5181
Epoch 9 Step 551 Train Loss: 0.5590
Epoch 9 Step 601 Train Loss: 0.5101
Epoch 9 Step 651 Train Loss: 0.4904
Epoch 9 Step 701 Train Loss: 0.4940
Epoch 9 Step 751 Train Loss: 0.4656
Epoch 9 Step 801 Train Loss: 0.4752
Epoch 9 Step 851 Train Loss: 0.5118
Epoch 9 Step 901 Train Loss: 0.5043
Epoch 9: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0547 Validation Top 20 DE MSE: 0.1581. 
Epoch 10 Step 1 Train Loss: 0.5233
Epoch 10 Step 51 Train Loss: 0.4921
Epoch 10 Step 101 Train Loss: 0.4781
Epoch 10 Step 151 Train Loss: 0.4941
Epoch 10 Step 201 Train Loss: 0.5209
Epoch 10 Step 251 Train Loss: 0.5159
Epoch 10 Step 301 Train Loss: 0.5448
Epoch 10 Step 351 Train Loss: 0.4788
Epoch 10 Step 401 Train Loss: 0.5548
Epoch 10 Step 451 Train Loss: 0.5643
Epoch 10 Step 501 Train Loss: 0.4922
Epoch 10 Step 551 Train Loss: 0.5120
Epoch 10 Step 601 Train Loss: 0.5117
Epoch 10 Step 651 Train Loss: 0.5245
Epoch 10 Step 701 Train Loss: 0.5013
Epoch 10 Step 751 Train Loss: 0.5049
Epoch 10 Step 801 Train Loss: 0.4923
Epoch 10 Step 851 Train Loss: 0.5145
Epoch 10 Step 901 Train Loss: 0.5397
Epoch 10: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0548 Validation Top 20 DE MSE: 0.1616. 
Epoch 11 Step 1 Train Loss: 0.4750
Epoch 11 Step 51 Train Loss: 0.4939
Epoch 11 Step 101 Train Loss: 0.4891
Epoch 11 Step 151 Train Loss: 0.4839
Epoch 11 Step 201 Train Loss: 0.4764
Epoch 11 Step 251 Train Loss: 0.5100
Epoch 11 Step 301 Train Loss: 0.5070
Epoch 11 Step 351 Train Loss: 0.5288
Epoch 11 Step 401 Train Loss: 0.5127
Epoch 11 Step 451 Train Loss: 0.5133
Epoch 11 Step 501 Train Loss: 0.4822
Epoch 11 Step 551 Train Loss: 0.5346
Epoch 11 Step 601 Train Loss: 0.5285
Epoch 11 Step 651 Train Loss: 0.5218
Epoch 11 Step 701 Train Loss: 0.5009
Epoch 11 Step 751 Train Loss: 0.5075
Epoch 11 Step 801 Train Loss: 0.5106
Epoch 11 Step 851 Train Loss: 0.5491
Epoch 11 Step 901 Train Loss: 0.4875
Epoch 11: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0549 Validation Top 20 DE MSE: 0.1640. 
Epoch 12 Step 1 Train Loss: 0.4774
Epoch 12 Step 51 Train Loss: 0.5266
Epoch 12 Step 101 Train Loss: 0.5111
Epoch 12 Step 151 Train Loss: 0.5003
Epoch 12 Step 201 Train Loss: 0.5129
Epoch 12 Step 251 Train Loss: 0.5053
Epoch 12 Step 301 Train Loss: 0.5517
Epoch 12 Step 351 Train Loss: 0.4852
Epoch 12 Step 401 Train Loss: 0.5517
Epoch 12 Step 451 Train Loss: 0.5257
Epoch 12 Step 501 Train Loss: 0.4608
Epoch 12 Step 551 Train Loss: 0.5220
Epoch 12 Step 601 Train Loss: 0.4861
Epoch 12 Step 651 Train Loss: 0.5073
Epoch 12 Step 701 Train Loss: 0.4906
Epoch 12 Step 751 Train Loss: 0.4908
Epoch 12 Step 801 Train Loss: 0.5020
Epoch 12 Step 851 Train Loss: 0.4923
Epoch 12 Step 901 Train Loss: 0.5256
Epoch 12: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0549 Validation Top 20 DE MSE: 0.1604. 
Epoch 13 Step 1 Train Loss: 0.4943
Epoch 13 Step 51 Train Loss: 0.5083
Epoch 13 Step 101 Train Loss: 0.4910
Epoch 13 Step 151 Train Loss: 0.5046
Epoch 13 Step 201 Train Loss: 0.5175
Epoch 13 Step 251 Train Loss: 0.5031
Epoch 13 Step 301 Train Loss: 0.5144
Epoch 13 Step 351 Train Loss: 0.5271
Epoch 13 Step 401 Train Loss: 0.5003
Epoch 13 Step 451 Train Loss: 0.4621
Epoch 13 Step 501 Train Loss: 0.5316
Epoch 13 Step 551 Train Loss: 0.4714
Epoch 13 Step 601 Train Loss: 0.4946
Epoch 13 Step 651 Train Loss: 0.5085
Epoch 13 Step 701 Train Loss: 0.5037
Epoch 13 Step 751 Train Loss: 0.4846
Epoch 13 Step 801 Train Loss: 0.5321
Epoch 13 Step 851 Train Loss: 0.5278
Epoch 13 Step 901 Train Loss: 0.5059
Epoch 13: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0542 Validation Top 20 DE MSE: 0.1626. 
Epoch 14 Step 1 Train Loss: 0.5236
Epoch 14 Step 51 Train Loss: 0.5011
Epoch 14 Step 101 Train Loss: 0.4975
Epoch 14 Step 151 Train Loss: 0.5025
Epoch 14 Step 201 Train Loss: 0.5131
Epoch 14 Step 251 Train Loss: 0.5163
Epoch 14 Step 301 Train Loss: 0.5220
Epoch 14 Step 351 Train Loss: 0.5216
Epoch 14 Step 401 Train Loss: 0.4905
Epoch 14 Step 451 Train Loss: 0.5286
Epoch 14 Step 501 Train Loss: 0.4904
Epoch 14 Step 551 Train Loss: 0.5079
Epoch 14 Step 601 Train Loss: 0.5050
Epoch 14 Step 651 Train Loss: 0.5677
Epoch 14 Step 701 Train Loss: 0.4980
Epoch 14 Step 751 Train Loss: 0.4726
Epoch 14 Step 801 Train Loss: 0.5012
Epoch 14 Step 851 Train Loss: 0.5177
Epoch 14 Step 901 Train Loss: 0.4732
Epoch 14: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0553 Validation Top 20 DE MSE: 0.1617. 
Epoch 15 Step 1 Train Loss: 0.5602
Epoch 15 Step 51 Train Loss: 0.5286
Epoch 15 Step 101 Train Loss: 0.5764
Epoch 15 Step 151 Train Loss: 0.4882
Epoch 15 Step 201 Train Loss: 0.4988
Epoch 15 Step 251 Train Loss: 0.4940
Epoch 15 Step 301 Train Loss: 0.4925
Epoch 15 Step 351 Train Loss: 0.5006
Epoch 15 Step 401 Train Loss: 0.5452
Epoch 15 Step 451 Train Loss: 0.5519
Epoch 15 Step 501 Train Loss: 0.4978
Epoch 15 Step 551 Train Loss: 0.5058
Epoch 15 Step 601 Train Loss: 0.4751
Epoch 15 Step 651 Train Loss: 0.4767
Epoch 15 Step 701 Train Loss: 0.4829
Epoch 15 Step 751 Train Loss: 0.5332
Epoch 15 Step 801 Train Loss: 0.4692
Epoch 15 Step 851 Train Loss: 0.5305
Epoch 15 Step 901 Train Loss: 0.5142
Epoch 15: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0556 Validation Top 20 DE MSE: 0.1631. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1284
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.004806366
test_combo_seen0_pearson: 0.98895835452121
test_combo_seen0_mse_de: 0.4049613
test_combo_seen0_pearson_de: 0.9308950732312478
test_combo_seen1_mse: 0.004192221
test_combo_seen1_pearson: 0.9907163176749344
test_combo_seen1_mse_de: 0.13073967
test_combo_seen1_pearson_de: 0.8292052070772147
test_combo_seen2_mse: 0.0040632905
test_combo_seen2_pearson: 0.9911290186965434
test_combo_seen2_mse_de: 0.090879925
test_combo_seen2_pearson_de: 0.8849648949657684
test_unseen_single_mse: 0.0024750542
test_unseen_single_pearson: 0.9943748236718468
test_unseen_single_mse_de: 0.13651522
test_unseen_single_pearson_de: 0.9404617416361726
test_combo_seen0_pearson_delta: 0.6714654451224954
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.1
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.7
test_combo_seen0_mse_top20_de_non_dropout: 0.41818228
test_combo_seen1_pearson_delta: 0.571459424942159
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.1358974358974359
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.8871794871794872
test_combo_seen1_mse_top20_de_non_dropout: 0.16256237
test_combo_seen2_pearson_delta: 0.6543844623067421
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.09347826086956523
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.9217391304347826
test_combo_seen2_mse_top20_de_non_dropout: 0.10717834
test_unseen_single_pearson_delta: 0.3527711929185187
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3055555555555556
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9259259259259258
test_unseen_single_mse_top20_de_non_dropout: 0.1519408
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.026 MB of 0.028 MB uploadedwandb: / 0.026 MB of 0.028 MB uploadedwandb: - 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá
wandb:                                                   val_de_mse ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñá‚ñÜ‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.1
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.7
wandb:                                         test_combo_seen0_mse 0.00481
wandb:                                      test_combo_seen0_mse_de 0.40496
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.41818
wandb:                                     test_combo_seen0_pearson 0.98896
wandb:                                  test_combo_seen0_pearson_de 0.9309
wandb:                               test_combo_seen0_pearson_delta 0.67147
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.1359
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.88718
wandb:                                         test_combo_seen1_mse 0.00419
wandb:                                      test_combo_seen1_mse_de 0.13074
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.16256
wandb:                                     test_combo_seen1_pearson 0.99072
wandb:                                  test_combo_seen1_pearson_de 0.82921
wandb:                               test_combo_seen1_pearson_delta 0.57146
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.09348
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.92174
wandb:                                         test_combo_seen2_mse 0.00406
wandb:                                      test_combo_seen2_mse_de 0.09088
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.10718
wandb:                                     test_combo_seen2_pearson 0.99113
wandb:                                  test_combo_seen2_pearson_de 0.88496
wandb:                               test_combo_seen2_pearson_delta 0.65438
wandb:                                                  test_de_mse 0.12841
wandb:                                              test_de_pearson 0.87854
wandb:               test_frac_opposite_direction_top20_non_dropout 0.17473
wandb:                          test_frac_sigma_below_1_non_dropout 0.9033
wandb:                                                     test_mse 0.00366
wandb:                                test_mse_top20_de_non_dropout 0.15103
wandb:                                                 test_pearson 0.99187
wandb:                                           test_pearson_delta 0.52973
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.30556
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.92593
wandb:                                       test_unseen_single_mse 0.00248
wandb:                                    test_unseen_single_mse_de 0.13652
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.15194
wandb:                                   test_unseen_single_pearson 0.99437
wandb:                                test_unseen_single_pearson_de 0.94046
wandb:                             test_unseen_single_pearson_delta 0.35277
wandb:                                                 train_de_mse 0.05564
wandb:                                             train_de_pearson 0.87584
wandb:                                                    train_mse 0.00194
wandb:                                                train_pearson 0.9959
wandb:                                                training_loss 0.47043
wandb:                                                   val_de_mse 0.16308
wandb:                                               val_de_pearson 0.8275
wandb:                                                      val_mse 0.00339
wandb:                                                  val_pearson 0.99248
wandb: 
wandb: üöÄ View run gears_esm_NormanWeissman2019_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/vej4id8f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_181300-vej4id8f/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:5
combo_seen1:44
combo_seen2:21
unseen_single:25
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/gears_esm/wandb/run-20240923_191503-wq86uu76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gears_esm_NormanWeissman2019_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/wq86uu76
Start Training...
Epoch 1 Step 1 Train Loss: 0.8493
Epoch 1 Step 51 Train Loss: 0.5706
Epoch 1 Step 101 Train Loss: 0.4821
Epoch 1 Step 151 Train Loss: 0.5657
Epoch 1 Step 201 Train Loss: 0.4923
Epoch 1 Step 251 Train Loss: 0.5217
Epoch 1 Step 301 Train Loss: 0.5036
Epoch 1 Step 351 Train Loss: 0.4813
Epoch 1 Step 401 Train Loss: 0.5134
Epoch 1 Step 451 Train Loss: 0.5278
Epoch 1 Step 501 Train Loss: 0.5115
Epoch 1 Step 551 Train Loss: 0.5269
Epoch 1 Step 601 Train Loss: 0.5140
Epoch 1 Step 651 Train Loss: 0.5005
Epoch 1 Step 701 Train Loss: 0.5667
Epoch 1 Step 751 Train Loss: 0.5088
Epoch 1 Step 801 Train Loss: 0.4804
Epoch 1 Step 851 Train Loss: 0.5100
Epoch 1 Step 901 Train Loss: 0.5345
Epoch 1: Train Overall MSE: 0.0043 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0976 Validation Top 20 DE MSE: 0.1725. 
Epoch 2 Step 1 Train Loss: 0.4873
Epoch 2 Step 51 Train Loss: 0.4926
Epoch 2 Step 101 Train Loss: 0.4999
Epoch 2 Step 151 Train Loss: 0.4947
Epoch 2 Step 201 Train Loss: 0.5222
Epoch 2 Step 251 Train Loss: 0.5129
Epoch 2 Step 301 Train Loss: 0.4732
Epoch 2 Step 351 Train Loss: 0.4800
Epoch 2 Step 401 Train Loss: 0.4935
Epoch 2 Step 451 Train Loss: 0.4977
Epoch 2 Step 501 Train Loss: 0.5386
Epoch 2 Step 551 Train Loss: 0.5359
Epoch 2 Step 601 Train Loss: 0.4724
Epoch 2 Step 651 Train Loss: 0.4739
Epoch 2 Step 701 Train Loss: 0.4677
Epoch 2 Step 751 Train Loss: 0.4784
Epoch 2 Step 801 Train Loss: 0.5322
Epoch 2 Step 851 Train Loss: 0.4743
Epoch 2 Step 901 Train Loss: 0.5204
Epoch 2: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0789 Validation Top 20 DE MSE: 0.1657. 
Epoch 3 Step 1 Train Loss: 0.4686
Epoch 3 Step 51 Train Loss: 0.4909
Epoch 3 Step 101 Train Loss: 0.4662
Epoch 3 Step 151 Train Loss: 0.5184
Epoch 3 Step 201 Train Loss: 0.5104
Epoch 3 Step 251 Train Loss: 0.4802
Epoch 3 Step 301 Train Loss: 0.4660
Epoch 3 Step 351 Train Loss: 0.5393
Epoch 3 Step 401 Train Loss: 0.4874
Epoch 3 Step 451 Train Loss: 0.4580
Epoch 3 Step 501 Train Loss: 0.5089
Epoch 3 Step 551 Train Loss: 0.5002
Epoch 3 Step 601 Train Loss: 0.5040
Epoch 3 Step 651 Train Loss: 0.5296
Epoch 3 Step 701 Train Loss: 0.5137
Epoch 3 Step 751 Train Loss: 0.4607
Epoch 3 Step 801 Train Loss: 0.5066
Epoch 3 Step 851 Train Loss: 0.5326
Epoch 3 Step 901 Train Loss: 0.4715
Epoch 3: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.0694 Validation Top 20 DE MSE: 0.1949. 
Epoch 4 Step 1 Train Loss: 0.5192
Epoch 4 Step 51 Train Loss: 0.4876
Epoch 4 Step 101 Train Loss: 0.5330
Epoch 4 Step 151 Train Loss: 0.4801
Epoch 4 Step 201 Train Loss: 0.5089
Epoch 4 Step 251 Train Loss: 0.5120
Epoch 4 Step 301 Train Loss: 0.4959
Epoch 4 Step 351 Train Loss: 0.5275
Epoch 4 Step 401 Train Loss: 0.5446
Epoch 4 Step 451 Train Loss: 0.5161
Epoch 4 Step 501 Train Loss: 0.5633
Epoch 4 Step 551 Train Loss: 0.4986
Epoch 4 Step 601 Train Loss: 0.4921
Epoch 4 Step 651 Train Loss: 0.5115
Epoch 4 Step 701 Train Loss: 0.4989
Epoch 4 Step 751 Train Loss: 0.5480
Epoch 4 Step 801 Train Loss: 0.4765
Epoch 4 Step 851 Train Loss: 0.4887
Epoch 4 Step 901 Train Loss: 0.5144
Epoch 4: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0640 Validation Top 20 DE MSE: 0.1711. 
Epoch 5 Step 1 Train Loss: 0.4941
Epoch 5 Step 51 Train Loss: 0.4886
Epoch 5 Step 101 Train Loss: 0.5054
Epoch 5 Step 151 Train Loss: 0.4994
Epoch 5 Step 201 Train Loss: 0.4820
Epoch 5 Step 251 Train Loss: 0.5030
Epoch 5 Step 301 Train Loss: 0.5555
Epoch 5 Step 351 Train Loss: 0.4650
Epoch 5 Step 401 Train Loss: 0.5217
Epoch 5 Step 451 Train Loss: 0.4972
Epoch 5 Step 501 Train Loss: 0.5257
Epoch 5 Step 551 Train Loss: 0.5391
Epoch 5 Step 601 Train Loss: 0.5035
Epoch 5 Step 651 Train Loss: 0.5350
Epoch 5 Step 701 Train Loss: 0.5181
Epoch 5 Step 751 Train Loss: 0.4736
Epoch 5 Step 801 Train Loss: 0.5094
Epoch 5 Step 851 Train Loss: 0.5160
Epoch 5 Step 901 Train Loss: 0.5034
Epoch 5: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0603 Validation Top 20 DE MSE: 0.1759. 
Epoch 6 Step 1 Train Loss: 0.5466
Epoch 6 Step 51 Train Loss: 0.5049
Epoch 6 Step 101 Train Loss: 0.4938
Epoch 6 Step 151 Train Loss: 0.5166
Epoch 6 Step 201 Train Loss: 0.5552
Epoch 6 Step 251 Train Loss: 0.4759
Epoch 6 Step 301 Train Loss: 0.4878
Epoch 6 Step 351 Train Loss: 0.5654
Epoch 6 Step 401 Train Loss: 0.5326
Epoch 6 Step 451 Train Loss: 0.5132
Epoch 6 Step 501 Train Loss: 0.5719
Epoch 6 Step 551 Train Loss: 0.5079
Epoch 6 Step 601 Train Loss: 0.5387
Epoch 6 Step 651 Train Loss: 0.5291
Epoch 6 Step 701 Train Loss: 0.5188
Epoch 6 Step 751 Train Loss: 0.5079
Epoch 6 Step 801 Train Loss: 0.5336
Epoch 6 Step 851 Train Loss: 0.5098
Epoch 6 Step 901 Train Loss: 0.4873
Epoch 6: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0553 Validation Top 20 DE MSE: 0.1580. 
Epoch 7 Step 1 Train Loss: 0.5127
Epoch 7 Step 51 Train Loss: 0.5183
Epoch 7 Step 101 Train Loss: 0.5609
Epoch 7 Step 151 Train Loss: 0.5040
Epoch 7 Step 201 Train Loss: 0.5189
Epoch 7 Step 251 Train Loss: 0.5195
Epoch 7 Step 301 Train Loss: 0.5233
Epoch 7 Step 351 Train Loss: 0.4945
Epoch 7 Step 401 Train Loss: 0.4911
Epoch 7 Step 451 Train Loss: 0.5326
Epoch 7 Step 501 Train Loss: 0.5033
Epoch 7 Step 551 Train Loss: 0.4985
Epoch 7 Step 601 Train Loss: 0.5093
Epoch 7 Step 651 Train Loss: 0.5333
Epoch 7 Step 701 Train Loss: 0.5093
Epoch 7 Step 751 Train Loss: 0.5299
Epoch 7 Step 801 Train Loss: 0.5398
Epoch 7 Step 851 Train Loss: 0.5160
Epoch 7 Step 901 Train Loss: 0.4991
Epoch 7: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0544 Validation Top 20 DE MSE: 0.1626. 
Epoch 8 Step 1 Train Loss: 0.4848
Epoch 8 Step 51 Train Loss: 0.5050
Epoch 8 Step 101 Train Loss: 0.5279
Epoch 8 Step 151 Train Loss: 0.4733
Epoch 8 Step 201 Train Loss: 0.5169
Epoch 8 Step 251 Train Loss: 0.5006
Epoch 8 Step 301 Train Loss: 0.4847
Epoch 8 Step 351 Train Loss: 0.5487
Epoch 8 Step 401 Train Loss: 0.4927
Epoch 8 Step 451 Train Loss: 0.5298
Epoch 8 Step 501 Train Loss: 0.5271
Epoch 8 Step 551 Train Loss: 0.5011
Epoch 8 Step 601 Train Loss: 0.5047
Epoch 8 Step 651 Train Loss: 0.5081
Epoch 8 Step 701 Train Loss: 0.5955
Epoch 8 Step 751 Train Loss: 0.5244
Epoch 8 Step 801 Train Loss: 0.5058
Epoch 8 Step 851 Train Loss: 0.5195
Epoch 8 Step 901 Train Loss: 0.4919
Epoch 8: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0609 Validation Top 20 DE MSE: 0.1622. 
Epoch 9 Step 1 Train Loss: 0.5313
Epoch 9 Step 51 Train Loss: 0.5042
Epoch 9 Step 101 Train Loss: 0.5178
Epoch 9 Step 151 Train Loss: 0.4945
Epoch 9 Step 201 Train Loss: 0.5198
Epoch 9 Step 251 Train Loss: 0.5084
Epoch 9 Step 301 Train Loss: 0.5194
Epoch 9 Step 351 Train Loss: 0.5381
Epoch 9 Step 401 Train Loss: 0.5586
Epoch 9 Step 451 Train Loss: 0.5127
Epoch 9 Step 501 Train Loss: 0.5486
Epoch 9 Step 551 Train Loss: 0.4973
Epoch 9 Step 601 Train Loss: 0.4988
Epoch 9 Step 651 Train Loss: 0.5309
Epoch 9 Step 701 Train Loss: 0.5264
Epoch 9 Step 751 Train Loss: 0.5507
Epoch 9 Step 801 Train Loss: 0.5242
Epoch 9 Step 851 Train Loss: 0.5704
Epoch 9 Step 901 Train Loss: 0.4984
Epoch 9: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0568 Validation Top 20 DE MSE: 0.1635. 
Epoch 10 Step 1 Train Loss: 0.4689
Epoch 10 Step 51 Train Loss: 0.4851
Epoch 10 Step 101 Train Loss: 0.5089
Epoch 10 Step 151 Train Loss: 0.5231
Epoch 10 Step 201 Train Loss: 0.5599
Epoch 10 Step 251 Train Loss: 0.5181
Epoch 10 Step 301 Train Loss: 0.5356
Epoch 10 Step 351 Train Loss: 0.4883
Epoch 10 Step 401 Train Loss: 0.5291
Epoch 10 Step 451 Train Loss: 0.5279
Epoch 10 Step 501 Train Loss: 0.5177
Epoch 10 Step 551 Train Loss: 0.4966
Epoch 10 Step 601 Train Loss: 0.4873
Epoch 10 Step 651 Train Loss: 0.5170
Epoch 10 Step 701 Train Loss: 0.5256
Epoch 10 Step 751 Train Loss: 0.5372
Epoch 10 Step 801 Train Loss: 0.5260
Epoch 10 Step 851 Train Loss: 0.5976
Epoch 10 Step 901 Train Loss: 0.4966
Epoch 10: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0552 Validation Top 20 DE MSE: 0.1623. 
Epoch 11 Step 1 Train Loss: 0.5512
Epoch 11 Step 51 Train Loss: 0.4926
Epoch 11 Step 101 Train Loss: 0.5352
Epoch 11 Step 151 Train Loss: 0.5237
Epoch 11 Step 201 Train Loss: 0.5154
Epoch 11 Step 251 Train Loss: 0.4980
Epoch 11 Step 301 Train Loss: 0.5177
Epoch 11 Step 351 Train Loss: 0.5185
Epoch 11 Step 401 Train Loss: 0.5745
Epoch 11 Step 451 Train Loss: 0.4917
Epoch 11 Step 501 Train Loss: 0.5217
Epoch 11 Step 551 Train Loss: 0.5354
Epoch 11 Step 601 Train Loss: 0.4928
Epoch 11 Step 651 Train Loss: 0.5161
Epoch 11 Step 701 Train Loss: 0.5538
Epoch 11 Step 751 Train Loss: 0.5094
Epoch 11 Step 801 Train Loss: 0.4845
Epoch 11 Step 851 Train Loss: 0.4894
Epoch 11 Step 901 Train Loss: 0.5320
Epoch 11: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0567 Validation Top 20 DE MSE: 0.1599. 
Epoch 12 Step 1 Train Loss: 0.5042
Epoch 12 Step 51 Train Loss: 0.4885
Epoch 12 Step 101 Train Loss: 0.4687
Epoch 12 Step 151 Train Loss: 0.5256
Epoch 12 Step 201 Train Loss: 0.4918
Epoch 12 Step 251 Train Loss: 0.5172
Epoch 12 Step 301 Train Loss: 0.5130
Epoch 12 Step 351 Train Loss: 0.5219
Epoch 12 Step 401 Train Loss: 0.4829
Epoch 12 Step 451 Train Loss: 0.5154
Epoch 12 Step 501 Train Loss: 0.4833
Epoch 12 Step 551 Train Loss: 0.5177
Epoch 12 Step 601 Train Loss: 0.4754
Epoch 12 Step 651 Train Loss: 0.5230
Epoch 12 Step 701 Train Loss: 0.5019
Epoch 12 Step 751 Train Loss: 0.5365
Epoch 12 Step 801 Train Loss: 0.4966
Epoch 12 Step 851 Train Loss: 0.5045
Epoch 12 Step 901 Train Loss: 0.5738
Epoch 12: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0537 Validation Top 20 DE MSE: 0.1580. 
Epoch 13 Step 1 Train Loss: 0.5181
Epoch 13 Step 51 Train Loss: 0.5290
Epoch 13 Step 101 Train Loss: 0.4939
Epoch 13 Step 151 Train Loss: 0.5144
Epoch 13 Step 201 Train Loss: 0.5060
Epoch 13 Step 251 Train Loss: 0.4726
Epoch 13 Step 301 Train Loss: 0.4920
Epoch 13 Step 351 Train Loss: 0.5143
Epoch 13 Step 401 Train Loss: 0.5043
Epoch 13 Step 451 Train Loss: 0.5188
Epoch 13 Step 501 Train Loss: 0.4804
Epoch 13 Step 551 Train Loss: 0.5164
Epoch 13 Step 601 Train Loss: 0.4991
Epoch 13 Step 651 Train Loss: 0.5316
Epoch 13 Step 701 Train Loss: 0.5221
Epoch 13 Step 751 Train Loss: 0.5009
Epoch 13 Step 801 Train Loss: 0.5160
Epoch 13 Step 851 Train Loss: 0.5514
Epoch 13 Step 901 Train Loss: 0.5375
Epoch 13: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0556 Validation Top 20 DE MSE: 0.1596. 
Epoch 14 Step 1 Train Loss: 0.5331
Epoch 14 Step 51 Train Loss: 0.5170
Epoch 14 Step 101 Train Loss: 0.5066
Epoch 14 Step 151 Train Loss: 0.5217
Epoch 14 Step 201 Train Loss: 0.5454
Epoch 14 Step 251 Train Loss: 0.5056
Epoch 14 Step 301 Train Loss: 0.5036
Epoch 14 Step 351 Train Loss: 0.5842
Epoch 14 Step 401 Train Loss: 0.5143
Epoch 14 Step 451 Train Loss: 0.5056
Epoch 14 Step 501 Train Loss: 0.5687
Epoch 14 Step 551 Train Loss: 0.5148
Epoch 14 Step 601 Train Loss: 0.5078
Epoch 14 Step 651 Train Loss: 0.5180
Epoch 14 Step 701 Train Loss: 0.4911
Epoch 14 Step 751 Train Loss: 0.5564
Epoch 14 Step 801 Train Loss: 0.5086
Epoch 14 Step 851 Train Loss: 0.5423
Epoch 14 Step 901 Train Loss: 0.5387
Epoch 14: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0593 Validation Top 20 DE MSE: 0.1628. 
Epoch 15 Step 1 Train Loss: 0.5536
Epoch 15 Step 51 Train Loss: 0.5008
Epoch 15 Step 101 Train Loss: 0.5072
Epoch 15 Step 151 Train Loss: 0.4954
Epoch 15 Step 201 Train Loss: 0.5045
Epoch 15 Step 251 Train Loss: 0.5366
Epoch 15 Step 301 Train Loss: 0.5163
Epoch 15 Step 351 Train Loss: 0.5289
Epoch 15 Step 401 Train Loss: 0.5341
Epoch 15 Step 451 Train Loss: 0.5041
Epoch 15 Step 501 Train Loss: 0.5138
Epoch 15 Step 551 Train Loss: 0.5126
Epoch 15 Step 601 Train Loss: 0.5115
Epoch 15 Step 651 Train Loss: 0.5697
Epoch 15 Step 701 Train Loss: 0.4809
Epoch 15 Step 751 Train Loss: 0.5330
Epoch 15 Step 801 Train Loss: 0.4846
Epoch 15 Step 851 Train Loss: 0.5049
Epoch 15 Step 901 Train Loss: 0.4756
Epoch 15: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0549 Validation Top 20 DE MSE: 0.1605. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1536
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.004090062
test_combo_seen0_pearson: 0.9906756152436506
test_combo_seen0_mse_de: 0.31908637
test_combo_seen0_pearson_de: 0.7589659634163677
test_combo_seen1_mse: 0.0034216284
test_combo_seen1_pearson: 0.9925473985910457
test_combo_seen1_mse_de: 0.15183318
test_combo_seen1_pearson_de: 0.8469889905046407
test_combo_seen2_mse: 0.003684564
test_combo_seen2_pearson: 0.9920424907828007
test_combo_seen2_mse_de: 0.09260176
test_combo_seen2_pearson_de: 0.7875852795877479
test_unseen_single_mse: 0.002374208
test_unseen_single_pearson: 0.9945735875898117
test_unseen_single_mse_de: 0.1746838
test_unseen_single_pearson_de: 0.9518339604796815
test_combo_seen0_pearson_delta: 0.41242089694353157
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.2
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.76
test_combo_seen0_mse_top20_de_non_dropout: 0.35237575
test_combo_seen1_pearson_delta: 0.6018939668107977
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.10795454545454546
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.8920454545454547
test_combo_seen1_mse_top20_de_non_dropout: 0.1709314
test_combo_seen2_pearson_delta: 0.653511593583998
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.10476190476190476
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.9261904761904761
test_combo_seen2_mse_top20_de_non_dropout: 0.1126315
test_unseen_single_pearson_delta: 0.34811635240423555
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.298
test_unseen_single_frac_sigma_below_1_non_dropout: 0.902
test_unseen_single_mse_top20_de_non_dropout: 0.18978332
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.001 MB of 0.028 MB uploadedwandb: / 0.026 MB of 0.028 MB uploadedwandb: - 0.026 MB of 0.028 MB uploadedwandb: \ 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÇ
wandb:                                                   val_de_mse ‚ñÑ‚ñÇ‚ñà‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                               val_de_pearson ‚ñÖ‚ñÜ‚ñÅ‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.2
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.76
wandb:                                         test_combo_seen0_mse 0.00409
wandb:                                      test_combo_seen0_mse_de 0.31909
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.35238
wandb:                                     test_combo_seen0_pearson 0.99068
wandb:                                  test_combo_seen0_pearson_de 0.75897
wandb:                               test_combo_seen0_pearson_delta 0.41242
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.10795
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.89205
wandb:                                         test_combo_seen1_mse 0.00342
wandb:                                      test_combo_seen1_mse_de 0.15183
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.17093
wandb:                                     test_combo_seen1_pearson 0.99255
wandb:                                  test_combo_seen1_pearson_de 0.84699
wandb:                               test_combo_seen1_pearson_delta 0.60189
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.10476
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.92619
wandb:                                         test_combo_seen2_mse 0.00368
wandb:                                      test_combo_seen2_mse_de 0.0926
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.11263
wandb:                                     test_combo_seen2_pearson 0.99204
wandb:                                  test_combo_seen2_pearson_de 0.78759
wandb:                               test_combo_seen2_pearson_delta 0.65351
wandb:                                                  test_de_mse 0.15356
wandb:                                              test_de_pearson 0.85682
wandb:               test_frac_opposite_direction_top20_non_dropout 0.16211
wandb:                          test_frac_sigma_below_1_non_dropout 0.89526
wandb:                                                     test_mse 0.00324
wandb:                                test_mse_top20_de_non_dropout 0.17255
wandb:                                                 test_pearson 0.99287
wandb:                                           test_pearson_delta 0.53655
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.298
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.902
wandb:                                       test_unseen_single_mse 0.00237
wandb:                                    test_unseen_single_mse_de 0.17468
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.18978
wandb:                                   test_unseen_single_pearson 0.99457
wandb:                                test_unseen_single_pearson_de 0.95183
wandb:                             test_unseen_single_pearson_delta 0.34812
wandb:                                                 train_de_mse 0.05486
wandb:                                             train_de_pearson 0.90283
wandb:                                                    train_mse 0.00203
wandb:                                                train_pearson 0.99571
wandb:                                                training_loss 0.54532
wandb:                                                   val_de_mse 0.16055
wandb:                                               val_de_pearson 0.76761
wandb:                                                      val_mse 0.00352
wandb:                                                  val_pearson 0.99206
wandb: 
wandb: üöÄ View run gears_esm_NormanWeissman2019_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/wq86uu76
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_191503-wq86uu76/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:10
combo_seen1:58
combo_seen2:16
unseen_single:27
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/gears_esm/wandb/run-20240923_201610-d8egb97g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gears_esm_NormanWeissman2019_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/d8egb97g
Start Training...
Epoch 1 Step 1 Train Loss: 1.1884
Epoch 1 Step 51 Train Loss: 0.5392
Epoch 1 Step 101 Train Loss: 0.5737
Epoch 1 Step 151 Train Loss: 0.5166
Epoch 1 Step 201 Train Loss: 0.5243
Epoch 1 Step 251 Train Loss: 0.4882
Epoch 1 Step 301 Train Loss: 0.5420
Epoch 1 Step 351 Train Loss: 0.5389
Epoch 1 Step 401 Train Loss: 0.4982
Epoch 1 Step 451 Train Loss: 0.5358
Epoch 1 Step 501 Train Loss: 0.4668
Epoch 1 Step 551 Train Loss: 0.4717
Epoch 1 Step 601 Train Loss: 0.5046
Epoch 1 Step 651 Train Loss: 0.4884
Epoch 1 Step 701 Train Loss: 0.5114
Epoch 1 Step 751 Train Loss: 0.4904
Epoch 1 Step 801 Train Loss: 0.5288
Epoch 1 Step 851 Train Loss: 0.4761
Epoch 1 Step 901 Train Loss: 0.4932
Epoch 1: Train Overall MSE: 0.0034 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.1371 Validation Top 20 DE MSE: 0.2494. 
Epoch 2 Step 1 Train Loss: 0.4986
Epoch 2 Step 51 Train Loss: 0.5358
Epoch 2 Step 101 Train Loss: 0.4452
Epoch 2 Step 151 Train Loss: 0.5263
Epoch 2 Step 201 Train Loss: 0.5370
Epoch 2 Step 251 Train Loss: 0.4931
Epoch 2 Step 301 Train Loss: 0.4618
Epoch 2 Step 351 Train Loss: 0.4709
Epoch 2 Step 401 Train Loss: 0.4863
Epoch 2 Step 451 Train Loss: 0.4779
Epoch 2 Step 501 Train Loss: 0.4977
Epoch 2 Step 551 Train Loss: 0.4777
Epoch 2 Step 601 Train Loss: 0.5332
Epoch 2 Step 651 Train Loss: 0.5029
Epoch 2 Step 701 Train Loss: 0.4837
Epoch 2 Step 751 Train Loss: 0.5134
Epoch 2 Step 801 Train Loss: 0.5141
Epoch 2 Step 851 Train Loss: 0.4793
Epoch 2 Step 901 Train Loss: 0.5085
Epoch 2: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.1099 Validation Top 20 DE MSE: 0.1906. 
Epoch 3 Step 1 Train Loss: 0.5022
Epoch 3 Step 51 Train Loss: 0.5362
Epoch 3 Step 101 Train Loss: 0.4679
Epoch 3 Step 151 Train Loss: 0.4682
Epoch 3 Step 201 Train Loss: 0.5193
Epoch 3 Step 251 Train Loss: 0.5192
Epoch 3 Step 301 Train Loss: 0.4774
Epoch 3 Step 351 Train Loss: 0.4750
Epoch 3 Step 401 Train Loss: 0.5032
Epoch 3 Step 451 Train Loss: 0.5421
Epoch 3 Step 501 Train Loss: 0.4862
Epoch 3 Step 551 Train Loss: 0.5088
Epoch 3 Step 601 Train Loss: 0.4612
Epoch 3 Step 651 Train Loss: 0.4611
Epoch 3 Step 701 Train Loss: 0.4820
Epoch 3 Step 751 Train Loss: 0.4434
Epoch 3 Step 801 Train Loss: 0.4671
Epoch 3 Step 851 Train Loss: 0.5468
Epoch 3 Step 901 Train Loss: 0.5401
Epoch 3: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0691 Validation Top 20 DE MSE: 0.1366. 
Epoch 4 Step 1 Train Loss: 0.4758
Epoch 4 Step 51 Train Loss: 0.4975
Epoch 4 Step 101 Train Loss: 0.5003
Epoch 4 Step 151 Train Loss: 0.5279
Epoch 4 Step 201 Train Loss: 0.4812
Epoch 4 Step 251 Train Loss: 0.4475
Epoch 4 Step 301 Train Loss: 0.5233
Epoch 4 Step 351 Train Loss: 0.4920
Epoch 4 Step 401 Train Loss: 0.4896
Epoch 4 Step 451 Train Loss: 0.4999
Epoch 4 Step 501 Train Loss: 0.4977
Epoch 4 Step 551 Train Loss: 0.5190
Epoch 4 Step 601 Train Loss: 0.4836
Epoch 4 Step 651 Train Loss: 0.5046
Epoch 4 Step 701 Train Loss: 0.4764
Epoch 4 Step 751 Train Loss: 0.4799
Epoch 4 Step 801 Train Loss: 0.4797
Epoch 4 Step 851 Train Loss: 0.4855
Epoch 4 Step 901 Train Loss: 0.5325
Epoch 4: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0730 Validation Top 20 DE MSE: 0.1708. 
Epoch 5 Step 1 Train Loss: 0.5016
Epoch 5 Step 51 Train Loss: 0.4653
Epoch 5 Step 101 Train Loss: 0.5354
Epoch 5 Step 151 Train Loss: 0.5085
Epoch 5 Step 201 Train Loss: 0.4977
Epoch 5 Step 251 Train Loss: 0.5029
Epoch 5 Step 301 Train Loss: 0.5185
Epoch 5 Step 351 Train Loss: 0.5300
Epoch 5 Step 401 Train Loss: 0.4912
Epoch 5 Step 451 Train Loss: 0.5168
Epoch 5 Step 501 Train Loss: 0.4690
Epoch 5 Step 551 Train Loss: 0.5808
Epoch 5 Step 601 Train Loss: 0.4850
Epoch 5 Step 651 Train Loss: 0.5050
Epoch 5 Step 701 Train Loss: 0.5094
Epoch 5 Step 751 Train Loss: 0.4901
Epoch 5 Step 801 Train Loss: 0.5111
Epoch 5 Step 851 Train Loss: 0.5234
Epoch 5 Step 901 Train Loss: 0.4847
Epoch 5: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0609 Validation Top 20 DE MSE: 0.1450. 
Epoch 6 Step 1 Train Loss: 0.4788
Epoch 6 Step 51 Train Loss: 0.5028
Epoch 6 Step 101 Train Loss: 0.4420
Epoch 6 Step 151 Train Loss: 0.4862
Epoch 6 Step 201 Train Loss: 0.4842
Epoch 6 Step 251 Train Loss: 0.4962
Epoch 6 Step 301 Train Loss: 0.5141
Epoch 6 Step 351 Train Loss: 0.4611
Epoch 6 Step 401 Train Loss: 0.5147
Epoch 6 Step 451 Train Loss: 0.5073
Epoch 6 Step 501 Train Loss: 0.5535
Epoch 6 Step 551 Train Loss: 0.5056
Epoch 6 Step 601 Train Loss: 0.4763
Epoch 6 Step 651 Train Loss: 0.5493
Epoch 6 Step 701 Train Loss: 0.5301
Epoch 6 Step 751 Train Loss: 0.4859
Epoch 6 Step 801 Train Loss: 0.4902
Epoch 6 Step 851 Train Loss: 0.4914
Epoch 6 Step 901 Train Loss: 0.4784
Epoch 6: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0560 Validation Top 20 DE MSE: 0.1464. 
Epoch 7 Step 1 Train Loss: 0.5128
Epoch 7 Step 51 Train Loss: 0.5327
Epoch 7 Step 101 Train Loss: 0.4883
Epoch 7 Step 151 Train Loss: 0.4903
Epoch 7 Step 201 Train Loss: 0.5019
Epoch 7 Step 251 Train Loss: 0.4917
Epoch 7 Step 301 Train Loss: 0.4861
Epoch 7 Step 351 Train Loss: 0.5076
Epoch 7 Step 401 Train Loss: 0.5640
Epoch 7 Step 451 Train Loss: 0.5404
Epoch 7 Step 501 Train Loss: 0.4729
Epoch 7 Step 551 Train Loss: 0.4966
Epoch 7 Step 601 Train Loss: 0.4944
Epoch 7 Step 651 Train Loss: 0.4738
Epoch 7 Step 701 Train Loss: 0.4666
Epoch 7 Step 751 Train Loss: 0.5078
Epoch 7 Step 801 Train Loss: 0.4996
Epoch 7 Step 851 Train Loss: 0.5103
Epoch 7 Step 901 Train Loss: 0.4920
Epoch 7: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0570 Validation Top 20 DE MSE: 0.1401. 
Epoch 8 Step 1 Train Loss: 0.5022
Epoch 8 Step 51 Train Loss: 0.4849
Epoch 8 Step 101 Train Loss: 0.4620
Epoch 8 Step 151 Train Loss: 0.4881
Epoch 8 Step 201 Train Loss: 0.4908
Epoch 8 Step 251 Train Loss: 0.5245
Epoch 8 Step 301 Train Loss: 0.4885
Epoch 8 Step 351 Train Loss: 0.5396
Epoch 8 Step 401 Train Loss: 0.4986
Epoch 8 Step 451 Train Loss: 0.5377
Epoch 8 Step 501 Train Loss: 0.4924
Epoch 8 Step 551 Train Loss: 0.5103
Epoch 8 Step 601 Train Loss: 0.5080
Epoch 8 Step 651 Train Loss: 0.5532
Epoch 8 Step 701 Train Loss: 0.4914
Epoch 8 Step 751 Train Loss: 0.4876
Epoch 8 Step 801 Train Loss: 0.4749
Epoch 8 Step 851 Train Loss: 0.5143
Epoch 8 Step 901 Train Loss: 0.5012
Epoch 8: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0522 Validation Top 20 DE MSE: 0.1389. 
Epoch 9 Step 1 Train Loss: 0.5244
Epoch 9 Step 51 Train Loss: 0.4993
Epoch 9 Step 101 Train Loss: 0.4802
Epoch 9 Step 151 Train Loss: 0.5128
Epoch 9 Step 201 Train Loss: 0.5237
Epoch 9 Step 251 Train Loss: 0.5497
Epoch 9 Step 301 Train Loss: 0.4867
Epoch 9 Step 351 Train Loss: 0.4886
Epoch 9 Step 401 Train Loss: 0.4773
Epoch 9 Step 451 Train Loss: 0.5113
Epoch 9 Step 501 Train Loss: 0.5449
Epoch 9 Step 551 Train Loss: 0.5285
Epoch 9 Step 601 Train Loss: 0.4889
Epoch 9 Step 651 Train Loss: 0.5080
Epoch 9 Step 701 Train Loss: 0.5010
Epoch 9 Step 751 Train Loss: 0.4895
Epoch 9 Step 801 Train Loss: 0.4846
Epoch 9 Step 851 Train Loss: 0.5026
Epoch 9 Step 901 Train Loss: 0.4946
Epoch 9: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0519 Validation Top 20 DE MSE: 0.1393. 
Epoch 10 Step 1 Train Loss: 0.5045
Epoch 10 Step 51 Train Loss: 0.5004
Epoch 10 Step 101 Train Loss: 0.5343
Epoch 10 Step 151 Train Loss: 0.5252
Epoch 10 Step 201 Train Loss: 0.5293
Epoch 10 Step 251 Train Loss: 0.5018
Epoch 10 Step 301 Train Loss: 0.4642
Epoch 10 Step 351 Train Loss: 0.4879
Epoch 10 Step 401 Train Loss: 0.4901
Epoch 10 Step 451 Train Loss: 0.4866
Epoch 10 Step 501 Train Loss: 0.5097
Epoch 10 Step 551 Train Loss: 0.5139
Epoch 10 Step 601 Train Loss: 0.5209
Epoch 10 Step 651 Train Loss: 0.4907
Epoch 10 Step 701 Train Loss: 0.5019
Epoch 10 Step 751 Train Loss: 0.5015
Epoch 10 Step 801 Train Loss: 0.4972
Epoch 10 Step 851 Train Loss: 0.5423
Epoch 10 Step 901 Train Loss: 0.5331
Epoch 10: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0535 Validation Top 20 DE MSE: 0.1393. 
Epoch 11 Step 1 Train Loss: 0.4676
Epoch 11 Step 51 Train Loss: 0.4820
Epoch 11 Step 101 Train Loss: 0.5266
Epoch 11 Step 151 Train Loss: 0.5670
Epoch 11 Step 201 Train Loss: 0.4867
Epoch 11 Step 251 Train Loss: 0.4934
Epoch 11 Step 301 Train Loss: 0.5025
Epoch 11 Step 351 Train Loss: 0.5023
Epoch 11 Step 401 Train Loss: 0.4973
Epoch 11 Step 451 Train Loss: 0.5047
Epoch 11 Step 501 Train Loss: 0.4994
Epoch 11 Step 551 Train Loss: 0.4979
Epoch 11 Step 601 Train Loss: 0.4882
Epoch 11 Step 651 Train Loss: 0.4833
Epoch 11 Step 701 Train Loss: 0.5053
Epoch 11 Step 751 Train Loss: 0.5501
Epoch 11 Step 801 Train Loss: 0.5302
Epoch 11 Step 851 Train Loss: 0.4602
Epoch 11 Step 901 Train Loss: 0.4843
Epoch 11: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0562 Validation Top 20 DE MSE: 0.1408. 
Epoch 12 Step 1 Train Loss: 0.4752
Epoch 12 Step 51 Train Loss: 0.4950
Epoch 12 Step 101 Train Loss: 0.4718
Epoch 12 Step 151 Train Loss: 0.4771
Epoch 12 Step 201 Train Loss: 0.4827
Epoch 12 Step 251 Train Loss: 0.5138
Epoch 12 Step 301 Train Loss: 0.4668
Epoch 12 Step 351 Train Loss: 0.4927
Epoch 12 Step 401 Train Loss: 0.4737
Epoch 12 Step 451 Train Loss: 0.4748
Epoch 12 Step 501 Train Loss: 0.5215
Epoch 12 Step 551 Train Loss: 0.4859
Epoch 12 Step 601 Train Loss: 0.4901
Epoch 12 Step 651 Train Loss: 0.4667
Epoch 12 Step 701 Train Loss: 0.4703
Epoch 12 Step 751 Train Loss: 0.5051
Epoch 12 Step 801 Train Loss: 0.4927
Epoch 12 Step 851 Train Loss: 0.5400
Epoch 12 Step 901 Train Loss: 0.5125
Epoch 12: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0542 Validation Top 20 DE MSE: 0.1345. 
Epoch 13 Step 1 Train Loss: 0.5046
Epoch 13 Step 51 Train Loss: 0.5004
Epoch 13 Step 101 Train Loss: 0.5250
Epoch 13 Step 151 Train Loss: 0.4782
Epoch 13 Step 201 Train Loss: 0.5223
Epoch 13 Step 251 Train Loss: 0.4934
Epoch 13 Step 301 Train Loss: 0.5167
Epoch 13 Step 351 Train Loss: 0.4955
Epoch 13 Step 401 Train Loss: 0.5094
Epoch 13 Step 451 Train Loss: 0.4503
Epoch 13 Step 501 Train Loss: 0.5067
Epoch 13 Step 551 Train Loss: 0.5419
Epoch 13 Step 601 Train Loss: 0.4997
Epoch 13 Step 651 Train Loss: 0.4630
Epoch 13 Step 701 Train Loss: 0.4938
Epoch 13 Step 751 Train Loss: 0.4708
Epoch 13 Step 801 Train Loss: 0.5137
Epoch 13 Step 851 Train Loss: 0.5291
Epoch 13 Step 901 Train Loss: 0.4605
Epoch 13: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0539 Validation Top 20 DE MSE: 0.1381. 
Epoch 14 Step 1 Train Loss: 0.5317
Epoch 14 Step 51 Train Loss: 0.4646
Epoch 14 Step 101 Train Loss: 0.4845
Epoch 14 Step 151 Train Loss: 0.4939
Epoch 14 Step 201 Train Loss: 0.4773
Epoch 14 Step 251 Train Loss: 0.4894
Epoch 14 Step 301 Train Loss: 0.5204
Epoch 14 Step 351 Train Loss: 0.5375
Epoch 14 Step 401 Train Loss: 0.4929
Epoch 14 Step 451 Train Loss: 0.4840
Epoch 14 Step 501 Train Loss: 0.5297
Epoch 14 Step 551 Train Loss: 0.5004
Epoch 14 Step 601 Train Loss: 0.5189
Epoch 14 Step 651 Train Loss: 0.5577
Epoch 14 Step 701 Train Loss: 0.5434
Epoch 14 Step 751 Train Loss: 0.4866
Epoch 14 Step 801 Train Loss: 0.5438
Epoch 14 Step 851 Train Loss: 0.4630
Epoch 14 Step 901 Train Loss: 0.4719
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0533 Validation Top 20 DE MSE: 0.1382. 
Epoch 15 Step 1 Train Loss: 0.5038
Epoch 15 Step 51 Train Loss: 0.4968
Epoch 15 Step 101 Train Loss: 0.5282
Epoch 15 Step 151 Train Loss: 0.4800
Epoch 15 Step 201 Train Loss: 0.5045
Epoch 15 Step 251 Train Loss: 0.4956
Epoch 15 Step 301 Train Loss: 0.4891
Epoch 15 Step 351 Train Loss: 0.5366
Epoch 15 Step 401 Train Loss: 0.5198
Epoch 15 Step 451 Train Loss: 0.4834
Epoch 15 Step 501 Train Loss: 0.4931
Epoch 15 Step 551 Train Loss: 0.4981
Epoch 15 Step 601 Train Loss: 0.5392
Epoch 15 Step 651 Train Loss: 0.4688
Epoch 15 Step 701 Train Loss: 0.5241
Epoch 15 Step 751 Train Loss: 0.4875
Epoch 15 Step 801 Train Loss: 0.4838
Epoch 15 Step 851 Train Loss: 0.4699
Epoch 15 Step 901 Train Loss: 0.5117
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0548 Validation Top 20 DE MSE: 0.1425. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1686
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.005131162
test_combo_seen0_pearson: 0.9882518821521513
test_combo_seen0_mse_de: 0.24563412
test_combo_seen0_pearson_de: 0.8298416741257938
test_combo_seen1_mse: 0.004389965
test_combo_seen1_pearson: 0.99012125541665
test_combo_seen1_mse_de: 0.15009958
test_combo_seen1_pearson_de: 0.7439911472128968
test_combo_seen2_mse: 0.0037205594
test_combo_seen2_pearson: 0.9914693738331499
test_combo_seen2_mse_de: 0.15650257
test_combo_seen2_pearson_de: 0.8981547760040647
test_unseen_single_mse: 0.0028273666
test_unseen_single_pearson: 0.9935350177019564
test_unseen_single_mse_de: 0.18718283
test_unseen_single_pearson_de: 0.9381416907617166
test_combo_seen0_pearson_delta: 0.4437344767019046
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.225
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.775
test_combo_seen0_mse_top20_de_non_dropout: 0.29480833
test_combo_seen1_pearson_delta: 0.5443944923962731
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.1724137931034483
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.856896551724138
test_combo_seen1_mse_top20_de_non_dropout: 0.21929477
test_combo_seen2_pearson_delta: 0.6915790737812184
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.03125
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.8875
test_combo_seen2_mse_top20_de_non_dropout: 0.1754924
test_unseen_single_pearson_delta: 0.36677477101452954
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2740740740740741
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8962962962962963
test_unseen_single_mse_top20_de_non_dropout: 0.2005082
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.001 MB of 0.028 MB uploadedwandb: / 0.026 MB of 0.028 MB uploadedwandb: - 0.026 MB of 0.028 MB uploadedwandb: \ 0.026 MB of 0.028 MB uploadedwandb: | 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñá‚ñÅ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.225
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.775
wandb:                                         test_combo_seen0_mse 0.00513
wandb:                                      test_combo_seen0_mse_de 0.24563
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.29481
wandb:                                     test_combo_seen0_pearson 0.98825
wandb:                                  test_combo_seen0_pearson_de 0.82984
wandb:                               test_combo_seen0_pearson_delta 0.44373
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.17241
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.8569
wandb:                                         test_combo_seen1_mse 0.00439
wandb:                                      test_combo_seen1_mse_de 0.1501
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.21929
wandb:                                     test_combo_seen1_pearson 0.99012
wandb:                                  test_combo_seen1_pearson_de 0.74399
wandb:                               test_combo_seen1_pearson_delta 0.54439
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.03125
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.8875
wandb:                                         test_combo_seen2_mse 0.00372
wandb:                                      test_combo_seen2_mse_de 0.1565
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.17549
wandb:                                     test_combo_seen2_pearson 0.99147
wandb:                                  test_combo_seen2_pearson_de 0.89815
wandb:                               test_combo_seen2_pearson_delta 0.69158
wandb:                                                  test_de_mse 0.16865
wandb:                                              test_de_pearson 0.82117
wandb:               test_frac_opposite_direction_top20_non_dropout 0.18153
wandb:                          test_frac_sigma_below_1_non_dropout 0.86351
wandb:                                                     test_mse 0.00398
wandb:                                test_mse_top20_de_non_dropout 0.21521
wandb:                                                 test_pearson 0.99098
wandb:                                           test_pearson_delta 0.51334
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.27407
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.8963
wandb:                                       test_unseen_single_mse 0.00283
wandb:                                    test_unseen_single_mse_de 0.18718
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.20051
wandb:                                   test_unseen_single_pearson 0.99354
wandb:                                test_unseen_single_pearson_de 0.93814
wandb:                             test_unseen_single_pearson_delta 0.36677
wandb:                                                 train_de_mse 0.05479
wandb:                                             train_de_pearson 0.91195
wandb:                                                    train_mse 0.00174
wandb:                                                train_pearson 0.99632
wandb:                                                training_loss 0.49347
wandb:                                                   val_de_mse 0.1425
wandb:                                               val_de_pearson 0.87453
wandb:                                                      val_mse 0.00262
wandb:                                                  val_pearson 0.99401
wandb: 
wandb: üöÄ View run gears_esm_NormanWeissman2019_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/d8egb97g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_201610-d8egb97g/logs
