cuda-11.8.0 loaded successful
gcc-12.2.0 loaded successful
cmake-3.27.0 loaded successful
openmpi-4.1.2 loaded successful
Openblas-0.3.25 loaded successful
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/33 [00:00<?, ?it/s]  6%|â–Œ         | 2/33 [00:00<00:13,  2.27it/s]  9%|â–‰         | 3/33 [00:01<00:18,  1.60it/s] 12%|â–ˆâ–        | 4/33 [00:02<00:17,  1.65it/s] 15%|â–ˆâ–Œ        | 5/33 [00:03<00:17,  1.59it/s] 18%|â–ˆâ–Š        | 6/33 [00:04<00:21,  1.23it/s] 21%|â–ˆâ–ˆ        | 7/33 [00:05<00:21,  1.23it/s] 24%|â–ˆâ–ˆâ–       | 8/33 [00:05<00:16,  1.50it/s] 27%|â–ˆâ–ˆâ–‹       | 9/33 [00:06<00:19,  1.24it/s] 30%|â–ˆâ–ˆâ–ˆ       | 10/33 [00:06<00:16,  1.43it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 11/33 [00:07<00:12,  1.81it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 12/33 [00:07<00:13,  1.60it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 13/33 [00:08<00:10,  1.98it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/33 [00:09<00:13,  1.41it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 15/33 [00:10<00:12,  1.40it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 16/33 [00:10<00:10,  1.64it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:11<00:09,  1.63it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/33 [00:11<00:08,  1.80it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 19/33 [00:12<00:09,  1.44it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 20/33 [00:13<00:09,  1.38it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 21/33 [00:13<00:08,  1.44it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:14<00:05,  1.87it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:14<00:05,  1.72it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:15<00:05,  1.65it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:16<00:04,  1.67it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:16<00:03,  1.85it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:16<00:03,  1.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:17<00:01,  2.14it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:17<00:01,  2.46it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:18<00:00,  2.13it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:19<00:00,  2.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:19<00:00,  1.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:19<00:00,  1.68it/s]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_stimulated/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_stimulated/splits/datlingerbock2017_stimulated_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_011821-9rrcaejh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_stimulated_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/9rrcaejh
  0%|          | 0/3118 [00:00<?, ?it/s]  0%|          | 9/3118 [00:00<00:35, 87.04it/s]  1%|          | 19/3118 [00:00<00:33, 91.86it/s]  1%|          | 32/3118 [00:00<00:28, 106.60it/s]  1%|â–         | 44/3118 [00:00<00:28, 109.12it/s]  2%|â–         | 57/3118 [00:00<00:26, 114.02it/s]  2%|â–         | 70/3118 [00:00<00:26, 116.91it/s]  3%|â–Ž         | 82/3118 [00:00<00:26, 116.11it/s]  3%|â–Ž         | 94/3118 [00:00<00:25, 117.14it/s]  3%|â–Ž         | 106/3118 [00:00<00:26, 113.35it/s]  4%|â–         | 118/3118 [00:01<00:26, 114.76it/s]  4%|â–         | 131/3118 [00:01<00:25, 118.00it/s]  5%|â–         | 144/3118 [00:01<00:25, 118.52it/s]  5%|â–Œ         | 156/3118 [00:01<00:25, 115.73it/s]  5%|â–Œ         | 168/3118 [00:01<00:25, 115.77it/s]  6%|â–Œ         | 180/3118 [00:01<00:25, 115.42it/s]  6%|â–Œ         | 192/3118 [00:01<00:25, 112.63it/s]  7%|â–‹         | 205/3118 [00:01<00:25, 112.14it/s]  7%|â–‹         | 219/3118 [00:01<00:24, 117.57it/s]  7%|â–‹         | 231/3118 [00:02<00:24, 116.27it/s]  8%|â–Š         | 244/3118 [00:02<00:24, 117.61it/s]  8%|â–Š         | 256/3118 [00:02<00:25, 114.07it/s]  9%|â–Š         | 268/3118 [00:02<00:24, 115.25it/s]  9%|â–‰         | 281/3118 [00:02<00:24, 114.97it/s]  9%|â–‰         | 294/3118 [00:02<00:23, 118.54it/s] 10%|â–‰         | 306/3118 [00:02<00:24, 114.56it/s] 10%|â–ˆ         | 319/3118 [00:02<00:24, 113.79it/s] 11%|â–ˆ         | 333/3118 [00:02<00:23, 119.19it/s] 11%|â–ˆ         | 345/3118 [00:03<00:23, 116.90it/s] 11%|â–ˆâ–        | 358/3118 [00:03<00:23, 119.35it/s] 12%|â–ˆâ–        | 370/3118 [00:03<00:23, 117.00it/s] 12%|â–ˆâ–        | 383/3118 [00:03<00:22, 119.86it/s] 13%|â–ˆâ–Ž        | 396/3118 [00:03<00:23, 118.00it/s] 13%|â–ˆâ–Ž        | 408/3118 [00:03<00:23, 116.92it/s] 14%|â–ˆâ–Ž        | 421/3118 [00:03<00:22, 118.18it/s] 14%|â–ˆâ–        | 434/3118 [00:03<00:22, 120.40it/s] 14%|â–ˆâ–        | 447/3118 [00:03<00:23, 115.38it/s] 15%|â–ˆâ–        | 460/3118 [00:03<00:23, 115.41it/s] 15%|â–ˆâ–Œ        | 472/3118 [00:04<00:24, 109.95it/s] 16%|â–ˆâ–Œ        | 484/3118 [00:04<00:24, 108.39it/s] 16%|â–ˆâ–Œ        | 498/3118 [00:04<00:23, 112.14it/s] 16%|â–ˆâ–‹        | 511/3118 [00:04<00:22, 113.67it/s] 17%|â–ˆâ–‹        | 525/3118 [00:04<00:21, 118.44it/s] 17%|â–ˆâ–‹        | 538/3118 [00:04<00:22, 116.45it/s] 18%|â–ˆâ–Š        | 551/3118 [00:04<00:21, 117.95it/s] 18%|â–ˆâ–Š        | 563/3118 [00:04<00:21, 117.64it/s] 18%|â–ˆâ–Š        | 575/3118 [00:04<00:21, 117.99it/s] 19%|â–ˆâ–‰        | 588/3118 [00:05<00:21, 118.00it/s] 19%|â–ˆâ–‰        | 601/3118 [00:05<00:21, 118.11it/s] 20%|â–ˆâ–‰        | 613/3118 [00:05<00:21, 117.71it/s] 20%|â–ˆâ–ˆ        | 625/3118 [00:05<00:21, 117.96it/s] 20%|â–ˆâ–ˆ        | 637/3118 [00:05<00:21, 117.48it/s] 21%|â–ˆâ–ˆ        | 649/3118 [00:05<00:21, 117.47it/s] 21%|â–ˆâ–ˆ        | 661/3118 [00:05<00:21, 116.88it/s] 22%|â–ˆâ–ˆâ–       | 674/3118 [00:05<00:21, 115.47it/s] 22%|â–ˆâ–ˆâ–       | 686/3118 [00:05<00:21, 114.22it/s] 22%|â–ˆâ–ˆâ–       | 699/3118 [00:06<00:20, 117.62it/s] 23%|â–ˆâ–ˆâ–Ž       | 711/3118 [00:06<00:21, 113.62it/s] 23%|â–ˆâ–ˆâ–Ž       | 724/3118 [00:06<00:21, 113.81it/s] 24%|â–ˆâ–ˆâ–Ž       | 736/3118 [00:06<00:20, 113.84it/s] 24%|â–ˆâ–ˆâ–       | 749/3118 [00:06<00:20, 116.62it/s] 24%|â–ˆâ–ˆâ–       | 761/3118 [00:06<00:21, 110.36it/s] 25%|â–ˆâ–ˆâ–       | 775/3118 [00:06<00:19, 117.75it/s] 25%|â–ˆâ–ˆâ–Œ       | 787/3118 [00:06<00:20, 115.54it/s] 26%|â–ˆâ–ˆâ–Œ       | 799/3118 [00:06<00:20, 112.31it/s] 26%|â–ˆâ–ˆâ–Œ       | 812/3118 [00:07<00:19, 115.36it/s] 26%|â–ˆâ–ˆâ–‹       | 824/3118 [00:07<00:19, 115.38it/s] 27%|â–ˆâ–ˆâ–‹       | 836/3118 [00:07<00:19, 114.60it/s] 27%|â–ˆâ–ˆâ–‹       | 848/3118 [00:07<00:20, 113.17it/s] 28%|â–ˆâ–ˆâ–Š       | 860/3118 [00:07<00:20, 112.28it/s] 28%|â–ˆâ–ˆâ–Š       | 872/3118 [00:07<00:19, 112.92it/s] 28%|â–ˆâ–ˆâ–Š       | 885/3118 [00:07<00:19, 115.13it/s] 29%|â–ˆâ–ˆâ–‰       | 897/3118 [00:07<00:19, 115.44it/s] 29%|â–ˆâ–ˆâ–‰       | 909/3118 [00:07<00:19, 114.25it/s] 30%|â–ˆâ–ˆâ–‰       | 921/3118 [00:08<00:19, 112.02it/s] 30%|â–ˆâ–ˆâ–‰       | 934/3118 [00:08<00:19, 114.51it/s] 30%|â–ˆâ–ˆâ–ˆ       | 946/3118 [00:08<00:18, 115.15it/s] 31%|â–ˆâ–ˆâ–ˆ       | 958/3118 [00:08<00:19, 113.36it/s] 31%|â–ˆâ–ˆâ–ˆ       | 970/3118 [00:08<00:19, 112.23it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 982/3118 [00:08<00:18, 113.49it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 995/3118 [00:08<00:18, 117.18it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1007/3118 [00:08<00:18, 116.76it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1019/3118 [00:08<00:18, 114.86it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1032/3118 [00:08<00:17, 118.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1044/3118 [00:09<00:17, 116.04it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1058/3118 [00:09<00:17, 120.04it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1071/3118 [00:09<00:17, 118.03it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1084/3118 [00:09<00:16, 120.83it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1097/3118 [00:09<00:16, 120.77it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1110/3118 [00:09<00:17, 116.72it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1122/3118 [00:09<00:16, 117.61it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1135/3118 [00:09<00:16, 119.50it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1147/3118 [00:09<00:16, 119.56it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1159/3118 [00:10<00:16, 117.93it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1171/3118 [00:10<00:17, 112.51it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1183/3118 [00:10<00:17, 112.55it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1195/3118 [00:10<00:17, 113.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1207/3118 [00:10<00:16, 113.04it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1219/3118 [00:10<00:17, 110.68it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1232/3118 [00:10<00:16, 113.82it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1244/3118 [00:10<00:16, 112.01it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1257/3118 [00:10<00:16, 114.40it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1269/3118 [00:11<00:16, 113.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1282/3118 [00:11<00:16, 113.28it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1294/3118 [00:11<00:16, 113.77it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1306/3118 [00:11<00:16, 113.25it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1319/3118 [00:11<00:15, 114.63it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1331/3118 [00:11<00:15, 112.65it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1343/3118 [00:11<00:16, 107.64it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1354/3118 [00:11<00:17, 101.92it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1365/3118 [00:11<00:17, 101.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1376/3118 [00:12<00:18, 96.57it/s]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1386/3118 [00:12<00:17, 96.78it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1396/3118 [00:12<00:18, 91.77it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1407/3118 [00:12<00:18, 94.50it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1417/3118 [00:12<00:18, 91.83it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1427/3118 [00:12<00:18, 91.48it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1437/3118 [00:12<00:19, 88.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1447/3118 [00:12<00:18, 89.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1456/3118 [00:12<00:18, 88.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1466/3118 [00:13<00:18, 89.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1475/3118 [00:13<00:18, 86.51it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1487/3118 [00:13<00:17, 94.68it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1497/3118 [00:13<00:17, 94.49it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1509/3118 [00:13<00:16, 99.84it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1520/3118 [00:13<00:16, 99.81it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1532/3118 [00:13<00:15, 100.73it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1544/3118 [00:13<00:14, 105.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1555/3118 [00:13<00:14, 105.37it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1567/3118 [00:14<00:14, 106.66it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1579/3118 [00:14<00:14, 105.55it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1590/3118 [00:14<00:35, 43.48it/s]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1598/3118 [00:14<00:32, 46.45it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1606/3118 [00:14<00:29, 51.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1614/3118 [00:15<00:36, 41.57it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1627/3118 [00:15<00:29, 49.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1672/3118 [00:15<00:12, 117.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1690/3118 [00:15<00:13, 107.83it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1705/3118 [00:15<00:13, 101.82it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1719/3118 [00:16<00:14, 97.55it/s]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1731/3118 [00:16<00:14, 93.28it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1742/3118 [00:16<00:15, 88.82it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1752/3118 [00:16<00:15, 88.44it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1762/3118 [00:16<00:15, 90.26it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1772/3118 [00:16<00:15, 88.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1782/3118 [00:16<00:14, 89.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1792/3118 [00:16<00:14, 89.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1802/3118 [00:17<00:14, 89.70it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1812/3118 [00:17<00:14, 90.48it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1822/3118 [00:17<00:14, 88.11it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1831/3118 [00:17<00:14, 88.47it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1840/3118 [00:17<00:14, 88.18it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1849/3118 [00:17<00:14, 86.68it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1860/3118 [00:17<00:14, 88.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1870/3118 [00:17<00:13, 89.40it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1880/3118 [00:17<00:13, 90.48it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1890/3118 [00:18<00:13, 90.43it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1900/3118 [00:18<00:13, 89.82it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1909/3118 [00:18<00:14, 85.51it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1918/3118 [00:18<00:14, 84.39it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1927/3118 [00:18<00:14, 84.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1936/3118 [00:18<00:14, 82.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1946/3118 [00:18<00:13, 85.78it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1955/3118 [00:18<00:13, 84.81it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1965/3118 [00:18<00:13, 88.33it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1975/3118 [00:19<00:12, 89.83it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1985/3118 [00:19<00:12, 89.21it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1994/3118 [00:19<00:13, 85.37it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2003/3118 [00:19<00:13, 84.16it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2013/3118 [00:19<00:12, 85.74it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2022/3118 [00:19<00:13, 82.26it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2031/3118 [00:19<00:13, 81.87it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2040/3118 [00:19<00:13, 81.75it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2049/3118 [00:19<00:13, 78.17it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2059/3118 [00:20<00:12, 83.67it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2068/3118 [00:20<00:12, 83.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2077/3118 [00:20<00:12, 80.41it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2087/3118 [00:20<00:12, 82.52it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2096/3118 [00:20<00:12, 83.70it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2106/3118 [00:20<00:11, 86.70it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2115/3118 [00:20<00:11, 86.96it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2124/3118 [00:20<00:11, 86.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2134/3118 [00:20<00:11, 88.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2144/3118 [00:21<00:10, 88.82it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2153/3118 [00:21<00:11, 87.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2163/3118 [00:21<00:10, 87.91it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2173/3118 [00:21<00:10, 88.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2182/3118 [00:21<00:10, 85.54it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2193/3118 [00:21<00:10, 87.77it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2203/3118 [00:21<00:10, 88.75it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2213/3118 [00:21<00:09, 90.78it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2223/3118 [00:21<00:10, 89.33it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2232/3118 [00:22<00:10, 87.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2242/3118 [00:22<00:09, 89.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2252/3118 [00:22<00:09, 88.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2263/3118 [00:22<00:09, 92.70it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2274/3118 [00:22<00:08, 97.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2285/3118 [00:22<00:08, 100.70it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2297/3118 [00:22<00:07, 103.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2309/3118 [00:22<00:07, 103.39it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2320/3118 [00:22<00:07, 103.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2331/3118 [00:23<00:14, 55.33it/s]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2340/3118 [00:23<00:18, 41.71it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2383/3118 [00:23<00:07, 96.62it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2400/3118 [00:23<00:07, 99.58it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2415/3118 [00:24<00:06, 100.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2429/3118 [00:24<00:07, 98.23it/s]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2442/3118 [00:24<00:06, 101.48it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2454/3118 [00:24<00:06, 101.39it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2466/3118 [00:24<00:06, 102.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2478/3118 [00:24<00:06, 96.91it/s]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2489/3118 [00:24<00:06, 99.46it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2500/3118 [00:24<00:06, 98.78it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2511/3118 [00:25<00:06, 97.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2521/3118 [00:25<00:06, 96.16it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2533/3118 [00:25<00:05, 100.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2544/3118 [00:25<00:05, 102.19it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2555/3118 [00:25<00:05, 99.56it/s]  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2566/3118 [00:25<00:06, 90.93it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2576/3118 [00:25<00:06, 88.53it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2585/3118 [00:25<00:06, 85.76it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2594/3118 [00:26<00:06, 86.53it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2605/3118 [00:26<00:05, 90.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2615/3118 [00:26<00:05, 86.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2624/3118 [00:26<00:05, 87.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2634/3118 [00:26<00:05, 89.53it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2644/3118 [00:26<00:05, 85.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2655/3118 [00:26<00:05, 91.62it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2665/3118 [00:26<00:04, 93.19it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2676/3118 [00:26<00:04, 96.14it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2689/3118 [00:27<00:04, 103.40it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2700/3118 [00:27<00:04, 103.61it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2711/3118 [00:27<00:03, 104.91it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2722/3118 [00:27<00:03, 99.58it/s]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2735/3118 [00:27<00:03, 104.83it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2746/3118 [00:27<00:03, 105.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2758/3118 [00:27<00:03, 108.41it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2770/3118 [00:27<00:03, 108.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2783/3118 [00:27<00:03, 110.50it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2795/3118 [00:27<00:02, 110.22it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2808/3118 [00:28<00:02, 112.44it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2820/3118 [00:28<00:02, 105.73it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2831/3118 [00:28<00:02, 97.81it/s]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2841/3118 [00:28<00:02, 96.47it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2852/3118 [00:28<00:02, 95.41it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2863/3118 [00:28<00:02, 96.68it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2873/3118 [00:28<00:02, 94.74it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2885/3118 [00:28<00:02, 100.49it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2896/3118 [00:29<00:02, 99.67it/s]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2907/3118 [00:29<00:02, 97.65it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2917/3118 [00:29<00:02, 95.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2928/3118 [00:29<00:01, 97.68it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2938/3118 [00:29<00:01, 96.57it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2948/3118 [00:29<00:01, 93.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2959/3118 [00:29<00:01, 96.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2969/3118 [00:29<00:01, 96.50it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2979/3118 [00:29<00:01, 93.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2989/3118 [00:30<00:01, 93.91it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3000/3118 [00:30<00:01, 96.71it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3010/3118 [00:30<00:01, 92.61it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3021/3118 [00:30<00:01, 96.46it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3031/3118 [00:30<00:00, 90.85it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3043/3118 [00:30<00:00, 98.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3053/3118 [00:30<00:00, 94.55it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3063/3118 [00:30<00:00, 90.81it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3073/3118 [00:30<00:00, 86.27it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3082/3118 [00:31<00:00, 80.14it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3091/3118 [00:31<00:00, 79.25it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3100/3118 [00:31<00:00, 80.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3109/3118 [00:31<00:00, 82.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3118/3118 [00:31<00:00, 99.03it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 1.0491
Epoch 1: Train Overall MSE: 0.0034 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0079 Validation Top 20 DE MSE: 0.0046. 
Epoch 2 Step 1 Train Loss: 0.6069
Epoch 2: Train Overall MSE: 0.0034 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0069 Validation Top 20 DE MSE: 0.0040. 
Epoch 3 Step 1 Train Loss: 0.6942
Epoch 3: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0088 Validation Top 20 DE MSE: 0.0063. 
Epoch 4 Step 1 Train Loss: 0.6278
Epoch 4: Train Overall MSE: 0.0070 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0061. 
Epoch 5 Step 1 Train Loss: 0.6585
Epoch 5: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0068. 
Epoch 6 Step 1 Train Loss: 0.6336
Epoch 6: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0057. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0069. 
Epoch 7 Step 1 Train Loss: 0.5351
Epoch 7: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0056. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0067. 
Epoch 8 Step 1 Train Loss: 0.7440
Epoch 8: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0071. 
Epoch 9 Step 1 Train Loss: 0.5588
Epoch 9: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0071. 
Epoch 10 Step 1 Train Loss: 0.7398
Epoch 10: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0073. 
Epoch 11 Step 1 Train Loss: 0.6995
Epoch 11: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0057. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0069. 
Epoch 12 Step 1 Train Loss: 0.4401
Epoch 12: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0069. 
Epoch 13 Step 1 Train Loss: 0.5668
Epoch 13: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0070. 
Epoch 14 Step 1 Train Loss: 0.6560
Epoch 14: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0074. 
Epoch 15 Step 1 Train Loss: 0.6950
Epoch 15: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0072. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0127
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0049023484
test_unseen_single_pearson: 0.9608742410341198
test_unseen_single_mse_de: 0.012655498
test_unseen_single_pearson_de: 0.3982467243076879
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.03743748988256067
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.44375000000000003
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5249999999999999
test_unseen_single_mse_top20_de_non_dropout: 0.017451681
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.004 MB of 0.018 MB uploadedwandb: | 0.004 MB of 0.018 MB uploadedwandb: / 0.018 MB of 0.018 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ƒâ–â–„â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡
wandb:                                             train_de_pearson â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                train_pearson â–ˆâ–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–
wandb:                                                training_loss â–‡â–ˆâ–†â–„â–ƒâ–„â–‚â–„â–„â–ƒâ–„â–„â–†â–„â–„â–„â–ƒâ–…â–…â–ƒâ–„â–„â–ƒâ–„â–ƒâ–…â–…â–ƒâ–„â–â–…â–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–…
wandb:                                                   val_de_mse â–‚â–â–†â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆ
wandb:                                               val_de_pearson â–â–ˆâ–‡â–†â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–‚â–ƒ
wandb:                                                      val_mse â–â–â–…â–…â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆ
wandb:                                                  val_pearson â–ˆâ–ˆâ–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01266
wandb:                                              test_de_pearson 0.39825
wandb:               test_frac_opposite_direction_top20_non_dropout 0.44375
wandb:                          test_frac_sigma_below_1_non_dropout 0.525
wandb:                                                     test_mse 0.0049
wandb:                                test_mse_top20_de_non_dropout 0.01745
wandb:                                                 test_pearson 0.96087
wandb:                                           test_pearson_delta 0.03744
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.44375
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.525
wandb:                                       test_unseen_single_mse 0.0049
wandb:                                    test_unseen_single_mse_de 0.01266
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01745
wandb:                                   test_unseen_single_pearson 0.96087
wandb:                                test_unseen_single_pearson_de 0.39825
wandb:                             test_unseen_single_pearson_delta 0.03744
wandb:                                                 train_de_mse 0.01067
wandb:                                             train_de_pearson 0.33771
wandb:                                                    train_mse 0.00787
wandb:                                                train_pearson 0.94124
wandb:                                                training_loss 0.66106
wandb:                                                   val_de_mse 0.00721
wandb:                                               val_de_pearson 0.53557
wandb:                                                      val_mse 0.00611
wandb:                                                  val_pearson 0.95199
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_stimulated_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/9rrcaejh
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_011821-9rrcaejh/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_stimulated/splits/datlingerbock2017_stimulated_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_012133-j3mh5ou0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_stimulated_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/j3mh5ou0
Start Training...
Epoch 1 Step 1 Train Loss: 0.8474
Epoch 1: Train Overall MSE: 0.0038 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0064. 
Epoch 2 Step 1 Train Loss: 0.6659
Epoch 2: Train Overall MSE: 0.0035 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0087 Validation Top 20 DE MSE: 0.0061. 
Epoch 3 Step 1 Train Loss: 0.5868
Epoch 3: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0065. 
Epoch 4 Step 1 Train Loss: 0.5894
Epoch 4: Train Overall MSE: 0.0071 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0067. 
Epoch 5 Step 1 Train Loss: 0.5764
Epoch 5: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0072. 
Epoch 6 Step 1 Train Loss: 0.6614
Epoch 6: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0071. 
Epoch 7 Step 1 Train Loss: 0.5169
Epoch 7: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0071. 
Epoch 8 Step 1 Train Loss: 0.6442
Epoch 8: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0070. 
Epoch 9 Step 1 Train Loss: 0.6514
Epoch 9: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0073. 
Epoch 10 Step 1 Train Loss: 0.6049
Epoch 10: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0073. 
Epoch 11 Step 1 Train Loss: 0.5652
Epoch 11: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0073. 
Epoch 12 Step 1 Train Loss: 0.6048
Epoch 12: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0074. 
Epoch 13 Step 1 Train Loss: 0.6535
Epoch 13: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0038. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0072. 
Epoch 14 Step 1 Train Loss: 0.5005
Epoch 14: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0072. 
Epoch 15 Step 1 Train Loss: 0.6751
Epoch 15: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0128 Validation Top 20 DE MSE: 0.0073. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0060
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0033334442
test_unseen_single_pearson: 0.972770086801324
test_unseen_single_mse_de: 0.005962253
test_unseen_single_pearson_de: 0.5252154126123094
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.01735835849626864
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5
test_unseen_single_frac_sigma_below_1_non_dropout: 0.59375
test_unseen_single_mse_top20_de_non_dropout: 0.01075275
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.017 MB uploadedwandb: | 0.001 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–‚â–â–ƒâ–…â–…â–†â–†â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                                             train_de_pearson â–ˆâ–†â–ƒâ–‚â–‚â–â–â–‚â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–„â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                train_pearson â–‡â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:                                                training_loss â–†â–†â–‡â–…â–‚â–ˆâ–‚â–„â–‡â–†â–‡â–ƒâ–…â–…â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–ƒâ–â–„â–ƒâ–„â–„â–„â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–„â–…â–…â–„â–„
wandb:                                                   val_de_mse â–ƒâ–â–ƒâ–„â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆ
wandb:                                               val_de_pearson â–†â–ˆâ–…â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–
wandb:                                                      val_mse â–â–‚â–‚â–„â–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:                                                  val_pearson â–ˆâ–‡â–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00596
wandb:                                              test_de_pearson 0.52522
wandb:               test_frac_opposite_direction_top20_non_dropout 0.5
wandb:                          test_frac_sigma_below_1_non_dropout 0.59375
wandb:                                                     test_mse 0.00333
wandb:                                test_mse_top20_de_non_dropout 0.01075
wandb:                                                 test_pearson 0.97277
wandb:                                           test_pearson_delta 0.01736
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.59375
wandb:                                       test_unseen_single_mse 0.00333
wandb:                                    test_unseen_single_mse_de 0.00596
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01075
wandb:                                   test_unseen_single_pearson 0.97277
wandb:                                test_unseen_single_pearson_de 0.52522
wandb:                             test_unseen_single_pearson_delta 0.01736
wandb:                                                 train_de_mse 0.01282
wandb:                                             train_de_pearson 0.33444
wandb:                                                    train_mse 0.00866
wandb:                                                train_pearson 0.93766
wandb:                                                training_loss 0.72262
wandb:                                                   val_de_mse 0.0073
wandb:                                               val_de_pearson 0.6362
wandb:                                                      val_mse 0.00365
wandb:                                                  val_pearson 0.97011
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_stimulated_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/j3mh5ou0
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_012133-j3mh5ou0/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_stimulated/splits/datlingerbock2017_stimulated_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_012339-8ic7xnq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_stimulated_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8ic7xnq3
Start Training...
Epoch 1 Step 1 Train Loss: 0.9137
Epoch 1: Train Overall MSE: 0.0032 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0060 Validation Top 20 DE MSE: 0.0042. 
Epoch 2 Step 1 Train Loss: 0.7341
Epoch 2: Train Overall MSE: 0.0032 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0059 Validation Top 20 DE MSE: 0.0047. 
Epoch 3 Step 1 Train Loss: 0.6040
Epoch 3: Train Overall MSE: 0.0067 Validation Overall MSE: 0.0057. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0095. 
Epoch 4 Step 1 Train Loss: 0.5566
Epoch 4: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0094. 
Epoch 5 Step 1 Train Loss: 0.6503
Epoch 5: Train Overall MSE: 0.0083 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0096. 
Epoch 6 Step 1 Train Loss: 0.6397
Epoch 6: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0099. 
Epoch 7 Step 1 Train Loss: 0.6929
Epoch 7: Train Overall MSE: 0.0091 Validation Overall MSE: 0.0065. 
Train Top 20 DE MSE: 0.0136 Validation Top 20 DE MSE: 0.0103. 
Epoch 8 Step 1 Train Loss: 0.6328
Epoch 8: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0097. 
Epoch 9 Step 1 Train Loss: 0.5359
Epoch 9: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0102. 
Epoch 10 Step 1 Train Loss: 0.4867
Epoch 10: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0098. 
Epoch 11 Step 1 Train Loss: 0.5898
Epoch 11: Train Overall MSE: 0.0090 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0133 Validation Top 20 DE MSE: 0.0100. 
Epoch 12 Step 1 Train Loss: 0.5691
Epoch 12: Train Overall MSE: 0.0083 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0095. 
Epoch 13 Step 1 Train Loss: 0.6400
Epoch 13: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0064. 
Train Top 20 DE MSE: 0.0131 Validation Top 20 DE MSE: 0.0102. 
Epoch 14 Step 1 Train Loss: 0.6089
Epoch 14: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0130 Validation Top 20 DE MSE: 0.0098. 
Epoch 15 Step 1 Train Loss: 0.6506
Epoch 15: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0095. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0120
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0040046666
test_unseen_single_pearson: 0.9682566155638717
test_unseen_single_mse_de: 0.011956251
test_unseen_single_pearson_de: 0.7420652469847284
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.0008019133911579008
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4625
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6875
test_unseen_single_mse_top20_de_non_dropout: 0.019412734
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–â–…â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡
wandb:                                             train_de_pearson â–ˆâ–†â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–…â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:                                                train_pearson â–ˆâ–ˆâ–„â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–‚
wandb:                                                training_loss â–ˆâ–‡â–‡â–…â–„â–…â–ƒâ–…â–…â–ƒâ–†â–‚â–ƒâ–„â–†â–ƒâ–„â–„â–…â–ƒâ–„â–ƒâ–†â–„â–…â–‚â–‚â–ƒâ–…â–„â–„â–„â–â–„â–„â–„â–â–ƒâ–ƒâ–ƒ
wandb:                                                   val_de_mse â–â–‚â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡
wandb:                                               val_de_pearson â–ˆâ–„â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–
wandb:                                                      val_mse â–â–‚â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡
wandb:                                                  val_pearson â–ˆâ–†â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01196
wandb:                                              test_de_pearson 0.74207
wandb:               test_frac_opposite_direction_top20_non_dropout 0.4625
wandb:                          test_frac_sigma_below_1_non_dropout 0.6875
wandb:                                                     test_mse 0.004
wandb:                                test_mse_top20_de_non_dropout 0.01941
wandb:                                                 test_pearson 0.96826
wandb:                                           test_pearson_delta -0.0008
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.4625
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.6875
wandb:                                       test_unseen_single_mse 0.004
wandb:                                    test_unseen_single_mse_de 0.01196
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01941
wandb:                                   test_unseen_single_pearson 0.96826
wandb:                                test_unseen_single_pearson_de 0.74207
wandb:                             test_unseen_single_pearson_delta -0.0008
wandb:                                                 train_de_mse 0.01243
wandb:                                             train_de_pearson 0.15971
wandb:                                                    train_mse 0.00836
wandb:                                                train_pearson 0.93882
wandb:                                                training_loss 0.59958
wandb:                                                   val_de_mse 0.00947
wandb:                                               val_de_pearson 0.09671
wandb:                                                      val_mse 0.00605
wandb:                                                  val_pearson 0.95297
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_stimulated_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8ic7xnq3
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_012339-8ic7xnq3/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_stimulated/splits/datlingerbock2017_stimulated_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_012553-tm35wagi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_stimulated_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/tm35wagi
Start Training...
Epoch 1 Step 1 Train Loss: 0.8497
Epoch 1: Train Overall MSE: 0.0041 Validation Overall MSE: 0.0039. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0041. 
Epoch 2 Step 1 Train Loss: 0.7137
Epoch 2: Train Overall MSE: 0.0035 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0080 Validation Top 20 DE MSE: 0.0053. 
Epoch 3 Step 1 Train Loss: 0.7066
Epoch 3: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0071. 
Epoch 4 Step 1 Train Loss: 0.6209
Epoch 4: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0069. 
Epoch 5 Step 1 Train Loss: 0.5623
Epoch 5: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0051. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0067. 
Epoch 6 Step 1 Train Loss: 0.6036
Epoch 6: Train Overall MSE: 0.0089 Validation Overall MSE: 0.0052. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0071. 
Epoch 7 Step 1 Train Loss: 0.5209
Epoch 7: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0071. 
Epoch 8 Step 1 Train Loss: 0.5446
Epoch 8: Train Overall MSE: 0.0093 Validation Overall MSE: 0.0052. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0070. 
Epoch 9 Step 1 Train Loss: 0.5823
Epoch 9: Train Overall MSE: 0.0091 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0071. 
Epoch 10 Step 1 Train Loss: 0.6640
Epoch 10: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0051. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0068. 
Epoch 11 Step 1 Train Loss: 0.6145
Epoch 11: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0072. 
Epoch 12 Step 1 Train Loss: 0.6445
Epoch 12: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0071. 
Epoch 13 Step 1 Train Loss: 0.8620
Epoch 13: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0051. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0068. 
Epoch 14 Step 1 Train Loss: 0.6176
Epoch 14: Train Overall MSE: 0.0091 Validation Overall MSE: 0.0052. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0069. 
Epoch 15 Step 1 Train Loss: 0.7474
Epoch 15: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0052. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0069. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0059
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0040049492
test_unseen_single_pearson: 0.9678604659893169
test_unseen_single_mse_de: 0.005930808
test_unseen_single_pearson_de: 0.5665617122262847
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.06742980743777766
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5
test_unseen_single_frac_sigma_below_1_non_dropout: 0.55
test_unseen_single_mse_top20_de_non_dropout: 0.014271501
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.017 MB uploadedwandb: | 0.003 MB of 0.017 MB uploadedwandb: / 0.003 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–…â–â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                                             train_de_pearson â–ˆâ–‡â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–‚â–â–…â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                                                train_pearson â–‡â–ˆâ–„â–ƒâ–‚â–â–‚â–â–â–â–‚â–‚â–‚â–â–‚
wandb:                                                training_loss â–ˆâ–„â–„â–„â–…â–„â–„â–„â–…â–ƒâ–‚â–â–‚â–„â–‚â–„â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–â–…â–‚â–‚â–‚â–…
wandb:                                                   val_de_mse â–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡
wandb:                                               val_de_pearson â–ˆâ–ˆâ–ƒâ–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–‚
wandb:                                                      val_mse â–â–„â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡
wandb:                                                  val_pearson â–ˆâ–…â–â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00593
wandb:                                              test_de_pearson 0.56656
wandb:               test_frac_opposite_direction_top20_non_dropout 0.5
wandb:                          test_frac_sigma_below_1_non_dropout 0.55
wandb:                                                     test_mse 0.004
wandb:                                test_mse_top20_de_non_dropout 0.01427
wandb:                                                 test_pearson 0.96786
wandb:                                           test_pearson_delta -0.06743
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.55
wandb:                                       test_unseen_single_mse 0.004
wandb:                                    test_unseen_single_mse_de 0.00593
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01427
wandb:                                   test_unseen_single_pearson 0.96786
wandb:                                test_unseen_single_pearson_de 0.56656
wandb:                             test_unseen_single_pearson_delta -0.06743
wandb:                                                 train_de_mse 0.01206
wandb:                                             train_de_pearson 0.37294
wandb:                                                    train_mse 0.00876
wandb:                                                train_pearson 0.93723
wandb:                                                training_loss 0.62817
wandb:                                                   val_de_mse 0.00686
wandb:                                               val_de_pearson 0.45134
wandb:                                                      val_mse 0.00517
wandb:                                                  val_pearson 0.95848
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_stimulated_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/tm35wagi
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_012553-tm35wagi/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_stimulated/splits/datlingerbock2017_stimulated_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_012817-vesw9x49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_stimulated_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/vesw9x49
Start Training...
Epoch 1 Step 1 Train Loss: 1.3025
Epoch 1: Train Overall MSE: 0.0042 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0043. 
Epoch 2 Step 1 Train Loss: 0.5589
Epoch 2: Train Overall MSE: 0.0038 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0062. 
Epoch 3 Step 1 Train Loss: 0.6632
Epoch 3: Train Overall MSE: 0.0063 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0085. 
Epoch 4 Step 1 Train Loss: 0.5984
Epoch 4: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0146 Validation Top 20 DE MSE: 0.0091. 
Epoch 5 Step 1 Train Loss: 0.5884
Epoch 5: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0152 Validation Top 20 DE MSE: 0.0099. 
Epoch 6 Step 1 Train Loss: 0.6845
Epoch 6: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0104. 
Epoch 7 Step 1 Train Loss: 0.6006
Epoch 7: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0159 Validation Top 20 DE MSE: 0.0103. 
Epoch 8 Step 1 Train Loss: 0.6825
Epoch 8: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0157 Validation Top 20 DE MSE: 0.0098. 
Epoch 9 Step 1 Train Loss: 0.5595
Epoch 9: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0102. 
Epoch 10 Step 1 Train Loss: 0.6509
Epoch 10: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0057. 
Train Top 20 DE MSE: 0.0156 Validation Top 20 DE MSE: 0.0096. 
Epoch 11 Step 1 Train Loss: 0.6793
Epoch 11: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0099. 
Epoch 12 Step 1 Train Loss: 0.5475
Epoch 12: Train Overall MSE: 0.0090 Validation Overall MSE: 0.0064. 
Train Top 20 DE MSE: 0.0160 Validation Top 20 DE MSE: 0.0108. 
Epoch 13 Step 1 Train Loss: 0.5281
Epoch 13: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0101. 
Epoch 14 Step 1 Train Loss: 0.6980
Epoch 14: Train Overall MSE: 0.0089 Validation Overall MSE: 0.0064. 
Train Top 20 DE MSE: 0.0163 Validation Top 20 DE MSE: 0.0108. 
Epoch 15 Step 1 Train Loss: 0.5483
Epoch 15: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0064. 
Train Top 20 DE MSE: 0.0161 Validation Top 20 DE MSE: 0.0108. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0070
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0039179176
test_unseen_single_pearson: 0.9684855492148007
test_unseen_single_mse_de: 0.006991285
test_unseen_single_pearson_de: 0.5548244920071052
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.03711330600580038
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.55625
test_unseen_single_frac_sigma_below_1_non_dropout: 0.4625
test_unseen_single_mse_top20_de_non_dropout: 0.013810154
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.017 MB uploadedwandb: | 0.001 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–‚â–â–…â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–†â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–‚â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                                                train_pearson â–‡â–ˆâ–„â–ƒâ–‚â–â–â–‚â–â–‚â–‚â–â–‚â–â–
wandb:                                                training_loss â–…â–ˆâ–ƒâ–‚â–„â–„â–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–†â–â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–‚â–‚â–ƒâ–„â–ƒâ–…â–‚â–„â–‚â–‚â–„â–„
wandb:                                                   val_de_mse â–â–ƒâ–…â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                                               val_de_pearson â–ˆâ–‡â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–
wandb:                                                      val_mse â–â–â–…â–†â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:                                                  val_pearson â–ˆâ–ˆâ–„â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00699
wandb:                                              test_de_pearson 0.55482
wandb:               test_frac_opposite_direction_top20_non_dropout 0.55625
wandb:                          test_frac_sigma_below_1_non_dropout 0.4625
wandb:                                                     test_mse 0.00392
wandb:                                test_mse_top20_de_non_dropout 0.01381
wandb:                                                 test_pearson 0.96849
wandb:                                           test_pearson_delta 0.03711
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.55625
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.4625
wandb:                                       test_unseen_single_mse 0.00392
wandb:                                    test_unseen_single_mse_de 0.00699
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01381
wandb:                                   test_unseen_single_pearson 0.96849
wandb:                                test_unseen_single_pearson_de 0.55482
wandb:                             test_unseen_single_pearson_delta 0.03711
wandb:                                                 train_de_mse 0.01614
wandb:                                             train_de_pearson 0.22875
wandb:                                                    train_mse 0.00875
wandb:                                                train_pearson 0.93535
wandb:                                                training_loss 0.62422
wandb:                                                   val_de_mse 0.01081
wandb:                                               val_de_pearson 0.35371
wandb:                                                      val_mse 0.00643
wandb:                                                  val_pearson 0.94892
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_stimulated_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/vesw9x49
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_012817-vesw9x49/logs
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/33 [00:00<?, ?it/s]  3%|â–Ž         | 1/33 [00:00<00:23,  1.38it/s]  6%|â–Œ         | 2/33 [00:01<00:18,  1.69it/s] 12%|â–ˆâ–        | 4/33 [00:01<00:10,  2.67it/s] 18%|â–ˆâ–Š        | 6/33 [00:02<00:11,  2.26it/s] 21%|â–ˆâ–ˆ        | 7/33 [00:03<00:12,  2.05it/s] 24%|â–ˆâ–ˆâ–       | 8/33 [00:03<00:12,  1.96it/s] 27%|â–ˆâ–ˆâ–‹       | 9/33 [00:04<00:12,  1.85it/s] 30%|â–ˆâ–ˆâ–ˆ       | 10/33 [00:05<00:13,  1.74it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 11/33 [00:05<00:11,  1.85it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 12/33 [00:06<00:11,  1.86it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 13/33 [00:06<00:11,  1.77it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/33 [00:07<00:11,  1.60it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 15/33 [00:08<00:11,  1.63it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 16/33 [00:08<00:10,  1.55it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:09<00:11,  1.41it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/33 [00:10<00:09,  1.66it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 19/33 [00:10<00:08,  1.65it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 20/33 [00:11<00:08,  1.48it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 21/33 [00:12<00:07,  1.64it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:12<00:07,  1.56it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:13<00:06,  1.55it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:13<00:04,  1.94it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:14<00:03,  2.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:14<00:03,  2.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:14<00:02,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:15<00:01,  2.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:15<00:01,  3.07it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:15<00:00,  3.82it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:15<00:00,  4.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:15<00:00,  4.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:16<00:00,  4.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:16<00:00,  2.05it/s]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_unstimulated/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_unstimulated/splits/datlingerbock2017_unstimulated_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_013126-0s3rrue0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_unstimulated_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0s3rrue0
  0%|          | 0/3129 [00:00<?, ?it/s]  0%|          | 5/3129 [00:00<01:05, 47.66it/s]  0%|          | 12/3129 [00:00<00:54, 57.56it/s]  1%|          | 19/3129 [00:00<00:49, 62.40it/s]  1%|          | 28/3129 [00:00<00:43, 71.22it/s]  1%|          | 37/3129 [00:00<00:41, 75.25it/s]  1%|â–         | 46/3129 [00:00<00:38, 79.32it/s]  2%|â–         | 54/3129 [00:00<00:38, 79.03it/s]  2%|â–         | 64/3129 [00:00<00:36, 83.70it/s]  2%|â–         | 74/3129 [00:00<00:35, 85.94it/s]  3%|â–Ž         | 83/3129 [00:01<00:35, 85.64it/s]  3%|â–Ž         | 92/3129 [00:01<00:35, 86.44it/s]  3%|â–Ž         | 101/3129 [00:01<00:36, 83.93it/s]  4%|â–Ž         | 110/3129 [00:01<00:36, 82.66it/s]  4%|â–         | 120/3129 [00:01<00:34, 86.23it/s]  4%|â–         | 129/3129 [00:01<00:34, 86.18it/s]  4%|â–         | 138/3129 [00:01<00:34, 85.92it/s]  5%|â–         | 147/3129 [00:01<00:34, 85.92it/s]  5%|â–         | 156/3129 [00:01<00:34, 85.79it/s]  5%|â–Œ         | 165/3129 [00:02<00:34, 85.24it/s]  6%|â–Œ         | 174/3129 [00:02<00:34, 85.44it/s]  6%|â–Œ         | 183/3129 [00:02<00:34, 84.44it/s]  6%|â–Œ         | 192/3129 [00:02<00:34, 84.03it/s]  6%|â–‹         | 201/3129 [00:02<00:34, 84.43it/s]  7%|â–‹         | 210/3129 [00:02<00:34, 84.18it/s]  7%|â–‹         | 219/3129 [00:02<00:34, 83.71it/s]  7%|â–‹         | 228/3129 [00:02<00:35, 82.23it/s]  8%|â–Š         | 237/3129 [00:02<00:35, 80.69it/s]  8%|â–Š         | 246/3129 [00:03<00:35, 80.45it/s]  8%|â–Š         | 255/3129 [00:03<00:39, 73.59it/s]  8%|â–Š         | 265/3129 [00:03<00:36, 79.01it/s]  9%|â–‰         | 275/3129 [00:03<00:35, 79.84it/s]  9%|â–‰         | 286/3129 [00:03<00:32, 86.49it/s]  9%|â–‰         | 297/3129 [00:03<00:30, 92.23it/s] 10%|â–‰         | 307/3129 [00:03<00:30, 92.72it/s] 10%|â–ˆ         | 319/3129 [00:03<00:29, 95.53it/s] 11%|â–ˆ         | 330/3129 [00:03<00:28, 98.46it/s] 11%|â–ˆ         | 340/3129 [00:04<00:28, 98.25it/s] 11%|â–ˆ         | 350/3129 [00:04<00:29, 95.40it/s] 12%|â–ˆâ–        | 360/3129 [00:04<00:28, 95.92it/s] 12%|â–ˆâ–        | 372/3129 [00:04<00:26, 102.15it/s] 12%|â–ˆâ–        | 383/3129 [00:04<00:26, 102.64it/s] 13%|â–ˆâ–Ž        | 394/3129 [00:04<00:26, 103.89it/s] 13%|â–ˆâ–Ž        | 405/3129 [00:04<00:26, 101.50it/s] 13%|â–ˆâ–Ž        | 417/3129 [00:04<00:25, 104.80it/s] 14%|â–ˆâ–Ž        | 428/3129 [00:04<00:26, 101.84it/s] 14%|â–ˆâ–        | 440/3129 [00:04<00:25, 104.59it/s] 14%|â–ˆâ–        | 452/3129 [00:05<00:25, 104.13it/s] 15%|â–ˆâ–        | 464/3129 [00:05<00:25, 106.24it/s] 15%|â–ˆâ–Œ        | 475/3129 [00:05<00:25, 103.70it/s] 16%|â–ˆâ–Œ        | 486/3129 [00:05<00:25, 102.67it/s] 16%|â–ˆâ–Œ        | 498/3129 [00:05<00:25, 103.82it/s] 16%|â–ˆâ–‹        | 510/3129 [00:05<00:25, 103.58it/s] 17%|â–ˆâ–‹        | 522/3129 [00:05<00:24, 106.24it/s] 17%|â–ˆâ–‹        | 533/3129 [00:05<00:25, 102.39it/s] 17%|â–ˆâ–‹        | 544/3129 [00:06<00:25, 101.35it/s] 18%|â–ˆâ–Š        | 555/3129 [00:06<00:26, 97.14it/s]  18%|â–ˆâ–Š        | 566/3129 [00:06<00:25, 99.70it/s] 18%|â–ˆâ–Š        | 577/3129 [00:06<00:25, 100.33it/s] 19%|â–ˆâ–‰        | 588/3129 [00:06<00:25, 98.81it/s]  19%|â–ˆâ–‰        | 599/3129 [00:06<00:25, 99.36it/s] 19%|â–ˆâ–‰        | 609/3129 [00:06<00:26, 95.45it/s] 20%|â–ˆâ–‰        | 619/3129 [00:06<00:26, 96.02it/s] 20%|â–ˆâ–ˆ        | 630/3129 [00:06<00:25, 97.46it/s] 20%|â–ˆâ–ˆ        | 641/3129 [00:06<00:24, 100.92it/s] 21%|â–ˆâ–ˆ        | 652/3129 [00:07<00:25, 98.80it/s]  21%|â–ˆâ–ˆ        | 663/3129 [00:07<00:25, 98.08it/s] 22%|â–ˆâ–ˆâ–       | 674/3129 [00:07<00:24, 99.43it/s] 22%|â–ˆâ–ˆâ–       | 685/3129 [00:07<00:24, 98.42it/s] 22%|â–ˆâ–ˆâ–       | 697/3129 [00:07<00:23, 101.46it/s] 23%|â–ˆâ–ˆâ–Ž       | 708/3129 [00:07<00:24, 99.60it/s]  23%|â–ˆâ–ˆâ–Ž       | 718/3129 [00:07<00:24, 98.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 729/3129 [00:07<00:24, 99.48it/s] 24%|â–ˆâ–ˆâ–Ž       | 739/3129 [00:07<00:24, 98.73it/s] 24%|â–ˆâ–ˆâ–       | 749/3129 [00:08<00:24, 98.28it/s] 24%|â–ˆâ–ˆâ–       | 759/3129 [00:08<00:24, 95.11it/s] 25%|â–ˆâ–ˆâ–       | 770/3129 [00:08<00:24, 97.83it/s] 25%|â–ˆâ–ˆâ–       | 780/3129 [00:08<00:24, 96.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 790/3129 [00:08<00:24, 95.32it/s] 26%|â–ˆâ–ˆâ–Œ       | 800/3129 [00:08<00:25, 92.38it/s] 26%|â–ˆâ–ˆâ–Œ       | 810/3129 [00:08<00:25, 89.94it/s] 26%|â–ˆâ–ˆâ–Œ       | 820/3129 [00:08<00:26, 85.55it/s] 27%|â–ˆâ–ˆâ–‹       | 830/3129 [00:09<00:26, 85.81it/s] 27%|â–ˆâ–ˆâ–‹       | 839/3129 [00:09<00:26, 86.09it/s] 27%|â–ˆâ–ˆâ–‹       | 850/3129 [00:09<00:25, 89.83it/s] 27%|â–ˆâ–ˆâ–‹       | 860/3129 [00:09<00:25, 89.95it/s] 28%|â–ˆâ–ˆâ–Š       | 870/3129 [00:09<00:25, 87.97it/s] 28%|â–ˆâ–ˆâ–Š       | 880/3129 [00:09<00:24, 90.77it/s] 28%|â–ˆâ–ˆâ–Š       | 890/3129 [00:09<00:24, 91.25it/s] 29%|â–ˆâ–ˆâ–‰       | 900/3129 [00:09<00:24, 91.33it/s] 29%|â–ˆâ–ˆâ–‰       | 910/3129 [00:09<00:24, 91.95it/s] 29%|â–ˆâ–ˆâ–‰       | 920/3129 [00:09<00:24, 91.24it/s] 30%|â–ˆâ–ˆâ–‰       | 930/3129 [00:10<00:24, 89.48it/s] 30%|â–ˆâ–ˆâ–ˆ       | 939/3129 [00:10<00:25, 85.94it/s] 30%|â–ˆâ–ˆâ–ˆ       | 948/3129 [00:10<00:26, 81.42it/s] 31%|â–ˆâ–ˆâ–ˆ       | 958/3129 [00:10<00:25, 85.14it/s] 31%|â–ˆâ–ˆâ–ˆ       | 967/3129 [00:10<00:26, 81.82it/s] 31%|â–ˆâ–ˆâ–ˆ       | 977/3129 [00:10<00:25, 85.64it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 986/3129 [00:10<00:24, 86.31it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 995/3129 [00:10<00:24, 86.30it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1004/3129 [00:10<00:24, 86.62it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1013/3129 [00:11<00:24, 86.63it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1022/3129 [00:11<00:25, 83.56it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1032/3129 [00:11<00:23, 87.96it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1041/3129 [00:11<00:23, 87.65it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1050/3129 [00:11<00:23, 86.83it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1060/3129 [00:11<00:23, 87.80it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1069/3129 [00:11<00:23, 86.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1078/3129 [00:11<00:23, 86.46it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1087/3129 [00:11<00:24, 84.45it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1097/3129 [00:12<00:23, 87.70it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1106/3129 [00:12<00:23, 85.84it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1117/3129 [00:12<00:22, 90.07it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1127/3129 [00:12<00:22, 88.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1136/3129 [00:12<00:22, 88.54it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1145/3129 [00:12<00:22, 88.93it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1154/3129 [00:12<00:22, 88.47it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1163/3129 [00:12<00:22, 88.67it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1172/3129 [00:12<00:22, 86.75it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1181/3129 [00:13<00:23, 84.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1190/3129 [00:13<00:22, 85.43it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1199/3129 [00:13<00:22, 86.26it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1209/3129 [00:13<00:21, 87.70it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1218/3129 [00:13<00:22, 84.67it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1229/3129 [00:13<00:21, 89.59it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1238/3129 [00:13<00:21, 87.01it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1250/3129 [00:13<00:19, 95.00it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1262/3129 [00:13<00:18, 99.62it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1273/3129 [00:13<00:18, 100.92it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1284/3129 [00:14<00:18, 99.04it/s]  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1295/3129 [00:14<00:18, 101.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1307/3129 [00:14<00:17, 103.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1318/3129 [00:14<00:17, 104.45it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1330/3129 [00:14<00:17, 105.55it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1341/3129 [00:14<00:17, 101.76it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1352/3129 [00:14<00:18, 94.64it/s]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1362/3129 [00:14<00:19, 91.92it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1372/3129 [00:15<00:19, 89.14it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1381/3129 [00:15<00:19, 88.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1391/3129 [00:15<00:19, 89.61it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1400/3129 [00:15<00:19, 87.47it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1409/3129 [00:15<00:19, 87.42it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1418/3129 [00:15<00:20, 84.69it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1427/3129 [00:15<00:20, 83.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1437/3129 [00:15<00:19, 85.87it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1446/3129 [00:15<00:20, 84.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1455/3129 [00:16<00:20, 82.70it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1465/3129 [00:16<00:19, 86.84it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1474/3129 [00:16<00:20, 82.44it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1484/3129 [00:16<00:19, 84.55it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1493/3129 [00:16<00:20, 81.62it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1502/3129 [00:16<00:19, 81.37it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1511/3129 [00:16<00:20, 80.24it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1520/3129 [00:16<00:19, 80.68it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1529/3129 [00:16<00:19, 81.37it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1538/3129 [00:17<00:19, 79.81it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1546/3129 [00:17<00:19, 79.55it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1555/3129 [00:17<00:19, 80.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1564/3129 [00:17<00:18, 82.65it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1573/3129 [00:17<00:18, 82.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1582/3129 [00:17<00:18, 82.69it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1591/3129 [00:17<00:18, 83.55it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1600/3129 [00:17<00:18, 83.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1609/3129 [00:17<00:18, 83.37it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1618/3129 [00:17<00:17, 85.20it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1628/3129 [00:18<00:17, 87.15it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1639/3129 [00:18<00:16, 89.59it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1650/3129 [00:18<00:15, 93.11it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1660/3129 [00:18<00:15, 93.68it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1670/3129 [00:18<00:15, 93.46it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1680/3129 [00:18<00:16, 88.15it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1692/3129 [00:18<00:14, 95.90it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1702/3129 [00:18<00:14, 95.52it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1712/3129 [00:18<00:15, 92.53it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1722/3129 [00:19<00:15, 93.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1733/3129 [00:19<00:14, 93.44it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1744/3129 [00:19<00:14, 96.15it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1754/3129 [00:19<00:15, 91.59it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1765/3129 [00:19<00:14, 94.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1775/3129 [00:19<00:15, 87.74it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1785/3129 [00:19<00:15, 88.54it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1795/3129 [00:19<00:14, 90.63it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1805/3129 [00:20<00:14, 88.95it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1814/3129 [00:20<00:15, 87.46it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1823/3129 [00:20<00:15, 86.11it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1832/3129 [00:20<00:15, 84.34it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1841/3129 [00:20<00:15, 83.58it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1851/3129 [00:20<00:15, 82.41it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1860/3129 [00:20<00:15, 84.28it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1869/3129 [00:20<00:15, 83.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1878/3129 [00:20<00:14, 83.55it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1887/3129 [00:21<00:15, 80.61it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1897/3129 [00:21<00:14, 85.48it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1906/3129 [00:21<00:14, 85.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1915/3129 [00:21<00:14, 84.53it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1924/3129 [00:21<00:14, 83.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1933/3129 [00:21<00:14, 82.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1942/3129 [00:21<00:14, 82.16it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1952/3129 [00:21<00:13, 84.66it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1961/3129 [00:21<00:14, 80.60it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1970/3129 [00:22<00:13, 83.06it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1979/3129 [00:22<00:13, 83.31it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1988/3129 [00:22<00:13, 81.83it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1997/3129 [00:22<00:13, 82.95it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2006/3129 [00:22<00:13, 82.66it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2015/3129 [00:22<00:13, 82.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2024/3129 [00:22<00:13, 82.63it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2033/3129 [00:22<00:12, 84.54it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2043/3129 [00:22<00:12, 86.89it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2053/3129 [00:22<00:12, 89.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2063/3129 [00:23<00:11, 91.22it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2073/3129 [00:23<00:11, 92.18it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2083/3129 [00:23<00:11, 93.46it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2093/3129 [00:23<00:10, 95.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2103/3129 [00:23<00:11, 91.39it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2114/3129 [00:23<00:10, 96.39it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2124/3129 [00:23<00:10, 94.87it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2137/3129 [00:23<00:09, 103.84it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2150/3129 [00:23<00:08, 109.97it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2163/3129 [00:24<00:08, 114.39it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2177/3129 [00:24<00:08, 114.54it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2189/3129 [00:24<00:08, 115.77it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2201/3129 [00:24<00:08, 115.70it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2213/3129 [00:24<00:07, 116.03it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2227/3129 [00:24<00:07, 117.73it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2239/3129 [00:24<00:07, 117.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2252/3129 [00:24<00:07, 117.72it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2265/3129 [00:24<00:07, 116.49it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2278/3129 [00:25<00:07, 118.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2291/3129 [00:25<00:06, 121.14it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2304/3129 [00:25<00:06, 121.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2317/3129 [00:25<00:06, 123.54it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2330/3129 [00:25<00:06, 119.56it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2343/3129 [00:25<00:06, 120.22it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2356/3129 [00:25<00:06, 120.86it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2369/3129 [00:25<00:06, 121.70it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2382/3129 [00:26<00:13, 53.89it/s]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2396/3129 [00:26<00:13, 52.59it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2438/3129 [00:26<00:07, 93.71it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2489/3129 [00:26<00:04, 156.75it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2512/3129 [00:27<00:04, 145.86it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2532/3129 [00:27<00:04, 134.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2550/3129 [00:27<00:04, 130.24it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2566/3129 [00:27<00:04, 126.59it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2581/3129 [00:27<00:04, 127.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2595/3129 [00:27<00:04, 123.44it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2609/3129 [00:27<00:04, 122.81it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2622/3129 [00:28<00:04, 123.59it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2635/3129 [00:28<00:04, 119.83it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2648/3129 [00:28<00:04, 119.83it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2661/3129 [00:28<00:03, 119.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2675/3129 [00:28<00:03, 120.37it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2688/3129 [00:28<00:03, 120.22it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2701/3129 [00:28<00:03, 120.30it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2714/3129 [00:28<00:03, 116.57it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2726/3129 [00:28<00:03, 116.39it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2738/3129 [00:29<00:03, 113.53it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2750/3129 [00:29<00:03, 113.54it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2762/3129 [00:29<00:03, 113.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2776/3129 [00:29<00:03, 115.41it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2788/3129 [00:29<00:06, 56.14it/s]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2841/3129 [00:29<00:02, 132.14it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2863/3129 [00:30<00:03, 87.70it/s]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2906/3129 [00:30<00:01, 132.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2930/3129 [00:30<00:01, 125.85it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2950/3129 [00:31<00:02, 84.76it/s]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2966/3129 [00:31<00:01, 90.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3008/3129 [00:31<00:00, 136.56it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3030/3129 [00:31<00:00, 104.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3060/3129 [00:31<00:00, 132.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3081/3129 [00:32<00:00, 80.13it/s]  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3108/3129 [00:32<00:00, 80.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3129/3129 [00:32<00:00, 95.29it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 1.6616
Epoch 1: Train Overall MSE: 0.0039 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0064 Validation Top 20 DE MSE: 0.0036. 
Epoch 2 Step 1 Train Loss: 0.7183
Epoch 2: Train Overall MSE: 0.0041 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0077 Validation Top 20 DE MSE: 0.0043. 
Epoch 3 Step 1 Train Loss: 0.6709
Epoch 3: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0065. 
Epoch 4 Step 1 Train Loss: 0.9330
Epoch 4: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0076. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0090. 
Epoch 5 Step 1 Train Loss: 0.7240
Epoch 5: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0091. 
Train Top 20 DE MSE: 0.0137 Validation Top 20 DE MSE: 0.0111. 
Epoch 6 Step 1 Train Loss: 0.7003
Epoch 6: Train Overall MSE: 0.0083 Validation Overall MSE: 0.0090. 
Train Top 20 DE MSE: 0.0140 Validation Top 20 DE MSE: 0.0108. 
Epoch 7 Step 1 Train Loss: 0.6990
Epoch 7: Train Overall MSE: 0.0083 Validation Overall MSE: 0.0090. 
Train Top 20 DE MSE: 0.0142 Validation Top 20 DE MSE: 0.0102. 
Epoch 8 Step 1 Train Loss: 0.5743
Epoch 8: Train Overall MSE: 0.0083 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0097. 
Epoch 9 Step 1 Train Loss: 0.9088
Epoch 9: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0093. 
Train Top 20 DE MSE: 0.0143 Validation Top 20 DE MSE: 0.0105. 
Epoch 10 Step 1 Train Loss: 0.7460
Epoch 10: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0090. 
Train Top 20 DE MSE: 0.0144 Validation Top 20 DE MSE: 0.0101. 
Epoch 11 Step 1 Train Loss: 0.7368
Epoch 11: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0094. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0111. 
Epoch 12 Step 1 Train Loss: 0.7136
Epoch 12: Train Overall MSE: 0.0083 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.0140 Validation Top 20 DE MSE: 0.0105. 
Epoch 13 Step 1 Train Loss: 0.6592
Epoch 13: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0106. 
Epoch 14 Step 1 Train Loss: 0.7329
Epoch 14: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0091. 
Train Top 20 DE MSE: 0.0143 Validation Top 20 DE MSE: 0.0104. 
Epoch 15 Step 1 Train Loss: 0.7742
Epoch 15: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.0139 Validation Top 20 DE MSE: 0.0103. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0115
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.004966372
test_unseen_single_pearson: 0.9662191240479606
test_unseen_single_mse_de: 0.011537904
test_unseen_single_pearson_de: 0.5986064214604409
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.01782009740324463
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.53125
test_unseen_single_frac_sigma_below_1_non_dropout: 0.48124999999999996
test_unseen_single_mse_top20_de_non_dropout: 0.01898941
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.003 MB of 0.018 MB uploadedwandb: | 0.003 MB of 0.018 MB uploadedwandb: / 0.018 MB of 0.018 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–‚â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                                             train_de_pearson â–ˆâ–‡â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                                                train_pearson â–ˆâ–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–‚
wandb:                                                training_loss â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–„â–‚â–ƒ
wandb:                                                   val_de_mse â–â–‚â–„â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:                                               val_de_pearson â–ˆâ–…â–ƒâ–‚â–â–â–â–‚â–â–‚â–â–â–â–â–
wandb:                                                      val_mse â–â–‚â–„â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                                                  val_pearson â–ˆâ–‡â–…â–ƒâ–â–â–â–‚â–â–â–â–â–â–â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01154
wandb:                                              test_de_pearson 0.59861
wandb:               test_frac_opposite_direction_top20_non_dropout 0.53125
wandb:                          test_frac_sigma_below_1_non_dropout 0.48125
wandb:                                                     test_mse 0.00497
wandb:                                test_mse_top20_de_non_dropout 0.01899
wandb:                                                 test_pearson 0.96622
wandb:                                           test_pearson_delta 0.01782
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.53125
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.48125
wandb:                                       test_unseen_single_mse 0.00497
wandb:                                    test_unseen_single_mse_de 0.01154
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01899
wandb:                                   test_unseen_single_pearson 0.96622
wandb:                                test_unseen_single_pearson_de 0.59861
wandb:                             test_unseen_single_pearson_delta 0.01782
wandb:                                                 train_de_mse 0.01387
wandb:                                             train_de_pearson 0.18651
wandb:                                                    train_mse 0.00819
wandb:                                                train_pearson 0.94609
wandb:                                                training_loss 0.66513
wandb:                                                   val_de_mse 0.01025
wandb:                                               val_de_pearson 0.29362
wandb:                                                      val_mse 0.00872
wandb:                                                  val_pearson 0.94019
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_unstimulated_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0s3rrue0
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_013126-0s3rrue0/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_unstimulated/splits/datlingerbock2017_unstimulated_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_013419-7o8mh46v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_unstimulated_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/7o8mh46v
Start Training...
Epoch 1 Step 1 Train Loss: 1.5971
Epoch 1: Train Overall MSE: 0.0044 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0076 Validation Top 20 DE MSE: 0.0076. 
Epoch 2 Step 1 Train Loss: 0.8327
Epoch 2: Train Overall MSE: 0.0046 Validation Overall MSE: 0.0046. 
Train Top 20 DE MSE: 0.0078 Validation Top 20 DE MSE: 0.0083. 
Epoch 3 Step 1 Train Loss: 0.7087
Epoch 3: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0098. 
Epoch 4 Step 1 Train Loss: 0.7331
Epoch 4: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0066. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0119. 
Epoch 5 Step 1 Train Loss: 0.6496
Epoch 5: Train Overall MSE: 0.0101 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0169 Validation Top 20 DE MSE: 0.0120. 
Epoch 6 Step 1 Train Loss: 0.7188
Epoch 6: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0068. 
Train Top 20 DE MSE: 0.0162 Validation Top 20 DE MSE: 0.0118. 
Epoch 7 Step 1 Train Loss: 0.6692
Epoch 7: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0073. 
Train Top 20 DE MSE: 0.0170 Validation Top 20 DE MSE: 0.0123. 
Epoch 8 Step 1 Train Loss: 0.6416
Epoch 8: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0163 Validation Top 20 DE MSE: 0.0119. 
Epoch 9 Step 1 Train Loss: 0.7185
Epoch 9: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0172 Validation Top 20 DE MSE: 0.0120. 
Epoch 10 Step 1 Train Loss: 0.7659
Epoch 10: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0164 Validation Top 20 DE MSE: 0.0119. 
Epoch 11 Step 1 Train Loss: 0.7327
Epoch 11: Train Overall MSE: 0.0108 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0178 Validation Top 20 DE MSE: 0.0122. 
Epoch 12 Step 1 Train Loss: 0.7060
Epoch 12: Train Overall MSE: 0.0106 Validation Overall MSE: 0.0070. 
Train Top 20 DE MSE: 0.0175 Validation Top 20 DE MSE: 0.0117. 
Epoch 13 Step 1 Train Loss: 0.8044
Epoch 13: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0070. 
Train Top 20 DE MSE: 0.0172 Validation Top 20 DE MSE: 0.0118. 
Epoch 14 Step 1 Train Loss: 0.7704
Epoch 14: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0172 Validation Top 20 DE MSE: 0.0121. 
Epoch 15 Step 1 Train Loss: 0.6744
Epoch 15: Train Overall MSE: 0.0107 Validation Overall MSE: 0.0073. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.0124. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0067
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0036042985
test_unseen_single_pearson: 0.974989626480019
test_unseen_single_mse_de: 0.0067472667
test_unseen_single_pearson_de: 0.6332186759304814
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.020500165069516886
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.525
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5375000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.011571976
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.017 MB uploadedwandb: | 0.003 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.017 MB uploadedwandb: \ 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–â–ƒâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–‡â–„â–‚â–â–‚â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–ƒâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                train_pearson â–ˆâ–ˆâ–†â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–
wandb:                                                training_loss â–ˆâ–„â–‚â–„â–„â–‚â–…â–‡â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–â–ƒâ–â–‚â–„â–ƒâ–‚â–…â–‚â–‚â–â–â–‚â–‚â–„â–‚â–…â–‚â–„â–‚
wandb:                                                   val_de_mse â–â–‚â–„â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                                               val_de_pearson â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                                                      val_mse â–â–‚â–„â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆ
wandb:                                                  val_pearson â–ˆâ–‡â–…â–ƒâ–â–‚â–â–â–â–â–â–‚â–‚â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00675
wandb:                                              test_de_pearson 0.63322
wandb:               test_frac_opposite_direction_top20_non_dropout 0.525
wandb:                          test_frac_sigma_below_1_non_dropout 0.5375
wandb:                                                     test_mse 0.0036
wandb:                                test_mse_top20_de_non_dropout 0.01157
wandb:                                                 test_pearson 0.97499
wandb:                                           test_pearson_delta 0.0205
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.525
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.5375
wandb:                                       test_unseen_single_mse 0.0036
wandb:                                    test_unseen_single_mse_de 0.00675
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01157
wandb:                                   test_unseen_single_pearson 0.97499
wandb:                                test_unseen_single_pearson_de 0.63322
wandb:                             test_unseen_single_pearson_delta 0.0205
wandb:                                                 train_de_mse 0.01763
wandb:                                             train_de_pearson 0.17633
wandb:                                                    train_mse 0.01075
wandb:                                                train_pearson 0.93349
wandb:                                                training_loss 0.73846
wandb:                                                   val_de_mse 0.01237
wandb:                                               val_de_pearson 0.22732
wandb:                                                      val_mse 0.00729
wandb:                                                  val_pearson 0.95025
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_unstimulated_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/7o8mh46v
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_013419-7o8mh46v/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_unstimulated/splits/datlingerbock2017_unstimulated_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_013609-8bvuhnhi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_unstimulated_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8bvuhnhi
Start Training...
Epoch 1 Step 1 Train Loss: 1.4388
Epoch 1: Train Overall MSE: 0.0046 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0079 Validation Top 20 DE MSE: 0.0078. 
Epoch 2 Step 1 Train Loss: 0.9240
Epoch 2: Train Overall MSE: 0.0044 Validation Overall MSE: 0.0044. 
Train Top 20 DE MSE: 0.0075 Validation Top 20 DE MSE: 0.0071. 
Epoch 3 Step 1 Train Loss: 0.7686
Epoch 3: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0051. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0080. 
Epoch 4 Step 1 Train Loss: 0.7674
Epoch 4: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0134 Validation Top 20 DE MSE: 0.0098. 
Epoch 5 Step 1 Train Loss: 0.6150
Epoch 5: Train Overall MSE: 0.0091 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0107. 
Epoch 6 Step 1 Train Loss: 0.7391
Epoch 6: Train Overall MSE: 0.0096 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0149 Validation Top 20 DE MSE: 0.0111. 
Epoch 7 Step 1 Train Loss: 0.8084
Epoch 7: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0150 Validation Top 20 DE MSE: 0.0114. 
Epoch 8 Step 1 Train Loss: 0.7932
Epoch 8: Train Overall MSE: 0.0095 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0147 Validation Top 20 DE MSE: 0.0114. 
Epoch 9 Step 1 Train Loss: 0.7599
Epoch 9: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0073. 
Train Top 20 DE MSE: 0.0153 Validation Top 20 DE MSE: 0.0115. 
Epoch 10 Step 1 Train Loss: 0.8360
Epoch 10: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0073. 
Train Top 20 DE MSE: 0.0147 Validation Top 20 DE MSE: 0.0116. 
Epoch 11 Step 1 Train Loss: 0.6120
Epoch 11: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0149 Validation Top 20 DE MSE: 0.0113. 
Epoch 12 Step 1 Train Loss: 0.7104
Epoch 12: Train Overall MSE: 0.0096 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0113. 
Epoch 13 Step 1 Train Loss: 0.7181
Epoch 13: Train Overall MSE: 0.0094 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0111. 
Epoch 14 Step 1 Train Loss: 0.8638
Epoch 14: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0073. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0113. 
Epoch 15 Step 1 Train Loss: 0.6628
Epoch 15: Train Overall MSE: 0.0095 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0119. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0075
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0043127732
test_unseen_single_pearson: 0.9706021409322675
test_unseen_single_mse_de: 0.0074891015
test_unseen_single_pearson_de: 0.6584922043755642
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.024168674604696024
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5125
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5187499999999999
test_unseen_single_mse_top20_de_non_dropout: 0.01130322
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.014 MB uploadedwandb: | 0.004 MB of 0.017 MB uploadedwandb: / 0.004 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–â–ƒâ–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–‡â–„â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–‚â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                                                train_pearson â–ˆâ–ˆâ–‡â–ƒâ–‚â–â–â–‚â–â–â–â–â–‚â–â–‚
wandb:                                                training_loss â–†â–ˆâ–…â–ƒâ–‚â–ƒâ–â–…â–„â–‚â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–„â–„â–ƒâ–‚â–…â–„â–ƒâ–ƒâ–‚â–â–â–â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–â–‚â–ƒ
wandb:                                                   val_de_mse â–‚â–â–‚â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:                                               val_de_pearson â–ˆâ–…â–„â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–
wandb:                                                      val_mse â–â–â–ƒâ–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆ
wandb:                                                  val_pearson â–ˆâ–ˆâ–†â–ƒâ–‚â–â–â–‚â–â–â–‚â–‚â–‚â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00749
wandb:                                              test_de_pearson 0.65849
wandb:               test_frac_opposite_direction_top20_non_dropout 0.5125
wandb:                          test_frac_sigma_below_1_non_dropout 0.51875
wandb:                                                     test_mse 0.00431
wandb:                                test_mse_top20_de_non_dropout 0.0113
wandb:                                                 test_pearson 0.9706
wandb:                                           test_pearson_delta -0.02417
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5125
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.51875
wandb:                                       test_unseen_single_mse 0.00431
wandb:                                    test_unseen_single_mse_de 0.00749
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.0113
wandb:                                   test_unseen_single_pearson 0.9706
wandb:                                test_unseen_single_pearson_de 0.65849
wandb:                             test_unseen_single_pearson_delta -0.02417
wandb:                                                 train_de_mse 0.01477
wandb:                                             train_de_pearson 0.16616
wandb:                                                    train_mse 0.00953
wandb:                                                train_pearson 0.93939
wandb:                                                training_loss 0.65023
wandb:                                                   val_de_mse 0.01194
wandb:                                               val_de_pearson 0.48484
wandb:                                                      val_mse 0.0074
wandb:                                                  val_pearson 0.94973
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_unstimulated_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8bvuhnhi
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_013609-8bvuhnhi/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_unstimulated/splits/datlingerbock2017_unstimulated_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_013800-8raift55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_unstimulated_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8raift55
Start Training...
Epoch 1 Step 1 Train Loss: 1.2122
Epoch 1: Train Overall MSE: 0.0040 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0069 Validation Top 20 DE MSE: 0.0101. 
Epoch 2 Step 1 Train Loss: 0.7053
Epoch 2: Train Overall MSE: 0.0042 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0073 Validation Top 20 DE MSE: 0.0103. 
Epoch 3 Step 1 Train Loss: 0.7575
Epoch 3: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0097. 
Epoch 4 Step 1 Train Loss: 0.6399
Epoch 4: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0078. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0099. 
Epoch 5 Step 1 Train Loss: 0.7045
Epoch 5: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0099. 
Epoch 6 Step 1 Train Loss: 0.7539
Epoch 6: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0075. 
Train Top 20 DE MSE: 0.0138 Validation Top 20 DE MSE: 0.0100. 
Epoch 7 Step 1 Train Loss: 0.6855
Epoch 7: Train Overall MSE: 0.0094 Validation Overall MSE: 0.0076. 
Train Top 20 DE MSE: 0.0144 Validation Top 20 DE MSE: 0.0101. 
Epoch 8 Step 1 Train Loss: 0.7393
Epoch 8: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0078. 
Train Top 20 DE MSE: 0.0149 Validation Top 20 DE MSE: 0.0102. 
Epoch 9 Step 1 Train Loss: 0.8045
Epoch 9: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.0150 Validation Top 20 DE MSE: 0.0102. 
Epoch 10 Step 1 Train Loss: 0.6398
Epoch 10: Train Overall MSE: 0.0093 Validation Overall MSE: 0.0076. 
Train Top 20 DE MSE: 0.0143 Validation Top 20 DE MSE: 0.0101. 
Epoch 11 Step 1 Train Loss: 0.6672
Epoch 11: Train Overall MSE: 0.0089 Validation Overall MSE: 0.0077. 
Train Top 20 DE MSE: 0.0139 Validation Top 20 DE MSE: 0.0101. 
Epoch 12 Step 1 Train Loss: 0.6691
Epoch 12: Train Overall MSE: 0.0092 Validation Overall MSE: 0.0077. 
Train Top 20 DE MSE: 0.0143 Validation Top 20 DE MSE: 0.0102. 
Epoch 13 Step 1 Train Loss: 0.7387
Epoch 13: Train Overall MSE: 0.0095 Validation Overall MSE: 0.0078. 
Train Top 20 DE MSE: 0.0147 Validation Top 20 DE MSE: 0.0102. 
Epoch 14 Step 1 Train Loss: 0.7088
Epoch 14: Train Overall MSE: 0.0094 Validation Overall MSE: 0.0078. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0101. 
Epoch 15 Step 1 Train Loss: 0.6522
Epoch 15: Train Overall MSE: 0.0094 Validation Overall MSE: 0.0078. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0102. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0105
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0072023696
test_unseen_single_pearson: 0.95142064826268
test_unseen_single_mse_de: 0.01049257
test_unseen_single_pearson_de: 0.4573755073080519
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.061014319606124696
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.42500000000000004
test_unseen_single_frac_sigma_below_1_non_dropout: 0.51875
test_unseen_single_mse_top20_de_non_dropout: 0.018914485
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.014 MB uploadedwandb: | 0.002 MB of 0.017 MB uploadedwandb: / 0.002 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–‡â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–ƒâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:                                                train_pearson â–ˆâ–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–‚â–â–â–
wandb:                                                training_loss â–†â–ˆâ–ƒâ–…â–„â–‚â–ƒâ–â–‚â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–†â–…â–…â–„â–ƒâ–ƒâ–…â–„â–„â–â–
wandb:                                                   val_de_mse â–†â–ˆâ–â–„â–ƒâ–„â–…â–‡â–‡â–…â–†â–†â–‡â–†â–‡
wandb:                                               val_de_pearson â–ˆâ–†â–ƒâ–â–â–‚â–‚â–â–â–â–‚â–‚â–â–â–
wandb:                                                      val_mse â–â–‚â–„â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                                                  val_pearson â–ˆâ–‡â–…â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01049
wandb:                                              test_de_pearson 0.45738
wandb:               test_frac_opposite_direction_top20_non_dropout 0.425
wandb:                          test_frac_sigma_below_1_non_dropout 0.51875
wandb:                                                     test_mse 0.0072
wandb:                                test_mse_top20_de_non_dropout 0.01891
wandb:                                                 test_pearson 0.95142
wandb:                                           test_pearson_delta 0.06101
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.425
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.51875
wandb:                                       test_unseen_single_mse 0.0072
wandb:                                    test_unseen_single_mse_de 0.01049
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01891
wandb:                                   test_unseen_single_pearson 0.95142
wandb:                                test_unseen_single_pearson_de 0.45738
wandb:                             test_unseen_single_pearson_delta 0.06101
wandb:                                                 train_de_mse 0.01448
wandb:                                             train_de_pearson 0.13096
wandb:                                                    train_mse 0.00939
wandb:                                                train_pearson 0.94187
wandb:                                                training_loss 0.67541
wandb:                                                   val_de_mse 0.01022
wandb:                                               val_de_pearson 0.46002
wandb:                                                      val_mse 0.00778
wandb:                                                  val_pearson 0.94585
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_unstimulated_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8raift55
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_013800-8raift55/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2017_unstimulated/splits/datlingerbock2017_unstimulated_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_013958-0hp7pza8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2017_unstimulated_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0hp7pza8
Start Training...
Epoch 1 Step 1 Train Loss: 1.3321
Epoch 1: Train Overall MSE: 0.0070 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0059. 
Epoch 2 Step 1 Train Loss: 0.7506
Epoch 2: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0039. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0051. 
Epoch 3 Step 1 Train Loss: 0.7519
Epoch 3: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0066. 
Epoch 4 Step 1 Train Loss: 0.7338
Epoch 4: Train Overall MSE: 0.0089 Validation Overall MSE: 0.0078. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0084. 
Epoch 5 Step 1 Train Loss: 0.7343
Epoch 5: Train Overall MSE: 0.0093 Validation Overall MSE: 0.0084. 
Train Top 20 DE MSE: 0.0133 Validation Top 20 DE MSE: 0.0090. 
Epoch 6 Step 1 Train Loss: 0.7570
Epoch 6: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.0137 Validation Top 20 DE MSE: 0.0095. 
Epoch 7 Step 1 Train Loss: 0.6649
Epoch 7: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0136 Validation Top 20 DE MSE: 0.0092. 
Epoch 8 Step 1 Train Loss: 0.6555
Epoch 8: Train Overall MSE: 0.0101 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0094. 
Epoch 9 Step 1 Train Loss: 0.7400
Epoch 9: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0085. 
Train Top 20 DE MSE: 0.0137 Validation Top 20 DE MSE: 0.0095. 
Epoch 10 Step 1 Train Loss: 0.7358
Epoch 10: Train Overall MSE: 0.0101 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0138 Validation Top 20 DE MSE: 0.0095. 
Epoch 11 Step 1 Train Loss: 0.7476
Epoch 11: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0140 Validation Top 20 DE MSE: 0.0094. 
Epoch 12 Step 1 Train Loss: 0.6215
Epoch 12: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0083. 
Train Top 20 DE MSE: 0.0138 Validation Top 20 DE MSE: 0.0093. 
Epoch 13 Step 1 Train Loss: 0.7603
Epoch 13: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.0140 Validation Top 20 DE MSE: 0.0097. 
Epoch 14 Step 1 Train Loss: 0.7660
Epoch 14: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0095. 
Epoch 15 Step 1 Train Loss: 0.7247
Epoch 15: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.0140 Validation Top 20 DE MSE: 0.0095. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0103
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.005394794
test_unseen_single_pearson: 0.9625021466349588
test_unseen_single_mse_de: 0.010328438
test_unseen_single_pearson_de: 0.46802990581673654
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.034992896238525306
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.53125
test_unseen_single_frac_sigma_below_1_non_dropout: 0.46875
test_unseen_single_mse_top20_de_non_dropout: 0.014217151
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.014 MB uploadedwandb: | 0.003 MB of 0.017 MB uploadedwandb: / 0.003 MB of 0.017 MB uploadedwandb: - 0.017 MB of 0.017 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–…â–â–‚â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                             train_de_pearson â–‡â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–„â–â–‚â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                train_pearson â–…â–ˆâ–‡â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–
wandb:                                                training_loss â–ˆâ–„â–…â–„â–‚â–„â–„â–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–ƒâ–„
wandb:                                                   val_de_mse â–‚â–â–ƒâ–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                                               val_de_pearson â–‚â–ˆâ–‡â–„â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:                                                      val_mse â–„â–â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                                                  val_pearson â–„â–ˆâ–…â–‚â–‚â–â–â–â–‚â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01033
wandb:                                              test_de_pearson 0.46803
wandb:               test_frac_opposite_direction_top20_non_dropout 0.53125
wandb:                          test_frac_sigma_below_1_non_dropout 0.46875
wandb:                                                     test_mse 0.00539
wandb:                                test_mse_top20_de_non_dropout 0.01422
wandb:                                                 test_pearson 0.9625
wandb:                                           test_pearson_delta -0.03499
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.53125
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.46875
wandb:                                       test_unseen_single_mse 0.00539
wandb:                                    test_unseen_single_mse_de 0.01033
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01422
wandb:                                   test_unseen_single_pearson 0.9625
wandb:                                test_unseen_single_pearson_de 0.46803
wandb:                             test_unseen_single_pearson_delta -0.03499
wandb:                                                 train_de_mse 0.014
wandb:                                             train_de_pearson 0.19091
wandb:                                                    train_mse 0.01033
wandb:                                                train_pearson 0.93469
wandb:                                                training_loss 0.73303
wandb:                                                   val_de_mse 0.00954
wandb:                                               val_de_pearson 0.27466
wandb:                                                      val_mse 0.00884
wandb:                                                  val_pearson 0.94415
wandb: 
wandb: ðŸš€ View run DatlingerBock2017_unstimulated_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0hp7pza8
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_013958-0hp7pza8/logs
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/21 [00:00<?, ?it/s]  5%|â–         | 1/21 [00:05<01:48,  5.42s/it] 10%|â–‰         | 2/21 [00:13<02:11,  6.92s/it] 14%|â–ˆâ–        | 3/21 [00:20<02:05,  6.98s/it] 19%|â–ˆâ–‰        | 4/21 [00:25<01:48,  6.36s/it] 24%|â–ˆâ–ˆâ–       | 5/21 [00:32<01:43,  6.44s/it] 29%|â–ˆâ–ˆâ–Š       | 6/21 [00:38<01:36,  6.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7/21 [00:44<01:25,  6.10s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 8/21 [00:51<01:23,  6.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 9/21 [00:57<01:17,  6.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 10/21 [01:02<01:03,  5.79s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 11/21 [01:05<00:51,  5.17s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 12/21 [01:12<00:50,  5.66s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 13/21 [01:20<00:50,  6.27s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 14/21 [01:25<00:41,  5.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 15/21 [01:30<00:33,  5.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 16/21 [01:33<00:24,  4.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 17/21 [01:40<00:22,  5.54s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 18/21 [01:45<00:16,  5.46s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 19/21 [01:49<00:09,  4.99s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 20/21 [01:52<00:04,  4.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:52<00:00,  3.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:52<00:00,  5.35s/it]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_stimulated/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_stimulated/splits/datlingerbock2021_stimulated_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_014425-mwtcgkwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_stimulated_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/mwtcgkwk
  0%|          | 0/4113 [00:00<?, ?it/s]  0%|          | 4/4113 [00:00<02:00, 34.18it/s]  0%|          | 9/4113 [00:00<01:35, 42.79it/s]  0%|          | 16/4113 [00:00<01:20, 50.59it/s]  1%|          | 22/4113 [00:00<01:19, 51.29it/s]  1%|          | 28/4113 [00:00<01:16, 53.49it/s]  1%|          | 35/4113 [00:00<01:12, 56.23it/s]  1%|          | 42/4113 [00:00<01:09, 58.74it/s]  1%|          | 49/4113 [00:00<01:07, 60.53it/s]  1%|â–         | 56/4113 [00:01<01:07, 60.41it/s]  2%|â–         | 63/4113 [00:01<01:07, 60.02it/s]  2%|â–         | 70/4113 [00:01<01:07, 59.63it/s]  2%|â–         | 76/4113 [00:01<01:08, 58.59it/s]  2%|â–         | 82/4113 [00:01<01:08, 58.44it/s]  2%|â–         | 89/4113 [00:01<01:07, 59.42it/s]  2%|â–         | 96/4113 [00:01<01:06, 60.46it/s]  3%|â–Ž         | 103/4113 [00:01<01:06, 60.42it/s]  3%|â–Ž         | 110/4113 [00:01<01:07, 58.89it/s]  3%|â–Ž         | 117/4113 [00:02<01:07, 59.36it/s]  3%|â–Ž         | 123/4113 [00:02<01:07, 58.73it/s]  3%|â–Ž         | 130/4113 [00:02<01:07, 59.19it/s]  3%|â–Ž         | 136/4113 [00:02<01:07, 59.26it/s]  3%|â–Ž         | 143/4113 [00:02<01:06, 59.62it/s]  4%|â–Ž         | 150/4113 [00:02<01:05, 60.27it/s]  4%|â–         | 157/4113 [00:02<01:07, 58.20it/s]  4%|â–         | 163/4113 [00:03<02:03, 31.87it/s]  4%|â–         | 176/4113 [00:03<02:01, 32.43it/s]  4%|â–         | 181/4113 [00:03<02:32, 25.76it/s]  4%|â–         | 185/4113 [00:04<03:15, 20.12it/s]  5%|â–         | 189/4113 [00:04<02:55, 22.41it/s]  5%|â–Œ         | 220/4113 [00:04<01:01, 63.74it/s]  6%|â–Œ         | 232/4113 [00:04<00:59, 64.71it/s]  6%|â–Œ         | 242/4113 [00:04<01:02, 62.24it/s]  6%|â–Œ         | 251/4113 [00:04<01:00, 63.88it/s]  6%|â–‹         | 260/4113 [00:05<01:00, 63.74it/s]  7%|â–‹         | 268/4113 [00:05<01:00, 63.55it/s]  7%|â–‹         | 276/4113 [00:05<01:00, 63.30it/s]  7%|â–‹         | 283/4113 [00:05<01:00, 63.20it/s]  7%|â–‹         | 290/4113 [00:05<01:00, 63.15it/s]  7%|â–‹         | 297/4113 [00:05<01:01, 61.57it/s]  7%|â–‹         | 304/4113 [00:05<01:02, 60.69it/s]  8%|â–Š         | 311/4113 [00:05<01:03, 60.27it/s]  8%|â–Š         | 320/4113 [00:06<00:55, 67.84it/s]  8%|â–Š         | 329/4113 [00:06<00:54, 70.04it/s]  8%|â–Š         | 339/4113 [00:06<00:51, 72.71it/s]  8%|â–Š         | 349/4113 [00:06<00:49, 76.66it/s]  9%|â–Š         | 357/4113 [00:06<00:51, 72.55it/s]  9%|â–‰         | 365/4113 [00:06<00:56, 66.06it/s]  9%|â–‰         | 374/4113 [00:06<00:52, 71.65it/s]  9%|â–‰         | 382/4113 [00:06<00:55, 67.84it/s] 10%|â–‰         | 391/4113 [00:07<00:52, 70.51it/s] 10%|â–‰         | 401/4113 [00:07<00:47, 78.11it/s] 10%|â–‰         | 410/4113 [00:07<00:49, 74.54it/s] 10%|â–ˆ         | 419/4113 [00:07<00:47, 77.42it/s] 10%|â–ˆ         | 427/4113 [00:07<00:47, 78.10it/s] 11%|â–ˆ         | 435/4113 [00:07<00:47, 77.82it/s] 11%|â–ˆ         | 443/4113 [00:07<00:49, 74.84it/s] 11%|â–ˆ         | 452/4113 [00:07<00:47, 77.03it/s] 11%|â–ˆ         | 460/4113 [00:07<00:48, 75.96it/s] 11%|â–ˆâ–        | 469/4113 [00:08<00:47, 76.95it/s] 12%|â–ˆâ–        | 477/4113 [00:08<00:47, 76.64it/s] 12%|â–ˆâ–        | 485/4113 [00:08<00:47, 77.02it/s] 12%|â–ˆâ–        | 494/4113 [00:08<00:45, 80.27it/s] 12%|â–ˆâ–        | 503/4113 [00:08<00:45, 79.20it/s] 12%|â–ˆâ–        | 511/4113 [00:08<00:46, 76.71it/s] 13%|â–ˆâ–Ž        | 520/4113 [00:08<00:44, 79.97it/s] 13%|â–ˆâ–Ž        | 529/4113 [00:08<00:47, 75.85it/s] 13%|â–ˆâ–Ž        | 537/4113 [00:08<00:53, 66.36it/s] 13%|â–ˆâ–Ž        | 544/4113 [00:09<00:54, 66.08it/s] 13%|â–ˆâ–Ž        | 551/4113 [00:09<00:55, 64.52it/s] 14%|â–ˆâ–Ž        | 558/4113 [00:09<00:58, 61.13it/s] 14%|â–ˆâ–Ž        | 565/4113 [00:09<00:56, 63.35it/s] 14%|â–ˆâ–        | 572/4113 [00:09<00:58, 60.06it/s] 14%|â–ˆâ–        | 579/4113 [00:09<00:56, 62.47it/s] 14%|â–ˆâ–        | 586/4113 [00:09<00:55, 63.54it/s] 14%|â–ˆâ–        | 593/4113 [00:09<00:56, 62.72it/s] 15%|â–ˆâ–        | 600/4113 [00:09<00:56, 61.80it/s] 15%|â–ˆâ–        | 607/4113 [00:10<00:55, 62.82it/s] 15%|â–ˆâ–        | 616/4113 [00:10<00:52, 66.98it/s] 15%|â–ˆâ–Œ        | 624/4113 [00:10<00:50, 69.76it/s] 15%|â–ˆâ–Œ        | 633/4113 [00:10<00:46, 74.37it/s] 16%|â–ˆâ–Œ        | 641/4113 [00:10<00:46, 75.00it/s] 16%|â–ˆâ–Œ        | 649/4113 [00:10<00:47, 72.91it/s] 16%|â–ˆâ–Œ        | 657/4113 [00:10<00:49, 70.15it/s] 16%|â–ˆâ–Œ        | 666/4113 [00:10<00:46, 74.75it/s] 16%|â–ˆâ–‹        | 674/4113 [00:10<00:46, 74.47it/s] 17%|â–ˆâ–‹        | 682/4113 [00:11<00:46, 74.47it/s] 17%|â–ˆâ–‹        | 690/4113 [00:11<00:46, 73.62it/s] 17%|â–ˆâ–‹        | 698/4113 [00:11<00:47, 72.44it/s] 17%|â–ˆâ–‹        | 706/4113 [00:11<00:47, 72.36it/s] 17%|â–ˆâ–‹        | 714/4113 [00:11<00:48, 69.74it/s] 18%|â–ˆâ–Š        | 722/4113 [00:11<00:47, 71.31it/s] 18%|â–ˆâ–Š        | 730/4113 [00:11<00:47, 71.67it/s] 18%|â–ˆâ–Š        | 739/4113 [00:11<00:46, 72.18it/s] 18%|â–ˆâ–Š        | 747/4113 [00:11<00:48, 69.79it/s] 18%|â–ˆâ–Š        | 757/4113 [00:12<00:46, 71.93it/s] 19%|â–ˆâ–Š        | 765/4113 [00:12<00:48, 68.78it/s] 19%|â–ˆâ–‰        | 773/4113 [00:12<00:49, 67.56it/s] 19%|â–ˆâ–‰        | 782/4113 [00:12<00:48, 68.92it/s] 19%|â–ˆâ–‰        | 792/4113 [00:12<00:45, 72.77it/s] 19%|â–ˆâ–‰        | 801/4113 [00:12<00:43, 75.97it/s] 20%|â–ˆâ–‰        | 809/4113 [00:12<00:43, 75.81it/s] 20%|â–ˆâ–‰        | 817/4113 [00:12<00:45, 73.07it/s] 20%|â–ˆâ–ˆ        | 825/4113 [00:13<00:44, 73.70it/s] 20%|â–ˆâ–ˆ        | 834/4113 [00:13<00:42, 76.51it/s] 20%|â–ˆâ–ˆ        | 842/4113 [00:13<00:44, 73.52it/s] 21%|â–ˆâ–ˆ        | 851/4113 [00:13<00:42, 76.40it/s] 21%|â–ˆâ–ˆ        | 859/4113 [00:13<00:42, 76.27it/s] 21%|â–ˆâ–ˆ        | 867/4113 [00:13<00:44, 72.91it/s] 21%|â–ˆâ–ˆâ–       | 876/4113 [00:13<00:44, 73.30it/s] 22%|â–ˆâ–ˆâ–       | 885/4113 [00:13<00:43, 74.44it/s] 22%|â–ˆâ–ˆâ–       | 893/4113 [00:13<00:43, 74.66it/s] 22%|â–ˆâ–ˆâ–       | 902/4113 [00:14<00:42, 74.82it/s] 22%|â–ˆâ–ˆâ–       | 910/4113 [00:14<00:42, 75.51it/s] 22%|â–ˆâ–ˆâ–       | 918/4113 [00:14<00:42, 75.75it/s] 23%|â–ˆâ–ˆâ–Ž       | 927/4113 [00:14<00:40, 78.44it/s] 23%|â–ˆâ–ˆâ–Ž       | 935/4113 [00:14<00:41, 75.74it/s] 23%|â–ˆâ–ˆâ–Ž       | 943/4113 [00:14<00:41, 75.92it/s] 23%|â–ˆâ–ˆâ–Ž       | 951/4113 [00:14<00:41, 76.15it/s] 23%|â–ˆâ–ˆâ–Ž       | 960/4113 [00:14<00:39, 79.07it/s] 24%|â–ˆâ–ˆâ–Ž       | 968/4113 [00:14<00:41, 74.90it/s] 24%|â–ˆâ–ˆâ–Ž       | 976/4113 [00:15<00:42, 74.37it/s] 24%|â–ˆâ–ˆâ–       | 984/4113 [00:15<00:43, 72.27it/s] 24%|â–ˆâ–ˆâ–       | 992/4113 [00:15<00:43, 72.22it/s] 24%|â–ˆâ–ˆâ–       | 1001/4113 [00:15<00:42, 72.74it/s] 25%|â–ˆâ–ˆâ–       | 1010/4113 [00:15<00:40, 76.42it/s] 25%|â–ˆâ–ˆâ–       | 1018/4113 [00:15<00:42, 73.69it/s] 25%|â–ˆâ–ˆâ–       | 1026/4113 [00:15<00:41, 74.21it/s] 25%|â–ˆâ–ˆâ–Œ       | 1034/4113 [00:15<00:42, 72.74it/s] 25%|â–ˆâ–ˆâ–Œ       | 1042/4113 [00:16<00:45, 67.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 1051/4113 [00:16<00:42, 71.39it/s] 26%|â–ˆâ–ˆâ–Œ       | 1059/4113 [00:16<00:42, 72.69it/s] 26%|â–ˆâ–ˆâ–Œ       | 1067/4113 [00:16<00:42, 72.30it/s] 26%|â–ˆâ–ˆâ–Œ       | 1075/4113 [00:16<00:44, 69.00it/s] 26%|â–ˆâ–ˆâ–‹       | 1084/4113 [00:16<00:41, 72.63it/s] 27%|â–ˆâ–ˆâ–‹       | 1092/4113 [00:16<00:43, 68.70it/s] 27%|â–ˆâ–ˆâ–‹       | 1100/4113 [00:16<00:43, 69.64it/s] 27%|â–ˆâ–ˆâ–‹       | 1108/4113 [00:16<00:42, 70.99it/s] 27%|â–ˆâ–ˆâ–‹       | 1116/4113 [00:17<00:41, 73.03it/s] 27%|â–ˆâ–ˆâ–‹       | 1124/4113 [00:17<00:40, 73.24it/s] 28%|â–ˆâ–ˆâ–Š       | 1132/4113 [00:17<00:42, 70.38it/s] 28%|â–ˆâ–ˆâ–Š       | 1140/4113 [00:17<00:42, 70.65it/s] 28%|â–ˆâ–ˆâ–Š       | 1149/4113 [00:17<00:41, 72.12it/s] 28%|â–ˆâ–ˆâ–Š       | 1157/4113 [00:17<00:40, 72.23it/s] 28%|â–ˆâ–ˆâ–Š       | 1165/4113 [00:17<00:40, 72.20it/s] 29%|â–ˆâ–ˆâ–Š       | 1173/4113 [00:17<00:40, 72.79it/s] 29%|â–ˆâ–ˆâ–Š       | 1181/4113 [00:17<00:40, 73.17it/s] 29%|â–ˆâ–ˆâ–‰       | 1190/4113 [00:18<00:38, 76.39it/s] 29%|â–ˆâ–ˆâ–‰       | 1198/4113 [00:18<00:38, 75.50it/s] 29%|â–ˆâ–ˆâ–‰       | 1206/4113 [00:18<00:40, 72.04it/s] 30%|â–ˆâ–ˆâ–‰       | 1215/4113 [00:18<00:39, 72.95it/s] 30%|â–ˆâ–ˆâ–‰       | 1224/4113 [00:18<00:37, 76.34it/s] 30%|â–ˆâ–ˆâ–‰       | 1232/4113 [00:18<00:37, 76.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1240/4113 [00:18<00:39, 73.26it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1249/4113 [00:18<00:37, 76.61it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1257/4113 [00:18<00:37, 76.64it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1265/4113 [00:19<00:38, 74.01it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1274/4113 [00:19<00:36, 77.13it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1282/4113 [00:19<00:36, 76.84it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 1290/4113 [00:19<00:36, 76.76it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1298/4113 [00:19<00:36, 76.42it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1306/4113 [00:19<00:36, 76.39it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1314/4113 [00:19<00:38, 72.64it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1322/4113 [00:19<00:37, 74.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1330/4113 [00:19<00:39, 71.16it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1339/4113 [00:20<00:36, 75.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1347/4113 [00:20<00:36, 75.52it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1355/4113 [00:20<00:36, 76.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1363/4113 [00:20<00:37, 74.24it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1371/4113 [00:20<00:37, 73.26it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1379/4113 [00:20<00:37, 73.07it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1387/4113 [00:20<00:37, 72.90it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1395/4113 [00:20<00:38, 70.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1404/4113 [00:20<00:37, 71.79it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1412/4113 [00:21<00:37, 72.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1420/4113 [00:21<00:37, 72.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1428/4113 [00:21<00:36, 72.73it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1437/4113 [00:21<00:35, 75.45it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1445/4113 [00:21<00:35, 74.67it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1453/4113 [00:21<00:37, 71.12it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1462/4113 [00:21<00:36, 71.79it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1470/4113 [00:21<00:36, 72.03it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1478/4113 [00:21<00:36, 71.82it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1487/4113 [00:22<00:36, 72.66it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1495/4113 [00:22<00:36, 72.35it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1504/4113 [00:22<00:34, 74.92it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1512/4113 [00:22<00:34, 75.05it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1520/4113 [00:22<00:35, 74.08it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1528/4113 [00:22<00:35, 73.33it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1536/4113 [00:22<00:35, 73.54it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1544/4113 [00:22<00:36, 69.77it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1552/4113 [00:22<00:36, 70.94it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1561/4113 [00:23<00:33, 75.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1569/4113 [00:23<00:35, 72.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1577/4113 [00:23<00:34, 72.90it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1585/4113 [00:23<00:33, 74.78it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1593/4113 [00:23<00:33, 75.66it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1602/4113 [00:23<00:32, 78.05it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1610/4113 [00:23<00:33, 75.36it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1618/4113 [00:23<00:33, 73.67it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1626/4113 [00:23<00:33, 75.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1634/4113 [00:24<00:34, 71.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1642/4113 [00:24<00:34, 71.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1650/4113 [00:24<00:35, 68.87it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1657/4113 [00:24<00:38, 63.74it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1664/4113 [00:24<00:39, 62.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1671/4113 [00:24<00:39, 61.32it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1678/4113 [00:24<00:39, 62.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1685/4113 [00:24<00:40, 60.29it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1692/4113 [00:25<00:40, 60.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1699/4113 [00:25<00:38, 62.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1706/4113 [00:25<00:39, 61.66it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1713/4113 [00:25<00:39, 60.23it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1720/4113 [00:25<00:40, 58.56it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1729/4113 [00:25<00:36, 64.98it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1737/4113 [00:25<00:36, 64.66it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1746/4113 [00:25<00:33, 69.90it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1754/4113 [00:25<00:33, 71.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1762/4113 [00:26<00:32, 72.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1770/4113 [00:26<00:32, 72.69it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1778/4113 [00:26<00:32, 72.90it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1786/4113 [00:26<00:31, 73.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1795/4113 [00:26<00:31, 73.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1803/4113 [00:26<00:32, 70.42it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1813/4113 [00:26<00:31, 73.94it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1821/4113 [00:26<00:30, 73.95it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1830/4113 [00:26<00:30, 75.94it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1838/4113 [00:27<00:31, 72.46it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1846/4113 [00:27<00:31, 72.68it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1855/4113 [00:27<00:30, 73.36it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1864/4113 [00:27<00:30, 73.44it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1872/4113 [00:27<00:30, 73.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1880/4113 [00:27<00:30, 73.81it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1888/4113 [00:27<00:29, 74.41it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1896/4113 [00:27<00:29, 74.61it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1905/4113 [00:27<00:28, 77.67it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1913/4113 [00:28<00:29, 74.56it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1921/4113 [00:28<00:29, 74.82it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1929/4113 [00:28<00:29, 75.30it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1938/4113 [00:28<00:27, 79.45it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1946/4113 [00:28<00:28, 76.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1954/4113 [00:28<00:28, 76.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1963/4113 [00:28<00:27, 79.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1971/4113 [00:28<00:27, 78.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1979/4113 [00:28<00:28, 74.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1988/4113 [00:29<00:27, 77.18it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1996/4113 [00:29<00:27, 77.57it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2004/4113 [00:29<00:28, 73.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2013/4113 [00:29<00:27, 77.41it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2021/4113 [00:29<00:27, 75.31it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2029/4113 [00:29<00:27, 75.18it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2038/4113 [00:29<00:26, 78.46it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2046/4113 [00:29<00:27, 74.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2054/4113 [00:29<00:29, 69.62it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2063/4113 [00:30<00:28, 70.77it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2071/4113 [00:30<01:05, 31.25it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2078/4113 [00:30<00:56, 36.20it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2086/4113 [00:30<00:47, 42.83it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2095/4113 [00:31<00:39, 50.85it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2102/4113 [00:31<00:37, 53.54it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2111/4113 [00:31<00:33, 58.94it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2120/4113 [00:31<00:31, 63.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2128/4113 [00:31<00:30, 65.77it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2137/4113 [00:31<00:28, 68.91it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2146/4113 [00:31<00:28, 70.25it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2155/4113 [00:31<00:27, 71.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2163/4113 [00:31<00:27, 72.11it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2171/4113 [00:32<00:26, 72.60it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2180/4113 [00:32<00:26, 73.33it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2188/4113 [00:32<00:26, 73.30it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2196/4113 [00:32<00:26, 73.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2205/4113 [00:32<00:25, 75.95it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2213/4113 [00:32<00:26, 71.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2222/4113 [00:32<00:25, 74.90it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2230/4113 [00:32<00:24, 75.49it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2239/4113 [00:32<00:23, 78.93it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2247/4113 [00:33<00:24, 75.64it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2255/4113 [00:33<00:24, 75.86it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2263/4113 [00:33<00:24, 76.43it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2272/4113 [00:33<00:24, 76.67it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2280/4113 [00:33<00:23, 76.65it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2289/4113 [00:33<00:23, 76.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2297/4113 [00:33<00:24, 73.82it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2305/4113 [00:33<00:24, 72.66it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2313/4113 [00:33<00:24, 73.82it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2321/4113 [00:34<00:24, 74.38it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2329/4113 [00:34<00:23, 74.53it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2338/4113 [00:34<00:22, 77.30it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2346/4113 [00:34<00:23, 73.64it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2355/4113 [00:34<00:22, 76.80it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2363/4113 [00:34<00:23, 73.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2372/4113 [00:34<00:23, 73.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2380/4113 [00:34<00:23, 73.71it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2388/4113 [00:34<00:23, 74.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2396/4113 [00:35<00:24, 70.72it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2405/4113 [00:35<00:23, 73.47it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2413/4113 [00:35<00:22, 73.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2422/4113 [00:35<00:22, 73.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2431/4113 [00:35<00:22, 75.73it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2439/4113 [00:35<00:22, 74.69it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2447/4113 [00:35<00:23, 70.94it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2456/4113 [00:35<00:23, 71.44it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2464/4113 [00:35<00:22, 72.50it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2472/4113 [00:36<00:22, 74.48it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2480/4113 [00:36<00:22, 71.33it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2489/4113 [00:36<00:22, 72.83it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2497/4113 [00:36<00:22, 72.77it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2506/4113 [00:36<00:21, 75.59it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2514/4113 [00:36<00:22, 72.16it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2522/4113 [00:36<00:21, 72.41it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2531/4113 [00:36<00:20, 75.61it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2539/4113 [00:37<00:21, 73.20it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2547/4113 [00:37<00:21, 73.95it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2556/4113 [00:37<00:20, 77.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2564/4113 [00:37<00:20, 74.63it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2573/4113 [00:37<00:19, 77.84it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2581/4113 [00:37<00:19, 77.06it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2589/4113 [00:37<00:19, 76.63it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2597/4113 [00:37<00:19, 76.60it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2605/4113 [00:37<00:19, 76.21it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2613/4113 [00:37<00:20, 73.38it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2621/4113 [00:38<00:20, 74.18it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2630/4113 [00:38<00:19, 74.33it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2639/4113 [00:38<00:20, 72.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2647/4113 [00:38<00:20, 72.56it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2655/4113 [00:38<00:20, 72.76it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2663/4113 [00:38<00:19, 73.54it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2671/4113 [00:38<00:19, 73.45it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2680/4113 [00:38<00:19, 73.44it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2689/4113 [00:39<00:19, 74.12it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2698/4113 [00:39<00:18, 76.10it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2706/4113 [00:39<00:18, 75.55it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2714/4113 [00:39<00:18, 76.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2722/4113 [00:39<00:19, 72.64it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2731/4113 [00:39<00:18, 75.90it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2739/4113 [00:39<00:18, 75.89it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2747/4113 [00:39<00:18, 72.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2756/4113 [00:39<00:18, 72.69it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2765/4113 [00:40<00:17, 75.91it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2773/4113 [00:40<00:17, 74.97it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2781/4113 [00:40<00:17, 75.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2789/4113 [00:40<00:18, 72.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2797/4113 [00:40<00:18, 72.79it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2805/4113 [00:40<00:17, 73.25it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2813/4113 [00:40<00:17, 73.45it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2822/4113 [00:40<00:16, 76.50it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2830/4113 [00:40<00:17, 73.58it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2839/4113 [00:41<00:16, 76.83it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2847/4113 [00:41<00:16, 76.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2855/4113 [00:41<00:16, 75.81it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2863/4113 [00:41<00:16, 75.32it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2871/4113 [00:41<00:16, 75.98it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2879/4113 [00:41<00:16, 74.08it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2887/4113 [00:41<00:16, 75.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2896/4113 [00:41<00:16, 74.23it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2905/4113 [00:41<00:15, 75.81it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2913/4113 [00:42<00:16, 72.31it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2921/4113 [00:42<00:16, 71.98it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2929/4113 [00:42<00:16, 71.92it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2938/4113 [00:42<00:16, 72.58it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2947/4113 [00:42<00:15, 74.93it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2955/4113 [00:42<00:15, 74.32it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2963/4113 [00:42<00:16, 69.74it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2973/4113 [00:42<00:15, 75.45it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2981/4113 [00:42<00:15, 73.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2989/4113 [00:43<00:15, 70.79it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2998/4113 [00:43<00:15, 73.72it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3006/4113 [00:43<00:15, 71.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3015/4113 [00:43<00:14, 75.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3023/4113 [00:43<00:15, 72.44it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3031/4113 [00:43<00:15, 71.50it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3039/4113 [00:43<00:15, 71.52it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3047/4113 [00:43<00:15, 69.93it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3055/4113 [00:44<00:15, 68.21it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3064/4113 [00:44<00:14, 71.38it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3072/4113 [00:44<00:14, 70.94it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3080/4113 [00:44<00:14, 72.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3088/4113 [00:44<00:14, 72.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3096/4113 [00:44<00:14, 69.48it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3105/4113 [00:44<00:13, 73.10it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3113/4113 [00:44<00:14, 70.20it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3122/4113 [00:44<00:13, 73.38it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3130/4113 [00:45<00:13, 70.54it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3138/4113 [00:45<00:13, 71.52it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3147/4113 [00:45<00:13, 74.20it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3155/4113 [00:45<00:13, 72.57it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3163/4113 [00:45<00:12, 73.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3171/4113 [00:45<00:12, 73.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3179/4113 [00:45<00:12, 71.94it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3187/4113 [00:45<00:12, 72.88it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3195/4113 [00:45<00:12, 72.50it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3203/4113 [00:46<00:12, 71.24it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3211/4113 [00:46<00:12, 69.83it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3220/4113 [00:46<00:12, 73.25it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3228/4113 [00:46<00:12, 73.51it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3236/4113 [00:46<00:12, 71.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3245/4113 [00:46<00:11, 74.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3253/4113 [00:46<00:11, 74.74it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3261/4113 [00:46<00:11, 72.84it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3270/4113 [00:46<00:11, 76.08it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3278/4113 [00:47<00:11, 75.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3286/4113 [00:47<00:11, 72.52it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3295/4113 [00:47<00:10, 75.90it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3303/4113 [00:47<00:10, 75.28it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3311/4113 [00:47<00:11, 72.25it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3319/4113 [00:47<00:10, 72.45it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3327/4113 [00:47<00:11, 69.22it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3336/4113 [00:47<00:10, 71.44it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3345/4113 [00:47<00:10, 74.59it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3353/4113 [00:48<00:10, 70.15it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3362/4113 [00:48<00:10, 70.51it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3371/4113 [00:48<00:10, 73.17it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3379/4113 [00:48<00:10, 72.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3387/4113 [00:48<00:09, 72.69it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3395/4113 [00:48<00:09, 72.21it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3403/4113 [00:48<00:09, 71.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3411/4113 [00:48<00:10, 69.39it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3420/4113 [00:49<00:09, 70.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3428/4113 [00:49<00:09, 72.51it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3436/4113 [00:49<00:09, 72.48it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3444/4113 [00:49<00:09, 72.71it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3452/4113 [00:49<00:09, 69.44it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3460/4113 [00:49<00:09, 70.28it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3468/4113 [00:49<00:09, 70.84it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3477/4113 [00:49<00:08, 71.52it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3486/4113 [00:49<00:08, 74.37it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3494/4113 [00:50<00:08, 74.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3502/4113 [00:50<00:08, 73.62it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3510/4113 [00:50<00:08, 72.36it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3518/4113 [00:50<00:08, 70.21it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3526/4113 [00:50<00:08, 69.88it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3534/4113 [00:50<00:07, 72.58it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3542/4113 [00:50<00:08, 70.20it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3551/4113 [00:50<00:07, 73.02it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3559/4113 [00:50<00:07, 73.15it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3567/4113 [00:51<00:07, 73.45it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3575/4113 [00:51<00:07, 72.99it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3583/4113 [00:51<00:07, 73.03it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3591/4113 [00:51<00:07, 73.56it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3599/4113 [00:51<00:07, 73.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3607/4113 [00:51<00:06, 73.56it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3615/4113 [00:51<00:06, 73.75it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3623/4113 [00:51<00:06, 73.55it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3631/4113 [00:51<00:06, 73.89it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3639/4113 [00:52<00:06, 73.94it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3647/4113 [00:52<00:06, 73.51it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3655/4113 [00:52<00:06, 70.87it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3664/4113 [00:52<00:06, 71.86it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3672/4113 [00:52<00:05, 73.72it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3680/4113 [00:52<00:06, 68.28it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3689/4113 [00:52<00:05, 72.40it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3697/4113 [00:52<00:05, 70.83it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3705/4113 [00:52<00:05, 71.91it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3713/4113 [00:53<00:05, 71.47it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3721/4113 [00:53<00:05, 70.75it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3729/4113 [00:53<00:05, 70.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3738/4113 [00:53<00:05, 70.20it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3746/4113 [00:53<00:05, 69.84it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3754/4113 [00:53<00:04, 72.26it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3762/4113 [00:53<00:04, 73.69it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3770/4113 [00:53<00:04, 70.81it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3779/4113 [00:54<00:04, 71.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3787/4113 [00:54<00:04, 71.50it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3796/4113 [00:54<00:04, 72.80it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3805/4113 [00:54<00:04, 74.75it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3813/4113 [00:54<00:04, 71.51it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3821/4113 [00:54<00:04, 71.25it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3829/4113 [00:54<00:03, 72.28it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3837/4113 [00:54<00:03, 72.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3845/4113 [00:54<00:03, 70.66it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3853/4113 [00:55<00:03, 70.63it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3861/4113 [00:55<00:03, 71.48it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3869/4113 [00:55<00:03, 70.53it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3877/4113 [00:55<00:03, 71.68it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3885/4113 [00:55<00:03, 72.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3893/4113 [00:55<00:03, 70.65it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3901/4113 [00:55<00:03, 70.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3909/4113 [00:55<00:02, 71.90it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3917/4113 [00:55<00:02, 71.22it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3925/4113 [00:56<00:02, 73.59it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3933/4113 [00:56<00:02, 74.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3941/4113 [00:56<00:02, 73.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3949/4113 [00:56<00:02, 75.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3957/4113 [00:56<00:02, 71.39it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3965/4113 [00:56<00:02, 72.43it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3973/4113 [00:56<00:01, 71.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3981/4113 [00:56<00:01, 69.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3989/4113 [00:56<00:01, 72.10it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3997/4113 [00:57<00:01, 73.79it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4005/4113 [00:57<00:01, 71.76it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4014/4113 [00:57<00:01, 72.93it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4022/4113 [00:57<00:01, 73.53it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4030/4113 [00:57<00:01, 69.60it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4038/4113 [00:57<00:01, 69.29it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4045/4113 [00:57<00:01, 67.74it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4052/4113 [00:57<00:00, 64.32it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4059/4113 [00:57<00:00, 64.79it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4067/4113 [00:58<00:00, 66.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4075/4113 [00:58<00:00, 67.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4082/4113 [00:58<00:00, 63.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4090/4113 [00:58<00:00, 66.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4097/4113 [00:58<00:00, 65.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4106/4113 [00:58<00:00, 70.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4113/4113 [00:58<00:00, 70.01it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.6122
Epoch 1 Step 51 Train Loss: 0.4285
Epoch 1 Step 101 Train Loss: 0.4151
Epoch 1 Step 151 Train Loss: 0.4028
Epoch 1: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0175. 
Epoch 2 Step 1 Train Loss: 0.4152
Epoch 2 Step 51 Train Loss: 0.3996
Epoch 2 Step 101 Train Loss: 0.3861
Epoch 2 Step 151 Train Loss: 0.4040
Epoch 2: Train Overall MSE: 0.0047 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0131. 
Epoch 3 Step 1 Train Loss: 0.4114
Epoch 3 Step 51 Train Loss: 0.4144
Epoch 3 Step 101 Train Loss: 0.4131
Epoch 3 Step 151 Train Loss: 0.3981
Epoch 3: Train Overall MSE: 0.0047 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0112. 
Epoch 4 Step 1 Train Loss: 0.3817
Epoch 4 Step 51 Train Loss: 0.3838
Epoch 4 Step 101 Train Loss: 0.3889
Epoch 4 Step 151 Train Loss: 0.4078
Epoch 4: Train Overall MSE: 0.0053 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0118. 
Epoch 5 Step 1 Train Loss: 0.4048
Epoch 5 Step 51 Train Loss: 0.3836
Epoch 5 Step 101 Train Loss: 0.4024
Epoch 5 Step 151 Train Loss: 0.3894
Epoch 5: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0108. 
Epoch 6 Step 1 Train Loss: 0.3782
Epoch 6 Step 51 Train Loss: 0.3812
Epoch 6 Step 101 Train Loss: 0.3750
Epoch 6 Step 151 Train Loss: 0.3898
Epoch 6: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0100. 
Epoch 7 Step 1 Train Loss: 0.3727
Epoch 7 Step 51 Train Loss: 0.4079
Epoch 7 Step 101 Train Loss: 0.3976
Epoch 7 Step 151 Train Loss: 0.3900
Epoch 7: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0092. 
Epoch 8 Step 1 Train Loss: 0.3864
Epoch 8 Step 51 Train Loss: 0.3812
Epoch 8 Step 101 Train Loss: 0.3906
Epoch 8 Step 151 Train Loss: 0.3810
Epoch 8: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0100. 
Epoch 9 Step 1 Train Loss: 0.3889
Epoch 9 Step 51 Train Loss: 0.3972
Epoch 9 Step 101 Train Loss: 0.3954
Epoch 9 Step 151 Train Loss: 0.3960
Epoch 9: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0102. 
Epoch 10 Step 1 Train Loss: 0.3826
Epoch 10 Step 51 Train Loss: 0.3900
Epoch 10 Step 101 Train Loss: 0.3903
Epoch 10 Step 151 Train Loss: 0.3829
Epoch 10: Train Overall MSE: 0.0056 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0096. 
Epoch 11 Step 1 Train Loss: 0.3970
Epoch 11 Step 51 Train Loss: 0.3853
Epoch 11 Step 101 Train Loss: 0.3952
Epoch 11 Step 151 Train Loss: 0.3681
Epoch 11: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0098. 
Epoch 12 Step 1 Train Loss: 0.3882
Epoch 12 Step 51 Train Loss: 0.3945
Epoch 12 Step 101 Train Loss: 0.3739
Epoch 12 Step 151 Train Loss: 0.3766
Epoch 12: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0098. 
Epoch 13 Step 1 Train Loss: 0.3944
Epoch 13 Step 51 Train Loss: 0.4033
Epoch 13 Step 101 Train Loss: 0.3616
Epoch 13 Step 151 Train Loss: 0.3817
Epoch 13: Train Overall MSE: 0.0062 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0131 Validation Top 20 DE MSE: 0.0099. 
Epoch 14 Step 1 Train Loss: 0.3943
Epoch 14 Step 51 Train Loss: 0.3527
Epoch 14 Step 101 Train Loss: 0.3920
Epoch 14 Step 151 Train Loss: 0.4180
Epoch 14: Train Overall MSE: 0.0061 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0112. 
Epoch 15 Step 1 Train Loss: 0.3967
Epoch 15 Step 51 Train Loss: 0.3549
Epoch 15 Step 101 Train Loss: 0.4016
Epoch 15 Step 151 Train Loss: 0.3807
Epoch 15: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0089. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0113
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0016822027
test_unseen_single_pearson: 0.8299592736715802
test_unseen_single_mse_de: 0.011318721
test_unseen_single_pearson_de: 0.7781654781414538
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.05776300901902746
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.41999999999999993
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8600000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.011388333
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.001 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–‚â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:                                             train_de_pearson â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–…â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:                                                train_pearson â–ˆâ–„â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:                                                training_loss â–ˆâ–‡â–…â–†â–…â–ƒâ–…â–†â–ˆâ–…â–‡â–…â–„â–„â–„â–ƒâ–…â–„â–…â–„â–‚â–†â–„â–‚â–…â–„â–„â–ƒâ–…â–ƒâ–…â–‚â–„â–„â–„â–„â–„â–…â–…â–
wandb:                                                   val_de_mse â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–
wandb:                                               val_de_pearson â–â–„â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb:                                                      val_mse â–‡â–‚â–â–‡â–„â–…â–„â–…â–…â–ƒâ–ƒâ–ƒâ–…â–ˆâ–‚
wandb:                                                  val_pearson â–â–‡â–ˆâ–â–…â–„â–…â–„â–„â–†â–‡â–†â–„â–â–‡
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01132
wandb:                                              test_de_pearson 0.77817
wandb:               test_frac_opposite_direction_top20_non_dropout 0.42
wandb:                          test_frac_sigma_below_1_non_dropout 0.86
wandb:                                                     test_mse 0.00168
wandb:                                test_mse_top20_de_non_dropout 0.01139
wandb:                                                 test_pearson 0.82996
wandb:                                           test_pearson_delta 0.05776
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.42
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.86
wandb:                                       test_unseen_single_mse 0.00168
wandb:                                    test_unseen_single_mse_de 0.01132
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01139
wandb:                                   test_unseen_single_pearson 0.82996
wandb:                                test_unseen_single_pearson_de 0.77817
wandb:                             test_unseen_single_pearson_delta 0.05776
wandb:                                                 train_de_mse 0.01219
wandb:                                             train_de_pearson 0.45177
wandb:                                                    train_mse 0.00577
wandb:                                                train_pearson 0.6573
wandb:                                                training_loss 0.37999
wandb:                                                   val_de_mse 0.00894
wandb:                                               val_de_pearson 0.96506
wandb:                                                      val_mse 0.00163
wandb:                                                  val_pearson 0.83709
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_stimulated_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/mwtcgkwk
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_014425-mwtcgkwk/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_stimulated/splits/datlingerbock2021_stimulated_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_015400-3yx6e2pj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_stimulated_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/3yx6e2pj
Start Training...
Epoch 1 Step 1 Train Loss: 0.6571
Epoch 1 Step 51 Train Loss: 0.4024
Epoch 1 Step 101 Train Loss: 0.3956
Epoch 1 Step 151 Train Loss: 0.4280
Epoch 1: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0059 Validation Top 20 DE MSE: 0.0035. 
Epoch 2 Step 1 Train Loss: 0.3954
Epoch 2 Step 51 Train Loss: 0.4012
Epoch 2 Step 101 Train Loss: 0.3725
Epoch 2 Step 151 Train Loss: 0.3927
Epoch 2: Train Overall MSE: 0.0031 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0056 Validation Top 20 DE MSE: 0.0021. 
Epoch 3 Step 1 Train Loss: 0.3909
Epoch 3 Step 51 Train Loss: 0.3775
Epoch 3 Step 101 Train Loss: 0.3879
Epoch 3 Step 151 Train Loss: 0.3956
Epoch 3: Train Overall MSE: 0.0045 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0087 Validation Top 20 DE MSE: 0.0027. 
Epoch 4 Step 1 Train Loss: 0.3746
Epoch 4 Step 51 Train Loss: 0.3938
Epoch 4 Step 101 Train Loss: 0.3841
Epoch 4 Step 151 Train Loss: 0.3991
Epoch 4: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0021. 
Epoch 5 Step 1 Train Loss: 0.3770
Epoch 5 Step 51 Train Loss: 0.3778
Epoch 5 Step 101 Train Loss: 0.3912
Epoch 5 Step 151 Train Loss: 0.3875
Epoch 5: Train Overall MSE: 0.0049 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0022. 
Epoch 6 Step 1 Train Loss: 0.3658
Epoch 6 Step 51 Train Loss: 0.3738
Epoch 6 Step 101 Train Loss: 0.3747
Epoch 6 Step 151 Train Loss: 0.3705
Epoch 6: Train Overall MSE: 0.0052 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0026. 
Epoch 7 Step 1 Train Loss: 0.3863
Epoch 7 Step 51 Train Loss: 0.3788
Epoch 7 Step 101 Train Loss: 0.3681
Epoch 7 Step 151 Train Loss: 0.3768
Epoch 7: Train Overall MSE: 0.0046 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0020. 
Epoch 8 Step 1 Train Loss: 0.3854
Epoch 8 Step 51 Train Loss: 0.3765
Epoch 8 Step 101 Train Loss: 0.3638
Epoch 8 Step 151 Train Loss: 0.3899
Epoch 8: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0022. 
Epoch 9 Step 1 Train Loss: 0.3688
Epoch 9 Step 51 Train Loss: 0.3495
Epoch 9 Step 101 Train Loss: 0.3756
Epoch 9 Step 151 Train Loss: 0.3697
Epoch 9: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0021. 
Epoch 10 Step 1 Train Loss: 0.3936
Epoch 10 Step 51 Train Loss: 0.3878
Epoch 10 Step 101 Train Loss: 0.3744
Epoch 10 Step 151 Train Loss: 0.3588
Epoch 10: Train Overall MSE: 0.0049 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0022. 
Epoch 11 Step 1 Train Loss: 0.4005
Epoch 11 Step 51 Train Loss: 0.3812
Epoch 11 Step 101 Train Loss: 0.3902
Epoch 11 Step 151 Train Loss: 0.3880
Epoch 11: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0022. 
Epoch 12 Step 1 Train Loss: 0.3723
Epoch 12 Step 51 Train Loss: 0.3964
Epoch 12 Step 101 Train Loss: 0.3671
Epoch 12 Step 151 Train Loss: 0.3795
Epoch 12: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0023. 
Epoch 13 Step 1 Train Loss: 0.3822
Epoch 13 Step 51 Train Loss: 0.3717
Epoch 13 Step 101 Train Loss: 0.3824
Epoch 13 Step 151 Train Loss: 0.3685
Epoch 13: Train Overall MSE: 0.0049 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0022. 
Epoch 14 Step 1 Train Loss: 0.3527
Epoch 14 Step 51 Train Loss: 0.3822
Epoch 14 Step 101 Train Loss: 0.3827
Epoch 14 Step 151 Train Loss: 0.3861
Epoch 14: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0020. 
Epoch 15 Step 1 Train Loss: 0.3999
Epoch 15 Step 51 Train Loss: 0.3656
Epoch 15 Step 101 Train Loss: 0.3925
Epoch 15 Step 151 Train Loss: 0.3923
Epoch 15: Train Overall MSE: 0.0052 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0024. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0197
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0024339594
test_unseen_single_pearson: 0.7764865180129176
test_unseen_single_mse_de: 0.019724779
test_unseen_single_pearson_de: 0.7648304551964147
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.03353833654599852
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.48999999999999994
test_unseen_single_frac_sigma_below_1_non_dropout: 0.82
test_unseen_single_mse_top20_de_non_dropout: 0.019740343
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.001 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–â–„â–†â–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:                                             train_de_pearson â–ˆâ–ˆâ–‡â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–â–…â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:                                                train_pearson â–ˆâ–ˆâ–„â–â–‚â–â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚
wandb:                                                training_loss â–ˆâ–†â–…â–†â–„â–â–…â–‡â–‡â–ƒâ–ƒâ–†â–†â–‚â–ƒâ–„â–„â–…â–ƒâ–ƒâ–‚â–‚â–â–…â–„â–…â–„â–„â–…â–ƒâ–…â–‚â–ƒâ–„â–â–‚â–ƒâ–ƒâ–ƒâ–„
wandb:                                                   val_de_mse â–ˆâ–‚â–„â–‚â–‚â–„â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–ƒ
wandb:                                               val_de_pearson â–â–‚â–„â–…â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡
wandb:                                                      val_mse â–ˆâ–â–†â–‚â–ƒâ–„â–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–â–„
wandb:                                                  val_pearson â–â–ˆâ–‚â–‡â–†â–„â–ˆâ–†â–‡â–†â–…â–…â–…â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01972
wandb:                                              test_de_pearson 0.76483
wandb:               test_frac_opposite_direction_top20_non_dropout 0.49
wandb:                          test_frac_sigma_below_1_non_dropout 0.82
wandb:                                                     test_mse 0.00243
wandb:                                test_mse_top20_de_non_dropout 0.01974
wandb:                                                 test_pearson 0.77649
wandb:                                           test_pearson_delta 0.03354
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.49
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.82
wandb:                                       test_unseen_single_mse 0.00243
wandb:                                    test_unseen_single_mse_de 0.01972
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01974
wandb:                                   test_unseen_single_pearson 0.77649
wandb:                                test_unseen_single_pearson_de 0.76483
wandb:                             test_unseen_single_pearson_delta 0.03354
wandb:                                                 train_de_mse 0.01215
wandb:                                             train_de_pearson 0.57667
wandb:                                                    train_mse 0.00521
wandb:                                                train_pearson 0.67341
wandb:                                                training_loss 0.36136
wandb:                                                   val_de_mse 0.00236
wandb:                                               val_de_pearson 0.53931
wandb:                                                      val_mse 0.00191
wandb:                                                  val_pearson 0.7972
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_stimulated_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/3yx6e2pj
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_015400-3yx6e2pj/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_stimulated/splits/datlingerbock2021_stimulated_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_020144-rljqu0nk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_stimulated_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/rljqu0nk
Start Training...
Epoch 1 Step 1 Train Loss: 0.5380
Epoch 1 Step 51 Train Loss: 0.4133
Epoch 1 Step 101 Train Loss: 0.4272
Epoch 1 Step 151 Train Loss: 0.4023
Epoch 1: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0092. 
Epoch 2 Step 1 Train Loss: 0.4137
Epoch 2 Step 51 Train Loss: 0.3888
Epoch 2 Step 101 Train Loss: 0.4096
Epoch 2 Step 151 Train Loss: 0.4064
Epoch 2: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0042. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0065. 
Epoch 3 Step 1 Train Loss: 0.4131
Epoch 3 Step 51 Train Loss: 0.3933
Epoch 3 Step 101 Train Loss: 0.3979
Epoch 3 Step 151 Train Loss: 0.3887
Epoch 3: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0060. 
Epoch 4 Step 1 Train Loss: 0.4001
Epoch 4 Step 51 Train Loss: 0.3848
Epoch 4 Step 101 Train Loss: 0.3800
Epoch 4 Step 151 Train Loss: 0.4174
Epoch 4: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0047. 
Epoch 5 Step 1 Train Loss: 0.3882
Epoch 5 Step 51 Train Loss: 0.3762
Epoch 5 Step 101 Train Loss: 0.3902
Epoch 5 Step 151 Train Loss: 0.4103
Epoch 5: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0047. 
Epoch 6 Step 1 Train Loss: 0.3724
Epoch 6 Step 51 Train Loss: 0.3815
Epoch 6 Step 101 Train Loss: 0.3833
Epoch 6 Step 151 Train Loss: 0.3862
Epoch 6: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0047. 
Epoch 7 Step 1 Train Loss: 0.4326
Epoch 7 Step 51 Train Loss: 0.3801
Epoch 7 Step 101 Train Loss: 0.3677
Epoch 7 Step 151 Train Loss: 0.4062
Epoch 7: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0132 Validation Top 20 DE MSE: 0.0047. 
Epoch 8 Step 1 Train Loss: 0.3662
Epoch 8 Step 51 Train Loss: 0.3898
Epoch 8 Step 101 Train Loss: 0.3750
Epoch 8 Step 151 Train Loss: 0.3670
Epoch 8: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0049. 
Epoch 9 Step 1 Train Loss: 0.3972
Epoch 9 Step 51 Train Loss: 0.3965
Epoch 9 Step 101 Train Loss: 0.3652
Epoch 9 Step 151 Train Loss: 0.3697
Epoch 9: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0048. 
Epoch 10 Step 1 Train Loss: 0.3534
Epoch 10 Step 51 Train Loss: 0.3752
Epoch 10 Step 101 Train Loss: 0.3640
Epoch 10 Step 151 Train Loss: 0.3926
Epoch 10: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0047. 
Epoch 11 Step 1 Train Loss: 0.3948
Epoch 11 Step 51 Train Loss: 0.3794
Epoch 11 Step 101 Train Loss: 0.3842
Epoch 11 Step 151 Train Loss: 0.3794
Epoch 11: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0132 Validation Top 20 DE MSE: 0.0047. 
Epoch 12 Step 1 Train Loss: 0.3897
Epoch 12 Step 51 Train Loss: 0.3568
Epoch 12 Step 101 Train Loss: 0.3730
Epoch 12 Step 151 Train Loss: 0.3784
Epoch 12: Train Overall MSE: 0.0054 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0048. 
Epoch 13 Step 1 Train Loss: 0.3715
Epoch 13 Step 51 Train Loss: 0.3662
Epoch 13 Step 101 Train Loss: 0.3750
Epoch 13 Step 151 Train Loss: 0.3681
Epoch 13: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0048. 
Epoch 14 Step 1 Train Loss: 0.3822
Epoch 14 Step 51 Train Loss: 0.3760
Epoch 14 Step 101 Train Loss: 0.3864
Epoch 14 Step 151 Train Loss: 0.3755
Epoch 14: Train Overall MSE: 0.0056 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0049. 
Epoch 15 Step 1 Train Loss: 0.4029
Epoch 15 Step 51 Train Loss: 0.3911
Epoch 15 Step 101 Train Loss: 0.3931
Epoch 15 Step 151 Train Loss: 0.3895
Epoch 15: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0050. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0065
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0024320376
test_unseen_single_pearson: 0.7667167300830007
test_unseen_single_mse_de: 0.0065179514
test_unseen_single_pearson_de: 0.941120138336494
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.1939068686294657
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6900000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.0068555004
Done!
wandb: - 0.001 MB of 0.019 MB uploadedwandb: \ 0.004 MB of 0.019 MB uploadedwandb: | 0.004 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–ƒâ–…â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:                                             train_de_pearson â–ˆâ–ˆâ–„â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–
wandb:                                                    train_mse â–â–‡â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡
wandb:                                                train_pearson â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:                                                training_loss â–ˆâ–ƒâ–…â–…â–ƒâ–…â–ƒâ–…â–„â–ƒâ–ƒâ–„â–ƒâ–â–„â–‚â–ƒâ–ƒâ–„â–…â–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–…â–„â–„â–„â–ƒâ–„â–„â–„â–ƒâ–‚â–‚â–„â–…
wandb:                                                   val_de_mse â–ˆâ–„â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:                                               val_de_pearson â–…â–â–†â–„â–‚â–…â–†â–†â–‡â–ˆâ–†â–…â–ˆâ–‡â–…
wandb:                                                      val_mse â–…â–ˆâ–â–„â–…â–„â–…â–„â–…â–„â–„â–„â–…â–„â–„
wandb:                                                  val_pearson â–„â–â–ˆâ–„â–â–…â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–„
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00652
wandb:                                              test_de_pearson 0.94112
wandb:               test_frac_opposite_direction_top20_non_dropout 0.3
wandb:                          test_frac_sigma_below_1_non_dropout 0.69
wandb:                                                     test_mse 0.00243
wandb:                                test_mse_top20_de_non_dropout 0.00686
wandb:                                                 test_pearson 0.76672
wandb:                                           test_pearson_delta 0.19391
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.3
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.69
wandb:                                       test_unseen_single_mse 0.00243
wandb:                                    test_unseen_single_mse_de 0.00652
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00686
wandb:                                   test_unseen_single_pearson 0.76672
wandb:                                test_unseen_single_pearson_de 0.94112
wandb:                             test_unseen_single_pearson_delta 0.19391
wandb:                                                 train_de_mse 0.0127
wandb:                                             train_de_pearson 0.4775
wandb:                                                    train_mse 0.00549
wandb:                                                train_pearson 0.66121
wandb:                                                training_loss 0.36348
wandb:                                                   val_de_mse 0.00497
wandb:                                               val_de_pearson 0.61662
wandb:                                                      val_mse 0.00319
wandb:                                                  val_pearson 0.73568
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_stimulated_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/rljqu0nk
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_020144-rljqu0nk/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_stimulated/splits/datlingerbock2021_stimulated_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_020909-2r7qb29z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_stimulated_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/2r7qb29z
Start Training...
Epoch 1 Step 1 Train Loss: 0.6852
Epoch 1 Step 51 Train Loss: 0.4434
Epoch 1 Step 101 Train Loss: 0.4289
Epoch 1 Step 151 Train Loss: 0.3952
Epoch 1: Train Overall MSE: 0.0032 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0059 Validation Top 20 DE MSE: 0.0089. 
Epoch 2 Step 1 Train Loss: 0.4081
Epoch 2 Step 51 Train Loss: 0.3864
Epoch 2 Step 101 Train Loss: 0.4096
Epoch 2 Step 151 Train Loss: 0.3973
Epoch 2: Train Overall MSE: 0.0048 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0077 Validation Top 20 DE MSE: 0.0130. 
Epoch 3 Step 1 Train Loss: 0.3912
Epoch 3 Step 51 Train Loss: 0.4055
Epoch 3 Step 101 Train Loss: 0.3738
Epoch 3 Step 151 Train Loss: 0.3935
Epoch 3: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0111. 
Epoch 4 Step 1 Train Loss: 0.4087
Epoch 4 Step 51 Train Loss: 0.3841
Epoch 4 Step 101 Train Loss: 0.3929
Epoch 4 Step 151 Train Loss: 0.3823
Epoch 4: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0114. 
Epoch 5 Step 1 Train Loss: 0.3837
Epoch 5 Step 51 Train Loss: 0.3785
Epoch 5 Step 101 Train Loss: 0.3797
Epoch 5 Step 151 Train Loss: 0.4088
Epoch 5: Train Overall MSE: 0.0054 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0124. 
Epoch 6 Step 1 Train Loss: 0.4041
Epoch 6 Step 51 Train Loss: 0.3740
Epoch 6 Step 101 Train Loss: 0.3828
Epoch 6 Step 151 Train Loss: 0.3699
Epoch 6: Train Overall MSE: 0.0054 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0131. 
Epoch 7 Step 1 Train Loss: 0.3872
Epoch 7 Step 51 Train Loss: 0.3792
Epoch 7 Step 101 Train Loss: 0.3898
Epoch 7 Step 151 Train Loss: 0.3841
Epoch 7: Train Overall MSE: 0.0056 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0133. 
Epoch 8 Step 1 Train Loss: 0.4017
Epoch 8 Step 51 Train Loss: 0.3810
Epoch 8 Step 101 Train Loss: 0.4007
Epoch 8 Step 151 Train Loss: 0.3665
Epoch 8: Train Overall MSE: 0.0056 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0131. 
Epoch 9 Step 1 Train Loss: 0.3894
Epoch 9 Step 51 Train Loss: 0.3932
Epoch 9 Step 101 Train Loss: 0.3589
Epoch 9 Step 151 Train Loss: 0.3967
Epoch 9: Train Overall MSE: 0.0056 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0130. 
Epoch 10 Step 1 Train Loss: 0.3944
Epoch 10 Step 51 Train Loss: 0.3820
Epoch 10 Step 101 Train Loss: 0.3619
Epoch 10 Step 151 Train Loss: 0.3970
Epoch 10: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0133. 
Epoch 11 Step 1 Train Loss: 0.3892
Epoch 11 Step 51 Train Loss: 0.3925
Epoch 11 Step 101 Train Loss: 0.3703
Epoch 11 Step 151 Train Loss: 0.3822
Epoch 11: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0132. 
Epoch 12 Step 1 Train Loss: 0.3997
Epoch 12 Step 51 Train Loss: 0.3899
Epoch 12 Step 101 Train Loss: 0.4036
Epoch 12 Step 151 Train Loss: 0.4026
Epoch 12: Train Overall MSE: 0.0053 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0130. 
Epoch 13 Step 1 Train Loss: 0.3956
Epoch 13 Step 51 Train Loss: 0.3811
Epoch 13 Step 101 Train Loss: 0.4085
Epoch 13 Step 151 Train Loss: 0.3648
Epoch 13: Train Overall MSE: 0.0058 Validation Overall MSE: 0.0065. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0136. 
Epoch 14 Step 1 Train Loss: 0.3790
Epoch 14 Step 51 Train Loss: 0.3951
Epoch 14 Step 101 Train Loss: 0.3934
Epoch 14 Step 151 Train Loss: 0.3793
Epoch 14: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0141. 
Epoch 15 Step 1 Train Loss: 0.3899
Epoch 15 Step 51 Train Loss: 0.3908
Epoch 15 Step 101 Train Loss: 0.3739
Epoch 15 Step 151 Train Loss: 0.3832
Epoch 15: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0132. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0110
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.002482858
test_unseen_single_pearson: 0.7764531781884698
test_unseen_single_mse_de: 0.011013797
test_unseen_single_pearson_de: 0.6335880338082174
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.05330192039762273
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.39
test_unseen_single_frac_sigma_below_1_non_dropout: 0.74
test_unseen_single_mse_top20_de_non_dropout: 0.0111143
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.019 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–ƒâ–‡â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–†â–‡â–ˆâ–‡
wandb:                                             train_de_pearson â–ˆâ–‡â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚
wandb:                                                    train_mse â–â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–ˆâ–‡
wandb:                                                train_pearson â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚
wandb:                                                training_loss â–ˆâ–„â–„â–ƒâ–†â–„â–„â–ƒâ–„â–‚â–ƒâ–‚â–„â–‚â–‚â–ƒâ–„â–ƒâ–„â–‚â–‚â–ƒâ–â–â–‚â–‚â–ƒâ–‚â–â–‚â–„â–‚â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–‚â–ƒ
wandb:                                                   val_de_mse â–â–‡â–„â–„â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                                               val_de_pearson â–ˆâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚
wandb:                                                      val_mse â–â–…â–ˆâ–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:                                                  val_pearson â–ˆâ–ƒâ–â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01101
wandb:                                              test_de_pearson 0.63359
wandb:               test_frac_opposite_direction_top20_non_dropout 0.39
wandb:                          test_frac_sigma_below_1_non_dropout 0.74
wandb:                                                     test_mse 0.00248
wandb:                                test_mse_top20_de_non_dropout 0.01111
wandb:                                                 test_pearson 0.77645
wandb:                                           test_pearson_delta 0.0533
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.39
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.74
wandb:                                       test_unseen_single_mse 0.00248
wandb:                                    test_unseen_single_mse_de 0.01101
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01111
wandb:                                   test_unseen_single_pearson 0.77645
wandb:                                test_unseen_single_pearson_de 0.63359
wandb:                             test_unseen_single_pearson_delta 0.0533
wandb:                                                 train_de_mse 0.01137
wandb:                                             train_de_pearson 0.52226
wandb:                                                    train_mse 0.00552
wandb:                                                train_pearson 0.65621
wandb:                                                training_loss 0.39043
wandb:                                                   val_de_mse 0.01321
wandb:                                               val_de_pearson 0.98834
wandb:                                                      val_mse 0.00591
wandb:                                                  val_pearson 0.58785
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_stimulated_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/2r7qb29z
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_020909-2r7qb29z/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_stimulated/splits/datlingerbock2021_stimulated_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_021647-y29fhn8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_stimulated_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/y29fhn8s
Start Training...
Epoch 1 Step 1 Train Loss: 0.6329
Epoch 1 Step 51 Train Loss: 0.4313
Epoch 1 Step 101 Train Loss: 0.4071
Epoch 1 Step 151 Train Loss: 0.3837
Epoch 1: Train Overall MSE: 0.0047 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0060 Validation Top 20 DE MSE: 0.0055. 
Epoch 2 Step 1 Train Loss: 0.3976
Epoch 2 Step 51 Train Loss: 0.3980
Epoch 2 Step 101 Train Loss: 0.3684
Epoch 2 Step 151 Train Loss: 0.4073
Epoch 2: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0057 Validation Top 20 DE MSE: 0.0062. 
Epoch 3 Step 1 Train Loss: 0.3964
Epoch 3 Step 51 Train Loss: 0.3780
Epoch 3 Step 101 Train Loss: 0.4001
Epoch 3 Step 151 Train Loss: 0.3850
Epoch 3: Train Overall MSE: 0.0045 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0077 Validation Top 20 DE MSE: 0.0051. 
Epoch 4 Step 1 Train Loss: 0.3896
Epoch 4 Step 51 Train Loss: 0.3956
Epoch 4 Step 101 Train Loss: 0.3886
Epoch 4 Step 151 Train Loss: 0.4007
Epoch 4: Train Overall MSE: 0.0048 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0044. 
Epoch 5 Step 1 Train Loss: 0.3973
Epoch 5 Step 51 Train Loss: 0.3836
Epoch 5 Step 101 Train Loss: 0.3681
Epoch 5 Step 151 Train Loss: 0.3874
Epoch 5: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0050. 
Epoch 6 Step 1 Train Loss: 0.3764
Epoch 6 Step 51 Train Loss: 0.3716
Epoch 6 Step 101 Train Loss: 0.3845
Epoch 6 Step 151 Train Loss: 0.3793
Epoch 6: Train Overall MSE: 0.0049 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0046. 
Epoch 7 Step 1 Train Loss: 0.3787
Epoch 7 Step 51 Train Loss: 0.3854
Epoch 7 Step 101 Train Loss: 0.3711
Epoch 7 Step 151 Train Loss: 0.3690
Epoch 7: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0046. 
Epoch 8 Step 1 Train Loss: 0.3805
Epoch 8 Step 51 Train Loss: 0.3754
Epoch 8 Step 101 Train Loss: 0.3847
Epoch 8 Step 151 Train Loss: 0.3816
Epoch 8: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0049. 
Epoch 9 Step 1 Train Loss: 0.3935
Epoch 9 Step 51 Train Loss: 0.3699
Epoch 9 Step 101 Train Loss: 0.3907
Epoch 9 Step 151 Train Loss: 0.3725
Epoch 9: Train Overall MSE: 0.0052 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0051. 
Epoch 10 Step 1 Train Loss: 0.3809
Epoch 10 Step 51 Train Loss: 0.3844
Epoch 10 Step 101 Train Loss: 0.3942
Epoch 10 Step 151 Train Loss: 0.3939
Epoch 10: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0050. 
Epoch 11 Step 1 Train Loss: 0.3819
Epoch 11 Step 51 Train Loss: 0.3666
Epoch 11 Step 101 Train Loss: 0.3771
Epoch 11 Step 151 Train Loss: 0.3775
Epoch 11: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0049. 
Epoch 12 Step 1 Train Loss: 0.3642
Epoch 12 Step 51 Train Loss: 0.3657
Epoch 12 Step 101 Train Loss: 0.3638
Epoch 12 Step 151 Train Loss: 0.3808
Epoch 12: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0048. 
Epoch 13 Step 1 Train Loss: 0.3908
Epoch 13 Step 51 Train Loss: 0.3911
Epoch 13 Step 101 Train Loss: 0.3958
Epoch 13 Step 151 Train Loss: 0.3675
Epoch 13: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0049. 
Epoch 14 Step 1 Train Loss: 0.3878
Epoch 14 Step 51 Train Loss: 0.3694
Epoch 14 Step 101 Train Loss: 0.3682
Epoch 14 Step 151 Train Loss: 0.3788
Epoch 14: Train Overall MSE: 0.0052 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0048. 
Epoch 15 Step 1 Train Loss: 0.3754
Epoch 15 Step 51 Train Loss: 0.3842
Epoch 15 Step 101 Train Loss: 0.3767
Epoch 15 Step 151 Train Loss: 0.3806
Epoch 15: Train Overall MSE: 0.0049 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0048. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0098
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0017459264
test_unseen_single_pearson: 0.8220033373162764
test_unseen_single_mse_de: 0.00978246
test_unseen_single_pearson_de: 0.8308456332998938
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.038691663029976696
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.67
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7000000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.009837736
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.019 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:                                             train_de_pearson â–ˆâ–‡â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–†â–â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡
wandb:                                                train_pearson â–ƒâ–ˆâ–ƒâ–‚â–â–‚â–‚â–â–â–â–â–‚â–‚â–â–‚
wandb:                                                training_loss â–ˆâ–„â–…â–‚â–…â–…â–‡â–†â–‚â–…â–…â–ƒâ–„â–…â–…â–„â–ƒâ–„â–‚â–‚â–‚â–„â–ƒâ–„â–„â–†â–‚â–‚â–‚â–ƒâ–ƒâ–…â–†â–ƒâ–â–…â–ƒâ–…â–ƒâ–ƒ
wandb:                                                   val_de_mse â–…â–ˆâ–„â–â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒ
wandb:                                               val_de_pearson â–â–„â–…â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:                                                      val_mse â–ˆâ–†â–„â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                  val_pearson â–â–ƒâ–„â–ˆâ–…â–…â–†â–…â–„â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00978
wandb:                                              test_de_pearson 0.83085
wandb:               test_frac_opposite_direction_top20_non_dropout 0.67
wandb:                          test_frac_sigma_below_1_non_dropout 0.7
wandb:                                                     test_mse 0.00175
wandb:                                test_mse_top20_de_non_dropout 0.00984
wandb:                                                 test_pearson 0.822
wandb:                                           test_pearson_delta -0.03869
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.67
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.7
wandb:                                       test_unseen_single_mse 0.00175
wandb:                                    test_unseen_single_mse_de 0.00978
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00984
wandb:                                   test_unseen_single_pearson 0.822
wandb:                                test_unseen_single_pearson_de 0.83085
wandb:                             test_unseen_single_pearson_delta -0.03869
wandb:                                                 train_de_mse 0.01026
wandb:                                             train_de_pearson 0.5095
wandb:                                                    train_mse 0.00485
wandb:                                                train_pearson 0.6785
wandb:                                                training_loss 0.38119
wandb:                                                   val_de_mse 0.00483
wandb:                                               val_de_pearson 0.92733
wandb:                                                      val_mse 0.00171
wandb:                                                  val_pearson 0.81984
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_stimulated_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/y29fhn8s
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_021647-y29fhn8s/logs
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/21 [00:00<?, ?it/s]  5%|â–         | 1/21 [00:06<02:03,  6.19s/it] 10%|â–‰         | 2/21 [00:12<02:04,  6.53s/it] 14%|â–ˆâ–        | 3/21 [00:23<02:31,  8.44s/it] 19%|â–ˆâ–‰        | 4/21 [00:30<02:09,  7.64s/it] 24%|â–ˆâ–ˆâ–       | 5/21 [00:35<01:46,  6.66s/it] 29%|â–ˆâ–ˆâ–Š       | 6/21 [00:43<01:50,  7.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7/21 [00:48<01:29,  6.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 8/21 [00:54<01:23,  6.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 9/21 [01:01<01:18,  6.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 10/21 [01:06<01:05,  5.94s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 11/21 [01:11<00:57,  5.71s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 12/21 [01:16<00:49,  5.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 13/21 [01:19<00:38,  4.79s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 14/21 [01:22<00:30,  4.30s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 15/21 [01:25<00:23,  3.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 16/21 [01:27<00:17,  3.40s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 17/21 [01:29<00:11,  2.80s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 18/21 [01:31<00:08,  2.70s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 19/21 [01:34<00:05,  2.68s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 20/21 [01:36<00:02,  2.65s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:36<00:00,  1.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:36<00:00,  4.62s/it]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_unstimulated/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_unstimulated/splits/datlingerbock2021_unstimulated_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_022657-0zuq7c97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_unstimulated_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0zuq7c97
  0%|          | 0/4173 [00:00<?, ?it/s]  0%|          | 7/4173 [00:00<01:05, 63.29it/s]  0%|          | 15/4173 [00:00<01:00, 69.13it/s]  1%|          | 22/4173 [00:00<01:00, 68.88it/s]  1%|          | 31/4173 [00:00<00:55, 74.52it/s]  1%|          | 39/4173 [00:00<00:54, 75.96it/s]  1%|          | 47/4173 [00:00<00:54, 75.32it/s]  1%|â–         | 55/4173 [00:00<00:55, 74.27it/s]  2%|â–         | 63/4173 [00:00<00:56, 72.13it/s]  2%|â–         | 72/4173 [00:00<00:53, 76.32it/s]  2%|â–         | 80/4173 [00:01<00:53, 76.20it/s]  2%|â–         | 88/4173 [00:01<00:53, 76.79it/s]  2%|â–         | 96/4173 [00:01<00:52, 77.03it/s]  2%|â–         | 104/4173 [00:01<00:53, 76.57it/s]  3%|â–Ž         | 112/4173 [00:01<00:52, 77.09it/s]  3%|â–Ž         | 120/4173 [00:01<00:52, 77.42it/s]  3%|â–Ž         | 128/4173 [00:01<00:52, 76.76it/s]  3%|â–Ž         | 136/4173 [00:01<00:52, 77.00it/s]  3%|â–Ž         | 144/4173 [00:01<00:52, 77.04it/s]  4%|â–Ž         | 152/4173 [00:02<00:52, 76.26it/s]  4%|â–         | 160/4173 [00:02<00:53, 74.54it/s]  4%|â–         | 168/4173 [00:02<00:54, 74.01it/s]  4%|â–         | 176/4173 [00:02<00:53, 74.14it/s]  4%|â–         | 184/4173 [00:02<00:52, 75.44it/s]  5%|â–         | 192/4173 [00:02<00:52, 75.79it/s]  5%|â–         | 200/4173 [00:02<00:53, 74.26it/s]  5%|â–         | 208/4173 [00:02<00:53, 74.08it/s]  5%|â–Œ         | 216/4173 [00:02<00:52, 74.91it/s]  5%|â–Œ         | 224/4173 [00:02<00:53, 74.08it/s]  6%|â–Œ         | 232/4173 [00:03<00:53, 73.54it/s]  6%|â–Œ         | 241/4173 [00:03<00:51, 75.78it/s]  6%|â–Œ         | 249/4173 [00:03<00:51, 76.25it/s]  6%|â–Œ         | 258/4173 [00:03<00:50, 78.10it/s]  6%|â–‹         | 267/4173 [00:03<00:49, 79.31it/s]  7%|â–‹         | 276/4173 [00:03<00:47, 81.84it/s]  7%|â–‹         | 285/4173 [00:03<00:47, 82.33it/s]  7%|â–‹         | 294/4173 [00:03<00:47, 82.34it/s]  7%|â–‹         | 303/4173 [00:03<00:47, 81.72it/s]  7%|â–‹         | 312/4173 [00:04<00:46, 82.74it/s]  8%|â–Š         | 321/4173 [00:04<00:48, 78.94it/s]  8%|â–Š         | 330/4173 [00:04<00:46, 81.93it/s]  8%|â–Š         | 339/4173 [00:04<00:52, 73.28it/s]  8%|â–Š         | 347/4173 [00:04<00:53, 71.82it/s]  9%|â–Š         | 355/4173 [00:04<00:52, 72.46it/s]  9%|â–Š         | 363/4173 [00:04<00:53, 71.39it/s]  9%|â–‰         | 371/4173 [00:04<00:53, 70.95it/s]  9%|â–‰         | 379/4173 [00:05<00:52, 71.80it/s]  9%|â–‰         | 387/4173 [00:05<00:53, 70.94it/s]  9%|â–‰         | 395/4173 [00:05<00:53, 70.72it/s] 10%|â–‰         | 403/4173 [00:05<00:52, 71.97it/s] 10%|â–‰         | 411/4173 [00:05<00:51, 72.37it/s] 10%|â–ˆ         | 419/4173 [00:05<00:51, 72.45it/s] 10%|â–ˆ         | 427/4173 [00:05<00:53, 70.63it/s] 10%|â–ˆ         | 436/4173 [00:05<00:50, 73.98it/s] 11%|â–ˆ         | 444/4173 [00:05<00:50, 73.33it/s] 11%|â–ˆ         | 452/4173 [00:06<00:50, 73.19it/s] 11%|â–ˆ         | 460/4173 [00:06<00:50, 73.41it/s] 11%|â–ˆ         | 468/4173 [00:06<00:50, 73.13it/s] 11%|â–ˆâ–        | 476/4173 [00:06<00:50, 72.88it/s] 12%|â–ˆâ–        | 484/4173 [00:06<00:50, 73.07it/s] 12%|â–ˆâ–        | 492/4173 [00:06<00:50, 72.69it/s] 12%|â–ˆâ–        | 500/4173 [00:06<00:51, 72.01it/s] 12%|â–ˆâ–        | 508/4173 [00:06<00:51, 71.31it/s] 12%|â–ˆâ–        | 516/4173 [00:06<00:51, 70.98it/s] 13%|â–ˆâ–Ž        | 524/4173 [00:07<00:51, 70.77it/s] 13%|â–ˆâ–Ž        | 532/4173 [00:07<00:51, 70.53it/s] 13%|â–ˆâ–Ž        | 540/4173 [00:07<00:51, 70.31it/s] 13%|â–ˆâ–Ž        | 548/4173 [00:07<00:51, 70.42it/s] 13%|â–ˆâ–Ž        | 556/4173 [00:07<00:51, 70.82it/s] 14%|â–ˆâ–Ž        | 564/4173 [00:07<00:50, 71.36it/s] 14%|â–ˆâ–Ž        | 572/4173 [00:07<00:50, 71.53it/s] 14%|â–ˆâ–        | 580/4173 [00:07<00:51, 69.38it/s] 14%|â–ˆâ–        | 589/4173 [00:07<00:48, 73.39it/s] 14%|â–ˆâ–        | 597/4173 [00:08<00:48, 73.45it/s] 14%|â–ˆâ–        | 605/4173 [00:08<00:48, 72.98it/s] 15%|â–ˆâ–        | 613/4173 [00:08<00:49, 72.32it/s] 15%|â–ˆâ–        | 621/4173 [00:08<00:49, 72.41it/s] 15%|â–ˆâ–Œ        | 629/4173 [00:08<00:48, 72.86it/s] 15%|â–ˆâ–Œ        | 637/4173 [00:08<00:48, 73.24it/s] 15%|â–ˆâ–Œ        | 645/4173 [00:08<00:47, 73.83it/s] 16%|â–ˆâ–Œ        | 653/4173 [00:08<00:47, 73.88it/s] 16%|â–ˆâ–Œ        | 661/4173 [00:08<00:47, 73.78it/s] 16%|â–ˆâ–Œ        | 669/4173 [00:09<00:47, 74.26it/s] 16%|â–ˆâ–Œ        | 677/4173 [00:09<00:47, 73.13it/s] 16%|â–ˆâ–‹        | 685/4173 [00:09<00:47, 72.78it/s] 17%|â–ˆâ–‹        | 693/4173 [00:09<00:48, 72.49it/s] 17%|â–ˆâ–‹        | 701/4173 [00:09<00:47, 73.19it/s] 17%|â–ˆâ–‹        | 709/4173 [00:09<00:47, 73.59it/s] 17%|â–ˆâ–‹        | 719/4173 [00:09<00:44, 78.32it/s] 17%|â–ˆâ–‹        | 729/4173 [00:09<00:42, 81.54it/s] 18%|â–ˆâ–Š        | 738/4173 [00:09<00:43, 79.83it/s] 18%|â–ˆâ–Š        | 746/4173 [00:10<00:43, 78.35it/s] 18%|â–ˆâ–Š        | 754/4173 [00:10<00:44, 76.45it/s] 18%|â–ˆâ–Š        | 762/4173 [00:10<00:44, 76.21it/s] 18%|â–ˆâ–Š        | 770/4173 [00:10<00:46, 73.06it/s] 19%|â–ˆâ–Š        | 779/4173 [00:10<00:46, 73.44it/s] 19%|â–ˆâ–‰        | 788/4173 [00:10<00:43, 77.15it/s] 19%|â–ˆâ–‰        | 796/4173 [00:10<00:43, 76.92it/s] 19%|â–ˆâ–‰        | 804/4173 [00:10<00:46, 72.88it/s] 19%|â–ˆâ–‰        | 813/4173 [00:10<00:44, 75.56it/s] 20%|â–ˆâ–‰        | 821/4173 [00:11<00:44, 75.25it/s] 20%|â–ˆâ–‰        | 829/4173 [00:11<00:44, 74.59it/s] 20%|â–ˆâ–ˆ        | 837/4173 [00:11<00:44, 74.91it/s] 20%|â–ˆâ–ˆ        | 845/4173 [00:11<00:44, 75.28it/s] 20%|â–ˆâ–ˆ        | 853/4173 [00:11<00:44, 75.05it/s] 21%|â–ˆâ–ˆ        | 861/4173 [00:11<00:45, 73.01it/s] 21%|â–ˆâ–ˆ        | 870/4173 [00:11<00:44, 73.96it/s] 21%|â–ˆâ–ˆ        | 879/4173 [00:11<00:44, 73.89it/s] 21%|â–ˆâ–ˆâ–       | 888/4173 [00:11<00:42, 77.02it/s] 21%|â–ˆâ–ˆâ–       | 896/4173 [00:12<00:42, 76.46it/s] 22%|â–ˆâ–ˆâ–       | 904/4173 [00:12<00:44, 73.00it/s] 22%|â–ˆâ–ˆâ–       | 913/4173 [00:12<00:42, 76.59it/s] 22%|â–ˆâ–ˆâ–       | 921/4173 [00:12<00:42, 76.38it/s] 22%|â–ˆâ–ˆâ–       | 929/4173 [00:12<00:42, 76.18it/s] 22%|â–ˆâ–ˆâ–       | 937/4173 [00:12<00:42, 75.69it/s] 23%|â–ˆâ–ˆâ–Ž       | 945/4173 [00:12<00:43, 73.45it/s] 23%|â–ˆâ–ˆâ–Ž       | 954/4173 [00:12<00:43, 73.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 962/4173 [00:12<00:43, 73.79it/s] 23%|â–ˆâ–ˆâ–Ž       | 970/4173 [00:13<00:43, 74.39it/s] 23%|â–ˆâ–ˆâ–Ž       | 979/4173 [00:13<00:44, 72.36it/s] 24%|â–ˆâ–ˆâ–Ž       | 989/4173 [00:13<00:40, 78.60it/s] 24%|â–ˆâ–ˆâ–       | 997/4173 [00:13<00:41, 77.23it/s] 24%|â–ˆâ–ˆâ–       | 1006/4173 [00:13<00:39, 79.40it/s] 24%|â–ˆâ–ˆâ–       | 1016/4173 [00:13<00:37, 83.21it/s] 25%|â–ˆâ–ˆâ–       | 1025/4173 [00:13<00:39, 80.65it/s] 25%|â–ˆâ–ˆâ–       | 1034/4173 [00:13<00:40, 78.02it/s] 25%|â–ˆâ–ˆâ–       | 1042/4173 [00:13<00:40, 76.70it/s] 25%|â–ˆâ–ˆâ–Œ       | 1050/4173 [00:14<00:42, 73.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 1059/4173 [00:14<00:40, 76.58it/s] 26%|â–ˆâ–ˆâ–Œ       | 1067/4173 [00:14<00:42, 73.59it/s] 26%|â–ˆâ–ˆâ–Œ       | 1076/4173 [00:14<00:41, 74.50it/s] 26%|â–ˆâ–ˆâ–Œ       | 1085/4173 [00:14<00:39, 77.62it/s] 26%|â–ˆâ–ˆâ–Œ       | 1093/4173 [00:14<00:41, 74.45it/s] 26%|â–ˆâ–ˆâ–‹       | 1102/4173 [00:14<00:40, 76.09it/s] 27%|â–ˆâ–ˆâ–‹       | 1110/4173 [00:14<00:40, 75.05it/s] 27%|â–ˆâ–ˆâ–‹       | 1118/4173 [00:14<00:42, 71.96it/s] 27%|â–ˆâ–ˆâ–‹       | 1127/4173 [00:15<00:40, 76.04it/s] 27%|â–ˆâ–ˆâ–‹       | 1135/4173 [00:15<00:39, 76.00it/s] 27%|â–ˆâ–ˆâ–‹       | 1143/4173 [00:15<00:39, 75.79it/s] 28%|â–ˆâ–ˆâ–Š       | 1151/4173 [00:15<00:39, 76.08it/s] 28%|â–ˆâ–ˆâ–Š       | 1159/4173 [00:15<00:39, 76.28it/s] 28%|â–ˆâ–ˆâ–Š       | 1167/4173 [00:15<00:41, 73.18it/s] 28%|â–ˆâ–ˆâ–Š       | 1176/4173 [00:15<00:39, 75.60it/s] 28%|â–ˆâ–ˆâ–Š       | 1184/4173 [00:15<00:40, 74.26it/s] 29%|â–ˆâ–ˆâ–Š       | 1192/4173 [00:15<00:40, 73.49it/s] 29%|â–ˆâ–ˆâ–‰       | 1200/4173 [00:16<00:40, 73.96it/s] 29%|â–ˆâ–ˆâ–‰       | 1208/4173 [00:16<00:41, 72.09it/s] 29%|â–ˆâ–ˆâ–‰       | 1217/4173 [00:16<00:38, 76.03it/s] 29%|â–ˆâ–ˆâ–‰       | 1225/4173 [00:16<00:38, 76.42it/s] 30%|â–ˆâ–ˆâ–‰       | 1233/4173 [00:16<00:39, 73.56it/s] 30%|â–ˆâ–ˆâ–‰       | 1242/4173 [00:16<00:38, 75.89it/s] 30%|â–ˆâ–ˆâ–‰       | 1250/4173 [00:16<00:40, 71.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1259/4173 [00:16<00:38, 75.15it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1267/4173 [00:16<00:39, 73.28it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1276/4173 [00:17<00:37, 76.84it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1284/4173 [00:17<00:37, 77.03it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1292/4173 [00:17<00:37, 77.09it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1300/4173 [00:17<00:37, 76.87it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 1308/4173 [00:17<00:37, 75.61it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1316/4173 [00:17<00:38, 74.87it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1324/4173 [00:17<00:38, 74.58it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1332/4173 [00:17<00:37, 75.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1340/4173 [00:17<00:37, 75.85it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1348/4173 [00:18<00:36, 76.39it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1356/4173 [00:18<00:38, 73.91it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1365/4173 [00:18<00:36, 77.83it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1373/4173 [00:18<00:36, 75.79it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1381/4173 [00:18<00:37, 74.56it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1389/4173 [00:18<00:37, 73.90it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1397/4173 [00:18<00:37, 74.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1405/4173 [00:18<00:36, 74.96it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1413/4173 [00:18<00:36, 75.73it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1421/4173 [00:18<00:36, 76.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1429/4173 [00:19<00:37, 73.64it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1438/4173 [00:19<00:35, 77.60it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1446/4173 [00:19<00:35, 76.01it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1454/4173 [00:19<00:37, 71.58it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1462/4173 [00:19<00:37, 72.20it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1471/4173 [00:19<00:35, 76.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1479/4173 [00:19<00:35, 76.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1487/4173 [00:19<00:34, 76.76it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1495/4173 [00:19<00:34, 76.94it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1503/4173 [00:20<00:35, 74.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1511/4173 [00:20<00:35, 75.04it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1520/4173 [00:20<00:34, 76.91it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1528/4173 [00:20<00:34, 75.69it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1536/4173 [00:20<00:35, 74.97it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1544/4173 [00:20<00:34, 75.48it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1552/4173 [00:20<00:34, 76.05it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1560/4173 [00:20<00:34, 76.51it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1568/4173 [00:20<00:33, 76.85it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1576/4173 [00:21<00:33, 76.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1584/4173 [00:21<00:34, 75.05it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1592/4173 [00:21<00:34, 74.66it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1600/4173 [00:21<00:34, 74.66it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1608/4173 [00:21<00:33, 75.47it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1616/4173 [00:21<00:33, 76.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1624/4173 [00:21<00:33, 76.52it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1632/4173 [00:21<00:34, 73.59it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1641/4173 [00:21<00:32, 77.53it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1649/4173 [00:22<00:33, 76.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1657/4173 [00:22<00:34, 71.92it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1666/4173 [00:22<00:33, 74.53it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1674/4173 [00:22<00:33, 74.75it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1682/4173 [00:22<00:34, 72.82it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1691/4173 [00:22<00:32, 77.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1699/4173 [00:22<00:32, 77.30it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1707/4173 [00:22<00:33, 73.76it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1716/4173 [00:22<00:32, 76.32it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1724/4173 [00:23<00:32, 75.38it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1732/4173 [00:23<00:32, 74.90it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1740/4173 [00:23<00:33, 72.88it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1749/4173 [00:23<00:31, 76.27it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1757/4173 [00:23<00:32, 73.84it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1765/4173 [00:23<00:32, 74.83it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1774/4173 [00:23<00:30, 78.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1782/4173 [00:23<00:31, 76.42it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1790/4173 [00:23<00:31, 75.81it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1798/4173 [00:23<00:32, 74.16it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1806/4173 [00:24<00:31, 74.56it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1814/4173 [00:24<00:31, 75.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1822/4173 [00:24<00:31, 75.62it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1830/4173 [00:24<00:30, 75.84it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1838/4173 [00:24<00:31, 73.48it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1847/4173 [00:24<00:30, 76.62it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1855/4173 [00:24<00:30, 75.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1863/4173 [00:24<00:31, 74.33it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1871/4173 [00:24<00:31, 74.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1879/4173 [00:25<00:31, 72.31it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1887/4173 [00:25<00:31, 72.82it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1895/4173 [00:25<00:30, 73.64it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1903/4173 [00:25<00:30, 74.49it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1911/4173 [00:25<00:31, 72.53it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1920/4173 [00:25<00:29, 75.87it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1928/4173 [00:25<00:29, 75.83it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1936/4173 [00:25<00:29, 75.84it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1944/4173 [00:25<00:29, 76.10it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1952/4173 [00:26<00:29, 75.94it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1960/4173 [00:26<00:30, 73.57it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1969/4173 [00:26<00:28, 76.90it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1977/4173 [00:26<00:28, 76.75it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1985/4173 [00:26<00:29, 73.91it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1994/4173 [00:26<00:28, 77.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2002/4173 [00:26<00:28, 76.72it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2010/4173 [00:26<00:28, 76.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2018/4173 [00:26<00:28, 76.11it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2026/4173 [00:27<00:28, 75.93it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2034/4173 [00:27<00:28, 76.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2042/4173 [00:27<00:28, 76.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2050/4173 [00:27<00:28, 75.67it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2058/4173 [00:27<00:28, 75.52it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2066/4173 [00:27<00:27, 76.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2074/4173 [00:27<00:27, 76.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2082/4173 [00:27<00:27, 76.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2090/4173 [00:27<00:27, 76.59it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2098/4173 [00:27<00:27, 76.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2106/4173 [00:28<00:27, 76.17it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2114/4173 [00:28<00:27, 75.28it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2122/4173 [00:28<00:27, 75.15it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2130/4173 [00:28<00:27, 75.16it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2138/4173 [00:28<00:26, 75.76it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2146/4173 [00:28<00:26, 75.96it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2154/4173 [00:28<00:26, 76.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2162/4173 [00:28<00:26, 76.41it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2170/4173 [00:28<00:26, 76.54it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2178/4173 [00:29<00:26, 76.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2186/4173 [00:29<00:25, 76.61it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2194/4173 [00:29<00:25, 76.13it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2202/4173 [00:29<00:26, 75.46it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2210/4173 [00:29<00:26, 73.45it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2219/4173 [00:29<00:25, 77.24it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2227/4173 [00:29<00:25, 77.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2235/4173 [00:29<00:26, 73.95it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2244/4173 [00:29<00:24, 77.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2252/4173 [00:29<00:24, 77.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2260/4173 [00:30<00:25, 73.88it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2269/4173 [00:30<00:24, 77.31it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2277/4173 [00:30<00:24, 76.78it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2285/4173 [00:30<00:25, 74.30it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2294/4173 [00:30<00:24, 77.79it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2302/4173 [00:30<00:24, 77.33it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2310/4173 [00:30<00:25, 74.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2319/4173 [00:30<00:23, 77.48it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2327/4173 [00:30<00:24, 76.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2335/4173 [00:31<00:23, 76.91it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2343/4173 [00:31<00:23, 76.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2351/4173 [00:31<00:25, 72.61it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2360/4173 [00:31<00:24, 74.22it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2369/4173 [00:31<00:24, 73.93it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2377/4173 [00:31<00:23, 75.32it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2385/4173 [00:31<00:23, 74.63it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2393/4173 [00:31<00:23, 74.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2401/4173 [00:31<00:24, 72.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2410/4173 [00:32<00:24, 71.40it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2419/4173 [00:32<00:23, 75.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2428/4173 [00:32<00:22, 77.38it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2436/4173 [00:32<00:22, 76.80it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2444/4173 [00:32<00:23, 72.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2453/4173 [00:32<00:23, 74.23it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2461/4173 [00:32<00:22, 75.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2469/4173 [00:32<00:23, 73.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2478/4173 [00:33<00:22, 76.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2486/4173 [00:33<00:21, 76.71it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2494/4173 [00:33<00:22, 73.63it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2503/4173 [00:33<00:22, 75.57it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2511/4173 [00:33<00:22, 75.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2519/4173 [00:33<00:23, 70.67it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2528/4173 [00:33<00:23, 71.46it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2537/4173 [00:33<00:21, 75.76it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2545/4173 [00:33<00:21, 75.79it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2553/4173 [00:34<00:22, 73.15it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2562/4173 [00:34<00:20, 76.83it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2570/4173 [00:34<00:21, 75.36it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2578/4173 [00:34<00:21, 73.21it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2586/4173 [00:34<00:21, 73.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2594/4173 [00:34<00:21, 73.27it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2602/4173 [00:34<00:22, 70.78it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2611/4173 [00:34<00:20, 75.11it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2619/4173 [00:34<00:20, 75.39it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2627/4173 [00:35<00:20, 75.52it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2635/4173 [00:35<00:21, 73.15it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2644/4173 [00:35<00:21, 72.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2652/4173 [00:35<00:21, 71.13it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2661/4173 [00:35<00:20, 74.67it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2669/4173 [00:35<00:20, 72.47it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2678/4173 [00:35<00:20, 73.35it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2687/4173 [00:35<00:19, 76.75it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2695/4173 [00:35<00:19, 76.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2703/4173 [00:36<00:20, 73.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2712/4173 [00:36<00:19, 76.76it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2720/4173 [00:36<00:19, 75.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2728/4173 [00:36<00:20, 71.12it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2737/4173 [00:36<00:19, 74.20it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2745/4173 [00:36<00:19, 72.45it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2753/4173 [00:36<00:19, 72.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2762/4173 [00:36<00:18, 76.63it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2770/4173 [00:36<00:18, 76.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2778/4173 [00:37<00:19, 72.93it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2787/4173 [00:37<00:18, 75.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2795/4173 [00:37<00:18, 73.93it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2803/4173 [00:37<00:19, 70.53it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2812/4173 [00:37<00:18, 74.93it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2820/4173 [00:37<00:17, 75.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2828/4173 [00:37<00:17, 75.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2836/4173 [00:37<00:17, 75.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2844/4173 [00:37<00:18, 72.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2853/4173 [00:38<00:17, 74.47it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2861/4173 [00:38<00:18, 70.59it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2869/4173 [00:38<00:18, 71.91it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2878/4173 [00:38<00:17, 72.98it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2887/4173 [00:38<00:16, 76.88it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2895/4173 [00:38<00:16, 76.52it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2903/4173 [00:38<00:17, 72.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2912/4173 [00:38<00:17, 74.15it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2920/4173 [00:38<00:17, 73.49it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2928/4173 [00:39<00:16, 73.81it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2936/4173 [00:39<00:16, 74.83it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2944/4173 [00:39<00:16, 72.51it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2953/4173 [00:39<00:17, 70.88it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2963/4173 [00:39<00:15, 77.78it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2971/4173 [00:39<00:15, 76.53it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2979/4173 [00:39<00:16, 74.44it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2987/4173 [00:39<00:16, 73.59it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2995/4173 [00:39<00:15, 74.69it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3003/4173 [00:40<00:15, 74.82it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3011/4173 [00:40<00:15, 75.63it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3019/4173 [00:40<00:15, 73.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3028/4173 [00:40<00:15, 73.70it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3037/4173 [00:40<00:14, 76.74it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3045/4173 [00:41<00:30, 37.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3066/4173 [00:41<00:22, 48.67it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3097/4173 [00:41<00:17, 62.97it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3107/4173 [00:42<00:21, 48.89it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3122/4173 [00:42<00:17, 58.79it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3141/4173 [00:42<00:17, 58.59it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3164/4173 [00:42<00:12, 78.85it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3184/4173 [00:43<00:14, 69.40it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3194/4173 [00:43<00:15, 63.57it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3214/4173 [00:43<00:17, 56.09it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3237/4173 [00:44<00:15, 60.56it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3249/4173 [00:44<00:13, 66.69it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3260/4173 [00:44<00:15, 57.38it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3267/4173 [00:44<00:15, 57.47it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3309/4173 [00:44<00:07, 115.47it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3326/4173 [00:44<00:08, 100.10it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3340/4173 [00:45<00:08, 95.13it/s]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3353/4173 [00:45<00:09, 87.46it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3364/4173 [00:45<00:09, 84.50it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3374/4173 [00:45<00:09, 82.42it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3384/4173 [00:45<00:09, 80.83it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3393/4173 [00:45<00:09, 81.66it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3402/4173 [00:45<00:09, 77.43it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3411/4173 [00:45<00:09, 79.70it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3420/4173 [00:46<00:09, 75.88it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3429/4173 [00:46<00:09, 77.57it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3437/4173 [00:46<00:09, 77.48it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3445/4173 [00:46<00:09, 74.18it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3454/4173 [00:46<00:09, 77.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3462/4173 [00:46<00:09, 77.46it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3470/4173 [00:46<00:09, 74.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3479/4173 [00:46<00:09, 76.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3487/4173 [00:47<00:08, 76.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3495/4173 [00:47<00:09, 73.54it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3504/4173 [00:47<00:09, 73.79it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3513/4173 [00:47<00:08, 77.51it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3521/4173 [00:47<00:08, 76.59it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3529/4173 [00:47<00:08, 76.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3537/4173 [00:47<00:08, 74.27it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3545/4173 [00:47<00:08, 74.15it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3554/4173 [00:47<00:08, 76.86it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3562/4173 [00:47<00:07, 76.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3570/4173 [00:48<00:08, 71.17it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3580/4173 [00:48<00:07, 75.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3589/4173 [00:48<00:07, 78.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3597/4173 [00:48<00:07, 74.39it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3606/4173 [00:48<00:07, 75.06it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3615/4173 [00:48<00:07, 77.90it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3623/4173 [00:48<00:07, 74.07it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3632/4173 [00:48<00:07, 77.21it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3640/4173 [00:49<00:06, 76.80it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3648/4173 [00:49<00:07, 73.87it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3657/4173 [00:49<00:06, 76.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3665/4173 [00:49<00:06, 76.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3673/4173 [00:49<00:06, 76.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3681/4173 [00:49<00:06, 76.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3689/4173 [00:49<00:06, 76.11it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3697/4173 [00:49<00:06, 75.29it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3705/4173 [00:49<00:06, 75.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3713/4173 [00:49<00:06, 75.85it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3721/4173 [00:50<00:05, 75.92it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3729/4173 [00:50<00:05, 75.77it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3737/4173 [00:50<00:05, 73.73it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3745/4173 [00:50<00:05, 71.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3754/4173 [00:50<00:05, 75.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3762/4173 [00:50<00:05, 75.70it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3770/4173 [00:50<00:05, 75.52it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3779/4173 [00:50<00:05, 77.93it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3787/4173 [00:50<00:04, 78.14it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3795/4173 [00:51<00:04, 77.63it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3803/4173 [00:51<00:04, 77.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3811/4173 [00:51<00:04, 77.22it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3819/4173 [00:51<00:04, 76.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3827/4173 [00:51<00:04, 73.73it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3836/4173 [00:51<00:04, 77.51it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3844/4173 [00:51<00:04, 74.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3852/4173 [00:51<00:04, 74.60it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3861/4173 [00:51<00:03, 78.52it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3869/4173 [00:52<00:04, 72.62it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3879/4173 [00:52<00:03, 78.80it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3887/4173 [00:52<00:03, 78.46it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3895/4173 [00:52<00:03, 77.42it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3903/4173 [00:52<00:03, 76.51it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3911/4173 [00:52<00:03, 74.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3919/4173 [00:52<00:03, 74.62it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3927/4173 [00:52<00:03, 74.72it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3935/4173 [00:52<00:03, 75.28it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3943/4173 [00:53<00:03, 75.66it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3952/4173 [00:53<00:02, 75.77it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3961/4173 [00:53<00:02, 78.70it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3969/4173 [00:53<00:02, 74.74it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3978/4173 [00:53<00:02, 77.40it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3986/4173 [00:53<00:02, 77.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3996/4173 [00:53<00:02, 82.66it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4005/4173 [00:53<00:01, 84.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4014/4173 [00:53<00:01, 84.17it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4024/4173 [00:54<00:01, 82.14it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4035/4173 [00:54<00:01, 86.36it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4044/4173 [00:54<00:01, 87.17it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4053/4173 [00:54<00:01, 83.41it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4062/4173 [00:54<00:01, 84.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4071/4173 [00:54<00:01, 84.37it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4080/4173 [00:54<00:01, 85.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4089/4173 [00:54<00:00, 84.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4099/4173 [00:54<00:00, 84.49it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4108/4173 [00:55<00:00, 84.46it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4117/4173 [00:55<00:00, 84.36it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4126/4173 [00:55<00:00, 81.77it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4136/4173 [00:55<00:00, 86.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4145/4173 [00:55<00:00, 84.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4154/4173 [00:55<00:00, 85.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4163/4173 [00:55<00:00, 85.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4173/4173 [00:55<00:00, 88.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4173/4173 [00:55<00:00, 74.83it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.8822
Epoch 1 Step 51 Train Loss: 0.5827
Epoch 1 Step 101 Train Loss: 0.5544
Epoch 1: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0084. 
Train Top 20 DE MSE: 0.0057 Validation Top 20 DE MSE: 0.0097. 
Epoch 2 Step 1 Train Loss: 0.5406
Epoch 2 Step 51 Train Loss: 0.5260
Epoch 2 Step 101 Train Loss: 0.5281
Epoch 2: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0081. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0162. 
Epoch 3 Step 1 Train Loss: 0.5133
Epoch 3 Step 51 Train Loss: 0.5104
Epoch 3 Step 101 Train Loss: 0.5081
Epoch 3: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0174 Validation Top 20 DE MSE: 0.0085. 
Epoch 4 Step 1 Train Loss: 0.5169
Epoch 4 Step 51 Train Loss: 0.5040
Epoch 4 Step 101 Train Loss: 0.4942
Epoch 4: Train Overall MSE: 0.0094 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0090. 
Epoch 5 Step 1 Train Loss: 0.5201
Epoch 5 Step 51 Train Loss: 0.4867
Epoch 5 Step 101 Train Loss: 0.5220
Epoch 5: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0070. 
Train Top 20 DE MSE: 0.0217 Validation Top 20 DE MSE: 0.0086. 
Epoch 6 Step 1 Train Loss: 0.4980
Epoch 6 Step 51 Train Loss: 0.5252
Epoch 6 Step 101 Train Loss: 0.5129
Epoch 6: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0227 Validation Top 20 DE MSE: 0.0087. 
Epoch 7 Step 1 Train Loss: 0.4865
Epoch 7 Step 51 Train Loss: 0.5107
Epoch 7 Step 101 Train Loss: 0.5046
Epoch 7: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0237 Validation Top 20 DE MSE: 0.0087. 
Epoch 8 Step 1 Train Loss: 0.5153
Epoch 8 Step 51 Train Loss: 0.5027
Epoch 8 Step 101 Train Loss: 0.4875
Epoch 8: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0229 Validation Top 20 DE MSE: 0.0086. 
Epoch 9 Step 1 Train Loss: 0.5027
Epoch 9 Step 51 Train Loss: 0.5068
Epoch 9 Step 101 Train Loss: 0.4963
Epoch 9: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0065. 
Train Top 20 DE MSE: 0.0227 Validation Top 20 DE MSE: 0.0087. 
Epoch 10 Step 1 Train Loss: 0.4864
Epoch 10 Step 51 Train Loss: 0.4972
Epoch 10 Step 101 Train Loss: 0.5258
Epoch 10: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0068. 
Train Top 20 DE MSE: 0.0230 Validation Top 20 DE MSE: 0.0087. 
Epoch 11 Step 1 Train Loss: 0.5179
Epoch 11 Step 51 Train Loss: 0.5179
Epoch 11 Step 101 Train Loss: 0.4991
Epoch 11: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0241 Validation Top 20 DE MSE: 0.0092. 
Epoch 12 Step 1 Train Loss: 0.5037
Epoch 12 Step 51 Train Loss: 0.5199
Epoch 12 Step 101 Train Loss: 0.5117
Epoch 12: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0243 Validation Top 20 DE MSE: 0.0089. 
Epoch 13 Step 1 Train Loss: 0.5121
Epoch 13 Step 51 Train Loss: 0.5142
Epoch 13 Step 101 Train Loss: 0.5002
Epoch 13: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0068. 
Train Top 20 DE MSE: 0.0234 Validation Top 20 DE MSE: 0.0089. 
Epoch 14 Step 1 Train Loss: 0.4910
Epoch 14 Step 51 Train Loss: 0.4755
Epoch 14 Step 101 Train Loss: 0.4868
Epoch 14: Train Overall MSE: 0.0101 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0232 Validation Top 20 DE MSE: 0.0088. 
Epoch 15 Step 1 Train Loss: 0.5240
Epoch 15 Step 51 Train Loss: 0.5188
Epoch 15 Step 101 Train Loss: 0.4839
Epoch 15: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0240 Validation Top 20 DE MSE: 0.0090. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0069
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0040345932
test_unseen_single_pearson: 0.6946046305989013
test_unseen_single_mse_de: 0.00691071
test_unseen_single_pearson_de: 0.6277555410992398
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.10546726705453784
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.43
test_unseen_single_frac_sigma_below_1_non_dropout: 0.79
test_unseen_single_mse_top20_de_non_dropout: 0.0060074595
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.015 MB uploadedwandb: | 0.016 MB of 0.019 MB uploadedwandb: / 0.016 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–ƒâ–…â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–‡â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–
wandb:                                                    train_mse â–â–„â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                train_pearson â–ˆâ–„â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:                                                training_loss â–ˆâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:                                                   val_de_mse â–‚â–ˆâ–â–â–â–â–â–â–â–â–‚â–â–â–â–‚
wandb:                                               val_de_pearson â–ƒâ–â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                                                      val_mse â–ˆâ–‡â–â–†â–…â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–…
wandb:                                                  val_pearson â–â–‚â–ˆâ–‚â–ƒâ–„â–ƒâ–„â–…â–„â–ƒâ–ƒâ–„â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00691
wandb:                                              test_de_pearson 0.62776
wandb:               test_frac_opposite_direction_top20_non_dropout 0.43
wandb:                          test_frac_sigma_below_1_non_dropout 0.79
wandb:                                                     test_mse 0.00403
wandb:                                test_mse_top20_de_non_dropout 0.00601
wandb:                                                 test_pearson 0.6946
wandb:                                           test_pearson_delta 0.10547
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.43
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.79
wandb:                                       test_unseen_single_mse 0.00403
wandb:                                    test_unseen_single_mse_de 0.00691
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00601
wandb:                                   test_unseen_single_pearson 0.6946
wandb:                                test_unseen_single_pearson_de 0.62776
wandb:                             test_unseen_single_pearson_delta 0.10547
wandb:                                                 train_de_mse 0.02404
wandb:                                             train_de_pearson 0.75135
wandb:                                                    train_mse 0.01033
wandb:                                                train_pearson 0.53765
wandb:                                                training_loss 0.49409
wandb:                                                   val_de_mse 0.00904
wandb:                                               val_de_pearson 0.70452
wandb:                                                      val_mse 0.00718
wandb:                                                  val_pearson 0.56775
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_unstimulated_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0zuq7c97
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_022657-0zuq7c97/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_unstimulated/splits/datlingerbock2021_unstimulated_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_023513-5j76r4uc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_unstimulated_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/5j76r4uc
Start Training...
Epoch 1 Step 1 Train Loss: 0.8003
Epoch 1 Step 51 Train Loss: 0.5727
Epoch 1 Step 101 Train Loss: 0.5165
Epoch 1: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0063. 
Epoch 2 Step 1 Train Loss: 0.5416
Epoch 2 Step 51 Train Loss: 0.5326
Epoch 2 Step 101 Train Loss: 0.5520
Epoch 2: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0070. 
Epoch 3 Step 1 Train Loss: 0.5165
Epoch 3 Step 51 Train Loss: 0.4988
Epoch 3 Step 101 Train Loss: 0.5330
Epoch 3: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0066. 
Epoch 4 Step 1 Train Loss: 0.4893
Epoch 4 Step 51 Train Loss: 0.4930
Epoch 4 Step 101 Train Loss: 0.5423
Epoch 4: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0137 Validation Top 20 DE MSE: 0.0073. 
Epoch 5 Step 1 Train Loss: 0.5203
Epoch 5 Step 51 Train Loss: 0.5058
Epoch 5 Step 101 Train Loss: 0.5199
Epoch 5: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.0070. 
Epoch 6 Step 1 Train Loss: 0.4965
Epoch 6 Step 51 Train Loss: 0.5188
Epoch 6 Step 101 Train Loss: 0.5020
Epoch 6: Train Overall MSE: 0.0091 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0171 Validation Top 20 DE MSE: 0.0072. 
Epoch 7 Step 1 Train Loss: 0.4802
Epoch 7 Step 51 Train Loss: 0.5302
Epoch 7 Step 101 Train Loss: 0.4864
Epoch 7: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0070. 
Train Top 20 DE MSE: 0.0187 Validation Top 20 DE MSE: 0.0083. 
Epoch 8 Step 1 Train Loss: 0.4951
Epoch 8 Step 51 Train Loss: 0.5112
Epoch 8 Step 101 Train Loss: 0.4790
Epoch 8: Train Overall MSE: 0.0101 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0200 Validation Top 20 DE MSE: 0.0084. 
Epoch 9 Step 1 Train Loss: 0.5034
Epoch 9 Step 51 Train Loss: 0.5167
Epoch 9 Step 101 Train Loss: 0.5072
Epoch 9: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0070. 
Train Top 20 DE MSE: 0.0200 Validation Top 20 DE MSE: 0.0084. 
Epoch 10 Step 1 Train Loss: 0.5306
Epoch 10 Step 51 Train Loss: 0.5121
Epoch 10 Step 101 Train Loss: 0.5309
Epoch 10: Train Overall MSE: 0.0096 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0184 Validation Top 20 DE MSE: 0.0080. 
Epoch 11 Step 1 Train Loss: 0.5062
Epoch 11 Step 51 Train Loss: 0.5362
Epoch 11 Step 101 Train Loss: 0.4995
Epoch 11: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0064. 
Train Top 20 DE MSE: 0.0198 Validation Top 20 DE MSE: 0.0079. 
Epoch 12 Step 1 Train Loss: 0.4969
Epoch 12 Step 51 Train Loss: 0.4939
Epoch 12 Step 101 Train Loss: 0.4931
Epoch 12: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0201 Validation Top 20 DE MSE: 0.0087. 
Epoch 13 Step 1 Train Loss: 0.5041
Epoch 13 Step 51 Train Loss: 0.4932
Epoch 13 Step 101 Train Loss: 0.5106
Epoch 13: Train Overall MSE: 0.0091 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0073. 
Epoch 14 Step 1 Train Loss: 0.5017
Epoch 14 Step 51 Train Loss: 0.5002
Epoch 14 Step 101 Train Loss: 0.5014
Epoch 14: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0065. 
Train Top 20 DE MSE: 0.0193 Validation Top 20 DE MSE: 0.0079. 
Epoch 15 Step 1 Train Loss: 0.5033
Epoch 15 Step 51 Train Loss: 0.5057
Epoch 15 Step 101 Train Loss: 0.5132
Epoch 15: Train Overall MSE: 0.0093 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0181 Validation Top 20 DE MSE: 0.0074. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0072
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0052312524
test_unseen_single_pearson: 0.6805371043462016
test_unseen_single_mse_de: 0.007184647
test_unseen_single_pearson_de: 0.6925306385047293
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.021468571518642676
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5
test_unseen_single_frac_sigma_below_1_non_dropout: 0.82
test_unseen_single_mse_top20_de_non_dropout: 0.0074926885
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.018 MB uploadedwandb: | 0.004 MB of 0.018 MB uploadedwandb: / 0.004 MB of 0.018 MB uploadedwandb: - 0.018 MB of 0.018 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–‚â–â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡
wandb:                                             train_de_pearson â–‡â–ˆâ–ƒâ–…â–ƒâ–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚
wandb:                                                    train_mse â–„â–â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡
wandb:                                                train_pearson â–„â–ˆâ–‡â–„â–ƒâ–‚â–â–â–â–‚â–â–â–‚â–â–‚
wandb:                                                training_loss â–ˆâ–ˆâ–…â–„â–†â–ƒâ–„â–†â–‚â–ƒâ–‚â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒ
wandb:                                                   val_de_mse â–â–ƒâ–‚â–„â–ƒâ–„â–‡â–‡â–‡â–†â–…â–ˆâ–„â–…â–„
wandb:                                               val_de_pearson â–â–…â–ˆâ–†â–‡â–†â–…â–…â–…â–†â–…â–…â–†â–†â–†
wandb:                                                      val_mse â–â–„â–‚â–†â–…â–†â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–†
wandb:                                                  val_pearson â–ˆâ–„â–‡â–‚â–ƒâ–‚â–â–â–â–‚â–‚â–â–ƒâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00718
wandb:                                              test_de_pearson 0.69253
wandb:               test_frac_opposite_direction_top20_non_dropout 0.5
wandb:                          test_frac_sigma_below_1_non_dropout 0.82
wandb:                                                     test_mse 0.00523
wandb:                                test_mse_top20_de_non_dropout 0.00749
wandb:                                                 test_pearson 0.68054
wandb:                                           test_pearson_delta 0.02147
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.82
wandb:                                       test_unseen_single_mse 0.00523
wandb:                                    test_unseen_single_mse_de 0.00718
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00749
wandb:                                   test_unseen_single_pearson 0.68054
wandb:                                test_unseen_single_pearson_de 0.69253
wandb:                             test_unseen_single_pearson_delta 0.02147
wandb:                                                 train_de_mse 0.01811
wandb:                                             train_de_pearson 0.64579
wandb:                                                    train_mse 0.00932
wandb:                                                train_pearson 0.56041
wandb:                                                training_loss 0.54639
wandb:                                                   val_de_mse 0.00745
wandb:                                               val_de_pearson 0.76966
wandb:                                                      val_mse 0.00605
wandb:                                                  val_pearson 0.60715
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_unstimulated_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/5j76r4uc
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_023513-5j76r4uc/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_unstimulated/splits/datlingerbock2021_unstimulated_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_024141-mu8f0sg5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_unstimulated_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/mu8f0sg5
Start Training...
Epoch 1 Step 1 Train Loss: 0.8301
Epoch 1 Step 51 Train Loss: 0.5334
Epoch 1 Step 101 Train Loss: 0.5353
Epoch 1: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0052 Validation Top 20 DE MSE: 0.0061. 
Epoch 2 Step 1 Train Loss: 0.5042
Epoch 2 Step 51 Train Loss: 0.5210
Epoch 2 Step 101 Train Loss: 0.5261
Epoch 2: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0056. 
Train Top 20 DE MSE: 0.0088 Validation Top 20 DE MSE: 0.0081. 
Epoch 3 Step 1 Train Loss: 0.5624
Epoch 3 Step 51 Train Loss: 0.4830
Epoch 3 Step 101 Train Loss: 0.5123
Epoch 3: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0095. 
Train Top 20 DE MSE: 0.0155 Validation Top 20 DE MSE: 0.0109. 
Epoch 4 Step 1 Train Loss: 0.4908
Epoch 4 Step 51 Train Loss: 0.5029
Epoch 4 Step 101 Train Loss: 0.5045
Epoch 4: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0123. 
Train Top 20 DE MSE: 0.0197 Validation Top 20 DE MSE: 0.0142. 
Epoch 5 Step 1 Train Loss: 0.5079
Epoch 5 Step 51 Train Loss: 0.5016
Epoch 5 Step 101 Train Loss: 0.5246
Epoch 5: Train Overall MSE: 0.0096 Validation Overall MSE: 0.0121. 
Train Top 20 DE MSE: 0.0204 Validation Top 20 DE MSE: 0.0144. 
Epoch 6 Step 1 Train Loss: 0.5091
Epoch 6 Step 51 Train Loss: 0.5338
Epoch 6 Step 101 Train Loss: 0.4827
Epoch 6: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0130. 
Train Top 20 DE MSE: 0.0214 Validation Top 20 DE MSE: 0.0152. 
Epoch 7 Step 1 Train Loss: 0.5311
Epoch 7 Step 51 Train Loss: 0.5175
Epoch 7 Step 101 Train Loss: 0.4982
Epoch 7: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0129. 
Train Top 20 DE MSE: 0.0233 Validation Top 20 DE MSE: 0.0152. 
Epoch 8 Step 1 Train Loss: 0.5023
Epoch 8 Step 51 Train Loss: 0.4891
Epoch 8 Step 101 Train Loss: 0.5256
Epoch 8: Train Overall MSE: 0.0105 Validation Overall MSE: 0.0132. 
Train Top 20 DE MSE: 0.0237 Validation Top 20 DE MSE: 0.0153. 
Epoch 9 Step 1 Train Loss: 0.5101
Epoch 9 Step 51 Train Loss: 0.4809
Epoch 9 Step 101 Train Loss: 0.4985
Epoch 9: Train Overall MSE: 0.0107 Validation Overall MSE: 0.0135. 
Train Top 20 DE MSE: 0.0240 Validation Top 20 DE MSE: 0.0156. 
Epoch 10 Step 1 Train Loss: 0.4737
Epoch 10 Step 51 Train Loss: 0.4983
Epoch 10 Step 101 Train Loss: 0.4949
Epoch 10: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0119. 
Train Top 20 DE MSE: 0.0233 Validation Top 20 DE MSE: 0.0141. 
Epoch 11 Step 1 Train Loss: 0.4946
Epoch 11 Step 51 Train Loss: 0.5286
Epoch 11 Step 101 Train Loss: 0.4946
Epoch 11: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0127. 
Train Top 20 DE MSE: 0.0232 Validation Top 20 DE MSE: 0.0149. 
Epoch 12 Step 1 Train Loss: 0.5039
Epoch 12 Step 51 Train Loss: 0.4870
Epoch 12 Step 101 Train Loss: 0.5231
Epoch 12: Train Overall MSE: 0.0105 Validation Overall MSE: 0.0134. 
Train Top 20 DE MSE: 0.0232 Validation Top 20 DE MSE: 0.0155. 
Epoch 13 Step 1 Train Loss: 0.5356
Epoch 13 Step 51 Train Loss: 0.4859
Epoch 13 Step 101 Train Loss: 0.4680
Epoch 13: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0119. 
Train Top 20 DE MSE: 0.0230 Validation Top 20 DE MSE: 0.0141. 
Epoch 14 Step 1 Train Loss: 0.4904
Epoch 14 Step 51 Train Loss: 0.4812
Epoch 14 Step 101 Train Loss: 0.4997
Epoch 14: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0110. 
Train Top 20 DE MSE: 0.0220 Validation Top 20 DE MSE: 0.0134. 
Epoch 15 Step 1 Train Loss: 0.5074
Epoch 15 Step 51 Train Loss: 0.5063
Epoch 15 Step 101 Train Loss: 0.4844
Epoch 15: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0115. 
Train Top 20 DE MSE: 0.0223 Validation Top 20 DE MSE: 0.0138. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0056
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0024334001
test_unseen_single_pearson: 0.7587436136168207
test_unseen_single_mse_de: 0.0056066466
test_unseen_single_pearson_de: 0.8753528569725703
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.07136281839666662
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.36000000000000004
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8699999999999999
test_unseen_single_mse_top20_de_non_dropout: 0.0058643976
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.018 MB uploadedwandb: | 0.018 MB of 0.018 MB uploadedwandb: / 0.018 MB of 0.018 MB uploadedwandb: - 0.018 MB of 0.018 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–‚â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:                                             train_de_pearson â–†â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–‚â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:                                                train_pearson â–ˆâ–†â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–‚
wandb:                                                training_loss â–ˆâ–…â–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–â–‚â–‚
wandb:                                                   val_de_mse â–â–ƒâ–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡
wandb:                                               val_de_pearson â–ˆâ–‡â–ƒâ–â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒ
wandb:                                                      val_mse â–â–‚â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–†â–†
wandb:                                                  val_pearson â–ˆâ–†â–ƒâ–â–‚â–â–â–â–â–‚â–â–â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00561
wandb:                                              test_de_pearson 0.87535
wandb:               test_frac_opposite_direction_top20_non_dropout 0.36
wandb:                          test_frac_sigma_below_1_non_dropout 0.87
wandb:                                                     test_mse 0.00243
wandb:                                test_mse_top20_de_non_dropout 0.00586
wandb:                                                 test_pearson 0.75874
wandb:                                           test_pearson_delta 0.07136
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.36
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.87
wandb:                                       test_unseen_single_mse 0.00243
wandb:                                    test_unseen_single_mse_de 0.00561
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00586
wandb:                                   test_unseen_single_pearson 0.75874
wandb:                                test_unseen_single_pearson_de 0.87535
wandb:                             test_unseen_single_pearson_delta 0.07136
wandb:                                                 train_de_mse 0.02227
wandb:                                             train_de_pearson 0.66898
wandb:                                                    train_mse 0.00988
wandb:                                                train_pearson 0.55166
wandb:                                                training_loss 0.52084
wandb:                                                   val_de_mse 0.01382
wandb:                                               val_de_pearson 0.7244
wandb:                                                      val_mse 0.01149
wandb:                                                  val_pearson 0.46761
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_unstimulated_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/mu8f0sg5
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_024141-mu8f0sg5/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_unstimulated/splits/datlingerbock2021_unstimulated_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_024753-h9v0y5y9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_unstimulated_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/h9v0y5y9
Start Training...
Epoch 1 Step 1 Train Loss: 0.8590
Epoch 1 Step 51 Train Loss: 0.5406
Epoch 1 Step 101 Train Loss: 0.5387
Epoch 1: Train Overall MSE: 0.0044 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0061. 
Epoch 2 Step 1 Train Loss: 0.5216
Epoch 2 Step 51 Train Loss: 0.5291
Epoch 2 Step 101 Train Loss: 0.5448
Epoch 2: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0090. 
Epoch 3 Step 1 Train Loss: 0.5539
Epoch 3 Step 51 Train Loss: 0.5198
Epoch 3 Step 101 Train Loss: 0.5224
Epoch 3: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0171 Validation Top 20 DE MSE: 0.0110. 
Epoch 4 Step 1 Train Loss: 0.4855
Epoch 4 Step 51 Train Loss: 0.5012
Epoch 4 Step 101 Train Loss: 0.5407
Epoch 4: Train Overall MSE: 0.0096 Validation Overall MSE: 0.0077. 
Train Top 20 DE MSE: 0.0213 Validation Top 20 DE MSE: 0.0140. 
Epoch 5 Step 1 Train Loss: 0.4978
Epoch 5 Step 51 Train Loss: 0.5094
Epoch 5 Step 101 Train Loss: 0.5266
Epoch 5: Train Overall MSE: 0.0094 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.0219 Validation Top 20 DE MSE: 0.0163. 
Epoch 6 Step 1 Train Loss: 0.5002
Epoch 6 Step 51 Train Loss: 0.5341
Epoch 6 Step 101 Train Loss: 0.5079
Epoch 6: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0229 Validation Top 20 DE MSE: 0.0147. 
Epoch 7 Step 1 Train Loss: 0.5054
Epoch 7 Step 51 Train Loss: 0.5223
Epoch 7 Step 101 Train Loss: 0.5026
Epoch 7: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0091. 
Train Top 20 DE MSE: 0.0235 Validation Top 20 DE MSE: 0.0167. 
Epoch 8 Step 1 Train Loss: 0.5164
Epoch 8 Step 51 Train Loss: 0.5110
Epoch 8 Step 101 Train Loss: 0.4901
Epoch 8: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0093. 
Train Top 20 DE MSE: 0.0238 Validation Top 20 DE MSE: 0.0166. 
Epoch 9 Step 1 Train Loss: 0.5160
Epoch 9 Step 51 Train Loss: 0.5076
Epoch 9 Step 101 Train Loss: 0.5027
Epoch 9: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.0243 Validation Top 20 DE MSE: 0.0160. 
Epoch 10 Step 1 Train Loss: 0.5399
Epoch 10 Step 51 Train Loss: 0.4997
Epoch 10 Step 101 Train Loss: 0.5096
Epoch 10: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.0239 Validation Top 20 DE MSE: 0.0161. 
Epoch 11 Step 1 Train Loss: 0.5224
Epoch 11 Step 51 Train Loss: 0.4861
Epoch 11 Step 101 Train Loss: 0.4795
Epoch 11: Train Overall MSE: 0.0101 Validation Overall MSE: 0.0094. 
Train Top 20 DE MSE: 0.0245 Validation Top 20 DE MSE: 0.0167. 
Epoch 12 Step 1 Train Loss: 0.5049
Epoch 12 Step 51 Train Loss: 0.5065
Epoch 12 Step 101 Train Loss: 0.5111
Epoch 12: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0093. 
Train Top 20 DE MSE: 0.0247 Validation Top 20 DE MSE: 0.0168. 
Epoch 13 Step 1 Train Loss: 0.5042
Epoch 13 Step 51 Train Loss: 0.4931
Epoch 13 Step 101 Train Loss: 0.5015
Epoch 13: Train Overall MSE: 0.0096 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.0228 Validation Top 20 DE MSE: 0.0155. 
Epoch 14 Step 1 Train Loss: 0.4796
Epoch 14 Step 51 Train Loss: 0.5181
Epoch 14 Step 101 Train Loss: 0.5321
Epoch 14: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0091. 
Train Top 20 DE MSE: 0.0242 Validation Top 20 DE MSE: 0.0164. 
Epoch 15 Step 1 Train Loss: 0.4988
Epoch 15 Step 51 Train Loss: 0.4926
Epoch 15 Step 101 Train Loss: 0.5165
Epoch 15: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0097. 
Train Top 20 DE MSE: 0.0245 Validation Top 20 DE MSE: 0.0171. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0043
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0026782558
test_unseen_single_pearson: 0.7449317647973499
test_unseen_single_mse_de: 0.0042554927
test_unseen_single_pearson_de: 0.7366236156270535
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.12544327775669573
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.35
test_unseen_single_frac_sigma_below_1_non_dropout: 0.89
test_unseen_single_mse_top20_de_non_dropout: 0.004351991
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.018 MB uploadedwandb: | 0.001 MB of 0.018 MB uploadedwandb: / 0.001 MB of 0.018 MB uploadedwandb: - 0.018 MB of 0.018 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–ƒâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–„â–†â–â–‚â–ƒâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:                                                    train_mse â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                                train_pearson â–ˆâ–„â–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–â–
wandb:                                                training_loss â–ˆâ–†â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚
wandb:                                                   val_de_mse â–â–ƒâ–„â–†â–‡â–†â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                               val_de_pearson â–„â–ˆâ–„â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–
wandb:                                                      val_mse â–â–‚â–‚â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆ
wandb:                                                  val_pearson â–ˆâ–ˆâ–‡â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00426
wandb:                                              test_de_pearson 0.73662
wandb:               test_frac_opposite_direction_top20_non_dropout 0.35
wandb:                          test_frac_sigma_below_1_non_dropout 0.89
wandb:                                                     test_mse 0.00268
wandb:                                test_mse_top20_de_non_dropout 0.00435
wandb:                                                 test_pearson 0.74493
wandb:                                           test_pearson_delta 0.12544
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.35
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.89
wandb:                                       test_unseen_single_mse 0.00268
wandb:                                    test_unseen_single_mse_de 0.00426
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00435
wandb:                                   test_unseen_single_pearson 0.74493
wandb:                                test_unseen_single_pearson_de 0.73662
wandb:                             test_unseen_single_pearson_delta 0.12544
wandb:                                                 train_de_mse 0.02449
wandb:                                             train_de_pearson 0.77881
wandb:                                                    train_mse 0.01018
wandb:                                                train_pearson 0.54021
wandb:                                                training_loss 0.52218
wandb:                                                   val_de_mse 0.01707
wandb:                                               val_de_pearson 0.26342
wandb:                                                      val_mse 0.00973
wandb:                                                  val_pearson 0.48982
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_unstimulated_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/h9v0y5y9
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_024753-h9v0y5y9/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/datlingerbock2021_unstimulated/splits/datlingerbock2021_unstimulated_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_025407-18xww6gt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DatlingerBock2021_unstimulated_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/18xww6gt
Start Training...
Epoch 1 Step 1 Train Loss: 0.9080
Epoch 1 Step 51 Train Loss: 0.5504
Epoch 1 Step 101 Train Loss: 0.5433
Epoch 1: Train Overall MSE: 0.0038 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0051 Validation Top 20 DE MSE: 0.0065. 
Epoch 2 Step 1 Train Loss: 0.5132
Epoch 2 Step 51 Train Loss: 0.5215
Epoch 2 Step 101 Train Loss: 0.5146
Epoch 2: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0091. 
Epoch 3 Step 1 Train Loss: 0.4799
Epoch 3 Step 51 Train Loss: 0.4990
Epoch 3 Step 101 Train Loss: 0.5105
Epoch 3: Train Overall MSE: 0.0086 Validation Overall MSE: 0.0046. 
Train Top 20 DE MSE: 0.0162 Validation Top 20 DE MSE: 0.0081. 
Epoch 4 Step 1 Train Loss: 0.5094
Epoch 4 Step 51 Train Loss: 0.5106
Epoch 4 Step 101 Train Loss: 0.4734
Epoch 4: Train Overall MSE: 0.0090 Validation Overall MSE: 0.0052. 
Train Top 20 DE MSE: 0.0200 Validation Top 20 DE MSE: 0.0094. 
Epoch 5 Step 1 Train Loss: 0.5022
Epoch 5 Step 51 Train Loss: 0.4681
Epoch 5 Step 101 Train Loss: 0.5138
Epoch 5: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0218 Validation Top 20 DE MSE: 0.0117. 
Epoch 6 Step 1 Train Loss: 0.5062
Epoch 6 Step 51 Train Loss: 0.5027
Epoch 6 Step 101 Train Loss: 0.5091
Epoch 6: Train Overall MSE: 0.0103 Validation Overall MSE: 0.0068. 
Train Top 20 DE MSE: 0.0224 Validation Top 20 DE MSE: 0.0116. 
Epoch 7 Step 1 Train Loss: 0.4924
Epoch 7 Step 51 Train Loss: 0.5043
Epoch 7 Step 101 Train Loss: 0.5030
Epoch 7: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0226 Validation Top 20 DE MSE: 0.0118. 
Epoch 8 Step 1 Train Loss: 0.5177
Epoch 8 Step 51 Train Loss: 0.4786
Epoch 8 Step 101 Train Loss: 0.4699
Epoch 8: Train Overall MSE: 0.0102 Validation Overall MSE: 0.0066. 
Train Top 20 DE MSE: 0.0231 Validation Top 20 DE MSE: 0.0111. 
Epoch 9 Step 1 Train Loss: 0.4932
Epoch 9 Step 51 Train Loss: 0.4961
Epoch 9 Step 101 Train Loss: 0.5074
Epoch 9: Train Overall MSE: 0.0110 Validation Overall MSE: 0.0081. 
Train Top 20 DE MSE: 0.0249 Validation Top 20 DE MSE: 0.0133. 
Epoch 10 Step 1 Train Loss: 0.5238
Epoch 10 Step 51 Train Loss: 0.4988
Epoch 10 Step 101 Train Loss: 0.5096
Epoch 10: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0065. 
Train Top 20 DE MSE: 0.0239 Validation Top 20 DE MSE: 0.0112. 
Epoch 11 Step 1 Train Loss: 0.5050
Epoch 11 Step 51 Train Loss: 0.4965
Epoch 11 Step 101 Train Loss: 0.5005
Epoch 11: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0236 Validation Top 20 DE MSE: 0.0113. 
Epoch 12 Step 1 Train Loss: 0.5050
Epoch 12 Step 51 Train Loss: 0.5324
Epoch 12 Step 101 Train Loss: 0.4787
Epoch 12: Train Overall MSE: 0.0100 Validation Overall MSE: 0.0066. 
Train Top 20 DE MSE: 0.0227 Validation Top 20 DE MSE: 0.0111. 
Epoch 13 Step 1 Train Loss: 0.4924
Epoch 13 Step 51 Train Loss: 0.4810
Epoch 13 Step 101 Train Loss: 0.4960
Epoch 13: Train Overall MSE: 0.0110 Validation Overall MSE: 0.0077. 
Train Top 20 DE MSE: 0.0251 Validation Top 20 DE MSE: 0.0129. 
Epoch 14 Step 1 Train Loss: 0.4909
Epoch 14 Step 51 Train Loss: 0.5134
Epoch 14 Step 101 Train Loss: 0.4921
Epoch 14: Train Overall MSE: 0.0107 Validation Overall MSE: 0.0073. 
Train Top 20 DE MSE: 0.0241 Validation Top 20 DE MSE: 0.0124. 
Epoch 15 Step 1 Train Loss: 0.5002
Epoch 15 Step 51 Train Loss: 0.5000
Epoch 15 Step 101 Train Loss: 0.4887
Epoch 15: Train Overall MSE: 0.0104 Validation Overall MSE: 0.0069. 
Train Top 20 DE MSE: 0.0238 Validation Top 20 DE MSE: 0.0115. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0119
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0040343986
test_unseen_single_pearson: 0.6932485611094423
test_unseen_single_mse_de: 0.011867429
test_unseen_single_pearson_de: 0.7563077832872708
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.14663705049112563
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.74
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7300000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.011992747
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.018 MB uploadedwandb: | 0.001 MB of 0.018 MB uploadedwandb: / 0.013 MB of 0.018 MB uploadedwandb: - 0.013 MB of 0.018 MB uploadedwandb: \ 0.018 MB of 0.018 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–ƒâ–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                                             train_de_pearson â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb:                                                    train_mse â–â–„â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb:                                                train_pearson â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                training_loss â–ˆâ–„â–‡â–‡â–„â–…â–…â–†â–ƒâ–„â–†â–ƒâ–„â–ƒâ–„â–‚â–‚â–„â–‚â–‚â–‚â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–‚â–„â–…â–„â–â–‚â–„
wandb:                                                   val_de_mse â–â–„â–ƒâ–„â–†â–†â–†â–†â–ˆâ–†â–†â–†â–ˆâ–‡â–†
wandb:                                               val_de_pearson â–ƒâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                      val_mse â–â–‚â–„â–…â–‡â–‡â–‡â–†â–ˆâ–†â–†â–†â–ˆâ–‡â–‡
wandb:                                                  val_pearson â–ˆâ–‡â–„â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01187
wandb:                                              test_de_pearson 0.75631
wandb:               test_frac_opposite_direction_top20_non_dropout 0.74
wandb:                          test_frac_sigma_below_1_non_dropout 0.73
wandb:                                                     test_mse 0.00403
wandb:                                test_mse_top20_de_non_dropout 0.01199
wandb:                                                 test_pearson 0.69325
wandb:                                           test_pearson_delta -0.14664
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.74
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.73
wandb:                                       test_unseen_single_mse 0.00403
wandb:                                    test_unseen_single_mse_de 0.01187
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01199
wandb:                                   test_unseen_single_pearson 0.69325
wandb:                                test_unseen_single_pearson_de 0.75631
wandb:                             test_unseen_single_pearson_delta -0.14664
wandb:                                                 train_de_mse 0.0238
wandb:                                             train_de_pearson 0.64938
wandb:                                                    train_mse 0.01043
wandb:                                                train_pearson 0.53953
wandb:                                                training_loss 0.52632
wandb:                                                   val_de_mse 0.01153
wandb:                                               val_de_pearson 0.74427
wandb:                                                      val_mse 0.00692
wandb:                                                  val_pearson 0.57558
wandb: 
wandb: ðŸš€ View run DatlingerBock2021_unstimulated_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/18xww6gt
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_025407-18xww6gt/logs
