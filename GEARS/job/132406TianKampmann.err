cuda-11.8.0 loaded successful
gcc-12.2.0 loaded successful
cmake-3.27.0 loaded successful
openmpi-4.1.2 loaded successful
Openblas-0.3.25 loaded successful
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:10<16:01, 10.12s/it]  2%|â–         | 2/96 [00:17<13:17,  8.49s/it]  3%|â–Ž         | 3/96 [00:35<19:47, 12.77s/it]  4%|â–         | 4/96 [00:44<17:34, 11.46s/it]  5%|â–Œ         | 5/96 [00:50<14:29,  9.55s/it]  6%|â–‹         | 6/96 [00:55<11:48,  7.87s/it]  7%|â–‹         | 7/96 [00:59<09:56,  6.70s/it]  8%|â–Š         | 8/96 [01:07<10:29,  7.15s/it]  9%|â–‰         | 9/96 [01:15<10:39,  7.35s/it] 10%|â–ˆ         | 10/96 [01:27<12:21,  8.62s/it] 11%|â–ˆâ–        | 11/96 [01:34<11:28,  8.11s/it] 12%|â–ˆâ–Ž        | 12/96 [01:43<12:05,  8.63s/it] 14%|â–ˆâ–Ž        | 13/96 [02:00<15:12, 10.99s/it] 15%|â–ˆâ–        | 14/96 [02:05<12:39,  9.27s/it] 16%|â–ˆâ–Œ        | 15/96 [02:11<11:15,  8.35s/it] 17%|â–ˆâ–‹        | 16/96 [02:19<10:47,  8.09s/it] 18%|â–ˆâ–Š        | 17/96 [02:33<12:55,  9.82s/it] 19%|â–ˆâ–‰        | 18/96 [02:42<12:32,  9.65s/it] 20%|â–ˆâ–‰        | 19/96 [02:51<12:10,  9.48s/it] 21%|â–ˆâ–ˆ        | 20/96 [03:01<12:04,  9.54s/it] 22%|â–ˆâ–ˆâ–       | 21/96 [03:10<11:52,  9.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [03:17<10:54,  8.85s/it] 24%|â–ˆâ–ˆâ–       | 23/96 [03:24<09:56,  8.18s/it] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [03:31<09:22,  7.81s/it] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [03:35<07:52,  6.65s/it] 28%|â–ˆâ–ˆâ–Š       | 27/96 [03:41<05:37,  4.90s/it] 29%|â–ˆâ–ˆâ–‰       | 28/96 [03:47<05:53,  5.20s/it] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [03:53<05:58,  5.35s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [03:56<05:11,  4.72s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [04:01<05:15,  4.85s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [04:04<04:47,  4.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [04:12<05:48,  5.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [04:27<08:23,  8.12s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [04:30<06:52,  6.76s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [04:38<06:53,  6.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [04:44<06:37,  6.73s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [04:55<07:46,  8.04s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [05:05<08:14,  8.67s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [05:11<07:14,  7.76s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [05:21<07:47,  8.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [05:27<07:02,  7.82s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [05:37<07:24,  8.39s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [05:45<07:11,  8.29s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [05:51<06:25,  7.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [05:59<06:28,  7.77s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [06:05<05:50,  7.15s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [06:13<05:55,  7.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [06:23<06:28,  8.27s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [06:40<08:20, 10.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [06:44<06:35,  8.78s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [06:51<06:00,  8.19s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [06:57<05:28,  7.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [07:03<04:58,  7.10s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [07:13<05:22,  7.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [07:19<04:54,  7.36s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [07:27<04:53,  7.52s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [07:34<04:46,  7.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [07:43<04:55,  7.99s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [07:53<05:10,  8.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [08:02<04:57,  8.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [08:09<04:32,  8.02s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [08:16<04:20,  7.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [08:23<04:03,  7.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [08:31<03:56,  7.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [08:35<03:21,  6.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [08:40<02:58,  6.14s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [08:49<03:16,  7.03s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [08:54<02:49,  6.30s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [09:10<03:58,  9.17s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [09:21<04:03,  9.75s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [09:29<03:40,  9.19s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [09:39<03:38,  9.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [09:50<03:41, 10.07s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [09:59<03:24,  9.74s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [10:07<03:04,  9.25s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [10:15<02:44,  8.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [10:26<02:48,  9.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [10:30<02:12,  7.82s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [10:35<01:52,  7.05s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [10:42<01:45,  7.02s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [10:47<01:30,  6.46s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [10:52<01:18,  6.05s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [10:57<01:07,  5.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [11:07<01:17,  7.04s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [11:13<01:07,  6.74s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [11:18<00:54,  6.02s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [11:20<00:39,  4.91s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [11:27<00:38,  5.53s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [11:31<00:29,  4.94s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [11:36<00:24,  4.94s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [11:42<00:21,  5.27s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [11:43<00:12,  4.08s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [11:45<00:06,  3.42s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [11:47<00:03,  3.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [11:53<00:00,  3.83s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [11:53<00:00,  7.43s/it]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispra/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispra/splits/tiankampmann2021_crispra_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_014200-aouizxw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRa_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/aouizxw6
  0%|          | 0/3536 [00:00<?, ?it/s]  0%|          | 6/3536 [00:00<01:02, 56.70it/s]  0%|          | 14/3536 [00:00<00:53, 65.24it/s]  1%|          | 22/3536 [00:00<00:51, 68.14it/s]  1%|          | 33/3536 [00:00<00:43, 80.34it/s]  1%|          | 42/3536 [00:00<00:43, 79.95it/s]  1%|â–         | 50/3536 [00:00<00:44, 79.16it/s]  2%|â–         | 59/3536 [00:00<00:43, 80.12it/s]  2%|â–         | 68/3536 [00:00<00:43, 80.15it/s]  2%|â–         | 77/3536 [00:00<00:43, 79.71it/s]  2%|â–         | 86/3536 [00:01<00:43, 79.97it/s]  3%|â–Ž         | 94/3536 [00:01<00:43, 79.94it/s]  3%|â–Ž         | 102/3536 [00:01<00:43, 78.78it/s]  3%|â–Ž         | 111/3536 [00:01<00:43, 79.51it/s]  3%|â–Ž         | 120/3536 [00:01<00:42, 80.25it/s]  4%|â–Ž         | 129/3536 [00:01<00:42, 80.17it/s]  4%|â–         | 138/3536 [00:01<00:43, 79.00it/s]  4%|â–         | 146/3536 [00:01<00:43, 78.26it/s]  4%|â–         | 154/3536 [00:01<00:44, 75.80it/s]  5%|â–         | 163/3536 [00:02<00:42, 79.33it/s]  5%|â–         | 171/3536 [00:02<00:42, 79.41it/s]  5%|â–Œ         | 179/3536 [00:02<00:43, 76.88it/s]  5%|â–Œ         | 188/3536 [00:02<00:41, 80.13it/s]  6%|â–Œ         | 197/3536 [00:02<00:41, 80.08it/s]  6%|â–Œ         | 206/3536 [00:02<00:41, 80.43it/s]  6%|â–Œ         | 215/3536 [00:02<00:43, 77.04it/s]  6%|â–‹         | 224/3536 [00:02<00:41, 80.34it/s]  7%|â–‹         | 233/3536 [00:02<00:40, 81.00it/s]  7%|â–‹         | 242/3536 [00:03<00:42, 77.29it/s]  7%|â–‹         | 251/3536 [00:03<00:40, 80.45it/s]  7%|â–‹         | 260/3536 [00:03<00:40, 80.18it/s]  8%|â–Š         | 269/3536 [00:03<00:42, 76.60it/s]  8%|â–Š         | 279/3536 [00:03<00:40, 80.39it/s]  8%|â–Š         | 288/3536 [00:03<00:41, 77.55it/s]  8%|â–Š         | 297/3536 [00:03<00:40, 80.44it/s]  9%|â–Š         | 306/3536 [00:03<00:40, 80.70it/s]  9%|â–‰         | 315/3536 [00:03<00:40, 80.38it/s]  9%|â–‰         | 324/3536 [00:04<00:39, 80.52it/s]  9%|â–‰         | 333/3536 [00:04<00:39, 81.24it/s] 10%|â–‰         | 342/3536 [00:04<00:39, 81.08it/s] 10%|â–‰         | 351/3536 [00:04<00:40, 77.83it/s] 10%|â–ˆ         | 359/3536 [00:04<00:43, 73.37it/s] 10%|â–ˆ         | 368/3536 [00:04<00:42, 74.17it/s] 11%|â–ˆ         | 377/3536 [00:04<00:41, 76.00it/s] 11%|â–ˆ         | 385/3536 [00:04<00:41, 75.14it/s] 11%|â–ˆ         | 393/3536 [00:05<00:41, 75.88it/s] 11%|â–ˆâ–        | 401/3536 [00:05<00:41, 75.58it/s] 12%|â–ˆâ–        | 409/3536 [00:05<00:40, 76.31it/s] 12%|â–ˆâ–        | 417/3536 [00:05<00:40, 77.19it/s] 12%|â–ˆâ–        | 425/3536 [00:05<00:40, 77.25it/s] 12%|â–ˆâ–        | 433/3536 [00:05<00:40, 76.81it/s] 12%|â–ˆâ–        | 441/3536 [00:05<00:41, 74.94it/s] 13%|â–ˆâ–Ž        | 450/3536 [00:05<00:39, 77.92it/s] 13%|â–ˆâ–Ž        | 458/3536 [00:05<00:39, 78.00it/s] 13%|â–ˆâ–Ž        | 466/3536 [00:05<00:39, 78.28it/s] 13%|â–ˆâ–Ž        | 474/3536 [00:06<00:40, 75.83it/s] 14%|â–ˆâ–Ž        | 483/3536 [00:06<00:38, 79.46it/s] 14%|â–ˆâ–        | 491/3536 [00:06<00:38, 79.23it/s] 14%|â–ˆâ–        | 499/3536 [00:06<00:38, 78.68it/s] 14%|â–ˆâ–        | 507/3536 [00:06<00:38, 78.35it/s] 15%|â–ˆâ–        | 515/3536 [00:06<00:38, 78.05it/s] 15%|â–ˆâ–        | 523/3536 [00:06<00:38, 77.59it/s] 15%|â–ˆâ–Œ        | 531/3536 [00:06<00:38, 77.18it/s] 15%|â–ˆâ–Œ        | 539/3536 [00:06<00:38, 77.26it/s] 15%|â–ˆâ–Œ        | 547/3536 [00:07<00:38, 76.91it/s] 16%|â–ˆâ–Œ        | 555/3536 [00:07<00:38, 77.41it/s] 16%|â–ˆâ–Œ        | 563/3536 [00:07<00:38, 77.06it/s] 16%|â–ˆâ–Œ        | 571/3536 [00:07<00:38, 76.89it/s] 16%|â–ˆâ–‹        | 579/3536 [00:07<00:38, 77.09it/s] 17%|â–ˆâ–‹        | 587/3536 [00:07<00:37, 77.63it/s] 17%|â–ˆâ–‹        | 596/3536 [00:07<00:37, 78.25it/s] 17%|â–ˆâ–‹        | 604/3536 [00:07<00:37, 78.40it/s] 17%|â–ˆâ–‹        | 612/3536 [00:07<00:37, 78.38it/s] 18%|â–ˆâ–Š        | 621/3536 [00:07<00:37, 78.47it/s] 18%|â–ˆâ–Š        | 629/3536 [00:08<00:37, 78.08it/s] 18%|â–ˆâ–Š        | 637/3536 [00:08<00:37, 76.91it/s] 18%|â–ˆâ–Š        | 645/3536 [00:08<00:37, 77.70it/s] 18%|â–ˆâ–Š        | 653/3536 [00:08<00:37, 76.18it/s] 19%|â–ˆâ–Š        | 661/3536 [00:08<00:37, 75.89it/s] 19%|â–ˆâ–‰        | 669/3536 [00:08<00:38, 74.70it/s] 19%|â–ˆâ–‰        | 678/3536 [00:08<00:38, 74.63it/s] 19%|â–ˆâ–‰        | 687/3536 [00:08<00:36, 77.27it/s] 20%|â–ˆâ–‰        | 695/3536 [00:08<00:36, 77.11it/s] 20%|â–ˆâ–‰        | 703/3536 [00:09<00:37, 76.53it/s] 20%|â–ˆâ–ˆ        | 711/3536 [00:09<00:36, 76.45it/s] 20%|â–ˆâ–ˆ        | 719/3536 [00:09<00:36, 77.01it/s] 21%|â–ˆâ–ˆ        | 727/3536 [00:09<00:36, 76.64it/s] 21%|â–ˆâ–ˆ        | 735/3536 [00:09<00:37, 75.70it/s] 21%|â–ˆâ–ˆ        | 743/3536 [00:09<00:37, 74.78it/s] 21%|â–ˆâ–ˆâ–       | 752/3536 [00:09<00:35, 77.98it/s] 21%|â–ˆâ–ˆâ–       | 760/3536 [00:09<00:36, 76.56it/s] 22%|â–ˆâ–ˆâ–       | 769/3536 [00:09<00:35, 78.69it/s] 22%|â–ˆâ–ˆâ–       | 778/3536 [00:10<00:45, 60.25it/s] 22%|â–ˆâ–ˆâ–       | 794/3536 [00:10<00:34, 79.64it/s] 23%|â–ˆâ–ˆâ–Ž       | 803/3536 [00:10<00:33, 81.92it/s] 23%|â–ˆâ–ˆâ–Ž       | 812/3536 [00:10<00:38, 70.40it/s] 23%|â–ˆâ–ˆâ–Ž       | 823/3536 [00:10<00:34, 79.55it/s] 24%|â–ˆâ–ˆâ–Ž       | 832/3536 [00:10<00:34, 79.18it/s] 24%|â–ˆâ–ˆâ–       | 841/3536 [00:10<00:34, 78.17it/s] 24%|â–ˆâ–ˆâ–       | 850/3536 [00:10<00:34, 78.74it/s] 24%|â–ˆâ–ˆâ–       | 859/3536 [00:11<00:38, 70.05it/s] 25%|â–ˆâ–ˆâ–       | 870/3536 [00:11<00:33, 78.46it/s] 25%|â–ˆâ–ˆâ–       | 879/3536 [00:11<00:32, 81.15it/s] 25%|â–ˆâ–ˆâ–Œ       | 888/3536 [00:11<00:33, 79.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 898/3536 [00:11<00:31, 82.64it/s] 26%|â–ˆâ–ˆâ–Œ       | 907/3536 [00:11<00:31, 82.94it/s] 26%|â–ˆâ–ˆâ–Œ       | 916/3536 [00:11<00:32, 80.31it/s] 26%|â–ˆâ–ˆâ–Œ       | 925/3536 [00:11<00:32, 80.90it/s] 26%|â–ˆâ–ˆâ–‹       | 934/3536 [00:12<00:31, 81.90it/s] 27%|â–ˆâ–ˆâ–‹       | 944/3536 [00:12<00:31, 82.95it/s] 27%|â–ˆâ–ˆâ–‹       | 954/3536 [00:12<00:30, 84.80it/s] 27%|â–ˆâ–ˆâ–‹       | 963/3536 [00:12<00:31, 82.45it/s] 28%|â–ˆâ–ˆâ–Š       | 973/3536 [00:12<00:30, 83.41it/s] 28%|â–ˆâ–ˆâ–Š       | 982/3536 [00:12<00:30, 83.04it/s] 28%|â–ˆâ–ˆâ–Š       | 991/3536 [00:12<00:30, 83.80it/s] 28%|â–ˆâ–ˆâ–Š       | 1001/3536 [00:12<00:30, 84.25it/s] 29%|â–ˆâ–ˆâ–Š       | 1011/3536 [00:12<00:29, 86.48it/s] 29%|â–ˆâ–ˆâ–‰       | 1020/3536 [00:13<00:29, 85.72it/s] 29%|â–ˆâ–ˆâ–‰       | 1030/3536 [00:13<00:28, 89.05it/s] 29%|â–ˆâ–ˆâ–‰       | 1039/3536 [00:13<00:29, 85.08it/s] 30%|â–ˆâ–ˆâ–‰       | 1048/3536 [00:13<00:29, 85.57it/s] 30%|â–ˆâ–ˆâ–‰       | 1058/3536 [00:13<00:27, 88.75it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1068/3536 [00:13<00:27, 89.20it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1078/3536 [00:13<00:27, 88.93it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1087/3536 [00:13<00:27, 87.57it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1096/3536 [00:13<00:27, 88.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 1105/3536 [00:13<00:27, 87.26it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1114/3536 [00:14<00:28, 84.17it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1124/3536 [00:14<00:27, 88.20it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1133/3536 [00:14<00:27, 86.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1142/3536 [00:14<00:28, 83.69it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1151/3536 [00:14<00:27, 85.45it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1160/3536 [00:14<00:28, 83.78it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1170/3536 [00:14<00:28, 83.55it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1179/3536 [00:14<00:27, 85.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1188/3536 [00:14<00:28, 82.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1198/3536 [00:15<00:27, 86.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1207/3536 [00:15<00:26, 86.69it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1216/3536 [00:15<00:26, 86.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1225/3536 [00:15<00:26, 86.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1234/3536 [00:15<00:26, 85.98it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1243/3536 [00:15<00:26, 86.60it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1252/3536 [00:15<00:26, 87.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1261/3536 [00:15<00:27, 82.82it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1271/3536 [00:15<00:26, 84.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1280/3536 [00:16<00:26, 84.63it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1289/3536 [00:16<00:26, 84.62it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1299/3536 [00:16<00:25, 88.09it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1308/3536 [00:16<00:26, 84.02it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1317/3536 [00:16<00:26, 82.97it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1327/3536 [00:16<00:25, 85.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1337/3536 [00:16<00:25, 86.49it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1346/3536 [00:16<00:25, 85.87it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1355/3536 [00:16<00:25, 85.63it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1364/3536 [00:17<00:26, 81.98it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1373/3536 [00:17<00:26, 81.35it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1382/3536 [00:17<00:26, 81.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1391/3536 [00:17<00:27, 77.73it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1401/3536 [00:17<00:25, 82.92it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1410/3536 [00:17<00:25, 84.51it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1419/3536 [00:17<00:24, 84.92it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1428/3536 [00:17<00:24, 84.79it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1437/3536 [00:17<00:25, 83.37it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1446/3536 [00:18<00:24, 83.95it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1455/3536 [00:18<00:25, 80.80it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1464/3536 [00:18<00:25, 81.59it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1473/3536 [00:18<00:25, 81.39it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1483/3536 [00:18<00:24, 84.61it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1492/3536 [00:18<00:24, 84.99it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1501/3536 [00:18<00:23, 85.23it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1510/3536 [00:18<00:24, 83.90it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1519/3536 [00:18<00:24, 81.38it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1529/3536 [00:19<00:23, 84.94it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1538/3536 [00:19<00:23, 84.72it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1547/3536 [00:19<00:23, 84.14it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1556/3536 [00:19<00:23, 83.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1565/3536 [00:19<00:24, 81.80it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1574/3536 [00:19<00:23, 82.34it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1584/3536 [00:19<00:23, 84.39it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1593/3536 [00:19<00:23, 81.60it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1603/3536 [00:19<00:23, 82.65it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1613/3536 [00:20<00:22, 85.42it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1622/3536 [00:20<00:23, 82.53it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1632/3536 [00:20<00:22, 84.89it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1641/3536 [00:20<00:23, 80.62it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1650/3536 [00:20<00:23, 81.63it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1660/3536 [00:20<00:22, 84.35it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1669/3536 [00:20<00:22, 83.60it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1678/3536 [00:20<00:22, 84.17it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1687/3536 [00:20<00:22, 82.97it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1696/3536 [00:21<00:22, 82.92it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1705/3536 [00:21<00:22, 83.21it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1714/3536 [00:21<00:21, 82.85it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1723/3536 [00:21<00:22, 82.39it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1732/3536 [00:21<00:21, 82.46it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1741/3536 [00:21<00:22, 79.93it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1751/3536 [00:21<00:21, 83.16it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1760/3536 [00:21<00:23, 75.89it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1768/3536 [00:21<00:24, 72.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1776/3536 [00:22<00:25, 69.40it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1784/3536 [00:22<00:25, 68.39it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1791/3536 [00:22<00:25, 68.22it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1798/3536 [00:22<00:25, 66.89it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1805/3536 [00:22<00:25, 67.15it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1812/3536 [00:22<00:25, 66.58it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1819/3536 [00:22<00:26, 64.73it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1826/3536 [00:22<00:26, 65.68it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1833/3536 [00:22<00:26, 64.45it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1841/3536 [00:23<00:24, 68.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1850/3536 [00:23<00:23, 73.26it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1858/3536 [00:23<00:23, 71.72it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1867/3536 [00:23<00:21, 76.28it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1875/3536 [00:23<00:21, 75.63it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1883/3536 [00:23<00:21, 76.39it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1892/3536 [00:23<00:20, 78.88it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1901/3536 [00:23<00:20, 79.57it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1910/3536 [00:23<00:20, 80.89it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1919/3536 [00:24<00:19, 81.39it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1928/3536 [00:24<00:19, 82.66it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1937/3536 [00:24<00:19, 82.77it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1946/3536 [00:24<00:20, 79.35it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1955/3536 [00:24<00:19, 80.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1965/3536 [00:24<00:19, 82.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1975/3536 [00:24<00:18, 84.19it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1985/3536 [00:24<00:17, 86.68it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1994/3536 [00:24<00:17, 85.94it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2003/3536 [00:25<00:18, 82.69it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2013/3536 [00:25<00:17, 86.39it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2022/3536 [00:25<00:18, 82.92it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2032/3536 [00:25<00:17, 85.61it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2041/3536 [00:25<00:17, 86.74it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2051/3536 [00:25<00:16, 87.40it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2060/3536 [00:25<00:16, 86.86it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2070/3536 [00:25<00:16, 89.87it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2080/3536 [00:25<00:16, 86.84it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2090/3536 [00:26<00:16, 87.89it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2099/3536 [00:26<00:16, 88.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2110/3536 [00:26<00:15, 91.82it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2120/3536 [00:26<00:16, 87.83it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2130/3536 [00:26<00:15, 90.35it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2140/3536 [00:26<00:16, 86.82it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2150/3536 [00:26<00:15, 88.60it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2159/3536 [00:26<00:16, 85.47it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2169/3536 [00:26<00:15, 88.45it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2178/3536 [00:27<00:16, 84.65it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2188/3536 [00:27<00:15, 88.69it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2197/3536 [00:27<00:15, 85.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2207/3536 [00:27<00:15, 87.63it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2216/3536 [00:27<00:15, 87.87it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2225/3536 [00:27<00:15, 84.56it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2235/3536 [00:27<00:15, 84.70it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2244/3536 [00:27<00:15, 85.36it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2254/3536 [00:27<00:14, 86.33it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2264/3536 [00:28<00:14, 87.55it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2274/3536 [00:28<00:13, 90.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2284/3536 [00:28<00:13, 90.73it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2294/3536 [00:28<00:13, 89.73it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2303/3536 [00:28<00:13, 89.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2313/3536 [00:28<00:13, 87.41it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2322/3536 [00:28<00:13, 88.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2332/3536 [00:28<00:13, 90.31it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2342/3536 [00:28<00:13, 90.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2352/3536 [00:29<00:13, 86.92it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2361/3536 [00:29<00:13, 87.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2371/3536 [00:29<00:13, 87.72it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2381/3536 [00:29<00:13, 85.12it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2393/3536 [00:29<00:12, 88.97it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2403/3536 [00:29<00:12, 88.78it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2413/3536 [00:29<00:12, 91.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2423/3536 [00:29<00:12, 87.96it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2433/3536 [00:29<00:12, 90.49it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2443/3536 [00:30<00:12, 88.83it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2453/3536 [00:30<00:12, 86.52it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2463/3536 [00:30<00:12, 87.36it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2473/3536 [00:30<00:11, 89.32it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2482/3536 [00:30<00:12, 86.82it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2492/3536 [00:30<00:11, 88.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2502/3536 [00:30<00:11, 88.83it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2511/3536 [00:30<00:11, 88.56it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2521/3536 [00:30<00:11, 90.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2531/3536 [00:31<00:11, 85.60it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2542/3536 [00:31<00:11, 89.47it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2551/3536 [00:31<00:11, 88.50it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2560/3536 [00:31<00:11, 85.50it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2570/3536 [00:31<00:11, 86.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2579/3536 [00:31<00:11, 86.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2589/3536 [00:31<00:10, 87.13it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2599/3536 [00:31<00:10, 86.65it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2609/3536 [00:31<00:10, 89.50it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2618/3536 [00:32<00:10, 88.83it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2627/3536 [00:32<00:10, 89.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2636/3536 [00:32<00:10, 85.70it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2645/3536 [00:32<00:23, 38.44it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2652/3536 [00:32<00:23, 37.62it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2658/3536 [00:33<00:32, 27.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2724/3536 [00:33<00:07, 108.20it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2746/3536 [00:33<00:07, 100.38it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2764/3536 [00:33<00:07, 97.82it/s]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2780/3536 [00:34<00:08, 93.60it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2793/3536 [00:34<00:07, 93.51it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2805/3536 [00:34<00:07, 91.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2816/3536 [00:34<00:07, 90.43it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2827/3536 [00:34<00:08, 88.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2837/3536 [00:34<00:07, 87.57it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2847/3536 [00:34<00:07, 89.23it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2857/3536 [00:35<00:07, 88.46it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2867/3536 [00:35<00:07, 85.87it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2876/3536 [00:35<00:07, 84.75it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2885/3536 [00:35<00:07, 82.66it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2894/3536 [00:35<00:07, 82.93it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2903/3536 [00:35<00:07, 83.89it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2913/3536 [00:35<00:07, 84.28it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2923/3536 [00:35<00:07, 87.44it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2932/3536 [00:35<00:06, 87.54it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2941/3536 [00:36<00:07, 83.73it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2950/3536 [00:36<00:07, 83.46it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2960/3536 [00:36<00:06, 82.84it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2969/3536 [00:36<00:06, 82.29it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2978/3536 [00:36<00:06, 83.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2988/3536 [00:36<00:06, 86.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2997/3536 [00:36<00:06, 85.57it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3006/3536 [00:36<00:06, 82.29it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3016/3536 [00:36<00:06, 84.83it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3025/3536 [00:37<00:06, 81.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3035/3536 [00:37<00:05, 85.80it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3044/3536 [00:37<00:05, 82.51it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3053/3536 [00:37<00:05, 83.29it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3062/3536 [00:37<00:05, 83.39it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3072/3536 [00:37<00:05, 85.94it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3081/3536 [00:37<00:05, 86.02it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3090/3536 [00:37<00:05, 85.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3099/3536 [00:37<00:05, 84.69it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3108/3536 [00:38<00:05, 84.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3117/3536 [00:38<00:05, 83.60it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3126/3536 [00:38<00:04, 83.85it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3135/3536 [00:38<00:04, 83.77it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3144/3536 [00:38<00:04, 83.44it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3153/3536 [00:38<00:04, 83.28it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3162/3536 [00:38<00:04, 80.66it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3172/3536 [00:38<00:04, 81.85it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3181/3536 [00:38<00:04, 82.37it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3191/3536 [00:39<00:04, 85.70it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3200/3536 [00:39<00:04, 82.92it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3210/3536 [00:39<00:03, 86.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3219/3536 [00:39<00:03, 84.86it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3228/3536 [00:39<00:03, 85.64it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3237/3536 [00:39<00:03, 82.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3247/3536 [00:39<00:03, 85.85it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3256/3536 [00:39<00:03, 83.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3266/3536 [00:39<00:03, 85.74it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3275/3536 [00:40<00:03, 85.14it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3284/3536 [00:40<00:03, 82.86it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3293/3536 [00:40<00:02, 83.18it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3303/3536 [00:40<00:02, 84.46it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3312/3536 [00:40<00:02, 81.39it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3323/3536 [00:40<00:02, 87.21it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3332/3536 [00:40<00:02, 84.53it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3342/3536 [00:40<00:02, 83.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3352/3536 [00:40<00:02, 87.35it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3361/3536 [00:41<00:02, 86.48it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3370/3536 [00:41<00:01, 84.75it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3379/3536 [00:41<00:01, 83.60it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3389/3536 [00:41<00:01, 85.45it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3398/3536 [00:41<00:01, 85.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3408/3536 [00:41<00:01, 85.51it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3418/3536 [00:41<00:01, 84.83it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3427/3536 [00:41<00:01, 85.76it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3437/3536 [00:41<00:01, 85.43it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3447/3536 [00:42<00:01, 88.14it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3456/3536 [00:42<00:00, 88.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3465/3536 [00:42<00:00, 86.47it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3474/3536 [00:42<00:00, 82.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3484/3536 [00:42<00:00, 84.12it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3493/3536 [00:42<00:00, 83.35it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3503/3536 [00:42<00:00, 83.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3512/3536 [00:42<00:00, 80.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3523/3536 [00:42<00:00, 86.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3532/3536 [00:43<00:00, 86.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3536/3536 [00:43<00:00, 82.02it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 1.1245
Epoch 1 Step 51 Train Loss: 0.6267
Epoch 1 Step 101 Train Loss: 0.6425
Epoch 1 Step 151 Train Loss: 0.5585
Epoch 1: Train Overall MSE: 0.0040 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0364 Validation Top 20 DE MSE: 0.0403. 
Epoch 2 Step 1 Train Loss: 0.5698
Epoch 2 Step 51 Train Loss: 0.5354
Epoch 2 Step 101 Train Loss: 0.5642
Epoch 2 Step 151 Train Loss: 0.5606
Epoch 2: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0288 Validation Top 20 DE MSE: 0.0363. 
Epoch 3 Step 1 Train Loss: 0.5382
Epoch 3 Step 51 Train Loss: 0.5263
Epoch 3 Step 101 Train Loss: 0.5634
Epoch 3 Step 151 Train Loss: 0.5595
Epoch 3: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0196 Validation Top 20 DE MSE: 0.0319. 
Epoch 4 Step 1 Train Loss: 0.5316
Epoch 4 Step 51 Train Loss: 0.6356
Epoch 4 Step 101 Train Loss: 0.5271
Epoch 4 Step 151 Train Loss: 0.5669
Epoch 4: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0202 Validation Top 20 DE MSE: 0.0280. 
Epoch 5 Step 1 Train Loss: 0.5438
Epoch 5 Step 51 Train Loss: 0.5545
Epoch 5 Step 101 Train Loss: 0.5419
Epoch 5 Step 151 Train Loss: 0.5199
Epoch 5: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0209 Validation Top 20 DE MSE: 0.0345. 
Epoch 6 Step 1 Train Loss: 0.5195
Epoch 6 Step 51 Train Loss: 0.5095
Epoch 6 Step 101 Train Loss: 0.4888
Epoch 6 Step 151 Train Loss: 0.5482
Epoch 6: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0201 Validation Top 20 DE MSE: 0.0317. 
Epoch 7 Step 1 Train Loss: 0.5446
Epoch 7 Step 51 Train Loss: 0.5637
Epoch 7 Step 101 Train Loss: 0.5318
Epoch 7 Step 151 Train Loss: 0.5113
Epoch 7: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0193 Validation Top 20 DE MSE: 0.0333. 
Epoch 8 Step 1 Train Loss: 0.5057
Epoch 8 Step 51 Train Loss: 0.5791
Epoch 8 Step 101 Train Loss: 0.5545
Epoch 8 Step 151 Train Loss: 0.6060
Epoch 8: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0325. 
Epoch 9 Step 1 Train Loss: 0.5327
Epoch 9 Step 51 Train Loss: 0.5302
Epoch 9 Step 101 Train Loss: 0.5973
Epoch 9 Step 151 Train Loss: 0.5382
Epoch 9: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0160 Validation Top 20 DE MSE: 0.0311. 
Epoch 10 Step 1 Train Loss: 0.5797
Epoch 10 Step 51 Train Loss: 0.6059
Epoch 10 Step 101 Train Loss: 0.5408
Epoch 10 Step 151 Train Loss: 0.5651
Epoch 10: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0192 Validation Top 20 DE MSE: 0.0332. 
Epoch 11 Step 1 Train Loss: 0.5183
Epoch 11 Step 51 Train Loss: 0.4833
Epoch 11 Step 101 Train Loss: 0.4942
Epoch 11 Step 151 Train Loss: 0.5309
Epoch 11: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0170 Validation Top 20 DE MSE: 0.0305. 
Epoch 12 Step 1 Train Loss: 0.5533
Epoch 12 Step 51 Train Loss: 0.5109
Epoch 12 Step 101 Train Loss: 0.4963
Epoch 12 Step 151 Train Loss: 0.5371
Epoch 12: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0205 Validation Top 20 DE MSE: 0.0319. 
Epoch 13 Step 1 Train Loss: 0.5383
Epoch 13 Step 51 Train Loss: 0.4830
Epoch 13 Step 101 Train Loss: 0.5860
Epoch 13 Step 151 Train Loss: 0.5592
Epoch 13: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0164 Validation Top 20 DE MSE: 0.0332. 
Epoch 14 Step 1 Train Loss: 0.5836
Epoch 14 Step 51 Train Loss: 0.5140
Epoch 14 Step 101 Train Loss: 0.5086
Epoch 14 Step 151 Train Loss: 0.5436
Epoch 14: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0170 Validation Top 20 DE MSE: 0.0325. 
Epoch 15 Step 1 Train Loss: 0.5276
Epoch 15 Step 51 Train Loss: 0.5722
Epoch 15 Step 101 Train Loss: 0.5305
Epoch 15 Step 151 Train Loss: 0.5474
Epoch 15: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0183 Validation Top 20 DE MSE: 0.0318. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0295
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00216981
test_unseen_single_pearson: 0.994426591403232
test_unseen_single_mse_de: 0.029500818
test_unseen_single_pearson_de: 0.951898122758668
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2470006975644979
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2916666666666667
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9500000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.03305852
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.019 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–…â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–ƒâ–â–â–‚
wandb:                                             train_de_pearson â–â–…â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–‚â–â–â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–
wandb:                                                train_pearson â–â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–ˆâ–…â–ƒâ–…â–„â–‚â–„â–ƒâ–‚â–‚â–…â–ƒâ–„â–ƒâ–†â–‚â–†â–„â–‚â–‚â–…â–…â–…â–…â–ƒâ–‚â–ƒâ–„â–„â–â–‚â–ƒâ–‚â–‚â–‚â–„â–‚â–â–ƒâ–„
wandb:                                                   val_de_mse â–ˆâ–†â–ƒâ–â–…â–ƒâ–„â–„â–ƒâ–„â–‚â–ƒâ–„â–„â–ƒ
wandb:                                               val_de_pearson â–ˆâ–…â–â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                      val_mse â–ˆâ–â–„â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒ
wandb:                                                  val_pearson â–â–ˆâ–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–‡â–†
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.0295
wandb:                                              test_de_pearson 0.9519
wandb:               test_frac_opposite_direction_top20_non_dropout 0.29167
wandb:                          test_frac_sigma_below_1_non_dropout 0.95
wandb:                                                     test_mse 0.00217
wandb:                                test_mse_top20_de_non_dropout 0.03306
wandb:                                                 test_pearson 0.99443
wandb:                                           test_pearson_delta 0.247
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.29167
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.95
wandb:                                       test_unseen_single_mse 0.00217
wandb:                                    test_unseen_single_mse_de 0.0295
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.03306
wandb:                                   test_unseen_single_pearson 0.99443
wandb:                                test_unseen_single_pearson_de 0.9519
wandb:                             test_unseen_single_pearson_delta 0.247
wandb:                                                 train_de_mse 0.0183
wandb:                                             train_de_pearson 0.96395
wandb:                                                    train_mse 0.0025
wandb:                                                train_pearson 0.9939
wandb:                                                training_loss 0.52962
wandb:                                                   val_de_mse 0.03175
wandb:                                               val_de_pearson 0.90941
wandb:                                                      val_mse 0.0024
wandb:                                                  val_pearson 0.99379
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRa_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/aouizxw6
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_014200-aouizxw6/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispra/splits/tiankampmann2021_crispra_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_015356-i6i8ehmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRa_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/i6i8ehmo
Start Training...
Epoch 1 Step 1 Train Loss: 1.2924
Epoch 1 Step 51 Train Loss: 0.5681
Epoch 1 Step 101 Train Loss: 0.5439
Epoch 1 Step 151 Train Loss: 0.5345
Epoch 1: Train Overall MSE: 0.0038 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0241 Validation Top 20 DE MSE: 0.0202. 
Epoch 2 Step 1 Train Loss: 0.5735
Epoch 2 Step 51 Train Loss: 0.5287
Epoch 2 Step 101 Train Loss: 0.5243
Epoch 2 Step 151 Train Loss: 0.5407
Epoch 2: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0189 Validation Top 20 DE MSE: 0.0195. 
Epoch 3 Step 1 Train Loss: 0.5720
Epoch 3 Step 51 Train Loss: 0.5324
Epoch 3 Step 101 Train Loss: 0.5233
Epoch 3 Step 151 Train Loss: 0.5593
Epoch 3: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0183 Validation Top 20 DE MSE: 0.0194. 
Epoch 4 Step 1 Train Loss: 0.5159
Epoch 4 Step 51 Train Loss: 0.5213
Epoch 4 Step 101 Train Loss: 0.5394
Epoch 4 Step 151 Train Loss: 0.5140
Epoch 4: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0161 Validation Top 20 DE MSE: 0.0207. 
Epoch 5 Step 1 Train Loss: 0.5449
Epoch 5 Step 51 Train Loss: 0.6059
Epoch 5 Step 101 Train Loss: 0.5879
Epoch 5 Step 151 Train Loss: 0.5193
Epoch 5: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.0215. 
Epoch 6 Step 1 Train Loss: 0.5217
Epoch 6 Step 51 Train Loss: 0.5971
Epoch 6 Step 101 Train Loss: 0.5075
Epoch 6 Step 151 Train Loss: 0.5548
Epoch 6: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0149 Validation Top 20 DE MSE: 0.0217. 
Epoch 7 Step 1 Train Loss: 0.5452
Epoch 7 Step 51 Train Loss: 0.4826
Epoch 7 Step 101 Train Loss: 0.5615
Epoch 7 Step 151 Train Loss: 0.5475
Epoch 7: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0152 Validation Top 20 DE MSE: 0.0221. 
Epoch 8 Step 1 Train Loss: 0.5444
Epoch 8 Step 51 Train Loss: 0.5204
Epoch 8 Step 101 Train Loss: 0.5260
Epoch 8 Step 151 Train Loss: 0.5586
Epoch 8: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.0220. 
Epoch 9 Step 1 Train Loss: 0.5344
Epoch 9 Step 51 Train Loss: 0.5384
Epoch 9 Step 101 Train Loss: 0.5208
Epoch 9 Step 151 Train Loss: 0.6242
Epoch 9: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.0220. 
Epoch 10 Step 1 Train Loss: 0.5318
Epoch 10 Step 51 Train Loss: 0.5455
Epoch 10 Step 101 Train Loss: 0.5066
Epoch 10 Step 151 Train Loss: 0.5179
Epoch 10: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.0218. 
Epoch 11 Step 1 Train Loss: 0.5487
Epoch 11 Step 51 Train Loss: 0.5650
Epoch 11 Step 101 Train Loss: 0.5637
Epoch 11 Step 151 Train Loss: 0.5081
Epoch 11: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0152 Validation Top 20 DE MSE: 0.0222. 
Epoch 12 Step 1 Train Loss: 0.5690
Epoch 12 Step 51 Train Loss: 0.5345
Epoch 12 Step 101 Train Loss: 0.5485
Epoch 12 Step 151 Train Loss: 0.5534
Epoch 12: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0153 Validation Top 20 DE MSE: 0.0226. 
Epoch 13 Step 1 Train Loss: 0.5440
Epoch 13 Step 51 Train Loss: 0.5556
Epoch 13 Step 101 Train Loss: 0.5593
Epoch 13 Step 151 Train Loss: 0.5352
Epoch 13: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0150 Validation Top 20 DE MSE: 0.0222. 
Epoch 14 Step 1 Train Loss: 0.5826
Epoch 14 Step 51 Train Loss: 0.5181
Epoch 14 Step 101 Train Loss: 0.4993
Epoch 14 Step 151 Train Loss: 0.5410
Epoch 14: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0152 Validation Top 20 DE MSE: 0.0218. 
Epoch 15 Step 1 Train Loss: 0.5280
Epoch 15 Step 51 Train Loss: 0.5712
Epoch 15 Step 101 Train Loss: 0.5535
Epoch 15 Step 151 Train Loss: 0.5464
Epoch 15: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0152 Validation Top 20 DE MSE: 0.0225. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1264
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.003687036
test_unseen_single_pearson: 0.9903607206089919
test_unseen_single_mse_de: 0.12636496
test_unseen_single_pearson_de: 0.9435193041167466
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.27058647740667946
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.26458333333333334
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9604166666666667
test_unseen_single_mse_top20_de_non_dropout: 0.12727264
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.016 MB uploadedwandb: | 0.004 MB of 0.019 MB uploadedwandb: / 0.004 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–„â–„â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                             train_de_pearson â–â–…â–„â–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:                                                train_pearson â–â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–ˆâ–‡â–‚â–„â–…â–…â–…â–„â–†â–ƒâ–â–„â–…â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–„â–†â–‚â–ƒâ–…â–„â–â–â–ƒâ–„â–…â–‚â–ƒâ–‚â–…â–…â–…â–ƒ
wandb:                                                   val_de_mse â–ƒâ–â–â–„â–†â–†â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–†â–ˆ
wandb:                                               val_de_pearson â–‡â–‡â–ˆâ–…â–„â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–
wandb:                                                      val_mse â–ˆâ–â–‚â–…â–†â–ˆâ–†â–…â–†â–…â–‡â–‡â–†â–†â–‡
wandb:                                                  val_pearson â–â–ˆâ–ˆâ–†â–…â–ƒâ–„â–…â–…â–…â–„â–„â–…â–…â–„
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.12636
wandb:                                              test_de_pearson 0.94352
wandb:               test_frac_opposite_direction_top20_non_dropout 0.26458
wandb:                          test_frac_sigma_below_1_non_dropout 0.96042
wandb:                                                     test_mse 0.00369
wandb:                                test_mse_top20_de_non_dropout 0.12727
wandb:                                                 test_pearson 0.99036
wandb:                                           test_pearson_delta 0.27059
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.26458
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.96042
wandb:                                       test_unseen_single_mse 0.00369
wandb:                                    test_unseen_single_mse_de 0.12636
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.12727
wandb:                                   test_unseen_single_pearson 0.99036
wandb:                                test_unseen_single_pearson_de 0.94352
wandb:                             test_unseen_single_pearson_delta 0.27059
wandb:                                                 train_de_mse 0.0152
wandb:                                             train_de_pearson 0.95994
wandb:                                                    train_mse 0.00219
wandb:                                                train_pearson 0.99469
wandb:                                                training_loss 0.52234
wandb:                                                   val_de_mse 0.02245
wandb:                                               val_de_pearson 0.88633
wandb:                                                      val_mse 0.00349
wandb:                                                  val_pearson 0.99163
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRa_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/i6i8ehmo
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_015356-i6i8ehmo/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispra/splits/tiankampmann2021_crispra_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_020356-k3vo9peg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRa_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/k3vo9peg
Start Training...
Epoch 1 Step 1 Train Loss: 1.7548
Epoch 1 Step 51 Train Loss: 0.6321
Epoch 1 Step 101 Train Loss: 0.5785
Epoch 1 Step 151 Train Loss: 0.5805
Epoch 1: Train Overall MSE: 0.0034 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0270 Validation Top 20 DE MSE: 0.0626. 
Epoch 2 Step 1 Train Loss: 0.5068
Epoch 2 Step 51 Train Loss: 0.5656
Epoch 2 Step 101 Train Loss: 0.5750
Epoch 2 Step 151 Train Loss: 0.5852
Epoch 2: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0209 Validation Top 20 DE MSE: 0.0576. 
Epoch 3 Step 1 Train Loss: 0.5808
Epoch 3 Step 51 Train Loss: 0.5516
Epoch 3 Step 101 Train Loss: 0.5950
Epoch 3 Step 151 Train Loss: 0.5566
Epoch 3: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0206 Validation Top 20 DE MSE: 0.0554. 
Epoch 4 Step 1 Train Loss: 0.5854
Epoch 4 Step 51 Train Loss: 0.4976
Epoch 4 Step 101 Train Loss: 0.5582
Epoch 4 Step 151 Train Loss: 0.5565
Epoch 4: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0169 Validation Top 20 DE MSE: 0.0543. 
Epoch 5 Step 1 Train Loss: 0.5776
Epoch 5 Step 51 Train Loss: 0.5483
Epoch 5 Step 101 Train Loss: 0.5502
Epoch 5 Step 151 Train Loss: 0.5493
Epoch 5: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0156 Validation Top 20 DE MSE: 0.0514. 
Epoch 6 Step 1 Train Loss: 0.5371
Epoch 6 Step 51 Train Loss: 0.5484
Epoch 6 Step 101 Train Loss: 0.5587
Epoch 6 Step 151 Train Loss: 0.6074
Epoch 6: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0157 Validation Top 20 DE MSE: 0.0534. 
Epoch 7 Step 1 Train Loss: 0.5388
Epoch 7 Step 51 Train Loss: 0.5851
Epoch 7 Step 101 Train Loss: 0.5056
Epoch 7 Step 151 Train Loss: 0.5945
Epoch 7: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0167 Validation Top 20 DE MSE: 0.0550. 
Epoch 8 Step 1 Train Loss: 0.5597
Epoch 8 Step 51 Train Loss: 0.5947
Epoch 8 Step 101 Train Loss: 0.5099
Epoch 8 Step 151 Train Loss: 0.5782
Epoch 8: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0526. 
Epoch 9 Step 1 Train Loss: 0.5525
Epoch 9 Step 51 Train Loss: 0.5685
Epoch 9 Step 101 Train Loss: 0.5696
Epoch 9 Step 151 Train Loss: 0.5402
Epoch 9: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0167 Validation Top 20 DE MSE: 0.0536. 
Epoch 10 Step 1 Train Loss: 0.5723
Epoch 10 Step 51 Train Loss: 0.5079
Epoch 10 Step 101 Train Loss: 0.5751
Epoch 10 Step 151 Train Loss: 0.5563
Epoch 10: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0157 Validation Top 20 DE MSE: 0.0538. 
Epoch 11 Step 1 Train Loss: 0.5414
Epoch 11 Step 51 Train Loss: 0.5421
Epoch 11 Step 101 Train Loss: 0.5232
Epoch 11 Step 151 Train Loss: 0.5125
Epoch 11: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0157 Validation Top 20 DE MSE: 0.0520. 
Epoch 12 Step 1 Train Loss: 0.5848
Epoch 12 Step 51 Train Loss: 0.5372
Epoch 12 Step 101 Train Loss: 0.5206
Epoch 12 Step 151 Train Loss: 0.5637
Epoch 12: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0184 Validation Top 20 DE MSE: 0.0530. 
Epoch 13 Step 1 Train Loss: 0.5361
Epoch 13 Step 51 Train Loss: 0.5620
Epoch 13 Step 101 Train Loss: 0.4931
Epoch 13 Step 151 Train Loss: 0.5517
Epoch 13: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0157 Validation Top 20 DE MSE: 0.0549. 
Epoch 14 Step 1 Train Loss: 0.5624
Epoch 14 Step 51 Train Loss: 0.5631
Epoch 14 Step 101 Train Loss: 0.5769
Epoch 14 Step 151 Train Loss: 0.5256
Epoch 14: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0530. 
Epoch 15 Step 1 Train Loss: 0.5356
Epoch 15 Step 51 Train Loss: 0.6027
Epoch 15 Step 101 Train Loss: 0.5955
Epoch 15 Step 151 Train Loss: 0.5664
Epoch 15: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0147 Validation Top 20 DE MSE: 0.0551. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0308
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0019052266
test_unseen_single_pearson: 0.9952716511095684
test_unseen_single_mse_de: 0.03083896
test_unseen_single_pearson_de: 0.948648163043805
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.25904069848454586
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.27708333333333335
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9520833333333334
test_unseen_single_mse_top20_de_non_dropout: 0.03234615
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.019 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–…â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–
wandb:                                             train_de_pearson â–â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–‡â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–
wandb:                                                train_pearson â–â–ƒâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–ˆâ–‡â–ˆ
wandb:                                                training_loss â–ˆâ–„â–‚â–„â–„â–…â–„â–…â–ƒâ–„â–…â–…â–â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–…â–ƒ
wandb:                                                   val_de_mse â–ˆâ–…â–„â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–ƒ
wandb:                                               val_de_pearson â–â–ƒâ–…â–…â–ˆâ–‡â–†â–‡â–‡â–†â–ˆâ–‡â–†â–‡â–†
wandb:                                                      val_mse â–ˆâ–‡â–„â–„â–„â–ƒâ–ƒâ–†â–‡â–„â–‡â–‡â–ƒâ–…â–
wandb:                                                  val_pearson â–â–„â–†â–‡â–‡â–‡â–‡â–…â–…â–‡â–…â–…â–‡â–†â–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.03084
wandb:                                              test_de_pearson 0.94865
wandb:               test_frac_opposite_direction_top20_non_dropout 0.27708
wandb:                          test_frac_sigma_below_1_non_dropout 0.95208
wandb:                                                     test_mse 0.00191
wandb:                                test_mse_top20_de_non_dropout 0.03235
wandb:                                                 test_pearson 0.99527
wandb:                                           test_pearson_delta 0.25904
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.27708
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.95208
wandb:                                       test_unseen_single_mse 0.00191
wandb:                                    test_unseen_single_mse_de 0.03084
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.03235
wandb:                                   test_unseen_single_pearson 0.99527
wandb:                                test_unseen_single_pearson_de 0.94865
wandb:                             test_unseen_single_pearson_delta 0.25904
wandb:                                                 train_de_mse 0.01473
wandb:                                             train_de_pearson 0.9568
wandb:                                                    train_mse 0.00248
wandb:                                                train_pearson 0.99405
wandb:                                                training_loss 0.61144
wandb:                                                   val_de_mse 0.0551
wandb:                                               val_de_pearson 0.9719
wandb:                                                      val_mse 0.00269
wandb:                                                  val_pearson 0.99334
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRa_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/k3vo9peg
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_020356-k3vo9peg/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispra/splits/tiankampmann2021_crispra_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_021359-31k7ilk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRa_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/31k7ilk1
Start Training...
Epoch 1 Step 1 Train Loss: 1.1580
Epoch 1 Step 51 Train Loss: 0.5463
Epoch 1 Step 101 Train Loss: 0.6340
Epoch 1 Step 151 Train Loss: 0.5197
Epoch 1: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0292 Validation Top 20 DE MSE: 0.0209. 
Epoch 2 Step 1 Train Loss: 0.5868
Epoch 2 Step 51 Train Loss: 0.5541
Epoch 2 Step 101 Train Loss: 0.5925
Epoch 2 Step 151 Train Loss: 0.5971
Epoch 2: Train Overall MSE: 0.0035 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0260 Validation Top 20 DE MSE: 0.0247. 
Epoch 3 Step 1 Train Loss: 0.6018
Epoch 3 Step 51 Train Loss: 0.5386
Epoch 3 Step 101 Train Loss: 0.5683
Epoch 3 Step 151 Train Loss: 0.5448
Epoch 3: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0204 Validation Top 20 DE MSE: 0.0264. 
Epoch 4 Step 1 Train Loss: 0.5252
Epoch 4 Step 51 Train Loss: 0.5691
Epoch 4 Step 101 Train Loss: 0.5117
Epoch 4 Step 151 Train Loss: 0.5504
Epoch 4: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0169 Validation Top 20 DE MSE: 0.0209. 
Epoch 5 Step 1 Train Loss: 0.5741
Epoch 5 Step 51 Train Loss: 0.5767
Epoch 5 Step 101 Train Loss: 0.5744
Epoch 5 Step 151 Train Loss: 0.5422
Epoch 5: Train Overall MSE: 0.0030 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0171 Validation Top 20 DE MSE: 0.0228. 
Epoch 6 Step 1 Train Loss: 0.5665
Epoch 6 Step 51 Train Loss: 0.5127
Epoch 6 Step 101 Train Loss: 0.5297
Epoch 6 Step 151 Train Loss: 0.5498
Epoch 6: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0166 Validation Top 20 DE MSE: 0.0225. 
Epoch 7 Step 1 Train Loss: 0.5808
Epoch 7 Step 51 Train Loss: 0.5804
Epoch 7 Step 101 Train Loss: 0.5493
Epoch 7 Step 151 Train Loss: 0.5744
Epoch 7: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0165 Validation Top 20 DE MSE: 0.0231. 
Epoch 8 Step 1 Train Loss: 0.5811
Epoch 8 Step 51 Train Loss: 0.5643
Epoch 8 Step 101 Train Loss: 0.5165
Epoch 8 Step 151 Train Loss: 0.5601
Epoch 8: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0161 Validation Top 20 DE MSE: 0.0220. 
Epoch 9 Step 1 Train Loss: 0.5770
Epoch 9 Step 51 Train Loss: 0.5736
Epoch 9 Step 101 Train Loss: 0.6040
Epoch 9 Step 151 Train Loss: 0.5344
Epoch 9: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0160 Validation Top 20 DE MSE: 0.0226. 
Epoch 10 Step 1 Train Loss: 0.5495
Epoch 10 Step 51 Train Loss: 0.5417
Epoch 10 Step 101 Train Loss: 0.5107
Epoch 10 Step 151 Train Loss: 0.5737
Epoch 10: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0220. 
Epoch 11 Step 1 Train Loss: 0.5597
Epoch 11 Step 51 Train Loss: 0.5364
Epoch 11 Step 101 Train Loss: 0.5416
Epoch 11 Step 151 Train Loss: 0.5056
Epoch 11: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0161 Validation Top 20 DE MSE: 0.0222. 
Epoch 12 Step 1 Train Loss: 0.5961
Epoch 12 Step 51 Train Loss: 0.5325
Epoch 12 Step 101 Train Loss: 0.5109
Epoch 12 Step 151 Train Loss: 0.5592
Epoch 12: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0161 Validation Top 20 DE MSE: 0.0230. 
Epoch 13 Step 1 Train Loss: 0.6234
Epoch 13 Step 51 Train Loss: 0.5415
Epoch 13 Step 101 Train Loss: 0.5239
Epoch 13 Step 151 Train Loss: 0.5378
Epoch 13: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0160 Validation Top 20 DE MSE: 0.0230. 
Epoch 14 Step 1 Train Loss: 0.5262
Epoch 14 Step 51 Train Loss: 0.5402
Epoch 14 Step 101 Train Loss: 0.5303
Epoch 14 Step 151 Train Loss: 0.5581
Epoch 14: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0163 Validation Top 20 DE MSE: 0.0226. 
Epoch 15 Step 1 Train Loss: 0.5307
Epoch 15 Step 51 Train Loss: 0.5082
Epoch 15 Step 101 Train Loss: 0.5406
Epoch 15 Step 151 Train Loss: 0.5262
Epoch 15: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0164 Validation Top 20 DE MSE: 0.0231. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0573
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.003395836
test_unseen_single_pearson: 0.9914413572280937
test_unseen_single_mse_de: 0.05732094
test_unseen_single_pearson_de: 0.9487570756509182
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.21486482926225728
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.31875000000000003
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9249999999999999
test_unseen_single_mse_top20_de_non_dropout: 0.060430247
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.001 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:                                             train_de_pearson â–â–â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–‡â–â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚
wandb:                                                train_pearson â–â–‚â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡
wandb:                                                training_loss â–ˆâ–…â–ƒâ–ƒâ–…â–ƒâ–…â–…â–„â–„â–„â–‚â–ƒâ–„â–„â–„â–„â–‚â–ƒâ–„â–„â–„â–ƒâ–‚â–ƒâ–„â–„â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–†â–„â–‚â–„
wandb:                                                   val_de_mse â–â–†â–ˆâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–„
wandb:                                               val_de_pearson â–ˆâ–â–‚â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:                                                      val_mse â–‡â–ˆâ–â–…â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–â–‚
wandb:                                                  val_pearson â–‚â–â–ˆâ–…â–†â–‡â–ˆâ–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.05732
wandb:                                              test_de_pearson 0.94876
wandb:               test_frac_opposite_direction_top20_non_dropout 0.31875
wandb:                          test_frac_sigma_below_1_non_dropout 0.925
wandb:                                                     test_mse 0.0034
wandb:                                test_mse_top20_de_non_dropout 0.06043
wandb:                                                 test_pearson 0.99144
wandb:                                           test_pearson_delta 0.21486
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.31875
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.925
wandb:                                       test_unseen_single_mse 0.0034
wandb:                                    test_unseen_single_mse_de 0.05732
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.06043
wandb:                                   test_unseen_single_pearson 0.99144
wandb:                                test_unseen_single_pearson_de 0.94876
wandb:                             test_unseen_single_pearson_delta 0.21486
wandb:                                                 train_de_mse 0.01642
wandb:                                             train_de_pearson 0.95717
wandb:                                                    train_mse 0.00267
wandb:                                                train_pearson 0.99364
wandb:                                                training_loss 0.5502
wandb:                                                   val_de_mse 0.02307
wandb:                                               val_de_pearson 0.98924
wandb:                                                      val_mse 0.00163
wandb:                                                  val_pearson 0.99597
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRa_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/31k7ilk1
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_021359-31k7ilk1/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispra/splits/tiankampmann2021_crispra_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_022357-4sdnzrka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRa_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/4sdnzrka
Start Training...
Epoch 1 Step 1 Train Loss: 0.9962
Epoch 1 Step 51 Train Loss: 0.6253
Epoch 1 Step 101 Train Loss: 0.5687
Epoch 1 Step 151 Train Loss: 0.5948
Epoch 1: Train Overall MSE: 0.0057 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0492 Validation Top 20 DE MSE: 0.0319. 
Epoch 2 Step 1 Train Loss: 0.5711
Epoch 2 Step 51 Train Loss: 0.5272
Epoch 2 Step 101 Train Loss: 0.5501
Epoch 2 Step 151 Train Loss: 0.5834
Epoch 2: Train Overall MSE: 0.0032 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0209 Validation Top 20 DE MSE: 0.0303. 
Epoch 3 Step 1 Train Loss: 0.5059
Epoch 3 Step 51 Train Loss: 0.5555
Epoch 3 Step 101 Train Loss: 0.5222
Epoch 3 Step 151 Train Loss: 0.5688
Epoch 3: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0204 Validation Top 20 DE MSE: 0.0318. 
Epoch 4 Step 1 Train Loss: 0.5489
Epoch 4 Step 51 Train Loss: 0.5515
Epoch 4 Step 101 Train Loss: 0.5689
Epoch 4 Step 151 Train Loss: 0.5425
Epoch 4: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0183 Validation Top 20 DE MSE: 0.0352. 
Epoch 5 Step 1 Train Loss: 0.5839
Epoch 5 Step 51 Train Loss: 0.5916
Epoch 5 Step 101 Train Loss: 0.5638
Epoch 5 Step 151 Train Loss: 0.5624
Epoch 5: Train Overall MSE: 0.0030 Validation Overall MSE: 0.0038. 
Train Top 20 DE MSE: 0.0204 Validation Top 20 DE MSE: 0.0271. 
Epoch 6 Step 1 Train Loss: 0.5355
Epoch 6 Step 51 Train Loss: 0.5500
Epoch 6 Step 101 Train Loss: 0.6024
Epoch 6 Step 151 Train Loss: 0.5286
Epoch 6: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0286. 
Epoch 7 Step 1 Train Loss: 0.6084
Epoch 7 Step 51 Train Loss: 0.5891
Epoch 7 Step 101 Train Loss: 0.5423
Epoch 7 Step 151 Train Loss: 0.5831
Epoch 7: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0168 Validation Top 20 DE MSE: 0.0297. 
Epoch 8 Step 1 Train Loss: 0.5279
Epoch 8 Step 51 Train Loss: 0.5682
Epoch 8 Step 101 Train Loss: 0.5434
Epoch 8 Step 151 Train Loss: 0.5699
Epoch 8: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0171 Validation Top 20 DE MSE: 0.0291. 
Epoch 9 Step 1 Train Loss: 0.5882
Epoch 9 Step 51 Train Loss: 0.5266
Epoch 9 Step 101 Train Loss: 0.5257
Epoch 9 Step 151 Train Loss: 0.5675
Epoch 9: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0185 Validation Top 20 DE MSE: 0.0293. 
Epoch 10 Step 1 Train Loss: 0.5406
Epoch 10 Step 51 Train Loss: 0.5721
Epoch 10 Step 101 Train Loss: 0.5369
Epoch 10 Step 151 Train Loss: 0.5500
Epoch 10: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0174 Validation Top 20 DE MSE: 0.0298. 
Epoch 11 Step 1 Train Loss: 0.5315
Epoch 11 Step 51 Train Loss: 0.4861
Epoch 11 Step 101 Train Loss: 0.5801
Epoch 11 Step 151 Train Loss: 0.6008
Epoch 11: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0156 Validation Top 20 DE MSE: 0.0295. 
Epoch 12 Step 1 Train Loss: 0.6119
Epoch 12 Step 51 Train Loss: 0.5561
Epoch 12 Step 101 Train Loss: 0.5028
Epoch 12 Step 151 Train Loss: 0.4852
Epoch 12: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0172 Validation Top 20 DE MSE: 0.0285. 
Epoch 13 Step 1 Train Loss: 0.5529
Epoch 13 Step 51 Train Loss: 0.5693
Epoch 13 Step 101 Train Loss: 0.5828
Epoch 13 Step 151 Train Loss: 0.5597
Epoch 13: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0172 Validation Top 20 DE MSE: 0.0293. 
Epoch 14 Step 1 Train Loss: 0.5500
Epoch 14 Step 51 Train Loss: 0.5576
Epoch 14 Step 101 Train Loss: 0.5974
Epoch 14 Step 151 Train Loss: 0.5199
Epoch 14: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0300. 
Epoch 15 Step 1 Train Loss: 0.5313
Epoch 15 Step 51 Train Loss: 0.5559
Epoch 15 Step 101 Train Loss: 0.5947
Epoch 15 Step 151 Train Loss: 0.5368
Epoch 15: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0190 Validation Top 20 DE MSE: 0.0303. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0257
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0030910934
test_unseen_single_pearson: 0.9924856269719001
test_unseen_single_mse_de: 0.025670493
test_unseen_single_pearson_de: 0.9494895814939216
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.25342033980367873
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3020833333333333
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9270833333333334
test_unseen_single_mse_top20_de_non_dropout: 0.0290206
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.004 MB of 0.019 MB uploadedwandb: / 0.004 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–‚
wandb:                                             train_de_pearson â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–ƒâ–â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–â–
wandb:                                                train_pearson â–â–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–ˆâ–„â–„â–‚â–…â–‚â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–„â–‚â–â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–ƒâ–‚â–‡â–‚â–†â–‚â–ƒâ–â–‚â–†â–„â–
wandb:                                                   val_de_mse â–…â–„â–…â–ˆâ–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„
wandb:                                               val_de_pearson â–ˆâ–ƒâ–â–…â–ƒâ–„â–„â–„â–ƒâ–„â–…â–„â–…â–„â–…
wandb:                                                      val_mse â–ƒâ–…â–„â–â–ˆâ–†â–†â–†â–†â–…â–…â–†â–…â–…â–…
wandb:                                                  val_pearson â–…â–„â–„â–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–…
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.02567
wandb:                                              test_de_pearson 0.94949
wandb:               test_frac_opposite_direction_top20_non_dropout 0.30208
wandb:                          test_frac_sigma_below_1_non_dropout 0.92708
wandb:                                                     test_mse 0.00309
wandb:                                test_mse_top20_de_non_dropout 0.02902
wandb:                                                 test_pearson 0.99249
wandb:                                           test_pearson_delta 0.25342
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.30208
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.92708
wandb:                                       test_unseen_single_mse 0.00309
wandb:                                    test_unseen_single_mse_de 0.02567
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.02902
wandb:                                   test_unseen_single_pearson 0.99249
wandb:                                test_unseen_single_pearson_de 0.94949
wandb:                             test_unseen_single_pearson_delta 0.25342
wandb:                                                 train_de_mse 0.01898
wandb:                                             train_de_pearson 0.9629
wandb:                                                    train_mse 0.00269
wandb:                                                train_pearson 0.99348
wandb:                                                training_loss 0.51987
wandb:                                                   val_de_mse 0.03027
wandb:                                               val_de_pearson 0.90483
wandb:                                                      val_mse 0.00317
wandb:                                                  val_pearson 0.99229
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRa_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/4sdnzrka
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_022357-4sdnzrka/logs
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/182 [00:00<?, ?it/s]  1%|          | 1/182 [00:05<17:56,  5.95s/it]  1%|          | 2/182 [00:31<52:39, 17.55s/it]  2%|â–         | 3/182 [00:44<45:45, 15.34s/it]  2%|â–         | 4/182 [01:01<47:15, 15.93s/it]  3%|â–Ž         | 5/182 [01:11<40:40, 13.79s/it]  3%|â–Ž         | 6/182 [01:27<43:27, 14.82s/it]  4%|â–         | 7/182 [01:43<43:57, 15.07s/it]  4%|â–         | 8/182 [01:54<39:27, 13.60s/it]  5%|â–         | 9/182 [02:03<35:15, 12.23s/it]  5%|â–Œ         | 10/182 [02:17<36:58, 12.90s/it]  6%|â–Œ         | 11/182 [02:28<34:57, 12.27s/it]  7%|â–‹         | 12/182 [02:40<34:14, 12.09s/it]  7%|â–‹         | 13/182 [02:56<37:17, 13.24s/it]  8%|â–Š         | 14/182 [03:04<33:24, 11.93s/it]  8%|â–Š         | 15/182 [03:18<34:44, 12.48s/it]  9%|â–‰         | 16/182 [03:32<35:41, 12.90s/it]  9%|â–‰         | 17/182 [03:42<33:12, 12.08s/it] 10%|â–‰         | 18/182 [04:03<40:14, 14.72s/it] 10%|â–ˆ         | 19/182 [04:16<38:14, 14.08s/it] 11%|â–ˆ         | 20/182 [04:29<37:18, 13.82s/it] 12%|â–ˆâ–        | 21/182 [04:44<37:58, 14.15s/it] 12%|â–ˆâ–        | 22/182 [05:05<43:01, 16.14s/it] 13%|â–ˆâ–Ž        | 23/182 [05:19<41:37, 15.71s/it] 13%|â–ˆâ–Ž        | 24/182 [05:31<38:21, 14.56s/it] 14%|â–ˆâ–Ž        | 25/182 [05:42<35:00, 13.38s/it] 14%|â–ˆâ–        | 26/182 [05:53<32:47, 12.61s/it] 15%|â–ˆâ–        | 27/182 [06:04<31:48, 12.31s/it] 15%|â–ˆâ–Œ        | 28/182 [06:22<35:32, 13.85s/it] 16%|â–ˆâ–Œ        | 29/182 [06:34<34:13, 13.42s/it] 16%|â–ˆâ–‹        | 30/182 [06:44<31:15, 12.34s/it] 17%|â–ˆâ–‹        | 31/182 [07:07<39:06, 15.54s/it] 18%|â–ˆâ–Š        | 32/182 [07:16<34:04, 13.63s/it] 18%|â–ˆâ–Š        | 33/182 [07:32<35:45, 14.40s/it] 19%|â–ˆâ–Š        | 34/182 [07:43<33:02, 13.39s/it] 19%|â–ˆâ–‰        | 35/182 [07:54<31:05, 12.69s/it] 20%|â–ˆâ–‰        | 36/182 [08:06<29:47, 12.24s/it] 20%|â–ˆâ–ˆ        | 37/182 [08:14<26:54, 11.14s/it] 21%|â–ˆâ–ˆ        | 38/182 [08:26<27:30, 11.46s/it] 21%|â–ˆâ–ˆâ–       | 39/182 [08:37<26:25, 11.09s/it] 22%|â–ˆâ–ˆâ–       | 40/182 [08:56<31:48, 13.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 41/182 [09:06<29:14, 12.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 42/182 [09:20<30:18, 12.99s/it] 24%|â–ˆâ–ˆâ–Ž       | 43/182 [09:31<28:28, 12.29s/it] 24%|â–ˆâ–ˆâ–       | 44/182 [09:38<25:04, 10.90s/it] 25%|â–ˆâ–ˆâ–       | 45/182 [09:48<23:55, 10.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 46/182 [09:59<24:27, 10.79s/it] 26%|â–ˆâ–ˆâ–Œ       | 47/182 [10:12<25:56, 11.53s/it] 26%|â–ˆâ–ˆâ–‹       | 48/182 [10:22<24:42, 11.07s/it] 27%|â–ˆâ–ˆâ–‹       | 49/182 [10:33<24:01, 10.84s/it] 27%|â–ˆâ–ˆâ–‹       | 50/182 [10:50<27:47, 12.63s/it] 28%|â–ˆâ–ˆâ–Š       | 51/182 [11:00<26:06, 11.96s/it] 29%|â–ˆâ–ˆâ–Š       | 52/182 [11:10<24:40, 11.39s/it] 29%|â–ˆâ–ˆâ–‰       | 53/182 [11:17<21:19,  9.92s/it] 30%|â–ˆâ–ˆâ–‰       | 54/182 [11:28<22:16, 10.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 55/182 [11:42<24:07, 11.39s/it] 31%|â–ˆâ–ˆâ–ˆ       | 56/182 [11:56<25:36, 12.19s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 57/182 [12:04<23:03, 11.07s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 58/182 [12:08<18:06,  8.77s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 59/182 [12:22<21:04, 10.28s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 60/182 [12:35<22:37, 11.13s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 61/182 [12:56<28:37, 14.20s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 62/182 [13:08<27:21, 13.68s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 63/182 [13:20<26:04, 13.15s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 64/182 [13:37<28:07, 14.30s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 65/182 [13:48<25:50, 13.25s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 66/182 [13:57<23:10, 11.99s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 67/182 [14:08<22:07, 11.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 68/182 [14:24<24:24, 12.85s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 69/182 [14:39<25:38, 13.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 70/182 [14:49<23:29, 12.59s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 71/182 [15:01<23:01, 12.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 72/182 [15:21<26:45, 14.59s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 73/182 [15:29<23:14, 12.80s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 74/182 [15:46<24:54, 13.84s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 75/182 [15:54<21:32, 12.08s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 76/182 [16:14<25:55, 14.68s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 77/182 [16:27<24:35, 14.06s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 78/182 [16:40<23:45, 13.71s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 79/182 [16:48<20:42, 12.06s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80/182 [17:02<21:35, 12.70s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 81/182 [17:21<24:09, 14.35s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 82/182 [17:32<22:24, 13.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 83/182 [17:47<22:51, 13.85s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 84/182 [17:56<20:24, 12.49s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 85/182 [18:07<19:14, 11.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 86/182 [18:21<20:11, 12.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 87/182 [18:37<21:32, 13.60s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 88/182 [18:47<19:35, 12.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 89/182 [18:52<15:56, 10.29s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 90/182 [19:06<17:28, 11.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 91/182 [19:19<18:00, 11.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 92/182 [19:19<12:32,  8.36s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 93/182 [19:26<11:40,  7.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 94/182 [19:38<13:31,  9.22s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 95/182 [19:52<15:29, 10.69s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 96/182 [20:06<16:48, 11.73s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 97/182 [20:18<16:38, 11.74s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 98/182 [20:32<17:28, 12.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 99/182 [20:47<18:12, 13.16s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 100/182 [20:57<16:29, 12.07s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 101/182 [21:07<15:27, 11.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 102/182 [21:19<15:36, 11.71s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 103/182 [21:30<15:15, 11.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 104/182 [21:45<16:10, 12.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 105/182 [22:10<20:55, 16.31s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 106/182 [22:22<19:01, 15.03s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 107/182 [22:33<17:11, 13.75s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 108/182 [22:43<15:32, 12.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 109/182 [22:58<16:16, 13.38s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 110/182 [23:07<14:25, 12.01s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 111/182 [23:18<14:06, 11.93s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 112/182 [23:30<13:44, 11.78s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 113/182 [23:41<13:19, 11.59s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 114/182 [23:55<14:03, 12.40s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 115/182 [24:07<13:30, 12.09s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 116/182 [24:16<12:27, 11.33s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 117/182 [24:32<13:51, 12.79s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 118/182 [24:43<13:03, 12.24s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 119/182 [24:57<13:24, 12.78s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 120/182 [25:08<12:29, 12.08s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 121/182 [25:20<12:12, 12.00s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 122/182 [25:32<12:07, 12.12s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 123/182 [25:40<10:41, 10.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 124/182 [25:58<12:33, 12.99s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 125/182 [26:10<11:59, 12.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 126/182 [26:21<11:22, 12.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 127/182 [26:32<10:47, 11.78s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 128/182 [26:42<10:06, 11.22s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 129/182 [26:53<09:59, 11.31s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 130/182 [27:05<10:00, 11.54s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 131/182 [27:16<09:32, 11.22s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 132/182 [27:29<09:50, 11.81s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 133/182 [27:46<10:50, 13.27s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 134/182 [27:58<10:26, 13.05s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 135/182 [28:09<09:38, 12.31s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 136/182 [28:18<08:42, 11.35s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 137/182 [28:27<08:05, 10.79s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 138/182 [28:40<08:24, 11.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 139/182 [28:53<08:26, 11.78s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 140/182 [29:05<08:16, 11.83s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 141/182 [29:19<08:33, 12.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 142/182 [29:33<08:39, 12.99s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 143/182 [29:43<07:51, 12.10s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 144/182 [29:56<07:47, 12.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 145/182 [30:10<07:59, 12.96s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 146/182 [30:22<07:28, 12.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 147/182 [30:32<06:50, 11.72s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 148/182 [30:40<06:03, 10.70s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 149/182 [30:55<06:34, 11.94s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 150/182 [31:07<06:23, 11.98s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 151/182 [31:15<05:33, 10.76s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 152/182 [31:25<05:21, 10.71s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 153/182 [31:43<06:13, 12.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 154/182 [31:53<05:37, 12.07s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 155/182 [32:08<05:50, 12.97s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 156/182 [32:20<05:22, 12.39s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 157/182 [32:30<04:58, 11.92s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 158/182 [32:40<04:32, 11.37s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 159/182 [32:49<04:03, 10.60s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 160/182 [33:03<04:12, 11.47s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 161/182 [33:24<05:00, 14.32s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 162/182 [33:34<04:21, 13.07s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 163/182 [33:44<03:53, 12.27s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 164/182 [33:59<03:51, 12.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 165/182 [34:08<03:22, 11.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 166/182 [34:20<03:10, 11.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 167/182 [34:32<02:59, 11.94s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 168/182 [34:42<02:36, 11.20s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 169/182 [34:52<02:21, 10.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 170/182 [35:09<02:32, 12.67s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 171/182 [35:18<02:08, 11.69s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 172/182 [35:28<01:51, 11.12s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 173/182 [35:43<01:51, 12.34s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 174/182 [35:55<01:37, 12.16s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 175/182 [36:06<01:22, 11.74s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 176/182 [36:13<01:02, 10.42s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 177/182 [36:24<00:53, 10.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 178/182 [36:37<00:45, 11.46s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 179/182 [36:45<00:31, 10.36s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 180/182 [36:59<00:22, 11.41s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 181/182 [37:04<00:09,  9.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182/182 [37:10<00:00,  8.30s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182/182 [37:10<00:00, 12.25s/it]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispri/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispri/splits/tiankampmann2021_crispri_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_031244-4lljl84s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRi_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/4lljl84s
  0%|          | 0/3277 [00:00<?, ?it/s]  0%|          | 6/3277 [00:00<01:02, 52.29it/s]  0%|          | 15/3277 [00:00<00:46, 69.42it/s]  1%|          | 22/3277 [00:00<00:49, 66.22it/s]  1%|          | 33/3277 [00:00<00:40, 79.44it/s]  1%|â–         | 42/3277 [00:00<00:39, 82.49it/s]  2%|â–         | 51/3277 [00:00<00:38, 84.75it/s]  2%|â–         | 60/3277 [00:00<00:38, 83.78it/s]  2%|â–         | 70/3277 [00:00<00:37, 85.96it/s]  2%|â–         | 79/3277 [00:00<00:37, 86.07it/s]  3%|â–Ž         | 88/3277 [00:01<00:38, 82.13it/s]  3%|â–Ž         | 97/3277 [00:01<00:38, 81.94it/s]  3%|â–Ž         | 106/3277 [00:01<00:38, 83.26it/s]  4%|â–Ž         | 115/3277 [00:01<00:38, 81.70it/s]  4%|â–         | 124/3277 [00:01<00:39, 79.29it/s]  4%|â–         | 133/3277 [00:01<00:38, 81.51it/s]  4%|â–         | 142/3277 [00:01<00:41, 76.02it/s]  5%|â–         | 150/3277 [00:01<00:41, 75.66it/s]  5%|â–         | 158/3277 [00:02<00:41, 74.98it/s]  5%|â–Œ         | 167/3277 [00:02<00:41, 74.31it/s]  5%|â–Œ         | 178/3277 [00:02<00:37, 81.75it/s]  6%|â–Œ         | 188/3277 [00:02<00:36, 84.10it/s]  6%|â–Œ         | 199/3277 [00:02<00:35, 87.25it/s]  6%|â–‹         | 208/3277 [00:02<00:34, 87.71it/s]  7%|â–‹         | 217/3277 [00:02<00:35, 86.46it/s]  7%|â–‹         | 226/3277 [00:02<00:35, 84.85it/s]  7%|â–‹         | 235/3277 [00:02<00:37, 81.78it/s]  7%|â–‹         | 245/3277 [00:03<00:36, 84.21it/s]  8%|â–Š         | 254/3277 [00:03<00:37, 80.60it/s]  8%|â–Š         | 264/3277 [00:03<00:37, 81.21it/s]  8%|â–Š         | 274/3277 [00:03<00:35, 84.18it/s]  9%|â–Š         | 283/3277 [00:03<00:37, 80.88it/s]  9%|â–‰         | 292/3277 [00:03<00:39, 74.81it/s]  9%|â–‰         | 300/3277 [00:03<00:40, 72.97it/s]  9%|â–‰         | 308/3277 [00:03<00:42, 70.64it/s] 10%|â–‰         | 316/3277 [00:03<00:41, 72.07it/s] 10%|â–‰         | 324/3277 [00:04<00:47, 62.51it/s] 10%|â–ˆ         | 333/3277 [00:04<00:43, 68.21it/s] 10%|â–ˆ         | 342/3277 [00:04<00:39, 73.40it/s] 11%|â–ˆ         | 351/3277 [00:04<00:37, 77.22it/s] 11%|â–ˆ         | 359/3277 [00:04<00:47, 61.25it/s] 11%|â–ˆâ–        | 375/3277 [00:04<00:34, 83.09it/s] 12%|â–ˆâ–        | 385/3277 [00:04<00:33, 86.61it/s] 12%|â–ˆâ–        | 395/3277 [00:04<00:33, 85.03it/s] 12%|â–ˆâ–        | 404/3277 [00:05<00:33, 85.20it/s] 13%|â–ˆâ–Ž        | 413/3277 [00:05<00:33, 86.14it/s] 13%|â–ˆâ–Ž        | 423/3277 [00:05<00:32, 88.38it/s] 13%|â–ˆâ–Ž        | 433/3277 [00:05<00:32, 86.23it/s] 13%|â–ˆâ–Ž        | 442/3277 [00:05<00:32, 86.98it/s] 14%|â–ˆâ–        | 451/3277 [00:05<00:32, 86.76it/s] 14%|â–ˆâ–        | 461/3277 [00:05<00:32, 86.31it/s] 14%|â–ˆâ–        | 470/3277 [00:05<00:32, 86.50it/s] 15%|â–ˆâ–        | 480/3277 [00:05<00:31, 87.93it/s] 15%|â–ˆâ–        | 489/3277 [00:06<00:31, 87.55it/s] 15%|â–ˆâ–Œ        | 500/3277 [00:06<00:31, 88.97it/s] 16%|â–ˆâ–Œ        | 509/3277 [00:06<00:31, 89.25it/s] 16%|â–ˆâ–Œ        | 518/3277 [00:06<00:31, 88.90it/s] 16%|â–ˆâ–Œ        | 528/3277 [00:06<00:30, 89.23it/s] 16%|â–ˆâ–‹        | 538/3277 [00:06<00:30, 88.53it/s] 17%|â–ˆâ–‹        | 548/3277 [00:06<00:30, 89.31it/s] 17%|â–ˆâ–‹        | 558/3277 [00:06<00:30, 88.98it/s] 17%|â–ˆâ–‹        | 567/3277 [00:06<00:31, 86.15it/s] 18%|â–ˆâ–Š        | 578/3277 [00:07<00:30, 89.96it/s] 18%|â–ˆâ–Š        | 588/3277 [00:07<00:30, 89.24it/s] 18%|â–ˆâ–Š        | 598/3277 [00:07<00:29, 90.22it/s] 19%|â–ˆâ–Š        | 608/3277 [00:07<00:29, 90.03it/s] 19%|â–ˆâ–‰        | 618/3277 [00:07<00:29, 91.13it/s] 19%|â–ˆâ–‰        | 628/3277 [00:07<00:29, 90.75it/s] 19%|â–ˆâ–‰        | 639/3277 [00:07<00:28, 94.09it/s] 20%|â–ˆâ–‰        | 649/3277 [00:07<00:29, 90.55it/s] 20%|â–ˆâ–ˆ        | 659/3277 [00:07<00:28, 92.17it/s] 20%|â–ˆâ–ˆ        | 669/3277 [00:08<00:28, 91.84it/s] 21%|â–ˆâ–ˆ        | 679/3277 [00:08<00:29, 87.28it/s] 21%|â–ˆâ–ˆ        | 689/3277 [00:08<00:28, 90.64it/s] 21%|â–ˆâ–ˆâ–       | 699/3277 [00:08<00:27, 92.26it/s] 22%|â–ˆâ–ˆâ–       | 710/3277 [00:08<00:26, 95.67it/s] 22%|â–ˆâ–ˆâ–       | 720/3277 [00:08<00:27, 91.37it/s] 22%|â–ˆâ–ˆâ–       | 731/3277 [00:08<00:27, 92.69it/s] 23%|â–ˆâ–ˆâ–Ž       | 742/3277 [00:08<00:27, 93.51it/s] 23%|â–ˆâ–ˆâ–Ž       | 752/3277 [00:08<00:26, 93.77it/s] 23%|â–ˆâ–ˆâ–Ž       | 763/3277 [00:09<00:26, 93.80it/s] 24%|â–ˆâ–ˆâ–Ž       | 774/3277 [00:09<00:25, 96.86it/s] 24%|â–ˆâ–ˆâ–       | 784/3277 [00:09<00:25, 96.74it/s] 24%|â–ˆâ–ˆâ–       | 794/3277 [00:09<00:26, 93.67it/s] 25%|â–ˆâ–ˆâ–       | 804/3277 [00:09<00:26, 91.66it/s] 25%|â–ˆâ–ˆâ–       | 815/3277 [00:09<00:26, 94.42it/s] 25%|â–ˆâ–ˆâ–Œ       | 825/3277 [00:09<00:25, 94.36it/s] 26%|â–ˆâ–ˆâ–Œ       | 836/3277 [00:09<00:25, 97.33it/s] 26%|â–ˆâ–ˆâ–Œ       | 846/3277 [00:09<00:25, 93.87it/s] 26%|â–ˆâ–ˆâ–Œ       | 857/3277 [00:10<00:24, 97.55it/s] 26%|â–ˆâ–ˆâ–‹       | 867/3277 [00:10<00:26, 91.03it/s] 27%|â–ˆâ–ˆâ–‹       | 878/3277 [00:10<00:25, 94.72it/s] 27%|â–ˆâ–ˆâ–‹       | 889/3277 [00:10<00:25, 94.09it/s] 27%|â–ˆâ–ˆâ–‹       | 900/3277 [00:10<00:24, 96.25it/s] 28%|â–ˆâ–ˆâ–Š       | 910/3277 [00:10<00:25, 94.56it/s] 28%|â–ˆâ–ˆâ–Š       | 920/3277 [00:10<00:25, 90.95it/s] 28%|â–ˆâ–ˆâ–Š       | 931/3277 [00:10<00:25, 92.14it/s] 29%|â–ˆâ–ˆâ–Š       | 941/3277 [00:10<00:25, 92.71it/s] 29%|â–ˆâ–ˆâ–‰       | 951/3277 [00:11<00:25, 92.48it/s] 29%|â–ˆâ–ˆâ–‰       | 961/3277 [00:11<00:24, 93.17it/s] 30%|â–ˆâ–ˆâ–‰       | 972/3277 [00:11<00:23, 96.95it/s] 30%|â–ˆâ–ˆâ–‰       | 982/3277 [00:11<00:24, 93.78it/s] 30%|â–ˆâ–ˆâ–ˆ       | 992/3277 [00:11<00:24, 94.83it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1002/3277 [00:11<00:24, 92.04it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1013/3277 [00:11<00:23, 95.99it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1024/3277 [00:11<00:22, 98.96it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1034/3277 [00:11<00:23, 95.59it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1046/3277 [00:12<00:23, 96.94it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1056/3277 [00:12<00:22, 96.83it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1068/3277 [00:12<00:22, 98.24it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1078/3277 [00:12<00:22, 97.83it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1088/3277 [00:12<00:22, 97.82it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1099/3277 [00:12<00:21, 100.32it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1110/3277 [00:12<00:22, 96.69it/s]  34%|â–ˆâ–ˆâ–ˆâ–      | 1120/3277 [00:12<00:22, 97.32it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1130/3277 [00:12<00:22, 97.49it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1141/3277 [00:13<00:21, 100.68it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1152/3277 [00:13<00:21, 96.75it/s]  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1162/3277 [00:13<00:21, 97.38it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1173/3277 [00:13<00:21, 98.95it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1183/3277 [00:13<00:21, 98.14it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1193/3277 [00:13<00:21, 96.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1203/3277 [00:13<00:21, 95.87it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1213/3277 [00:13<00:21, 96.84it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1224/3277 [00:13<00:20, 99.76it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1234/3277 [00:13<00:20, 99.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1244/3277 [00:14<00:21, 96.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1254/3277 [00:14<00:21, 96.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1265/3277 [00:14<00:20, 95.93it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1275/3277 [00:14<00:20, 96.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1285/3277 [00:14<00:20, 96.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1295/3277 [00:14<00:20, 96.70it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1306/3277 [00:14<00:20, 97.74it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1316/3277 [00:14<00:20, 97.60it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1326/3277 [00:14<00:19, 97.74it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1337/3277 [00:15<00:19, 100.99it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1348/3277 [00:15<00:19, 97.12it/s]  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1359/3277 [00:15<00:19, 98.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1369/3277 [00:15<00:19, 96.25it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1382/3277 [00:15<00:18, 100.27it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1393/3277 [00:15<00:18, 99.56it/s]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1403/3277 [00:15<00:18, 99.29it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1413/3277 [00:15<00:18, 98.69it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1424/3277 [00:15<00:18, 98.96it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1435/3277 [00:16<00:18, 100.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1446/3277 [00:16<00:18, 99.62it/s]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1457/3277 [00:16<00:18, 100.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1468/3277 [00:16<00:18, 99.49it/s]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1478/3277 [00:16<00:18, 98.80it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1489/3277 [00:16<00:17, 100.87it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1500/3277 [00:16<00:18, 96.69it/s]  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1511/3277 [00:16<00:18, 98.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1522/3277 [00:16<00:17, 98.61it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1533/3277 [00:17<00:17, 98.79it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1543/3277 [00:17<00:17, 98.13it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1553/3277 [00:17<00:17, 97.93it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1563/3277 [00:17<00:17, 97.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1575/3277 [00:17<00:16, 100.91it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1586/3277 [00:17<00:17, 97.69it/s]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1597/3277 [00:17<00:16, 100.68it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1608/3277 [00:17<00:17, 95.38it/s]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1619/3277 [00:17<00:17, 93.61it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1632/3277 [00:18<00:16, 100.62it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1643/3277 [00:18<00:16, 99.81it/s]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1654/3277 [00:18<00:15, 101.81it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1665/3277 [00:18<00:15, 101.57it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1676/3277 [00:18<00:15, 100.58it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1687/3277 [00:18<00:19, 82.72it/s]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1707/3277 [00:18<00:14, 110.83it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1720/3277 [00:18<00:14, 108.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1732/3277 [00:18<00:14, 108.47it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1744/3277 [00:19<00:14, 105.96it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1755/3277 [00:19<00:14, 102.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1766/3277 [00:19<00:14, 103.20it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1777/3277 [00:19<00:14, 101.78it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1788/3277 [00:19<00:14, 101.14it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1799/3277 [00:19<00:14, 102.51it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1810/3277 [00:19<00:14, 99.57it/s]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1821/3277 [00:19<00:14, 99.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1831/3277 [00:19<00:14, 97.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1843/3277 [00:20<00:14, 99.70it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1853/3277 [00:20<00:14, 99.50it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1863/3277 [00:20<00:14, 99.39it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1873/3277 [00:20<00:14, 99.43it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1883/3277 [00:20<00:14, 97.22it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1894/3277 [00:20<00:13, 99.62it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1904/3277 [00:20<00:13, 99.61it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1914/3277 [00:20<00:13, 99.27it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1924/3277 [00:20<00:13, 98.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1935/3277 [00:21<00:13, 99.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1945/3277 [00:21<00:14, 94.50it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1956/3277 [00:21<00:13, 96.92it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1966/3277 [00:21<00:14, 92.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1976/3277 [00:21<00:15, 84.72it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1985/3277 [00:21<00:16, 80.50it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1994/3277 [00:21<00:16, 79.71it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2003/3277 [00:21<00:17, 74.90it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2011/3277 [00:22<00:16, 75.28it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2019/3277 [00:22<00:16, 74.16it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2027/3277 [00:22<00:17, 71.94it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2036/3277 [00:22<00:16, 75.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2044/3277 [00:22<00:16, 76.15it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2052/3277 [00:22<00:16, 74.38it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2060/3277 [00:22<00:16, 74.31it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2068/3277 [00:22<00:15, 75.71it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2076/3277 [00:22<00:16, 71.86it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2084/3277 [00:23<00:16, 70.27it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2093/3277 [00:23<00:16, 73.70it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2102/3277 [00:23<00:15, 76.30it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2113/3277 [00:23<00:13, 83.44it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2122/3277 [00:23<00:13, 85.12it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2131/3277 [00:23<00:13, 84.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2141/3277 [00:23<00:12, 88.73it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2151/3277 [00:23<00:12, 90.23it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2161/3277 [00:23<00:12, 87.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2171/3277 [00:23<00:12, 89.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2181/3277 [00:24<00:12, 90.50it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2191/3277 [00:24<00:11, 93.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2201/3277 [00:24<00:11, 90.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2211/3277 [00:24<00:11, 92.78it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2222/3277 [00:24<00:11, 92.86it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2232/3277 [00:24<00:11, 94.08it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2243/3277 [00:24<00:10, 96.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2253/3277 [00:24<00:10, 93.98it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2263/3277 [00:24<00:10, 94.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2274/3277 [00:25<00:10, 96.97it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2284/3277 [00:25<00:10, 97.49it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2294/3277 [00:25<00:10, 93.76it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2304/3277 [00:25<00:10, 89.64it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2316/3277 [00:25<00:10, 95.65it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2327/3277 [00:25<00:09, 97.91it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2337/3277 [00:25<00:09, 97.99it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2347/3277 [00:25<00:09, 97.01it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2357/3277 [00:25<00:09, 94.66it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2368/3277 [00:26<00:09, 97.27it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2378/3277 [00:26<00:09, 96.64it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2388/3277 [00:26<00:09, 94.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2398/3277 [00:26<00:09, 94.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2408/3277 [00:26<00:09, 95.60it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2418/3277 [00:26<00:09, 94.62it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2428/3277 [00:26<00:08, 94.93it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2439/3277 [00:26<00:08, 95.87it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2449/3277 [00:26<00:08, 95.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2461/3277 [00:27<00:08, 99.45it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2471/3277 [00:27<00:08, 95.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2481/3277 [00:27<00:08, 94.56it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2493/3277 [00:27<00:07, 100.57it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2504/3277 [00:27<00:07, 97.23it/s]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2515/3277 [00:27<00:07, 98.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2526/3277 [00:27<00:07, 100.55it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2537/3277 [00:27<00:07, 102.14it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2548/3277 [00:27<00:07, 100.66it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2559/3277 [00:28<00:07, 98.78it/s]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2570/3277 [00:28<00:07, 97.15it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2581/3277 [00:28<00:07, 99.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2591/3277 [00:28<00:07, 95.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2601/3277 [00:28<00:07, 95.87it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2611/3277 [00:28<00:06, 96.92it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2622/3277 [00:28<00:06, 98.64it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2632/3277 [00:28<00:06, 95.28it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2642/3277 [00:28<00:06, 95.92it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2652/3277 [00:28<00:06, 92.74it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2663/3277 [00:29<00:06, 97.12it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2673/3277 [00:29<00:06, 92.65it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2683/3277 [00:29<00:06, 94.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2694/3277 [00:29<00:06, 96.36it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2704/3277 [00:29<00:05, 96.20it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2714/3277 [00:29<00:05, 96.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2724/3277 [00:29<00:05, 93.12it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2734/3277 [00:29<00:05, 94.45it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2744/3277 [00:29<00:05, 93.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2754/3277 [00:30<00:06, 84.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2763/3277 [00:30<00:06, 81.94it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2772/3277 [00:30<00:06, 80.36it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2782/3277 [00:30<00:06, 81.59it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2793/3277 [00:30<00:05, 87.28it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2802/3277 [00:30<00:05, 84.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2814/3277 [00:30<00:04, 92.90it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2824/3277 [00:30<00:04, 92.75it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2834/3277 [00:30<00:04, 93.58it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2844/3277 [00:31<00:04, 93.01it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2854/3277 [00:31<00:04, 93.19it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2864/3277 [00:31<00:04, 93.81it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2874/3277 [00:31<00:04, 93.50it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2884/3277 [00:31<00:04, 93.93it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2894/3277 [00:31<00:04, 93.15it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2904/3277 [00:31<00:04, 92.85it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2914/3277 [00:31<00:03, 93.66it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2924/3277 [00:31<00:03, 91.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2934/3277 [00:32<00:03, 93.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2944/3277 [00:32<00:03, 93.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2955/3277 [00:32<00:03, 94.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2965/3277 [00:32<00:03, 92.44it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2975/3277 [00:32<00:03, 93.30it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2986/3277 [00:32<00:03, 96.55it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2996/3277 [00:32<00:03, 93.56it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3007/3277 [00:32<00:02, 96.44it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3017/3277 [00:32<00:02, 93.25it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3027/3277 [00:33<00:02, 93.47it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3038/3277 [00:33<00:02, 95.50it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3048/3277 [00:33<00:02, 94.90it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3058/3277 [00:33<00:02, 92.36it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3069/3277 [00:33<00:02, 92.48it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3079/3277 [00:33<00:02, 92.64it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3090/3277 [00:33<00:02, 93.40it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3100/3277 [00:33<00:01, 93.34it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3111/3277 [00:33<00:01, 96.46it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3121/3277 [00:34<00:01, 92.43it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3132/3277 [00:34<00:01, 95.23it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3142/3277 [00:34<00:01, 94.63it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3152/3277 [00:34<00:01, 91.18it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3162/3277 [00:34<00:01, 92.73it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3172/3277 [00:34<00:01, 91.57it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3182/3277 [00:34<00:01, 82.84it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3191/3277 [00:34<00:01, 78.84it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3200/3277 [00:35<00:00, 78.74it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3208/3277 [00:35<00:00, 74.89it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3217/3277 [00:35<00:00, 77.75it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3225/3277 [00:35<00:00, 74.72it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3234/3277 [00:35<00:00, 74.36it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3242/3277 [00:35<00:00, 73.74it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3250/3277 [00:35<00:00, 73.62it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3258/3277 [00:35<00:00, 73.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3266/3277 [00:35<00:00, 71.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3274/3277 [00:36<00:00, 70.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3277/3277 [00:36<00:00, 90.82it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 1.1638
Epoch 1 Step 51 Train Loss: 0.6535
Epoch 1 Step 101 Train Loss: 0.6566
Epoch 1 Step 151 Train Loss: 0.7211
Epoch 1 Step 201 Train Loss: 0.6549
Epoch 1 Step 251 Train Loss: 0.6668
Epoch 1 Step 301 Train Loss: 0.6593
Epoch 1: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0158. 
Epoch 2 Step 1 Train Loss: 0.5768
Epoch 2 Step 51 Train Loss: 0.6225
Epoch 2 Step 101 Train Loss: 0.5897
Epoch 2 Step 151 Train Loss: 0.5874
Epoch 2 Step 201 Train Loss: 0.6325
Epoch 2 Step 251 Train Loss: 0.6194
Epoch 2 Step 301 Train Loss: 0.5758
Epoch 2: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0162 Validation Top 20 DE MSE: 0.0154. 
Epoch 3 Step 1 Train Loss: 0.5843
Epoch 3 Step 51 Train Loss: 0.6321
Epoch 3 Step 101 Train Loss: 0.5984
Epoch 3 Step 151 Train Loss: 0.6039
Epoch 3 Step 201 Train Loss: 0.6069
Epoch 3 Step 251 Train Loss: 0.6266
Epoch 3 Step 301 Train Loss: 0.6309
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0156. 
Epoch 4 Step 1 Train Loss: 0.5767
Epoch 4 Step 51 Train Loss: 0.6307
Epoch 4 Step 101 Train Loss: 0.6170
Epoch 4 Step 151 Train Loss: 0.5692
Epoch 4 Step 201 Train Loss: 0.6026
Epoch 4 Step 251 Train Loss: 0.5970
Epoch 4 Step 301 Train Loss: 0.6181
Epoch 4: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0133 Validation Top 20 DE MSE: 0.0160. 
Epoch 5 Step 1 Train Loss: 0.6007
Epoch 5 Step 51 Train Loss: 0.6265
Epoch 5 Step 101 Train Loss: 0.5764
Epoch 5 Step 151 Train Loss: 0.6192
Epoch 5 Step 201 Train Loss: 0.5508
Epoch 5 Step 251 Train Loss: 0.6179
Epoch 5 Step 301 Train Loss: 0.5635
Epoch 5: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0150 Validation Top 20 DE MSE: 0.0156. 
Epoch 6 Step 1 Train Loss: 0.6067
Epoch 6 Step 51 Train Loss: 0.5973
Epoch 6 Step 101 Train Loss: 0.5956
Epoch 6 Step 151 Train Loss: 0.5732
Epoch 6 Step 201 Train Loss: 0.6056
Epoch 6 Step 251 Train Loss: 0.6211
Epoch 6 Step 301 Train Loss: 0.6027
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0156. 
Epoch 7 Step 1 Train Loss: 0.6503
Epoch 7 Step 51 Train Loss: 0.6074
Epoch 7 Step 101 Train Loss: 0.6276
Epoch 7 Step 151 Train Loss: 0.5850
Epoch 7 Step 201 Train Loss: 0.6180
Epoch 7 Step 251 Train Loss: 0.6515
Epoch 7 Step 301 Train Loss: 0.5757
Epoch 7: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0157. 
Epoch 8 Step 1 Train Loss: 0.6032
Epoch 8 Step 51 Train Loss: 0.5617
Epoch 8 Step 101 Train Loss: 0.6051
Epoch 8 Step 151 Train Loss: 0.6012
Epoch 8 Step 201 Train Loss: 0.5745
Epoch 8 Step 251 Train Loss: 0.5766
Epoch 8 Step 301 Train Loss: 0.6472
Epoch 8: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0157. 
Epoch 9 Step 1 Train Loss: 0.6098
Epoch 9 Step 51 Train Loss: 0.6226
Epoch 9 Step 101 Train Loss: 0.5857
Epoch 9 Step 151 Train Loss: 0.6058
Epoch 9 Step 201 Train Loss: 0.6285
Epoch 9 Step 251 Train Loss: 0.6468
Epoch 9 Step 301 Train Loss: 0.5790
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0157. 
Epoch 10 Step 1 Train Loss: 0.5612
Epoch 10 Step 51 Train Loss: 0.6143
Epoch 10 Step 101 Train Loss: 0.6040
Epoch 10 Step 151 Train Loss: 0.5995
Epoch 10 Step 201 Train Loss: 0.5802
Epoch 10 Step 251 Train Loss: 0.5456
Epoch 10 Step 301 Train Loss: 0.5704
Epoch 10: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0157. 
Epoch 11 Step 1 Train Loss: 0.6074
Epoch 11 Step 51 Train Loss: 0.5945
Epoch 11 Step 101 Train Loss: 0.6380
Epoch 11 Step 151 Train Loss: 0.5636
Epoch 11 Step 201 Train Loss: 0.6198
Epoch 11 Step 251 Train Loss: 0.5689
Epoch 11 Step 301 Train Loss: 0.5970
Epoch 11: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0156. 
Epoch 12 Step 1 Train Loss: 0.5952
Epoch 12 Step 51 Train Loss: 0.6000
Epoch 12 Step 101 Train Loss: 0.5962
Epoch 12 Step 151 Train Loss: 0.5984
Epoch 12 Step 201 Train Loss: 0.6471
Epoch 12 Step 251 Train Loss: 0.6005
Epoch 12 Step 301 Train Loss: 0.6006
Epoch 12: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0157. 
Epoch 13 Step 1 Train Loss: 0.6038
Epoch 13 Step 51 Train Loss: 0.5730
Epoch 13 Step 101 Train Loss: 0.5905
Epoch 13 Step 151 Train Loss: 0.5863
Epoch 13 Step 201 Train Loss: 0.5389
Epoch 13 Step 251 Train Loss: 0.5989
Epoch 13 Step 301 Train Loss: 0.6150
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0157. 
Epoch 14 Step 1 Train Loss: 0.5992
Epoch 14 Step 51 Train Loss: 0.5674
Epoch 14 Step 101 Train Loss: 0.6323
Epoch 14 Step 151 Train Loss: 0.6165
Epoch 14 Step 201 Train Loss: 0.6279
Epoch 14 Step 251 Train Loss: 0.6148
Epoch 14 Step 301 Train Loss: 0.6569
Epoch 14: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0157. 
Epoch 15 Step 1 Train Loss: 0.6172
Epoch 15 Step 51 Train Loss: 0.6009
Epoch 15 Step 101 Train Loss: 0.6062
Epoch 15 Step 151 Train Loss: 0.6528
Epoch 15 Step 201 Train Loss: 0.6361
Epoch 15 Step 251 Train Loss: 0.5918
Epoch 15 Step 301 Train Loss: 0.5546
Epoch 15: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0156. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0094
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0012891672
test_unseen_single_pearson: 0.9964537733178901
test_unseen_single_mse_de: 0.009448832
test_unseen_single_pearson_de: 0.9728179951431324
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.21765229915033835
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.31195652173913047
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9586956521739131
test_unseen_single_mse_top20_de_non_dropout: 0.011826975
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.017 MB uploadedwandb: | 0.001 MB of 0.021 MB uploadedwandb: / 0.020 MB of 0.021 MB uploadedwandb: - 0.020 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ƒâ–ˆâ–‚â–…â–‡â–â–ƒâ–ƒâ–‚â–‚â–„â–‚â–‚â–ƒâ–ƒ
wandb:                                             train_de_pearson â–ƒâ–â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–†â–‚â–‚â–ƒâ–â–â–â–â–â–‚â–â–â–‚â–
wandb:                                                train_pearson â–â–ƒâ–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                                                training_loss â–‡â–„â–†â–‡â–…â–ˆâ–†â–†â–„â–…â–‡â–‡â–ƒâ–†â–„â–…â–„â–…â–…â–…â–…â–…â–‚â–…â–†â–â–‚â–‡â–ƒâ–†â–„â–†â–‡â–…â–…â–„â–‚â–ƒâ–ƒâ–„
wandb:                                                   val_de_mse â–†â–â–„â–ˆâ–„â–„â–…â–…â–…â–…â–„â–…â–…â–…â–„
wandb:                                               val_de_pearson â–â–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                      val_mse â–ˆâ–„â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:                                                  val_pearson â–â–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00945
wandb:                                              test_de_pearson 0.97282
wandb:               test_frac_opposite_direction_top20_non_dropout 0.31196
wandb:                          test_frac_sigma_below_1_non_dropout 0.9587
wandb:                                                     test_mse 0.00129
wandb:                                test_mse_top20_de_non_dropout 0.01183
wandb:                                                 test_pearson 0.99645
wandb:                                           test_pearson_delta 0.21765
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.31196
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.9587
wandb:                                       test_unseen_single_mse 0.00129
wandb:                                    test_unseen_single_mse_de 0.00945
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01183
wandb:                                   test_unseen_single_pearson 0.99645
wandb:                                test_unseen_single_pearson_de 0.97282
wandb:                             test_unseen_single_pearson_delta 0.21765
wandb:                                                 train_de_mse 0.01065
wandb:                                             train_de_pearson 0.97252
wandb:                                                    train_mse 0.00126
wandb:                                                train_pearson 0.9965
wandb:                                                training_loss 0.60734
wandb:                                                   val_de_mse 0.01565
wandb:                                               val_de_pearson 0.96083
wandb:                                                      val_mse 0.00127
wandb:                                                  val_pearson 0.99648
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRi_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/4lljl84s
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_031244-4lljl84s/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispri/splits/tiankampmann2021_crispri_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_033539-o5ns3nmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRi_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/o5ns3nmg
Start Training...
Epoch 1 Step 1 Train Loss: 1.2452
Epoch 1 Step 51 Train Loss: 0.6454
Epoch 1 Step 101 Train Loss: 0.7259
Epoch 1 Step 151 Train Loss: 0.6422
Epoch 1 Step 201 Train Loss: 0.6684
Epoch 1 Step 251 Train Loss: 0.6597
Epoch 1 Step 301 Train Loss: 0.6192
Epoch 1: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0400. 
Epoch 2 Step 1 Train Loss: 0.6390
Epoch 2 Step 51 Train Loss: 0.6064
Epoch 2 Step 101 Train Loss: 0.6594
Epoch 2 Step 151 Train Loss: 0.5745
Epoch 2 Step 201 Train Loss: 0.6151
Epoch 2 Step 251 Train Loss: 0.6187
Epoch 2 Step 301 Train Loss: 0.6482
Epoch 2: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0394. 
Epoch 3 Step 1 Train Loss: 0.6600
Epoch 3 Step 51 Train Loss: 0.5781
Epoch 3 Step 101 Train Loss: 0.5959
Epoch 3 Step 151 Train Loss: 0.6108
Epoch 3 Step 201 Train Loss: 0.5716
Epoch 3 Step 251 Train Loss: 0.6432
Epoch 3 Step 301 Train Loss: 0.6480
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0391. 
Epoch 4 Step 1 Train Loss: 0.6524
Epoch 4 Step 51 Train Loss: 0.5402
Epoch 4 Step 101 Train Loss: 0.5992
Epoch 4 Step 151 Train Loss: 0.6123
Epoch 4 Step 201 Train Loss: 0.6008
Epoch 4 Step 251 Train Loss: 0.6931
Epoch 4 Step 301 Train Loss: 0.6115
Epoch 4: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0395. 
Epoch 5 Step 1 Train Loss: 0.5793
Epoch 5 Step 51 Train Loss: 0.5732
Epoch 5 Step 101 Train Loss: 0.6071
Epoch 5 Step 151 Train Loss: 0.6455
Epoch 5 Step 201 Train Loss: 0.6500
Epoch 5 Step 251 Train Loss: 0.6010
Epoch 5 Step 301 Train Loss: 0.6203
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0396. 
Epoch 6 Step 1 Train Loss: 0.5726
Epoch 6 Step 51 Train Loss: 0.6004
Epoch 6 Step 101 Train Loss: 0.6204
Epoch 6 Step 151 Train Loss: 0.6789
Epoch 6 Step 201 Train Loss: 0.6110
Epoch 6 Step 251 Train Loss: 0.5635
Epoch 6 Step 301 Train Loss: 0.5885
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0409. 
Epoch 7 Step 1 Train Loss: 0.6394
Epoch 7 Step 51 Train Loss: 0.6481
Epoch 7 Step 101 Train Loss: 0.5932
Epoch 7 Step 151 Train Loss: 0.6361
Epoch 7 Step 201 Train Loss: 0.6194
Epoch 7 Step 251 Train Loss: 0.6085
Epoch 7 Step 301 Train Loss: 0.6056
Epoch 7: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0395. 
Epoch 8 Step 1 Train Loss: 0.6139
Epoch 8 Step 51 Train Loss: 0.5971
Epoch 8 Step 101 Train Loss: 0.5863
Epoch 8 Step 151 Train Loss: 0.5725
Epoch 8 Step 201 Train Loss: 0.5902
Epoch 8 Step 251 Train Loss: 0.5998
Epoch 8 Step 301 Train Loss: 0.6195
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0390. 
Epoch 9 Step 1 Train Loss: 0.6063
Epoch 9 Step 51 Train Loss: 0.5697
Epoch 9 Step 101 Train Loss: 0.5553
Epoch 9 Step 151 Train Loss: 0.6049
Epoch 9 Step 201 Train Loss: 0.5968
Epoch 9 Step 251 Train Loss: 0.6428
Epoch 9 Step 301 Train Loss: 0.6260
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0390. 
Epoch 10 Step 1 Train Loss: 0.5535
Epoch 10 Step 51 Train Loss: 0.5756
Epoch 10 Step 101 Train Loss: 0.6347
Epoch 10 Step 151 Train Loss: 0.6090
Epoch 10 Step 201 Train Loss: 0.5514
Epoch 10 Step 251 Train Loss: 0.6594
Epoch 10 Step 301 Train Loss: 0.6060
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0388. 
Epoch 11 Step 1 Train Loss: 0.6267
Epoch 11 Step 51 Train Loss: 0.5963
Epoch 11 Step 101 Train Loss: 0.6334
Epoch 11 Step 151 Train Loss: 0.5996
Epoch 11 Step 201 Train Loss: 0.5841
Epoch 11 Step 251 Train Loss: 0.6031
Epoch 11 Step 301 Train Loss: 0.5639
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0390. 
Epoch 12 Step 1 Train Loss: 0.6162
Epoch 12 Step 51 Train Loss: 0.5857
Epoch 12 Step 101 Train Loss: 0.6264
Epoch 12 Step 151 Train Loss: 0.5863
Epoch 12 Step 201 Train Loss: 0.5517
Epoch 12 Step 251 Train Loss: 0.6271
Epoch 12 Step 301 Train Loss: 0.5577
Epoch 12: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0389. 
Epoch 13 Step 1 Train Loss: 0.6023
Epoch 13 Step 51 Train Loss: 0.5818
Epoch 13 Step 101 Train Loss: 0.6482
Epoch 13 Step 151 Train Loss: 0.6089
Epoch 13 Step 201 Train Loss: 0.6279
Epoch 13 Step 251 Train Loss: 0.6048
Epoch 13 Step 301 Train Loss: 0.5927
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0387. 
Epoch 14 Step 1 Train Loss: 0.5967
Epoch 14 Step 51 Train Loss: 0.5870
Epoch 14 Step 101 Train Loss: 0.6414
Epoch 14 Step 151 Train Loss: 0.6308
Epoch 14 Step 201 Train Loss: 0.5894
Epoch 14 Step 251 Train Loss: 0.5885
Epoch 14 Step 301 Train Loss: 0.5605
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0389. 
Epoch 15 Step 1 Train Loss: 0.6200
Epoch 15 Step 51 Train Loss: 0.5876
Epoch 15 Step 101 Train Loss: 0.5567
Epoch 15 Step 151 Train Loss: 0.6115
Epoch 15 Step 201 Train Loss: 0.6000
Epoch 15 Step 251 Train Loss: 0.6409
Epoch 15 Step 301 Train Loss: 0.5949
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0387. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0085
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0011690287
test_unseen_single_pearson: 0.9967696840457778
test_unseen_single_mse_de: 0.0084507195
test_unseen_single_pearson_de: 0.9750879965845831
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2647569197870925
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.25869565217391305
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9771739130434783
test_unseen_single_mse_top20_de_non_dropout: 0.010426646
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.019 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–„â–„â–„â–ƒâ–„â–‚â–‚â–â–â–â–â–â–â–
wandb:                                             train_de_pearson â–â–†â–…â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–‚â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                train_pearson â–â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–†â–†â–†â–ˆâ–†â–„â–„â–„â–‡â–†â–…â–„â–ƒâ–„â–„â–ƒâ–„â–â–ƒâ–ˆâ–…â–ƒâ–„â–…â–†â–â–ƒâ–†â–„â–ƒâ–„â–†â–†â–ƒâ–†â–ƒâ–„â–‚â–ƒâ–ƒ
wandb:                                                   val_de_mse â–…â–ƒâ–‚â–„â–„â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–
wandb:                                               val_de_pearson â–â–‡â–†â–‡â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                      val_mse â–ˆâ–†â–‚â–‚â–â–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                                  val_pearson â–â–„â–‡â–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00845
wandb:                                              test_de_pearson 0.97509
wandb:               test_frac_opposite_direction_top20_non_dropout 0.2587
wandb:                          test_frac_sigma_below_1_non_dropout 0.97717
wandb:                                                     test_mse 0.00117
wandb:                                test_mse_top20_de_non_dropout 0.01043
wandb:                                                 test_pearson 0.99677
wandb:                                           test_pearson_delta 0.26476
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.2587
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.97717
wandb:                                       test_unseen_single_mse 0.00117
wandb:                                    test_unseen_single_mse_de 0.00845
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01043
wandb:                                   test_unseen_single_pearson 0.99677
wandb:                                test_unseen_single_pearson_de 0.97509
wandb:                             test_unseen_single_pearson_delta 0.26476
wandb:                                                 train_de_mse 0.0099
wandb:                                             train_de_pearson 0.96954
wandb:                                                    train_mse 0.00122
wandb:                                                train_pearson 0.99662
wandb:                                                training_loss 0.63031
wandb:                                                   val_de_mse 0.03872
wandb:                                               val_de_pearson 0.97992
wandb:                                                      val_mse 0.00177
wandb:                                                  val_pearson 0.99504
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRi_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/o5ns3nmg
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_033539-o5ns3nmg/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispri/splits/tiankampmann2021_crispri_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_035732-m46beqll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRi_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/m46beqll
Start Training...
Epoch 1 Step 1 Train Loss: 1.2376
Epoch 1 Step 51 Train Loss: 0.6744
Epoch 1 Step 101 Train Loss: 0.6470
Epoch 1 Step 151 Train Loss: 0.6288
Epoch 1 Step 201 Train Loss: 0.6238
Epoch 1 Step 251 Train Loss: 0.6267
Epoch 1 Step 301 Train Loss: 0.6458
Epoch 1: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0120 Validation Top 20 DE MSE: 0.0059. 
Epoch 2 Step 1 Train Loss: 0.6320
Epoch 2 Step 51 Train Loss: 0.6381
Epoch 2 Step 101 Train Loss: 0.5945
Epoch 2 Step 151 Train Loss: 0.5839
Epoch 2 Step 201 Train Loss: 0.5958
Epoch 2 Step 251 Train Loss: 0.6337
Epoch 2 Step 301 Train Loss: 0.5903
Epoch 2: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0055. 
Epoch 3 Step 1 Train Loss: 0.6070
Epoch 3 Step 51 Train Loss: 0.6409
Epoch 3 Step 101 Train Loss: 0.6302
Epoch 3 Step 151 Train Loss: 0.6168
Epoch 3 Step 201 Train Loss: 0.6022
Epoch 3 Step 251 Train Loss: 0.6096
Epoch 3 Step 301 Train Loss: 0.6199
Epoch 3: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0054. 
Epoch 4 Step 1 Train Loss: 0.5564
Epoch 4 Step 51 Train Loss: 0.6619
Epoch 4 Step 101 Train Loss: 0.5925
Epoch 4 Step 151 Train Loss: 0.6029
Epoch 4 Step 201 Train Loss: 0.6146
Epoch 4 Step 251 Train Loss: 0.6044
Epoch 4 Step 301 Train Loss: 0.6252
Epoch 4: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.0053. 
Epoch 5 Step 1 Train Loss: 0.6430
Epoch 5 Step 51 Train Loss: 0.6453
Epoch 5 Step 101 Train Loss: 0.5953
Epoch 5 Step 151 Train Loss: 0.6615
Epoch 5 Step 201 Train Loss: 0.5741
Epoch 5 Step 251 Train Loss: 0.5685
Epoch 5 Step 301 Train Loss: 0.6183
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0053. 
Epoch 6 Step 1 Train Loss: 0.6346
Epoch 6 Step 51 Train Loss: 0.5767
Epoch 6 Step 101 Train Loss: 0.5760
Epoch 6 Step 151 Train Loss: 0.5642
Epoch 6 Step 201 Train Loss: 0.5896
Epoch 6 Step 251 Train Loss: 0.6055
Epoch 6 Step 301 Train Loss: 0.6045
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0053. 
Epoch 7 Step 1 Train Loss: 0.5426
Epoch 7 Step 51 Train Loss: 0.5869
Epoch 7 Step 101 Train Loss: 0.5902
Epoch 7 Step 151 Train Loss: 0.5914
Epoch 7 Step 201 Train Loss: 0.6124
Epoch 7 Step 251 Train Loss: 0.6461
Epoch 7 Step 301 Train Loss: 0.5543
Epoch 7: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0052. 
Epoch 8 Step 1 Train Loss: 0.6180
Epoch 8 Step 51 Train Loss: 0.6031
Epoch 8 Step 101 Train Loss: 0.5755
Epoch 8 Step 151 Train Loss: 0.6263
Epoch 8 Step 201 Train Loss: 0.6019
Epoch 8 Step 251 Train Loss: 0.5778
Epoch 8 Step 301 Train Loss: 0.6292
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0054. 
Epoch 9 Step 1 Train Loss: 0.5931
Epoch 9 Step 51 Train Loss: 0.5917
Epoch 9 Step 101 Train Loss: 0.6001
Epoch 9 Step 151 Train Loss: 0.5971
Epoch 9 Step 201 Train Loss: 0.6150
Epoch 9 Step 251 Train Loss: 0.6007
Epoch 9 Step 301 Train Loss: 0.6290
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0053. 
Epoch 10 Step 1 Train Loss: 0.5856
Epoch 10 Step 51 Train Loss: 0.5884
Epoch 10 Step 101 Train Loss: 0.5885
Epoch 10 Step 151 Train Loss: 0.6292
Epoch 10 Step 201 Train Loss: 0.6199
Epoch 10 Step 251 Train Loss: 0.5745
Epoch 10 Step 301 Train Loss: 0.6101
Epoch 10: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0053. 
Epoch 11 Step 1 Train Loss: 0.6089
Epoch 11 Step 51 Train Loss: 0.6584
Epoch 11 Step 101 Train Loss: 0.6446
Epoch 11 Step 151 Train Loss: 0.6127
Epoch 11 Step 201 Train Loss: 0.6351
Epoch 11 Step 251 Train Loss: 0.6252
Epoch 11 Step 301 Train Loss: 0.5552
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0053. 
Epoch 12 Step 1 Train Loss: 0.6222
Epoch 12 Step 51 Train Loss: 0.6058
Epoch 12 Step 101 Train Loss: 0.6279
Epoch 12 Step 151 Train Loss: 0.5525
Epoch 12 Step 201 Train Loss: 0.5935
Epoch 12 Step 251 Train Loss: 0.6200
Epoch 12 Step 301 Train Loss: 0.6171
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0054. 
Epoch 13 Step 1 Train Loss: 0.6058
Epoch 13 Step 51 Train Loss: 0.5576
Epoch 13 Step 101 Train Loss: 0.5640
Epoch 13 Step 151 Train Loss: 0.5775
Epoch 13 Step 201 Train Loss: 0.6015
Epoch 13 Step 251 Train Loss: 0.6194
Epoch 13 Step 301 Train Loss: 0.6146
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0053. 
Epoch 14 Step 1 Train Loss: 0.5830
Epoch 14 Step 51 Train Loss: 0.5892
Epoch 14 Step 101 Train Loss: 0.6698
Epoch 14 Step 151 Train Loss: 0.6335
Epoch 14 Step 201 Train Loss: 0.6065
Epoch 14 Step 251 Train Loss: 0.6664
Epoch 14 Step 301 Train Loss: 0.6092
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0053. 
Epoch 15 Step 1 Train Loss: 0.6372
Epoch 15 Step 51 Train Loss: 0.6282
Epoch 15 Step 101 Train Loss: 0.6066
Epoch 15 Step 151 Train Loss: 0.6281
Epoch 15 Step 201 Train Loss: 0.5706
Epoch 15 Step 251 Train Loss: 0.6283
Epoch 15 Step 301 Train Loss: 0.5955
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0053. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0122
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0012407542
test_unseen_single_pearson: 0.9965479050284014
test_unseen_single_mse_de: 0.012210888
test_unseen_single_pearson_de: 0.9697133550797681
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.23836525528336083
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.25869565217391305
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9804347826086959
test_unseen_single_mse_top20_de_non_dropout: 0.014343179
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.019 MB of 0.021 MB uploadedwandb: / 0.019 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–„â–‚â–â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–…â–ƒâ–â–â–ƒâ–‚
wandb:                                             train_de_pearson â–â–„â–†â–…â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–†â–ƒâ–…â–‚â–‚â–‚â–â–â–ƒâ–‚â–â–â–‚â–
wandb:                                                train_pearson â–â–ƒâ–†â–„â–‡â–‡â–‡â–ˆâ–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                                                training_loss â–…â–„â–ˆâ–‚â–…â–‚â–‚â–ƒâ–„â–…â–ƒâ–„â–…â–„â–„â–„â–†â–‚â–„â–‚â–â–ƒâ–ˆâ–ƒâ–â–„â–ƒâ–â–ƒâ–â–ƒâ–„â–…â–…â–ƒâ–„â–ƒâ–â–â–
wandb:                                                   val_de_mse â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚
wandb:                                               val_de_pearson â–â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                      val_mse â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                  val_pearson â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01221
wandb:                                              test_de_pearson 0.96971
wandb:               test_frac_opposite_direction_top20_non_dropout 0.2587
wandb:                          test_frac_sigma_below_1_non_dropout 0.98043
wandb:                                                     test_mse 0.00124
wandb:                                test_mse_top20_de_non_dropout 0.01434
wandb:                                                 test_pearson 0.99655
wandb:                                           test_pearson_delta 0.23837
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.2587
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.98043
wandb:                                       test_unseen_single_mse 0.00124
wandb:                                    test_unseen_single_mse_de 0.01221
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01434
wandb:                                   test_unseen_single_pearson 0.99655
wandb:                                test_unseen_single_pearson_de 0.96971
wandb:                             test_unseen_single_pearson_delta 0.23837
wandb:                                                 train_de_mse 0.0095
wandb:                                             train_de_pearson 0.97435
wandb:                                                    train_mse 0.00116
wandb:                                                train_pearson 0.99677
wandb:                                                training_loss 0.64164
wandb:                                                   val_de_mse 0.0053
wandb:                                               val_de_pearson 0.95302
wandb:                                                      val_mse 0.00118
wandb:                                                  val_pearson 0.99672
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRi_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/m46beqll
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_035732-m46beqll/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispri/splits/tiankampmann2021_crispri_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_041922-0ulsyu5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRi_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0ulsyu5m
Start Training...
Epoch 1 Step 1 Train Loss: 1.3196
Epoch 1 Step 51 Train Loss: 0.6689
Epoch 1 Step 101 Train Loss: 0.5963
Epoch 1 Step 151 Train Loss: 0.6657
Epoch 1 Step 201 Train Loss: 0.6351
Epoch 1 Step 251 Train Loss: 0.6576
Epoch 1 Step 301 Train Loss: 0.6210
Epoch 1: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0108. 
Epoch 2 Step 1 Train Loss: 0.6729
Epoch 2 Step 51 Train Loss: 0.6236
Epoch 2 Step 101 Train Loss: 0.5898
Epoch 2 Step 151 Train Loss: 0.6688
Epoch 2 Step 201 Train Loss: 0.5955
Epoch 2 Step 251 Train Loss: 0.6604
Epoch 2 Step 301 Train Loss: 0.6762
Epoch 2: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0100. 
Epoch 3 Step 1 Train Loss: 0.5881
Epoch 3 Step 51 Train Loss: 0.6249
Epoch 3 Step 101 Train Loss: 0.6423
Epoch 3 Step 151 Train Loss: 0.6231
Epoch 3 Step 201 Train Loss: 0.6536
Epoch 3 Step 251 Train Loss: 0.6026
Epoch 3 Step 301 Train Loss: 0.5677
Epoch 3: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0096. 
Epoch 4 Step 1 Train Loss: 0.6328
Epoch 4 Step 51 Train Loss: 0.6072
Epoch 4 Step 101 Train Loss: 0.6363
Epoch 4 Step 151 Train Loss: 0.6170
Epoch 4 Step 201 Train Loss: 0.6224
Epoch 4 Step 251 Train Loss: 0.6170
Epoch 4 Step 301 Train Loss: 0.5941
Epoch 4: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0128 Validation Top 20 DE MSE: 0.0097. 
Epoch 5 Step 1 Train Loss: 0.5877
Epoch 5 Step 51 Train Loss: 0.6067
Epoch 5 Step 101 Train Loss: 0.6240
Epoch 5 Step 151 Train Loss: 0.6314
Epoch 5 Step 201 Train Loss: 0.6450
Epoch 5 Step 251 Train Loss: 0.5688
Epoch 5 Step 301 Train Loss: 0.6313
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0099. 
Epoch 6 Step 1 Train Loss: 0.6356
Epoch 6 Step 51 Train Loss: 0.6182
Epoch 6 Step 101 Train Loss: 0.5709
Epoch 6 Step 151 Train Loss: 0.5544
Epoch 6 Step 201 Train Loss: 0.6600
Epoch 6 Step 251 Train Loss: 0.6528
Epoch 6 Step 301 Train Loss: 0.6315
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0098. 
Epoch 7 Step 1 Train Loss: 0.6163
Epoch 7 Step 51 Train Loss: 0.6275
Epoch 7 Step 101 Train Loss: 0.5983
Epoch 7 Step 151 Train Loss: 0.6331
Epoch 7 Step 201 Train Loss: 0.6479
Epoch 7 Step 251 Train Loss: 0.5649
Epoch 7 Step 301 Train Loss: 0.5978
Epoch 7: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0099. 
Epoch 8 Step 1 Train Loss: 0.6009
Epoch 8 Step 51 Train Loss: 0.5715
Epoch 8 Step 101 Train Loss: 0.6047
Epoch 8 Step 151 Train Loss: 0.5677
Epoch 8 Step 201 Train Loss: 0.6171
Epoch 8 Step 251 Train Loss: 0.6241
Epoch 8 Step 301 Train Loss: 0.6013
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0099. 
Epoch 9 Step 1 Train Loss: 0.6064
Epoch 9 Step 51 Train Loss: 0.6344
Epoch 9 Step 101 Train Loss: 0.5820
Epoch 9 Step 151 Train Loss: 0.5764
Epoch 9 Step 201 Train Loss: 0.6018
Epoch 9 Step 251 Train Loss: 0.6005
Epoch 9 Step 301 Train Loss: 0.6032
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0100. 
Epoch 10 Step 1 Train Loss: 0.6387
Epoch 10 Step 51 Train Loss: 0.6287
Epoch 10 Step 101 Train Loss: 0.6188
Epoch 10 Step 151 Train Loss: 0.6229
Epoch 10 Step 201 Train Loss: 0.6099
Epoch 10 Step 251 Train Loss: 0.5493
Epoch 10 Step 301 Train Loss: 0.5524
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0100. 
Epoch 11 Step 1 Train Loss: 0.6024
Epoch 11 Step 51 Train Loss: 0.6234
Epoch 11 Step 101 Train Loss: 0.6159
Epoch 11 Step 151 Train Loss: 0.6166
Epoch 11 Step 201 Train Loss: 0.5732
Epoch 11 Step 251 Train Loss: 0.5699
Epoch 11 Step 301 Train Loss: 0.6008
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0100. 
Epoch 12 Step 1 Train Loss: 0.5916
Epoch 12 Step 51 Train Loss: 0.6083
Epoch 12 Step 101 Train Loss: 0.6089
Epoch 12 Step 151 Train Loss: 0.6049
Epoch 12 Step 201 Train Loss: 0.5716
Epoch 12 Step 251 Train Loss: 0.6240
Epoch 12 Step 301 Train Loss: 0.6317
Epoch 12: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0099. 
Epoch 13 Step 1 Train Loss: 0.6036
Epoch 13 Step 51 Train Loss: 0.6240
Epoch 13 Step 101 Train Loss: 0.6312
Epoch 13 Step 151 Train Loss: 0.6262
Epoch 13 Step 201 Train Loss: 0.6158
Epoch 13 Step 251 Train Loss: 0.6088
Epoch 13 Step 301 Train Loss: 0.6361
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0100. 
Epoch 14 Step 1 Train Loss: 0.6147
Epoch 14 Step 51 Train Loss: 0.6157
Epoch 14 Step 101 Train Loss: 0.6075
Epoch 14 Step 151 Train Loss: 0.5786
Epoch 14 Step 201 Train Loss: 0.6162
Epoch 14 Step 251 Train Loss: 0.6257
Epoch 14 Step 301 Train Loss: 0.6035
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0099. 
Epoch 15 Step 1 Train Loss: 0.6042
Epoch 15 Step 51 Train Loss: 0.5952
Epoch 15 Step 101 Train Loss: 0.6287
Epoch 15 Step 151 Train Loss: 0.5741
Epoch 15 Step 201 Train Loss: 0.6528
Epoch 15 Step 251 Train Loss: 0.6116
Epoch 15 Step 301 Train Loss: 0.5911
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0099. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0092
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0011144087
test_unseen_single_pearson: 0.9968971730932052
test_unseen_single_mse_de: 0.009157122
test_unseen_single_pearson_de: 0.9718238613564215
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2590288360854194
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.257608695652174
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9826086956521741
test_unseen_single_mse_top20_de_non_dropout: 0.010884014
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.019 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–†â–…â–‚â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚
wandb:                                             train_de_pearson â–â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                train_pearson â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–…â–ˆâ–…â–…â–„â–…â–‚â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–„â–‚â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–„â–ƒ
wandb:                                                   val_de_mse â–ˆâ–ƒâ–â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                               val_de_pearson â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                      val_mse â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                  val_pearson â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00916
wandb:                                              test_de_pearson 0.97182
wandb:               test_frac_opposite_direction_top20_non_dropout 0.25761
wandb:                          test_frac_sigma_below_1_non_dropout 0.98261
wandb:                                                     test_mse 0.00111
wandb:                                test_mse_top20_de_non_dropout 0.01088
wandb:                                                 test_pearson 0.9969
wandb:                                           test_pearson_delta 0.25903
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.25761
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.98261
wandb:                                       test_unseen_single_mse 0.00111
wandb:                                    test_unseen_single_mse_de 0.00916
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01088
wandb:                                   test_unseen_single_pearson 0.9969
wandb:                                test_unseen_single_pearson_de 0.97182
wandb:                             test_unseen_single_pearson_delta 0.25903
wandb:                                                 train_de_mse 0.01004
wandb:                                             train_de_pearson 0.97137
wandb:                                                    train_mse 0.00121
wandb:                                                train_pearson 0.99664
wandb:                                                training_loss 0.61506
wandb:                                                   val_de_mse 0.00992
wandb:                                               val_de_pearson 0.96857
wandb:                                                      val_mse 0.00139
wandb:                                                  val_pearson 0.99616
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRi_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/0ulsyu5m
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_041922-0ulsyu5m/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2021_crispri/splits/tiankampmann2021_crispri_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_044027-8qgk0968
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2021_CRISPRi_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8qgk0968
Start Training...
Epoch 1 Step 1 Train Loss: 1.6858
Epoch 1 Step 51 Train Loss: 0.6960
Epoch 1 Step 101 Train Loss: 0.6433
Epoch 1 Step 151 Train Loss: 0.6506
Epoch 1 Step 201 Train Loss: 0.6647
Epoch 1 Step 251 Train Loss: 0.6357
Epoch 1 Step 301 Train Loss: 0.6617
Epoch 1: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0174. 
Epoch 2 Step 1 Train Loss: 0.6384
Epoch 2 Step 51 Train Loss: 0.6431
Epoch 2 Step 101 Train Loss: 0.6446
Epoch 2 Step 151 Train Loss: 0.5824
Epoch 2 Step 201 Train Loss: 0.6256
Epoch 2 Step 251 Train Loss: 0.6792
Epoch 2 Step 301 Train Loss: 0.6317
Epoch 2: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0168. 
Epoch 3 Step 1 Train Loss: 0.6402
Epoch 3 Step 51 Train Loss: 0.5936
Epoch 3 Step 101 Train Loss: 0.6258
Epoch 3 Step 151 Train Loss: 0.6061
Epoch 3 Step 201 Train Loss: 0.6175
Epoch 3 Step 251 Train Loss: 0.6160
Epoch 3 Step 301 Train Loss: 0.6163
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0178. 
Epoch 4 Step 1 Train Loss: 0.6926
Epoch 4 Step 51 Train Loss: 0.6503
Epoch 4 Step 101 Train Loss: 0.5882
Epoch 4 Step 151 Train Loss: 0.6265
Epoch 4 Step 201 Train Loss: 0.6069
Epoch 4 Step 251 Train Loss: 0.6467
Epoch 4 Step 301 Train Loss: 0.6381
Epoch 4: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0176. 
Epoch 5 Step 1 Train Loss: 0.5865
Epoch 5 Step 51 Train Loss: 0.6090
Epoch 5 Step 101 Train Loss: 0.5915
Epoch 5 Step 151 Train Loss: 0.6293
Epoch 5 Step 201 Train Loss: 0.6266
Epoch 5 Step 251 Train Loss: 0.6307
Epoch 5 Step 301 Train Loss: 0.5640
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0084 Validation Top 20 DE MSE: 0.0172. 
Epoch 6 Step 1 Train Loss: 0.6407
Epoch 6 Step 51 Train Loss: 0.6591
Epoch 6 Step 101 Train Loss: 0.5911
Epoch 6 Step 151 Train Loss: 0.6134
Epoch 6 Step 201 Train Loss: 0.6286
Epoch 6 Step 251 Train Loss: 0.6249
Epoch 6 Step 301 Train Loss: 0.5866
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0083 Validation Top 20 DE MSE: 0.0175. 
Epoch 7 Step 1 Train Loss: 0.6594
Epoch 7 Step 51 Train Loss: 0.5783
Epoch 7 Step 101 Train Loss: 0.6454
Epoch 7 Step 151 Train Loss: 0.5894
Epoch 7 Step 201 Train Loss: 0.6341
Epoch 7 Step 251 Train Loss: 0.5968
Epoch 7 Step 301 Train Loss: 0.6312
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0172. 
Epoch 8 Step 1 Train Loss: 0.6044
Epoch 8 Step 51 Train Loss: 0.6287
Epoch 8 Step 101 Train Loss: 0.5913
Epoch 8 Step 151 Train Loss: 0.6103
Epoch 8 Step 201 Train Loss: 0.5596
Epoch 8 Step 251 Train Loss: 0.6137
Epoch 8 Step 301 Train Loss: 0.6101
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0173. 
Epoch 9 Step 1 Train Loss: 0.6723
Epoch 9 Step 51 Train Loss: 0.5784
Epoch 9 Step 101 Train Loss: 0.6603
Epoch 9 Step 151 Train Loss: 0.6243
Epoch 9 Step 201 Train Loss: 0.6292
Epoch 9 Step 251 Train Loss: 0.5900
Epoch 9 Step 301 Train Loss: 0.6194
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0174. 
Epoch 10 Step 1 Train Loss: 0.6507
Epoch 10 Step 51 Train Loss: 0.5930
Epoch 10 Step 101 Train Loss: 0.6047
Epoch 10 Step 151 Train Loss: 0.6050
Epoch 10 Step 201 Train Loss: 0.5840
Epoch 10 Step 251 Train Loss: 0.5919
Epoch 10 Step 301 Train Loss: 0.6101
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0174. 
Epoch 11 Step 1 Train Loss: 0.6016
Epoch 11 Step 51 Train Loss: 0.6236
Epoch 11 Step 101 Train Loss: 0.6425
Epoch 11 Step 151 Train Loss: 0.5897
Epoch 11 Step 201 Train Loss: 0.6360
Epoch 11 Step 251 Train Loss: 0.5810
Epoch 11 Step 301 Train Loss: 0.5875
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0174. 
Epoch 12 Step 1 Train Loss: 0.5884
Epoch 12 Step 51 Train Loss: 0.6472
Epoch 12 Step 101 Train Loss: 0.5461
Epoch 12 Step 151 Train Loss: 0.5524
Epoch 12 Step 201 Train Loss: 0.6476
Epoch 12 Step 251 Train Loss: 0.5839
Epoch 12 Step 301 Train Loss: 0.6114
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0174. 
Epoch 13 Step 1 Train Loss: 0.5934
Epoch 13 Step 51 Train Loss: 0.5785
Epoch 13 Step 101 Train Loss: 0.6178
Epoch 13 Step 151 Train Loss: 0.6305
Epoch 13 Step 201 Train Loss: 0.5932
Epoch 13 Step 251 Train Loss: 0.6530
Epoch 13 Step 301 Train Loss: 0.6104
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0173. 
Epoch 14 Step 1 Train Loss: 0.5876
Epoch 14 Step 51 Train Loss: 0.6047
Epoch 14 Step 101 Train Loss: 0.6324
Epoch 14 Step 151 Train Loss: 0.5971
Epoch 14 Step 201 Train Loss: 0.6497
Epoch 14 Step 251 Train Loss: 0.5983
Epoch 14 Step 301 Train Loss: 0.5948
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0173. 
Epoch 15 Step 1 Train Loss: 0.6280
Epoch 15 Step 51 Train Loss: 0.5842
Epoch 15 Step 101 Train Loss: 0.5655
Epoch 15 Step 151 Train Loss: 0.5891
Epoch 15 Step 201 Train Loss: 0.6088
Epoch 15 Step 251 Train Loss: 0.6339
Epoch 15 Step 301 Train Loss: 0.5798
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0082 Validation Top 20 DE MSE: 0.0174. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0201
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00143537
test_unseen_single_pearson: 0.9959883403715482
test_unseen_single_mse_de: 0.020082071
test_unseen_single_pearson_de: 0.9629599733715442
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.26046903447204817
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2619565217391304
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9739130434782608
test_unseen_single_mse_top20_de_non_dropout: 0.021852605
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.019 MB of 0.021 MB uploadedwandb: / 0.019 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–„â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                                             train_de_pearson â–â–ƒâ–†â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                train_pearson â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–…â–ˆâ–†â–„â–„â–„â–‡â–…â–‚â–‚â–…â–‚â–ƒâ–„â–„â–„â–„â–â–ƒâ–‚â–„â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–â–ƒâ–„â–…â–„â–„â–ƒâ–„â–…â–„â–‚â–ƒ
wandb:                                                   val_de_mse â–…â–â–ˆâ–†â–„â–†â–„â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                                               val_de_pearson â–â–ˆâ–ƒâ–ƒâ–‡â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–†â–†
wandb:                                                      val_mse â–ˆâ–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                  val_pearson â–â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.02008
wandb:                                              test_de_pearson 0.96296
wandb:               test_frac_opposite_direction_top20_non_dropout 0.26196
wandb:                          test_frac_sigma_below_1_non_dropout 0.97391
wandb:                                                     test_mse 0.00144
wandb:                                test_mse_top20_de_non_dropout 0.02185
wandb:                                                 test_pearson 0.99599
wandb:                                           test_pearson_delta 0.26047
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.26196
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.97391
wandb:                                       test_unseen_single_mse 0.00144
wandb:                                    test_unseen_single_mse_de 0.02008
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.02185
wandb:                                   test_unseen_single_pearson 0.99599
wandb:                                test_unseen_single_pearson_de 0.96296
wandb:                             test_unseen_single_pearson_delta 0.26047
wandb:                                                 train_de_mse 0.00816
wandb:                                             train_de_pearson 0.97265
wandb:                                                    train_mse 0.00112
wandb:                                                train_pearson 0.99689
wandb:                                                training_loss 0.58889
wandb:                                                   val_de_mse 0.01738
wandb:                                               val_de_pearson 0.98153
wandb:                                                      val_mse 0.00138
wandb:                                                  val_pearson 0.99617
wandb: 
wandb: ðŸš€ View run TianKampmann2021_CRISPRi_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/8qgk0968
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_044027-8qgk0968/logs
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/207 [00:00<?, ?it/s]  0%|          | 1/207 [00:04<14:59,  4.37s/it]  1%|          | 2/207 [00:04<06:54,  2.02s/it]  1%|â–         | 3/207 [00:21<30:14,  8.89s/it]  2%|â–         | 4/207 [01:22<1:38:48, 29.20s/it]  2%|â–         | 5/207 [01:22<1:03:48, 18.95s/it]  3%|â–Ž         | 6/207 [01:24<43:39, 13.03s/it]    3%|â–Ž         | 7/207 [01:54<1:01:44, 18.52s/it]  4%|â–         | 8/207 [02:12<1:00:59, 18.39s/it]  4%|â–         | 9/207 [02:41<1:12:07, 21.86s/it]  5%|â–         | 10/207 [02:44<51:53, 15.81s/it]   5%|â–Œ         | 11/207 [03:47<1:39:00, 30.31s/it]  6%|â–Œ         | 12/207 [03:55<1:16:44, 23.61s/it]  6%|â–‹         | 13/207 [04:16<1:13:54, 22.86s/it]  7%|â–‹         | 14/207 [04:53<1:27:15, 27.13s/it]  7%|â–‹         | 15/207 [05:14<1:20:38, 25.20s/it]  8%|â–Š         | 16/207 [05:30<1:11:15, 22.39s/it]  8%|â–Š         | 17/207 [05:40<58:54, 18.60s/it]    9%|â–Š         | 18/207 [05:40<41:13, 13.09s/it]  9%|â–‰         | 19/207 [09:21<3:56:40, 75.53s/it] 10%|â–‰         | 20/207 [09:30<2:53:12, 55.58s/it] 10%|â–ˆ         | 21/207 [11:16<3:39:35, 70.84s/it] 11%|â–ˆ         | 22/207 [11:19<2:35:14, 50.35s/it] 11%|â–ˆ         | 23/207 [11:20<1:48:44, 35.46s/it] 12%|â–ˆâ–        | 24/207 [11:20<1:16:04, 24.94s/it] 12%|â–ˆâ–        | 25/207 [11:25<57:05, 18.82s/it]   13%|â–ˆâ–Ž        | 26/207 [11:50<1:02:56, 20.86s/it] 13%|â–ˆâ–Ž        | 27/207 [12:07<58:50, 19.61s/it]   14%|â–ˆâ–Ž        | 28/207 [12:40<1:10:06, 23.50s/it] 14%|â–ˆâ–        | 29/207 [12:42<51:26, 17.34s/it]   14%|â–ˆâ–        | 30/207 [12:51<43:16, 14.67s/it] 15%|â–ˆâ–        | 31/207 [12:58<36:36, 12.48s/it] 15%|â–ˆâ–Œ        | 32/207 [13:08<34:14, 11.74s/it] 16%|â–ˆâ–Œ        | 33/207 [13:17<31:08, 10.74s/it] 16%|â–ˆâ–‹        | 34/207 [13:20<24:36,  8.53s/it] 17%|â–ˆâ–‹        | 35/207 [13:22<18:33,  6.47s/it] 17%|â–ˆâ–‹        | 36/207 [13:22<13:18,  4.67s/it] 18%|â–ˆâ–Š        | 37/207 [13:23<09:39,  3.41s/it] 18%|â–ˆâ–Š        | 38/207 [13:27<10:45,  3.82s/it] 19%|â–ˆâ–‰        | 39/207 [13:32<11:06,  3.97s/it] 19%|â–ˆâ–‰        | 40/207 [13:43<17:02,  6.12s/it] 20%|â–ˆâ–‰        | 41/207 [13:45<13:28,  4.87s/it] 20%|â–ˆâ–ˆ        | 42/207 [13:51<14:36,  5.31s/it] 21%|â–ˆâ–ˆ        | 43/207 [13:54<12:46,  4.67s/it] 21%|â–ˆâ–ˆâ–       | 44/207 [13:56<09:59,  3.68s/it] 22%|â–ˆâ–ˆâ–       | 45/207 [14:01<10:54,  4.04s/it] 22%|â–ˆâ–ˆâ–       | 46/207 [14:03<09:38,  3.59s/it] 23%|â–ˆâ–ˆâ–Ž       | 47/207 [14:04<07:17,  2.73s/it] 23%|â–ˆâ–ˆâ–Ž       | 48/207 [14:04<05:28,  2.07s/it] 24%|â–ˆâ–ˆâ–Ž       | 49/207 [14:11<09:04,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 50/207 [14:11<06:28,  2.48s/it] 25%|â–ˆâ–ˆâ–       | 51/207 [14:16<07:48,  3.00s/it] 25%|â–ˆâ–ˆâ–Œ       | 52/207 [14:16<05:46,  2.23s/it] 26%|â–ˆâ–ˆâ–Œ       | 53/207 [14:17<04:27,  1.73s/it] 26%|â–ˆâ–ˆâ–Œ       | 54/207 [14:17<03:20,  1.31s/it] 27%|â–ˆâ–ˆâ–‹       | 55/207 [14:26<09:17,  3.67s/it] 27%|â–ˆâ–ˆâ–‹       | 56/207 [14:27<07:00,  2.78s/it] 28%|â–ˆâ–ˆâ–Š       | 57/207 [14:27<05:18,  2.12s/it] 28%|â–ˆâ–ˆâ–Š       | 58/207 [14:28<04:08,  1.66s/it] 29%|â–ˆâ–ˆâ–Š       | 59/207 [14:29<03:27,  1.40s/it] 29%|â–ˆâ–ˆâ–‰       | 60/207 [14:31<04:22,  1.78s/it] 29%|â–ˆâ–ˆâ–‰       | 61/207 [14:39<08:37,  3.55s/it] 30%|â–ˆâ–ˆâ–‰       | 62/207 [14:40<06:39,  2.76s/it] 30%|â–ˆâ–ˆâ–ˆ       | 63/207 [14:41<05:43,  2.38s/it] 31%|â–ˆâ–ˆâ–ˆ       | 64/207 [14:43<05:20,  2.24s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 65/207 [14:44<03:55,  1.66s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 66/207 [14:44<03:03,  1.30s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 67/207 [14:45<02:53,  1.24s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 68/207 [14:48<03:59,  1.72s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 69/207 [14:48<02:55,  1.27s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 70/207 [14:53<05:16,  2.31s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 71/207 [14:55<04:45,  2.10s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 72/207 [14:57<05:08,  2.29s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 73/207 [14:59<04:29,  2.01s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 74/207 [15:01<04:20,  1.96s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 75/207 [15:02<04:13,  1.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 76/207 [15:03<03:35,  1.65s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 77/207 [15:04<02:40,  1.24s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 78/207 [15:04<02:16,  1.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 79/207 [15:07<03:28,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 80/207 [15:09<03:16,  1.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 81/207 [15:14<05:31,  2.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 82/207 [15:16<05:13,  2.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 83/207 [15:16<03:51,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 84/207 [15:17<02:54,  1.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 85/207 [15:19<03:38,  1.79s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/207 [15:20<02:44,  1.36s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/207 [15:21<02:37,  1.31s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 88/207 [15:22<02:07,  1.07s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 89/207 [15:22<01:45,  1.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 90/207 [15:23<01:57,  1.00s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 91/207 [15:24<01:31,  1.27it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/207 [15:25<01:59,  1.04s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 93/207 [15:26<01:39,  1.14it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 94/207 [15:27<02:02,  1.09s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 95/207 [15:28<01:40,  1.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 96/207 [15:28<01:23,  1.33it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 97/207 [15:29<01:17,  1.42it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 98/207 [15:29<01:15,  1.45it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 99/207 [15:30<01:24,  1.27it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 100/207 [15:32<01:50,  1.03s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 101/207 [15:34<02:33,  1.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 102/207 [15:35<02:15,  1.29s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 103/207 [15:36<01:56,  1.12s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 104/207 [15:37<01:50,  1.08s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 105/207 [15:38<01:42,  1.00s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 106/207 [15:38<01:21,  1.24it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/207 [15:43<03:24,  2.05s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/207 [15:44<02:34,  1.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 109/207 [15:44<01:58,  1.21s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 110/207 [15:47<02:43,  1.68s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 111/207 [15:47<01:59,  1.24s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 112/207 [15:47<01:31,  1.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 113/207 [15:48<01:16,  1.23it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 114/207 [15:49<01:17,  1.20it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 115/207 [15:49<01:00,  1.53it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 116/207 [15:52<01:58,  1.30s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 117/207 [15:52<01:40,  1.11s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 118/207 [15:53<01:27,  1.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 119/207 [15:53<01:12,  1.21it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 120/207 [15:55<01:30,  1.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 121/207 [15:55<01:10,  1.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 122/207 [15:56<00:56,  1.50it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 123/207 [15:56<00:50,  1.66it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 124/207 [15:59<01:36,  1.16s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 125/207 [15:59<01:14,  1.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 126/207 [15:59<01:04,  1.26it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 127/207 [16:00<01:00,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/207 [16:00<00:50,  1.55it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/207 [16:02<01:15,  1.03it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 130/207 [16:03<01:12,  1.06it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 131/207 [16:04<01:01,  1.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 132/207 [16:04<00:48,  1.54it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 133/207 [16:04<00:45,  1.62it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 134/207 [16:05<00:53,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 135/207 [16:06<00:42,  1.69it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 136/207 [16:06<00:47,  1.49it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 137/207 [16:07<00:48,  1.45it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 138/207 [16:08<00:39,  1.76it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 139/207 [16:08<00:39,  1.73it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 140/207 [16:09<00:39,  1.68it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 141/207 [16:09<00:42,  1.55it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 142/207 [16:10<00:33,  1.93it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 143/207 [16:10<00:34,  1.85it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 144/207 [16:11<00:33,  1.88it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 145/207 [16:11<00:27,  2.28it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 146/207 [16:11<00:23,  2.62it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 147/207 [16:12<00:37,  1.59it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/207 [16:13<00:30,  1.95it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/207 [16:13<00:33,  1.74it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/207 [16:14<00:29,  1.93it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 151/207 [16:14<00:30,  1.85it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 152/207 [16:15<00:29,  1.85it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 153/207 [16:16<00:29,  1.82it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 154/207 [16:17<00:45,  1.18it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 155/207 [16:17<00:34,  1.49it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 156/207 [16:18<00:32,  1.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 157/207 [16:19<00:38,  1.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 158/207 [16:19<00:30,  1.61it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 159/207 [16:20<00:26,  1.80it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 160/207 [16:20<00:24,  1.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 161/207 [16:21<00:25,  1.82it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 162/207 [16:21<00:26,  1.69it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 163/207 [16:22<00:21,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 164/207 [16:22<00:20,  2.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 165/207 [16:22<00:18,  2.21it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 166/207 [16:23<00:18,  2.26it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 167/207 [16:24<00:22,  1.75it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 168/207 [16:24<00:21,  1.85it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/207 [16:25<00:17,  2.15it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 170/207 [16:25<00:19,  1.90it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 171/207 [16:26<00:22,  1.57it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 172/207 [16:26<00:17,  1.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 173/207 [16:27<00:14,  2.39it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 174/207 [16:27<00:14,  2.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 175/207 [16:28<00:14,  2.15it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 176/207 [16:28<00:14,  2.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 177/207 [16:28<00:11,  2.53it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 178/207 [16:29<00:13,  2.18it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 179/207 [16:30<00:16,  1.73it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 180/207 [16:30<00:12,  2.17it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 181/207 [16:31<00:13,  1.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 182/207 [16:31<00:11,  2.21it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 183/207 [16:31<00:10,  2.27it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 184/207 [16:32<00:09,  2.37it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 185/207 [16:32<00:07,  2.84it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 186/207 [16:32<00:06,  3.30it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 187/207 [16:32<00:07,  2.74it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 188/207 [16:33<00:06,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/207 [16:33<00:05,  3.35it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 190/207 [16:33<00:04,  3.76it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 191/207 [16:33<00:03,  4.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 192/207 [16:34<00:04,  3.30it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 193/207 [16:34<00:03,  3.72it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 194/207 [16:34<00:03,  3.92it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 195/207 [16:35<00:03,  3.32it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 196/207 [16:35<00:03,  3.17it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 197/207 [16:35<00:02,  3.61it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 198/207 [16:35<00:02,  3.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 199/207 [16:36<00:01,  4.13it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 200/207 [16:36<00:01,  4.41it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 201/207 [16:36<00:01,  3.92it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 202/207 [16:36<00:01,  4.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 203/207 [16:37<00:00,  4.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 204/207 [16:37<00:00,  4.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 205/207 [16:37<00:00,  4.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 206/207 [16:37<00:00,  4.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 207/207 [16:37<00:00,  4.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 207/207 [16:37<00:00,  4.82s/it]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_day7neuron/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_day7neuron/splits/tiankampmann2019_day7neuron_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:16
combo_seen1:76
combo_seen2:22
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_051913-jyxv2ttk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_day7neuron_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/jyxv2ttk
  0%|          | 0/3459 [00:00<?, ?it/s]  0%|          | 6/3459 [00:00<00:58, 58.88it/s]  0%|          | 17/3459 [00:00<00:39, 87.41it/s]  1%|          | 28/3459 [00:00<00:36, 93.85it/s]  1%|          | 39/3459 [00:00<00:35, 97.03it/s]  1%|â–         | 51/3459 [00:00<00:32, 104.56it/s]  2%|â–         | 62/3459 [00:00<00:32, 103.11it/s]  2%|â–         | 75/3459 [00:00<00:30, 109.17it/s]  2%|â–         | 86/3459 [00:00<00:31, 105.63it/s]  3%|â–Ž         | 98/3459 [00:00<00:31, 106.90it/s]  3%|â–Ž         | 110/3459 [00:01<00:30, 109.97it/s]  4%|â–Ž         | 122/3459 [00:01<00:30, 110.66it/s]  4%|â–         | 134/3459 [00:01<00:31, 106.01it/s]  4%|â–         | 147/3459 [00:01<00:29, 110.40it/s]  5%|â–         | 159/3459 [00:01<00:31, 106.33it/s]  5%|â–         | 172/3459 [00:01<00:30, 107.38it/s]  5%|â–Œ         | 184/3459 [00:01<00:29, 109.24it/s]  6%|â–Œ         | 196/3459 [00:01<00:29, 109.84it/s]  6%|â–Œ         | 208/3459 [00:01<00:29, 109.23it/s]  6%|â–‹         | 219/3459 [00:02<00:30, 106.84it/s]  7%|â–‹         | 231/3459 [00:02<00:29, 109.91it/s]  7%|â–‹         | 243/3459 [00:02<00:29, 108.94it/s]  7%|â–‹         | 254/3459 [00:02<00:32, 97.96it/s]   8%|â–Š         | 268/3459 [00:02<00:29, 108.51it/s]  8%|â–Š         | 280/3459 [00:02<00:29, 108.80it/s]  8%|â–Š         | 292/3459 [00:02<00:29, 106.19it/s]  9%|â–‰         | 303/3459 [00:02<00:29, 106.88it/s]  9%|â–‰         | 314/3459 [00:02<00:29, 106.49it/s]  9%|â–‰         | 325/3459 [00:03<00:29, 106.68it/s] 10%|â–‰         | 336/3459 [00:03<00:29, 106.63it/s] 10%|â–ˆ         | 348/3459 [00:03<00:28, 110.05it/s] 10%|â–ˆ         | 360/3459 [00:03<00:28, 109.16it/s] 11%|â–ˆ         | 371/3459 [00:03<00:28, 108.44it/s] 11%|â–ˆ         | 383/3459 [00:03<00:27, 110.75it/s] 11%|â–ˆâ–        | 395/3459 [00:03<00:27, 110.94it/s] 12%|â–ˆâ–        | 407/3459 [00:03<00:28, 107.53it/s] 12%|â–ˆâ–        | 419/3459 [00:03<00:27, 110.88it/s] 12%|â–ˆâ–        | 431/3459 [00:04<00:27, 110.92it/s] 13%|â–ˆâ–Ž        | 443/3459 [00:04<00:27, 111.05it/s] 13%|â–ˆâ–Ž        | 455/3459 [00:04<00:27, 107.97it/s] 14%|â–ˆâ–Ž        | 467/3459 [00:04<00:27, 109.85it/s] 14%|â–ˆâ–        | 479/3459 [00:04<00:27, 109.37it/s] 14%|â–ˆâ–        | 490/3459 [00:04<00:27, 109.06it/s] 14%|â–ˆâ–        | 501/3459 [00:04<00:27, 106.65it/s] 15%|â–ˆâ–        | 513/3459 [00:04<00:26, 109.26it/s] 15%|â–ˆâ–Œ        | 524/3459 [00:04<00:26, 109.19it/s] 15%|â–ˆâ–Œ        | 535/3459 [00:04<00:26, 108.55it/s] 16%|â–ˆâ–Œ        | 546/3459 [00:05<00:26, 108.66it/s] 16%|â–ˆâ–Œ        | 557/3459 [00:05<00:26, 108.15it/s] 16%|â–ˆâ–‹        | 568/3459 [00:05<00:26, 107.94it/s] 17%|â–ˆâ–‹        | 579/3459 [00:05<00:26, 108.53it/s] 17%|â–ˆâ–‹        | 590/3459 [00:05<00:26, 108.36it/s] 17%|â–ˆâ–‹        | 601/3459 [00:05<00:26, 108.69it/s] 18%|â–ˆâ–Š        | 612/3459 [00:05<00:26, 107.68it/s] 18%|â–ˆâ–Š        | 623/3459 [00:05<00:27, 103.47it/s] 18%|â–ˆâ–Š        | 634/3459 [00:05<00:26, 104.99it/s] 19%|â–ˆâ–Š        | 646/3459 [00:06<00:25, 109.27it/s] 19%|â–ˆâ–‰        | 657/3459 [00:06<00:25, 109.42it/s] 19%|â–ˆâ–‰        | 669/3459 [00:06<00:26, 107.18it/s] 20%|â–ˆâ–‰        | 681/3459 [00:06<00:26, 106.68it/s] 20%|â–ˆâ–ˆ        | 693/3459 [00:06<00:25, 109.11it/s] 20%|â–ˆâ–ˆ        | 704/3459 [00:06<00:25, 109.32it/s] 21%|â–ˆâ–ˆ        | 716/3459 [00:06<00:25, 106.83it/s] 21%|â–ˆâ–ˆ        | 729/3459 [00:06<00:24, 110.77it/s] 21%|â–ˆâ–ˆâ–       | 741/3459 [00:06<00:24, 110.61it/s] 22%|â–ˆâ–ˆâ–       | 753/3459 [00:07<00:25, 107.70it/s] 22%|â–ˆâ–ˆâ–       | 765/3459 [00:07<00:24, 110.03it/s] 22%|â–ˆâ–ˆâ–       | 777/3459 [00:07<00:24, 110.38it/s] 23%|â–ˆâ–ˆâ–Ž       | 789/3459 [00:07<00:24, 109.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 801/3459 [00:07<00:24, 110.56it/s] 24%|â–ˆâ–ˆâ–Ž       | 813/3459 [00:07<00:24, 110.02it/s] 24%|â–ˆâ–ˆâ–       | 825/3459 [00:07<00:23, 110.86it/s] 24%|â–ˆâ–ˆâ–       | 837/3459 [00:07<00:23, 109.95it/s] 25%|â–ˆâ–ˆâ–       | 849/3459 [00:07<00:24, 105.73it/s] 25%|â–ˆâ–ˆâ–       | 863/3459 [00:08<00:23, 110.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 875/3459 [00:08<00:23, 111.11it/s] 26%|â–ˆâ–ˆâ–Œ       | 887/3459 [00:08<00:23, 111.29it/s] 26%|â–ˆâ–ˆâ–Œ       | 900/3459 [00:08<00:22, 115.00it/s] 26%|â–ˆâ–ˆâ–‹       | 912/3459 [00:08<00:22, 113.09it/s] 27%|â–ˆâ–ˆâ–‹       | 924/3459 [00:08<00:22, 113.27it/s] 27%|â–ˆâ–ˆâ–‹       | 936/3459 [00:08<00:22, 113.07it/s] 27%|â–ˆâ–ˆâ–‹       | 948/3459 [00:08<00:22, 113.47it/s] 28%|â–ˆâ–ˆâ–Š       | 960/3459 [00:08<00:22, 112.41it/s] 28%|â–ˆâ–ˆâ–Š       | 972/3459 [00:08<00:22, 112.81it/s] 28%|â–ˆâ–ˆâ–Š       | 984/3459 [00:09<00:22, 108.39it/s] 29%|â–ˆâ–ˆâ–‰       | 997/3459 [00:09<00:22, 111.72it/s] 29%|â–ˆâ–ˆâ–‰       | 1009/3459 [00:09<00:22, 107.80it/s] 30%|â–ˆâ–ˆâ–‰       | 1022/3459 [00:09<00:22, 108.82it/s] 30%|â–ˆâ–ˆâ–‰       | 1034/3459 [00:09<00:21, 111.60it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1046/3459 [00:09<00:21, 111.83it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1058/3459 [00:09<00:21, 110.92it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1070/3459 [00:09<00:22, 108.16it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 1082/3459 [00:09<00:21, 111.32it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1094/3459 [00:10<00:21, 108.26it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1107/3459 [00:10<00:21, 109.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1119/3459 [00:10<00:21, 110.18it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1132/3459 [00:10<00:21, 110.44it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1144/3459 [00:10<00:21, 109.74it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1157/3459 [00:10<00:20, 110.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1169/3459 [00:10<00:20, 110.80it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1181/3459 [00:10<00:20, 113.25it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1193/3459 [00:10<00:20, 112.54it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1205/3459 [00:11<00:20, 112.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1217/3459 [00:11<00:20, 108.82it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1229/3459 [00:11<00:19, 111.71it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1241/3459 [00:11<00:20, 108.63it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1254/3459 [00:11<00:19, 112.12it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1266/3459 [00:11<00:20, 108.80it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1278/3459 [00:11<00:19, 109.57it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1290/3459 [00:11<00:19, 108.65it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1302/3459 [00:11<00:20, 107.02it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1315/3459 [00:12<00:19, 109.50it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1327/3459 [00:12<00:19, 109.88it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1339/3459 [00:12<00:19, 111.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1351/3459 [00:12<00:18, 112.02it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1363/3459 [00:12<00:18, 110.71it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1375/3459 [00:12<00:23, 87.11it/s]  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1396/3459 [00:12<00:17, 115.97it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1409/3459 [00:12<00:17, 117.16it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1422/3459 [00:13<00:17, 115.47it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1435/3459 [00:13<00:18, 112.24it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1448/3459 [00:13<00:17, 114.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1460/3459 [00:13<00:18, 110.91it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1472/3459 [00:13<00:18, 110.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1484/3459 [00:13<00:17, 110.69it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1496/3459 [00:13<00:17, 113.15it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1508/3459 [00:13<00:17, 112.37it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1520/3459 [00:13<00:17, 111.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1532/3459 [00:14<00:17, 110.77it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1544/3459 [00:14<00:17, 107.56it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1557/3459 [00:14<00:17, 108.50it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1568/3459 [00:14<00:18, 103.37it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1582/3459 [00:14<00:16, 112.45it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1594/3459 [00:14<00:17, 109.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1606/3459 [00:14<00:16, 111.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1618/3459 [00:14<00:16, 111.30it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1630/3459 [00:14<00:16, 108.88it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1641/3459 [00:15<00:17, 105.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1652/3459 [00:15<00:17, 104.14it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1666/3459 [00:15<00:15, 113.87it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1678/3459 [00:15<00:16, 109.67it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1690/3459 [00:15<00:16, 109.79it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1702/3459 [00:15<00:15, 111.27it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1714/3459 [00:15<00:15, 111.42it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1726/3459 [00:15<00:15, 111.28it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1738/3459 [00:15<00:15, 110.88it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1750/3459 [00:16<00:15, 110.12it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1762/3459 [00:16<00:15, 109.94it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1774/3459 [00:16<00:15, 109.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1785/3459 [00:16<00:15, 108.64it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1796/3459 [00:16<00:15, 106.37it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1807/3459 [00:16<00:15, 104.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1821/3459 [00:16<00:14, 111.28it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1833/3459 [00:16<00:14, 110.67it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1845/3459 [00:16<00:14, 111.83it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1857/3459 [00:17<00:14, 109.65it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1870/3459 [00:17<00:13, 113.64it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1882/3459 [00:17<00:14, 110.86it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1895/3459 [00:17<00:13, 114.85it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1907/3459 [00:17<00:13, 114.56it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1919/3459 [00:17<00:14, 108.68it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1933/3459 [00:17<00:13, 113.72it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1945/3459 [00:17<00:13, 111.10it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1959/3459 [00:17<00:13, 111.31it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1973/3459 [00:18<00:12, 116.11it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1985/3459 [00:18<00:13, 112.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1997/3459 [00:18<00:13, 112.21it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2010/3459 [00:18<00:12, 114.67it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2022/3459 [00:18<00:12, 113.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2034/3459 [00:18<00:12, 112.86it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2046/3459 [00:18<00:12, 109.93it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2058/3459 [00:18<00:12, 109.67it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2071/3459 [00:18<00:12, 113.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2083/3459 [00:19<00:12, 112.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2095/3459 [00:19<00:12, 111.93it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2107/3459 [00:19<00:12, 110.83it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2119/3459 [00:19<00:12, 107.70it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2131/3459 [00:19<00:11, 110.88it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2143/3459 [00:19<00:12, 105.92it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2156/3459 [00:19<00:12, 108.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2168/3459 [00:19<00:11, 109.52it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2181/3459 [00:19<00:11, 108.07it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2193/3459 [00:20<00:11, 110.67it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2206/3459 [00:20<00:11, 113.64it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2218/3459 [00:20<00:11, 110.66it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2230/3459 [00:20<00:11, 110.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2243/3459 [00:20<00:11, 109.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2256/3459 [00:20<00:10, 111.94it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2268/3459 [00:20<00:10, 110.11it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2280/3459 [00:20<00:10, 110.16it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2293/3459 [00:20<00:10, 113.94it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2306/3459 [00:21<00:09, 116.29it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2318/3459 [00:21<00:10, 112.78it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2331/3459 [00:21<00:09, 115.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2343/3459 [00:21<00:10, 111.05it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2355/3459 [00:21<00:09, 111.60it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2367/3459 [00:21<00:09, 113.76it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2379/3459 [00:21<00:09, 114.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2391/3459 [00:21<00:09, 110.57it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2404/3459 [00:21<00:09, 109.84it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2417/3459 [00:22<00:09, 113.01it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2429/3459 [00:22<00:09, 113.51it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2442/3459 [00:22<00:08, 115.83it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2454/3459 [00:22<00:08, 115.48it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2466/3459 [00:22<00:08, 111.32it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2479/3459 [00:22<00:08, 111.68it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2491/3459 [00:22<00:08, 111.66it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2503/3459 [00:22<00:08, 112.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2515/3459 [00:22<00:08, 112.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2528/3459 [00:23<00:08, 115.62it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2540/3459 [00:23<00:08, 109.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2554/3459 [00:23<00:07, 115.39it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2566/3459 [00:23<00:07, 112.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2579/3459 [00:23<00:07, 112.20it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2591/3459 [00:23<00:07, 111.64it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2603/3459 [00:23<00:07, 113.42it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2615/3459 [00:23<00:08, 103.96it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2626/3459 [00:23<00:08, 101.76it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2637/3459 [00:24<00:08, 99.06it/s]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2647/3459 [00:24<00:08, 94.85it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2657/3459 [00:24<00:08, 91.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2667/3459 [00:24<00:08, 91.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2679/3459 [00:24<00:08, 96.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2691/3459 [00:24<00:07, 101.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2704/3459 [00:24<00:07, 103.28it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2716/3459 [00:24<00:06, 106.76it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2730/3459 [00:24<00:06, 111.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2743/3459 [00:25<00:06, 116.33it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2755/3459 [00:25<00:06, 113.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2768/3459 [00:25<00:05, 117.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2780/3459 [00:25<00:06, 108.63it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2794/3459 [00:25<00:05, 116.69it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2807/3459 [00:25<00:05, 117.71it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2819/3459 [00:25<00:05, 115.48it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2831/3459 [00:25<00:05, 106.76it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2842/3459 [00:25<00:06, 100.64it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2853/3459 [00:26<00:06, 94.03it/s]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2863/3459 [00:26<00:06, 94.29it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2873/3459 [00:26<00:06, 88.55it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2882/3459 [00:26<00:06, 87.34it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2891/3459 [00:26<00:06, 84.78it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2900/3459 [00:26<00:06, 82.55it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2909/3459 [00:26<00:06, 82.23it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2918/3459 [00:26<00:06, 79.79it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2927/3459 [00:27<00:06, 81.69it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2936/3459 [00:27<00:06, 79.57it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2946/3459 [00:27<00:06, 84.21it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2955/3459 [00:27<00:06, 81.16it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2964/3459 [00:27<00:05, 82.85it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2973/3459 [00:27<00:05, 82.10it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2982/3459 [00:27<00:05, 83.75it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2991/3459 [00:27<00:05, 84.47it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3000/3459 [00:27<00:05, 82.07it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3009/3459 [00:28<00:05, 79.71it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3018/3459 [00:28<00:05, 82.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3027/3459 [00:28<00:05, 78.78it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3037/3459 [00:28<00:05, 81.60it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3046/3459 [00:28<00:05, 79.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3056/3459 [00:28<00:05, 80.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3066/3459 [00:28<00:04, 81.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3075/3459 [00:28<00:04, 82.68it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3084/3459 [00:28<00:04, 79.44it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3094/3459 [00:29<00:04, 83.22it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3103/3459 [00:29<00:04, 84.24it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3113/3459 [00:29<00:03, 87.61it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3122/3459 [00:29<00:04, 78.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3131/3459 [00:29<00:04, 81.78it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3140/3459 [00:29<00:03, 83.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3149/3459 [00:29<00:03, 82.82it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3158/3459 [00:29<00:03, 81.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3167/3459 [00:29<00:03, 82.18it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3176/3459 [00:30<00:03, 80.65it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3185/3459 [00:30<00:03, 80.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3194/3459 [00:30<00:03, 79.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3202/3459 [00:30<00:03, 73.17it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3211/3459 [00:30<00:03, 75.55it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3219/3459 [00:30<00:03, 74.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3228/3459 [00:30<00:03, 74.59it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3236/3459 [00:30<00:02, 75.70it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3244/3459 [00:30<00:02, 74.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3253/3459 [00:31<00:02, 75.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3261/3459 [00:31<00:02, 74.76it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3270/3459 [00:31<00:02, 73.21it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3279/3459 [00:31<00:02, 75.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3287/3459 [00:31<00:02, 76.52it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3295/3459 [00:31<00:02, 76.56it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3304/3459 [00:31<00:01, 79.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3313/3459 [00:31<00:01, 78.83it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3322/3459 [00:31<00:01, 81.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3332/3459 [00:32<00:01, 86.33it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3342/3459 [00:32<00:01, 87.52it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3351/3459 [00:32<00:01, 88.10it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3361/3459 [00:32<00:01, 88.78it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3370/3459 [00:32<00:01, 86.78it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3380/3459 [00:32<00:00, 88.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3390/3459 [00:32<00:00, 88.86it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3399/3459 [00:32<00:00, 89.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3408/3459 [00:32<00:00, 86.81it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3419/3459 [00:33<00:00, 93.33it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3429/3459 [00:33<00:00, 92.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3439/3459 [00:33<00:00, 92.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3449/3459 [00:33<00:00, 91.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3459/3459 [00:33<00:00, 92.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3459/3459 [00:33<00:00, 103.35it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.2153
Epoch 1 Step 51 Train Loss: 0.1883
Epoch 1 Step 101 Train Loss: 0.1716
Epoch 1 Step 151 Train Loss: 0.1683
Epoch 1 Step 201 Train Loss: 0.1648
Epoch 1 Step 251 Train Loss: 0.1644
Epoch 1: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0037 Validation Top 20 DE MSE: 0.0053. 
Epoch 2 Step 1 Train Loss: 0.1531
Epoch 2 Step 51 Train Loss: 0.1742
Epoch 2 Step 101 Train Loss: 0.1562
Epoch 2 Step 151 Train Loss: 0.1588
Epoch 2 Step 201 Train Loss: 0.1624
Epoch 2 Step 251 Train Loss: 0.1576
Epoch 2: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0049. 
Epoch 3 Step 1 Train Loss: 0.1541
Epoch 3 Step 51 Train Loss: 0.1681
Epoch 3 Step 101 Train Loss: 0.1506
Epoch 3 Step 151 Train Loss: 0.1521
Epoch 3 Step 201 Train Loss: 0.1574
Epoch 3 Step 251 Train Loss: 0.1441
Epoch 3: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0049. 
Epoch 4 Step 1 Train Loss: 0.1648
Epoch 4 Step 51 Train Loss: 0.1442
Epoch 4 Step 101 Train Loss: 0.1169
Epoch 4 Step 151 Train Loss: 0.1408
Epoch 4 Step 201 Train Loss: 0.1582
Epoch 4 Step 251 Train Loss: 0.1513
Epoch 4: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0033 Validation Top 20 DE MSE: 0.0049. 
Epoch 5 Step 1 Train Loss: 0.1497
Epoch 5 Step 51 Train Loss: 0.1328
Epoch 5 Step 101 Train Loss: 0.1505
Epoch 5 Step 151 Train Loss: 0.1667
Epoch 5 Step 201 Train Loss: 0.1527
Epoch 5 Step 251 Train Loss: 0.1461
Epoch 5: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0033 Validation Top 20 DE MSE: 0.0048. 
Epoch 6 Step 1 Train Loss: 0.1474
Epoch 6 Step 51 Train Loss: 0.1303
Epoch 6 Step 101 Train Loss: 0.1575
Epoch 6 Step 151 Train Loss: 0.1496
Epoch 6 Step 201 Train Loss: 0.1477
Epoch 6 Step 251 Train Loss: 0.1630
Epoch 6: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0033 Validation Top 20 DE MSE: 0.0048. 
Epoch 7 Step 1 Train Loss: 0.1529
Epoch 7 Step 51 Train Loss: 0.1509
Epoch 7 Step 101 Train Loss: 0.1461
Epoch 7 Step 151 Train Loss: 0.1393
Epoch 7 Step 201 Train Loss: 0.1430
Epoch 7 Step 251 Train Loss: 0.1592
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0049. 
Epoch 8 Step 1 Train Loss: 0.1524
Epoch 8 Step 51 Train Loss: 0.1498
Epoch 8 Step 101 Train Loss: 0.1473
Epoch 8 Step 151 Train Loss: 0.1488
Epoch 8 Step 201 Train Loss: 0.1602
Epoch 8 Step 251 Train Loss: 0.1541
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0049. 
Epoch 9 Step 1 Train Loss: 0.1446
Epoch 9 Step 51 Train Loss: 0.1597
Epoch 9 Step 101 Train Loss: 0.1530
Epoch 9 Step 151 Train Loss: 0.1417
Epoch 9 Step 201 Train Loss: 0.1421
Epoch 9 Step 251 Train Loss: 0.1550
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0049. 
Epoch 10 Step 1 Train Loss: 0.1478
Epoch 10 Step 51 Train Loss: 0.1542
Epoch 10 Step 101 Train Loss: 0.1582
Epoch 10 Step 151 Train Loss: 0.1519
Epoch 10 Step 201 Train Loss: 0.1412
Epoch 10 Step 251 Train Loss: 0.1490
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0049. 
Epoch 11 Step 1 Train Loss: 0.1461
Epoch 11 Step 51 Train Loss: 0.1557
Epoch 11 Step 101 Train Loss: 0.1519
Epoch 11 Step 151 Train Loss: 0.1393
Epoch 11 Step 201 Train Loss: 0.1528
Epoch 11 Step 251 Train Loss: 0.1488
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0050. 
Epoch 12 Step 1 Train Loss: 0.1497
Epoch 12 Step 51 Train Loss: 0.1548
Epoch 12 Step 101 Train Loss: 0.1590
Epoch 12 Step 151 Train Loss: 0.1478
Epoch 12 Step 201 Train Loss: 0.1469
Epoch 12 Step 251 Train Loss: 0.1477
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0050. 
Epoch 13 Step 1 Train Loss: 0.1562
Epoch 13 Step 51 Train Loss: 0.1511
Epoch 13 Step 101 Train Loss: 0.1464
Epoch 13 Step 151 Train Loss: 0.1425
Epoch 13 Step 201 Train Loss: 0.1406
Epoch 13 Step 251 Train Loss: 0.1448
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0049. 
Epoch 14 Step 1 Train Loss: 0.1453
Epoch 14 Step 51 Train Loss: 0.1514
Epoch 14 Step 101 Train Loss: 0.1451
Epoch 14 Step 151 Train Loss: 0.1570
Epoch 14 Step 201 Train Loss: 0.1438
Epoch 14 Step 251 Train Loss: 0.1526
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0049. 
Epoch 15 Step 1 Train Loss: 0.1509
Epoch 15 Step 51 Train Loss: 0.1544
Epoch 15 Step 101 Train Loss: 0.1527
Epoch 15 Step 151 Train Loss: 0.1527
Epoch 15 Step 201 Train Loss: 0.1497
Epoch 15 Step 251 Train Loss: 0.1523
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0049. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0033
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0012640775
test_combo_seen0_pearson: 0.8694799466368891
test_combo_seen0_mse_de: 0.004796195
test_combo_seen0_pearson_de: 0.23446147790122146
test_combo_seen1_mse: 0.00114903
test_combo_seen1_pearson: 0.8769401589710436
test_combo_seen1_mse_de: 0.0025646652
test_combo_seen1_pearson_de: 0.3000257076366574
test_combo_seen2_mse: 0.0016411357
test_combo_seen2_pearson: 0.8328303057303799
test_combo_seen2_mse_de: 0.0056942985
test_combo_seen2_pearson_de: 0.21732116212592886
test_unseen_single_mse: 8.5332715e-05
test_unseen_single_pearson: 0.9892749199217895
test_unseen_single_mse_de: 0.00016346449
test_unseen_single_pearson_de: 0.6003684312354547
test_combo_seen0_pearson_delta: 0.008347752133198055
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.35
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.3125
test_combo_seen0_mse_top20_de_non_dropout: 0.009880099
test_combo_seen1_pearson_delta: 0.030331771903610704
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.34605263157894733
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.24999999999999994
test_combo_seen1_mse_top20_de_non_dropout: 0.0039031922
test_combo_seen2_pearson_delta: -0.006487305537067778
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.3499999999999999
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.2318181818181818
test_combo_seen2_mse_top20_de_non_dropout: 0.010868871
test_unseen_single_pearson_delta: 0.10404770870757148
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.48571428571428577
test_unseen_single_frac_sigma_below_1_non_dropout: 0.4928571428571428
test_unseen_single_mse_top20_de_non_dropout: 0.00017052593
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.004 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–ƒâ–…â–â–â–‚â–„â–…â–…â–…â–‡â–†â–†â–…â–†
wandb:                                             train_de_pearson â–†â–‡â–‡â–‡â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚
wandb:                                                    train_mse â–ˆâ–ƒâ–ƒâ–‚â–â–ƒâ–…â–…â–…â–†â–†â–†â–†â–†â–†
wandb:                                                train_pearson â–‚â–…â–…â–‡â–ˆâ–†â–ƒâ–ƒâ–ƒâ–‚â–â–â–â–‚â–
wandb:                                                training_loss â–‡â–ˆâ–†â–„â–„â–†â–…â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–†â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–â–…â–ƒâ–â–„â–„â–…â–‚â–†
wandb:                                                   val_de_mse â–ˆâ–‚â–ƒâ–‚â–â–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                               val_de_pearson â–ˆâ–ƒâ–†â–ˆâ–…â–…â–â–ƒâ–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:                                                      val_mse â–ƒâ–‚â–‚â–â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                                                  val_pearson â–†â–‡â–‡â–ˆâ–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.35
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.3125
wandb:                                         test_combo_seen0_mse 0.00126
wandb:                                      test_combo_seen0_mse_de 0.0048
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.00988
wandb:                                     test_combo_seen0_pearson 0.86948
wandb:                                  test_combo_seen0_pearson_de 0.23446
wandb:                               test_combo_seen0_pearson_delta 0.00835
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.34605
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.25
wandb:                                         test_combo_seen1_mse 0.00115
wandb:                                      test_combo_seen1_mse_de 0.00256
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.0039
wandb:                                     test_combo_seen1_pearson 0.87694
wandb:                                  test_combo_seen1_pearson_de 0.30003
wandb:                               test_combo_seen1_pearson_delta 0.03033
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.35
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.23182
wandb:                                         test_combo_seen2_mse 0.00164
wandb:                                      test_combo_seen2_mse_de 0.00569
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.01087
wandb:                                     test_combo_seen2_pearson 0.83283
wandb:                                  test_combo_seen2_pearson_de 0.21732
wandb:                               test_combo_seen2_pearson_delta -0.00649
wandb:                                                  test_de_mse 0.00329
wandb:                                              test_de_pearson 0.29369
wandb:               test_frac_opposite_direction_top20_non_dropout 0.35537
wandb:                          test_frac_sigma_below_1_non_dropout 0.26901
wandb:                                                     test_mse 0.00119
wandb:                                test_mse_top20_de_non_dropout 0.00574
wandb:                                                 test_pearson 0.87443
wandb:                                           test_pearson_delta 0.02499
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.48571
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.49286
wandb:                                       test_unseen_single_mse 9e-05
wandb:                                    test_unseen_single_mse_de 0.00016
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00017
wandb:                                   test_unseen_single_pearson 0.98927
wandb:                                test_unseen_single_pearson_de 0.60037
wandb:                             test_unseen_single_pearson_delta 0.10405
wandb:                                                 train_de_mse 0.00355
wandb:                                             train_de_pearson 0.31948
wandb:                                                    train_mse 0.00114
wandb:                                                train_pearson 0.88066
wandb:                                                training_loss 0.16313
wandb:                                                   val_de_mse 0.00494
wandb:                                               val_de_pearson 0.2088
wandb:                                                      val_mse 0.00179
wandb:                                                  val_pearson 0.81545
wandb: 
wandb: ðŸš€ View run TianKampmann2019_day7neuron_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/jyxv2ttk
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_051913-jyxv2ttk/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_day7neuron/splits/tiankampmann2019_day7neuron_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:18
combo_seen1:77
combo_seen2:22
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_053309-sac90wn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_day7neuron_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/sac90wn9
Start Training...
Epoch 1 Step 1 Train Loss: 0.2146
Epoch 1 Step 51 Train Loss: 0.1841
Epoch 1 Step 101 Train Loss: 0.1709
Epoch 1 Step 151 Train Loss: 0.1629
Epoch 1 Step 201 Train Loss: 0.1648
Epoch 1: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0040 Validation Top 20 DE MSE: 0.0022. 
Epoch 2 Step 1 Train Loss: 0.1655
Epoch 2 Step 51 Train Loss: 0.1727
Epoch 2 Step 101 Train Loss: 0.1616
Epoch 2 Step 151 Train Loss: 0.1573
Epoch 2 Step 201 Train Loss: 0.1585
Epoch 2: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0023. 
Epoch 3 Step 1 Train Loss: 0.1543
Epoch 3 Step 51 Train Loss: 0.1504
Epoch 3 Step 101 Train Loss: 0.1464
Epoch 3 Step 151 Train Loss: 0.1599
Epoch 3 Step 201 Train Loss: 0.1604
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0037 Validation Top 20 DE MSE: 0.0020. 
Epoch 4 Step 1 Train Loss: 0.1507
Epoch 4 Step 51 Train Loss: 0.1573
Epoch 4 Step 101 Train Loss: 0.1565
Epoch 4 Step 151 Train Loss: 0.1687
Epoch 4 Step 201 Train Loss: 0.1552
Epoch 4: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 5 Step 1 Train Loss: 0.1515
Epoch 5 Step 51 Train Loss: 0.1481
Epoch 5 Step 101 Train Loss: 0.1508
Epoch 5 Step 151 Train Loss: 0.1662
Epoch 5 Step 201 Train Loss: 0.1452
Epoch 5: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0037 Validation Top 20 DE MSE: 0.0021. 
Epoch 6 Step 1 Train Loss: 0.1604
Epoch 6 Step 51 Train Loss: 0.1564
Epoch 6 Step 101 Train Loss: 0.1660
Epoch 6 Step 151 Train Loss: 0.1675
Epoch 6 Step 201 Train Loss: 0.1651
Epoch 6: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0021. 
Epoch 7 Step 1 Train Loss: 0.1522
Epoch 7 Step 51 Train Loss: 0.1598
Epoch 7 Step 101 Train Loss: 0.1711
Epoch 7 Step 151 Train Loss: 0.1622
Epoch 7 Step 201 Train Loss: 0.1608
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0037 Validation Top 20 DE MSE: 0.0022. 
Epoch 8 Step 1 Train Loss: 0.1616
Epoch 8 Step 51 Train Loss: 0.1607
Epoch 8 Step 101 Train Loss: 0.1653
Epoch 8 Step 151 Train Loss: 0.1706
Epoch 8 Step 201 Train Loss: 0.1610
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0038 Validation Top 20 DE MSE: 0.0022. 
Epoch 9 Step 1 Train Loss: 0.1660
Epoch 9 Step 51 Train Loss: 0.1659
Epoch 9 Step 101 Train Loss: 0.1567
Epoch 9 Step 151 Train Loss: 0.1596
Epoch 9 Step 201 Train Loss: 0.1611
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0038 Validation Top 20 DE MSE: 0.0023. 
Epoch 10 Step 1 Train Loss: 0.1587
Epoch 10 Step 51 Train Loss: 0.1714
Epoch 10 Step 101 Train Loss: 0.1592
Epoch 10 Step 151 Train Loss: 0.1634
Epoch 10 Step 201 Train Loss: 0.1657
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0023. 
Epoch 11 Step 1 Train Loss: 0.1606
Epoch 11 Step 51 Train Loss: 0.1631
Epoch 11 Step 101 Train Loss: 0.1672
Epoch 11 Step 151 Train Loss: 0.1639
Epoch 11 Step 201 Train Loss: 0.1646
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0024. 
Epoch 12 Step 1 Train Loss: 0.1613
Epoch 12 Step 51 Train Loss: 0.1669
Epoch 12 Step 101 Train Loss: 0.1588
Epoch 12 Step 151 Train Loss: 0.1713
Epoch 12 Step 201 Train Loss: 0.1686
Epoch 12: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0024. 
Epoch 13 Step 1 Train Loss: 0.1397
Epoch 13 Step 51 Train Loss: 0.1684
Epoch 13 Step 101 Train Loss: 0.1604
Epoch 13 Step 151 Train Loss: 0.1640
Epoch 13 Step 201 Train Loss: 0.1694
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0024. 
Epoch 14 Step 1 Train Loss: 0.1661
Epoch 14 Step 51 Train Loss: 0.1638
Epoch 14 Step 101 Train Loss: 0.1640
Epoch 14 Step 151 Train Loss: 0.1760
Epoch 14 Step 201 Train Loss: 0.1718
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0038 Validation Top 20 DE MSE: 0.0023. 
Epoch 15 Step 1 Train Loss: 0.1582
Epoch 15 Step 51 Train Loss: 0.1662
Epoch 15 Step 101 Train Loss: 0.1715
Epoch 15 Step 151 Train Loss: 0.1651
Epoch 15 Step 201 Train Loss: 0.1599
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0024. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0036
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0011119274
test_combo_seen0_pearson: 0.8795649969377837
test_combo_seen0_mse_de: 0.0033279795
test_combo_seen0_pearson_de: 0.3811576341556654
test_combo_seen1_mse: 0.0011206272
test_combo_seen1_pearson: 0.8820567185142649
test_combo_seen1_mse_de: 0.0037590752
test_combo_seen1_pearson_de: 0.4150434402258982
test_combo_seen2_mse: 0.0015840982
test_combo_seen2_pearson: 0.8384931165294056
test_combo_seen2_mse_de: 0.0041295486
test_combo_seen2_pearson_de: 0.3889161121561157
test_unseen_single_mse: 9.751368e-05
test_unseen_single_pearson: 0.9873612208204658
test_unseen_single_mse_de: 0.0001082971
test_unseen_single_pearson_de: 0.4309862663944113
test_combo_seen0_pearson_delta: 0.014186021047270486
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.3416666666666666
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.28888888888888886
test_combo_seen0_mse_top20_de_non_dropout: 0.0037410627
test_combo_seen1_pearson_delta: 0.023570969883082854
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.4032467532467533
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.3162337662337662
test_combo_seen1_mse_top20_de_non_dropout: 0.007470505
test_combo_seen2_pearson_delta: 0.015159082627833336
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.3181818181818182
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.35454545454545455
test_combo_seen2_mse_top20_de_non_dropout: 0.008315904
test_unseen_single_pearson_delta: 0.06748658499982862
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.37857142857142856
test_unseen_single_frac_sigma_below_1_non_dropout: 0.4642857142857143
test_unseen_single_mse_top20_de_non_dropout: 0.00010743423
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.020 MB uploadedwandb: | 0.001 MB of 0.020 MB uploadedwandb: / 0.020 MB of 0.020 MB uploadedwandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.020 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–…â–ƒâ–â–ƒâ–‚â–ƒâ–„â–„â–…â–†â–…â–†â–…â–†
wandb:                                             train_de_pearson â–ƒâ–„â–„â–ˆâ–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:                                                    train_mse â–ˆâ–…â–ƒâ–â–‚â–‚â–„â–„â–…â–†â–†â–†â–‡â–†â–†
wandb:                                                train_pearson â–â–„â–†â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–„â–ƒâ–„â–ƒ
wandb:                                                training_loss â–ˆâ–†â–ƒâ–„â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–„â–„â–„â–ƒâ–ƒâ–‚â–„â–‚â–„â–„â–ƒ
wandb:                                                   val_de_mse â–…â–‡â–‚â–â–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–‡â–ˆâ–†â–ˆ
wandb:                                               val_de_pearson â–‡â–‡â–ˆâ–ˆâ–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–‚â–
wandb:                                                      val_mse â–…â–„â–‚â–â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆ
wandb:                                                  val_pearson â–„â–…â–‡â–ˆâ–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.34167
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.28889
wandb:                                         test_combo_seen0_mse 0.00111
wandb:                                      test_combo_seen0_mse_de 0.00333
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.00374
wandb:                                     test_combo_seen0_pearson 0.87956
wandb:                                  test_combo_seen0_pearson_de 0.38116
wandb:                               test_combo_seen0_pearson_delta 0.01419
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.40325
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.31623
wandb:                                         test_combo_seen1_mse 0.00112
wandb:                                      test_combo_seen1_mse_de 0.00376
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00747
wandb:                                     test_combo_seen1_pearson 0.88206
wandb:                                  test_combo_seen1_pearson_de 0.41504
wandb:                               test_combo_seen1_pearson_delta 0.02357
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.31818
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.35455
wandb:                                         test_combo_seen2_mse 0.00158
wandb:                                      test_combo_seen2_mse_de 0.00413
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00832
wandb:                                     test_combo_seen2_pearson 0.83849
wandb:                                  test_combo_seen2_pearson_de 0.38892
wandb:                               test_combo_seen2_pearson_delta 0.01516
wandb:                                                  test_de_mse 0.00356
wandb:                                              test_de_pearson 0.40639
wandb:               test_frac_opposite_direction_top20_non_dropout 0.37782
wandb:                          test_frac_sigma_below_1_non_dropout 0.32742
wandb:                                                     test_mse 0.00114
wandb:                                test_mse_top20_de_non_dropout 0.00666
wandb:                                                 test_pearson 0.87991
wandb:                                           test_pearson_delta 0.0232
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.37857
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.46429
wandb:                                       test_unseen_single_mse 0.0001
wandb:                                    test_unseen_single_mse_de 0.00011
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00011
wandb:                                   test_unseen_single_pearson 0.98736
wandb:                                test_unseen_single_pearson_de 0.43099
wandb:                             test_unseen_single_pearson_delta 0.06749
wandb:                                                 train_de_mse 0.0039
wandb:                                             train_de_pearson 0.20378
wandb:                                                    train_mse 0.00116
wandb:                                                train_pearson 0.87953
wandb:                                                training_loss 0.16197
wandb:                                                   val_de_mse 0.0024
wandb:                                               val_de_pearson 0.18643
wandb:                                                      val_mse 0.0012
wandb:                                                  val_pearson 0.87804
wandb: 
wandb: ðŸš€ View run TianKampmann2019_day7neuron_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/sac90wn9
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_053309-sac90wn9/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_day7neuron/splits/tiankampmann2019_day7neuron_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:18
combo_seen1:79
combo_seen2:21
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_054521-qil6vqe8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_day7neuron_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/qil6vqe8
Start Training...
Epoch 1 Step 1 Train Loss: 0.2252
Epoch 1 Step 51 Train Loss: 0.1785
Epoch 1 Step 101 Train Loss: 0.1692
Epoch 1 Step 151 Train Loss: 0.1682
Epoch 1 Step 201 Train Loss: 0.1705
Epoch 1 Step 251 Train Loss: 0.1644
Epoch 1 Step 301 Train Loss: 0.1514
Epoch 1 Step 351 Train Loss: 0.1658
Epoch 1 Step 401 Train Loss: 0.1616
Epoch 1: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0033 Validation Top 20 DE MSE: 0.0042. 
Epoch 2 Step 1 Train Loss: 0.1682
Epoch 2 Step 51 Train Loss: 0.1542
Epoch 2 Step 101 Train Loss: 0.1393
Epoch 2 Step 151 Train Loss: 0.1471
Epoch 2 Step 201 Train Loss: 0.1505
Epoch 2 Step 251 Train Loss: 0.1501
Epoch 2 Step 301 Train Loss: 0.1502
Epoch 2 Step 351 Train Loss: 0.1545
Epoch 2 Step 401 Train Loss: 0.1512
Epoch 2: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0031 Validation Top 20 DE MSE: 0.0041. 
Epoch 3 Step 1 Train Loss: 0.1408
Epoch 3 Step 51 Train Loss: 0.1382
Epoch 3 Step 101 Train Loss: 0.1513
Epoch 3 Step 151 Train Loss: 0.1523
Epoch 3 Step 201 Train Loss: 0.1513
Epoch 3 Step 251 Train Loss: 0.1390
Epoch 3 Step 301 Train Loss: 0.1199
Epoch 3 Step 351 Train Loss: 0.1493
Epoch 3 Step 401 Train Loss: 0.1365
Epoch 3: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0040. 
Epoch 4 Step 1 Train Loss: 0.1305
Epoch 4 Step 51 Train Loss: 0.1538
Epoch 4 Step 101 Train Loss: 0.1383
Epoch 4 Step 151 Train Loss: 0.1331
Epoch 4 Step 201 Train Loss: 0.1202
Epoch 4 Step 251 Train Loss: 0.1543
Epoch 4 Step 301 Train Loss: 0.1423
Epoch 4 Step 351 Train Loss: 0.1290
Epoch 4 Step 401 Train Loss: 0.1500
Epoch 4: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 5 Step 1 Train Loss: 0.1452
Epoch 5 Step 51 Train Loss: 0.1417
Epoch 5 Step 101 Train Loss: 0.1293
Epoch 5 Step 151 Train Loss: 0.1407
Epoch 5 Step 201 Train Loss: 0.1302
Epoch 5 Step 251 Train Loss: 0.1317
Epoch 5 Step 301 Train Loss: 0.1328
Epoch 5 Step 351 Train Loss: 0.1428
Epoch 5 Step 401 Train Loss: 0.1350
Epoch 5: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0040. 
Epoch 6 Step 1 Train Loss: 0.1331
Epoch 6 Step 51 Train Loss: 0.1307
Epoch 6 Step 101 Train Loss: 0.1303
Epoch 6 Step 151 Train Loss: 0.1391
Epoch 6 Step 201 Train Loss: 0.1130
Epoch 6 Step 251 Train Loss: 0.1192
Epoch 6 Step 301 Train Loss: 0.1436
Epoch 6 Step 351 Train Loss: 0.1304
Epoch 6 Step 401 Train Loss: 0.1365
Epoch 6: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0040. 
Epoch 7 Step 1 Train Loss: 0.1340
Epoch 7 Step 51 Train Loss: 0.1418
Epoch 7 Step 101 Train Loss: 0.1357
Epoch 7 Step 151 Train Loss: 0.1386
Epoch 7 Step 201 Train Loss: 0.1278
Epoch 7 Step 251 Train Loss: 0.1215
Epoch 7 Step 301 Train Loss: 0.1240
Epoch 7 Step 351 Train Loss: 0.1213
Epoch 7 Step 401 Train Loss: 0.1334
Epoch 7: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0040. 
Epoch 8 Step 1 Train Loss: 0.1315
Epoch 8 Step 51 Train Loss: 0.1275
Epoch 8 Step 101 Train Loss: 0.1223
Epoch 8 Step 151 Train Loss: 0.1442
Epoch 8 Step 201 Train Loss: 0.1168
Epoch 8 Step 251 Train Loss: 0.1231
Epoch 8 Step 301 Train Loss: 0.1277
Epoch 8 Step 351 Train Loss: 0.1318
Epoch 8 Step 401 Train Loss: 0.1319
Epoch 8: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 9 Step 1 Train Loss: 0.1331
Epoch 9 Step 51 Train Loss: 0.1270
Epoch 9 Step 101 Train Loss: 0.1290
Epoch 9 Step 151 Train Loss: 0.1372
Epoch 9 Step 201 Train Loss: 0.1369
Epoch 9 Step 251 Train Loss: 0.1344
Epoch 9 Step 301 Train Loss: 0.1412
Epoch 9 Step 351 Train Loss: 0.1408
Epoch 9 Step 401 Train Loss: 0.1405
Epoch 9: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 10 Step 1 Train Loss: 0.1347
Epoch 10 Step 51 Train Loss: 0.1335
Epoch 10 Step 101 Train Loss: 0.1364
Epoch 10 Step 151 Train Loss: 0.1267
Epoch 10 Step 201 Train Loss: 0.1214
Epoch 10 Step 251 Train Loss: 0.1395
Epoch 10 Step 301 Train Loss: 0.1400
Epoch 10 Step 351 Train Loss: 0.1493
Epoch 10 Step 401 Train Loss: 0.1282
Epoch 10: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 11 Step 1 Train Loss: 0.1258
Epoch 11 Step 51 Train Loss: 0.1272
Epoch 11 Step 101 Train Loss: 0.1431
Epoch 11 Step 151 Train Loss: 0.1338
Epoch 11 Step 201 Train Loss: 0.1331
Epoch 11 Step 251 Train Loss: 0.1327
Epoch 11 Step 301 Train Loss: 0.1425
Epoch 11 Step 351 Train Loss: 0.1307
Epoch 11 Step 401 Train Loss: 0.1192
Epoch 11: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 12 Step 1 Train Loss: 0.1322
Epoch 12 Step 51 Train Loss: 0.1261
Epoch 12 Step 101 Train Loss: 0.1443
Epoch 12 Step 151 Train Loss: 0.1376
Epoch 12 Step 201 Train Loss: 0.1397
Epoch 12 Step 251 Train Loss: 0.1265
Epoch 12 Step 301 Train Loss: 0.1337
Epoch 12 Step 351 Train Loss: 0.1348
Epoch 12 Step 401 Train Loss: 0.1317
Epoch 12: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 13 Step 1 Train Loss: 0.1334
Epoch 13 Step 51 Train Loss: 0.1355
Epoch 13 Step 101 Train Loss: 0.1392
Epoch 13 Step 151 Train Loss: 0.1322
Epoch 13 Step 201 Train Loss: 0.1344
Epoch 13 Step 251 Train Loss: 0.1370
Epoch 13 Step 301 Train Loss: 0.1515
Epoch 13 Step 351 Train Loss: 0.1332
Epoch 13 Step 401 Train Loss: 0.1405
Epoch 13: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 14 Step 1 Train Loss: 0.1342
Epoch 14 Step 51 Train Loss: 0.1387
Epoch 14 Step 101 Train Loss: 0.1311
Epoch 14 Step 151 Train Loss: 0.1272
Epoch 14 Step 201 Train Loss: 0.1254
Epoch 14 Step 251 Train Loss: 0.1283
Epoch 14 Step 301 Train Loss: 0.1410
Epoch 14 Step 351 Train Loss: 0.1350
Epoch 14 Step 401 Train Loss: 0.1292
Epoch 14: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Epoch 15 Step 1 Train Loss: 0.1409
Epoch 15 Step 51 Train Loss: 0.1396
Epoch 15 Step 101 Train Loss: 0.1337
Epoch 15 Step 151 Train Loss: 0.1381
Epoch 15 Step 201 Train Loss: 0.1246
Epoch 15 Step 251 Train Loss: 0.1348
Epoch 15 Step 301 Train Loss: 0.1371
Epoch 15 Step 351 Train Loss: 0.1402
Epoch 15 Step 401 Train Loss: 0.1439
Epoch 15: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0041. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0035
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0014907192
test_combo_seen0_pearson: 0.8508111959885597
test_combo_seen0_mse_de: 0.0059841024
test_combo_seen0_pearson_de: 0.2857595021767914
test_combo_seen1_mse: 0.0012305344
test_combo_seen1_pearson: 0.8707274150521637
test_combo_seen1_mse_de: 0.0030840412
test_combo_seen1_pearson_de: 0.3645028895097781
test_combo_seen2_mse: 0.001257656
test_combo_seen2_pearson: 0.8695672044335726
test_combo_seen2_mse_de: 0.003816149
test_combo_seen2_pearson_de: 0.3206364877993155
test_unseen_single_mse: 0.00010113867
test_unseen_single_pearson: 0.9871841390531081
test_unseen_single_mse_de: 0.0002271971
test_unseen_single_pearson_de: 0.5041577567227086
test_combo_seen0_pearson_delta: 0.02488193022628972
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.3861111111111111
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.29166666666666663
test_combo_seen0_mse_top20_de_non_dropout: 0.012778153
test_combo_seen1_pearson_delta: 0.014516012758091128
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.3626582278481012
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.2892405063291139
test_combo_seen1_mse_top20_de_non_dropout: 0.005557574
test_combo_seen2_pearson_delta: 0.004802591098452356
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.37142857142857144
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.26904761904761904
test_combo_seen2_mse_top20_de_non_dropout: 0.007727955
test_unseen_single_pearson_delta: 0.055618250547984804
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5142857142857142
test_unseen_single_frac_sigma_below_1_non_dropout: 0.42142857142857143
test_unseen_single_mse_top20_de_non_dropout: 0.00022564422
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.004 MB of 0.022 MB uploadedwandb: / 0.022 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb: \ 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–…â–†â–ƒâ–ƒâ–â–â–â–â–‚â–â–â–‚â–‚â–‚
wandb:                                             train_de_pearson â–â–…â–ˆâ–†â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚
wandb:                                                    train_mse â–ˆâ–‚â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                train_pearson â–â–‡â–ˆâ–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:                                                training_loss â–ˆâ–‡â–†â–†â–…â–„â–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:                                                   val_de_mse â–ˆâ–†â–ƒâ–â–‚â–‚â–ƒâ–„â–…â–‡â–…â–†â–†â–†â–†
wandb:                                               val_de_pearson â–â–‡â–‡â–ˆâ–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„
wandb:                                                      val_mse â–ˆâ–‚â–â–‚â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:                                                  val_pearson â–â–‡â–ˆâ–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.38611
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.29167
wandb:                                         test_combo_seen0_mse 0.00149
wandb:                                      test_combo_seen0_mse_de 0.00598
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.01278
wandb:                                     test_combo_seen0_pearson 0.85081
wandb:                                  test_combo_seen0_pearson_de 0.28576
wandb:                               test_combo_seen0_pearson_delta 0.02488
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.36266
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.28924
wandb:                                         test_combo_seen1_mse 0.00123
wandb:                                      test_combo_seen1_mse_de 0.00308
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00556
wandb:                                     test_combo_seen1_pearson 0.87073
wandb:                                  test_combo_seen1_pearson_de 0.3645
wandb:                               test_combo_seen1_pearson_delta 0.01452
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.37143
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.26905
wandb:                                         test_combo_seen2_mse 0.00126
wandb:                                      test_combo_seen2_mse_de 0.00382
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00773
wandb:                                     test_combo_seen2_pearson 0.86957
wandb:                                  test_combo_seen2_pearson_de 0.32064
wandb:                               test_combo_seen2_pearson_delta 0.0048
wandb:                                                  test_de_mse 0.00346
wandb:                                              test_de_pearson 0.35361
wandb:               test_frac_opposite_direction_top20_non_dropout 0.376
wandb:                          test_frac_sigma_below_1_non_dropout 0.2936
wandb:                                                     test_mse 0.00121
wandb:                                test_mse_top20_de_non_dropout 0.00666
wandb:                                                 test_pearson 0.87419
wandb:                                           test_pearson_delta 0.01668
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.51429
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.42143
wandb:                                       test_unseen_single_mse 0.0001
wandb:                                    test_unseen_single_mse_de 0.00023
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00023
wandb:                                   test_unseen_single_pearson 0.98718
wandb:                                test_unseen_single_pearson_de 0.50416
wandb:                             test_unseen_single_pearson_delta 0.05562
wandb:                                                 train_de_mse 0.00291
wandb:                                             train_de_pearson 0.33671
wandb:                                                    train_mse 0.00089
wandb:                                                train_pearson 0.90517
wandb:                                                training_loss 0.13494
wandb:                                                   val_de_mse 0.00411
wandb:                                               val_de_pearson 0.22337
wandb:                                                      val_mse 0.00161
wandb:                                                  val_pearson 0.83883
wandb: 
wandb: ðŸš€ View run TianKampmann2019_day7neuron_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/qil6vqe8
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_054521-qil6vqe8/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_day7neuron/splits/tiankampmann2019_day7neuron_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:15
combo_seen1:81
combo_seen2:21
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_060254-5hmzf2r3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_day7neuron_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/5hmzf2r3
Start Training...
Epoch 1 Step 1 Train Loss: 0.2242
Epoch 1 Step 51 Train Loss: 0.1973
Epoch 1 Step 101 Train Loss: 0.1628
Epoch 1 Step 151 Train Loss: 0.1598
Epoch 1 Step 201 Train Loss: 0.1683
Epoch 1 Step 251 Train Loss: 0.1532
Epoch 1 Step 301 Train Loss: 0.1624
Epoch 1: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0043 Validation Top 20 DE MSE: 0.0058. 
Epoch 2 Step 1 Train Loss: 0.1743
Epoch 2 Step 51 Train Loss: 0.1576
Epoch 2 Step 101 Train Loss: 0.1418
Epoch 2 Step 151 Train Loss: 0.1711
Epoch 2 Step 201 Train Loss: 0.1494
Epoch 2 Step 251 Train Loss: 0.1319
Epoch 2 Step 301 Train Loss: 0.1362
Epoch 2: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0049. 
Epoch 3 Step 1 Train Loss: 0.1462
Epoch 3 Step 51 Train Loss: 0.1366
Epoch 3 Step 101 Train Loss: 0.1310
Epoch 3 Step 151 Train Loss: 0.1360
Epoch 3 Step 201 Train Loss: 0.1407
Epoch 3 Step 251 Train Loss: 0.1527
Epoch 3 Step 301 Train Loss: 0.1485
Epoch 3: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0048. 
Epoch 4 Step 1 Train Loss: 0.1538
Epoch 4 Step 51 Train Loss: 0.1745
Epoch 4 Step 101 Train Loss: 0.1684
Epoch 4 Step 151 Train Loss: 0.1630
Epoch 4 Step 201 Train Loss: 0.1644
Epoch 4 Step 251 Train Loss: 0.1591
Epoch 4 Step 301 Train Loss: 0.1532
Epoch 4: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0051. 
Epoch 5 Step 1 Train Loss: 0.1626
Epoch 5 Step 51 Train Loss: 0.1625
Epoch 5 Step 101 Train Loss: 0.1645
Epoch 5 Step 151 Train Loss: 0.1623
Epoch 5 Step 201 Train Loss: 0.1722
Epoch 5 Step 251 Train Loss: 0.1530
Epoch 5 Step 301 Train Loss: 0.1540
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0048. 
Epoch 6 Step 1 Train Loss: 0.1707
Epoch 6 Step 51 Train Loss: 0.1593
Epoch 6 Step 101 Train Loss: 0.1681
Epoch 6 Step 151 Train Loss: 0.1644
Epoch 6 Step 201 Train Loss: 0.1701
Epoch 6 Step 251 Train Loss: 0.1459
Epoch 6 Step 301 Train Loss: 0.1640
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0053. 
Epoch 7 Step 1 Train Loss: 0.1673
Epoch 7 Step 51 Train Loss: 0.1643
Epoch 7 Step 101 Train Loss: 0.1676
Epoch 7 Step 151 Train Loss: 0.1627
Epoch 7 Step 201 Train Loss: 0.1648
Epoch 7 Step 251 Train Loss: 0.1580
Epoch 7 Step 301 Train Loss: 0.1633
Epoch 7: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0053. 
Epoch 8 Step 1 Train Loss: 0.1637
Epoch 8 Step 51 Train Loss: 0.1664
Epoch 8 Step 101 Train Loss: 0.1586
Epoch 8 Step 151 Train Loss: 0.1594
Epoch 8 Step 201 Train Loss: 0.1608
Epoch 8 Step 251 Train Loss: 0.1625
Epoch 8 Step 301 Train Loss: 0.1664
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0053. 
Epoch 9 Step 1 Train Loss: 0.1677
Epoch 9 Step 51 Train Loss: 0.1731
Epoch 9 Step 101 Train Loss: 0.1628
Epoch 9 Step 151 Train Loss: 0.1720
Epoch 9 Step 201 Train Loss: 0.1611
Epoch 9 Step 251 Train Loss: 0.1747
Epoch 9 Step 301 Train Loss: 0.1571
Epoch 9: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0056. 
Epoch 10 Step 1 Train Loss: 0.1634
Epoch 10 Step 51 Train Loss: 0.1641
Epoch 10 Step 101 Train Loss: 0.1657
Epoch 10 Step 151 Train Loss: 0.1707
Epoch 10 Step 201 Train Loss: 0.1680
Epoch 10 Step 251 Train Loss: 0.1611
Epoch 10 Step 301 Train Loss: 0.1690
Epoch 10: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0055. 
Epoch 11 Step 1 Train Loss: 0.1678
Epoch 11 Step 51 Train Loss: 0.1668
Epoch 11 Step 101 Train Loss: 0.1668
Epoch 11 Step 151 Train Loss: 0.1558
Epoch 11 Step 201 Train Loss: 0.1614
Epoch 11 Step 251 Train Loss: 0.1768
Epoch 11 Step 301 Train Loss: 0.1645
Epoch 11: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0055. 
Epoch 12 Step 1 Train Loss: 0.1575
Epoch 12 Step 51 Train Loss: 0.1551
Epoch 12 Step 101 Train Loss: 0.1640
Epoch 12 Step 151 Train Loss: 0.1570
Epoch 12 Step 201 Train Loss: 0.1629
Epoch 12 Step 251 Train Loss: 0.1723
Epoch 12 Step 301 Train Loss: 0.1718
Epoch 12: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0055. 
Epoch 13 Step 1 Train Loss: 0.1721
Epoch 13 Step 51 Train Loss: 0.1577
Epoch 13 Step 101 Train Loss: 0.1641
Epoch 13 Step 151 Train Loss: 0.1599
Epoch 13 Step 201 Train Loss: 0.1618
Epoch 13 Step 251 Train Loss: 0.1571
Epoch 13 Step 301 Train Loss: 0.1732
Epoch 13: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0057. 
Epoch 14 Step 1 Train Loss: 0.1570
Epoch 14 Step 51 Train Loss: 0.1628
Epoch 14 Step 101 Train Loss: 0.1551
Epoch 14 Step 151 Train Loss: 0.1642
Epoch 14 Step 201 Train Loss: 0.1630
Epoch 14 Step 251 Train Loss: 0.1619
Epoch 14 Step 301 Train Loss: 0.1581
Epoch 14: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0054. 
Epoch 15 Step 1 Train Loss: 0.1530
Epoch 15 Step 51 Train Loss: 0.1652
Epoch 15 Step 101 Train Loss: 0.1632
Epoch 15 Step 151 Train Loss: 0.1707
Epoch 15 Step 201 Train Loss: 0.1587
Epoch 15 Step 251 Train Loss: 0.1713
Epoch 15 Step 301 Train Loss: 0.1631
Epoch 15: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0055. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0031
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0011170751
test_combo_seen0_pearson: 0.8808731130769356
test_combo_seen0_mse_de: 0.0038171164
test_combo_seen0_pearson_de: 0.31121170817351124
test_combo_seen1_mse: 0.0011041741
test_combo_seen1_pearson: 0.8824545072011448
test_combo_seen1_mse_de: 0.003306016
test_combo_seen1_pearson_de: 0.31823278835639557
test_combo_seen2_mse: 0.0012033673
test_combo_seen2_pearson: 0.8718685669058375
test_combo_seen2_mse_de: 0.0026689558
test_combo_seen2_pearson_de: 0.5079822166119113
test_unseen_single_mse: 0.00014626903
test_unseen_single_pearson: 0.9815048048163183
test_unseen_single_mse_de: 0.00034282642
test_unseen_single_pearson_de: 0.44200751607920774
test_combo_seen0_pearson_delta: 0.015992710880218478
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.36333333333333334
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.33333333333333337
test_combo_seen0_mse_top20_de_non_dropout: 0.009314967
test_combo_seen1_pearson_delta: 0.030925340527943348
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.35370370370370374
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.2993827160493827
test_combo_seen1_mse_top20_de_non_dropout: 0.005691565
test_combo_seen2_pearson_delta: 0.03158687725318689
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.31428571428571433
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.32142857142857145
test_combo_seen2_mse_top20_de_non_dropout: 0.0043518366
test_unseen_single_pearson_delta: 0.1020131515180832
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4
test_unseen_single_frac_sigma_below_1_non_dropout: 0.4928571428571429
test_unseen_single_mse_top20_de_non_dropout: 0.00032872087
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.020 MB of 0.021 MB uploadedwandb: / 0.020 MB of 0.021 MB uploadedwandb: - 0.020 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–â–‚
wandb:                                             train_de_pearson â–â–ˆâ–ƒâ–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:                                                    train_mse â–ˆâ–â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                train_pearson â–â–ˆâ–†â–‡â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–…â–†â–†
wandb:                                                training_loss â–ˆâ–…â–ƒâ–„â–„â–â–‚â–ƒâ–„â–†â–ƒâ–„â–„â–…â–…â–†â–…â–…â–†â–…â–…â–„â–„â–…â–„â–„â–†â–…â–…â–…â–…â–†â–…â–…â–…â–‡â–…â–†â–†â–…
wandb:                                                   val_de_mse â–ˆâ–‚â–‚â–ƒâ–â–„â–„â–„â–†â–†â–†â–†â–‡â–…â–†
wandb:                                               val_de_pearson â–…â–ˆâ–„â–„â–…â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–
wandb:                                                      val_mse â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–„â–…â–…â–„â–„
wandb:                                                  val_pearson â–â–ˆâ–…â–‡â–‡â–…â–…â–…â–„â–„â–„â–„â–ƒâ–„â–„
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.36333
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.33333
wandb:                                         test_combo_seen0_mse 0.00112
wandb:                                      test_combo_seen0_mse_de 0.00382
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.00931
wandb:                                     test_combo_seen0_pearson 0.88087
wandb:                                  test_combo_seen0_pearson_de 0.31121
wandb:                               test_combo_seen0_pearson_delta 0.01599
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.3537
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.29938
wandb:                                         test_combo_seen1_mse 0.0011
wandb:                                      test_combo_seen1_mse_de 0.00331
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00569
wandb:                                     test_combo_seen1_pearson 0.88245
wandb:                                  test_combo_seen1_pearson_de 0.31823
wandb:                               test_combo_seen1_pearson_delta 0.03093
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.31429
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.32143
wandb:                                         test_combo_seen2_mse 0.0012
wandb:                                      test_combo_seen2_mse_de 0.00267
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00435
wandb:                                     test_combo_seen2_pearson 0.87187
wandb:                                  test_combo_seen2_pearson_de 0.50798
wandb:                               test_combo_seen2_pearson_delta 0.03159
wandb:                                                  test_de_mse 0.00309
wandb:                                              test_de_pearson 0.35651
wandb:               test_frac_opposite_direction_top20_non_dropout 0.35081
wandb:                          test_frac_sigma_below_1_non_dropout 0.31815
wandb:                                                     test_mse 0.00107
wandb:                                test_mse_top20_de_non_dropout 0.0056
wandb:                                                 test_pearson 0.88606
wandb:                                           test_pearson_delta 0.03324
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.4
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.49286
wandb:                                       test_unseen_single_mse 0.00015
wandb:                                    test_unseen_single_mse_de 0.00034
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00033
wandb:                                   test_unseen_single_pearson 0.9815
wandb:                                test_unseen_single_pearson_de 0.44201
wandb:                             test_unseen_single_pearson_delta 0.10201
wandb:                                                 train_de_mse 0.00349
wandb:                                             train_de_pearson 0.25393
wandb:                                                    train_mse 0.00131
wandb:                                                train_pearson 0.86841
wandb:                                                training_loss 0.16293
wandb:                                                   val_de_mse 0.00552
wandb:                                               val_de_pearson 0.11737
wandb:                                                      val_mse 0.00161
wandb:                                                  val_pearson 0.83162
wandb: 
wandb: ðŸš€ View run TianKampmann2019_day7neuron_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/5hmzf2r3
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_060254-5hmzf2r3/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_day7neuron/splits/tiankampmann2019_day7neuron_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:13
combo_seen1:75
combo_seen2:23
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_061651-657ax1et
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_day7neuron_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/657ax1et
Start Training...
Epoch 1 Step 1 Train Loss: 0.2155
Epoch 1 Step 51 Train Loss: 0.1863
Epoch 1 Step 101 Train Loss: 0.1565
Epoch 1 Step 151 Train Loss: 0.1664
Epoch 1 Step 201 Train Loss: 0.1651
Epoch 1 Step 251 Train Loss: 0.1644
Epoch 1: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0031 Validation Top 20 DE MSE: 0.0038. 
Epoch 2 Step 1 Train Loss: 0.1612
Epoch 2 Step 51 Train Loss: 0.1656
Epoch 2 Step 101 Train Loss: 0.1652
Epoch 2 Step 151 Train Loss: 0.1501
Epoch 2 Step 201 Train Loss: 0.1563
Epoch 2 Step 251 Train Loss: 0.1497
Epoch 2: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0031 Validation Top 20 DE MSE: 0.0042. 
Epoch 3 Step 1 Train Loss: 0.1744
Epoch 3 Step 51 Train Loss: 0.1488
Epoch 3 Step 101 Train Loss: 0.1561
Epoch 3 Step 151 Train Loss: 0.1326
Epoch 3 Step 201 Train Loss: 0.1457
Epoch 3 Step 251 Train Loss: 0.1535
Epoch 3: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0028 Validation Top 20 DE MSE: 0.0037. 
Epoch 4 Step 1 Train Loss: 0.1474
Epoch 4 Step 51 Train Loss: 0.1446
Epoch 4 Step 101 Train Loss: 0.1596
Epoch 4 Step 151 Train Loss: 0.1533
Epoch 4 Step 201 Train Loss: 0.1687
Epoch 4 Step 251 Train Loss: 0.1515
Epoch 4: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0050 Validation Top 20 DE MSE: 0.0067. 
Epoch 5 Step 1 Train Loss: 0.1318
Epoch 5 Step 51 Train Loss: 0.1502
Epoch 5 Step 101 Train Loss: 0.1338
Epoch 5 Step 151 Train Loss: 0.1540
Epoch 5 Step 201 Train Loss: 0.1454
Epoch 5 Step 251 Train Loss: 0.1584
Epoch 5: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0027 Validation Top 20 DE MSE: 0.0036. 
Epoch 6 Step 1 Train Loss: 0.1384
Epoch 6 Step 51 Train Loss: 0.1334
Epoch 6 Step 101 Train Loss: 0.1486
Epoch 6 Step 151 Train Loss: 0.1378
Epoch 6 Step 201 Train Loss: 0.1454
Epoch 6 Step 251 Train Loss: 0.1558
Epoch 6: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0027 Validation Top 20 DE MSE: 0.0038. 
Epoch 7 Step 1 Train Loss: 0.1607
Epoch 7 Step 51 Train Loss: 0.1523
Epoch 7 Step 101 Train Loss: 0.1557
Epoch 7 Step 151 Train Loss: 0.1567
Epoch 7 Step 201 Train Loss: 0.1513
Epoch 7 Step 251 Train Loss: 0.1544
Epoch 7: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0027 Validation Top 20 DE MSE: 0.0038. 
Epoch 8 Step 1 Train Loss: 0.1571
Epoch 8 Step 51 Train Loss: 0.1587
Epoch 8 Step 101 Train Loss: 0.1469
Epoch 8 Step 151 Train Loss: 0.1513
Epoch 8 Step 201 Train Loss: 0.1542
Epoch 8 Step 251 Train Loss: 0.1589
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0028 Validation Top 20 DE MSE: 0.0040. 
Epoch 9 Step 1 Train Loss: 0.1500
Epoch 9 Step 51 Train Loss: 0.1509
Epoch 9 Step 101 Train Loss: 0.1544
Epoch 9 Step 151 Train Loss: 0.1532
Epoch 9 Step 201 Train Loss: 0.1537
Epoch 9 Step 251 Train Loss: 0.1468
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0042. 
Epoch 10 Step 1 Train Loss: 0.1516
Epoch 10 Step 51 Train Loss: 0.1608
Epoch 10 Step 101 Train Loss: 0.1548
Epoch 10 Step 151 Train Loss: 0.1547
Epoch 10 Step 201 Train Loss: 0.1634
Epoch 10 Step 251 Train Loss: 0.1705
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0042. 
Epoch 11 Step 1 Train Loss: 0.1522
Epoch 11 Step 51 Train Loss: 0.1613
Epoch 11 Step 101 Train Loss: 0.1632
Epoch 11 Step 151 Train Loss: 0.1538
Epoch 11 Step 201 Train Loss: 0.1495
Epoch 11 Step 251 Train Loss: 0.1544
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0042. 
Epoch 12 Step 1 Train Loss: 0.1807
Epoch 12 Step 51 Train Loss: 0.1567
Epoch 12 Step 101 Train Loss: 0.1522
Epoch 12 Step 151 Train Loss: 0.1573
Epoch 12 Step 201 Train Loss: 0.1589
Epoch 12 Step 251 Train Loss: 0.1680
Epoch 12: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0042. 
Epoch 13 Step 1 Train Loss: 0.1573
Epoch 13 Step 51 Train Loss: 0.1613
Epoch 13 Step 101 Train Loss: 0.1499
Epoch 13 Step 151 Train Loss: 0.1584
Epoch 13 Step 201 Train Loss: 0.1610
Epoch 13 Step 251 Train Loss: 0.1546
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0031 Validation Top 20 DE MSE: 0.0044. 
Epoch 14 Step 1 Train Loss: 0.1492
Epoch 14 Step 51 Train Loss: 0.1738
Epoch 14 Step 101 Train Loss: 0.1519
Epoch 14 Step 151 Train Loss: 0.1504
Epoch 14 Step 201 Train Loss: 0.1557
Epoch 14 Step 251 Train Loss: 0.1489
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0043. 
Epoch 15 Step 1 Train Loss: 0.1556
Epoch 15 Step 51 Train Loss: 0.1483
Epoch 15 Step 101 Train Loss: 0.1522
Epoch 15 Step 151 Train Loss: 0.1466
Epoch 15 Step 201 Train Loss: 0.1572
Epoch 15 Step 251 Train Loss: 0.1490
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0031 Validation Top 20 DE MSE: 0.0043. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0035
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.00097294233
test_combo_seen0_pearson: 0.8944230142411327
test_combo_seen0_mse_de: 0.0047376077
test_combo_seen0_pearson_de: 0.35339573801892044
test_combo_seen1_mse: 0.0011916461
test_combo_seen1_pearson: 0.8752075595540727
test_combo_seen1_mse_de: 0.0035846757
test_combo_seen1_pearson_de: 0.32354553853677925
test_combo_seen2_mse: 0.001154767
test_combo_seen2_pearson: 0.8800482602832771
test_combo_seen2_mse_de: 0.0036852357
test_combo_seen2_pearson_de: 0.3021667103982982
test_unseen_single_mse: 9.156817e-05
test_unseen_single_pearson: 0.9882836057310401
test_unseen_single_mse_de: 0.00023071328
test_unseen_single_pearson_de: 0.5748281780418095
test_combo_seen0_pearson_delta: 0.04559583177520998
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.4115384615384615
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.3192307692307692
test_combo_seen0_mse_top20_de_non_dropout: 0.011219026
test_combo_seen1_pearson_delta: 0.01203505642329695
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.3606666666666667
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.33066666666666666
test_combo_seen1_mse_top20_de_non_dropout: 0.0059049074
test_combo_seen2_pearson_delta: 0.015095956523976132
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.358695652173913
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.28260869565217395
test_combo_seen2_mse_top20_de_non_dropout: 0.008373721
test_unseen_single_pearson_delta: 0.09898455176585803
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4642857142857143
test_unseen_single_frac_sigma_below_1_non_dropout: 0.37142857142857144
test_unseen_single_mse_top20_de_non_dropout: 0.00023210549
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.004 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–‚â–‚â–â–ˆâ–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                                             train_de_pearson â–†â–‡â–ˆâ–„â–ˆâ–„â–„â–ƒâ–â–‚â–â–‚â–â–â–
wandb:                                                    train_mse â–‚â–‚â–â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:                                                train_pearson â–†â–‡â–ˆâ–â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†
wandb:                                                training_loss â–ˆâ–…â–…â–‡â–ƒâ–†â–ƒâ–„â–„â–ƒâ–„â–â–‚â–„â–†â–ƒâ–„â–‚â–ƒâ–„â–…â–†â–„â–…â–†â–…â–„â–ƒâ–…â–„â–„â–„â–„â–„â–†â–„â–…â–…â–…â–„
wandb:                                                   val_de_mse â–â–‚â–â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:                                               val_de_pearson â–ˆâ–‡â–ˆâ–ƒâ–ˆâ–„â–„â–ƒâ–â–‚â–â–‚â–â–â–
wandb:                                                      val_mse â–‚â–‚â–â–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                  val_pearson â–‡â–‡â–ˆâ–â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.41154
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.31923
wandb:                                         test_combo_seen0_mse 0.00097
wandb:                                      test_combo_seen0_mse_de 0.00474
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.01122
wandb:                                     test_combo_seen0_pearson 0.89442
wandb:                                  test_combo_seen0_pearson_de 0.3534
wandb:                               test_combo_seen0_pearson_delta 0.0456
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.36067
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.33067
wandb:                                         test_combo_seen1_mse 0.00119
wandb:                                      test_combo_seen1_mse_de 0.00358
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.0059
wandb:                                     test_combo_seen1_pearson 0.87521
wandb:                                  test_combo_seen1_pearson_de 0.32355
wandb:                               test_combo_seen1_pearson_delta 0.01204
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.3587
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.28261
wandb:                                         test_combo_seen2_mse 0.00115
wandb:                                      test_combo_seen2_mse_de 0.00369
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00837
wandb:                                     test_combo_seen2_pearson 0.88005
wandb:                                  test_combo_seen2_pearson_de 0.30217
wandb:                               test_combo_seen2_pearson_delta 0.0151
wandb:                                                  test_de_mse 0.00353
wandb:                                              test_de_pearson 0.33757
wandb:               test_frac_opposite_direction_top20_non_dropout 0.37203
wandb:                          test_frac_sigma_below_1_non_dropout 0.32246
wandb:                                                     test_mse 0.0011
wandb:                                test_mse_top20_de_non_dropout 0.00664
wandb:                                                 test_pearson 0.88498
wandb:                                           test_pearson_delta 0.02149
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.46429
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.37143
wandb:                                       test_unseen_single_mse 9e-05
wandb:                                    test_unseen_single_mse_de 0.00023
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00023
wandb:                                   test_unseen_single_pearson 0.98828
wandb:                                test_unseen_single_pearson_de 0.57483
wandb:                             test_unseen_single_pearson_delta 0.09898
wandb:                                                 train_de_mse 0.00307
wandb:                                             train_de_pearson 0.2251
wandb:                                                    train_mse 0.00123
wandb:                                                train_pearson 0.87207
wandb:                                                training_loss 0.14735
wandb:                                                   val_de_mse 0.00434
wandb:                                               val_de_pearson 0.21137
wandb:                                                      val_mse 0.00182
wandb:                                                  val_pearson 0.81214
wandb: 
wandb: ðŸš€ View run TianKampmann2019_day7neuron_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/657ax1et
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_061651-657ax1et/logs
Found local copy...
Creating pyg object for each cell in the data...
Creating dataset file...
  0%|          | 0/249 [00:00<?, ?it/s]  0%|          | 1/249 [00:49<3:23:52, 49.33s/it]  1%|          | 2/249 [01:03<1:56:54, 28.40s/it]  1%|          | 3/249 [01:08<1:13:08, 17.84s/it]  2%|â–         | 4/249 [04:01<5:23:31, 79.23s/it]  2%|â–         | 5/249 [05:56<6:14:40, 92.13s/it]  2%|â–         | 6/249 [06:13<4:29:17, 66.49s/it]  3%|â–Ž         | 7/249 [06:16<3:04:33, 45.76s/it]  3%|â–Ž         | 8/249 [06:53<2:52:15, 42.89s/it]  4%|â–Ž         | 9/249 [06:53<1:58:24, 29.60s/it]  4%|â–         | 10/249 [06:57<1:26:43, 21.77s/it]  5%|â–         | 12/249 [06:58<46:18, 11.72s/it]    5%|â–Œ         | 13/249 [07:12<48:01, 12.21s/it]  6%|â–Œ         | 14/249 [07:20<44:18, 11.31s/it]  6%|â–Œ         | 15/249 [07:22<33:50,  8.68s/it]  6%|â–‹         | 16/249 [08:12<1:18:31, 20.22s/it]  7%|â–‹         | 17/249 [08:51<1:38:56, 25.59s/it]  7%|â–‹         | 18/249 [09:13<1:34:38, 24.58s/it]  8%|â–Š         | 19/249 [09:22<1:16:14, 19.89s/it]  8%|â–Š         | 20/249 [09:35<1:08:09, 17.86s/it]  8%|â–Š         | 21/249 [09:36<49:36, 13.05s/it]    9%|â–‰         | 22/249 [09:42<40:39, 10.75s/it]  9%|â–‰         | 23/249 [09:51<39:33, 10.50s/it] 10%|â–‰         | 24/249 [09:53<28:49,  7.69s/it] 10%|â–ˆ         | 25/249 [10:07<35:52,  9.61s/it] 10%|â–ˆ         | 26/249 [10:20<40:07, 10.80s/it] 11%|â–ˆ         | 27/249 [10:23<30:51,  8.34s/it] 11%|â–ˆ         | 28/249 [10:32<31:29,  8.55s/it] 12%|â–ˆâ–        | 29/249 [10:32<22:20,  6.09s/it] 12%|â–ˆâ–        | 30/249 [10:34<17:03,  4.67s/it] 12%|â–ˆâ–        | 31/249 [10:34<12:02,  3.32s/it] 13%|â–ˆâ–Ž        | 32/249 [10:38<13:22,  3.70s/it] 13%|â–ˆâ–Ž        | 33/249 [10:39<09:31,  2.64s/it] 14%|â–ˆâ–Ž        | 34/249 [10:50<19:11,  5.35s/it] 14%|â–ˆâ–        | 35/249 [11:10<34:53,  9.78s/it] 14%|â–ˆâ–        | 36/249 [11:13<27:41,  7.80s/it] 15%|â–ˆâ–        | 37/249 [11:15<20:54,  5.92s/it] 15%|â–ˆâ–Œ        | 38/249 [11:18<17:46,  5.05s/it] 16%|â–ˆâ–Œ        | 39/249 [11:18<12:32,  3.58s/it] 16%|â–ˆâ–Œ        | 40/249 [11:19<09:41,  2.78s/it] 16%|â–ˆâ–‹        | 41/249 [11:27<15:20,  4.42s/it] 17%|â–ˆâ–‹        | 42/249 [11:29<11:53,  3.45s/it] 17%|â–ˆâ–‹        | 43/249 [11:32<11:36,  3.38s/it] 18%|â–ˆâ–Š        | 44/249 [11:36<12:27,  3.64s/it] 18%|â–ˆâ–Š        | 45/249 [11:40<13:00,  3.83s/it] 18%|â–ˆâ–Š        | 46/249 [11:48<16:56,  5.01s/it] 19%|â–ˆâ–‰        | 47/249 [11:49<13:02,  3.88s/it] 19%|â–ˆâ–‰        | 48/249 [11:56<15:26,  4.61s/it] 20%|â–ˆâ–‰        | 49/249 [11:59<13:40,  4.10s/it] 20%|â–ˆâ–ˆ        | 50/249 [12:04<14:31,  4.38s/it] 20%|â–ˆâ–ˆ        | 51/249 [12:05<11:04,  3.36s/it] 21%|â–ˆâ–ˆ        | 52/249 [12:07<10:08,  3.09s/it] 21%|â–ˆâ–ˆâ–       | 53/249 [12:10<09:37,  2.94s/it] 22%|â–ˆâ–ˆâ–       | 54/249 [12:10<06:53,  2.12s/it] 22%|â–ˆâ–ˆâ–       | 55/249 [12:12<06:39,  2.06s/it] 22%|â–ˆâ–ˆâ–       | 56/249 [12:16<09:14,  2.88s/it] 23%|â–ˆâ–ˆâ–Ž       | 57/249 [12:23<12:47,  4.00s/it] 23%|â–ˆâ–ˆâ–Ž       | 58/249 [12:28<13:42,  4.31s/it] 24%|â–ˆâ–ˆâ–Ž       | 59/249 [12:31<12:43,  4.02s/it] 24%|â–ˆâ–ˆâ–       | 60/249 [12:32<09:13,  2.93s/it] 24%|â–ˆâ–ˆâ–       | 61/249 [12:33<07:01,  2.24s/it] 25%|â–ˆâ–ˆâ–       | 62/249 [12:33<05:33,  1.78s/it] 25%|â–ˆâ–ˆâ–Œ       | 63/249 [12:36<06:45,  2.18s/it] 26%|â–ˆâ–ˆâ–Œ       | 64/249 [12:38<06:31,  2.12s/it] 26%|â–ˆâ–ˆâ–Œ       | 65/249 [12:43<08:41,  2.83s/it] 27%|â–ˆâ–ˆâ–‹       | 66/249 [12:43<06:32,  2.15s/it] 27%|â–ˆâ–ˆâ–‹       | 67/249 [12:44<05:01,  1.66s/it] 27%|â–ˆâ–ˆâ–‹       | 68/249 [12:44<03:39,  1.21s/it] 28%|â–ˆâ–ˆâ–Š       | 69/249 [12:49<06:36,  2.20s/it] 28%|â–ˆâ–ˆâ–Š       | 70/249 [12:49<04:44,  1.59s/it] 29%|â–ˆâ–ˆâ–Š       | 71/249 [12:49<03:30,  1.18s/it] 29%|â–ˆâ–ˆâ–‰       | 72/249 [12:49<02:44,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 73/249 [12:50<02:34,  1.14it/s] 30%|â–ˆâ–ˆâ–ˆ       | 75/249 [12:50<01:31,  1.90it/s] 31%|â–ˆâ–ˆâ–ˆ       | 76/249 [12:51<02:01,  1.43it/s] 31%|â–ˆâ–ˆâ–ˆ       | 77/249 [12:52<01:40,  1.72it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 78/249 [12:54<03:08,  1.10s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 79/249 [12:54<02:21,  1.20it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 80/249 [12:55<01:51,  1.52it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 81/249 [12:57<03:02,  1.09s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 82/249 [12:57<02:30,  1.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 83/249 [12:58<02:06,  1.31it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 84/249 [12:59<02:32,  1.08it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 85/249 [12:59<02:02,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 86/249 [13:01<02:57,  1.09s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 87/249 [13:01<02:18,  1.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 88/249 [13:03<02:55,  1.09s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 89/249 [13:04<03:02,  1.14s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 90/249 [13:05<02:27,  1.08it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 91/249 [13:05<02:02,  1.29it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 92/249 [13:07<02:52,  1.10s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 93/249 [13:07<02:08,  1.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 94/249 [13:08<02:06,  1.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 95/249 [13:08<01:40,  1.53it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 96/249 [13:10<02:13,  1.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 97/249 [13:14<04:32,  1.80s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 98/249 [13:14<03:27,  1.37s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 99/249 [13:16<03:30,  1.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 100/249 [13:16<03:06,  1.25s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 101/249 [13:18<03:20,  1.36s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 102/249 [13:19<02:51,  1.17s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 103/249 [13:20<02:51,  1.17s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 104/249 [13:20<02:18,  1.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 105/249 [13:21<02:15,  1.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 106/249 [13:22<02:11,  1.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 107/249 [13:23<02:18,  1.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 108/249 [13:25<02:36,  1.11s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 109/249 [13:28<03:56,  1.69s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 110/249 [13:29<03:25,  1.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 111/249 [13:30<03:03,  1.33s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 112/249 [13:32<03:56,  1.72s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 113/249 [13:33<03:23,  1.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 114/249 [13:34<02:32,  1.13s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 115/249 [13:35<02:27,  1.10s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 116/249 [13:36<02:28,  1.12s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 117/249 [13:36<01:48,  1.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 118/249 [13:36<01:20,  1.62it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 119/249 [13:37<01:23,  1.57it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 120/249 [13:37<01:14,  1.73it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 121/249 [13:38<01:07,  1.90it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 122/249 [13:38<00:52,  2.43it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 123/249 [13:38<00:51,  2.43it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 124/249 [13:38<00:46,  2.70it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 125/249 [13:41<02:27,  1.19s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 126/249 [13:42<02:02,  1.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 127/249 [13:44<02:20,  1.16s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 128/249 [13:44<01:49,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 129/249 [13:44<01:26,  1.39it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 130/249 [13:45<01:19,  1.50it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 131/249 [13:46<01:26,  1.37it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 132/249 [13:46<01:12,  1.62it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 133/249 [13:47<01:21,  1.43it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 134/249 [13:47<01:06,  1.74it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 135/249 [13:47<00:49,  2.29it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 136/249 [13:47<00:38,  2.94it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 137/249 [13:49<01:18,  1.42it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 138/249 [13:49<01:01,  1.82it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 139/249 [13:50<01:08,  1.61it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 140/249 [13:50<01:06,  1.63it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 141/249 [13:51<00:57,  1.87it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 142/249 [13:51<00:58,  1.82it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 144/249 [13:52<00:41,  2.51it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 145/249 [13:52<00:36,  2.82it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 146/249 [13:52<00:31,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 147/249 [13:52<00:27,  3.68it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 148/249 [13:53<00:25,  3.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 149/249 [13:53<00:23,  4.29it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 150/249 [13:53<00:25,  3.90it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 152/249 [13:53<00:19,  4.92it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 154/249 [13:54<00:15,  6.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 155/249 [13:54<00:22,  4.13it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 156/249 [13:54<00:24,  3.81it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 157/249 [13:55<00:20,  4.42it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 159/249 [13:55<00:16,  5.33it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 160/249 [13:55<00:20,  4.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 161/249 [13:55<00:18,  4.69it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 162/249 [13:56<00:24,  3.50it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 163/249 [13:56<00:22,  3.74it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 164/249 [13:56<00:24,  3.51it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 166/249 [13:57<00:17,  4.75it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 167/249 [13:57<00:15,  5.19it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 168/249 [13:57<00:18,  4.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 169/249 [13:57<00:16,  4.72it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 170/249 [13:58<00:34,  2.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 171/249 [13:59<00:28,  2.75it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 172/249 [13:59<00:40,  1.90it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 173/249 [14:00<00:32,  2.31it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 174/249 [14:00<00:27,  2.76it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 176/249 [14:00<00:17,  4.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 177/249 [14:00<00:18,  3.87it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 178/249 [14:00<00:16,  4.42it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 179/249 [14:01<00:16,  4.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 180/249 [14:01<00:18,  3.64it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 181/249 [14:01<00:18,  3.59it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 182/249 [14:02<00:17,  3.85it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 183/249 [14:02<00:16,  3.96it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 184/249 [14:02<00:15,  4.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 185/249 [14:03<00:26,  2.42it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 187/249 [14:03<00:20,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 188/249 [14:03<00:17,  3.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 189/249 [14:04<00:15,  3.93it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 191/249 [14:04<00:11,  4.96it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 192/249 [14:04<00:10,  5.42it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 194/249 [14:04<00:08,  6.16it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 196/249 [14:04<00:07,  7.50it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 197/249 [14:05<00:09,  5.51it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 198/249 [14:05<00:14,  3.64it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 199/249 [14:06<00:11,  4.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 200/249 [14:06<00:13,  3.65it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 201/249 [14:06<00:11,  4.15it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 202/249 [14:06<00:11,  3.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 203/249 [14:07<00:11,  4.10it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 204/249 [14:07<00:12,  3.70it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 205/249 [14:07<00:13,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 206/249 [14:08<00:12,  3.39it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 207/249 [14:08<00:10,  3.88it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 209/249 [14:08<00:07,  5.37it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 210/249 [14:08<00:10,  3.65it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 211/249 [14:09<00:11,  3.44it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 213/249 [14:09<00:07,  4.55it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 214/249 [14:10<00:10,  3.50it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 215/249 [14:10<00:08,  3.80it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 216/249 [14:10<00:07,  4.35it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 217/249 [14:10<00:06,  5.14it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 218/249 [14:10<00:05,  5.78it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 219/249 [14:10<00:04,  6.37it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 220/249 [14:10<00:04,  6.60it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 221/249 [14:11<00:04,  6.55it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 222/249 [14:11<00:04,  6.51it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 224/249 [14:11<00:03,  7.80it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 226/249 [14:11<00:03,  5.92it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 227/249 [14:11<00:03,  6.37it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 229/249 [14:12<00:02,  6.84it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 231/249 [14:12<00:02,  7.55it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 232/249 [14:12<00:02,  6.74it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 234/249 [14:12<00:02,  7.46it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 236/249 [14:13<00:01,  7.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 237/249 [14:13<00:01,  8.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 238/249 [14:13<00:01,  7.14it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 240/249 [14:13<00:01,  8.60it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 242/249 [14:13<00:00,  8.82it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 243/249 [14:13<00:00,  8.87it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 245/249 [14:14<00:00,  9.48it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 247/249 [14:14<00:00,  9.61it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249/249 [14:14<00:00, 10.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249/249 [14:14<00:00,  3.43s/it]
Done!
Saving new dataset pyg object at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_ipsc/data_pyg/cell_graphs.pkl
Done!
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_ipsc/splits/tiankampmann2019_ipsc_simulation_1_0.75.pkl
Simulation split test composition:
combo_seen0:21
combo_seen1:100
combo_seen2:26
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_064456-ai0cr9se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_iPSC_split1
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/ai0cr9se
  0%|          | 0/3982 [00:00<?, ?it/s]  0%|          | 3/3982 [00:00<06:23, 10.37it/s]  1%|          | 29/3982 [00:00<00:43, 89.88it/s]  1%|          | 44/3982 [00:00<00:43, 90.64it/s]  1%|â–         | 56/3982 [00:00<00:44, 88.70it/s]  2%|â–         | 67/3982 [00:00<00:44, 88.87it/s]  2%|â–         | 77/3982 [00:00<00:43, 89.12it/s]  2%|â–         | 88/3982 [00:01<00:43, 89.94it/s]  2%|â–         | 98/3982 [00:01<00:42, 92.09it/s]  3%|â–Ž         | 108/3982 [00:01<00:41, 92.96it/s]  3%|â–Ž         | 118/3982 [00:01<00:41, 92.25it/s]  3%|â–Ž         | 128/3982 [00:01<00:41, 91.91it/s]  3%|â–Ž         | 138/3982 [00:01<00:42, 91.52it/s]  4%|â–Ž         | 148/3982 [00:01<00:42, 91.10it/s]  4%|â–         | 158/3982 [00:01<00:41, 91.85it/s]  4%|â–         | 168/3982 [00:01<00:41, 91.47it/s]  4%|â–         | 178/3982 [00:02<00:42, 88.84it/s]  5%|â–         | 188/3982 [00:02<00:41, 91.11it/s]  5%|â–         | 198/3982 [00:02<00:41, 90.81it/s]  5%|â–Œ         | 208/3982 [00:02<00:41, 91.75it/s]  5%|â–Œ         | 218/3982 [00:02<00:42, 88.68it/s]  6%|â–Œ         | 229/3982 [00:02<00:41, 89.52it/s]  6%|â–Œ         | 238/3982 [00:02<00:42, 88.58it/s]  6%|â–Œ         | 247/3982 [00:02<00:42, 88.20it/s]  6%|â–‹         | 258/3982 [00:02<00:40, 92.52it/s]  7%|â–‹         | 268/3982 [00:03<00:41, 88.92it/s]  7%|â–‹         | 278/3982 [00:03<00:41, 89.77it/s]  7%|â–‹         | 289/3982 [00:03<00:40, 90.36it/s]  8%|â–Š         | 300/3982 [00:03<00:39, 93.13it/s]  8%|â–Š         | 310/3982 [00:03<00:40, 90.42it/s]  8%|â–Š         | 320/3982 [00:03<00:40, 89.58it/s]  8%|â–Š         | 329/3982 [00:03<00:43, 83.78it/s]  8%|â–Š         | 338/3982 [00:03<00:42, 84.89it/s]  9%|â–Š         | 347/3982 [00:03<00:44, 81.72it/s]  9%|â–‰         | 356/3982 [00:04<00:46, 77.78it/s]  9%|â–‰         | 365/3982 [00:04<00:45, 79.75it/s]  9%|â–‰         | 374/3982 [00:04<00:44, 80.99it/s] 10%|â–‰         | 383/3982 [00:04<00:45, 79.86it/s] 10%|â–‰         | 392/3982 [00:04<00:44, 80.95it/s] 10%|â–ˆ         | 401/3982 [00:04<00:43, 82.43it/s] 10%|â–ˆ         | 412/3982 [00:04<00:41, 86.65it/s] 11%|â–ˆ         | 421/3982 [00:04<00:41, 85.77it/s] 11%|â–ˆ         | 430/3982 [00:04<00:41, 85.78it/s] 11%|â–ˆ         | 440/3982 [00:05<00:39, 89.02it/s] 11%|â–ˆâ–        | 449/3982 [00:05<00:40, 87.74it/s] 12%|â–ˆâ–        | 458/3982 [00:05<00:40, 87.78it/s] 12%|â–ˆâ–        | 467/3982 [00:05<00:41, 84.92it/s] 12%|â–ˆâ–        | 476/3982 [00:05<00:41, 85.42it/s] 12%|â–ˆâ–        | 486/3982 [00:05<00:39, 88.29it/s] 12%|â–ˆâ–        | 495/3982 [00:05<00:40, 87.03it/s] 13%|â–ˆâ–Ž        | 504/3982 [00:05<00:41, 84.11it/s] 13%|â–ˆâ–Ž        | 514/3982 [00:05<00:41, 84.11it/s] 13%|â–ˆâ–Ž        | 524/3982 [00:06<00:42, 82.08it/s] 13%|â–ˆâ–Ž        | 535/3982 [00:06<00:39, 88.29it/s] 14%|â–ˆâ–Ž        | 544/3982 [00:06<00:40, 84.48it/s] 14%|â–ˆâ–        | 553/3982 [00:06<00:40, 83.96it/s] 14%|â–ˆâ–        | 563/3982 [00:06<00:40, 83.65it/s] 14%|â–ˆâ–        | 572/3982 [00:06<00:40, 84.21it/s] 15%|â–ˆâ–        | 582/3982 [00:06<00:39, 86.89it/s] 15%|â–ˆâ–        | 591/3982 [00:06<00:40, 83.70it/s] 15%|â–ˆâ–Œ        | 600/3982 [00:06<00:39, 84.63it/s] 15%|â–ˆâ–Œ        | 610/3982 [00:07<00:39, 85.31it/s] 16%|â–ˆâ–Œ        | 619/3982 [00:07<00:39, 85.08it/s] 16%|â–ˆâ–Œ        | 628/3982 [00:07<00:40, 82.60it/s] 16%|â–ˆâ–Œ        | 638/3982 [00:07<00:38, 87.06it/s] 16%|â–ˆâ–Œ        | 647/3982 [00:07<00:39, 84.93it/s] 17%|â–ˆâ–‹        | 658/3982 [00:07<00:36, 91.16it/s] 17%|â–ˆâ–‹        | 668/3982 [00:07<00:38, 86.24it/s] 17%|â–ˆâ–‹        | 677/3982 [00:07<00:38, 86.94it/s] 17%|â–ˆâ–‹        | 688/3982 [00:07<00:36, 90.84it/s] 18%|â–ˆâ–Š        | 698/3982 [00:08<00:37, 87.18it/s] 18%|â–ˆâ–Š        | 707/3982 [00:08<00:40, 81.73it/s] 18%|â–ˆâ–Š        | 716/3982 [00:08<00:41, 78.64it/s] 18%|â–ˆâ–Š        | 726/3982 [00:08<00:39, 83.34it/s] 18%|â–ˆâ–Š        | 735/3982 [00:08<00:41, 77.35it/s] 19%|â–ˆâ–Š        | 743/3982 [00:08<00:42, 75.56it/s] 19%|â–ˆâ–‰        | 752/3982 [00:08<00:41, 77.58it/s] 19%|â–ˆâ–‰        | 760/3982 [00:08<00:41, 78.02it/s] 19%|â–ˆâ–‰        | 769/3982 [00:09<00:41, 78.25it/s] 20%|â–ˆâ–‰        | 778/3982 [00:09<00:40, 79.22it/s] 20%|â–ˆâ–‰        | 789/3982 [00:09<00:37, 85.40it/s] 20%|â–ˆâ–ˆ        | 798/3982 [00:09<00:37, 85.65it/s] 20%|â–ˆâ–ˆ        | 808/3982 [00:09<00:35, 88.45it/s] 21%|â–ˆâ–ˆ        | 818/3982 [00:09<00:35, 89.17it/s] 21%|â–ˆâ–ˆ        | 827/3982 [00:09<00:35, 88.48it/s] 21%|â–ˆâ–ˆ        | 836/3982 [00:09<00:35, 88.07it/s] 21%|â–ˆâ–ˆ        | 846/3982 [00:09<00:34, 89.92it/s] 21%|â–ˆâ–ˆâ–       | 856/3982 [00:09<00:34, 90.53it/s] 22%|â–ˆâ–ˆâ–       | 867/3982 [00:10<00:33, 93.44it/s] 22%|â–ˆâ–ˆâ–       | 877/3982 [00:10<00:34, 89.31it/s] 22%|â–ˆâ–ˆâ–       | 887/3982 [00:10<00:33, 91.44it/s] 23%|â–ˆâ–ˆâ–Ž       | 897/3982 [00:10<00:34, 90.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 907/3982 [00:10<00:33, 90.72it/s] 23%|â–ˆâ–ˆâ–Ž       | 917/3982 [00:10<00:32, 93.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 927/3982 [00:10<00:34, 88.59it/s] 24%|â–ˆâ–ˆâ–Ž       | 938/3982 [00:10<00:32, 93.67it/s] 24%|â–ˆâ–ˆâ–       | 948/3982 [00:10<00:34, 88.91it/s] 24%|â–ˆâ–ˆâ–       | 957/3982 [00:11<00:34, 87.58it/s] 24%|â–ˆâ–ˆâ–       | 967/3982 [00:11<00:33, 89.85it/s] 25%|â–ˆâ–ˆâ–       | 977/3982 [00:11<00:34, 86.08it/s] 25%|â–ˆâ–ˆâ–       | 987/3982 [00:11<00:33, 89.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 997/3982 [00:11<00:32, 92.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 1007/3982 [00:11<00:32, 92.67it/s] 26%|â–ˆâ–ˆâ–Œ       | 1018/3982 [00:11<00:32, 89.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 1028/3982 [00:11<00:31, 92.60it/s] 26%|â–ˆâ–ˆâ–Œ       | 1038/3982 [00:11<00:31, 94.31it/s] 26%|â–ˆâ–ˆâ–‹       | 1048/3982 [00:12<00:30, 95.85it/s] 27%|â–ˆâ–ˆâ–‹       | 1058/3982 [00:12<00:31, 92.63it/s] 27%|â–ˆâ–ˆâ–‹       | 1068/3982 [00:12<00:31, 93.19it/s] 27%|â–ˆâ–ˆâ–‹       | 1078/3982 [00:12<00:31, 92.29it/s] 27%|â–ˆâ–ˆâ–‹       | 1088/3982 [00:12<00:30, 93.46it/s] 28%|â–ˆâ–ˆâ–Š       | 1098/3982 [00:12<00:30, 94.88it/s] 28%|â–ˆâ–ˆâ–Š       | 1108/3982 [00:12<00:30, 95.04it/s] 28%|â–ˆâ–ˆâ–Š       | 1118/3982 [00:12<00:31, 91.71it/s] 28%|â–ˆâ–ˆâ–Š       | 1128/3982 [00:12<00:31, 90.63it/s] 29%|â–ˆâ–ˆâ–Š       | 1138/3982 [00:13<00:30, 92.01it/s] 29%|â–ˆâ–ˆâ–‰       | 1148/3982 [00:13<00:30, 93.68it/s] 29%|â–ˆâ–ˆâ–‰       | 1158/3982 [00:13<00:31, 88.40it/s] 29%|â–ˆâ–ˆâ–‰       | 1168/3982 [00:13<00:31, 88.72it/s] 30%|â–ˆâ–ˆâ–‰       | 1178/3982 [00:13<00:30, 91.57it/s] 30%|â–ˆâ–ˆâ–‰       | 1188/3982 [00:13<00:29, 93.63it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1198/3982 [00:13<00:30, 92.76it/s] 30%|â–ˆâ–ˆâ–ˆ       | 1208/3982 [00:13<00:30, 91.43it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1219/3982 [00:13<00:29, 94.58it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1229/3982 [00:14<00:29, 94.47it/s] 31%|â–ˆâ–ˆâ–ˆ       | 1240/3982 [00:14<00:28, 94.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 1251/3982 [00:14<00:29, 94.17it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1261/3982 [00:14<00:29, 92.53it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1272/3982 [00:14<00:28, 94.71it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1282/3982 [00:14<00:28, 94.83it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 1292/3982 [00:14<00:32, 83.50it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1301/3982 [00:14<00:32, 81.72it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1310/3982 [00:14<00:34, 78.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1318/3982 [00:15<00:36, 73.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1326/3982 [00:15<00:37, 71.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1334/3982 [00:15<00:39, 67.20it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1343/3982 [00:15<00:36, 71.41it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1351/3982 [00:15<00:36, 72.67it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1362/3982 [00:15<00:32, 81.67it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 1371/3982 [00:15<00:31, 83.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 1380/3982 [00:15<00:36, 70.76it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1394/3982 [00:16<00:30, 84.49it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1405/3982 [00:16<00:29, 88.82it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1415/3982 [00:16<00:28, 89.58it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1426/3982 [00:16<00:28, 89.86it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1436/3982 [00:16<00:27, 92.07it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1446/3982 [00:16<00:28, 88.29it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1456/3982 [00:16<00:28, 89.18it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1466/3982 [00:16<00:28, 89.33it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1476/3982 [00:16<00:27, 91.53it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1486/3982 [00:17<00:28, 86.64it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1495/3982 [00:17<00:31, 80.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1508/3982 [00:17<00:27, 90.47it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1519/3982 [00:17<00:26, 94.68it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1529/3982 [00:17<00:27, 88.94it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1539/3982 [00:17<00:27, 90.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1549/3982 [00:17<00:26, 92.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1559/3982 [00:17<00:27, 89.29it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1569/3982 [00:18<00:26, 90.25it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1579/3982 [00:18<00:25, 92.51it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1589/3982 [00:18<00:26, 89.90it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1599/3982 [00:18<00:25, 92.46it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1609/3982 [00:18<00:26, 89.36it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1619/3982 [00:18<00:27, 85.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1631/3982 [00:18<00:25, 92.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1641/3982 [00:18<00:25, 92.92it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1651/3982 [00:18<00:25, 92.41it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1661/3982 [00:19<00:24, 94.43it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1671/3982 [00:19<00:24, 93.49it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1681/3982 [00:19<00:25, 89.51it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1692/3982 [00:19<00:26, 87.98it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1704/3982 [00:19<00:24, 94.59it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1714/3982 [00:19<00:24, 94.25it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1724/3982 [00:19<00:24, 93.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1734/3982 [00:19<00:25, 89.74it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1745/3982 [00:19<00:24, 90.97it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1755/3982 [00:20<00:24, 91.97it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1765/3982 [00:20<00:23, 92.68it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1776/3982 [00:20<00:23, 94.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1786/3982 [00:20<00:23, 95.20it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1796/3982 [00:20<00:22, 95.59it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1806/3982 [00:20<00:23, 91.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1816/3982 [00:20<00:24, 87.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1826/3982 [00:20<00:24, 88.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1835/3982 [00:20<00:27, 78.67it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1844/3982 [00:21<00:28, 75.44it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1852/3982 [00:21<00:29, 71.83it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1860/3982 [00:21<00:30, 70.18it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1868/3982 [00:21<00:30, 69.26it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1875/3982 [00:21<00:31, 66.83it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1882/3982 [00:21<00:33, 62.64it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1890/3982 [00:21<00:31, 65.63it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1897/3982 [00:21<00:33, 61.44it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1905/3982 [00:22<00:32, 64.43it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1913/3982 [00:22<00:31, 66.38it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1920/3982 [00:22<00:30, 66.54it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1927/3982 [00:22<00:30, 66.95it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1934/3982 [00:22<00:31, 65.47it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1941/3982 [00:22<00:31, 64.96it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1948/3982 [00:22<00:33, 60.89it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1956/3982 [00:22<00:31, 64.52it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1964/3982 [00:22<00:30, 66.37it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1973/3982 [00:23<00:28, 71.18it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1983/3982 [00:23<00:25, 77.88it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1991/3982 [00:23<00:25, 78.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2001/3982 [00:23<00:23, 82.69it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2010/3982 [00:23<00:24, 81.46it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2020/3982 [00:23<00:23, 84.66it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2030/3982 [00:23<00:23, 84.45it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2040/3982 [00:23<00:22, 87.37it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2049/3982 [00:23<00:22, 87.15it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2058/3982 [00:24<00:22, 86.92it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2069/3982 [00:24<00:21, 88.83it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2079/3982 [00:24<00:21, 87.93it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2089/3982 [00:24<00:21, 89.55it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2099/3982 [00:24<00:20, 89.77it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2108/3982 [00:24<00:21, 86.68it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2117/3982 [00:24<00:23, 78.83it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2126/3982 [00:24<00:24, 76.58it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2134/3982 [00:24<00:24, 74.49it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2143/3982 [00:25<00:23, 76.85it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2151/3982 [00:25<00:26, 70.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2159/3982 [00:25<00:25, 70.75it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2167/3982 [00:25<00:26, 68.74it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2174/3982 [00:25<00:27, 66.40it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2181/3982 [00:25<00:27, 65.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2189/3982 [00:25<00:27, 66.35it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2196/3982 [00:25<00:27, 65.68it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2203/3982 [00:26<00:27, 65.60it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2211/3982 [00:26<00:25, 68.45it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2218/3982 [00:26<00:26, 67.58it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2225/3982 [00:26<00:26, 66.45it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2232/3982 [00:26<00:26, 66.22it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2239/3982 [00:26<00:26, 65.51it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2246/3982 [00:26<00:26, 66.21it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2254/3982 [00:26<00:25, 67.53it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2263/3982 [00:26<00:24, 70.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2271/3982 [00:27<00:23, 71.82it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2279/3982 [00:27<00:23, 72.71it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2287/3982 [00:27<00:22, 73.83it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2295/3982 [00:27<00:22, 74.20it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2304/3982 [00:27<00:21, 77.87it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2312/3982 [00:27<00:21, 77.28it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2320/3982 [00:27<00:21, 76.76it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2328/3982 [00:27<00:21, 75.83it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2336/3982 [00:27<00:21, 75.57it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2344/3982 [00:27<00:22, 73.11it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2352/3982 [00:28<00:22, 73.69it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2361/3982 [00:28<00:21, 74.72it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2369/3982 [00:28<00:21, 75.73it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2378/3982 [00:28<00:20, 77.92it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2386/3982 [00:28<00:21, 74.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2394/3982 [00:28<00:21, 74.73it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2403/3982 [00:28<00:20, 77.78it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2411/3982 [00:28<00:20, 76.95it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2419/3982 [00:28<00:20, 76.67it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2427/3982 [00:29<00:20, 76.20it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2435/3982 [00:29<00:21, 73.26it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2444/3982 [00:29<00:20, 74.36it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2452/3982 [00:29<00:21, 72.26it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2461/3982 [00:29<00:20, 75.72it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2470/3982 [00:29<00:19, 76.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2479/3982 [00:29<00:19, 75.53it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2488/3982 [00:29<00:19, 78.02it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2496/3982 [00:29<00:19, 77.64it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2504/3982 [00:30<00:19, 74.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2513/3982 [00:30<00:19, 75.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2522/3982 [00:30<00:18, 77.77it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2530/3982 [00:30<00:18, 77.21it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2538/3982 [00:30<00:18, 76.72it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2546/3982 [00:30<00:18, 76.56it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2554/3982 [00:30<00:19, 73.34it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2562/3982 [00:30<00:19, 74.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2571/3982 [00:30<00:18, 77.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2579/3982 [00:31<00:18, 73.94it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2588/3982 [00:31<00:18, 74.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2599/3982 [00:31<00:17, 80.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2609/3982 [00:31<00:16, 83.62it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2619/3982 [00:31<00:15, 86.81it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2628/3982 [00:31<00:15, 86.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2637/3982 [00:31<00:15, 87.74it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2647/3982 [00:31<00:15, 88.49it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2657/3982 [00:31<00:14, 91.43it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2667/3982 [00:32<00:14, 87.67it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2678/3982 [00:32<00:14, 90.29it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2689/3982 [00:32<00:14, 91.92it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2700/3982 [00:32<00:13, 92.18it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2710/3982 [00:32<00:14, 85.94it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2719/3982 [00:32<00:14, 84.84it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2728/3982 [00:32<00:16, 77.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2736/3982 [00:32<00:16, 74.44it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2744/3982 [00:33<00:16, 74.12it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2752/3982 [00:33<00:17, 71.56it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2760/3982 [00:33<00:17, 69.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2767/3982 [00:33<00:17, 67.53it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2774/3982 [00:33<00:17, 67.58it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2781/3982 [00:33<00:18, 66.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2789/3982 [00:33<00:17, 67.77it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2797/3982 [00:33<00:17, 67.05it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2805/3982 [00:33<00:17, 68.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2813/3982 [00:34<00:16, 70.76it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2821/3982 [00:34<00:16, 70.52it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2829/3982 [00:34<00:16, 69.82it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2837/3982 [00:34<00:15, 71.82it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2845/3982 [00:34<00:16, 70.32it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2854/3982 [00:34<00:15, 73.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2862/3982 [00:34<00:16, 67.43it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2871/3982 [00:34<00:15, 70.66it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2879/3982 [00:35<00:15, 69.31it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2886/3982 [00:35<00:15, 69.27it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2893/3982 [00:35<00:15, 69.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2900/3982 [00:35<00:15, 68.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2908/3982 [00:35<00:15, 69.56it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2915/3982 [00:35<00:15, 68.40it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2922/3982 [00:35<00:15, 68.47it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2929/3982 [00:35<00:15, 66.48it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2937/3982 [00:35<00:14, 69.84it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2945/3982 [00:35<00:14, 70.34it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2953/3982 [00:36<00:15, 65.57it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2960/3982 [00:36<00:15, 65.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2968/3982 [00:36<00:14, 68.54it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2975/3982 [00:36<00:15, 66.78it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2982/3982 [00:36<00:15, 65.46it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2989/3982 [00:36<00:15, 64.22it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2997/3982 [00:36<00:14, 68.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3005/3982 [00:36<00:14, 66.18it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3014/3982 [00:36<00:13, 70.28it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3022/3982 [00:37<00:13, 69.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3029/3982 [00:37<00:13, 68.43it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3036/3982 [00:37<00:14, 66.83it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3045/3982 [00:37<00:13, 71.72it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3053/3982 [00:37<00:13, 68.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3060/3982 [00:37<00:13, 67.90it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3067/3982 [00:37<00:14, 64.63it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3076/3982 [00:37<00:13, 68.80it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3083/3982 [00:38<00:13, 64.76it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3091/3982 [00:38<00:13, 67.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3098/3982 [00:38<00:13, 67.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3105/3982 [00:38<00:13, 65.23it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3112/3982 [00:38<00:13, 65.79it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3120/3982 [00:38<00:12, 67.70it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3127/3982 [00:38<00:12, 67.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3134/3982 [00:38<00:12, 67.64it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3142/3982 [00:38<00:12, 69.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3149/3982 [00:39<00:12, 66.41it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3157/3982 [00:39<00:12, 67.50it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3164/3982 [00:39<00:12, 67.12it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3171/3982 [00:39<00:12, 65.65it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3179/3982 [00:39<00:11, 67.93it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3186/3982 [00:39<00:11, 66.49it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3194/3982 [00:39<00:11, 69.49it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3201/3982 [00:39<00:11, 67.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3208/3982 [00:39<00:11, 66.52it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3215/3982 [00:40<00:12, 63.24it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3222/3982 [00:40<00:12, 63.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3229/3982 [00:40<00:11, 64.58it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3236/3982 [00:40<00:11, 65.63it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3243/3982 [00:40<00:11, 63.87it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3250/3982 [00:40<00:11, 65.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3257/3982 [00:40<00:11, 64.92it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3264/3982 [00:40<00:11, 63.70it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3271/3982 [00:40<00:10, 65.45it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3281/3982 [00:40<00:09, 71.76it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3291/3982 [00:41<00:08, 79.51it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3300/3982 [00:41<00:08, 81.85it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3309/3982 [00:41<00:08, 81.43it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3321/3982 [00:41<00:07, 91.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3331/3982 [00:41<00:07, 87.35it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3341/3982 [00:41<00:07, 89.70it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3351/3982 [00:41<00:07, 89.29it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3361/3982 [00:41<00:06, 90.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3372/3982 [00:41<00:06, 94.55it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3382/3982 [00:42<00:06, 93.88it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3392/3982 [00:42<00:06, 92.44it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3402/3982 [00:42<00:06, 83.42it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3411/3982 [00:42<00:07, 78.84it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3420/3982 [00:42<00:07, 76.43it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3428/3982 [00:42<00:07, 72.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3436/3982 [00:42<00:07, 69.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3443/3982 [00:42<00:07, 68.49it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3450/3982 [00:43<00:07, 68.08it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3459/3982 [00:43<00:07, 72.37it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3467/3982 [00:43<00:07, 70.91it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3475/3982 [00:43<00:07, 64.81it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3482/3982 [00:43<00:07, 64.82it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3489/3982 [00:43<00:07, 64.11it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3497/3982 [00:43<00:07, 67.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3504/3982 [00:43<00:07, 66.13it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3511/3982 [00:43<00:07, 63.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3520/3982 [00:44<00:06, 67.11it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3527/3982 [00:44<00:06, 67.63it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3534/3982 [00:44<00:06, 68.27it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3541/3982 [00:44<00:06, 66.73it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3548/3982 [00:44<00:06, 65.35it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3556/3982 [00:44<00:06, 65.83it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3564/3982 [00:44<00:06, 68.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3572/3982 [00:44<00:05, 69.79it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3579/3982 [00:44<00:06, 67.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3586/3982 [00:45<00:07, 56.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3599/3982 [00:45<00:05, 72.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3607/3982 [00:45<00:05, 71.84it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3617/3982 [00:45<00:04, 77.46it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3626/3982 [00:45<00:04, 80.69it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3636/3982 [00:45<00:04, 82.21it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3647/3982 [00:45<00:03, 88.13it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3657/3982 [00:45<00:03, 88.35it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3667/3982 [00:46<00:03, 86.80it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3678/3982 [00:46<00:03, 92.57it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3688/3982 [00:46<00:03, 92.80it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3698/3982 [00:46<00:03, 93.33it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3708/3982 [00:46<00:02, 92.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3718/3982 [00:46<00:02, 90.88it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3729/3982 [00:46<00:02, 90.72it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3739/3982 [00:46<00:02, 92.20it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3749/3982 [00:46<00:02, 92.81it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3759/3982 [00:47<00:02, 93.08it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3769/3982 [00:47<00:02, 93.75it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3779/3982 [00:47<00:02, 92.41it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3789/3982 [00:47<00:02, 94.55it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3800/3982 [00:47<00:01, 97.44it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3810/3982 [00:47<00:01, 93.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3821/3982 [00:47<00:01, 95.75it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3831/3982 [00:47<00:01, 90.79it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3842/3982 [00:47<00:01, 92.88it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3853/3982 [00:48<00:01, 93.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3864/3982 [00:48<00:01, 96.74it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3874/3982 [00:48<00:01, 95.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3884/3982 [00:48<00:01, 91.70it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3895/3982 [00:48<00:00, 92.56it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3905/3982 [00:48<00:00, 94.36it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3915/3982 [00:48<00:00, 94.90it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3925/3982 [00:48<00:00, 94.13it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3935/3982 [00:48<00:00, 94.44it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3945/3982 [00:49<00:00, 92.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3955/3982 [00:49<00:00, 91.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3966/3982 [00:49<00:00, 91.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3977/3982 [00:49<00:00, 93.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3982/3982 [00:49<00:00, 80.60it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.5094
Epoch 1 Step 51 Train Loss: 0.2320
Epoch 1 Step 101 Train Loss: 0.2483
Epoch 1 Step 151 Train Loss: 0.2304
Epoch 1 Step 201 Train Loss: 0.2337
Epoch 1 Step 251 Train Loss: 0.2151
Epoch 1 Step 301 Train Loss: 0.2284
Epoch 1 Step 351 Train Loss: 0.2292
Epoch 1: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0213 Validation Top 20 DE MSE: 0.0155. 
Epoch 2 Step 1 Train Loss: 0.2519
Epoch 2 Step 51 Train Loss: 0.2431
Epoch 2 Step 101 Train Loss: 0.2621
Epoch 2 Step 151 Train Loss: 0.2360
Epoch 2 Step 201 Train Loss: 0.2440
Epoch 2 Step 251 Train Loss: 0.2435
Epoch 2 Step 301 Train Loss: 0.2421
Epoch 2 Step 351 Train Loss: 0.2618
Epoch 2: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0212 Validation Top 20 DE MSE: 0.0154. 
Epoch 3 Step 1 Train Loss: 0.2478
Epoch 3 Step 51 Train Loss: 0.2473
Epoch 3 Step 101 Train Loss: 0.2408
Epoch 3 Step 151 Train Loss: 0.2369
Epoch 3 Step 201 Train Loss: 0.2775
Epoch 3 Step 251 Train Loss: 0.2158
Epoch 3 Step 301 Train Loss: 0.2456
Epoch 3 Step 351 Train Loss: 0.2619
Epoch 3: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0143. 
Epoch 4 Step 1 Train Loss: 0.2599
Epoch 4 Step 51 Train Loss: 0.2612
Epoch 4 Step 101 Train Loss: 0.2632
Epoch 4 Step 151 Train Loss: 0.2732
Epoch 4 Step 201 Train Loss: 0.2607
Epoch 4 Step 251 Train Loss: 0.2610
Epoch 4 Step 301 Train Loss: 0.2583
Epoch 4 Step 351 Train Loss: 0.1792
Epoch 4: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0203 Validation Top 20 DE MSE: 0.0144. 
Epoch 5 Step 1 Train Loss: 0.1809
Epoch 5 Step 51 Train Loss: 0.1942
Epoch 5 Step 101 Train Loss: 0.2179
Epoch 5 Step 151 Train Loss: 0.2010
Epoch 5 Step 201 Train Loss: 0.1893
Epoch 5 Step 251 Train Loss: 0.2219
Epoch 5 Step 301 Train Loss: 0.1928
Epoch 5 Step 351 Train Loss: 0.2055
Epoch 5: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0226 Validation Top 20 DE MSE: 0.0169. 
Epoch 6 Step 1 Train Loss: 0.2438
Epoch 6 Step 51 Train Loss: 0.2358
Epoch 6 Step 101 Train Loss: 0.2209
Epoch 6 Step 151 Train Loss: 0.2148
Epoch 6 Step 201 Train Loss: 0.1912
Epoch 6 Step 251 Train Loss: 0.2774
Epoch 6 Step 301 Train Loss: 0.2827
Epoch 6 Step 351 Train Loss: 0.2947
Epoch 6: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0207 Validation Top 20 DE MSE: 0.0147. 
Epoch 7 Step 1 Train Loss: 0.2729
Epoch 7 Step 51 Train Loss: 0.2710
Epoch 7 Step 101 Train Loss: 0.2864
Epoch 7 Step 151 Train Loss: 0.2586
Epoch 7 Step 201 Train Loss: 0.2792
Epoch 7 Step 251 Train Loss: 0.2562
Epoch 7 Step 301 Train Loss: 0.2672
Epoch 7 Step 351 Train Loss: 0.3452
Epoch 7: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0231 Validation Top 20 DE MSE: 0.0181. 
Epoch 8 Step 1 Train Loss: 0.2667
Epoch 8 Step 51 Train Loss: 0.3464
Epoch 8 Step 101 Train Loss: 0.2682
Epoch 8 Step 151 Train Loss: 0.2854
Epoch 8 Step 201 Train Loss: 0.2802
Epoch 8 Step 251 Train Loss: 0.2525
Epoch 8 Step 301 Train Loss: 0.2696
Epoch 8 Step 351 Train Loss: 0.2760
Epoch 8: Train Overall MSE: 0.0032 Validation Overall MSE: 0.0042. 
Train Top 20 DE MSE: 0.0246 Validation Top 20 DE MSE: 0.0203. 
Epoch 9 Step 1 Train Loss: 0.2718
Epoch 9 Step 51 Train Loss: 0.2491
Epoch 9 Step 101 Train Loss: 0.2519
Epoch 9 Step 151 Train Loss: 0.2408
Epoch 9 Step 201 Train Loss: 0.2786
Epoch 9 Step 251 Train Loss: 0.2655
Epoch 9 Step 301 Train Loss: 0.2552
Epoch 9 Step 351 Train Loss: 0.2673
Epoch 9: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0254 Validation Top 20 DE MSE: 0.0214. 
Epoch 10 Step 1 Train Loss: 0.2482
Epoch 10 Step 51 Train Loss: 0.2337
Epoch 10 Step 101 Train Loss: 0.2497
Epoch 10 Step 151 Train Loss: 0.2537
Epoch 10 Step 201 Train Loss: 0.2565
Epoch 10 Step 251 Train Loss: 0.2507
Epoch 10 Step 301 Train Loss: 0.2593
Epoch 10 Step 351 Train Loss: 0.2361
Epoch 10: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0252 Validation Top 20 DE MSE: 0.0211. 
Epoch 11 Step 1 Train Loss: 0.2546
Epoch 11 Step 51 Train Loss: 0.2750
Epoch 11 Step 101 Train Loss: 0.3533
Epoch 11 Step 151 Train Loss: 0.2682
Epoch 11 Step 201 Train Loss: 0.2617
Epoch 11 Step 251 Train Loss: 0.2524
Epoch 11 Step 301 Train Loss: 0.2728
Epoch 11 Step 351 Train Loss: 0.2439
Epoch 11: Train Overall MSE: 0.0041 Validation Overall MSE: 0.0056. 
Train Top 20 DE MSE: 0.0258 Validation Top 20 DE MSE: 0.0221. 
Epoch 12 Step 1 Train Loss: 0.2493
Epoch 12 Step 51 Train Loss: 0.2648
Epoch 12 Step 101 Train Loss: 0.2549
Epoch 12 Step 151 Train Loss: 0.2599
Epoch 12 Step 201 Train Loss: 0.2555
Epoch 12 Step 251 Train Loss: 0.2461
Epoch 12 Step 301 Train Loss: 0.2412
Epoch 12 Step 351 Train Loss: 0.2549
Epoch 12: Train Overall MSE: 0.0040 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0256 Validation Top 20 DE MSE: 0.0218. 
Epoch 13 Step 1 Train Loss: 0.2727
Epoch 13 Step 51 Train Loss: 0.3125
Epoch 13 Step 101 Train Loss: 0.2512
Epoch 13 Step 151 Train Loss: 0.2416
Epoch 13 Step 201 Train Loss: 0.2355
Epoch 13 Step 251 Train Loss: 0.2434
Epoch 13 Step 301 Train Loss: 0.2405
Epoch 13 Step 351 Train Loss: 0.2490
Epoch 13: Train Overall MSE: 0.0040 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0255 Validation Top 20 DE MSE: 0.0215. 
Epoch 14 Step 1 Train Loss: 0.2938
Epoch 14 Step 51 Train Loss: 0.2539
Epoch 14 Step 101 Train Loss: 0.2445
Epoch 14 Step 151 Train Loss: 0.2417
Epoch 14 Step 201 Train Loss: 0.2464
Epoch 14 Step 251 Train Loss: 0.2640
Epoch 14 Step 301 Train Loss: 0.2427
Epoch 14 Step 351 Train Loss: 0.2495
Epoch 14: Train Overall MSE: 0.0040 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0255 Validation Top 20 DE MSE: 0.0216. 
Epoch 15 Step 1 Train Loss: 0.2555
Epoch 15 Step 51 Train Loss: 0.2412
Epoch 15 Step 101 Train Loss: 0.2366
Epoch 15 Step 151 Train Loss: 0.2374
Epoch 15 Step 201 Train Loss: 0.2718
Epoch 15 Step 251 Train Loss: 0.2407
Epoch 15 Step 301 Train Loss: 0.2719
Epoch 15 Step 351 Train Loss: 0.2374
Epoch 15: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0251 Validation Top 20 DE MSE: 0.0212. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0183
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0015086175
test_combo_seen0_pearson: 0.9353956004948477
test_combo_seen0_mse_de: 0.01306722
test_combo_seen0_pearson_de: 0.09698579323561342
test_combo_seen1_mse: 0.0015913199
test_combo_seen1_pearson: 0.9322899086539199
test_combo_seen1_mse_de: 0.017886035
test_combo_seen1_pearson_de: 0.08592618285461304
test_combo_seen2_mse: 0.002317082
test_combo_seen2_pearson: 0.9017255086012818
test_combo_seen2_mse_de: 0.028707325
test_combo_seen2_pearson_de: -0.003899039934602113
test_unseen_single_mse: 0.00046570817
test_unseen_single_pearson: 0.9824296827137958
test_unseen_single_mse_de: 0.00092034385
test_unseen_single_pearson_de: 0.5329131057569256
test_combo_seen0_pearson_delta: 0.01304958936115647
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.5571428571428572
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.5642857142857143
test_combo_seen0_mse_top20_de_non_dropout: 0.044761527
test_combo_seen1_pearson_delta: 0.036938263572388504
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.5365000000000001
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5755
test_combo_seen1_mse_top20_de_non_dropout: 0.051707324
test_combo_seen2_pearson_delta: 0.008469583203796885
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5384615384615384
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.5365384615384615
test_combo_seen2_mse_top20_de_non_dropout: 0.09636191
test_unseen_single_pearson_delta: 0.11919813732353461
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4714285714285714
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6857142857142857
test_unseen_single_mse_top20_de_non_dropout: 0.0008827259
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.021 MB of 0.022 MB uploadedwandb: / 0.021 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ƒâ–‚â–â–â–„â–‚â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                                             train_de_pearson â–â–ƒâ–„â–ˆâ–ˆâ–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                                                    train_mse â–ƒâ–‚â–â–â–ƒâ–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                                                train_pearson â–„â–†â–‡â–ˆâ–†â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–‚
wandb:                                                training_loss â–‚â–‚â–ƒâ–…â–…â–…â–„â–„â–†â–†â–‚â–„â–‚â–â–„â–ˆâ–ˆâ–†â–ˆâ–‡â–‡â–†â–†â–…â–„â–…â–…â–…â–„â–„â–‡â–…â–ƒâ–„â–‚â–„â–…â–…â–„â–„
wandb:                                                   val_de_mse â–‚â–‚â–â–â–ƒâ–â–„â–†â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:                                               val_de_pearson â–‡â–†â–…â–ˆâ–…â–ƒâ–„â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–ƒ
wandb:                                                      val_mse â–‚â–‚â–â–â–ƒâ–â–ƒâ–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:                                                  val_pearson â–†â–‡â–ˆâ–ˆâ–†â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–‚
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.55714
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.56429
wandb:                                         test_combo_seen0_mse 0.00151
wandb:                                      test_combo_seen0_mse_de 0.01307
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.04476
wandb:                                     test_combo_seen0_pearson 0.9354
wandb:                                  test_combo_seen0_pearson_de 0.09699
wandb:                               test_combo_seen0_pearson_delta 0.01305
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.5365
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.5755
wandb:                                         test_combo_seen1_mse 0.00159
wandb:                                      test_combo_seen1_mse_de 0.01789
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05171
wandb:                                     test_combo_seen1_pearson 0.93229
wandb:                                  test_combo_seen1_pearson_de 0.08593
wandb:                               test_combo_seen1_pearson_delta 0.03694
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.53846
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.53654
wandb:                                         test_combo_seen2_mse 0.00232
wandb:                                      test_combo_seen2_mse_de 0.02871
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.09636
wandb:                                     test_combo_seen2_pearson 0.90173
wandb:                                  test_combo_seen2_pearson_de -0.0039
wandb:                               test_combo_seen2_pearson_delta 0.00847
wandb:                                                  test_de_mse 0.01828
wandb:                                              test_de_pearson 0.09259
wandb:               test_frac_opposite_direction_top20_non_dropout 0.53669
wandb:                          test_frac_sigma_below_1_non_dropout 0.5724
wandb:                                                     test_mse 0.00165
wandb:                                test_mse_top20_de_non_dropout 0.05599
wandb:                                                 test_pearson 0.92983
wandb:                                           test_pearson_delta 0.03261
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.47143
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.68571
wandb:                                       test_unseen_single_mse 0.00047
wandb:                                    test_unseen_single_mse_de 0.00092
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00088
wandb:                                   test_unseen_single_pearson 0.98243
wandb:                                test_unseen_single_pearson_de 0.53291
wandb:                             test_unseen_single_pearson_delta 0.1192
wandb:                                                 train_de_mse 0.02511
wandb:                                             train_de_pearson 0.15321
wandb:                                                    train_mse 0.0037
wandb:                                                train_pearson 0.89706
wandb:                                                training_loss 0.25638
wandb:                                                   val_de_mse 0.02115
wandb:                                               val_de_pearson 0.01325
wandb:                                                      val_mse 0.00503
wandb:                                                  val_pearson 0.86352
wandb: 
wandb: ðŸš€ View run TianKampmann2019_iPSC_split1 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/ai0cr9se
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_064456-ai0cr9se/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_ipsc/splits/tiankampmann2019_ipsc_simulation_2_0.75.pkl
Simulation split test composition:
combo_seen0:17
combo_seen1:84
combo_seen2:31
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_070518-k0tdt80p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_iPSC_split2
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/k0tdt80p
Start Training...
Epoch 1 Step 1 Train Loss: 0.2867
Epoch 1 Step 51 Train Loss: 0.2210
Epoch 1 Step 101 Train Loss: 0.2140
Epoch 1 Step 151 Train Loss: 0.2344
Epoch 1 Step 201 Train Loss: 0.1981
Epoch 1 Step 251 Train Loss: 0.1988
Epoch 1 Step 301 Train Loss: 0.2187
Epoch 1 Step 351 Train Loss: 0.2107
Epoch 1: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0176. 
Epoch 2 Step 1 Train Loss: 0.2078
Epoch 2 Step 51 Train Loss: 0.2385
Epoch 2 Step 101 Train Loss: 0.1936
Epoch 2 Step 151 Train Loss: 0.2142
Epoch 2 Step 201 Train Loss: 0.1921
Epoch 2 Step 251 Train Loss: 0.2035
Epoch 2 Step 301 Train Loss: 0.2216
Epoch 2 Step 351 Train Loss: 0.2608
Epoch 2: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0138 Validation Top 20 DE MSE: 0.0180. 
Epoch 3 Step 1 Train Loss: 0.2478
Epoch 3 Step 51 Train Loss: 0.2546
Epoch 3 Step 101 Train Loss: 0.2673
Epoch 3 Step 151 Train Loss: 0.2646
Epoch 3 Step 201 Train Loss: 0.2915
Epoch 3 Step 251 Train Loss: 0.2592
Epoch 3 Step 301 Train Loss: 0.2665
Epoch 3 Step 351 Train Loss: 0.2426
Epoch 3: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0151 Validation Top 20 DE MSE: 0.0193. 
Epoch 4 Step 1 Train Loss: 0.2500
Epoch 4 Step 51 Train Loss: 0.2509
Epoch 4 Step 101 Train Loss: 0.2623
Epoch 4 Step 151 Train Loss: 0.2755
Epoch 4 Step 201 Train Loss: 0.2711
Epoch 4 Step 251 Train Loss: 0.2618
Epoch 4 Step 301 Train Loss: 0.2309
Epoch 4 Step 351 Train Loss: 0.2309
Epoch 4: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0134 Validation Top 20 DE MSE: 0.0176. 
Epoch 5 Step 1 Train Loss: 0.2458
Epoch 5 Step 51 Train Loss: 0.2423
Epoch 5 Step 101 Train Loss: 0.2546
Epoch 5 Step 151 Train Loss: 0.2671
Epoch 5 Step 201 Train Loss: 0.2786
Epoch 5 Step 251 Train Loss: 0.2809
Epoch 5 Step 301 Train Loss: 0.2471
Epoch 5 Step 351 Train Loss: 0.2524
Epoch 5: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0166 Validation Top 20 DE MSE: 0.0217. 
Epoch 6 Step 1 Train Loss: 0.2408
Epoch 6 Step 51 Train Loss: 0.2305
Epoch 6 Step 101 Train Loss: 0.2456
Epoch 6 Step 151 Train Loss: 0.2626
Epoch 6 Step 201 Train Loss: 0.2119
Epoch 6 Step 251 Train Loss: 0.2326
Epoch 6 Step 301 Train Loss: 0.2631
Epoch 6 Step 351 Train Loss: 0.2785
Epoch 6: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0170 Validation Top 20 DE MSE: 0.0220. 
Epoch 7 Step 1 Train Loss: 0.2793
Epoch 7 Step 51 Train Loss: 0.2812
Epoch 7 Step 101 Train Loss: 0.2767
Epoch 7 Step 151 Train Loss: 0.2686
Epoch 7 Step 201 Train Loss: 0.2593
Epoch 7 Step 251 Train Loss: 0.2555
Epoch 7 Step 301 Train Loss: 0.2476
Epoch 7 Step 351 Train Loss: 0.2776
Epoch 7: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0233. 
Epoch 8 Step 1 Train Loss: 0.2517
Epoch 8 Step 51 Train Loss: 0.2496
Epoch 8 Step 101 Train Loss: 0.2275
Epoch 8 Step 151 Train Loss: 0.2370
Epoch 8 Step 201 Train Loss: 0.2498
Epoch 8 Step 251 Train Loss: 0.2217
Epoch 8 Step 301 Train Loss: 0.2640
Epoch 8 Step 351 Train Loss: 0.2693
Epoch 8: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0181 Validation Top 20 DE MSE: 0.0236. 
Epoch 9 Step 1 Train Loss: 0.2456
Epoch 9 Step 51 Train Loss: 0.2741
Epoch 9 Step 101 Train Loss: 0.2562
Epoch 9 Step 151 Train Loss: 0.2740
Epoch 9 Step 201 Train Loss: 0.3015
Epoch 9 Step 251 Train Loss: 0.2753
Epoch 9 Step 301 Train Loss: 0.2675
Epoch 9 Step 351 Train Loss: 0.2604
Epoch 9: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0187 Validation Top 20 DE MSE: 0.0244. 
Epoch 10 Step 1 Train Loss: 0.2322
Epoch 10 Step 51 Train Loss: 0.2670
Epoch 10 Step 101 Train Loss: 0.2552
Epoch 10 Step 151 Train Loss: 0.2533
Epoch 10 Step 201 Train Loss: 0.2758
Epoch 10 Step 251 Train Loss: 0.2495
Epoch 10 Step 301 Train Loss: 0.2443
Epoch 10 Step 351 Train Loss: 0.2548
Epoch 10: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0180 Validation Top 20 DE MSE: 0.0235. 
Epoch 11 Step 1 Train Loss: 0.2711
Epoch 11 Step 51 Train Loss: 0.2433
Epoch 11 Step 101 Train Loss: 0.2609
Epoch 11 Step 151 Train Loss: 0.2768
Epoch 11 Step 201 Train Loss: 0.2454
Epoch 11 Step 251 Train Loss: 0.2563
Epoch 11 Step 301 Train Loss: 0.2563
Epoch 11 Step 351 Train Loss: 0.2601
Epoch 11: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0188 Validation Top 20 DE MSE: 0.0245. 
Epoch 12 Step 1 Train Loss: 0.2567
Epoch 12 Step 51 Train Loss: 0.2691
Epoch 12 Step 101 Train Loss: 0.2530
Epoch 12 Step 151 Train Loss: 0.2380
Epoch 12 Step 201 Train Loss: 0.2464
Epoch 12 Step 251 Train Loss: 0.2930
Epoch 12 Step 301 Train Loss: 0.2446
Epoch 12 Step 351 Train Loss: 0.2645
Epoch 12: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0187 Validation Top 20 DE MSE: 0.0245. 
Epoch 13 Step 1 Train Loss: 0.2698
Epoch 13 Step 51 Train Loss: 0.2242
Epoch 13 Step 101 Train Loss: 0.2733
Epoch 13 Step 151 Train Loss: 0.2587
Epoch 13 Step 201 Train Loss: 0.2531
Epoch 13 Step 251 Train Loss: 0.2620
Epoch 13 Step 301 Train Loss: 0.2638
Epoch 13 Step 351 Train Loss: 0.2728
Epoch 13: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0178 Validation Top 20 DE MSE: 0.0233. 
Epoch 14 Step 1 Train Loss: 0.2628
Epoch 14 Step 51 Train Loss: 0.2710
Epoch 14 Step 101 Train Loss: 0.2426
Epoch 14 Step 151 Train Loss: 0.2457
Epoch 14 Step 201 Train Loss: 0.2653
Epoch 14 Step 251 Train Loss: 0.2629
Epoch 14 Step 301 Train Loss: 0.2721
Epoch 14 Step 351 Train Loss: 0.2319
Epoch 14: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0187 Validation Top 20 DE MSE: 0.0244. 
Epoch 15 Step 1 Train Loss: 0.2312
Epoch 15 Step 51 Train Loss: 0.2460
Epoch 15 Step 101 Train Loss: 0.2470
Epoch 15 Step 151 Train Loss: 0.2581
Epoch 15 Step 201 Train Loss: 0.2262
Epoch 15 Step 251 Train Loss: 0.2656
Epoch 15 Step 301 Train Loss: 0.2611
Epoch 15 Step 351 Train Loss: 0.2547
Epoch 15: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0186 Validation Top 20 DE MSE: 0.0244. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0203
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0023298708
test_combo_seen0_pearson: 0.8993542574487082
test_combo_seen0_mse_de: 0.03282393
test_combo_seen0_pearson_de: 0.05627777764373553
test_combo_seen1_mse: 0.0015980761
test_combo_seen1_pearson: 0.9312697901632385
test_combo_seen1_mse_de: 0.020656051
test_combo_seen1_pearson_de: 0.035728619924257334
test_combo_seen2_mse: 0.0015083548
test_combo_seen2_pearson: 0.9354937234963003
test_combo_seen2_mse_de: 0.017196551
test_combo_seen2_pearson_de: 0.10971900727548528
test_unseen_single_mse: 0.00016570697
test_unseen_single_pearson: 0.9924811998096359
test_unseen_single_mse_de: 0.00031760262
test_unseen_single_pearson_de: 0.48571154225341673
test_combo_seen0_pearson_delta: 0.013691545444076414
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.4852941176470588
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.6470588235294118
test_combo_seen0_mse_top20_de_non_dropout: 0.08854907
test_combo_seen1_pearson_delta: 0.021142175407693004
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.55
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5755952380952382
test_combo_seen1_mse_top20_de_non_dropout: 0.054070905
test_combo_seen2_pearson_delta: 0.04963547714648899
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5709677419354838
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.503225806451613
test_combo_seen2_mse_top20_de_non_dropout: 0.05706043
test_unseen_single_pearson_delta: 0.08756095315414959
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5142857142857142
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6714285714285714
test_unseen_single_mse_top20_de_non_dropout: 0.00044078653
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.001 MB of 0.022 MB uploadedwandb: / 0.001 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–â–‚â–ƒâ–â–…â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                             train_de_pearson â–‡â–â–â–ˆâ–ˆâ–ƒâ–…â–„â–…â–…â–…â–…â–†â–†â–…
wandb:                                                    train_mse â–‚â–‚â–‚â–â–ƒâ–„â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–ˆ
wandb:                                                train_pearson â–‡â–†â–†â–ˆâ–†â–…â–ƒâ–‚â–â–‚â–â–â–‚â–â–
wandb:                                                training_loss â–‚â–â–„â–ƒâ–â–…â–„â–„â–…â–‡â–…â–†â–‡â–ƒâ–„â–…â–…â–…â–ˆâ–„â–…â–…â–…â–†â–…â–†â–…â–ƒâ–„â–…â–„â–…â–…â–…â–†â–‡â–…â–…â–„â–…
wandb:                                                   val_de_mse â–â–â–ƒâ–â–…â–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                               val_de_pearson â–ˆâ–…â–…â–‡â–ˆâ–„â–â–ƒâ–‚â–ƒâ–‚â–â–„â–â–ƒ
wandb:                                                      val_mse â–â–‚â–‚â–â–ƒâ–„â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:                                                  val_pearson â–‡â–‡â–‡â–ˆâ–†â–…â–ƒâ–‚â–â–‚â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.48529
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.64706
wandb:                                         test_combo_seen0_mse 0.00233
wandb:                                      test_combo_seen0_mse_de 0.03282
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.08855
wandb:                                     test_combo_seen0_pearson 0.89935
wandb:                                  test_combo_seen0_pearson_de 0.05628
wandb:                               test_combo_seen0_pearson_delta 0.01369
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.55
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.5756
wandb:                                         test_combo_seen1_mse 0.0016
wandb:                                      test_combo_seen1_mse_de 0.02066
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05407
wandb:                                     test_combo_seen1_pearson 0.93127
wandb:                                  test_combo_seen1_pearson_de 0.03573
wandb:                               test_combo_seen1_pearson_delta 0.02114
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.57097
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.50323
wandb:                                         test_combo_seen2_mse 0.00151
wandb:                                      test_combo_seen2_mse_de 0.0172
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.05706
wandb:                                     test_combo_seen2_pearson 0.93549
wandb:                                  test_combo_seen2_pearson_de 0.10972
wandb:                               test_combo_seen2_pearson_delta 0.04964
wandb:                                                  test_de_mse 0.02035
wandb:                                              test_de_pearson 0.0774
wandb:               test_frac_opposite_direction_top20_non_dropout 0.54496
wandb:                          test_frac_sigma_below_1_non_dropout 0.57302
wandb:                                                     test_mse 0.0016
wandb:                                test_mse_top20_de_non_dropout 0.05625
wandb:                                                 test_pearson 0.93139
wandb:                                           test_pearson_delta 0.02993
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.51429
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.67143
wandb:                                       test_unseen_single_mse 0.00017
wandb:                                    test_unseen_single_mse_de 0.00032
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00044
wandb:                                   test_unseen_single_pearson 0.99248
wandb:                                test_unseen_single_pearson_de 0.48571
wandb:                             test_unseen_single_pearson_delta 0.08756
wandb:                                                 train_de_mse 0.01863
wandb:                                             train_de_pearson 0.12878
wandb:                                                    train_mse 0.00277
wandb:                                                train_pearson 0.91249
wandb:                                                training_loss 0.25529
wandb:                                                   val_de_mse 0.02437
wandb:                                               val_de_pearson 0.17995
wandb:                                                      val_mse 0.00324
wandb:                                                  val_pearson 0.89896
wandb: 
wandb: ðŸš€ View run TianKampmann2019_iPSC_split2 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/k0tdt80p
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_070518-k0tdt80p/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_ipsc/splits/tiankampmann2019_ipsc_simulation_3_0.75.pkl
Simulation split test composition:
combo_seen0:17
combo_seen1:90
combo_seen2:29
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_072600-wbv9nsxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_iPSC_split3
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/wbv9nsxk
Start Training...
Epoch 1 Step 1 Train Loss: 0.2094
Epoch 1 Step 51 Train Loss: 0.2222
Epoch 1 Step 101 Train Loss: 0.1942
Epoch 1 Step 151 Train Loss: 0.2281
Epoch 1 Step 201 Train Loss: 0.2034
Epoch 1 Step 251 Train Loss: 0.1942
Epoch 1 Step 301 Train Loss: 0.2057
Epoch 1 Step 351 Train Loss: 0.2296
Epoch 1 Step 401 Train Loss: 0.1978
Epoch 1 Step 451 Train Loss: 0.2013
Epoch 1: Train Overall MSE: 0.0040 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0213 Validation Top 20 DE MSE: 0.0191. 
Epoch 2 Step 1 Train Loss: 0.2160
Epoch 2 Step 51 Train Loss: 0.2385
Epoch 2 Step 101 Train Loss: 0.1922
Epoch 2 Step 151 Train Loss: 0.2142
Epoch 2 Step 201 Train Loss: 0.2441
Epoch 2 Step 251 Train Loss: 0.2151
Epoch 2 Step 301 Train Loss: 0.1962
Epoch 2 Step 351 Train Loss: 0.1915
Epoch 2 Step 401 Train Loss: 0.2672
Epoch 2 Step 451 Train Loss: 0.2053
Epoch 2: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0183 Validation Top 20 DE MSE: 0.0166. 
Epoch 3 Step 1 Train Loss: 0.2826
Epoch 3 Step 51 Train Loss: 0.2068
Epoch 3 Step 101 Train Loss: 0.1994
Epoch 3 Step 151 Train Loss: 0.1944
Epoch 3 Step 201 Train Loss: 0.2043
Epoch 3 Step 251 Train Loss: 0.2118
Epoch 3 Step 301 Train Loss: 0.1943
Epoch 3 Step 351 Train Loss: 0.1859
Epoch 3 Step 401 Train Loss: 0.1942
Epoch 3 Step 451 Train Loss: 0.1845
Epoch 3: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0227 Validation Top 20 DE MSE: 0.0207. 
Epoch 4 Step 1 Train Loss: 0.1819
Epoch 4 Step 51 Train Loss: 0.1642
Epoch 4 Step 101 Train Loss: 0.1733
Epoch 4 Step 151 Train Loss: 0.1835
Epoch 4 Step 201 Train Loss: 0.2036
Epoch 4 Step 251 Train Loss: 0.1902
Epoch 4 Step 301 Train Loss: 0.1963
Epoch 4 Step 351 Train Loss: 0.2019
Epoch 4 Step 401 Train Loss: 0.2039
Epoch 4 Step 451 Train Loss: 0.1926
Epoch 4: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0184 Validation Top 20 DE MSE: 0.0166. 
Epoch 5 Step 1 Train Loss: 0.2012
Epoch 5 Step 51 Train Loss: 0.1993
Epoch 5 Step 101 Train Loss: 0.2087
Epoch 5 Step 151 Train Loss: 0.3249
Epoch 5 Step 201 Train Loss: 0.1874
Epoch 5 Step 251 Train Loss: 0.1699
Epoch 5 Step 301 Train Loss: 0.1788
Epoch 5 Step 351 Train Loss: 0.2118
Epoch 5 Step 401 Train Loss: 0.1587
Epoch 5 Step 451 Train Loss: 0.1559
Epoch 5: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0187 Validation Top 20 DE MSE: 0.0169. 
Epoch 6 Step 1 Train Loss: 0.1756
Epoch 6 Step 51 Train Loss: 0.1871
Epoch 6 Step 101 Train Loss: 0.1808
Epoch 6 Step 151 Train Loss: 0.1893
Epoch 6 Step 201 Train Loss: 0.1686
Epoch 6 Step 251 Train Loss: 0.1773
Epoch 6 Step 301 Train Loss: 0.1745
Epoch 6 Step 351 Train Loss: 0.2131
Epoch 6 Step 401 Train Loss: 0.1728
Epoch 6 Step 451 Train Loss: 0.1513
Epoch 6: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0195 Validation Top 20 DE MSE: 0.0176. 
Epoch 7 Step 1 Train Loss: 0.4154
Epoch 7 Step 51 Train Loss: 0.1734
Epoch 7 Step 101 Train Loss: 0.1575
Epoch 7 Step 151 Train Loss: 0.1661
Epoch 7 Step 201 Train Loss: 0.2881
Epoch 7 Step 251 Train Loss: 0.1415
Epoch 7 Step 301 Train Loss: 0.1400
Epoch 7 Step 351 Train Loss: 0.1318
Epoch 7 Step 401 Train Loss: 0.1381
Epoch 7 Step 451 Train Loss: 0.1875
Epoch 7: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0189 Validation Top 20 DE MSE: 0.0183. 
Epoch 8 Step 1 Train Loss: 0.1574
Epoch 8 Step 51 Train Loss: 0.1645
Epoch 8 Step 101 Train Loss: 0.1668
Epoch 8 Step 151 Train Loss: 0.1143
Epoch 8 Step 201 Train Loss: 0.1797
Epoch 8 Step 251 Train Loss: 0.1459
Epoch 8 Step 301 Train Loss: 0.1692
Epoch 8 Step 351 Train Loss: 0.1905
Epoch 8 Step 401 Train Loss: 0.1716
Epoch 8 Step 451 Train Loss: 0.1822
Epoch 8: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0215 Validation Top 20 DE MSE: 0.0196. 
Epoch 9 Step 1 Train Loss: 0.1296
Epoch 9 Step 51 Train Loss: 0.1495
Epoch 9 Step 101 Train Loss: 0.1977
Epoch 9 Step 151 Train Loss: 0.1652
Epoch 9 Step 201 Train Loss: 0.1641
Epoch 9 Step 251 Train Loss: 0.1530
Epoch 9 Step 301 Train Loss: 0.1796
Epoch 9 Step 351 Train Loss: 0.1225
Epoch 9 Step 401 Train Loss: 0.1721
Epoch 9 Step 451 Train Loss: 0.1993
Epoch 9: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0211 Validation Top 20 DE MSE: 0.0192. 
Epoch 10 Step 1 Train Loss: 0.1867
Epoch 10 Step 51 Train Loss: 0.1621
Epoch 10 Step 101 Train Loss: 0.1566
Epoch 10 Step 151 Train Loss: 0.2167
Epoch 10 Step 201 Train Loss: 0.1743
Epoch 10 Step 251 Train Loss: 0.1618
Epoch 10 Step 301 Train Loss: 0.1391
Epoch 10 Step 351 Train Loss: 0.1593
Epoch 10 Step 401 Train Loss: 0.1715
Epoch 10 Step 451 Train Loss: 0.1724
Epoch 10: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0214 Validation Top 20 DE MSE: 0.0196. 
Epoch 11 Step 1 Train Loss: 0.1890
Epoch 11 Step 51 Train Loss: 0.1849
Epoch 11 Step 101 Train Loss: 0.1433
Epoch 11 Step 151 Train Loss: 0.1817
Epoch 11 Step 201 Train Loss: 0.1537
Epoch 11 Step 251 Train Loss: 0.1110
Epoch 11 Step 301 Train Loss: 0.1318
Epoch 11 Step 351 Train Loss: 0.1174
Epoch 11 Step 401 Train Loss: 0.1766
Epoch 11 Step 451 Train Loss: 0.1592
Epoch 11: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0218 Validation Top 20 DE MSE: 0.0202. 
Epoch 12 Step 1 Train Loss: 0.1668
Epoch 12 Step 51 Train Loss: 0.1587
Epoch 12 Step 101 Train Loss: 0.1928
Epoch 12 Step 151 Train Loss: 0.1266
Epoch 12 Step 201 Train Loss: 0.1262
Epoch 12 Step 251 Train Loss: 0.1568
Epoch 12 Step 301 Train Loss: 0.1533
Epoch 12 Step 351 Train Loss: 0.1856
Epoch 12 Step 401 Train Loss: 0.1692
Epoch 12 Step 451 Train Loss: 0.1480
Epoch 12: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0217 Validation Top 20 DE MSE: 0.0201. 
Epoch 13 Step 1 Train Loss: 0.2003
Epoch 13 Step 51 Train Loss: 0.1625
Epoch 13 Step 101 Train Loss: 0.1193
Epoch 13 Step 151 Train Loss: 0.1581
Epoch 13 Step 201 Train Loss: 0.1511
Epoch 13 Step 251 Train Loss: 0.1924
Epoch 13 Step 301 Train Loss: 0.1286
Epoch 13 Step 351 Train Loss: 0.1561
Epoch 13 Step 401 Train Loss: 0.3625
Epoch 13 Step 451 Train Loss: 0.1826
Epoch 13: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0218 Validation Top 20 DE MSE: 0.0203. 
Epoch 14 Step 1 Train Loss: 0.1509
Epoch 14 Step 51 Train Loss: 0.1527
Epoch 14 Step 101 Train Loss: 0.1777
Epoch 14 Step 151 Train Loss: 0.1915
Epoch 14 Step 201 Train Loss: 0.1564
Epoch 14 Step 251 Train Loss: 0.2040
Epoch 14 Step 301 Train Loss: 0.2570
Epoch 14 Step 351 Train Loss: 0.1899
Epoch 14 Step 401 Train Loss: 0.1833
Epoch 14 Step 451 Train Loss: 0.1678
Epoch 14: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0218 Validation Top 20 DE MSE: 0.0204. 
Epoch 15 Step 1 Train Loss: 0.1834
Epoch 15 Step 51 Train Loss: 0.1900
Epoch 15 Step 101 Train Loss: 0.1575
Epoch 15 Step 151 Train Loss: 0.1687
Epoch 15 Step 201 Train Loss: 0.1684
Epoch 15 Step 251 Train Loss: 0.1776
Epoch 15 Step 301 Train Loss: 0.1728
Epoch 15 Step 351 Train Loss: 0.1811
Epoch 15 Step 401 Train Loss: 0.1573
Epoch 15 Step 451 Train Loss: 0.2319
Epoch 15: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0219 Validation Top 20 DE MSE: 0.0205. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0184
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0019021595
test_combo_seen0_pearson: 0.9170418970698727
test_combo_seen0_mse_de: 0.027809715
test_combo_seen0_pearson_de: 0.06358849469500454
test_combo_seen1_mse: 0.0013525685
test_combo_seen1_pearson: 0.9400423330531932
test_combo_seen1_mse_de: 0.01723614
test_combo_seen1_pearson_de: 0.06688152428846385
test_combo_seen2_mse: 0.0015387696
test_combo_seen2_pearson: 0.9308791919070909
test_combo_seen2_mse_de: 0.020720644
test_combo_seen2_pearson_de: 0.10531066996590924
test_unseen_single_mse: 0.00011414973
test_unseen_single_pearson: 0.9953076769336759
test_unseen_single_mse_de: 0.0003451678
test_unseen_single_pearson_de: 0.4814906062563775
test_combo_seen0_pearson_delta: 0.026151182593682713
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.5617647058823528
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.5764705882352942
test_combo_seen0_mse_top20_de_non_dropout: 0.073740765
test_combo_seen1_pearson_delta: 0.016496233378057952
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.49944444444444447
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.6172222222222222
test_combo_seen1_mse_top20_de_non_dropout: 0.054145448
test_combo_seen2_pearson_delta: 0.02073743125587706
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5051724137931035
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.65
test_combo_seen2_mse_top20_de_non_dropout: 0.06469435
test_unseen_single_pearson_delta: 0.12643118079067156
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7428571428571429
test_unseen_single_mse_top20_de_non_dropout: 0.0005257934
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.023 MB uploadedwandb: | 0.021 MB of 0.023 MB uploadedwandb: / 0.021 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–†â–â–ˆâ–â–‚â–ƒâ–‚â–†â–…â–†â–‡â–‡â–‡â–‡â–‡
wandb:                                             train_de_pearson â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                    train_mse â–ˆâ–â–ƒâ–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                train_pearson â–â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                                                training_loss â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–‚â–‚â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–â–â–ƒâ–„â–â–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–‚â–‚â–â–ƒâ–ƒ
wandb:                                                   val_de_mse â–…â–â–ˆâ–â–â–ƒâ–„â–†â–…â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:                                               val_de_pearson â–â–‡â–…â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:                                                      val_mse â–ˆâ–â–„â–â–â–‚â–‚â–„â–ƒâ–„â–„â–…â–…â–…â–…
wandb:                                                  val_pearson â–â–ˆâ–„â–ˆâ–ˆâ–‡â–‡â–†â–‡â–†â–†â–†â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.56176
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.57647
wandb:                                         test_combo_seen0_mse 0.0019
wandb:                                      test_combo_seen0_mse_de 0.02781
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.07374
wandb:                                     test_combo_seen0_pearson 0.91704
wandb:                                  test_combo_seen0_pearson_de 0.06359
wandb:                               test_combo_seen0_pearson_delta 0.02615
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.49944
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.61722
wandb:                                         test_combo_seen1_mse 0.00135
wandb:                                      test_combo_seen1_mse_de 0.01724
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05415
wandb:                                     test_combo_seen1_pearson 0.94004
wandb:                                  test_combo_seen1_pearson_de 0.06688
wandb:                               test_combo_seen1_pearson_delta 0.0165
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.50517
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.65
wandb:                                         test_combo_seen2_mse 0.00154
wandb:                                      test_combo_seen2_mse_de 0.02072
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.06469
wandb:                                     test_combo_seen2_pearson 0.93088
wandb:                                  test_combo_seen2_pearson_de 0.10531
wandb:                               test_combo_seen2_pearson_delta 0.02074
wandb:                                                  test_de_mse 0.01837
wandb:                                              test_de_pearson 0.09458
wandb:               test_frac_opposite_direction_top20_non_dropout 0.50804
wandb:                          test_frac_sigma_below_1_non_dropout 0.62517
wandb:                                                     test_mse 0.0014
wandb:                                test_mse_top20_de_non_dropout 0.05599
wandb:                                                 test_pearson 0.93816
wandb:                                           test_pearson_delta 0.02389
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.74286
wandb:                                       test_unseen_single_mse 0.00011
wandb:                                    test_unseen_single_mse_de 0.00035
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00053
wandb:                                   test_unseen_single_pearson 0.99531
wandb:                                test_unseen_single_pearson_de 0.48149
wandb:                             test_unseen_single_pearson_delta 0.12643
wandb:                                                 train_de_mse 0.0219
wandb:                                             train_de_pearson 0.19023
wandb:                                                    train_mse 0.00196
wandb:                                                train_pearson 0.92794
wandb:                                                training_loss 0.19415
wandb:                                                   val_de_mse 0.02049
wandb:                                               val_de_pearson 0.14337
wandb:                                                      val_mse 0.00248
wandb:                                                  val_pearson 0.91165
wandb: 
wandb: ðŸš€ View run TianKampmann2019_iPSC_split3 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/wbv9nsxk
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_072600-wbv9nsxk/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_ipsc/splits/tiankampmann2019_ipsc_simulation_4_0.75.pkl
Simulation split test composition:
combo_seen0:19
combo_seen1:92
combo_seen2:28
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.17.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_074830-2eujkhd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_iPSC_split4
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/2eujkhd8
Start Training...
Epoch 1 Step 1 Train Loss: 0.2421
Epoch 1 Step 51 Train Loss: 0.2243
Epoch 1 Step 101 Train Loss: 0.2041
Epoch 1 Step 151 Train Loss: 0.1960
Epoch 1 Step 201 Train Loss: 0.2218
Epoch 1 Step 251 Train Loss: 0.2265
Epoch 1 Step 301 Train Loss: 0.2321
Epoch 1 Step 351 Train Loss: 0.2315
Epoch 1 Step 401 Train Loss: 0.2265
Epoch 1 Step 451 Train Loss: 0.2048
Epoch 1 Step 501 Train Loss: 0.2074
Epoch 1: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0165 Validation Top 20 DE MSE: 0.0317. 
Epoch 2 Step 1 Train Loss: 0.2053
Epoch 2 Step 51 Train Loss: 0.2216
Epoch 2 Step 101 Train Loss: 0.2188
Epoch 2 Step 151 Train Loss: 0.2208
Epoch 2 Step 201 Train Loss: 0.2128
Epoch 2 Step 251 Train Loss: 0.2262
Epoch 2 Step 301 Train Loss: 0.2109
Epoch 2 Step 351 Train Loss: 0.2187
Epoch 2 Step 401 Train Loss: 0.1676
Epoch 2 Step 451 Train Loss: 0.2171
Epoch 2 Step 501 Train Loss: 0.1935
Epoch 2: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0262. 
Epoch 3 Step 1 Train Loss: 0.1943
Epoch 3 Step 51 Train Loss: 0.2182
Epoch 3 Step 101 Train Loss: 0.2213
Epoch 3 Step 151 Train Loss: 0.2138
Epoch 3 Step 201 Train Loss: 0.1759
Epoch 3 Step 251 Train Loss: 0.1894
Epoch 3 Step 301 Train Loss: 0.1909
Epoch 3 Step 351 Train Loss: 0.1971
Epoch 3 Step 401 Train Loss: 0.2032
Epoch 3 Step 451 Train Loss: 0.1767
Epoch 3 Step 501 Train Loss: 0.1702
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0144 Validation Top 20 DE MSE: 0.0293. 
Epoch 4 Step 1 Train Loss: 0.1901
Epoch 4 Step 51 Train Loss: 0.1819
Epoch 4 Step 101 Train Loss: 0.1789
Epoch 4 Step 151 Train Loss: 0.1827
Epoch 4 Step 201 Train Loss: 0.1638
Epoch 4 Step 251 Train Loss: 0.1913
Epoch 4 Step 301 Train Loss: 0.1716
Epoch 4 Step 351 Train Loss: 0.1645
Epoch 4 Step 401 Train Loss: 0.1886
Epoch 4 Step 451 Train Loss: 0.1664
Epoch 4 Step 501 Train Loss: 0.1948
Epoch 4: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0296. 
Epoch 5 Step 1 Train Loss: 0.1822
Epoch 5 Step 51 Train Loss: 0.1885
Epoch 5 Step 101 Train Loss: 0.1720
Epoch 5 Step 151 Train Loss: 0.1792
Epoch 5 Step 201 Train Loss: 0.1817
Epoch 5 Step 251 Train Loss: 0.1479
Epoch 5 Step 301 Train Loss: 0.1642
Epoch 5 Step 351 Train Loss: 0.1667
Epoch 5 Step 401 Train Loss: 0.1676
Epoch 5 Step 451 Train Loss: 0.1515
Epoch 5 Step 501 Train Loss: 0.1584
Epoch 5: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0274. 
Epoch 6 Step 1 Train Loss: 0.1581
Epoch 6 Step 51 Train Loss: 0.1657
Epoch 6 Step 101 Train Loss: 0.1605
Epoch 6 Step 151 Train Loss: 0.1801
Epoch 6 Step 201 Train Loss: 0.2019
Epoch 6 Step 251 Train Loss: 0.1632
Epoch 6 Step 301 Train Loss: 0.1252
Epoch 6 Step 351 Train Loss: 0.1707
Epoch 6 Step 401 Train Loss: 0.1712
Epoch 6 Step 451 Train Loss: 0.1807
Epoch 6 Step 501 Train Loss: 0.1631
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0134 Validation Top 20 DE MSE: 0.0281. 
Epoch 7 Step 1 Train Loss: 0.1846
Epoch 7 Step 51 Train Loss: 0.1796
Epoch 7 Step 101 Train Loss: 0.1624
Epoch 7 Step 151 Train Loss: 0.1708
Epoch 7 Step 201 Train Loss: 0.1721
Epoch 7 Step 251 Train Loss: 0.1556
Epoch 7 Step 301 Train Loss: 0.1486
Epoch 7 Step 351 Train Loss: 0.1625
Epoch 7 Step 401 Train Loss: 0.1519
Epoch 7 Step 451 Train Loss: 0.1975
Epoch 7 Step 501 Train Loss: 0.1892
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0283. 
Epoch 8 Step 1 Train Loss: 0.1561
Epoch 8 Step 51 Train Loss: 0.1716
Epoch 8 Step 101 Train Loss: 0.1715
Epoch 8 Step 151 Train Loss: 0.1878
Epoch 8 Step 201 Train Loss: 0.1795
Epoch 8 Step 251 Train Loss: 0.1692
Epoch 8 Step 301 Train Loss: 0.1672
Epoch 8 Step 351 Train Loss: 0.1443
Epoch 8 Step 401 Train Loss: 0.1744
Epoch 8 Step 451 Train Loss: 0.1828
Epoch 8 Step 501 Train Loss: 0.1812
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0282. 
Epoch 9 Step 1 Train Loss: 0.1602
Epoch 9 Step 51 Train Loss: 0.1899
Epoch 9 Step 101 Train Loss: 0.1756
Epoch 9 Step 151 Train Loss: 0.1910
Epoch 9 Step 201 Train Loss: 0.1874
Epoch 9 Step 251 Train Loss: 0.1678
Epoch 9 Step 301 Train Loss: 0.1505
Epoch 9 Step 351 Train Loss: 0.1686
Epoch 9 Step 401 Train Loss: 0.1759
Epoch 9 Step 451 Train Loss: 0.1860
Epoch 9 Step 501 Train Loss: 0.1620
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0283. 
Epoch 10 Step 1 Train Loss: 0.1414
Epoch 10 Step 51 Train Loss: 0.1594
Epoch 10 Step 101 Train Loss: 0.1736
Epoch 10 Step 151 Train Loss: 0.2390
Epoch 10 Step 201 Train Loss: 0.1958
Epoch 10 Step 251 Train Loss: 0.1703
Epoch 10 Step 301 Train Loss: 0.2017
Epoch 10 Step 351 Train Loss: 0.1784
Epoch 10 Step 401 Train Loss: 0.1802
Epoch 10 Step 451 Train Loss: 0.1816
Epoch 10 Step 501 Train Loss: 0.1640
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0283. 
Epoch 11 Step 1 Train Loss: 0.1532
Epoch 11 Step 51 Train Loss: 0.1698
Epoch 11 Step 101 Train Loss: 0.1584
Epoch 11 Step 151 Train Loss: 0.1676
Epoch 11 Step 201 Train Loss: 0.1567
Epoch 11 Step 251 Train Loss: 0.1284
Epoch 11 Step 301 Train Loss: 0.1875
Epoch 11 Step 351 Train Loss: 0.1785
Epoch 11 Step 401 Train Loss: 0.1748
Epoch 11 Step 451 Train Loss: 0.1484
Epoch 11 Step 501 Train Loss: 0.1906
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0137 Validation Top 20 DE MSE: 0.0284. 
Epoch 12 Step 1 Train Loss: 0.1408
Epoch 12 Step 51 Train Loss: 0.1835
Epoch 12 Step 101 Train Loss: 0.1672
Epoch 12 Step 151 Train Loss: 0.1940
Epoch 12 Step 201 Train Loss: 0.1893
Epoch 12 Step 251 Train Loss: 0.1540
Epoch 12 Step 301 Train Loss: 0.1539
Epoch 12 Step 351 Train Loss: 0.1478
Epoch 12 Step 401 Train Loss: 0.1761
Epoch 12 Step 451 Train Loss: 0.1738
Epoch 12 Step 501 Train Loss: 0.1735
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0282. 
Epoch 13 Step 1 Train Loss: 0.1656
Epoch 13 Step 51 Train Loss: 0.1606
Epoch 13 Step 101 Train Loss: 0.1708
Epoch 13 Step 151 Train Loss: 0.1790
Epoch 13 Step 201 Train Loss: 0.1638
Epoch 13 Step 251 Train Loss: 0.1472
Epoch 13 Step 301 Train Loss: 0.1717
Epoch 13 Step 351 Train Loss: 0.1633
Epoch 13 Step 401 Train Loss: 0.1725
Epoch 13 Step 451 Train Loss: 0.1527
Epoch 13 Step 501 Train Loss: 0.1713
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0136 Validation Top 20 DE MSE: 0.0284. 
Epoch 14 Step 1 Train Loss: 0.2154
Epoch 14 Step 51 Train Loss: 0.1669
Epoch 14 Step 101 Train Loss: 0.1493
Epoch 14 Step 151 Train Loss: 0.1494
Epoch 14 Step 201 Train Loss: 0.1668
Epoch 14 Step 251 Train Loss: 0.1672
Epoch 14 Step 301 Train Loss: 0.1821
Epoch 14 Step 351 Train Loss: 0.1710
Epoch 14 Step 401 Train Loss: 0.1617
Epoch 14 Step 451 Train Loss: 0.1689
Epoch 14 Step 501 Train Loss: 0.1780
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0137 Validation Top 20 DE MSE: 0.0285. 
Epoch 15 Step 1 Train Loss: 0.1678
Epoch 15 Step 51 Train Loss: 0.1799
Epoch 15 Step 101 Train Loss: 0.1442
Epoch 15 Step 151 Train Loss: 0.1342
Epoch 15 Step 201 Train Loss: 0.1791
Epoch 15 Step 251 Train Loss: 0.2100
Epoch 15 Step 301 Train Loss: 0.1763
Epoch 15 Step 351 Train Loss: 0.1555
Epoch 15 Step 401 Train Loss: 0.1636
Epoch 15 Step 451 Train Loss: 0.2060
Epoch 15 Step 501 Train Loss: 0.1793
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0282. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0193
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0020791923
test_combo_seen0_pearson: 0.908115115822996
test_combo_seen0_mse_de: 0.023301877
test_combo_seen0_pearson_de: 0.022631216016408898
test_combo_seen1_mse: 0.0016909613
test_combo_seen1_pearson: 0.9254949425295721
test_combo_seen1_mse_de: 0.019410787
test_combo_seen1_pearson_de: 0.09938416069710795
test_combo_seen2_mse: 0.0017428447
test_combo_seen2_pearson: 0.923061730319848
test_combo_seen2_mse_de: 0.02052072
test_combo_seen2_pearson_de: 0.03790645147909316
test_unseen_single_mse: 0.00043039647
test_unseen_single_pearson: 0.980066926118561
test_unseen_single_mse_de: 0.0012634556
test_unseen_single_pearson_de: 0.41086430626391435
test_combo_seen0_pearson_delta: 0.011736635247926357
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.5131578947368421
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.5684210526315789
test_combo_seen0_mse_top20_de_non_dropout: 0.0870975
test_combo_seen1_pearson_delta: 0.007819883104910861
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.5043478260869566
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5385869565217392
test_combo_seen1_mse_top20_de_non_dropout: 0.055353206
test_combo_seen2_pearson_delta: 0.0012736999946838007
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5357142857142857
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.6589285714285714
test_combo_seen2_mse_top20_de_non_dropout: 0.06335284
test_unseen_single_pearson_delta: 0.0561525757248964
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4785714285714286
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7142857142857143
test_unseen_single_mse_top20_de_non_dropout: 0.00095778157
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.023 MB uploadedwandb: | 0.001 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                             train_de_pearson â–â–ƒâ–‚â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                                                    train_mse â–ˆâ–‚â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:                                                train_pearson â–â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                                training_loss â–ˆâ–‡â–‡â–ˆâ–‡â–…â–…â–…â–„â–„â–„â–ƒâ–„â–â–„â–‚â–‚â–†â–â–ƒâ–‚â–‡â–‚â–„â–ƒâ–â–„â–…â–‡â–‚â–ƒâ–ƒâ–„â–‚â–„â–„â–‚â–†â–‡â–„
wandb:                                                   val_de_mse â–ˆâ–â–…â–…â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:                                               val_de_pearson â–â–…â–‚â–‡â–ˆâ–†â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                                                      val_mse â–ˆâ–‚â–„â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                                                  val_pearson â–â–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.51316
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.56842
wandb:                                         test_combo_seen0_mse 0.00208
wandb:                                      test_combo_seen0_mse_de 0.0233
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.0871
wandb:                                     test_combo_seen0_pearson 0.90812
wandb:                                  test_combo_seen0_pearson_de 0.02263
wandb:                               test_combo_seen0_pearson_delta 0.01174
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.50435
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.53859
wandb:                                         test_combo_seen1_mse 0.00169
wandb:                                      test_combo_seen1_mse_de 0.01941
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05535
wandb:                                     test_combo_seen1_pearson 0.92549
wandb:                                  test_combo_seen1_pearson_de 0.09938
wandb:                               test_combo_seen1_pearson_delta 0.00782
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.53571
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.65893
wandb:                                         test_combo_seen2_mse 0.00174
wandb:                                      test_combo_seen2_mse_de 0.02052
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.06335
wandb:                                     test_combo_seen2_pearson 0.92306
wandb:                                  test_combo_seen2_pearson_de 0.03791
wandb:                               test_combo_seen2_pearson_delta 0.00127
wandb:                                                  test_de_mse 0.01926
wandb:                                              test_de_pearson 0.09254
wandb:               test_frac_opposite_direction_top20_non_dropout 0.51027
wandb:                          test_frac_sigma_below_1_non_dropout 0.57397
wandb:                                                     test_mse 0.00169
wandb:                                test_mse_top20_de_non_dropout 0.05841
wandb:                                                 test_pearson 0.92538
wandb:                                           test_pearson_delta 0.00939
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.47857
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.71429
wandb:                                       test_unseen_single_mse 0.00043
wandb:                                    test_unseen_single_mse_de 0.00126
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00096
wandb:                                   test_unseen_single_pearson 0.98007
wandb:                                test_unseen_single_pearson_de 0.41086
wandb:                             test_unseen_single_pearson_delta 0.05615
wandb:                                                 train_de_mse 0.01349
wandb:                                             train_de_pearson 0.18439
wandb:                                                    train_mse 0.00108
wandb:                                                train_pearson 0.95473
wandb:                                                training_loss 0.17567
wandb:                                                   val_de_mse 0.02822
wandb:                                               val_de_pearson 0.03445
wandb:                                                      val_mse 0.00189
wandb:                                                  val_pearson 0.9198
wandb: 
wandb: ðŸš€ View run TianKampmann2019_iPSC_split4 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/2eujkhd8
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_074830-2eujkhd8/logs
Creating new splits....
Saving new splits at /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/tiankampmann2019_ipsc/splits/tiankampmann2019_ipsc_simulation_5_0.75.pkl
Simulation split test composition:
combo_seen0:12
combo_seen1:91
combo_seen2:30
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/benchmark_data/01A_total_re/03final/wandb/run-20240724_081426-cvsq3pey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TianKampmann2019_iPSC_split5
wandb: â­ï¸ View project at https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: ðŸš€ View run at https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/cvsq3pey
Start Training...
Epoch 1 Step 1 Train Loss: 0.2254
Epoch 1 Step 51 Train Loss: 0.2277
Epoch 1 Step 101 Train Loss: 0.2198
Epoch 1 Step 151 Train Loss: 0.2926
Epoch 1 Step 201 Train Loss: 0.2132
Epoch 1 Step 251 Train Loss: 0.2287
Epoch 1 Step 301 Train Loss: 0.2403
Epoch 1 Step 351 Train Loss: 0.2185
Epoch 1 Step 401 Train Loss: 0.2126
Epoch 1: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0387. 
Epoch 2 Step 1 Train Loss: 0.2179
Epoch 2 Step 51 Train Loss: 0.2279
Epoch 2 Step 101 Train Loss: 0.2221
Epoch 2 Step 151 Train Loss: 0.2199
Epoch 2 Step 201 Train Loss: 0.2276
Epoch 2 Step 251 Train Loss: 0.2087
Epoch 2 Step 301 Train Loss: 0.1998
Epoch 2 Step 351 Train Loss: 0.2313
Epoch 2 Step 401 Train Loss: 0.2463
Epoch 2: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0289. 
Epoch 3 Step 1 Train Loss: 0.2600
Epoch 3 Step 51 Train Loss: 0.2542
Epoch 3 Step 101 Train Loss: 0.2799
Epoch 3 Step 151 Train Loss: 0.2627
Epoch 3 Step 201 Train Loss: 0.2575
Epoch 3 Step 251 Train Loss: 0.2441
Epoch 3 Step 301 Train Loss: 0.2552
Epoch 3 Step 351 Train Loss: 0.2052
Epoch 3 Step 401 Train Loss: 0.2268
Epoch 3: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0087 Validation Top 20 DE MSE: 0.0267. 
Epoch 4 Step 1 Train Loss: 0.2274
Epoch 4 Step 51 Train Loss: 0.2176
Epoch 4 Step 101 Train Loss: 0.2002
Epoch 4 Step 151 Train Loss: 0.2248
Epoch 4 Step 201 Train Loss: 0.2199
Epoch 4 Step 251 Train Loss: 0.2123
Epoch 4 Step 301 Train Loss: 0.2099
Epoch 4 Step 351 Train Loss: 0.2383
Epoch 4 Step 401 Train Loss: 0.3136
Epoch 4: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0297. 
Epoch 5 Step 1 Train Loss: 0.2323
Epoch 5 Step 51 Train Loss: 0.2496
Epoch 5 Step 101 Train Loss: 0.2227
Epoch 5 Step 151 Train Loss: 0.2218
Epoch 5 Step 201 Train Loss: 0.2102
Epoch 5 Step 251 Train Loss: 0.2028
Epoch 5 Step 301 Train Loss: 0.2296
Epoch 5 Step 351 Train Loss: 0.2252
Epoch 5 Step 401 Train Loss: 0.1979
Epoch 5: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0311. 
Epoch 6 Step 1 Train Loss: 0.2581
Epoch 6 Step 51 Train Loss: 0.2186
Epoch 6 Step 101 Train Loss: 0.2086
Epoch 6 Step 151 Train Loss: 0.2050
Epoch 6 Step 201 Train Loss: 0.1986
Epoch 6 Step 251 Train Loss: 0.2083
Epoch 6 Step 301 Train Loss: 0.2141
Epoch 6 Step 351 Train Loss: 0.2128
Epoch 6 Step 401 Train Loss: 0.2318
Epoch 6: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0309. 
Epoch 7 Step 1 Train Loss: 0.2447
Epoch 7 Step 51 Train Loss: 0.1989
Epoch 7 Step 101 Train Loss: 0.2184
Epoch 7 Step 151 Train Loss: 0.1866
Epoch 7 Step 201 Train Loss: 0.2098
Epoch 7 Step 251 Train Loss: 0.1836
Epoch 7 Step 301 Train Loss: 0.2117
Epoch 7 Step 351 Train Loss: 0.2141
Epoch 7 Step 401 Train Loss: 0.2304
Epoch 7: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0314. 
Epoch 8 Step 1 Train Loss: 0.2241
Epoch 8 Step 51 Train Loss: 0.1791
Epoch 8 Step 101 Train Loss: 0.2271
Epoch 8 Step 151 Train Loss: 0.2016
Epoch 8 Step 201 Train Loss: 0.2105
Epoch 8 Step 251 Train Loss: 0.1985
Epoch 8 Step 301 Train Loss: 0.1985
Epoch 8 Step 351 Train Loss: 0.1843
Epoch 8 Step 401 Train Loss: 0.1754
Epoch 8: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0310. 
Epoch 9 Step 1 Train Loss: 0.1755
Epoch 9 Step 51 Train Loss: 0.2100
Epoch 9 Step 101 Train Loss: 0.2051
Epoch 9 Step 151 Train Loss: 0.1839
Epoch 9 Step 201 Train Loss: 0.1876
Epoch 9 Step 251 Train Loss: 0.1670
Epoch 9 Step 301 Train Loss: 0.1607
Epoch 9 Step 351 Train Loss: 0.2024
Epoch 9 Step 401 Train Loss: 0.1661
Epoch 9: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0316. 
Epoch 10 Step 1 Train Loss: 0.1701
Epoch 10 Step 51 Train Loss: 0.1656
Epoch 10 Step 101 Train Loss: 0.1831
Epoch 10 Step 151 Train Loss: 0.1856
Epoch 10 Step 201 Train Loss: 0.1793
Epoch 10 Step 251 Train Loss: 0.1905
Epoch 10 Step 301 Train Loss: 0.2023
Epoch 10 Step 351 Train Loss: 0.1990
Epoch 10 Step 401 Train Loss: 0.1956
Epoch 10: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0320. 
Epoch 11 Step 1 Train Loss: 0.1788
Epoch 11 Step 51 Train Loss: 0.1991
Epoch 11 Step 101 Train Loss: 0.1971
Epoch 11 Step 151 Train Loss: 0.1547
Epoch 11 Step 201 Train Loss: 0.1562
Epoch 11 Step 251 Train Loss: 0.1750
Epoch 11 Step 301 Train Loss: 0.1710
Epoch 11 Step 351 Train Loss: 0.1679
Epoch 11 Step 401 Train Loss: 0.1983
Epoch 11: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0315. 
Epoch 12 Step 1 Train Loss: 0.2393
Epoch 12 Step 51 Train Loss: 0.1835
Epoch 12 Step 101 Train Loss: 0.2024
Epoch 12 Step 151 Train Loss: 0.1839
Epoch 12 Step 201 Train Loss: 0.1735
Epoch 12 Step 251 Train Loss: 0.1972
Epoch 12 Step 301 Train Loss: 0.1921
Epoch 12 Step 351 Train Loss: 0.2088
Epoch 12 Step 401 Train Loss: 0.1981
Epoch 12: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0314. 
Epoch 13 Step 1 Train Loss: 0.1904
Epoch 13 Step 51 Train Loss: 0.2056
Epoch 13 Step 101 Train Loss: 0.1961
Epoch 13 Step 151 Train Loss: 0.1629
Epoch 13 Step 201 Train Loss: 0.1606
Epoch 13 Step 251 Train Loss: 0.1740
Epoch 13 Step 301 Train Loss: 0.1807
Epoch 13 Step 351 Train Loss: 0.2074
Epoch 13 Step 401 Train Loss: 0.2025
Epoch 13: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0314. 
Epoch 14 Step 1 Train Loss: 0.1978
Epoch 14 Step 51 Train Loss: 0.1899
Epoch 14 Step 101 Train Loss: 0.1862
Epoch 14 Step 151 Train Loss: 0.2118
Epoch 14 Step 201 Train Loss: 0.1960
Epoch 14 Step 251 Train Loss: 0.1779
Epoch 14 Step 301 Train Loss: 0.1804
Epoch 14 Step 351 Train Loss: 0.1990
Epoch 14 Step 401 Train Loss: 0.2061
Epoch 14: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0314. 
Epoch 15 Step 1 Train Loss: 0.1873
Epoch 15 Step 51 Train Loss: 0.2031
Epoch 15 Step 101 Train Loss: 0.1808
Epoch 15 Step 151 Train Loss: 0.1807
Epoch 15 Step 201 Train Loss: 0.1916
Epoch 15 Step 251 Train Loss: 0.1964
Epoch 15 Step 301 Train Loss: 0.2055
Epoch 15 Step 351 Train Loss: 0.2307
Epoch 15 Step 401 Train Loss: 0.1683
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0316. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0200
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0010177173
test_combo_seen0_pearson: 0.9523495674305934
test_combo_seen0_mse_de: 0.011274519
test_combo_seen0_pearson_de: 0.014503095017601888
test_combo_seen1_mse: 0.0017087249
test_combo_seen1_pearson: 0.9252812957039939
test_combo_seen1_mse_de: 0.021278711
test_combo_seen1_pearson_de: 0.08968413083203984
test_combo_seen2_mse: 0.0014864786
test_combo_seen2_pearson: 0.9342219984125146
test_combo_seen2_mse_de: 0.023986896
test_combo_seen2_pearson_de: 0.10683390273721455
test_unseen_single_mse: 0.0001483512
test_unseen_single_pearson: 0.9929197503996002
test_unseen_single_mse_de: 0.00040701017
test_unseen_single_pearson_de: 0.37372668435426115
test_combo_seen0_pearson_delta: 0.019072078534319723
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.43333333333333335
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.65
test_combo_seen0_mse_top20_de_non_dropout: 0.027972085
test_combo_seen1_pearson_delta: 0.0017007581179224133
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.5016483516483515
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5895604395604396
test_combo_seen1_mse_top20_de_non_dropout: 0.07138167
test_combo_seen2_pearson_delta: -0.010795062771321244
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5033333333333334
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.5383333333333333
test_combo_seen2_mse_top20_de_non_dropout: 0.06095153
test_unseen_single_pearson_delta: 0.06518188259820563
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.43571428571428567
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8357142857142856
test_unseen_single_mse_top20_de_non_dropout: 0.00045346166
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.001 MB uploadedwandb: / 0.001 MB of 0.022 MB uploadedwandb: - 0.004 MB of 0.022 MB uploadedwandb: \ 0.017 MB of 0.022 MB uploadedwandb: | 0.017 MB of 0.022 MB uploadedwandb: / 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen0_mse â–
wandb:                                      test_combo_seen0_mse_de â–
wandb:                    test_combo_seen0_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen0_pearson â–
wandb:                                  test_combo_seen0_pearson_de â–
wandb:                               test_combo_seen0_pearson_delta â–
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen1_mse â–
wandb:                                      test_combo_seen1_mse_de â–
wandb:                    test_combo_seen1_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen1_pearson â–
wandb:                                  test_combo_seen1_pearson_de â–
wandb:                               test_combo_seen1_pearson_delta â–
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout â–
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout â–
wandb:                                         test_combo_seen2_mse â–
wandb:                                      test_combo_seen2_mse_de â–
wandb:                    test_combo_seen2_mse_top20_de_non_dropout â–
wandb:                                     test_combo_seen2_pearson â–
wandb:                                  test_combo_seen2_pearson_de â–
wandb:                               test_combo_seen2_pearson_delta â–
wandb:                                                  test_de_mse â–
wandb:                                              test_de_pearson â–
wandb:               test_frac_opposite_direction_top20_non_dropout â–
wandb:                          test_frac_sigma_below_1_non_dropout â–
wandb:                                                     test_mse â–
wandb:                                test_mse_top20_de_non_dropout â–
wandb:                                                 test_pearson â–
wandb:                                           test_pearson_delta â–
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout â–
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout â–
wandb:                                       test_unseen_single_mse â–
wandb:                                    test_unseen_single_mse_de â–
wandb:                  test_unseen_single_mse_top20_de_non_dropout â–
wandb:                                   test_unseen_single_pearson â–
wandb:                                test_unseen_single_pearson_de â–
wandb:                             test_unseen_single_pearson_delta â–
wandb:                                                 train_de_mse â–ˆâ–ƒâ–â–ƒâ–„â–„â–…â–„â–…â–…â–…â–…â–…â–…â–…
wandb:                                             train_de_pearson â–â–…â–„â–ˆâ–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:                                                    train_mse â–ˆâ–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                                                train_pearson â–â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡
wandb:                                                training_loss â–ˆâ–†â–…â–…â–…â–†â–‡â–‚â–…â–„â–†â–…â–„â–ˆâ–ƒâ–„â–„â–„â–…â–…â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–…â–
wandb:                                                   val_de_mse â–ˆâ–‚â–â–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–„â–„
wandb:                                               val_de_pearson â–â–â–ˆâ–‡â–ˆâ–‡â–…â–†â–…â–…â–…â–†â–†â–†â–…
wandb:                                                      val_mse â–ˆâ–‚â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–„
wandb:                                                  val_pearson â–â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.43333
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.65
wandb:                                         test_combo_seen0_mse 0.00102
wandb:                                      test_combo_seen0_mse_de 0.01127
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.02797
wandb:                                     test_combo_seen0_pearson 0.95235
wandb:                                  test_combo_seen0_pearson_de 0.0145
wandb:                               test_combo_seen0_pearson_delta 0.01907
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.50165
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.58956
wandb:                                         test_combo_seen1_mse 0.00171
wandb:                                      test_combo_seen1_mse_de 0.02128
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.07138
wandb:                                     test_combo_seen1_pearson 0.92528
wandb:                                  test_combo_seen1_pearson_de 0.08968
wandb:                               test_combo_seen1_pearson_delta 0.0017
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.50333
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.53833
wandb:                                         test_combo_seen2_mse 0.00149
wandb:                                      test_combo_seen2_mse_de 0.02399
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.06095
wandb:                                     test_combo_seen2_pearson 0.93422
wandb:                                  test_combo_seen2_pearson_de 0.10683
wandb:                               test_combo_seen2_pearson_delta -0.0108
wandb:                                                  test_de_mse 0.01996
wandb:                                              test_de_pearson 0.10112
wandb:               test_frac_opposite_direction_top20_non_dropout 0.49286
wandb:                          test_frac_sigma_below_1_non_dropout 0.59607
wandb:                                                     test_mse 0.00152
wandb:                                test_mse_top20_de_non_dropout 0.06188
wandb:                                                 test_pearson 0.9329
wandb:                                           test_pearson_delta 0.00369
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.43571
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.83571
wandb:                                       test_unseen_single_mse 0.00015
wandb:                                    test_unseen_single_mse_de 0.00041
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00045
wandb:                                   test_unseen_single_pearson 0.99292
wandb:                                test_unseen_single_pearson_de 0.37373
wandb:                             test_unseen_single_pearson_delta 0.06518
wandb:                                                 train_de_mse 0.01167
wandb:                                             train_de_pearson 0.13032
wandb:                                                    train_mse 0.00167
wandb:                                                train_pearson 0.94241
wandb:                                                training_loss 0.18456
wandb:                                                   val_de_mse 0.03159
wandb:                                               val_de_pearson 0.07831
wandb:                                                      val_mse 0.00266
wandb:                                                  val_pearson 0.9036
wandb: 
wandb: ðŸš€ View run TianKampmann2019_iPSC_split5 at: https://wandb.ai/zhoumin1130/01_dataset_all_gears/runs/cvsq3pey
wandb: â­ï¸ View project at: https://wandb.ai/zhoumin1130/01_dataset_all_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240724_081426-cvsq3pey/logs
