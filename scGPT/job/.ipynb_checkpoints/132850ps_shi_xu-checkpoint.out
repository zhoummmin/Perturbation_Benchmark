环境设置完成！
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_arrayed_RNA/scgpt/split1
scGPT - INFO - Running on 2024-07-26 21:52:57
scGPT - INFO - match 4997/5000 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/120 batches | lr 0.0001 | ms/batch 405.88 | loss  0.15 | mse  0.15 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 50.67s | valid loss/mse 0.0868 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0868
scGPT - INFO - | epoch   2 | 100/120 batches | lr 0.0001 | ms/batch 395.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 49.58s | valid loss/mse 0.0854 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0854
scGPT - INFO - | epoch   3 | 100/120 batches | lr 0.0001 | ms/batch 394.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 49.54s | valid loss/mse 0.0843 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0843
scGPT - INFO - | epoch   4 | 100/120 batches | lr 0.0001 | ms/batch 395.21 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 49.59s | valid loss/mse 0.0850 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/120 batches | lr 0.0001 | ms/batch 395.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 49.59s | valid loss/mse 0.0856 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/120 batches | lr 0.0001 | ms/batch 395.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 49.60s | valid loss/mse 0.0852 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/120 batches | lr 0.0001 | ms/batch 395.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 49.60s | valid loss/mse 0.0860 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/120 batches | lr 0.0000 | ms/batch 395.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 49.59s | valid loss/mse 0.0862 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 8
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_arrayed_RNA/scgpt/split2
scGPT - INFO - Running on 2024-07-26 22:00:59
scGPT - INFO - match 4997/5000 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/121 batches | lr 0.0001 | ms/batch 395.46 | loss  0.15 | mse  0.15 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 49.06s | valid loss/mse 0.0993 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0993
scGPT - INFO - | epoch   2 | 100/121 batches | lr 0.0001 | ms/batch 395.61 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 49.06s | valid loss/mse 0.0955 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0955
scGPT - INFO - | epoch   3 | 100/121 batches | lr 0.0001 | ms/batch 395.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 49.08s | valid loss/mse 0.0949 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0949
scGPT - INFO - | epoch   4 | 100/121 batches | lr 0.0001 | ms/batch 395.71 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 49.07s | valid loss/mse 0.0963 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/121 batches | lr 0.0001 | ms/batch 395.56 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 49.06s | valid loss/mse 0.0912 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0912
scGPT - INFO - | epoch   6 | 100/121 batches | lr 0.0001 | ms/batch 395.80 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 49.08s | valid loss/mse 0.0935 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/121 batches | lr 0.0001 | ms/batch 395.64 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 49.08s | valid loss/mse 0.0914 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/121 batches | lr 0.0000 | ms/batch 396.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 49.12s | valid loss/mse 0.0911 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0911
scGPT - INFO - | epoch   9 | 100/121 batches | lr 0.0000 | ms/batch 395.89 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 49.10s | valid loss/mse 0.0933 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/121 batches | lr 0.0000 | ms/batch 395.93 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 49.10s | valid loss/mse 0.0953 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/121 batches | lr 0.0000 | ms/batch 395.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 49.05s | valid loss/mse 0.0928 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/121 batches | lr 0.0000 | ms/batch 395.69 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 49.08s | valid loss/mse 0.0953 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/121 batches | lr 0.0000 | ms/batch 396.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 49.12s | valid loss/mse 0.0927 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 13
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_arrayed_RNA/scgpt/split3
scGPT - INFO - Running on 2024-07-26 22:13:08
scGPT - INFO - match 4997/5000 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/115 batches | lr 0.0001 | ms/batch 395.92 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 45.12s | valid loss/mse 0.1030 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1030
scGPT - INFO - | epoch   2 | 100/115 batches | lr 0.0001 | ms/batch 396.02 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 45.12s | valid loss/mse 0.1007 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1007
scGPT - INFO - | epoch   3 | 100/115 batches | lr 0.0001 | ms/batch 395.93 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 45.11s | valid loss/mse 0.0859 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0859
scGPT - INFO - | epoch   4 | 100/115 batches | lr 0.0001 | ms/batch 396.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 45.14s | valid loss/mse 0.0807 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0807
scGPT - INFO - | epoch   5 | 100/115 batches | lr 0.0001 | ms/batch 395.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 45.09s | valid loss/mse 0.0882 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/115 batches | lr 0.0001 | ms/batch 396.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 45.13s | valid loss/mse 0.0893 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/115 batches | lr 0.0001 | ms/batch 396.41 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 45.16s | valid loss/mse 0.0868 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/115 batches | lr 0.0000 | ms/batch 396.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 45.14s | valid loss/mse 0.0960 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/115 batches | lr 0.0000 | ms/batch 395.72 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 45.08s | valid loss/mse 0.0881 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 9
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_arrayed_RNA/scgpt/split4
scGPT - INFO - Running on 2024-07-26 22:21:47
scGPT - INFO - match 4997/5000 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 41.79s | valid loss/mse 0.1123 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1123
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 41.76s | valid loss/mse 0.1022 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1022
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 41.76s | valid loss/mse 0.1027 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 41.76s | valid loss/mse 0.1021 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1021
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 41.77s | valid loss/mse 0.1067 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 41.78s | valid loss/mse 0.0971 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0971
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 41.78s | valid loss/mse 0.1117 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 41.75s | valid loss/mse 0.1008 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 41.75s | valid loss/mse 0.1047 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 41.77s | valid loss/mse 0.1045 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 41.79s | valid loss/mse 0.1100 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 11
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_arrayed_RNA/scgpt/split5
scGPT - INFO - Running on 2024-07-26 22:31:21
scGPT - INFO - match 4997/5000 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/134 batches | lr 0.0001 | ms/batch 396.22 | loss  0.15 | mse  0.15 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 52.59s | valid loss/mse 0.0781 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0781
scGPT - INFO - | epoch   2 | 100/134 batches | lr 0.0001 | ms/batch 395.77 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 52.54s | valid loss/mse 0.0836 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/134 batches | lr 0.0001 | ms/batch 398.01 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 52.76s | valid loss/mse 0.0836 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/134 batches | lr 0.0001 | ms/batch 395.66 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 52.53s | valid loss/mse 0.0797 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/134 batches | lr 0.0001 | ms/batch 395.97 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 52.56s | valid loss/mse 0.0797 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/134 batches | lr 0.0001 | ms/batch 395.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 52.55s | valid loss/mse 0.0885 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 6
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_RNA/scgpt/split1
scGPT - INFO - Running on 2024-07-26 22:55:38
scGPT - INFO - match 4999/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/374 batches | lr 0.0001 | ms/batch 404.51 | loss  0.23 | mse  0.23 |
scGPT - INFO - | epoch   1 | 200/374 batches | lr 0.0001 | ms/batch 391.63 | loss  0.15 | mse  0.15 |
scGPT - INFO - | epoch   1 | 300/374 batches | lr 0.0001 | ms/batch 394.02 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 154.62s | valid loss/mse 0.1471 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1471
scGPT - INFO - | epoch   2 | 100/374 batches | lr 0.0001 | ms/batch 395.47 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 200/374 batches | lr 0.0001 | ms/batch 391.56 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 300/374 batches | lr 0.0001 | ms/batch 391.48 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 153.47s | valid loss/mse 0.1505 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/374 batches | lr 0.0001 | ms/batch 395.52 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   3 | 200/374 batches | lr 0.0001 | ms/batch 391.39 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   3 | 300/374 batches | lr 0.0001 | ms/batch 391.32 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 153.44s | valid loss/mse 0.1499 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/374 batches | lr 0.0001 | ms/batch 395.34 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 200/374 batches | lr 0.0001 | ms/batch 391.19 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   4 | 300/374 batches | lr 0.0001 | ms/batch 391.06 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 153.36s | valid loss/mse 0.1498 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/374 batches | lr 0.0001 | ms/batch 395.96 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 200/374 batches | lr 0.0001 | ms/batch 391.70 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 300/374 batches | lr 0.0001 | ms/batch 391.53 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 153.53s | valid loss/mse 0.1503 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/374 batches | lr 0.0001 | ms/batch 395.30 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   6 | 200/374 batches | lr 0.0001 | ms/batch 391.35 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   6 | 300/374 batches | lr 0.0001 | ms/batch 391.62 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 153.44s | valid loss/mse 0.1479 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 6
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_RNA/scgpt/split2
scGPT - INFO - Running on 2024-07-26 23:21:24
scGPT - INFO - match 4999/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/372 batches | lr 0.0001 | ms/batch 395.99 | loss  0.21 | mse  0.21 |
scGPT - INFO - | epoch   1 | 200/372 batches | lr 0.0001 | ms/batch 391.70 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   1 | 300/372 batches | lr 0.0001 | ms/batch 391.74 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 153.02s | valid loss/mse 0.1540 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1540
scGPT - INFO - | epoch   2 | 100/372 batches | lr 0.0001 | ms/batch 396.05 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 200/372 batches | lr 0.0001 | ms/batch 391.41 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 300/372 batches | lr 0.0001 | ms/batch 391.64 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 152.99s | valid loss/mse 0.1495 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1495
scGPT - INFO - | epoch   3 | 100/372 batches | lr 0.0001 | ms/batch 396.03 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 200/372 batches | lr 0.0001 | ms/batch 391.99 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 300/372 batches | lr 0.0001 | ms/batch 391.91 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 153.07s | valid loss/mse 0.1510 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/372 batches | lr 0.0001 | ms/batch 395.63 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 200/372 batches | lr 0.0001 | ms/batch 392.04 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   4 | 300/372 batches | lr 0.0001 | ms/batch 391.98 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 153.05s | valid loss/mse 0.1526 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/372 batches | lr 0.0001 | ms/batch 396.08 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 200/372 batches | lr 0.0001 | ms/batch 392.01 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 300/372 batches | lr 0.0001 | ms/batch 391.82 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 153.03s | valid loss/mse 0.1496 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/372 batches | lr 0.0001 | ms/batch 395.73 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   6 | 200/372 batches | lr 0.0001 | ms/batch 392.06 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   6 | 300/372 batches | lr 0.0001 | ms/batch 392.05 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 153.05s | valid loss/mse 0.1490 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1490
scGPT - INFO - | epoch   7 | 100/372 batches | lr 0.0001 | ms/batch 396.34 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   7 | 200/372 batches | lr 0.0001 | ms/batch 392.47 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   7 | 300/372 batches | lr 0.0001 | ms/batch 392.10 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 153.19s | valid loss/mse 0.1486 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1486
scGPT - INFO - | epoch   8 | 100/372 batches | lr 0.0000 | ms/batch 395.87 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   8 | 200/372 batches | lr 0.0000 | ms/batch 391.77 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   8 | 300/372 batches | lr 0.0000 | ms/batch 391.69 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 152.96s | valid loss/mse 0.1508 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/372 batches | lr 0.0000 | ms/batch 395.65 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   9 | 200/372 batches | lr 0.0000 | ms/batch 391.49 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   9 | 300/372 batches | lr 0.0000 | ms/batch 391.46 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 152.91s | valid loss/mse 0.1503 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/372 batches | lr 0.0000 | ms/batch 395.83 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  10 | 200/372 batches | lr 0.0000 | ms/batch 391.73 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  10 | 300/372 batches | lr 0.0000 | ms/batch 392.13 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 153.04s | valid loss/mse 0.1509 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/372 batches | lr 0.0000 | ms/batch 395.87 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  11 | 200/372 batches | lr 0.0000 | ms/batch 392.04 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  11 | 300/372 batches | lr 0.0000 | ms/batch 392.16 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 153.06s | valid loss/mse 0.1481 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1481
scGPT - INFO - | epoch  12 | 100/372 batches | lr 0.0000 | ms/batch 395.54 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  12 | 200/372 batches | lr 0.0000 | ms/batch 392.05 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  12 | 300/372 batches | lr 0.0000 | ms/batch 391.95 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 153.01s | valid loss/mse 0.1496 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/372 batches | lr 0.0000 | ms/batch 395.80 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  13 | 200/372 batches | lr 0.0000 | ms/batch 391.92 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  13 | 300/372 batches | lr 0.0000 | ms/batch 391.87 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 153.01s | valid loss/mse 0.1476 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1476
scGPT - INFO - | epoch  14 | 100/372 batches | lr 0.0000 | ms/batch 396.10 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch  14 | 200/372 batches | lr 0.0000 | ms/batch 392.30 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  14 | 300/372 batches | lr 0.0000 | ms/batch 391.97 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 153.12s | valid loss/mse 0.1490 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/372 batches | lr 0.0000 | ms/batch 396.00 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  15 | 200/372 batches | lr 0.0000 | ms/batch 391.96 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  15 | 300/372 batches | lr 0.0000 | ms/batch 391.90 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 153.08s | valid loss/mse 0.1523 |
scGPT - INFO - -----------------------------------------------------------------------------------------
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_RNA/scgpt/split3
scGPT - INFO - Running on 2024-07-27 00:10:07
scGPT - INFO - match 4999/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/374 batches | lr 0.0001 | ms/batch 396.66 | loss  0.22 | mse  0.22 |
scGPT - INFO - | epoch   1 | 200/374 batches | lr 0.0001 | ms/batch 392.22 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   1 | 300/374 batches | lr 0.0001 | ms/batch 392.33 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 150.88s | valid loss/mse 0.1481 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1481
scGPT - INFO - | epoch   2 | 100/374 batches | lr 0.0001 | ms/batch 395.89 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 200/374 batches | lr 0.0001 | ms/batch 392.01 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 300/374 batches | lr 0.0001 | ms/batch 391.98 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 150.71s | valid loss/mse 0.1447 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1447
scGPT - INFO - | epoch   3 | 100/374 batches | lr 0.0001 | ms/batch 396.01 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 200/374 batches | lr 0.0001 | ms/batch 392.41 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 300/374 batches | lr 0.0001 | ms/batch 392.24 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 150.78s | valid loss/mse 0.1430 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1430
scGPT - INFO - | epoch   4 | 100/374 batches | lr 0.0001 | ms/batch 396.20 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 200/374 batches | lr 0.0001 | ms/batch 392.19 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 300/374 batches | lr 0.0001 | ms/batch 392.30 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 150.80s | valid loss/mse 0.1487 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/374 batches | lr 0.0001 | ms/batch 396.69 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   5 | 200/374 batches | lr 0.0001 | ms/batch 391.92 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 300/374 batches | lr 0.0001 | ms/batch 391.92 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 150.73s | valid loss/mse 0.1453 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/374 batches | lr 0.0001 | ms/batch 395.57 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   6 | 200/374 batches | lr 0.0001 | ms/batch 391.64 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   6 | 300/374 batches | lr 0.0001 | ms/batch 391.98 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 150.62s | valid loss/mse 0.1457 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/374 batches | lr 0.0001 | ms/batch 395.94 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   7 | 200/374 batches | lr 0.0001 | ms/batch 392.15 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   7 | 300/374 batches | lr 0.0001 | ms/batch 392.15 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 150.74s | valid loss/mse 0.1456 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/374 batches | lr 0.0000 | ms/batch 396.00 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   8 | 200/374 batches | lr 0.0000 | ms/batch 392.12 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   8 | 300/374 batches | lr 0.0000 | ms/batch 391.86 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 150.68s | valid loss/mse 0.1453 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 8
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_RNA/scgpt/split4
scGPT - INFO - Running on 2024-07-27 00:41:55
scGPT - INFO - match 4999/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/397 batches | lr 0.0001 | ms/batch 396.82 | loss  0.25 | mse  0.25 |
scGPT - INFO - | epoch   1 | 200/397 batches | lr 0.0001 | ms/batch 392.58 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   1 | 300/397 batches | lr 0.0001 | ms/batch 392.47 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 165.17s | valid loss/mse 0.1479 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1479
scGPT - INFO - | epoch   2 | 100/397 batches | lr 0.0001 | ms/batch 396.51 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 200/397 batches | lr 0.0001 | ms/batch 392.60 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 300/397 batches | lr 0.0001 | ms/batch 392.73 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 165.14s | valid loss/mse 0.1534 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/397 batches | lr 0.0001 | ms/batch 396.56 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 200/397 batches | lr 0.0001 | ms/batch 392.31 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 300/397 batches | lr 0.0001 | ms/batch 392.42 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 165.08s | valid loss/mse 0.1490 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/397 batches | lr 0.0001 | ms/batch 396.55 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 200/397 batches | lr 0.0001 | ms/batch 392.49 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   4 | 300/397 batches | lr 0.0001 | ms/batch 392.56 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 165.11s | valid loss/mse 0.1502 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/397 batches | lr 0.0001 | ms/batch 396.31 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   5 | 200/397 batches | lr 0.0001 | ms/batch 392.69 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 300/397 batches | lr 0.0001 | ms/batch 392.58 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 165.11s | valid loss/mse 0.1533 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/397 batches | lr 0.0001 | ms/batch 396.49 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   6 | 200/397 batches | lr 0.0001 | ms/batch 392.59 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   6 | 300/397 batches | lr 0.0001 | ms/batch 392.60 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 165.09s | valid loss/mse 0.1522 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 6
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/PapalexiSatija2021_eccite_RNA/scgpt/split5
scGPT - INFO - Running on 2024-07-27 01:06:04
scGPT - INFO - match 4999/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/369 batches | lr 0.0001 | ms/batch 396.32 | loss  0.25 | mse  0.25 |
scGPT - INFO - | epoch   1 | 200/369 batches | lr 0.0001 | ms/batch 392.31 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   1 | 300/369 batches | lr 0.0001 | ms/batch 392.02 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 150.78s | valid loss/mse 0.1441 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1441
scGPT - INFO - | epoch   2 | 100/369 batches | lr 0.0001 | ms/batch 395.86 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 200/369 batches | lr 0.0001 | ms/batch 392.03 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   2 | 300/369 batches | lr 0.0001 | ms/batch 391.78 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 150.63s | valid loss/mse 0.1424 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1424
scGPT - INFO - | epoch   3 | 100/369 batches | lr 0.0001 | ms/batch 396.49 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 200/369 batches | lr 0.0001 | ms/batch 392.44 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   3 | 300/369 batches | lr 0.0001 | ms/batch 392.29 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 150.83s | valid loss/mse 0.1411 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1411
scGPT - INFO - | epoch   4 | 100/369 batches | lr 0.0001 | ms/batch 396.77 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 200/369 batches | lr 0.0001 | ms/batch 392.36 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   4 | 300/369 batches | lr 0.0001 | ms/batch 392.32 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 150.83s | valid loss/mse 0.1426 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/369 batches | lr 0.0001 | ms/batch 396.26 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   5 | 200/369 batches | lr 0.0001 | ms/batch 392.42 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   5 | 300/369 batches | lr 0.0001 | ms/batch 392.51 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 150.85s | valid loss/mse 0.1416 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/369 batches | lr 0.0001 | ms/batch 396.44 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   6 | 200/369 batches | lr 0.0001 | ms/batch 392.40 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   6 | 300/369 batches | lr 0.0001 | ms/batch 392.54 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 150.85s | valid loss/mse 0.1413 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/369 batches | lr 0.0001 | ms/batch 396.39 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   7 | 200/369 batches | lr 0.0001 | ms/batch 392.54 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   7 | 300/369 batches | lr 0.0001 | ms/batch 392.38 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 150.83s | valid loss/mse 0.1405 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1405
scGPT - INFO - | epoch   8 | 100/369 batches | lr 0.0000 | ms/batch 396.51 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   8 | 200/369 batches | lr 0.0000 | ms/batch 392.60 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   8 | 300/369 batches | lr 0.0000 | ms/batch 392.65 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 150.89s | valid loss/mse 0.1412 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/369 batches | lr 0.0000 | ms/batch 396.34 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch   9 | 200/369 batches | lr 0.0000 | ms/batch 392.30 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch   9 | 300/369 batches | lr 0.0000 | ms/batch 392.13 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 150.77s | valid loss/mse 0.1413 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/369 batches | lr 0.0000 | ms/batch 396.40 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch  10 | 200/369 batches | lr 0.0000 | ms/batch 392.35 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  10 | 300/369 batches | lr 0.0000 | ms/batch 392.17 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 150.80s | valid loss/mse 0.1429 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/369 batches | lr 0.0000 | ms/batch 396.29 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch  11 | 200/369 batches | lr 0.0000 | ms/batch 392.26 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  11 | 300/369 batches | lr 0.0000 | ms/batch 392.00 | loss  0.14 | mse  0.14 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 150.74s | valid loss/mse 0.1422 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/369 batches | lr 0.0000 | ms/batch 396.16 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  12 | 200/369 batches | lr 0.0000 | ms/batch 392.21 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  12 | 300/369 batches | lr 0.0000 | ms/batch 392.15 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 150.74s | valid loss/mse 0.1400 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1400
scGPT - INFO - | epoch  13 | 100/369 batches | lr 0.0000 | ms/batch 395.86 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch  13 | 200/369 batches | lr 0.0000 | ms/batch 392.10 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  13 | 300/369 batches | lr 0.0000 | ms/batch 392.68 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 150.79s | valid loss/mse 0.1409 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/369 batches | lr 0.0000 | ms/batch 396.18 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch  14 | 200/369 batches | lr 0.0000 | ms/batch 392.54 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  14 | 300/369 batches | lr 0.0000 | ms/batch 392.35 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 150.79s | valid loss/mse 0.1414 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/369 batches | lr 0.0000 | ms/batch 396.27 | loss  0.14 | mse  0.14 |
scGPT - INFO - | epoch  15 | 200/369 batches | lr 0.0000 | ms/batch 392.29 | loss  0.13 | mse  0.13 |
scGPT - INFO - | epoch  15 | 300/369 batches | lr 0.0000 | ms/batch 392.42 | loss  0.13 | mse  0.13 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 150.80s | valid loss/mse 0.1392 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1392
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/ShifrutMarson2018/scgpt/split1
scGPT - INFO - Running on 2024-07-27 01:57:27
scGPT - INFO - match 4647/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1331 batches | lr 0.0001 | ms/batch 406.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 200/1331 batches | lr 0.0001 | ms/batch 392.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/1331 batches | lr 0.0001 | ms/batch 395.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/1331 batches | lr 0.0001 | ms/batch 394.54 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/1331 batches | lr 0.0001 | ms/batch 394.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/1331 batches | lr 0.0001 | ms/batch 394.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/1331 batches | lr 0.0001 | ms/batch 394.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 800/1331 batches | lr 0.0001 | ms/batch 393.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 900/1331 batches | lr 0.0001 | ms/batch 394.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1000/1331 batches | lr 0.0001 | ms/batch 393.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1100/1331 batches | lr 0.0001 | ms/batch 395.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1200/1331 batches | lr 0.0001 | ms/batch 394.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1300/1331 batches | lr 0.0001 | ms/batch 393.32 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 536.65s | valid loss/mse 0.0657 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0657
scGPT - INFO - | epoch   2 | 100/1331 batches | lr 0.0001 | ms/batch 398.19 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/1331 batches | lr 0.0001 | ms/batch 393.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/1331 batches | lr 0.0001 | ms/batch 394.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/1331 batches | lr 0.0001 | ms/batch 393.18 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/1331 batches | lr 0.0001 | ms/batch 393.10 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/1331 batches | lr 0.0001 | ms/batch 393.96 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/1331 batches | lr 0.0001 | ms/batch 396.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 800/1331 batches | lr 0.0001 | ms/batch 393.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 900/1331 batches | lr 0.0001 | ms/batch 392.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1000/1331 batches | lr 0.0001 | ms/batch 392.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1100/1331 batches | lr 0.0001 | ms/batch 393.21 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1200/1331 batches | lr 0.0001 | ms/batch 394.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1300/1331 batches | lr 0.0001 | ms/batch 396.18 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 535.61s | valid loss/mse 0.0662 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/1331 batches | lr 0.0001 | ms/batch 398.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/1331 batches | lr 0.0001 | ms/batch 395.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/1331 batches | lr 0.0001 | ms/batch 395.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/1331 batches | lr 0.0001 | ms/batch 396.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/1331 batches | lr 0.0001 | ms/batch 396.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/1331 batches | lr 0.0001 | ms/batch 396.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/1331 batches | lr 0.0001 | ms/batch 395.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 800/1331 batches | lr 0.0001 | ms/batch 395.98 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 900/1331 batches | lr 0.0001 | ms/batch 396.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1000/1331 batches | lr 0.0001 | ms/batch 396.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1100/1331 batches | lr 0.0001 | ms/batch 395.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1200/1331 batches | lr 0.0001 | ms/batch 395.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1300/1331 batches | lr 0.0001 | ms/batch 395.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 537.98s | valid loss/mse 0.0616 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0616
scGPT - INFO - | epoch   4 | 100/1331 batches | lr 0.0001 | ms/batch 398.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/1331 batches | lr 0.0001 | ms/batch 395.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/1331 batches | lr 0.0001 | ms/batch 395.63 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/1331 batches | lr 0.0001 | ms/batch 395.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/1331 batches | lr 0.0001 | ms/batch 395.85 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/1331 batches | lr 0.0001 | ms/batch 396.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/1331 batches | lr 0.0001 | ms/batch 396.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 800/1331 batches | lr 0.0001 | ms/batch 396.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 900/1331 batches | lr 0.0001 | ms/batch 398.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1000/1331 batches | lr 0.0001 | ms/batch 398.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1100/1331 batches | lr 0.0001 | ms/batch 399.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1200/1331 batches | lr 0.0001 | ms/batch 400.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1300/1331 batches | lr 0.0001 | ms/batch 399.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 540.13s | valid loss/mse 0.0606 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0606
scGPT - INFO - | epoch   5 | 100/1331 batches | lr 0.0001 | ms/batch 403.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/1331 batches | lr 0.0001 | ms/batch 398.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/1331 batches | lr 0.0001 | ms/batch 398.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/1331 batches | lr 0.0001 | ms/batch 399.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/1331 batches | lr 0.0001 | ms/batch 400.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/1331 batches | lr 0.0001 | ms/batch 402.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/1331 batches | lr 0.0001 | ms/batch 402.56 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 800/1331 batches | lr 0.0001 | ms/batch 401.54 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 900/1331 batches | lr 0.0001 | ms/batch 401.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1000/1331 batches | lr 0.0001 | ms/batch 401.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1100/1331 batches | lr 0.0001 | ms/batch 400.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1200/1331 batches | lr 0.0001 | ms/batch 400.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1300/1331 batches | lr 0.0001 | ms/batch 401.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 544.68s | valid loss/mse 0.0656 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/1331 batches | lr 0.0001 | ms/batch 404.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/1331 batches | lr 0.0001 | ms/batch 400.44 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/1331 batches | lr 0.0001 | ms/batch 399.80 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/1331 batches | lr 0.0001 | ms/batch 400.32 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/1331 batches | lr 0.0001 | ms/batch 402.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/1331 batches | lr 0.0001 | ms/batch 401.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/1331 batches | lr 0.0001 | ms/batch 402.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 800/1331 batches | lr 0.0001 | ms/batch 403.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 900/1331 batches | lr 0.0001 | ms/batch 403.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1000/1331 batches | lr 0.0001 | ms/batch 402.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1100/1331 batches | lr 0.0001 | ms/batch 402.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1200/1331 batches | lr 0.0001 | ms/batch 402.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1300/1331 batches | lr 0.0001 | ms/batch 402.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 546.63s | valid loss/mse 0.0644 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/1331 batches | lr 0.0001 | ms/batch 407.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/1331 batches | lr 0.0001 | ms/batch 402.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/1331 batches | lr 0.0001 | ms/batch 403.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/1331 batches | lr 0.0001 | ms/batch 403.19 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/1331 batches | lr 0.0001 | ms/batch 403.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 600/1331 batches | lr 0.0001 | ms/batch 403.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 700/1331 batches | lr 0.0001 | ms/batch 403.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 800/1331 batches | lr 0.0001 | ms/batch 403.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 900/1331 batches | lr 0.0001 | ms/batch 404.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 1000/1331 batches | lr 0.0001 | ms/batch 403.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 1100/1331 batches | lr 0.0001 | ms/batch 403.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 1200/1331 batches | lr 0.0001 | ms/batch 403.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 1300/1331 batches | lr 0.0001 | ms/batch 404.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 548.83s | valid loss/mse 0.0700 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/1331 batches | lr 0.0000 | ms/batch 408.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/1331 batches | lr 0.0000 | ms/batch 404.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/1331 batches | lr 0.0000 | ms/batch 404.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 400/1331 batches | lr 0.0000 | ms/batch 405.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 500/1331 batches | lr 0.0000 | ms/batch 404.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 600/1331 batches | lr 0.0000 | ms/batch 403.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 700/1331 batches | lr 0.0000 | ms/batch 404.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 800/1331 batches | lr 0.0000 | ms/batch 404.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 900/1331 batches | lr 0.0000 | ms/batch 404.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 1000/1331 batches | lr 0.0000 | ms/batch 404.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 1100/1331 batches | lr 0.0000 | ms/batch 404.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 1200/1331 batches | lr 0.0000 | ms/batch 404.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 1300/1331 batches | lr 0.0000 | ms/batch 405.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 550.33s | valid loss/mse 0.0611 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/1331 batches | lr 0.0000 | ms/batch 409.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 200/1331 batches | lr 0.0000 | ms/batch 404.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 300/1331 batches | lr 0.0000 | ms/batch 404.93 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 400/1331 batches | lr 0.0000 | ms/batch 405.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 500/1331 batches | lr 0.0000 | ms/batch 404.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 600/1331 batches | lr 0.0000 | ms/batch 403.74 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 700/1331 batches | lr 0.0000 | ms/batch 404.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 800/1331 batches | lr 0.0000 | ms/batch 404.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 900/1331 batches | lr 0.0000 | ms/batch 404.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 1000/1331 batches | lr 0.0000 | ms/batch 404.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 1100/1331 batches | lr 0.0000 | ms/batch 404.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 1200/1331 batches | lr 0.0000 | ms/batch 404.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 1300/1331 batches | lr 0.0000 | ms/batch 404.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 550.32s | valid loss/mse 0.0601 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0601
scGPT - INFO - | epoch  10 | 100/1331 batches | lr 0.0000 | ms/batch 409.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 200/1331 batches | lr 0.0000 | ms/batch 404.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 300/1331 batches | lr 0.0000 | ms/batch 404.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 400/1331 batches | lr 0.0000 | ms/batch 404.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 500/1331 batches | lr 0.0000 | ms/batch 409.68 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 600/1331 batches | lr 0.0000 | ms/batch 404.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 700/1331 batches | lr 0.0000 | ms/batch 405.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 800/1331 batches | lr 0.0000 | ms/batch 404.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 900/1331 batches | lr 0.0000 | ms/batch 403.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 1000/1331 batches | lr 0.0000 | ms/batch 404.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 1100/1331 batches | lr 0.0000 | ms/batch 404.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 1200/1331 batches | lr 0.0000 | ms/batch 404.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 1300/1331 batches | lr 0.0000 | ms/batch 404.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 550.91s | valid loss/mse 0.0594 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0594
scGPT - INFO - | epoch  11 | 100/1331 batches | lr 0.0000 | ms/batch 409.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 200/1331 batches | lr 0.0000 | ms/batch 404.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 300/1331 batches | lr 0.0000 | ms/batch 404.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 400/1331 batches | lr 0.0000 | ms/batch 404.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 500/1331 batches | lr 0.0000 | ms/batch 404.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 600/1331 batches | lr 0.0000 | ms/batch 404.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 700/1331 batches | lr 0.0000 | ms/batch 403.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 800/1331 batches | lr 0.0000 | ms/batch 404.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 900/1331 batches | lr 0.0000 | ms/batch 404.60 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 1000/1331 batches | lr 0.0000 | ms/batch 404.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 1100/1331 batches | lr 0.0000 | ms/batch 404.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 1200/1331 batches | lr 0.0000 | ms/batch 404.73 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 1300/1331 batches | lr 0.0000 | ms/batch 405.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 550.22s | valid loss/mse 0.0685 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/1331 batches | lr 0.0000 | ms/batch 408.73 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 200/1331 batches | lr 0.0000 | ms/batch 404.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 300/1331 batches | lr 0.0000 | ms/batch 404.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 400/1331 batches | lr 0.0000 | ms/batch 404.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 500/1331 batches | lr 0.0000 | ms/batch 404.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 600/1331 batches | lr 0.0000 | ms/batch 404.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 700/1331 batches | lr 0.0000 | ms/batch 404.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 800/1331 batches | lr 0.0000 | ms/batch 404.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 900/1331 batches | lr 0.0000 | ms/batch 404.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 1000/1331 batches | lr 0.0000 | ms/batch 403.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 1100/1331 batches | lr 0.0000 | ms/batch 404.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 1200/1331 batches | lr 0.0000 | ms/batch 404.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 1300/1331 batches | lr 0.0000 | ms/batch 404.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 550.00s | valid loss/mse 0.0655 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/1331 batches | lr 0.0000 | ms/batch 408.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 200/1331 batches | lr 0.0000 | ms/batch 404.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 300/1331 batches | lr 0.0000 | ms/batch 404.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 400/1331 batches | lr 0.0000 | ms/batch 404.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 500/1331 batches | lr 0.0000 | ms/batch 404.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 600/1331 batches | lr 0.0000 | ms/batch 404.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 700/1331 batches | lr 0.0000 | ms/batch 404.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 800/1331 batches | lr 0.0000 | ms/batch 404.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 900/1331 batches | lr 0.0000 | ms/batch 404.29 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 1000/1331 batches | lr 0.0000 | ms/batch 404.35 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 1100/1331 batches | lr 0.0000 | ms/batch 403.80 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 1200/1331 batches | lr 0.0000 | ms/batch 404.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 1300/1331 batches | lr 0.0000 | ms/batch 404.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 550.15s | valid loss/mse 0.0601 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/1331 batches | lr 0.0000 | ms/batch 408.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 200/1331 batches | lr 0.0000 | ms/batch 404.98 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 300/1331 batches | lr 0.0000 | ms/batch 404.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 400/1331 batches | lr 0.0000 | ms/batch 404.54 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 500/1331 batches | lr 0.0000 | ms/batch 404.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 600/1331 batches | lr 0.0000 | ms/batch 404.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 700/1331 batches | lr 0.0000 | ms/batch 404.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 800/1331 batches | lr 0.0000 | ms/batch 404.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 900/1331 batches | lr 0.0000 | ms/batch 404.60 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 1000/1331 batches | lr 0.0000 | ms/batch 404.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 1100/1331 batches | lr 0.0000 | ms/batch 404.96 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 1200/1331 batches | lr 0.0000 | ms/batch 404.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 1300/1331 batches | lr 0.0000 | ms/batch 405.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 550.45s | valid loss/mse 0.0628 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/1331 batches | lr 0.0000 | ms/batch 409.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 200/1331 batches | lr 0.0000 | ms/batch 405.35 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 300/1331 batches | lr 0.0000 | ms/batch 405.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 400/1331 batches | lr 0.0000 | ms/batch 405.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 500/1331 batches | lr 0.0000 | ms/batch 405.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 600/1331 batches | lr 0.0000 | ms/batch 405.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 700/1331 batches | lr 0.0000 | ms/batch 405.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 800/1331 batches | lr 0.0000 | ms/batch 405.24 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 900/1331 batches | lr 0.0000 | ms/batch 405.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 1000/1331 batches | lr 0.0000 | ms/batch 405.44 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 1100/1331 batches | lr 0.0000 | ms/batch 405.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 1200/1331 batches | lr 0.0000 | ms/batch 405.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  15 | 1300/1331 batches | lr 0.0000 | ms/batch 405.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 551.38s | valid loss/mse 0.0647 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 15
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/ShifrutMarson2018/scgpt/split2
scGPT - INFO - Running on 2024-07-27 04:17:28
scGPT - INFO - match 4647/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1350 batches | lr 0.0001 | ms/batch 401.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 200/1350 batches | lr 0.0001 | ms/batch 397.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 300/1350 batches | lr 0.0001 | ms/batch 392.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/1350 batches | lr 0.0001 | ms/batch 392.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/1350 batches | lr 0.0001 | ms/batch 392.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/1350 batches | lr 0.0001 | ms/batch 392.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/1350 batches | lr 0.0001 | ms/batch 392.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 800/1350 batches | lr 0.0001 | ms/batch 392.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 900/1350 batches | lr 0.0001 | ms/batch 392.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1000/1350 batches | lr 0.0001 | ms/batch 392.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1100/1350 batches | lr 0.0001 | ms/batch 392.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1200/1350 batches | lr 0.0001 | ms/batch 392.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1300/1350 batches | lr 0.0001 | ms/batch 392.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 537.59s | valid loss/mse 0.0598 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0598
scGPT - INFO - | epoch   2 | 100/1350 batches | lr 0.0001 | ms/batch 396.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/1350 batches | lr 0.0001 | ms/batch 393.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/1350 batches | lr 0.0001 | ms/batch 392.65 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/1350 batches | lr 0.0001 | ms/batch 392.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/1350 batches | lr 0.0001 | ms/batch 392.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/1350 batches | lr 0.0001 | ms/batch 393.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/1350 batches | lr 0.0001 | ms/batch 392.80 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 800/1350 batches | lr 0.0001 | ms/batch 392.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 900/1350 batches | lr 0.0001 | ms/batch 393.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1000/1350 batches | lr 0.0001 | ms/batch 393.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1100/1350 batches | lr 0.0001 | ms/batch 393.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1200/1350 batches | lr 0.0001 | ms/batch 393.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1300/1350 batches | lr 0.0001 | ms/batch 393.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 537.09s | valid loss/mse 0.0688 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/1350 batches | lr 0.0001 | ms/batch 397.73 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/1350 batches | lr 0.0001 | ms/batch 393.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/1350 batches | lr 0.0001 | ms/batch 393.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/1350 batches | lr 0.0001 | ms/batch 393.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/1350 batches | lr 0.0001 | ms/batch 393.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/1350 batches | lr 0.0001 | ms/batch 393.74 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/1350 batches | lr 0.0001 | ms/batch 393.84 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 800/1350 batches | lr 0.0001 | ms/batch 394.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 900/1350 batches | lr 0.0001 | ms/batch 394.24 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1000/1350 batches | lr 0.0001 | ms/batch 394.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1100/1350 batches | lr 0.0001 | ms/batch 394.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1200/1350 batches | lr 0.0001 | ms/batch 394.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 1300/1350 batches | lr 0.0001 | ms/batch 394.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 538.33s | valid loss/mse 0.0629 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/1350 batches | lr 0.0001 | ms/batch 398.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/1350 batches | lr 0.0001 | ms/batch 394.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/1350 batches | lr 0.0001 | ms/batch 394.15 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/1350 batches | lr 0.0001 | ms/batch 395.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/1350 batches | lr 0.0001 | ms/batch 395.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/1350 batches | lr 0.0001 | ms/batch 395.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/1350 batches | lr 0.0001 | ms/batch 395.29 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 800/1350 batches | lr 0.0001 | ms/batch 394.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 900/1350 batches | lr 0.0001 | ms/batch 394.85 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1000/1350 batches | lr 0.0001 | ms/batch 394.73 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1100/1350 batches | lr 0.0001 | ms/batch 394.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1200/1350 batches | lr 0.0001 | ms/batch 394.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 1300/1350 batches | lr 0.0001 | ms/batch 395.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 539.73s | valid loss/mse 0.0598 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/1350 batches | lr 0.0001 | ms/batch 399.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/1350 batches | lr 0.0001 | ms/batch 396.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/1350 batches | lr 0.0001 | ms/batch 396.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/1350 batches | lr 0.0001 | ms/batch 395.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/1350 batches | lr 0.0001 | ms/batch 395.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/1350 batches | lr 0.0001 | ms/batch 395.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/1350 batches | lr 0.0001 | ms/batch 396.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 800/1350 batches | lr 0.0001 | ms/batch 396.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 900/1350 batches | lr 0.0001 | ms/batch 396.56 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1000/1350 batches | lr 0.0001 | ms/batch 397.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1100/1350 batches | lr 0.0001 | ms/batch 397.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1200/1350 batches | lr 0.0001 | ms/batch 397.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 1300/1350 batches | lr 0.0001 | ms/batch 397.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 541.94s | valid loss/mse 0.0631 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/1350 batches | lr 0.0001 | ms/batch 401.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/1350 batches | lr 0.0001 | ms/batch 397.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/1350 batches | lr 0.0001 | ms/batch 396.85 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/1350 batches | lr 0.0001 | ms/batch 397.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/1350 batches | lr 0.0001 | ms/batch 397.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/1350 batches | lr 0.0001 | ms/batch 398.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/1350 batches | lr 0.0001 | ms/batch 397.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 800/1350 batches | lr 0.0001 | ms/batch 398.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 900/1350 batches | lr 0.0001 | ms/batch 398.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1000/1350 batches | lr 0.0001 | ms/batch 398.55 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1100/1350 batches | lr 0.0001 | ms/batch 398.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1200/1350 batches | lr 0.0001 | ms/batch 398.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 1300/1350 batches | lr 0.0001 | ms/batch 398.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 543.76s | valid loss/mse 0.0622 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 6
---Creating test_res
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/XuCao2023/scgpt/split1
scGPT - INFO - Running on 2024-07-27 06:30:09
scGPT - INFO - match 5164/5172 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1869 batches | lr 0.0001 | ms/batch 407.05 | loss  0.04 | mse  0.04 |
scGPT - INFO - | epoch   1 | 200/1869 batches | lr 0.0001 | ms/batch 394.79 | loss  0.03 | mse  0.03 |
scGPT - INFO - | epoch   1 | 300/1869 batches | lr 0.0001 | ms/batch 391.07 | loss  0.03 | mse  0.03 |
scGPT - INFO - | epoch   1 | 400/1869 batches | lr 0.0001 | ms/batch 391.00 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 500/1869 batches | lr 0.0001 | ms/batch 390.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 600/1869 batches | lr 0.0001 | ms/batch 391.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 700/1869 batches | lr 0.0001 | ms/batch 391.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 800/1869 batches | lr 0.0001 | ms/batch 391.01 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 900/1869 batches | lr 0.0001 | ms/batch 391.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1000/1869 batches | lr 0.0001 | ms/batch 391.24 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1100/1869 batches | lr 0.0001 | ms/batch 391.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1200/1869 batches | lr 0.0001 | ms/batch 391.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1300/1869 batches | lr 0.0001 | ms/batch 391.42 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1400/1869 batches | lr 0.0001 | ms/batch 391.23 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1500/1869 batches | lr 0.0001 | ms/batch 391.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1600/1869 batches | lr 0.0001 | ms/batch 391.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1700/1869 batches | lr 0.0001 | ms/batch 391.88 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1800/1869 batches | lr 0.0001 | ms/batch 392.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 773.10s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0167
scGPT - INFO - | epoch   2 | 100/1869 batches | lr 0.0001 | ms/batch 396.36 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 200/1869 batches | lr 0.0001 | ms/batch 392.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 300/1869 batches | lr 0.0001 | ms/batch 392.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 400/1869 batches | lr 0.0001 | ms/batch 392.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 500/1869 batches | lr 0.0001 | ms/batch 392.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 600/1869 batches | lr 0.0001 | ms/batch 392.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 700/1869 batches | lr 0.0001 | ms/batch 392.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 800/1869 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 900/1869 batches | lr 0.0001 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1000/1869 batches | lr 0.0001 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1100/1869 batches | lr 0.0001 | ms/batch 393.54 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1200/1869 batches | lr 0.0001 | ms/batch 393.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1300/1869 batches | lr 0.0001 | ms/batch 394.02 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1400/1869 batches | lr 0.0001 | ms/batch 394.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1500/1869 batches | lr 0.0001 | ms/batch 394.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1600/1869 batches | lr 0.0001 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1700/1869 batches | lr 0.0001 | ms/batch 392.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1800/1869 batches | lr 0.0001 | ms/batch 391.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 774.39s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/1869 batches | lr 0.0001 | ms/batch 397.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 200/1869 batches | lr 0.0001 | ms/batch 391.92 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 300/1869 batches | lr 0.0001 | ms/batch 392.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 400/1869 batches | lr 0.0001 | ms/batch 392.87 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 500/1869 batches | lr 0.0001 | ms/batch 392.52 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 600/1869 batches | lr 0.0001 | ms/batch 392.30 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 700/1869 batches | lr 0.0001 | ms/batch 392.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 800/1869 batches | lr 0.0001 | ms/batch 392.29 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 900/1869 batches | lr 0.0001 | ms/batch 392.41 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1000/1869 batches | lr 0.0001 | ms/batch 392.61 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1100/1869 batches | lr 0.0001 | ms/batch 392.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1200/1869 batches | lr 0.0001 | ms/batch 392.54 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1300/1869 batches | lr 0.0001 | ms/batch 393.05 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1400/1869 batches | lr 0.0001 | ms/batch 393.28 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1500/1869 batches | lr 0.0001 | ms/batch 392.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1600/1869 batches | lr 0.0001 | ms/batch 392.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1700/1869 batches | lr 0.0001 | ms/batch 392.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1800/1869 batches | lr 0.0001 | ms/batch 392.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 773.94s | valid loss/mse 0.0187 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/1869 batches | lr 0.0001 | ms/batch 396.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 200/1869 batches | lr 0.0001 | ms/batch 392.62 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 300/1869 batches | lr 0.0001 | ms/batch 391.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 400/1869 batches | lr 0.0001 | ms/batch 392.02 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 500/1869 batches | lr 0.0001 | ms/batch 392.15 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 600/1869 batches | lr 0.0001 | ms/batch 391.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 700/1869 batches | lr 0.0001 | ms/batch 391.62 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 800/1869 batches | lr 0.0001 | ms/batch 391.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 900/1869 batches | lr 0.0001 | ms/batch 391.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1000/1869 batches | lr 0.0001 | ms/batch 392.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1100/1869 batches | lr 0.0001 | ms/batch 392.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1200/1869 batches | lr 0.0001 | ms/batch 391.97 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1300/1869 batches | lr 0.0001 | ms/batch 391.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1400/1869 batches | lr 0.0001 | ms/batch 391.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1500/1869 batches | lr 0.0001 | ms/batch 391.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1600/1869 batches | lr 0.0001 | ms/batch 392.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1700/1869 batches | lr 0.0001 | ms/batch 392.13 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1800/1869 batches | lr 0.0001 | ms/batch 392.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 772.72s | valid loss/mse 0.0166 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0166
scGPT - INFO - | epoch   5 | 100/1869 batches | lr 0.0001 | ms/batch 395.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 200/1869 batches | lr 0.0001 | ms/batch 392.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 300/1869 batches | lr 0.0001 | ms/batch 392.65 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 400/1869 batches | lr 0.0001 | ms/batch 392.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 500/1869 batches | lr 0.0001 | ms/batch 392.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 600/1869 batches | lr 0.0001 | ms/batch 392.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 700/1869 batches | lr 0.0001 | ms/batch 392.25 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 800/1869 batches | lr 0.0001 | ms/batch 392.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 900/1869 batches | lr 0.0001 | ms/batch 392.55 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1000/1869 batches | lr 0.0001 | ms/batch 392.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1100/1869 batches | lr 0.0001 | ms/batch 392.43 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1200/1869 batches | lr 0.0001 | ms/batch 392.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1300/1869 batches | lr 0.0001 | ms/batch 392.10 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1400/1869 batches | lr 0.0001 | ms/batch 392.25 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1500/1869 batches | lr 0.0001 | ms/batch 392.45 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1600/1869 batches | lr 0.0001 | ms/batch 392.23 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1700/1869 batches | lr 0.0001 | ms/batch 392.22 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1800/1869 batches | lr 0.0001 | ms/batch 392.50 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 773.31s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/1869 batches | lr 0.0001 | ms/batch 396.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 200/1869 batches | lr 0.0001 | ms/batch 392.25 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 300/1869 batches | lr 0.0001 | ms/batch 392.31 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 400/1869 batches | lr 0.0001 | ms/batch 393.42 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 500/1869 batches | lr 0.0001 | ms/batch 392.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 600/1869 batches | lr 0.0001 | ms/batch 392.60 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 700/1869 batches | lr 0.0001 | ms/batch 392.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 800/1869 batches | lr 0.0001 | ms/batch 392.98 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 900/1869 batches | lr 0.0001 | ms/batch 392.75 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1000/1869 batches | lr 0.0001 | ms/batch 392.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1100/1869 batches | lr 0.0001 | ms/batch 392.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1200/1869 batches | lr 0.0001 | ms/batch 392.92 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1300/1869 batches | lr 0.0001 | ms/batch 393.29 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1400/1869 batches | lr 0.0001 | ms/batch 392.93 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1500/1869 batches | lr 0.0001 | ms/batch 393.08 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1600/1869 batches | lr 0.0001 | ms/batch 393.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1700/1869 batches | lr 0.0001 | ms/batch 393.53 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1800/1869 batches | lr 0.0001 | ms/batch 393.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 774.78s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/1869 batches | lr 0.0001 | ms/batch 397.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 200/1869 batches | lr 0.0001 | ms/batch 393.50 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 300/1869 batches | lr 0.0001 | ms/batch 393.35 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 400/1869 batches | lr 0.0001 | ms/batch 393.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 500/1869 batches | lr 0.0001 | ms/batch 393.50 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 600/1869 batches | lr 0.0001 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 700/1869 batches | lr 0.0001 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 800/1869 batches | lr 0.0001 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 900/1869 batches | lr 0.0001 | ms/batch 393.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1000/1869 batches | lr 0.0001 | ms/batch 393.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1100/1869 batches | lr 0.0001 | ms/batch 393.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1200/1869 batches | lr 0.0001 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1300/1869 batches | lr 0.0001 | ms/batch 395.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1400/1869 batches | lr 0.0001 | ms/batch 395.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1500/1869 batches | lr 0.0001 | ms/batch 394.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1600/1869 batches | lr 0.0001 | ms/batch 393.53 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1700/1869 batches | lr 0.0001 | ms/batch 393.25 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1800/1869 batches | lr 0.0001 | ms/batch 393.11 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 776.14s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/1869 batches | lr 0.0000 | ms/batch 397.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 200/1869 batches | lr 0.0000 | ms/batch 393.44 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 300/1869 batches | lr 0.0000 | ms/batch 393.79 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 400/1869 batches | lr 0.0000 | ms/batch 394.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 500/1869 batches | lr 0.0000 | ms/batch 393.42 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 600/1869 batches | lr 0.0000 | ms/batch 393.61 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 700/1869 batches | lr 0.0000 | ms/batch 394.13 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 800/1869 batches | lr 0.0000 | ms/batch 393.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 900/1869 batches | lr 0.0000 | ms/batch 393.41 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1000/1869 batches | lr 0.0000 | ms/batch 393.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1100/1869 batches | lr 0.0000 | ms/batch 393.36 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1200/1869 batches | lr 0.0000 | ms/batch 393.44 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1300/1869 batches | lr 0.0000 | ms/batch 393.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1400/1869 batches | lr 0.0000 | ms/batch 393.93 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1500/1869 batches | lr 0.0000 | ms/batch 394.14 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1600/1869 batches | lr 0.0000 | ms/batch 393.70 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1700/1869 batches | lr 0.0000 | ms/batch 393.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1800/1869 batches | lr 0.0000 | ms/batch 393.73 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 776.17s | valid loss/mse 0.0166 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0166
scGPT - INFO - | epoch   9 | 100/1869 batches | lr 0.0000 | ms/batch 397.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 200/1869 batches | lr 0.0000 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 300/1869 batches | lr 0.0000 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 400/1869 batches | lr 0.0000 | ms/batch 393.62 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 500/1869 batches | lr 0.0000 | ms/batch 393.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 600/1869 batches | lr 0.0000 | ms/batch 393.95 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 700/1869 batches | lr 0.0000 | ms/batch 393.60 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 800/1869 batches | lr 0.0000 | ms/batch 393.31 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 900/1869 batches | lr 0.0000 | ms/batch 393.29 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1000/1869 batches | lr 0.0000 | ms/batch 393.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1100/1869 batches | lr 0.0000 | ms/batch 393.30 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1200/1869 batches | lr 0.0000 | ms/batch 393.31 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1300/1869 batches | lr 0.0000 | ms/batch 393.35 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1400/1869 batches | lr 0.0000 | ms/batch 393.24 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1500/1869 batches | lr 0.0000 | ms/batch 393.16 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1600/1869 batches | lr 0.0000 | ms/batch 393.54 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1700/1869 batches | lr 0.0000 | ms/batch 393.35 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1800/1869 batches | lr 0.0000 | ms/batch 392.97 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 775.56s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/1869 batches | lr 0.0000 | ms/batch 397.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 200/1869 batches | lr 0.0000 | ms/batch 393.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 300/1869 batches | lr 0.0000 | ms/batch 393.30 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 400/1869 batches | lr 0.0000 | ms/batch 393.33 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 500/1869 batches | lr 0.0000 | ms/batch 393.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 600/1869 batches | lr 0.0000 | ms/batch 393.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 700/1869 batches | lr 0.0000 | ms/batch 393.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 800/1869 batches | lr 0.0000 | ms/batch 393.52 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 900/1869 batches | lr 0.0000 | ms/batch 393.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1000/1869 batches | lr 0.0000 | ms/batch 393.22 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1100/1869 batches | lr 0.0000 | ms/batch 393.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1200/1869 batches | lr 0.0000 | ms/batch 393.64 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1300/1869 batches | lr 0.0000 | ms/batch 393.41 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1400/1869 batches | lr 0.0000 | ms/batch 393.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1500/1869 batches | lr 0.0000 | ms/batch 393.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1600/1869 batches | lr 0.0000 | ms/batch 394.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1700/1869 batches | lr 0.0000 | ms/batch 393.76 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1800/1869 batches | lr 0.0000 | ms/batch 393.61 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 775.89s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/1869 batches | lr 0.0000 | ms/batch 397.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 200/1869 batches | lr 0.0000 | ms/batch 393.89 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 300/1869 batches | lr 0.0000 | ms/batch 393.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 400/1869 batches | lr 0.0000 | ms/batch 393.70 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 500/1869 batches | lr 0.0000 | ms/batch 393.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 600/1869 batches | lr 0.0000 | ms/batch 393.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 700/1869 batches | lr 0.0000 | ms/batch 394.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 800/1869 batches | lr 0.0000 | ms/batch 394.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 900/1869 batches | lr 0.0000 | ms/batch 393.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1000/1869 batches | lr 0.0000 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1100/1869 batches | lr 0.0000 | ms/batch 393.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1200/1869 batches | lr 0.0000 | ms/batch 393.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1300/1869 batches | lr 0.0000 | ms/batch 393.43 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1400/1869 batches | lr 0.0000 | ms/batch 393.45 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1500/1869 batches | lr 0.0000 | ms/batch 393.28 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1600/1869 batches | lr 0.0000 | ms/batch 393.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1700/1869 batches | lr 0.0000 | ms/batch 393.30 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1800/1869 batches | lr 0.0000 | ms/batch 393.44 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 775.95s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/1869 batches | lr 0.0000 | ms/batch 399.27 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 200/1869 batches | lr 0.0000 | ms/batch 393.29 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 300/1869 batches | lr 0.0000 | ms/batch 392.64 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 400/1869 batches | lr 0.0000 | ms/batch 392.60 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 500/1869 batches | lr 0.0000 | ms/batch 392.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 600/1869 batches | lr 0.0000 | ms/batch 392.54 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 700/1869 batches | lr 0.0000 | ms/batch 393.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 800/1869 batches | lr 0.0000 | ms/batch 392.89 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 900/1869 batches | lr 0.0000 | ms/batch 392.93 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1000/1869 batches | lr 0.0000 | ms/batch 392.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1100/1869 batches | lr 0.0000 | ms/batch 392.84 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1200/1869 batches | lr 0.0000 | ms/batch 393.02 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1300/1869 batches | lr 0.0000 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1400/1869 batches | lr 0.0000 | ms/batch 392.96 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1500/1869 batches | lr 0.0000 | ms/batch 392.90 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1600/1869 batches | lr 0.0000 | ms/batch 392.60 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1700/1869 batches | lr 0.0000 | ms/batch 392.80 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1800/1869 batches | lr 0.0000 | ms/batch 392.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 774.69s | valid loss/mse 0.0166 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/1869 batches | lr 0.0000 | ms/batch 396.99 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 200/1869 batches | lr 0.0000 | ms/batch 392.65 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 300/1869 batches | lr 0.0000 | ms/batch 392.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 400/1869 batches | lr 0.0000 | ms/batch 393.10 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 500/1869 batches | lr 0.0000 | ms/batch 393.28 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 600/1869 batches | lr 0.0000 | ms/batch 393.06 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 700/1869 batches | lr 0.0000 | ms/batch 393.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 800/1869 batches | lr 0.0000 | ms/batch 392.98 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 900/1869 batches | lr 0.0000 | ms/batch 392.93 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1000/1869 batches | lr 0.0000 | ms/batch 392.80 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1100/1869 batches | lr 0.0000 | ms/batch 392.65 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1200/1869 batches | lr 0.0000 | ms/batch 392.62 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1300/1869 batches | lr 0.0000 | ms/batch 392.93 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1400/1869 batches | lr 0.0000 | ms/batch 392.56 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1500/1869 batches | lr 0.0000 | ms/batch 392.63 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1600/1869 batches | lr 0.0000 | ms/batch 392.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1700/1869 batches | lr 0.0000 | ms/batch 392.67 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1800/1869 batches | lr 0.0000 | ms/batch 393.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 774.47s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 13
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/XuCao2023/scgpt/split2
scGPT - INFO - Running on 2024-07-27 09:54:22
scGPT - INFO - match 5164/5172 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/2009 batches | lr 0.0001 | ms/batch 396.76 | loss  0.04 | mse  0.04 |
scGPT - INFO - | epoch   1 | 200/2009 batches | lr 0.0001 | ms/batch 391.88 | loss  0.03 | mse  0.03 |
scGPT - INFO - | epoch   1 | 300/2009 batches | lr 0.0001 | ms/batch 391.80 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 400/2009 batches | lr 0.0001 | ms/batch 391.73 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 500/2009 batches | lr 0.0001 | ms/batch 391.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 600/2009 batches | lr 0.0001 | ms/batch 391.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 700/2009 batches | lr 0.0001 | ms/batch 392.05 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 800/2009 batches | lr 0.0001 | ms/batch 392.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 900/2009 batches | lr 0.0001 | ms/batch 392.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1000/2009 batches | lr 0.0001 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1100/2009 batches | lr 0.0001 | ms/batch 392.98 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1200/2009 batches | lr 0.0001 | ms/batch 393.11 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1300/2009 batches | lr 0.0001 | ms/batch 393.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1400/2009 batches | lr 0.0001 | ms/batch 393.45 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1500/2009 batches | lr 0.0001 | ms/batch 393.96 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1600/2009 batches | lr 0.0001 | ms/batch 394.13 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1700/2009 batches | lr 0.0001 | ms/batch 394.25 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1800/2009 batches | lr 0.0001 | ms/batch 393.70 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 1900/2009 batches | lr 0.0001 | ms/batch 393.16 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 2000/2009 batches | lr 0.0001 | ms/batch 393.37 | loss  0.03 | mse  0.03 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 818.28s | valid loss/mse 0.0200 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0200
scGPT - INFO - | epoch   2 | 100/2009 batches | lr 0.0001 | ms/batch 396.64 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 200/2009 batches | lr 0.0001 | ms/batch 392.36 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 300/2009 batches | lr 0.0001 | ms/batch 392.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 400/2009 batches | lr 0.0001 | ms/batch 393.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 500/2009 batches | lr 0.0001 | ms/batch 392.98 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 600/2009 batches | lr 0.0001 | ms/batch 393.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 700/2009 batches | lr 0.0001 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 800/2009 batches | lr 0.0001 | ms/batch 393.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 900/2009 batches | lr 0.0001 | ms/batch 393.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1000/2009 batches | lr 0.0001 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1100/2009 batches | lr 0.0001 | ms/batch 393.63 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1200/2009 batches | lr 0.0001 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1300/2009 batches | lr 0.0001 | ms/batch 393.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1400/2009 batches | lr 0.0001 | ms/batch 393.60 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1500/2009 batches | lr 0.0001 | ms/batch 393.27 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1600/2009 batches | lr 0.0001 | ms/batch 393.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1700/2009 batches | lr 0.0001 | ms/batch 393.11 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1800/2009 batches | lr 0.0001 | ms/batch 393.22 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 1900/2009 batches | lr 0.0001 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   2 | 2000/2009 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 818.89s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0169
scGPT - INFO - | epoch   3 | 100/2009 batches | lr 0.0001 | ms/batch 400.42 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 200/2009 batches | lr 0.0001 | ms/batch 393.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 300/2009 batches | lr 0.0001 | ms/batch 394.05 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 400/2009 batches | lr 0.0001 | ms/batch 393.70 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 500/2009 batches | lr 0.0001 | ms/batch 393.61 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 600/2009 batches | lr 0.0001 | ms/batch 393.44 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 700/2009 batches | lr 0.0001 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 800/2009 batches | lr 0.0001 | ms/batch 393.43 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 900/2009 batches | lr 0.0001 | ms/batch 393.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1000/2009 batches | lr 0.0001 | ms/batch 393.43 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1100/2009 batches | lr 0.0001 | ms/batch 393.61 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1200/2009 batches | lr 0.0001 | ms/batch 393.80 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1300/2009 batches | lr 0.0001 | ms/batch 393.77 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1400/2009 batches | lr 0.0001 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1500/2009 batches | lr 0.0001 | ms/batch 394.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1600/2009 batches | lr 0.0001 | ms/batch 394.28 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1700/2009 batches | lr 0.0001 | ms/batch 394.54 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1800/2009 batches | lr 0.0001 | ms/batch 394.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 1900/2009 batches | lr 0.0001 | ms/batch 392.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   3 | 2000/2009 batches | lr 0.0001 | ms/batch 392.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 819.92s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0169
scGPT - INFO - | epoch   4 | 100/2009 batches | lr 0.0001 | ms/batch 397.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 200/2009 batches | lr 0.0001 | ms/batch 393.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 300/2009 batches | lr 0.0001 | ms/batch 393.10 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 400/2009 batches | lr 0.0001 | ms/batch 393.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 500/2009 batches | lr 0.0001 | ms/batch 393.23 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 600/2009 batches | lr 0.0001 | ms/batch 393.02 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 700/2009 batches | lr 0.0001 | ms/batch 393.10 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 800/2009 batches | lr 0.0001 | ms/batch 393.38 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 900/2009 batches | lr 0.0001 | ms/batch 393.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1000/2009 batches | lr 0.0001 | ms/batch 394.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1100/2009 batches | lr 0.0001 | ms/batch 393.55 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1200/2009 batches | lr 0.0001 | ms/batch 393.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1300/2009 batches | lr 0.0001 | ms/batch 393.42 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1400/2009 batches | lr 0.0001 | ms/batch 393.76 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1500/2009 batches | lr 0.0001 | ms/batch 394.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1600/2009 batches | lr 0.0001 | ms/batch 394.33 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1700/2009 batches | lr 0.0001 | ms/batch 393.30 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1800/2009 batches | lr 0.0001 | ms/batch 392.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 1900/2009 batches | lr 0.0001 | ms/batch 393.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   4 | 2000/2009 batches | lr 0.0001 | ms/batch 393.22 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 819.28s | valid loss/mse 0.0174 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/2009 batches | lr 0.0001 | ms/batch 397.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 200/2009 batches | lr 0.0001 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 300/2009 batches | lr 0.0001 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 400/2009 batches | lr 0.0001 | ms/batch 393.56 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 500/2009 batches | lr 0.0001 | ms/batch 393.16 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 600/2009 batches | lr 0.0001 | ms/batch 392.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 700/2009 batches | lr 0.0001 | ms/batch 393.08 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 800/2009 batches | lr 0.0001 | ms/batch 392.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 900/2009 batches | lr 0.0001 | ms/batch 392.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1000/2009 batches | lr 0.0001 | ms/batch 392.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1100/2009 batches | lr 0.0001 | ms/batch 392.89 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1200/2009 batches | lr 0.0001 | ms/batch 393.02 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1300/2009 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1400/2009 batches | lr 0.0001 | ms/batch 392.95 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1500/2009 batches | lr 0.0001 | ms/batch 392.88 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1600/2009 batches | lr 0.0001 | ms/batch 392.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1700/2009 batches | lr 0.0001 | ms/batch 393.00 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1800/2009 batches | lr 0.0001 | ms/batch 392.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 1900/2009 batches | lr 0.0001 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   5 | 2000/2009 batches | lr 0.0001 | ms/batch 393.22 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 818.49s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0169
scGPT - INFO - | epoch   6 | 100/2009 batches | lr 0.0001 | ms/batch 397.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 200/2009 batches | lr 0.0001 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 300/2009 batches | lr 0.0001 | ms/batch 393.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 400/2009 batches | lr 0.0001 | ms/batch 393.27 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 500/2009 batches | lr 0.0001 | ms/batch 393.11 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 600/2009 batches | lr 0.0001 | ms/batch 393.04 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 700/2009 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 800/2009 batches | lr 0.0001 | ms/batch 392.96 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 900/2009 batches | lr 0.0001 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1000/2009 batches | lr 0.0001 | ms/batch 392.97 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1100/2009 batches | lr 0.0001 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1200/2009 batches | lr 0.0001 | ms/batch 392.68 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1300/2009 batches | lr 0.0001 | ms/batch 392.93 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1400/2009 batches | lr 0.0001 | ms/batch 392.67 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1500/2009 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1600/2009 batches | lr 0.0001 | ms/batch 392.85 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1700/2009 batches | lr 0.0001 | ms/batch 392.84 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1800/2009 batches | lr 0.0001 | ms/batch 392.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 1900/2009 batches | lr 0.0001 | ms/batch 392.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   6 | 2000/2009 batches | lr 0.0001 | ms/batch 392.62 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 818.30s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/2009 batches | lr 0.0001 | ms/batch 397.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 200/2009 batches | lr 0.0001 | ms/batch 393.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 300/2009 batches | lr 0.0001 | ms/batch 393.11 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 400/2009 batches | lr 0.0001 | ms/batch 392.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 500/2009 batches | lr 0.0001 | ms/batch 392.62 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 600/2009 batches | lr 0.0001 | ms/batch 392.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 700/2009 batches | lr 0.0001 | ms/batch 393.27 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 800/2009 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 900/2009 batches | lr 0.0001 | ms/batch 392.95 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1000/2009 batches | lr 0.0001 | ms/batch 393.10 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1100/2009 batches | lr 0.0001 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1200/2009 batches | lr 0.0001 | ms/batch 392.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1300/2009 batches | lr 0.0001 | ms/batch 392.68 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1400/2009 batches | lr 0.0001 | ms/batch 392.80 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1500/2009 batches | lr 0.0001 | ms/batch 392.86 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1600/2009 batches | lr 0.0001 | ms/batch 392.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1700/2009 batches | lr 0.0001 | ms/batch 392.60 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1800/2009 batches | lr 0.0001 | ms/batch 392.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 1900/2009 batches | lr 0.0001 | ms/batch 392.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   7 | 2000/2009 batches | lr 0.0001 | ms/batch 392.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 818.11s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0168
scGPT - INFO - | epoch   8 | 100/2009 batches | lr 0.0000 | ms/batch 396.67 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 200/2009 batches | lr 0.0000 | ms/batch 392.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 300/2009 batches | lr 0.0000 | ms/batch 392.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 400/2009 batches | lr 0.0000 | ms/batch 392.68 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 500/2009 batches | lr 0.0000 | ms/batch 392.44 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 600/2009 batches | lr 0.0000 | ms/batch 392.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 700/2009 batches | lr 0.0000 | ms/batch 392.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 800/2009 batches | lr 0.0000 | ms/batch 392.76 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 900/2009 batches | lr 0.0000 | ms/batch 392.73 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1000/2009 batches | lr 0.0000 | ms/batch 392.36 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1100/2009 batches | lr 0.0000 | ms/batch 392.33 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1200/2009 batches | lr 0.0000 | ms/batch 392.41 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1300/2009 batches | lr 0.0000 | ms/batch 392.41 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1400/2009 batches | lr 0.0000 | ms/batch 392.88 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1500/2009 batches | lr 0.0000 | ms/batch 392.85 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1600/2009 batches | lr 0.0000 | ms/batch 393.22 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1700/2009 batches | lr 0.0000 | ms/batch 393.33 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1800/2009 batches | lr 0.0000 | ms/batch 393.24 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 1900/2009 batches | lr 0.0000 | ms/batch 393.00 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   8 | 2000/2009 batches | lr 0.0000 | ms/batch 392.98 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 817.99s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/2009 batches | lr 0.0000 | ms/batch 397.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 200/2009 batches | lr 0.0000 | ms/batch 393.23 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 300/2009 batches | lr 0.0000 | ms/batch 393.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 400/2009 batches | lr 0.0000 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 500/2009 batches | lr 0.0000 | ms/batch 393.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 600/2009 batches | lr 0.0000 | ms/batch 393.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 700/2009 batches | lr 0.0000 | ms/batch 392.89 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 800/2009 batches | lr 0.0000 | ms/batch 393.01 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 900/2009 batches | lr 0.0000 | ms/batch 393.03 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1000/2009 batches | lr 0.0000 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1100/2009 batches | lr 0.0000 | ms/batch 392.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1200/2009 batches | lr 0.0000 | ms/batch 392.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1300/2009 batches | lr 0.0000 | ms/batch 392.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1400/2009 batches | lr 0.0000 | ms/batch 392.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1500/2009 batches | lr 0.0000 | ms/batch 392.88 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1600/2009 batches | lr 0.0000 | ms/batch 393.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1700/2009 batches | lr 0.0000 | ms/batch 393.12 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1800/2009 batches | lr 0.0000 | ms/batch 392.94 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 1900/2009 batches | lr 0.0000 | ms/batch 393.24 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   9 | 2000/2009 batches | lr 0.0000 | ms/batch 393.50 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 818.66s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/2009 batches | lr 0.0000 | ms/batch 397.92 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 200/2009 batches | lr 0.0000 | ms/batch 392.75 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 300/2009 batches | lr 0.0000 | ms/batch 392.96 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 400/2009 batches | lr 0.0000 | ms/batch 393.26 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 500/2009 batches | lr 0.0000 | ms/batch 393.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 600/2009 batches | lr 0.0000 | ms/batch 393.27 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 700/2009 batches | lr 0.0000 | ms/batch 393.20 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 800/2009 batches | lr 0.0000 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 900/2009 batches | lr 0.0000 | ms/batch 393.47 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1000/2009 batches | lr 0.0000 | ms/batch 393.52 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1100/2009 batches | lr 0.0000 | ms/batch 393.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1200/2009 batches | lr 0.0000 | ms/batch 393.64 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1300/2009 batches | lr 0.0000 | ms/batch 393.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1400/2009 batches | lr 0.0000 | ms/batch 393.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1500/2009 batches | lr 0.0000 | ms/batch 393.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1600/2009 batches | lr 0.0000 | ms/batch 393.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1700/2009 batches | lr 0.0000 | ms/batch 393.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1800/2009 batches | lr 0.0000 | ms/batch 393.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 1900/2009 batches | lr 0.0000 | ms/batch 393.65 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  10 | 2000/2009 batches | lr 0.0000 | ms/batch 393.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 819.39s | valid loss/mse 0.0168 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/2009 batches | lr 0.0000 | ms/batch 397.42 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 200/2009 batches | lr 0.0000 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 300/2009 batches | lr 0.0000 | ms/batch 393.36 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 400/2009 batches | lr 0.0000 | ms/batch 393.15 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 500/2009 batches | lr 0.0000 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 600/2009 batches | lr 0.0000 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 700/2009 batches | lr 0.0000 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 800/2009 batches | lr 0.0000 | ms/batch 393.29 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 900/2009 batches | lr 0.0000 | ms/batch 393.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1000/2009 batches | lr 0.0000 | ms/batch 393.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1100/2009 batches | lr 0.0000 | ms/batch 393.56 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1200/2009 batches | lr 0.0000 | ms/batch 393.92 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1300/2009 batches | lr 0.0000 | ms/batch 393.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1400/2009 batches | lr 0.0000 | ms/batch 393.63 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1500/2009 batches | lr 0.0000 | ms/batch 393.43 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1600/2009 batches | lr 0.0000 | ms/batch 393.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1700/2009 batches | lr 0.0000 | ms/batch 393.63 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1800/2009 batches | lr 0.0000 | ms/batch 393.63 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 1900/2009 batches | lr 0.0000 | ms/batch 393.39 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  11 | 2000/2009 batches | lr 0.0000 | ms/batch 393.30 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 819.48s | valid loss/mse 0.0172 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/2009 batches | lr 0.0000 | ms/batch 397.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 200/2009 batches | lr 0.0000 | ms/batch 393.77 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 300/2009 batches | lr 0.0000 | ms/batch 393.73 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 400/2009 batches | lr 0.0000 | ms/batch 394.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 500/2009 batches | lr 0.0000 | ms/batch 394.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 600/2009 batches | lr 0.0000 | ms/batch 394.32 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 700/2009 batches | lr 0.0000 | ms/batch 394.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 800/2009 batches | lr 0.0000 | ms/batch 393.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 900/2009 batches | lr 0.0000 | ms/batch 393.80 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1000/2009 batches | lr 0.0000 | ms/batch 393.76 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1100/2009 batches | lr 0.0000 | ms/batch 393.52 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1200/2009 batches | lr 0.0000 | ms/batch 393.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1300/2009 batches | lr 0.0000 | ms/batch 393.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1400/2009 batches | lr 0.0000 | ms/batch 393.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1500/2009 batches | lr 0.0000 | ms/batch 393.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1600/2009 batches | lr 0.0000 | ms/batch 393.79 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1700/2009 batches | lr 0.0000 | ms/batch 393.70 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1800/2009 batches | lr 0.0000 | ms/batch 393.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 1900/2009 batches | lr 0.0000 | ms/batch 393.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  12 | 2000/2009 batches | lr 0.0000 | ms/batch 393.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 820.18s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0167
scGPT - INFO - | epoch  13 | 100/2009 batches | lr 0.0000 | ms/batch 397.77 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 200/2009 batches | lr 0.0000 | ms/batch 393.82 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 300/2009 batches | lr 0.0000 | ms/batch 393.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 400/2009 batches | lr 0.0000 | ms/batch 393.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 500/2009 batches | lr 0.0000 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 600/2009 batches | lr 0.0000 | ms/batch 393.37 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 700/2009 batches | lr 0.0000 | ms/batch 393.34 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 800/2009 batches | lr 0.0000 | ms/batch 393.50 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 900/2009 batches | lr 0.0000 | ms/batch 393.56 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1000/2009 batches | lr 0.0000 | ms/batch 393.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1100/2009 batches | lr 0.0000 | ms/batch 393.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1200/2009 batches | lr 0.0000 | ms/batch 393.76 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1300/2009 batches | lr 0.0000 | ms/batch 393.75 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1400/2009 batches | lr 0.0000 | ms/batch 393.40 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1500/2009 batches | lr 0.0000 | ms/batch 393.45 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1600/2009 batches | lr 0.0000 | ms/batch 393.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1700/2009 batches | lr 0.0000 | ms/batch 393.69 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1800/2009 batches | lr 0.0000 | ms/batch 393.92 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 1900/2009 batches | lr 0.0000 | ms/batch 393.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  13 | 2000/2009 batches | lr 0.0000 | ms/batch 393.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 820.03s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/2009 batches | lr 0.0000 | ms/batch 397.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 200/2009 batches | lr 0.0000 | ms/batch 393.68 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 300/2009 batches | lr 0.0000 | ms/batch 394.16 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 400/2009 batches | lr 0.0000 | ms/batch 393.82 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 500/2009 batches | lr 0.0000 | ms/batch 393.45 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 600/2009 batches | lr 0.0000 | ms/batch 393.33 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 700/2009 batches | lr 0.0000 | ms/batch 393.51 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 800/2009 batches | lr 0.0000 | ms/batch 393.58 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 900/2009 batches | lr 0.0000 | ms/batch 393.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1000/2009 batches | lr 0.0000 | ms/batch 393.78 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1100/2009 batches | lr 0.0000 | ms/batch 393.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1200/2009 batches | lr 0.0000 | ms/batch 393.75 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1300/2009 batches | lr 0.0000 | ms/batch 393.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1400/2009 batches | lr 0.0000 | ms/batch 393.46 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1500/2009 batches | lr 0.0000 | ms/batch 393.57 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1600/2009 batches | lr 0.0000 | ms/batch 393.59 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1700/2009 batches | lr 0.0000 | ms/batch 394.07 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1800/2009 batches | lr 0.0000 | ms/batch 393.72 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 1900/2009 batches | lr 0.0000 | ms/batch 393.73 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  14 | 2000/2009 batches | lr 0.0000 | ms/batch 393.99 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 820.11s | valid loss/mse 0.0169 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/2009 batches | lr 0.0000 | ms/batch 398.48 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 200/2009 batches | lr 0.0000 | ms/batch 393.81 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 300/2009 batches | lr 0.0000 | ms/batch 393.76 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 400/2009 batches | lr 0.0000 | ms/batch 393.71 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 500/2009 batches | lr 0.0000 | ms/batch 393.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 600/2009 batches | lr 0.0000 | ms/batch 393.74 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 700/2009 batches | lr 0.0000 | ms/batch 393.83 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 800/2009 batches | lr 0.0000 | ms/batch 393.84 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 900/2009 batches | lr 0.0000 | ms/batch 393.97 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1000/2009 batches | lr 0.0000 | ms/batch 393.89 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1100/2009 batches | lr 0.0000 | ms/batch 394.09 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1200/2009 batches | lr 0.0000 | ms/batch 394.02 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1300/2009 batches | lr 0.0000 | ms/batch 394.21 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1400/2009 batches | lr 0.0000 | ms/batch 394.23 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1500/2009 batches | lr 0.0000 | ms/batch 394.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1600/2009 batches | lr 0.0000 | ms/batch 394.16 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1700/2009 batches | lr 0.0000 | ms/batch 394.18 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1800/2009 batches | lr 0.0000 | ms/batch 393.99 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 1900/2009 batches | lr 0.0000 | ms/batch 393.95 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch  15 | 2000/2009 batches | lr 0.0000 | ms/batch 393.91 | loss  0.02 | mse  0.02 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 820.56s | valid loss/mse 0.0167 |
scGPT - INFO - -----------------------------------------------------------------------------------------
---Creating test_res
