环境设置完成！
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_combined/scgpt/split1
scGPT - INFO - Running on 2024-07-26 05:13:55
scGPT - INFO - match 3748/5015 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1027 batches | lr 0.0001 | ms/batch 409.34 | loss  0.21 | mse  0.21 |
scGPT - INFO - | epoch   1 | 200/1027 batches | lr 0.0001 | ms/batch 391.59 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 300/1027 batches | lr 0.0001 | ms/batch 393.02 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 400/1027 batches | lr 0.0001 | ms/batch 391.47 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 500/1027 batches | lr 0.0001 | ms/batch 391.49 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 600/1027 batches | lr 0.0001 | ms/batch 391.62 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 700/1027 batches | lr 0.0001 | ms/batch 393.66 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 800/1027 batches | lr 0.0001 | ms/batch 392.73 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 900/1027 batches | lr 0.0001 | ms/batch 391.78 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 1000/1027 batches | lr 0.0001 | ms/batch 391.77 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 424.38s | valid loss/mse 0.1065 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1065
scGPT - INFO - | epoch   2 | 100/1027 batches | lr 0.0001 | ms/batch 396.43 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/1027 batches | lr 0.0001 | ms/batch 392.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/1027 batches | lr 0.0001 | ms/batch 392.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 400/1027 batches | lr 0.0001 | ms/batch 392.30 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 500/1027 batches | lr 0.0001 | ms/batch 392.22 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 600/1027 batches | lr 0.0001 | ms/batch 392.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 700/1027 batches | lr 0.0001 | ms/batch 393.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 800/1027 batches | lr 0.0001 | ms/batch 392.39 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 900/1027 batches | lr 0.0001 | ms/batch 392.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 1000/1027 batches | lr 0.0001 | ms/batch 393.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 423.44s | valid loss/mse 0.1020 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1020
scGPT - INFO - | epoch   3 | 100/1027 batches | lr 0.0001 | ms/batch 397.39 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 200/1027 batches | lr 0.0001 | ms/batch 392.56 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 300/1027 batches | lr 0.0001 | ms/batch 392.47 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 400/1027 batches | lr 0.0001 | ms/batch 393.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 500/1027 batches | lr 0.0001 | ms/batch 392.49 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 600/1027 batches | lr 0.0001 | ms/batch 392.69 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 700/1027 batches | lr 0.0001 | ms/batch 392.07 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 800/1027 batches | lr 0.0001 | ms/batch 392.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 900/1027 batches | lr 0.0001 | ms/batch 392.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 1000/1027 batches | lr 0.0001 | ms/batch 392.01 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 423.40s | valid loss/mse 0.1031 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/1027 batches | lr 0.0001 | ms/batch 396.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 200/1027 batches | lr 0.0001 | ms/batch 392.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 300/1027 batches | lr 0.0001 | ms/batch 392.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 400/1027 batches | lr 0.0001 | ms/batch 392.30 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 500/1027 batches | lr 0.0001 | ms/batch 392.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 600/1027 batches | lr 0.0001 | ms/batch 392.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 700/1027 batches | lr 0.0001 | ms/batch 392.21 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 800/1027 batches | lr 0.0001 | ms/batch 392.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 900/1027 batches | lr 0.0001 | ms/batch 392.18 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 1000/1027 batches | lr 0.0001 | ms/batch 392.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 423.10s | valid loss/mse 0.1064 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/1027 batches | lr 0.0001 | ms/batch 396.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 200/1027 batches | lr 0.0001 | ms/batch 392.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 300/1027 batches | lr 0.0001 | ms/batch 392.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 400/1027 batches | lr 0.0001 | ms/batch 392.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 500/1027 batches | lr 0.0001 | ms/batch 392.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 600/1027 batches | lr 0.0001 | ms/batch 392.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 700/1027 batches | lr 0.0001 | ms/batch 392.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 800/1027 batches | lr 0.0001 | ms/batch 392.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 900/1027 batches | lr 0.0001 | ms/batch 392.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 1000/1027 batches | lr 0.0001 | ms/batch 391.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 423.01s | valid loss/mse 0.1041 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/1027 batches | lr 0.0001 | ms/batch 396.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 200/1027 batches | lr 0.0001 | ms/batch 392.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 300/1027 batches | lr 0.0001 | ms/batch 392.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 400/1027 batches | lr 0.0001 | ms/batch 392.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 500/1027 batches | lr 0.0001 | ms/batch 392.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 600/1027 batches | lr 0.0001 | ms/batch 392.93 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 700/1027 batches | lr 0.0001 | ms/batch 392.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 800/1027 batches | lr 0.0001 | ms/batch 392.05 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 900/1027 batches | lr 0.0001 | ms/batch 392.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 1000/1027 batches | lr 0.0001 | ms/batch 392.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 423.18s | valid loss/mse 0.1056 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/1027 batches | lr 0.0001 | ms/batch 396.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 200/1027 batches | lr 0.0001 | ms/batch 392.85 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 300/1027 batches | lr 0.0001 | ms/batch 392.38 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 400/1027 batches | lr 0.0001 | ms/batch 392.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 500/1027 batches | lr 0.0001 | ms/batch 392.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 600/1027 batches | lr 0.0001 | ms/batch 392.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 700/1027 batches | lr 0.0001 | ms/batch 392.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 800/1027 batches | lr 0.0001 | ms/batch 392.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 900/1027 batches | lr 0.0001 | ms/batch 392.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 1000/1027 batches | lr 0.0001 | ms/batch 392.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 423.27s | valid loss/mse 0.1056 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_combined/scgpt/split2
scGPT - INFO - Running on 2024-07-26 06:28:31
scGPT - INFO - match 3748/5015 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/942 batches | lr 0.0001 | ms/batch 396.44 | loss  0.21 | mse  0.21 |
scGPT - INFO - | epoch   1 | 200/942 batches | lr 0.0001 | ms/batch 392.36 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 300/942 batches | lr 0.0001 | ms/batch 393.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/942 batches | lr 0.0001 | ms/batch 392.68 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/942 batches | lr 0.0001 | ms/batch 392.78 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 600/942 batches | lr 0.0001 | ms/batch 392.82 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 700/942 batches | lr 0.0001 | ms/batch 392.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 800/942 batches | lr 0.0001 | ms/batch 392.94 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 900/942 batches | lr 0.0001 | ms/batch 392.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 390.55s | valid loss/mse 0.1067 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1067
scGPT - INFO - | epoch   2 | 100/942 batches | lr 0.0001 | ms/batch 396.87 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/942 batches | lr 0.0001 | ms/batch 393.01 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/942 batches | lr 0.0001 | ms/batch 392.85 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 400/942 batches | lr 0.0001 | ms/batch 393.04 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 500/942 batches | lr 0.0001 | ms/batch 393.00 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 600/942 batches | lr 0.0001 | ms/batch 392.87 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 700/942 batches | lr 0.0001 | ms/batch 392.92 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 800/942 batches | lr 0.0001 | ms/batch 392.82 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 900/942 batches | lr 0.0001 | ms/batch 392.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 390.45s | valid loss/mse 0.1093 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/942 batches | lr 0.0001 | ms/batch 396.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 200/942 batches | lr 0.0001 | ms/batch 392.88 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 300/942 batches | lr 0.0001 | ms/batch 392.94 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 400/942 batches | lr 0.0001 | ms/batch 392.90 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 500/942 batches | lr 0.0001 | ms/batch 392.86 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 600/942 batches | lr 0.0001 | ms/batch 392.73 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 700/942 batches | lr 0.0001 | ms/batch 392.73 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 800/942 batches | lr 0.0001 | ms/batch 392.80 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 900/942 batches | lr 0.0001 | ms/batch 392.80 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 390.37s | valid loss/mse 0.1072 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/942 batches | lr 0.0001 | ms/batch 396.80 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 200/942 batches | lr 0.0001 | ms/batch 392.76 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 300/942 batches | lr 0.0001 | ms/batch 392.89 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 400/942 batches | lr 0.0001 | ms/batch 392.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 500/942 batches | lr 0.0001 | ms/batch 392.97 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 600/942 batches | lr 0.0001 | ms/batch 392.79 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 700/942 batches | lr 0.0001 | ms/batch 392.72 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 800/942 batches | lr 0.0001 | ms/batch 392.65 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 900/942 batches | lr 0.0001 | ms/batch 392.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 390.34s | valid loss/mse 0.1065 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1065
scGPT - INFO - | epoch   5 | 100/942 batches | lr 0.0001 | ms/batch 396.55 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 200/942 batches | lr 0.0001 | ms/batch 392.62 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 300/942 batches | lr 0.0001 | ms/batch 392.58 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 400/942 batches | lr 0.0001 | ms/batch 392.69 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 500/942 batches | lr 0.0001 | ms/batch 392.76 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 600/942 batches | lr 0.0001 | ms/batch 392.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 700/942 batches | lr 0.0001 | ms/batch 392.76 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 800/942 batches | lr 0.0001 | ms/batch 392.92 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 900/942 batches | lr 0.0001 | ms/batch 392.93 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 390.32s | valid loss/mse 0.1066 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/942 batches | lr 0.0001 | ms/batch 396.75 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 200/942 batches | lr 0.0001 | ms/batch 392.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 300/942 batches | lr 0.0001 | ms/batch 392.77 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 400/942 batches | lr 0.0001 | ms/batch 392.70 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 500/942 batches | lr 0.0001 | ms/batch 392.65 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 600/942 batches | lr 0.0001 | ms/batch 392.67 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 700/942 batches | lr 0.0001 | ms/batch 392.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 800/942 batches | lr 0.0001 | ms/batch 392.64 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 900/942 batches | lr 0.0001 | ms/batch 392.89 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 390.29s | valid loss/mse 0.1051 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1051
scGPT - INFO - | epoch   7 | 100/942 batches | lr 0.0001 | ms/batch 396.79 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 200/942 batches | lr 0.0001 | ms/batch 392.91 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 300/942 batches | lr 0.0001 | ms/batch 392.79 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 400/942 batches | lr 0.0001 | ms/batch 392.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 500/942 batches | lr 0.0001 | ms/batch 392.79 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 600/942 batches | lr 0.0001 | ms/batch 392.73 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 700/942 batches | lr 0.0001 | ms/batch 392.60 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 800/942 batches | lr 0.0001 | ms/batch 392.71 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 900/942 batches | lr 0.0001 | ms/batch 392.95 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 390.38s | valid loss/mse 0.1063 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/942 batches | lr 0.0000 | ms/batch 396.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 200/942 batches | lr 0.0000 | ms/batch 392.63 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 300/942 batches | lr 0.0000 | ms/batch 392.68 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 400/942 batches | lr 0.0000 | ms/batch 392.73 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 500/942 batches | lr 0.0000 | ms/batch 392.82 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 600/942 batches | lr 0.0000 | ms/batch 392.89 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 700/942 batches | lr 0.0000 | ms/batch 392.77 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 800/942 batches | lr 0.0000 | ms/batch 392.79 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 900/942 batches | lr 0.0000 | ms/batch 392.91 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 390.35s | valid loss/mse 0.1080 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/942 batches | lr 0.0000 | ms/batch 396.53 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 200/942 batches | lr 0.0000 | ms/batch 392.56 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 300/942 batches | lr 0.0000 | ms/batch 392.55 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 400/942 batches | lr 0.0000 | ms/batch 392.59 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 500/942 batches | lr 0.0000 | ms/batch 392.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 600/942 batches | lr 0.0000 | ms/batch 392.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 700/942 batches | lr 0.0000 | ms/batch 392.53 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 800/942 batches | lr 0.0000 | ms/batch 392.58 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 900/942 batches | lr 0.0000 | ms/batch 392.92 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 390.26s | valid loss/mse 0.1041 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1041
scGPT - INFO - | epoch  10 | 100/942 batches | lr 0.0000 | ms/batch 398.72 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 200/942 batches | lr 0.0000 | ms/batch 394.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 300/942 batches | lr 0.0000 | ms/batch 392.97 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 400/942 batches | lr 0.0000 | ms/batch 392.78 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 500/942 batches | lr 0.0000 | ms/batch 392.75 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 600/942 batches | lr 0.0000 | ms/batch 392.75 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 700/942 batches | lr 0.0000 | ms/batch 392.70 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 800/942 batches | lr 0.0000 | ms/batch 392.68 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 900/942 batches | lr 0.0000 | ms/batch 393.00 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 390.72s | valid loss/mse 0.1075 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/942 batches | lr 0.0000 | ms/batch 396.72 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 200/942 batches | lr 0.0000 | ms/batch 392.79 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 300/942 batches | lr 0.0000 | ms/batch 392.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 400/942 batches | lr 0.0000 | ms/batch 392.78 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 500/942 batches | lr 0.0000 | ms/batch 392.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 600/942 batches | lr 0.0000 | ms/batch 392.57 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 700/942 batches | lr 0.0000 | ms/batch 392.77 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 800/942 batches | lr 0.0000 | ms/batch 392.76 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 900/942 batches | lr 0.0000 | ms/batch 392.61 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 390.32s | valid loss/mse 0.1061 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/942 batches | lr 0.0000 | ms/batch 396.71 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 200/942 batches | lr 0.0000 | ms/batch 392.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 300/942 batches | lr 0.0000 | ms/batch 392.76 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 400/942 batches | lr 0.0000 | ms/batch 392.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 500/942 batches | lr 0.0000 | ms/batch 392.54 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 600/942 batches | lr 0.0000 | ms/batch 392.41 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 700/942 batches | lr 0.0000 | ms/batch 392.48 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 800/942 batches | lr 0.0000 | ms/batch 392.48 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  12 | 900/942 batches | lr 0.0000 | ms/batch 392.86 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 390.25s | valid loss/mse 0.1073 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/942 batches | lr 0.0000 | ms/batch 396.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 200/942 batches | lr 0.0000 | ms/batch 392.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 300/942 batches | lr 0.0000 | ms/batch 392.90 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 400/942 batches | lr 0.0000 | ms/batch 392.75 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 500/942 batches | lr 0.0000 | ms/batch 392.64 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 600/942 batches | lr 0.0000 | ms/batch 392.51 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 700/942 batches | lr 0.0000 | ms/batch 392.70 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 800/942 batches | lr 0.0000 | ms/batch 392.65 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  13 | 900/942 batches | lr 0.0000 | ms/batch 392.57 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 390.32s | valid loss/mse 0.1063 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/942 batches | lr 0.0000 | ms/batch 396.54 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 200/942 batches | lr 0.0000 | ms/batch 392.50 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 300/942 batches | lr 0.0000 | ms/batch 392.47 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 400/942 batches | lr 0.0000 | ms/batch 392.56 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 500/942 batches | lr 0.0000 | ms/batch 392.53 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 600/942 batches | lr 0.0000 | ms/batch 392.74 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 700/942 batches | lr 0.0000 | ms/batch 392.88 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 800/942 batches | lr 0.0000 | ms/batch 392.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 900/942 batches | lr 0.0000 | ms/batch 392.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 390.22s | valid loss/mse 0.1085 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 14
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_combined/scgpt/split3
scGPT - INFO - Running on 2024-07-26 08:31:13
scGPT - INFO - match 3748/5015 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/989 batches | lr 0.0001 | ms/batch 397.77 | loss  0.18 | mse  0.18 |
scGPT - INFO - | epoch   1 | 200/989 batches | lr 0.0001 | ms/batch 392.80 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 300/989 batches | lr 0.0001 | ms/batch 392.91 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 400/989 batches | lr 0.0001 | ms/batch 392.97 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 500/989 batches | lr 0.0001 | ms/batch 392.87 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 600/989 batches | lr 0.0001 | ms/batch 393.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 700/989 batches | lr 0.0001 | ms/batch 393.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 800/989 batches | lr 0.0001 | ms/batch 393.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 900/989 batches | lr 0.0001 | ms/batch 393.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 420.41s | valid loss/mse 0.1124 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1124
scGPT - INFO - | epoch   2 | 100/989 batches | lr 0.0001 | ms/batch 397.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/989 batches | lr 0.0001 | ms/batch 393.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/989 batches | lr 0.0001 | ms/batch 393.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 400/989 batches | lr 0.0001 | ms/batch 393.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 500/989 batches | lr 0.0001 | ms/batch 393.18 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 600/989 batches | lr 0.0001 | ms/batch 393.30 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 700/989 batches | lr 0.0001 | ms/batch 393.37 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 800/989 batches | lr 0.0001 | ms/batch 393.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 900/989 batches | lr 0.0001 | ms/batch 393.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 420.54s | valid loss/mse 0.1139 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/989 batches | lr 0.0001 | ms/batch 397.20 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 200/989 batches | lr 0.0001 | ms/batch 393.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 300/989 batches | lr 0.0001 | ms/batch 393.18 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 400/989 batches | lr 0.0001 | ms/batch 393.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 500/989 batches | lr 0.0001 | ms/batch 392.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 600/989 batches | lr 0.0001 | ms/batch 393.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 700/989 batches | lr 0.0001 | ms/batch 393.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 800/989 batches | lr 0.0001 | ms/batch 392.90 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 900/989 batches | lr 0.0001 | ms/batch 392.99 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 420.19s | valid loss/mse 0.1111 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1111
scGPT - INFO - | epoch   4 | 100/989 batches | lr 0.0001 | ms/batch 397.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 200/989 batches | lr 0.0001 | ms/batch 393.04 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 300/989 batches | lr 0.0001 | ms/batch 393.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 400/989 batches | lr 0.0001 | ms/batch 393.09 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 500/989 batches | lr 0.0001 | ms/batch 392.88 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 600/989 batches | lr 0.0001 | ms/batch 392.95 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 700/989 batches | lr 0.0001 | ms/batch 392.98 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 800/989 batches | lr 0.0001 | ms/batch 392.88 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 900/989 batches | lr 0.0001 | ms/batch 393.05 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 420.01s | valid loss/mse 0.1097 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1097
scGPT - INFO - | epoch   5 | 100/989 batches | lr 0.0001 | ms/batch 396.81 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 200/989 batches | lr 0.0001 | ms/batch 392.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 300/989 batches | lr 0.0001 | ms/batch 392.95 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 400/989 batches | lr 0.0001 | ms/batch 393.02 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 500/989 batches | lr 0.0001 | ms/batch 392.93 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 600/989 batches | lr 0.0001 | ms/batch 393.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 700/989 batches | lr 0.0001 | ms/batch 393.09 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 800/989 batches | lr 0.0001 | ms/batch 393.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 900/989 batches | lr 0.0001 | ms/batch 393.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 420.10s | valid loss/mse 0.1141 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/989 batches | lr 0.0001 | ms/batch 397.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 200/989 batches | lr 0.0001 | ms/batch 393.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 300/989 batches | lr 0.0001 | ms/batch 393.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 400/989 batches | lr 0.0001 | ms/batch 393.20 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 500/989 batches | lr 0.0001 | ms/batch 393.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 600/989 batches | lr 0.0001 | ms/batch 393.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 700/989 batches | lr 0.0001 | ms/batch 393.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 800/989 batches | lr 0.0001 | ms/batch 393.22 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 900/989 batches | lr 0.0001 | ms/batch 393.41 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 420.31s | valid loss/mse 0.1118 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/989 batches | lr 0.0001 | ms/batch 397.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 200/989 batches | lr 0.0001 | ms/batch 393.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 300/989 batches | lr 0.0001 | ms/batch 393.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 400/989 batches | lr 0.0001 | ms/batch 393.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 500/989 batches | lr 0.0001 | ms/batch 393.22 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 600/989 batches | lr 0.0001 | ms/batch 393.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 700/989 batches | lr 0.0001 | ms/batch 393.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 800/989 batches | lr 0.0001 | ms/batch 393.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 900/989 batches | lr 0.0001 | ms/batch 393.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 420.29s | valid loss/mse 0.1125 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/989 batches | lr 0.0000 | ms/batch 397.18 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 200/989 batches | lr 0.0000 | ms/batch 393.18 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 300/989 batches | lr 0.0000 | ms/batch 393.09 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 400/989 batches | lr 0.0000 | ms/batch 393.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 500/989 batches | lr 0.0000 | ms/batch 393.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 600/989 batches | lr 0.0000 | ms/batch 393.11 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 700/989 batches | lr 0.0000 | ms/batch 393.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 800/989 batches | lr 0.0000 | ms/batch 393.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 900/989 batches | lr 0.0000 | ms/batch 393.41 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 420.44s | valid loss/mse 0.1134 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/989 batches | lr 0.0000 | ms/batch 397.67 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 200/989 batches | lr 0.0000 | ms/batch 393.71 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 300/989 batches | lr 0.0000 | ms/batch 393.68 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 400/989 batches | lr 0.0000 | ms/batch 394.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 500/989 batches | lr 0.0000 | ms/batch 394.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 600/989 batches | lr 0.0000 | ms/batch 393.84 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 700/989 batches | lr 0.0000 | ms/batch 394.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 800/989 batches | lr 0.0000 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 900/989 batches | lr 0.0000 | ms/batch 394.21 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 421.34s | valid loss/mse 0.1111 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 9
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_combined/scgpt/split4
scGPT - INFO - Running on 2024-07-26 09:57:34
scGPT - INFO - match 3748/5015 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1130 batches | lr 0.0001 | ms/batch 400.15 | loss  0.19 | mse  0.19 |
scGPT - INFO - | epoch   1 | 200/1130 batches | lr 0.0001 | ms/batch 394.16 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 300/1130 batches | lr 0.0001 | ms/batch 394.18 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 400/1130 batches | lr 0.0001 | ms/batch 394.24 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 500/1130 batches | lr 0.0001 | ms/batch 394.43 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 600/1130 batches | lr 0.0001 | ms/batch 394.37 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 700/1130 batches | lr 0.0001 | ms/batch 394.40 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 800/1130 batches | lr 0.0001 | ms/batch 394.39 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 900/1130 batches | lr 0.0001 | ms/batch 394.36 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 1000/1130 batches | lr 0.0001 | ms/batch 394.27 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 1100/1130 batches | lr 0.0001 | ms/batch 394.10 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 455.93s | valid loss/mse 0.1082 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1082
scGPT - INFO - | epoch   2 | 100/1130 batches | lr 0.0001 | ms/batch 398.08 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/1130 batches | lr 0.0001 | ms/batch 394.05 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/1130 batches | lr 0.0001 | ms/batch 394.11 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 400/1130 batches | lr 0.0001 | ms/batch 394.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 500/1130 batches | lr 0.0001 | ms/batch 394.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 600/1130 batches | lr 0.0001 | ms/batch 394.42 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 700/1130 batches | lr 0.0001 | ms/batch 394.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 800/1130 batches | lr 0.0001 | ms/batch 394.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 900/1130 batches | lr 0.0001 | ms/batch 394.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 1000/1130 batches | lr 0.0001 | ms/batch 394.16 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 1100/1130 batches | lr 0.0001 | ms/batch 394.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 455.36s | valid loss/mse 0.1114 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/1130 batches | lr 0.0001 | ms/batch 398.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 200/1130 batches | lr 0.0001 | ms/batch 394.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 300/1130 batches | lr 0.0001 | ms/batch 394.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 400/1130 batches | lr 0.0001 | ms/batch 393.97 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 500/1130 batches | lr 0.0001 | ms/batch 394.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 600/1130 batches | lr 0.0001 | ms/batch 394.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 700/1130 batches | lr 0.0001 | ms/batch 394.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 800/1130 batches | lr 0.0001 | ms/batch 394.24 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 900/1130 batches | lr 0.0001 | ms/batch 394.20 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 1000/1130 batches | lr 0.0001 | ms/batch 394.32 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 1100/1130 batches | lr 0.0001 | ms/batch 394.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 455.53s | valid loss/mse 0.1089 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/1130 batches | lr 0.0001 | ms/batch 398.29 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 200/1130 batches | lr 0.0001 | ms/batch 394.11 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 300/1130 batches | lr 0.0001 | ms/batch 394.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 400/1130 batches | lr 0.0001 | ms/batch 394.38 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 500/1130 batches | lr 0.0001 | ms/batch 394.39 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 600/1130 batches | lr 0.0001 | ms/batch 394.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 700/1130 batches | lr 0.0001 | ms/batch 394.21 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 800/1130 batches | lr 0.0001 | ms/batch 394.44 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 900/1130 batches | lr 0.0001 | ms/batch 394.51 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 1000/1130 batches | lr 0.0001 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 1100/1130 batches | lr 0.0001 | ms/batch 394.73 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 455.60s | valid loss/mse 0.1063 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1063
scGPT - INFO - | epoch   5 | 100/1130 batches | lr 0.0001 | ms/batch 398.37 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 200/1130 batches | lr 0.0001 | ms/batch 394.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 300/1130 batches | lr 0.0001 | ms/batch 394.21 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 400/1130 batches | lr 0.0001 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 500/1130 batches | lr 0.0001 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 600/1130 batches | lr 0.0001 | ms/batch 394.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 700/1130 batches | lr 0.0001 | ms/batch 394.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 800/1130 batches | lr 0.0001 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 900/1130 batches | lr 0.0001 | ms/batch 394.41 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 1000/1130 batches | lr 0.0001 | ms/batch 394.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 1100/1130 batches | lr 0.0001 | ms/batch 394.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 455.52s | valid loss/mse 0.1066 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/1130 batches | lr 0.0001 | ms/batch 398.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 200/1130 batches | lr 0.0001 | ms/batch 394.16 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 300/1130 batches | lr 0.0001 | ms/batch 394.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 400/1130 batches | lr 0.0001 | ms/batch 394.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 500/1130 batches | lr 0.0001 | ms/batch 394.37 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 600/1130 batches | lr 0.0001 | ms/batch 394.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 700/1130 batches | lr 0.0001 | ms/batch 394.27 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 800/1130 batches | lr 0.0001 | ms/batch 394.18 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 900/1130 batches | lr 0.0001 | ms/batch 394.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 1000/1130 batches | lr 0.0001 | ms/batch 394.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 1100/1130 batches | lr 0.0001 | ms/batch 394.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 455.46s | valid loss/mse 0.1085 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/1130 batches | lr 0.0001 | ms/batch 398.03 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 200/1130 batches | lr 0.0001 | ms/batch 394.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 300/1130 batches | lr 0.0001 | ms/batch 394.58 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 400/1130 batches | lr 0.0001 | ms/batch 394.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 500/1130 batches | lr 0.0001 | ms/batch 394.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 600/1130 batches | lr 0.0001 | ms/batch 394.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 700/1130 batches | lr 0.0001 | ms/batch 394.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 800/1130 batches | lr 0.0001 | ms/batch 394.48 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 900/1130 batches | lr 0.0001 | ms/batch 394.43 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 1000/1130 batches | lr 0.0001 | ms/batch 394.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 1100/1130 batches | lr 0.0001 | ms/batch 394.11 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 455.56s | valid loss/mse 0.1068 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/1130 batches | lr 0.0000 | ms/batch 398.38 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 200/1130 batches | lr 0.0000 | ms/batch 394.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 300/1130 batches | lr 0.0000 | ms/batch 394.11 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 400/1130 batches | lr 0.0000 | ms/batch 394.50 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 500/1130 batches | lr 0.0000 | ms/batch 395.30 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 600/1130 batches | lr 0.0000 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 700/1130 batches | lr 0.0000 | ms/batch 394.54 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 800/1130 batches | lr 0.0000 | ms/batch 394.37 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 900/1130 batches | lr 0.0000 | ms/batch 394.39 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 1000/1130 batches | lr 0.0000 | ms/batch 394.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 1100/1130 batches | lr 0.0000 | ms/batch 394.38 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 455.71s | valid loss/mse 0.1082 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/1130 batches | lr 0.0000 | ms/batch 398.50 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 200/1130 batches | lr 0.0000 | ms/batch 393.90 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   9 | 300/1130 batches | lr 0.0000 | ms/batch 394.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 400/1130 batches | lr 0.0000 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 500/1130 batches | lr 0.0000 | ms/batch 394.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 600/1130 batches | lr 0.0000 | ms/batch 394.20 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 700/1130 batches | lr 0.0000 | ms/batch 394.30 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 800/1130 batches | lr 0.0000 | ms/batch 394.07 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 900/1130 batches | lr 0.0000 | ms/batch 394.08 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 1000/1130 batches | lr 0.0000 | ms/batch 394.02 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 1100/1130 batches | lr 0.0000 | ms/batch 394.15 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 455.40s | valid loss/mse 0.1065 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 9
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_combined/scgpt/split5
scGPT - INFO - Running on 2024-07-26 11:28:09
scGPT - INFO - match 3748/5015 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1110 batches | lr 0.0001 | ms/batch 399.66 | loss  0.25 | mse  0.25 |
scGPT - INFO - | epoch   1 | 200/1110 batches | lr 0.0001 | ms/batch 394.05 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 300/1110 batches | lr 0.0001 | ms/batch 394.05 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 400/1110 batches | lr 0.0001 | ms/batch 393.98 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 500/1110 batches | lr 0.0001 | ms/batch 394.10 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 600/1110 batches | lr 0.0001 | ms/batch 394.15 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 700/1110 batches | lr 0.0001 | ms/batch 394.78 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 800/1110 batches | lr 0.0001 | ms/batch 394.02 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 900/1110 batches | lr 0.0001 | ms/batch 394.15 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 1000/1110 batches | lr 0.0001 | ms/batch 394.21 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 1100/1110 batches | lr 0.0001 | ms/batch 394.13 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 449.96s | valid loss/mse 0.1033 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1033
scGPT - INFO - | epoch   2 | 100/1110 batches | lr 0.0001 | ms/batch 398.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/1110 batches | lr 0.0001 | ms/batch 394.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/1110 batches | lr 0.0001 | ms/batch 394.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 400/1110 batches | lr 0.0001 | ms/batch 394.00 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 500/1110 batches | lr 0.0001 | ms/batch 394.04 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 600/1110 batches | lr 0.0001 | ms/batch 394.01 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 700/1110 batches | lr 0.0001 | ms/batch 394.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 800/1110 batches | lr 0.0001 | ms/batch 394.14 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 900/1110 batches | lr 0.0001 | ms/batch 394.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 1000/1110 batches | lr 0.0001 | ms/batch 394.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 1100/1110 batches | lr 0.0001 | ms/batch 394.43 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 449.66s | valid loss/mse 0.1038 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/1110 batches | lr 0.0001 | ms/batch 398.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 200/1110 batches | lr 0.0001 | ms/batch 394.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 300/1110 batches | lr 0.0001 | ms/batch 394.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 400/1110 batches | lr 0.0001 | ms/batch 394.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 500/1110 batches | lr 0.0001 | ms/batch 394.37 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 600/1110 batches | lr 0.0001 | ms/batch 394.00 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 700/1110 batches | lr 0.0001 | ms/batch 394.22 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 800/1110 batches | lr 0.0001 | ms/batch 394.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 900/1110 batches | lr 0.0001 | ms/batch 394.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 1000/1110 batches | lr 0.0001 | ms/batch 393.99 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   3 | 1100/1110 batches | lr 0.0001 | ms/batch 394.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 449.72s | valid loss/mse 0.1044 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/1110 batches | lr 0.0001 | ms/batch 398.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 200/1110 batches | lr 0.0001 | ms/batch 394.09 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 300/1110 batches | lr 0.0001 | ms/batch 394.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 400/1110 batches | lr 0.0001 | ms/batch 394.08 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 500/1110 batches | lr 0.0001 | ms/batch 394.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 600/1110 batches | lr 0.0001 | ms/batch 394.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 700/1110 batches | lr 0.0001 | ms/batch 394.13 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 800/1110 batches | lr 0.0001 | ms/batch 394.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 900/1110 batches | lr 0.0001 | ms/batch 394.86 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 1000/1110 batches | lr 0.0001 | ms/batch 394.05 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 1100/1110 batches | lr 0.0001 | ms/batch 394.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 449.78s | valid loss/mse 0.1033 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/1110 batches | lr 0.0001 | ms/batch 397.86 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 200/1110 batches | lr 0.0001 | ms/batch 393.92 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 300/1110 batches | lr 0.0001 | ms/batch 394.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 400/1110 batches | lr 0.0001 | ms/batch 394.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 500/1110 batches | lr 0.0001 | ms/batch 394.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 600/1110 batches | lr 0.0001 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 700/1110 batches | lr 0.0001 | ms/batch 394.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 800/1110 batches | lr 0.0001 | ms/batch 393.92 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 900/1110 batches | lr 0.0001 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 1000/1110 batches | lr 0.0001 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 1100/1110 batches | lr 0.0001 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 449.69s | valid loss/mse 0.1031 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1031
scGPT - INFO - | epoch   6 | 100/1110 batches | lr 0.0001 | ms/batch 397.86 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 200/1110 batches | lr 0.0001 | ms/batch 394.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 300/1110 batches | lr 0.0001 | ms/batch 394.58 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 400/1110 batches | lr 0.0001 | ms/batch 394.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 500/1110 batches | lr 0.0001 | ms/batch 394.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 600/1110 batches | lr 0.0001 | ms/batch 394.12 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 700/1110 batches | lr 0.0001 | ms/batch 394.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 800/1110 batches | lr 0.0001 | ms/batch 394.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 900/1110 batches | lr 0.0001 | ms/batch 394.43 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 1000/1110 batches | lr 0.0001 | ms/batch 395.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 1100/1110 batches | lr 0.0001 | ms/batch 394.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 449.85s | valid loss/mse 0.1008 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1008
scGPT - INFO - | epoch   7 | 100/1110 batches | lr 0.0001 | ms/batch 398.42 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 200/1110 batches | lr 0.0001 | ms/batch 394.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 300/1110 batches | lr 0.0001 | ms/batch 394.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 400/1110 batches | lr 0.0001 | ms/batch 393.98 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 500/1110 batches | lr 0.0001 | ms/batch 394.04 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 600/1110 batches | lr 0.0001 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 700/1110 batches | lr 0.0001 | ms/batch 394.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 800/1110 batches | lr 0.0001 | ms/batch 394.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 900/1110 batches | lr 0.0001 | ms/batch 394.16 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 1000/1110 batches | lr 0.0001 | ms/batch 394.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   7 | 1100/1110 batches | lr 0.0001 | ms/batch 394.48 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 449.77s | valid loss/mse 0.1040 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/1110 batches | lr 0.0000 | ms/batch 399.71 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 200/1110 batches | lr 0.0000 | ms/batch 394.62 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 300/1110 batches | lr 0.0000 | ms/batch 394.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 400/1110 batches | lr 0.0000 | ms/batch 394.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 500/1110 batches | lr 0.0000 | ms/batch 394.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 600/1110 batches | lr 0.0000 | ms/batch 394.25 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 700/1110 batches | lr 0.0000 | ms/batch 394.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 800/1110 batches | lr 0.0000 | ms/batch 394.57 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 900/1110 batches | lr 0.0000 | ms/batch 394.11 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 1000/1110 batches | lr 0.0000 | ms/batch 394.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   8 | 1100/1110 batches | lr 0.0000 | ms/batch 394.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 449.97s | valid loss/mse 0.1014 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/1110 batches | lr 0.0000 | ms/batch 398.09 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 200/1110 batches | lr 0.0000 | ms/batch 394.38 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 300/1110 batches | lr 0.0000 | ms/batch 394.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 400/1110 batches | lr 0.0000 | ms/batch 394.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 500/1110 batches | lr 0.0000 | ms/batch 394.02 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 600/1110 batches | lr 0.0000 | ms/batch 394.07 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 700/1110 batches | lr 0.0000 | ms/batch 394.11 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 800/1110 batches | lr 0.0000 | ms/batch 394.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 900/1110 batches | lr 0.0000 | ms/batch 394.27 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 1000/1110 batches | lr 0.0000 | ms/batch 394.47 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   9 | 1100/1110 batches | lr 0.0000 | ms/batch 394.43 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 449.75s | valid loss/mse 0.1045 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/1110 batches | lr 0.0000 | ms/batch 398.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 200/1110 batches | lr 0.0000 | ms/batch 394.17 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 300/1110 batches | lr 0.0000 | ms/batch 394.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 400/1110 batches | lr 0.0000 | ms/batch 394.32 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 500/1110 batches | lr 0.0000 | ms/batch 394.23 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 600/1110 batches | lr 0.0000 | ms/batch 394.55 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 700/1110 batches | lr 0.0000 | ms/batch 394.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 800/1110 batches | lr 0.0000 | ms/batch 394.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 900/1110 batches | lr 0.0000 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 1000/1110 batches | lr 0.0000 | ms/batch 394.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  10 | 1100/1110 batches | lr 0.0000 | ms/batch 394.15 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 449.80s | valid loss/mse 0.1027 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/1110 batches | lr 0.0000 | ms/batch 398.09 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 200/1110 batches | lr 0.0000 | ms/batch 394.10 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 300/1110 batches | lr 0.0000 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 400/1110 batches | lr 0.0000 | ms/batch 394.40 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 500/1110 batches | lr 0.0000 | ms/batch 394.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 600/1110 batches | lr 0.0000 | ms/batch 394.22 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 700/1110 batches | lr 0.0000 | ms/batch 394.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 800/1110 batches | lr 0.0000 | ms/batch 394.24 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 900/1110 batches | lr 0.0000 | ms/batch 394.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 1000/1110 batches | lr 0.0000 | ms/batch 394.69 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  11 | 1100/1110 batches | lr 0.0000 | ms/batch 394.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 449.81s | valid loss/mse 0.1025 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 11
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396858/scgpt/split1
scGPT - INFO - Running on 2024-07-26 13:37:32
scGPT - INFO - match 3727/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/671 batches | lr 0.0001 | ms/batch 418.22 | loss  0.18 | mse  0.18 |
scGPT - INFO - | epoch   1 | 200/671 batches | lr 0.0001 | ms/batch 393.43 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 300/671 batches | lr 0.0001 | ms/batch 393.35 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/671 batches | lr 0.0001 | ms/batch 393.41 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/671 batches | lr 0.0001 | ms/batch 393.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 600/671 batches | lr 0.0001 | ms/batch 393.29 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 273.70s | valid loss/mse 0.0988 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0988
scGPT - INFO - | epoch   2 | 100/671 batches | lr 0.0001 | ms/batch 397.46 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/671 batches | lr 0.0001 | ms/batch 393.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/671 batches | lr 0.0001 | ms/batch 393.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/671 batches | lr 0.0001 | ms/batch 393.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/671 batches | lr 0.0001 | ms/batch 393.45 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 600/671 batches | lr 0.0001 | ms/batch 393.42 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 271.53s | valid loss/mse 0.1002 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/671 batches | lr 0.0001 | ms/batch 397.24 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/671 batches | lr 0.0001 | ms/batch 393.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/671 batches | lr 0.0001 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/671 batches | lr 0.0001 | ms/batch 393.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/671 batches | lr 0.0001 | ms/batch 393.33 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 600/671 batches | lr 0.0001 | ms/batch 393.26 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 271.52s | valid loss/mse 0.0973 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0973
scGPT - INFO - | epoch   4 | 100/671 batches | lr 0.0001 | ms/batch 396.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/671 batches | lr 0.0001 | ms/batch 393.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/671 batches | lr 0.0001 | ms/batch 393.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 400/671 batches | lr 0.0001 | ms/batch 393.07 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/671 batches | lr 0.0001 | ms/batch 393.09 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 600/671 batches | lr 0.0001 | ms/batch 392.93 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 271.26s | valid loss/mse 0.0986 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/671 batches | lr 0.0001 | ms/batch 396.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/671 batches | lr 0.0001 | ms/batch 393.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/671 batches | lr 0.0001 | ms/batch 393.50 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 400/671 batches | lr 0.0001 | ms/batch 393.32 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/671 batches | lr 0.0001 | ms/batch 393.23 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 600/671 batches | lr 0.0001 | ms/batch 393.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 271.44s | valid loss/mse 0.0968 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0968
scGPT - INFO - | epoch   6 | 100/671 batches | lr 0.0001 | ms/batch 397.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/671 batches | lr 0.0001 | ms/batch 393.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/671 batches | lr 0.0001 | ms/batch 393.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/671 batches | lr 0.0001 | ms/batch 393.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/671 batches | lr 0.0001 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 600/671 batches | lr 0.0001 | ms/batch 393.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 271.60s | valid loss/mse 0.0974 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/671 batches | lr 0.0001 | ms/batch 397.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/671 batches | lr 0.0001 | ms/batch 393.65 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/671 batches | lr 0.0001 | ms/batch 393.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/671 batches | lr 0.0001 | ms/batch 393.63 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/671 batches | lr 0.0001 | ms/batch 393.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 600/671 batches | lr 0.0001 | ms/batch 393.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 271.66s | valid loss/mse 0.1020 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/671 batches | lr 0.0000 | ms/batch 397.63 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/671 batches | lr 0.0000 | ms/batch 393.48 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/671 batches | lr 0.0000 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 400/671 batches | lr 0.0000 | ms/batch 393.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 500/671 batches | lr 0.0000 | ms/batch 393.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 600/671 batches | lr 0.0000 | ms/batch 393.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 271.69s | valid loss/mse 0.1003 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/671 batches | lr 0.0000 | ms/batch 397.61 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/671 batches | lr 0.0000 | ms/batch 393.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/671 batches | lr 0.0000 | ms/batch 393.47 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 400/671 batches | lr 0.0000 | ms/batch 393.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 500/671 batches | lr 0.0000 | ms/batch 393.63 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 600/671 batches | lr 0.0000 | ms/batch 393.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 271.69s | valid loss/mse 0.0984 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/671 batches | lr 0.0000 | ms/batch 397.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/671 batches | lr 0.0000 | ms/batch 393.82 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/671 batches | lr 0.0000 | ms/batch 393.71 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 400/671 batches | lr 0.0000 | ms/batch 393.71 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 500/671 batches | lr 0.0000 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 600/671 batches | lr 0.0000 | ms/batch 393.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 271.74s | valid loss/mse 0.0963 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0963
scGPT - INFO - | epoch  11 | 100/671 batches | lr 0.0000 | ms/batch 397.48 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/671 batches | lr 0.0000 | ms/batch 393.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/671 batches | lr 0.0000 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 400/671 batches | lr 0.0000 | ms/batch 393.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 500/671 batches | lr 0.0000 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 600/671 batches | lr 0.0000 | ms/batch 393.52 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 271.70s | valid loss/mse 0.0995 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/671 batches | lr 0.0000 | ms/batch 397.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/671 batches | lr 0.0000 | ms/batch 393.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/671 batches | lr 0.0000 | ms/batch 393.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 400/671 batches | lr 0.0000 | ms/batch 393.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 500/671 batches | lr 0.0000 | ms/batch 393.56 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 600/671 batches | lr 0.0000 | ms/batch 394.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 271.76s | valid loss/mse 0.1008 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/671 batches | lr 0.0000 | ms/batch 397.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/671 batches | lr 0.0000 | ms/batch 393.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 300/671 batches | lr 0.0000 | ms/batch 393.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 400/671 batches | lr 0.0000 | ms/batch 393.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 500/671 batches | lr 0.0000 | ms/batch 393.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 600/671 batches | lr 0.0000 | ms/batch 393.41 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 271.70s | valid loss/mse 0.0992 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/671 batches | lr 0.0000 | ms/batch 397.55 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch  14 | 200/671 batches | lr 0.0000 | ms/batch 393.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 300/671 batches | lr 0.0000 | ms/batch 393.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 400/671 batches | lr 0.0000 | ms/batch 393.43 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 500/671 batches | lr 0.0000 | ms/batch 393.53 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 600/671 batches | lr 0.0000 | ms/batch 393.47 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 271.59s | valid loss/mse 0.0988 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/671 batches | lr 0.0000 | ms/batch 397.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 200/671 batches | lr 0.0000 | ms/batch 393.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 300/671 batches | lr 0.0000 | ms/batch 393.43 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 400/671 batches | lr 0.0000 | ms/batch 393.43 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 500/671 batches | lr 0.0000 | ms/batch 393.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 600/671 batches | lr 0.0000 | ms/batch 393.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 271.64s | valid loss/mse 0.0990 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 15
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396858/scgpt/split2
scGPT - INFO - Running on 2024-07-26 14:49:24
scGPT - INFO - match 3727/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/633 batches | lr 0.0001 | ms/batch 398.45 | loss  0.16 | mse  0.16 |
scGPT - INFO - | epoch   1 | 200/633 batches | lr 0.0001 | ms/batch 393.36 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/633 batches | lr 0.0001 | ms/batch 393.50 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/633 batches | lr 0.0001 | ms/batch 393.34 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/633 batches | lr 0.0001 | ms/batch 393.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 600/633 batches | lr 0.0001 | ms/batch 393.65 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 260.54s | valid loss/mse 0.1054 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1054
scGPT - INFO - | epoch   2 | 100/633 batches | lr 0.0001 | ms/batch 397.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/633 batches | lr 0.0001 | ms/batch 393.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/633 batches | lr 0.0001 | ms/batch 393.86 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/633 batches | lr 0.0001 | ms/batch 393.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/633 batches | lr 0.0001 | ms/batch 393.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 600/633 batches | lr 0.0001 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 260.49s | valid loss/mse 0.0962 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0962
scGPT - INFO - | epoch   3 | 100/633 batches | lr 0.0001 | ms/batch 397.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/633 batches | lr 0.0001 | ms/batch 393.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/633 batches | lr 0.0001 | ms/batch 393.68 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/633 batches | lr 0.0001 | ms/batch 393.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/633 batches | lr 0.0001 | ms/batch 393.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 600/633 batches | lr 0.0001 | ms/batch 393.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 260.43s | valid loss/mse 0.0982 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/633 batches | lr 0.0001 | ms/batch 397.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/633 batches | lr 0.0001 | ms/batch 394.09 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/633 batches | lr 0.0001 | ms/batch 393.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 400/633 batches | lr 0.0001 | ms/batch 393.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/633 batches | lr 0.0001 | ms/batch 394.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 600/633 batches | lr 0.0001 | ms/batch 393.41 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 260.58s | valid loss/mse 0.0985 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/633 batches | lr 0.0001 | ms/batch 397.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/633 batches | lr 0.0001 | ms/batch 393.46 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/633 batches | lr 0.0001 | ms/batch 393.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 400/633 batches | lr 0.0001 | ms/batch 393.71 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/633 batches | lr 0.0001 | ms/batch 393.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 600/633 batches | lr 0.0001 | ms/batch 393.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 260.42s | valid loss/mse 0.0986 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/633 batches | lr 0.0001 | ms/batch 397.63 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/633 batches | lr 0.0001 | ms/batch 393.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/633 batches | lr 0.0001 | ms/batch 393.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/633 batches | lr 0.0001 | ms/batch 393.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/633 batches | lr 0.0001 | ms/batch 393.47 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 600/633 batches | lr 0.0001 | ms/batch 393.32 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 260.40s | valid loss/mse 0.0999 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/633 batches | lr 0.0001 | ms/batch 397.52 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/633 batches | lr 0.0001 | ms/batch 393.43 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/633 batches | lr 0.0001 | ms/batch 393.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/633 batches | lr 0.0001 | ms/batch 393.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/633 batches | lr 0.0001 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 600/633 batches | lr 0.0001 | ms/batch 393.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 260.45s | valid loss/mse 0.0975 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396858/scgpt/split3
scGPT - INFO - Running on 2024-07-26 15:24:00
scGPT - INFO - match 3727/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/507 batches | lr 0.0001 | ms/batch 399.11 | loss  0.21 | mse  0.21 |
scGPT - INFO - | epoch   1 | 200/507 batches | lr 0.0001 | ms/batch 393.90 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/507 batches | lr 0.0001 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 400/507 batches | lr 0.0001 | ms/batch 393.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 500/507 batches | lr 0.0001 | ms/batch 393.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 220.01s | valid loss/mse 0.1045 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1045
scGPT - INFO - | epoch   2 | 100/507 batches | lr 0.0001 | ms/batch 397.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/507 batches | lr 0.0001 | ms/batch 393.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/507 batches | lr 0.0001 | ms/batch 393.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/507 batches | lr 0.0001 | ms/batch 394.07 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/507 batches | lr 0.0001 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 219.82s | valid loss/mse 0.1036 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1036
scGPT - INFO - | epoch   3 | 100/507 batches | lr 0.0001 | ms/batch 397.48 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/507 batches | lr 0.0001 | ms/batch 393.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/507 batches | lr 0.0001 | ms/batch 393.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/507 batches | lr 0.0001 | ms/batch 393.88 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/507 batches | lr 0.0001 | ms/batch 393.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 219.75s | valid loss/mse 0.1067 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/507 batches | lr 0.0001 | ms/batch 397.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/507 batches | lr 0.0001 | ms/batch 393.60 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   4 | 300/507 batches | lr 0.0001 | ms/batch 393.94 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   4 | 400/507 batches | lr 0.0001 | ms/batch 393.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/507 batches | lr 0.0001 | ms/batch 393.64 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 219.75s | valid loss/mse 0.1024 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1024
scGPT - INFO - | epoch   5 | 100/507 batches | lr 0.0001 | ms/batch 397.85 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   5 | 200/507 batches | lr 0.0001 | ms/batch 393.78 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   5 | 300/507 batches | lr 0.0001 | ms/batch 393.87 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   5 | 400/507 batches | lr 0.0001 | ms/batch 393.75 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   5 | 500/507 batches | lr 0.0001 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 219.81s | valid loss/mse 0.1003 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1003
scGPT - INFO - | epoch   6 | 100/507 batches | lr 0.0001 | ms/batch 397.49 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   6 | 200/507 batches | lr 0.0001 | ms/batch 393.58 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   6 | 300/507 batches | lr 0.0001 | ms/batch 393.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/507 batches | lr 0.0001 | ms/batch 393.99 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   6 | 500/507 batches | lr 0.0001 | ms/batch 393.92 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 219.74s | valid loss/mse 0.1008 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/507 batches | lr 0.0001 | ms/batch 397.80 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   7 | 200/507 batches | lr 0.0001 | ms/batch 393.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/507 batches | lr 0.0001 | ms/batch 393.86 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   7 | 400/507 batches | lr 0.0001 | ms/batch 393.45 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   7 | 500/507 batches | lr 0.0001 | ms/batch 393.44 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 219.71s | valid loss/mse 0.1045 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/507 batches | lr 0.0000 | ms/batch 397.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/507 batches | lr 0.0000 | ms/batch 393.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/507 batches | lr 0.0000 | ms/batch 393.77 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   8 | 400/507 batches | lr 0.0000 | ms/batch 393.85 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   8 | 500/507 batches | lr 0.0000 | ms/batch 393.76 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 219.81s | valid loss/mse 0.1082 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/507 batches | lr 0.0000 | ms/batch 397.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/507 batches | lr 0.0000 | ms/batch 393.75 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   9 | 300/507 batches | lr 0.0000 | ms/batch 393.71 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   9 | 400/507 batches | lr 0.0000 | ms/batch 393.52 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 500/507 batches | lr 0.0000 | ms/batch 393.94 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 219.77s | valid loss/mse 0.1041 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/507 batches | lr 0.0000 | ms/batch 397.84 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  10 | 200/507 batches | lr 0.0000 | ms/batch 393.64 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  10 | 300/507 batches | lr 0.0000 | ms/batch 393.66 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  10 | 400/507 batches | lr 0.0000 | ms/batch 393.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 500/507 batches | lr 0.0000 | ms/batch 393.92 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 219.76s | valid loss/mse 0.1048 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 10
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396858/scgpt/split4
scGPT - INFO - Running on 2024-07-26 16:06:46
scGPT - INFO - match 3727/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/619 batches | lr 0.0001 | ms/batch 398.95 | loss  0.17 | mse  0.17 |
scGPT - INFO - | epoch   1 | 200/619 batches | lr 0.0001 | ms/batch 393.96 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/619 batches | lr 0.0001 | ms/batch 393.89 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/619 batches | lr 0.0001 | ms/batch 393.55 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/619 batches | lr 0.0001 | ms/batch 393.61 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 600/619 batches | lr 0.0001 | ms/batch 393.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 261.16s | valid loss/mse 0.1003 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1003
scGPT - INFO - | epoch   2 | 100/619 batches | lr 0.0001 | ms/batch 397.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/619 batches | lr 0.0001 | ms/batch 393.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/619 batches | lr 0.0001 | ms/batch 393.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/619 batches | lr 0.0001 | ms/batch 393.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/619 batches | lr 0.0001 | ms/batch 394.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 600/619 batches | lr 0.0001 | ms/batch 393.89 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 261.01s | valid loss/mse 0.0977 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0977
scGPT - INFO - | epoch   3 | 100/619 batches | lr 0.0001 | ms/batch 397.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/619 batches | lr 0.0001 | ms/batch 393.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/619 batches | lr 0.0001 | ms/batch 393.71 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/619 batches | lr 0.0001 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/619 batches | lr 0.0001 | ms/batch 393.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 600/619 batches | lr 0.0001 | ms/batch 394.26 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 260.96s | valid loss/mse 0.0992 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/619 batches | lr 0.0001 | ms/batch 397.86 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/619 batches | lr 0.0001 | ms/batch 393.73 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/619 batches | lr 0.0001 | ms/batch 394.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 400/619 batches | lr 0.0001 | ms/batch 394.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/619 batches | lr 0.0001 | ms/batch 394.04 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 600/619 batches | lr 0.0001 | ms/batch 393.99 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 261.05s | valid loss/mse 0.0976 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0976
scGPT - INFO - | epoch   5 | 100/619 batches | lr 0.0001 | ms/batch 398.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/619 batches | lr 0.0001 | ms/batch 393.68 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/619 batches | lr 0.0001 | ms/batch 393.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 400/619 batches | lr 0.0001 | ms/batch 393.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/619 batches | lr 0.0001 | ms/batch 394.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 600/619 batches | lr 0.0001 | ms/batch 393.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 260.96s | valid loss/mse 0.0973 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0973
scGPT - INFO - | epoch   6 | 100/619 batches | lr 0.0001 | ms/batch 397.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/619 batches | lr 0.0001 | ms/batch 393.63 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/619 batches | lr 0.0001 | ms/batch 393.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/619 batches | lr 0.0001 | ms/batch 394.37 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/619 batches | lr 0.0001 | ms/batch 394.42 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 600/619 batches | lr 0.0001 | ms/batch 394.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 261.13s | valid loss/mse 0.1017 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/619 batches | lr 0.0001 | ms/batch 397.82 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/619 batches | lr 0.0001 | ms/batch 393.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/619 batches | lr 0.0001 | ms/batch 393.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/619 batches | lr 0.0001 | ms/batch 394.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/619 batches | lr 0.0001 | ms/batch 393.99 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 600/619 batches | lr 0.0001 | ms/batch 394.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 261.03s | valid loss/mse 0.0976 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/619 batches | lr 0.0000 | ms/batch 398.00 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/619 batches | lr 0.0000 | ms/batch 394.07 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/619 batches | lr 0.0000 | ms/batch 394.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 400/619 batches | lr 0.0000 | ms/batch 394.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 500/619 batches | lr 0.0000 | ms/batch 394.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 600/619 batches | lr 0.0000 | ms/batch 394.11 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 261.16s | valid loss/mse 0.0963 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0963
scGPT - INFO - | epoch   9 | 100/619 batches | lr 0.0000 | ms/batch 397.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/619 batches | lr 0.0000 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/619 batches | lr 0.0000 | ms/batch 393.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 400/619 batches | lr 0.0000 | ms/batch 393.90 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 500/619 batches | lr 0.0000 | ms/batch 393.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 600/619 batches | lr 0.0000 | ms/batch 394.05 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 260.98s | valid loss/mse 0.0953 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0953
scGPT - INFO - | epoch  10 | 100/619 batches | lr 0.0000 | ms/batch 397.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/619 batches | lr 0.0000 | ms/batch 393.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/619 batches | lr 0.0000 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 400/619 batches | lr 0.0000 | ms/batch 393.89 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 500/619 batches | lr 0.0000 | ms/batch 393.86 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 600/619 batches | lr 0.0000 | ms/batch 394.01 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 260.93s | valid loss/mse 0.0965 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/619 batches | lr 0.0000 | ms/batch 397.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/619 batches | lr 0.0000 | ms/batch 394.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/619 batches | lr 0.0000 | ms/batch 393.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 400/619 batches | lr 0.0000 | ms/batch 393.93 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 500/619 batches | lr 0.0000 | ms/batch 393.82 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 600/619 batches | lr 0.0000 | ms/batch 393.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 261.02s | valid loss/mse 0.0987 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/619 batches | lr 0.0000 | ms/batch 397.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/619 batches | lr 0.0000 | ms/batch 393.92 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/619 batches | lr 0.0000 | ms/batch 394.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 400/619 batches | lr 0.0000 | ms/batch 393.89 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 500/619 batches | lr 0.0000 | ms/batch 394.11 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 600/619 batches | lr 0.0000 | ms/batch 394.05 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 261.07s | valid loss/mse 0.0978 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/619 batches | lr 0.0000 | ms/batch 397.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/619 batches | lr 0.0000 | ms/batch 393.88 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 300/619 batches | lr 0.0000 | ms/batch 393.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 400/619 batches | lr 0.0000 | ms/batch 394.00 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 500/619 batches | lr 0.0000 | ms/batch 394.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 600/619 batches | lr 0.0000 | ms/batch 393.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 260.97s | valid loss/mse 0.0995 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/619 batches | lr 0.0000 | ms/batch 397.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 200/619 batches | lr 0.0000 | ms/batch 393.99 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 300/619 batches | lr 0.0000 | ms/batch 393.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 400/619 batches | lr 0.0000 | ms/batch 394.16 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 500/619 batches | lr 0.0000 | ms/batch 393.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 600/619 batches | lr 0.0000 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 261.04s | valid loss/mse 0.0988 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 14
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396858/scgpt/split5
scGPT - INFO - Running on 2024-07-26 17:11:31
scGPT - INFO - match 3727/5008 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/529 batches | lr 0.0001 | ms/batch 401.17 | loss  0.16 | mse  0.16 |
scGPT - INFO - | epoch   1 | 200/529 batches | lr 0.0001 | ms/batch 394.07 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/529 batches | lr 0.0001 | ms/batch 393.89 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/529 batches | lr 0.0001 | ms/batch 393.99 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 500/529 batches | lr 0.0001 | ms/batch 393.99 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 228.99s | valid loss/mse 0.1058 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1058
scGPT - INFO - | epoch   2 | 100/529 batches | lr 0.0001 | ms/batch 397.87 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/529 batches | lr 0.0001 | ms/batch 394.06 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/529 batches | lr 0.0001 | ms/batch 393.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/529 batches | lr 0.0001 | ms/batch 393.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/529 batches | lr 0.0001 | ms/batch 394.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 228.60s | valid loss/mse 0.1018 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1018
scGPT - INFO - | epoch   3 | 100/529 batches | lr 0.0001 | ms/batch 398.32 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/529 batches | lr 0.0001 | ms/batch 398.01 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/529 batches | lr 0.0001 | ms/batch 394.20 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/529 batches | lr 0.0001 | ms/batch 393.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/529 batches | lr 0.0001 | ms/batch 394.04 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 228.97s | valid loss/mse 0.1114 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/529 batches | lr 0.0001 | ms/batch 398.04 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/529 batches | lr 0.0001 | ms/batch 394.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/529 batches | lr 0.0001 | ms/batch 394.25 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   4 | 400/529 batches | lr 0.0001 | ms/batch 394.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/529 batches | lr 0.0001 | ms/batch 393.96 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 228.63s | valid loss/mse 0.0996 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0996
scGPT - INFO - | epoch   5 | 100/529 batches | lr 0.0001 | ms/batch 398.56 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/529 batches | lr 0.0001 | ms/batch 394.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/529 batches | lr 0.0001 | ms/batch 394.10 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   5 | 400/529 batches | lr 0.0001 | ms/batch 394.01 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/529 batches | lr 0.0001 | ms/batch 394.24 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 228.67s | valid loss/mse 0.1025 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/529 batches | lr 0.0001 | ms/batch 397.87 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/529 batches | lr 0.0001 | ms/batch 394.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/529 batches | lr 0.0001 | ms/batch 394.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/529 batches | lr 0.0001 | ms/batch 394.11 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/529 batches | lr 0.0001 | ms/batch 394.15 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 228.63s | valid loss/mse 0.1058 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/529 batches | lr 0.0001 | ms/batch 397.89 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/529 batches | lr 0.0001 | ms/batch 393.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/529 batches | lr 0.0001 | ms/batch 394.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/529 batches | lr 0.0001 | ms/batch 394.08 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/529 batches | lr 0.0001 | ms/batch 394.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 228.65s | valid loss/mse 0.1038 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/529 batches | lr 0.0000 | ms/batch 398.50 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/529 batches | lr 0.0000 | ms/batch 394.17 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch   8 | 300/529 batches | lr 0.0000 | ms/batch 393.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 400/529 batches | lr 0.0000 | ms/batch 394.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 500/529 batches | lr 0.0000 | ms/batch 394.24 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 228.70s | valid loss/mse 0.1043 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/529 batches | lr 0.0000 | ms/batch 397.84 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/529 batches | lr 0.0000 | ms/batch 393.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/529 batches | lr 0.0000 | ms/batch 394.22 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 400/529 batches | lr 0.0000 | ms/batch 394.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 500/529 batches | lr 0.0000 | ms/batch 394.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 228.60s | valid loss/mse 0.0980 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0980
scGPT - INFO - | epoch  10 | 100/529 batches | lr 0.0000 | ms/batch 398.08 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  10 | 200/529 batches | lr 0.0000 | ms/batch 394.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/529 batches | lr 0.0000 | ms/batch 394.25 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 400/529 batches | lr 0.0000 | ms/batch 394.09 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 500/529 batches | lr 0.0000 | ms/batch 394.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 228.62s | valid loss/mse 0.1031 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/529 batches | lr 0.0000 | ms/batch 398.15 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/529 batches | lr 0.0000 | ms/batch 394.14 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  11 | 300/529 batches | lr 0.0000 | ms/batch 394.31 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 400/529 batches | lr 0.0000 | ms/batch 394.11 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 500/529 batches | lr 0.0000 | ms/batch 394.23 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 228.75s | valid loss/mse 0.1012 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/529 batches | lr 0.0000 | ms/batch 398.88 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/529 batches | lr 0.0000 | ms/batch 394.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/529 batches | lr 0.0000 | ms/batch 394.44 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  12 | 400/529 batches | lr 0.0000 | ms/batch 394.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 500/529 batches | lr 0.0000 | ms/batch 394.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 228.89s | valid loss/mse 0.1012 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/529 batches | lr 0.0000 | ms/batch 398.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/529 batches | lr 0.0000 | ms/batch 394.28 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  13 | 300/529 batches | lr 0.0000 | ms/batch 394.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 400/529 batches | lr 0.0000 | ms/batch 394.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 500/529 batches | lr 0.0000 | ms/batch 394.28 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 228.80s | valid loss/mse 0.1029 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/529 batches | lr 0.0000 | ms/batch 398.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 200/529 batches | lr 0.0000 | ms/batch 394.40 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 300/529 batches | lr 0.0000 | ms/batch 394.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 400/529 batches | lr 0.0000 | ms/batch 394.23 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  14 | 500/529 batches | lr 0.0000 | ms/batch 394.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 228.88s | valid loss/mse 0.1030 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 14
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396861/scgpt/split1
scGPT - INFO - Running on 2024-07-26 18:28:58
scGPT - INFO - match 3784/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/429 batches | lr 0.0001 | ms/batch 414.72 | loss  0.22 | mse  0.22 |
scGPT - INFO - | epoch   1 | 200/429 batches | lr 0.0001 | ms/batch 392.67 | loss  0.11 | mse  0.11 |
scGPT - INFO - | epoch   1 | 300/429 batches | lr 0.0001 | ms/batch 392.61 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 400/429 batches | lr 0.0001 | ms/batch 392.51 | loss  0.10 | mse  0.10 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 184.66s | valid loss/mse 0.1076 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1076
scGPT - INFO - | epoch   2 | 100/429 batches | lr 0.0001 | ms/batch 396.80 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 200/429 batches | lr 0.0001 | ms/batch 392.83 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 300/429 batches | lr 0.0001 | ms/batch 392.77 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 400/429 batches | lr 0.0001 | ms/batch 392.85 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 182.91s | valid loss/mse 0.1066 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1066
scGPT - INFO - | epoch   3 | 100/429 batches | lr 0.0001 | ms/batch 396.92 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 200/429 batches | lr 0.0001 | ms/batch 393.04 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 300/429 batches | lr 0.0001 | ms/batch 392.98 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 400/429 batches | lr 0.0001 | ms/batch 393.05 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 182.98s | valid loss/mse 0.1042 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1042
scGPT - INFO - | epoch   4 | 100/429 batches | lr 0.0001 | ms/batch 396.91 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 200/429 batches | lr 0.0001 | ms/batch 392.98 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 300/429 batches | lr 0.0001 | ms/batch 392.69 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 400/429 batches | lr 0.0001 | ms/batch 392.59 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 182.90s | valid loss/mse 0.1029 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1029
scGPT - INFO - | epoch   5 | 100/429 batches | lr 0.0001 | ms/batch 396.67 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 200/429 batches | lr 0.0001 | ms/batch 392.76 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 300/429 batches | lr 0.0001 | ms/batch 392.92 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 400/429 batches | lr 0.0001 | ms/batch 392.74 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 182.86s | valid loss/mse 0.1046 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/429 batches | lr 0.0001 | ms/batch 397.69 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 200/429 batches | lr 0.0001 | ms/batch 392.80 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 300/429 batches | lr 0.0001 | ms/batch 392.65 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 400/429 batches | lr 0.0001 | ms/batch 392.69 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 182.97s | valid loss/mse 0.1032 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/429 batches | lr 0.0001 | ms/batch 396.65 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 200/429 batches | lr 0.0001 | ms/batch 392.65 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 300/429 batches | lr 0.0001 | ms/batch 392.80 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 400/429 batches | lr 0.0001 | ms/batch 392.81 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 182.87s | valid loss/mse 0.1052 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/429 batches | lr 0.0000 | ms/batch 396.87 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 200/429 batches | lr 0.0000 | ms/batch 392.93 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 300/429 batches | lr 0.0000 | ms/batch 392.94 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 400/429 batches | lr 0.0000 | ms/batch 392.93 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 182.94s | valid loss/mse 0.1070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/429 batches | lr 0.0000 | ms/batch 396.93 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   9 | 200/429 batches | lr 0.0000 | ms/batch 392.90 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   9 | 300/429 batches | lr 0.0000 | ms/batch 392.70 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   9 | 400/429 batches | lr 0.0000 | ms/batch 392.60 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 182.88s | valid loss/mse 0.1041 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 9
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396861/scgpt/split2
scGPT - INFO - Running on 2024-07-26 19:05:50
scGPT - INFO - match 3784/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/460 batches | lr 0.0001 | ms/batch 397.68 | loss  0.26 | mse  0.26 |
scGPT - INFO - | epoch   1 | 200/460 batches | lr 0.0001 | ms/batch 393.11 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 300/460 batches | lr 0.0001 | ms/batch 392.68 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 400/460 batches | lr 0.0001 | ms/batch 392.87 | loss  0.10 | mse  0.10 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 184.07s | valid loss/mse 0.1086 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1086
scGPT - INFO - | epoch   2 | 100/460 batches | lr 0.0001 | ms/batch 396.82 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 200/460 batches | lr 0.0001 | ms/batch 392.96 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 300/460 batches | lr 0.0001 | ms/batch 393.08 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 400/460 batches | lr 0.0001 | ms/batch 393.04 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 183.98s | valid loss/mse 0.1059 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1059
scGPT - INFO - | epoch   3 | 100/460 batches | lr 0.0001 | ms/batch 396.98 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 200/460 batches | lr 0.0001 | ms/batch 393.22 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 300/460 batches | lr 0.0001 | ms/batch 393.14 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 400/460 batches | lr 0.0001 | ms/batch 393.18 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 184.04s | valid loss/mse 0.1072 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/460 batches | lr 0.0001 | ms/batch 396.79 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 200/460 batches | lr 0.0001 | ms/batch 392.64 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 300/460 batches | lr 0.0001 | ms/batch 393.02 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 400/460 batches | lr 0.0001 | ms/batch 392.86 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 183.91s | valid loss/mse 0.1074 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/460 batches | lr 0.0001 | ms/batch 397.09 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 200/460 batches | lr 0.0001 | ms/batch 393.15 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 300/460 batches | lr 0.0001 | ms/batch 393.17 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 400/460 batches | lr 0.0001 | ms/batch 393.14 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 184.06s | valid loss/mse 0.1085 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/460 batches | lr 0.0001 | ms/batch 397.21 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 200/460 batches | lr 0.0001 | ms/batch 393.22 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 300/460 batches | lr 0.0001 | ms/batch 393.21 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 400/460 batches | lr 0.0001 | ms/batch 393.13 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 184.08s | valid loss/mse 0.1069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/460 batches | lr 0.0001 | ms/batch 397.07 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 200/460 batches | lr 0.0001 | ms/batch 393.15 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 300/460 batches | lr 0.0001 | ms/batch 393.19 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 400/460 batches | lr 0.0001 | ms/batch 393.17 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 184.05s | valid loss/mse 0.1107 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396861/scgpt/split3
scGPT - INFO - Running on 2024-07-26 19:39:26
scGPT - INFO - match 3784/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/440 batches | lr 0.0001 | ms/batch 398.00 | loss  0.26 | mse  0.26 |
scGPT - INFO - | epoch   1 | 200/440 batches | lr 0.0001 | ms/batch 393.06 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 300/440 batches | lr 0.0001 | ms/batch 393.04 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 400/440 batches | lr 0.0001 | ms/batch 393.03 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 175.53s | valid loss/mse 0.1074 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1074
scGPT - INFO - | epoch   2 | 100/440 batches | lr 0.0001 | ms/batch 397.13 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   2 | 200/440 batches | lr 0.0001 | ms/batch 393.13 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 300/440 batches | lr 0.0001 | ms/batch 393.34 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 400/440 batches | lr 0.0001 | ms/batch 393.26 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 175.44s | valid loss/mse 0.1062 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1062
scGPT - INFO - | epoch   3 | 100/440 batches | lr 0.0001 | ms/batch 397.06 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 200/440 batches | lr 0.0001 | ms/batch 393.09 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 300/440 batches | lr 0.0001 | ms/batch 393.24 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 400/440 batches | lr 0.0001 | ms/batch 393.35 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 175.43s | valid loss/mse 0.1057 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1057
scGPT - INFO - | epoch   4 | 100/440 batches | lr 0.0001 | ms/batch 397.64 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 200/440 batches | lr 0.0001 | ms/batch 393.32 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 300/440 batches | lr 0.0001 | ms/batch 393.32 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 400/440 batches | lr 0.0001 | ms/batch 393.35 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 175.53s | valid loss/mse 0.1063 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/440 batches | lr 0.0001 | ms/batch 397.31 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 200/440 batches | lr 0.0001 | ms/batch 393.55 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 300/440 batches | lr 0.0001 | ms/batch 393.38 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 400/440 batches | lr 0.0001 | ms/batch 393.39 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 175.53s | valid loss/mse 0.1066 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/440 batches | lr 0.0001 | ms/batch 397.24 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 200/440 batches | lr 0.0001 | ms/batch 393.26 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 300/440 batches | lr 0.0001 | ms/batch 393.23 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 400/440 batches | lr 0.0001 | ms/batch 393.20 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 175.45s | valid loss/mse 0.1084 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/440 batches | lr 0.0001 | ms/batch 397.33 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 200/440 batches | lr 0.0001 | ms/batch 393.23 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 300/440 batches | lr 0.0001 | ms/batch 393.35 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 400/440 batches | lr 0.0001 | ms/batch 393.13 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 175.47s | valid loss/mse 0.1061 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/440 batches | lr 0.0000 | ms/batch 397.19 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 200/440 batches | lr 0.0000 | ms/batch 393.17 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 300/440 batches | lr 0.0000 | ms/batch 393.19 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 400/440 batches | lr 0.0000 | ms/batch 393.06 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 175.42s | valid loss/mse 0.1057 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 8
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396861/scgpt/split4
scGPT - INFO - Running on 2024-07-26 20:16:49
scGPT - INFO - match 3784/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/425 batches | lr 0.0001 | ms/batch 398.14 | loss  0.27 | mse  0.27 |
scGPT - INFO - | epoch   1 | 200/425 batches | lr 0.0001 | ms/batch 393.44 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 300/425 batches | lr 0.0001 | ms/batch 393.33 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   1 | 400/425 batches | lr 0.0001 | ms/batch 393.47 | loss  0.10 | mse  0.10 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 170.54s | valid loss/mse 0.1087 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1087
scGPT - INFO - | epoch   2 | 100/425 batches | lr 0.0001 | ms/batch 397.42 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   2 | 200/425 batches | lr 0.0001 | ms/batch 393.54 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   2 | 300/425 batches | lr 0.0001 | ms/batch 393.46 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 400/425 batches | lr 0.0001 | ms/batch 393.88 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 170.49s | valid loss/mse 0.1073 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1073
scGPT - INFO - | epoch   3 | 100/425 batches | lr 0.0001 | ms/batch 397.58 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 200/425 batches | lr 0.0001 | ms/batch 393.68 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 300/425 batches | lr 0.0001 | ms/batch 393.59 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 400/425 batches | lr 0.0001 | ms/batch 393.62 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 170.49s | valid loss/mse 0.1071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1071
scGPT - INFO - | epoch   4 | 100/425 batches | lr 0.0001 | ms/batch 397.98 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 200/425 batches | lr 0.0001 | ms/batch 393.63 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 300/425 batches | lr 0.0001 | ms/batch 393.55 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 400/425 batches | lr 0.0001 | ms/batch 393.52 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 170.51s | valid loss/mse 0.1142 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/425 batches | lr 0.0001 | ms/batch 397.49 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 200/425 batches | lr 0.0001 | ms/batch 393.57 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 300/425 batches | lr 0.0001 | ms/batch 393.55 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 400/425 batches | lr 0.0001 | ms/batch 393.40 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 170.43s | valid loss/mse 0.1071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/425 batches | lr 0.0001 | ms/batch 397.47 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 200/425 batches | lr 0.0001 | ms/batch 393.55 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 300/425 batches | lr 0.0001 | ms/batch 393.57 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 400/425 batches | lr 0.0001 | ms/batch 393.54 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 170.45s | valid loss/mse 0.1080 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/425 batches | lr 0.0001 | ms/batch 397.52 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 200/425 batches | lr 0.0001 | ms/batch 393.37 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 300/425 batches | lr 0.0001 | ms/batch 393.56 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 400/425 batches | lr 0.0001 | ms/batch 393.08 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 170.39s | valid loss/mse 0.1098 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/425 batches | lr 0.0000 | ms/batch 397.52 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 200/425 batches | lr 0.0000 | ms/batch 393.35 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 300/425 batches | lr 0.0000 | ms/batch 393.18 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 400/425 batches | lr 0.0000 | ms/batch 393.28 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 170.37s | valid loss/mse 0.1074 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 8
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/Dixit_GSM2396861/scgpt/split5
scGPT - INFO - Running on 2024-07-26 20:54:28
scGPT - INFO - match 3784/5007 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/396 batches | lr 0.0001 | ms/batch 398.81 | loss  0.20 | mse  0.20 |
scGPT - INFO - | epoch   1 | 200/396 batches | lr 0.0001 | ms/batch 393.29 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   1 | 300/396 batches | lr 0.0001 | ms/batch 393.75 | loss  0.10 | mse  0.10 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 163.10s | valid loss/mse 0.1075 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1075
scGPT - INFO - | epoch   2 | 100/396 batches | lr 0.0001 | ms/batch 397.36 | loss  0.10 | mse  0.10 |
scGPT - INFO - | epoch   2 | 200/396 batches | lr 0.0001 | ms/batch 393.34 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   2 | 300/396 batches | lr 0.0001 | ms/batch 393.35 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 162.85s | valid loss/mse 0.1065 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1065
scGPT - INFO - | epoch   3 | 100/396 batches | lr 0.0001 | ms/batch 397.48 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 200/396 batches | lr 0.0001 | ms/batch 393.46 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   3 | 300/396 batches | lr 0.0001 | ms/batch 393.63 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 162.95s | valid loss/mse 0.1063 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1063
scGPT - INFO - | epoch   4 | 100/396 batches | lr 0.0001 | ms/batch 398.10 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 200/396 batches | lr 0.0001 | ms/batch 393.00 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   4 | 300/396 batches | lr 0.0001 | ms/batch 393.28 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 162.90s | valid loss/mse 0.1059 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1059
scGPT - INFO - | epoch   5 | 100/396 batches | lr 0.0001 | ms/batch 397.22 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 200/396 batches | lr 0.0001 | ms/batch 393.35 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   5 | 300/396 batches | lr 0.0001 | ms/batch 393.71 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 162.90s | valid loss/mse 0.1074 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/396 batches | lr 0.0001 | ms/batch 397.54 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 200/396 batches | lr 0.0001 | ms/batch 393.62 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   6 | 300/396 batches | lr 0.0001 | ms/batch 393.55 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 162.96s | valid loss/mse 0.1078 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/396 batches | lr 0.0001 | ms/batch 397.39 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 200/396 batches | lr 0.0001 | ms/batch 393.32 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   7 | 300/396 batches | lr 0.0001 | ms/batch 393.24 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 162.85s | valid loss/mse 0.1071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/396 batches | lr 0.0000 | ms/batch 397.60 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 200/396 batches | lr 0.0000 | ms/batch 393.43 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   8 | 300/396 batches | lr 0.0000 | ms/batch 393.47 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 162.90s | valid loss/mse 0.1069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/396 batches | lr 0.0000 | ms/batch 397.42 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   9 | 200/396 batches | lr 0.0000 | ms/batch 393.68 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch   9 | 300/396 batches | lr 0.0000 | ms/batch 393.71 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 162.95s | valid loss/mse 0.1051 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1051
scGPT - INFO - | epoch  10 | 100/396 batches | lr 0.0000 | ms/batch 397.53 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  10 | 200/396 batches | lr 0.0000 | ms/batch 393.47 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  10 | 300/396 batches | lr 0.0000 | ms/batch 393.49 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 162.92s | valid loss/mse 0.1050 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.1050
scGPT - INFO - | epoch  11 | 100/396 batches | lr 0.0000 | ms/batch 397.63 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  11 | 200/396 batches | lr 0.0000 | ms/batch 393.61 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  11 | 300/396 batches | lr 0.0000 | ms/batch 393.67 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 162.95s | valid loss/mse 0.1062 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/396 batches | lr 0.0000 | ms/batch 397.52 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  12 | 200/396 batches | lr 0.0000 | ms/batch 393.70 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  12 | 300/396 batches | lr 0.0000 | ms/batch 393.46 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 162.95s | valid loss/mse 0.1053 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/396 batches | lr 0.0000 | ms/batch 397.56 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  13 | 200/396 batches | lr 0.0000 | ms/batch 393.62 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  13 | 300/396 batches | lr 0.0000 | ms/batch 393.63 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 162.93s | valid loss/mse 0.1060 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/396 batches | lr 0.0000 | ms/batch 397.47 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  14 | 200/396 batches | lr 0.0000 | ms/batch 393.48 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  14 | 300/396 batches | lr 0.0000 | ms/batch 393.47 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 162.86s | valid loss/mse 0.1065 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/396 batches | lr 0.0000 | ms/batch 397.84 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  15 | 200/396 batches | lr 0.0000 | ms/batch 393.29 | loss  0.09 | mse  0.09 |
scGPT - INFO - | epoch  15 | 300/396 batches | lr 0.0000 | ms/batch 393.51 | loss  0.09 | mse  0.09 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 162.94s | valid loss/mse 0.1075 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 15
---Creating test_res
test_res saved successfully----
Split5 computation completed
