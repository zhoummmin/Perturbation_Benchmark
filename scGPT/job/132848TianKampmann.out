环境设置完成！
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_day7neuron/scgpt/split1
scGPT - INFO - Running on 2024-07-26 08:46:34
scGPT - INFO - match 4455/5016 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/569 batches | lr 0.0001 | ms/batch 374.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 200/569 batches | lr 0.0001 | ms/batch 357.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/569 batches | lr 0.0001 | ms/batch 357.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/569 batches | lr 0.0001 | ms/batch 357.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/569 batches | lr 0.0001 | ms/batch 357.93 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 207.95s | valid loss/mse 0.0085 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0085
scGPT - INFO - | epoch   2 | 100/569 batches | lr 0.0001 | ms/batch 361.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/569 batches | lr 0.0001 | ms/batch 358.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/569 batches | lr 0.0001 | ms/batch 358.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/569 batches | lr 0.0001 | ms/batch 361.21 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/569 batches | lr 0.0001 | ms/batch 358.65 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 207.38s | valid loss/mse 0.0084 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0084
scGPT - INFO - | epoch   3 | 100/569 batches | lr 0.0001 | ms/batch 363.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/569 batches | lr 0.0001 | ms/batch 359.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/569 batches | lr 0.0001 | ms/batch 360.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/569 batches | lr 0.0001 | ms/batch 360.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/569 batches | lr 0.0001 | ms/batch 360.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 208.07s | valid loss/mse 0.0087 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/569 batches | lr 0.0001 | ms/batch 364.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/569 batches | lr 0.0001 | ms/batch 360.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/569 batches | lr 0.0001 | ms/batch 361.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/569 batches | lr 0.0001 | ms/batch 362.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/569 batches | lr 0.0001 | ms/batch 361.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 208.75s | valid loss/mse 0.0085 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/569 batches | lr 0.0001 | ms/batch 364.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/569 batches | lr 0.0001 | ms/batch 361.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/569 batches | lr 0.0001 | ms/batch 361.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/569 batches | lr 0.0001 | ms/batch 363.32 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/569 batches | lr 0.0001 | ms/batch 362.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 209.15s | valid loss/mse 0.0084 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/569 batches | lr 0.0001 | ms/batch 365.55 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/569 batches | lr 0.0001 | ms/batch 361.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/569 batches | lr 0.0001 | ms/batch 361.74 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/569 batches | lr 0.0001 | ms/batch 361.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/569 batches | lr 0.0001 | ms/batch 361.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 208.86s | valid loss/mse 0.0084 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/569 batches | lr 0.0001 | ms/batch 369.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/569 batches | lr 0.0001 | ms/batch 362.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/569 batches | lr 0.0001 | ms/batch 362.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/569 batches | lr 0.0001 | ms/batch 362.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/569 batches | lr 0.0001 | ms/batch 361.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 209.83s | valid loss/mse 0.0091 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_day7neuron/scgpt/split2
scGPT - INFO - Running on 2024-07-26 09:23:58
scGPT - INFO - match 4455/5016 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/494 batches | lr 0.0001 | ms/batch 365.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 200/494 batches | lr 0.0001 | ms/batch 357.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/494 batches | lr 0.0001 | ms/batch 358.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/494 batches | lr 0.0001 | ms/batch 358.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 217.09s | valid loss/mse 0.0092 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0092
scGPT - INFO - | epoch   2 | 100/494 batches | lr 0.0001 | ms/batch 363.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/494 batches | lr 0.0001 | ms/batch 359.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/494 batches | lr 0.0001 | ms/batch 359.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/494 batches | lr 0.0001 | ms/batch 359.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 217.45s | valid loss/mse 0.0090 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0090
scGPT - INFO - | epoch   3 | 100/494 batches | lr 0.0001 | ms/batch 363.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/494 batches | lr 0.0001 | ms/batch 360.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/494 batches | lr 0.0001 | ms/batch 361.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/494 batches | lr 0.0001 | ms/batch 361.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 218.76s | valid loss/mse 0.0097 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/494 batches | lr 0.0001 | ms/batch 366.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/494 batches | lr 0.0001 | ms/batch 362.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/494 batches | lr 0.0001 | ms/batch 361.16 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/494 batches | lr 0.0001 | ms/batch 362.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 219.49s | valid loss/mse 0.0094 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/494 batches | lr 0.0001 | ms/batch 367.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/494 batches | lr 0.0001 | ms/batch 363.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/494 batches | lr 0.0001 | ms/batch 364.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/494 batches | lr 0.0001 | ms/batch 365.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 220.63s | valid loss/mse 0.0107 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/494 batches | lr 0.0001 | ms/batch 365.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/494 batches | lr 0.0001 | ms/batch 361.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/494 batches | lr 0.0001 | ms/batch 362.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/494 batches | lr 0.0001 | ms/batch 362.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 219.26s | valid loss/mse 0.0089 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0089
scGPT - INFO - | epoch   7 | 100/494 batches | lr 0.0001 | ms/batch 364.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/494 batches | lr 0.0001 | ms/batch 363.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/494 batches | lr 0.0001 | ms/batch 362.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/494 batches | lr 0.0001 | ms/batch 362.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 219.39s | valid loss/mse 0.0099 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/494 batches | lr 0.0000 | ms/batch 366.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/494 batches | lr 0.0000 | ms/batch 363.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/494 batches | lr 0.0000 | ms/batch 363.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 400/494 batches | lr 0.0000 | ms/batch 363.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 220.47s | valid loss/mse 0.0095 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/494 batches | lr 0.0000 | ms/batch 367.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 200/494 batches | lr 0.0000 | ms/batch 363.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 300/494 batches | lr 0.0000 | ms/batch 363.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 400/494 batches | lr 0.0000 | ms/batch 363.90 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 220.47s | valid loss/mse 0.0092 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/494 batches | lr 0.0000 | ms/batch 366.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 200/494 batches | lr 0.0000 | ms/batch 363.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 300/494 batches | lr 0.0000 | ms/batch 362.18 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 400/494 batches | lr 0.0000 | ms/batch 361.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 219.17s | valid loss/mse 0.0092 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/494 batches | lr 0.0000 | ms/batch 364.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 200/494 batches | lr 0.0000 | ms/batch 360.56 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 300/494 batches | lr 0.0000 | ms/batch 360.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 400/494 batches | lr 0.0000 | ms/batch 360.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 218.19s | valid loss/mse 0.0092 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 11
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_day7neuron/scgpt/split3
scGPT - INFO - Running on 2024-07-26 10:13:30
scGPT - INFO - match 4455/5016 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/804 batches | lr 0.0001 | ms/batch 361.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 200/804 batches | lr 0.0001 | ms/batch 358.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/804 batches | lr 0.0001 | ms/batch 358.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/804 batches | lr 0.0001 | ms/batch 358.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/804 batches | lr 0.0001 | ms/batch 360.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/804 batches | lr 0.0001 | ms/batch 361.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/804 batches | lr 0.0001 | ms/batch 360.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 800/804 batches | lr 0.0001 | ms/batch 363.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 293.21s | valid loss/mse 0.0088 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0088
scGPT - INFO - | epoch   2 | 100/804 batches | lr 0.0001 | ms/batch 365.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/804 batches | lr 0.0001 | ms/batch 361.73 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/804 batches | lr 0.0001 | ms/batch 362.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/804 batches | lr 0.0001 | ms/batch 362.74 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/804 batches | lr 0.0001 | ms/batch 363.15 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/804 batches | lr 0.0001 | ms/batch 363.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/804 batches | lr 0.0001 | ms/batch 363.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 800/804 batches | lr 0.0001 | ms/batch 363.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 295.49s | valid loss/mse 0.0083 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0083
scGPT - INFO - | epoch   3 | 100/804 batches | lr 0.0001 | ms/batch 366.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/804 batches | lr 0.0001 | ms/batch 362.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/804 batches | lr 0.0001 | ms/batch 362.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/804 batches | lr 0.0001 | ms/batch 361.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/804 batches | lr 0.0001 | ms/batch 362.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/804 batches | lr 0.0001 | ms/batch 362.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/804 batches | lr 0.0001 | ms/batch 362.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 800/804 batches | lr 0.0001 | ms/batch 362.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 295.05s | valid loss/mse 0.0086 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/804 batches | lr 0.0001 | ms/batch 365.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/804 batches | lr 0.0001 | ms/batch 361.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/804 batches | lr 0.0001 | ms/batch 359.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/804 batches | lr 0.0001 | ms/batch 359.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/804 batches | lr 0.0001 | ms/batch 357.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/804 batches | lr 0.0001 | ms/batch 356.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/804 batches | lr 0.0001 | ms/batch 356.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 800/804 batches | lr 0.0001 | ms/batch 356.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 291.98s | valid loss/mse 0.0112 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/804 batches | lr 0.0001 | ms/batch 359.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/804 batches | lr 0.0001 | ms/batch 356.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/804 batches | lr 0.0001 | ms/batch 356.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/804 batches | lr 0.0001 | ms/batch 356.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/804 batches | lr 0.0001 | ms/batch 356.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/804 batches | lr 0.0001 | ms/batch 356.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/804 batches | lr 0.0001 | ms/batch 356.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 800/804 batches | lr 0.0001 | ms/batch 356.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 290.12s | valid loss/mse 0.0115 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/804 batches | lr 0.0001 | ms/batch 359.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/804 batches | lr 0.0001 | ms/batch 356.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/804 batches | lr 0.0001 | ms/batch 356.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/804 batches | lr 0.0001 | ms/batch 356.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/804 batches | lr 0.0001 | ms/batch 356.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/804 batches | lr 0.0001 | ms/batch 356.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/804 batches | lr 0.0001 | ms/batch 356.55 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 800/804 batches | lr 0.0001 | ms/batch 356.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 290.12s | valid loss/mse 0.0112 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/804 batches | lr 0.0001 | ms/batch 360.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/804 batches | lr 0.0001 | ms/batch 356.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/804 batches | lr 0.0001 | ms/batch 357.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/804 batches | lr 0.0001 | ms/batch 357.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/804 batches | lr 0.0001 | ms/batch 356.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 600/804 batches | lr 0.0001 | ms/batch 356.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 700/804 batches | lr 0.0001 | ms/batch 356.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 800/804 batches | lr 0.0001 | ms/batch 356.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 290.25s | valid loss/mse 0.0114 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_day7neuron/scgpt/split4
scGPT - INFO - Running on 2024-07-26 10:55:32
scGPT - INFO - match 4455/5016 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/630 batches | lr 0.0001 | ms/batch 364.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 200/630 batches | lr 0.0001 | ms/batch 358.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/630 batches | lr 0.0001 | ms/batch 360.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/630 batches | lr 0.0001 | ms/batch 360.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/630 batches | lr 0.0001 | ms/batch 359.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/630 batches | lr 0.0001 | ms/batch 360.85 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 235.06s | valid loss/mse 0.0089 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0089
scGPT - INFO - | epoch   2 | 100/630 batches | lr 0.0001 | ms/batch 364.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/630 batches | lr 0.0001 | ms/batch 360.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/630 batches | lr 0.0001 | ms/batch 361.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/630 batches | lr 0.0001 | ms/batch 361.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/630 batches | lr 0.0001 | ms/batch 361.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/630 batches | lr 0.0001 | ms/batch 361.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 235.59s | valid loss/mse 0.0090 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/630 batches | lr 0.0001 | ms/batch 365.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/630 batches | lr 0.0001 | ms/batch 361.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/630 batches | lr 0.0001 | ms/batch 362.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/630 batches | lr 0.0001 | ms/batch 362.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/630 batches | lr 0.0001 | ms/batch 361.77 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/630 batches | lr 0.0001 | ms/batch 362.60 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 236.28s | valid loss/mse 0.0091 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/630 batches | lr 0.0001 | ms/batch 366.80 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/630 batches | lr 0.0001 | ms/batch 362.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/630 batches | lr 0.0001 | ms/batch 362.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/630 batches | lr 0.0001 | ms/batch 361.98 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/630 batches | lr 0.0001 | ms/batch 362.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/630 batches | lr 0.0001 | ms/batch 363.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 236.69s | valid loss/mse 0.0091 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/630 batches | lr 0.0001 | ms/batch 366.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/630 batches | lr 0.0001 | ms/batch 361.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/630 batches | lr 0.0001 | ms/batch 362.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/630 batches | lr 0.0001 | ms/batch 361.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/630 batches | lr 0.0001 | ms/batch 363.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/630 batches | lr 0.0001 | ms/batch 363.98 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 236.79s | valid loss/mse 0.0089 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0089
scGPT - INFO - | epoch   6 | 100/630 batches | lr 0.0001 | ms/batch 367.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/630 batches | lr 0.0001 | ms/batch 364.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/630 batches | lr 0.0001 | ms/batch 363.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/630 batches | lr 0.0001 | ms/batch 360.44 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 500/630 batches | lr 0.0001 | ms/batch 356.26 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 600/630 batches | lr 0.0001 | ms/batch 356.23 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 235.40s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/630 batches | lr 0.0001 | ms/batch 359.75 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 200/630 batches | lr 0.0001 | ms/batch 356.25 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 300/630 batches | lr 0.0001 | ms/batch 356.13 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 400/630 batches | lr 0.0001 | ms/batch 356.11 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 500/630 batches | lr 0.0001 | ms/batch 356.03 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 600/630 batches | lr 0.0001 | ms/batch 355.83 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 232.57s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/630 batches | lr 0.0000 | ms/batch 359.73 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 200/630 batches | lr 0.0000 | ms/batch 356.23 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 300/630 batches | lr 0.0000 | ms/batch 356.34 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 400/630 batches | lr 0.0000 | ms/batch 356.25 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 500/630 batches | lr 0.0000 | ms/batch 356.64 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 600/630 batches | lr 0.0000 | ms/batch 356.19 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 232.70s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/630 batches | lr 0.0000 | ms/batch 359.82 | loss   nan | mse   nan |
scGPT - INFO - | epoch   9 | 200/630 batches | lr 0.0000 | ms/batch 356.15 | loss   nan | mse   nan |
scGPT - INFO - | epoch   9 | 300/630 batches | lr 0.0000 | ms/batch 356.39 | loss   nan | mse   nan |
scGPT - INFO - | epoch   9 | 400/630 batches | lr 0.0000 | ms/batch 356.26 | loss   nan | mse   nan |
scGPT - INFO - | epoch   9 | 500/630 batches | lr 0.0000 | ms/batch 356.29 | loss   nan | mse   nan |
scGPT - INFO - | epoch   9 | 600/630 batches | lr 0.0000 | ms/batch 356.33 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 232.68s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/630 batches | lr 0.0000 | ms/batch 359.76 | loss   nan | mse   nan |
scGPT - INFO - | epoch  10 | 200/630 batches | lr 0.0000 | ms/batch 356.22 | loss   nan | mse   nan |
scGPT - INFO - | epoch  10 | 300/630 batches | lr 0.0000 | ms/batch 356.18 | loss   nan | mse   nan |
scGPT - INFO - | epoch  10 | 400/630 batches | lr 0.0000 | ms/batch 356.23 | loss   nan | mse   nan |
scGPT - INFO - | epoch  10 | 500/630 batches | lr 0.0000 | ms/batch 356.01 | loss   nan | mse   nan |
scGPT - INFO - | epoch  10 | 600/630 batches | lr 0.0000 | ms/batch 356.12 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 232.60s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 10
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_day7neuron/scgpt/split5
scGPT - INFO - Running on 2024-07-26 11:45:53
scGPT - INFO - match 4455/5016 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/557 batches | lr 0.0001 | ms/batch 363.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 200/557 batches | lr 0.0001 | ms/batch 359.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/557 batches | lr 0.0001 | ms/batch 359.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/557 batches | lr 0.0001 | ms/batch 359.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/557 batches | lr 0.0001 | ms/batch 359.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 207.34s | valid loss/mse 0.0090 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0090
scGPT - INFO - | epoch   2 | 100/557 batches | lr 0.0001 | ms/batch 363.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/557 batches | lr 0.0001 | ms/batch 359.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/557 batches | lr 0.0001 | ms/batch 360.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/557 batches | lr 0.0001 | ms/batch 360.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/557 batches | lr 0.0001 | ms/batch 361.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 207.89s | valid loss/mse 0.0091 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/557 batches | lr 0.0001 | ms/batch 364.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/557 batches | lr 0.0001 | ms/batch 360.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/557 batches | lr 0.0001 | ms/batch 359.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/557 batches | lr 0.0001 | ms/batch 360.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/557 batches | lr 0.0001 | ms/batch 361.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 207.98s | valid loss/mse 0.0090 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0090
scGPT - INFO - | epoch   4 | 100/557 batches | lr 0.0001 | ms/batch 365.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/557 batches | lr 0.0001 | ms/batch 361.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/557 batches | lr 0.0001 | ms/batch 362.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/557 batches | lr 0.0001 | ms/batch 361.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/557 batches | lr 0.0001 | ms/batch 361.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 208.43s | valid loss/mse 0.0096 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/557 batches | lr 0.0001 | ms/batch 364.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/557 batches | lr 0.0001 | ms/batch 361.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/557 batches | lr 0.0001 | ms/batch 361.84 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/557 batches | lr 0.0001 | ms/batch 361.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/557 batches | lr 0.0001 | ms/batch 361.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 208.39s | valid loss/mse 0.0088 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0088
scGPT - INFO - | epoch   6 | 100/557 batches | lr 0.0001 | ms/batch 365.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/557 batches | lr 0.0001 | ms/batch 361.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/557 batches | lr 0.0001 | ms/batch 358.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/557 batches | lr 0.0001 | ms/batch 362.74 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/557 batches | lr 0.0001 | ms/batch 363.93 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 208.75s | valid loss/mse 0.0088 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/557 batches | lr 0.0001 | ms/batch 368.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/557 batches | lr 0.0001 | ms/batch 364.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/557 batches | lr 0.0001 | ms/batch 364.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/557 batches | lr 0.0001 | ms/batch 364.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/557 batches | lr 0.0001 | ms/batch 364.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 210.22s | valid loss/mse 0.0094 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/557 batches | lr 0.0000 | ms/batch 368.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/557 batches | lr 0.0000 | ms/batch 364.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/557 batches | lr 0.0000 | ms/batch 364.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 400/557 batches | lr 0.0000 | ms/batch 364.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 500/557 batches | lr 0.0000 | ms/batch 364.29 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 209.98s | valid loss/mse 0.0089 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/557 batches | lr 0.0000 | ms/batch 367.10 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 200/557 batches | lr 0.0000 | ms/batch 363.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 300/557 batches | lr 0.0000 | ms/batch 363.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 400/557 batches | lr 0.0000 | ms/batch 363.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 500/557 batches | lr 0.0000 | ms/batch 363.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 209.50s | valid loss/mse 0.0086 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0086
scGPT - INFO - | epoch  10 | 100/557 batches | lr 0.0000 | ms/batch 368.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 200/557 batches | lr 0.0000 | ms/batch 364.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 300/557 batches | lr 0.0000 | ms/batch 364.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 400/557 batches | lr 0.0000 | ms/batch 363.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 500/557 batches | lr 0.0000 | ms/batch 363.63 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 209.85s | valid loss/mse 0.0092 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/557 batches | lr 0.0000 | ms/batch 369.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 200/557 batches | lr 0.0000 | ms/batch 363.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 300/557 batches | lr 0.0000 | ms/batch 364.15 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 400/557 batches | lr 0.0000 | ms/batch 363.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 500/557 batches | lr 0.0000 | ms/batch 363.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 209.87s | valid loss/mse 0.0089 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/557 batches | lr 0.0000 | ms/batch 365.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 200/557 batches | lr 0.0000 | ms/batch 362.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 300/557 batches | lr 0.0000 | ms/batch 363.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 400/557 batches | lr 0.0000 | ms/batch 363.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 500/557 batches | lr 0.0000 | ms/batch 363.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 209.36s | valid loss/mse 0.0090 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/557 batches | lr 0.0000 | ms/batch 367.18 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 200/557 batches | lr 0.0000 | ms/batch 363.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 300/557 batches | lr 0.0000 | ms/batch 363.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 400/557 batches | lr 0.0000 | ms/batch 363.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 500/557 batches | lr 0.0000 | ms/batch 363.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 209.37s | valid loss/mse 0.0087 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/557 batches | lr 0.0000 | ms/batch 367.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 200/557 batches | lr 0.0000 | ms/batch 363.21 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 300/557 batches | lr 0.0000 | ms/batch 364.24 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 400/557 batches | lr 0.0000 | ms/batch 364.96 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  14 | 500/557 batches | lr 0.0000 | ms/batch 365.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 210.06s | valid loss/mse 0.0088 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 14
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_iPSC/scgpt/split1
scGPT - INFO - Running on 2024-07-26 13:01:42
scGPT - INFO - match 4538/5020 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/757 batches | lr 0.0001 | ms/batch 372.19 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 200/757 batches | lr 0.0001 | ms/batch 357.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 300/757 batches | lr 0.0001 | ms/batch 356.64 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 400/757 batches | lr 0.0001 | ms/batch 355.82 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 500/757 batches | lr 0.0001 | ms/batch 358.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/757 batches | lr 0.0001 | ms/batch 358.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/757 batches | lr 0.0001 | ms/batch 358.77 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 276.84s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0069
scGPT - INFO - | epoch   2 | 100/757 batches | lr 0.0001 | ms/batch 361.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/757 batches | lr 0.0001 | ms/batch 358.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/757 batches | lr 0.0001 | ms/batch 359.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/757 batches | lr 0.0001 | ms/batch 358.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/757 batches | lr 0.0001 | ms/batch 358.96 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/757 batches | lr 0.0001 | ms/batch 358.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/757 batches | lr 0.0001 | ms/batch 358.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 276.59s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/757 batches | lr 0.0001 | ms/batch 362.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/757 batches | lr 0.0001 | ms/batch 358.29 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/757 batches | lr 0.0001 | ms/batch 358.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/757 batches | lr 0.0001 | ms/batch 358.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/757 batches | lr 0.0001 | ms/batch 358.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/757 batches | lr 0.0001 | ms/batch 358.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/757 batches | lr 0.0001 | ms/batch 359.84 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 276.64s | valid loss/mse 0.0068 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0068
scGPT - INFO - | epoch   4 | 100/757 batches | lr 0.0001 | ms/batch 362.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/757 batches | lr 0.0001 | ms/batch 359.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/757 batches | lr 0.0001 | ms/batch 359.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/757 batches | lr 0.0001 | ms/batch 359.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/757 batches | lr 0.0001 | ms/batch 358.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/757 batches | lr 0.0001 | ms/batch 358.77 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/757 batches | lr 0.0001 | ms/batch 359.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 276.94s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/757 batches | lr 0.0001 | ms/batch 362.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/757 batches | lr 0.0001 | ms/batch 359.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/757 batches | lr 0.0001 | ms/batch 359.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/757 batches | lr 0.0001 | ms/batch 360.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/757 batches | lr 0.0001 | ms/batch 361.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/757 batches | lr 0.0001 | ms/batch 360.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/757 batches | lr 0.0001 | ms/batch 360.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 277.54s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/757 batches | lr 0.0001 | ms/batch 362.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/757 batches | lr 0.0001 | ms/batch 359.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/757 batches | lr 0.0001 | ms/batch 359.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/757 batches | lr 0.0001 | ms/batch 360.10 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/757 batches | lr 0.0001 | ms/batch 360.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/757 batches | lr 0.0001 | ms/batch 359.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/757 batches | lr 0.0001 | ms/batch 359.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 277.29s | valid loss/mse 0.0072 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/757 batches | lr 0.0001 | ms/batch 366.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/757 batches | lr 0.0001 | ms/batch 361.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/757 batches | lr 0.0001 | ms/batch 360.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/757 batches | lr 0.0001 | ms/batch 360.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/757 batches | lr 0.0001 | ms/batch 360.77 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 600/757 batches | lr 0.0001 | ms/batch 360.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 700/757 batches | lr 0.0001 | ms/batch 360.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 278.45s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/757 batches | lr 0.0000 | ms/batch 364.24 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/757 batches | lr 0.0000 | ms/batch 360.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/757 batches | lr 0.0000 | ms/batch 360.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 400/757 batches | lr 0.0000 | ms/batch 361.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 500/757 batches | lr 0.0000 | ms/batch 360.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 600/757 batches | lr 0.0000 | ms/batch 361.32 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 700/757 batches | lr 0.0000 | ms/batch 361.56 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 278.41s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 8
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_iPSC/scgpt/split2
scGPT - INFO - Running on 2024-07-26 14:05:36
scGPT - INFO - match 4538/5020 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/751 batches | lr 0.0001 | ms/batch 366.49 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 200/751 batches | lr 0.0001 | ms/batch 357.45 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/751 batches | lr 0.0001 | ms/batch 357.80 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/751 batches | lr 0.0001 | ms/batch 358.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/751 batches | lr 0.0001 | ms/batch 358.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/751 batches | lr 0.0001 | ms/batch 359.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/751 batches | lr 0.0001 | ms/batch 359.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 325.71s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0071
scGPT - INFO - | epoch   2 | 100/751 batches | lr 0.0001 | ms/batch 363.16 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/751 batches | lr 0.0001 | ms/batch 359.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/751 batches | lr 0.0001 | ms/batch 359.21 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/751 batches | lr 0.0001 | ms/batch 359.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/751 batches | lr 0.0001 | ms/batch 359.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/751 batches | lr 0.0001 | ms/batch 359.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/751 batches | lr 0.0001 | ms/batch 359.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 326.58s | valid loss/mse 0.0074 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/751 batches | lr 0.0001 | ms/batch 364.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/751 batches | lr 0.0001 | ms/batch 359.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/751 batches | lr 0.0001 | ms/batch 359.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/751 batches | lr 0.0001 | ms/batch 360.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/751 batches | lr 0.0001 | ms/batch 360.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/751 batches | lr 0.0001 | ms/batch 360.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/751 batches | lr 0.0001 | ms/batch 360.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 327.02s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0070
scGPT - INFO - | epoch   4 | 100/751 batches | lr 0.0001 | ms/batch 363.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/751 batches | lr 0.0001 | ms/batch 359.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/751 batches | lr 0.0001 | ms/batch 359.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/751 batches | lr 0.0001 | ms/batch 359.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/751 batches | lr 0.0001 | ms/batch 361.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/751 batches | lr 0.0001 | ms/batch 360.93 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/751 batches | lr 0.0001 | ms/batch 360.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 326.88s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/751 batches | lr 0.0001 | ms/batch 364.23 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/751 batches | lr 0.0001 | ms/batch 360.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/751 batches | lr 0.0001 | ms/batch 360.91 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/751 batches | lr 0.0001 | ms/batch 361.15 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/751 batches | lr 0.0001 | ms/batch 360.10 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/751 batches | lr 0.0001 | ms/batch 359.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/751 batches | lr 0.0001 | ms/batch 359.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 326.64s | valid loss/mse 0.0073 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/751 batches | lr 0.0001 | ms/batch 363.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/751 batches | lr 0.0001 | ms/batch 360.56 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/751 batches | lr 0.0001 | ms/batch 360.44 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/751 batches | lr 0.0001 | ms/batch 360.45 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/751 batches | lr 0.0001 | ms/batch 360.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/751 batches | lr 0.0001 | ms/batch 361.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/751 batches | lr 0.0001 | ms/batch 361.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 327.73s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/751 batches | lr 0.0001 | ms/batch 367.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/751 batches | lr 0.0001 | ms/batch 361.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/751 batches | lr 0.0001 | ms/batch 361.90 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/751 batches | lr 0.0001 | ms/batch 361.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/751 batches | lr 0.0001 | ms/batch 361.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 600/751 batches | lr 0.0001 | ms/batch 362.19 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 700/751 batches | lr 0.0001 | ms/batch 361.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 328.81s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/751 batches | lr 0.0000 | ms/batch 365.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/751 batches | lr 0.0000 | ms/batch 361.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/751 batches | lr 0.0000 | ms/batch 360.66 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 400/751 batches | lr 0.0000 | ms/batch 354.07 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 500/751 batches | lr 0.0000 | ms/batch 354.38 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 600/751 batches | lr 0.0000 | ms/batch 354.25 | loss   nan | mse   nan |
scGPT - INFO - | epoch   8 | 700/751 batches | lr 0.0000 | ms/batch 354.35 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 324.91s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 8
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_iPSC/scgpt/split3
scGPT - INFO - Running on 2024-07-26 15:03:29
scGPT - INFO - match 4538/5020 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/931 batches | lr 0.0001 | ms/batch 363.50 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 200/931 batches | lr 0.0001 | ms/batch 358.13 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 300/931 batches | lr 0.0001 | ms/batch 358.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/931 batches | lr 0.0001 | ms/batch 359.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/931 batches | lr 0.0001 | ms/batch 359.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/931 batches | lr 0.0001 | ms/batch 359.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/931 batches | lr 0.0001 | ms/batch 360.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 800/931 batches | lr 0.0001 | ms/batch 359.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 900/931 batches | lr 0.0001 | ms/batch 359.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 356.26s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0071
scGPT - INFO - | epoch   2 | 100/931 batches | lr 0.0001 | ms/batch 363.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/931 batches | lr 0.0001 | ms/batch 359.80 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/931 batches | lr 0.0001 | ms/batch 360.16 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/931 batches | lr 0.0001 | ms/batch 360.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/931 batches | lr 0.0001 | ms/batch 360.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/931 batches | lr 0.0001 | ms/batch 360.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/931 batches | lr 0.0001 | ms/batch 360.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 800/931 batches | lr 0.0001 | ms/batch 360.59 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 900/931 batches | lr 0.0001 | ms/batch 360.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 357.09s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0071
scGPT - INFO - | epoch   3 | 100/931 batches | lr 0.0001 | ms/batch 364.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/931 batches | lr 0.0001 | ms/batch 360.04 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/931 batches | lr 0.0001 | ms/batch 360.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/931 batches | lr 0.0001 | ms/batch 359.96 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/931 batches | lr 0.0001 | ms/batch 360.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/931 batches | lr 0.0001 | ms/batch 360.20 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/931 batches | lr 0.0001 | ms/batch 360.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 800/931 batches | lr 0.0001 | ms/batch 360.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 900/931 batches | lr 0.0001 | ms/batch 360.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 357.29s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0070
scGPT - INFO - | epoch   4 | 100/931 batches | lr 0.0001 | ms/batch 364.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/931 batches | lr 0.0001 | ms/batch 361.18 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/931 batches | lr 0.0001 | ms/batch 361.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/931 batches | lr 0.0001 | ms/batch 361.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/931 batches | lr 0.0001 | ms/batch 361.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/931 batches | lr 0.0001 | ms/batch 362.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/931 batches | lr 0.0001 | ms/batch 361.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 800/931 batches | lr 0.0001 | ms/batch 360.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 900/931 batches | lr 0.0001 | ms/batch 362.44 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 358.60s | valid loss/mse 0.0072 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/931 batches | lr 0.0001 | ms/batch 365.90 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/931 batches | lr 0.0001 | ms/batch 361.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/931 batches | lr 0.0001 | ms/batch 361.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/931 batches | lr 0.0001 | ms/batch 361.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/931 batches | lr 0.0001 | ms/batch 361.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/931 batches | lr 0.0001 | ms/batch 362.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/931 batches | lr 0.0001 | ms/batch 361.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 800/931 batches | lr 0.0001 | ms/batch 361.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 900/931 batches | lr 0.0001 | ms/batch 361.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 358.64s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0069
scGPT - INFO - | epoch   6 | 100/931 batches | lr 0.0001 | ms/batch 365.55 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/931 batches | lr 0.0001 | ms/batch 361.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/931 batches | lr 0.0001 | ms/batch 361.93 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/931 batches | lr 0.0001 | ms/batch 362.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/931 batches | lr 0.0001 | ms/batch 362.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/931 batches | lr 0.0001 | ms/batch 362.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/931 batches | lr 0.0001 | ms/batch 362.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 800/931 batches | lr 0.0001 | ms/batch 361.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 900/931 batches | lr 0.0001 | ms/batch 361.90 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 358.92s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/931 batches | lr 0.0001 | ms/batch 366.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/931 batches | lr 0.0001 | ms/batch 361.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/931 batches | lr 0.0001 | ms/batch 362.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/931 batches | lr 0.0001 | ms/batch 361.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/931 batches | lr 0.0001 | ms/batch 362.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 600/931 batches | lr 0.0001 | ms/batch 361.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 700/931 batches | lr 0.0001 | ms/batch 362.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 800/931 batches | lr 0.0001 | ms/batch 362.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 900/931 batches | lr 0.0001 | ms/batch 362.54 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 359.11s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0069
scGPT - INFO - | epoch   8 | 100/931 batches | lr 0.0000 | ms/batch 366.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/931 batches | lr 0.0000 | ms/batch 362.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/931 batches | lr 0.0000 | ms/batch 362.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 400/931 batches | lr 0.0000 | ms/batch 362.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 500/931 batches | lr 0.0000 | ms/batch 362.36 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 600/931 batches | lr 0.0000 | ms/batch 363.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 700/931 batches | lr 0.0000 | ms/batch 362.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 800/931 batches | lr 0.0000 | ms/batch 363.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 900/931 batches | lr 0.0000 | ms/batch 362.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 359.52s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/931 batches | lr 0.0000 | ms/batch 365.48 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 200/931 batches | lr 0.0000 | ms/batch 362.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 300/931 batches | lr 0.0000 | ms/batch 361.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 400/931 batches | lr 0.0000 | ms/batch 362.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 500/931 batches | lr 0.0000 | ms/batch 362.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 600/931 batches | lr 0.0000 | ms/batch 362.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 700/931 batches | lr 0.0000 | ms/batch 362.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 800/931 batches | lr 0.0000 | ms/batch 362.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 900/931 batches | lr 0.0000 | ms/batch 362.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 359.24s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/931 batches | lr 0.0000 | ms/batch 366.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 200/931 batches | lr 0.0000 | ms/batch 363.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 300/931 batches | lr 0.0000 | ms/batch 362.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 400/931 batches | lr 0.0000 | ms/batch 363.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 500/931 batches | lr 0.0000 | ms/batch 362.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 600/931 batches | lr 0.0000 | ms/batch 363.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 700/931 batches | lr 0.0000 | ms/batch 362.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 800/931 batches | lr 0.0000 | ms/batch 363.32 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 900/931 batches | lr 0.0000 | ms/batch 363.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 359.98s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/931 batches | lr 0.0000 | ms/batch 366.56 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 200/931 batches | lr 0.0000 | ms/batch 363.22 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 300/931 batches | lr 0.0000 | ms/batch 363.09 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 400/931 batches | lr 0.0000 | ms/batch 363.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 500/931 batches | lr 0.0000 | ms/batch 363.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 600/931 batches | lr 0.0000 | ms/batch 363.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 700/931 batches | lr 0.0000 | ms/batch 362.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 800/931 batches | lr 0.0000 | ms/batch 363.90 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 900/931 batches | lr 0.0000 | ms/batch 364.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 360.43s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/931 batches | lr 0.0000 | ms/batch 367.46 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 200/931 batches | lr 0.0000 | ms/batch 364.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 300/931 batches | lr 0.0000 | ms/batch 363.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 400/931 batches | lr 0.0000 | ms/batch 364.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 500/931 batches | lr 0.0000 | ms/batch 363.96 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 600/931 batches | lr 0.0000 | ms/batch 363.74 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 700/931 batches | lr 0.0000 | ms/batch 363.99 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 800/931 batches | lr 0.0000 | ms/batch 363.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 900/931 batches | lr 0.0000 | ms/batch 364.17 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 360.98s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 12
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_iPSC/scgpt/split4
scGPT - INFO - Running on 2024-07-26 16:31:35
scGPT - INFO - match 4538/5020 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/1042 batches | lr 0.0001 | ms/batch 363.17 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 200/1042 batches | lr 0.0001 | ms/batch 359.16 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/1042 batches | lr 0.0001 | ms/batch 359.27 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/1042 batches | lr 0.0001 | ms/batch 359.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/1042 batches | lr 0.0001 | ms/batch 359.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/1042 batches | lr 0.0001 | ms/batch 359.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/1042 batches | lr 0.0001 | ms/batch 359.60 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 800/1042 batches | lr 0.0001 | ms/batch 358.88 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 900/1042 batches | lr 0.0001 | ms/batch 358.37 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 1000/1042 batches | lr 0.0001 | ms/batch 359.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 379.79s | valid loss/mse 0.0077 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0077
scGPT - INFO - | epoch   2 | 100/1042 batches | lr 0.0001 | ms/batch 363.53 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/1042 batches | lr 0.0001 | ms/batch 360.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/1042 batches | lr 0.0001 | ms/batch 361.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/1042 batches | lr 0.0001 | ms/batch 361.32 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/1042 batches | lr 0.0001 | ms/batch 361.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/1042 batches | lr 0.0001 | ms/batch 362.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/1042 batches | lr 0.0001 | ms/batch 361.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 800/1042 batches | lr 0.0001 | ms/batch 361.86 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 900/1042 batches | lr 0.0001 | ms/batch 361.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 1000/1042 batches | lr 0.0001 | ms/batch 362.51 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 381.94s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0070
scGPT - INFO - | epoch   3 | 100/1042 batches | lr 0.0001 | ms/batch 365.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/1042 batches | lr 0.0001 | ms/batch 361.00 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/1042 batches | lr 0.0001 | ms/batch 361.71 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/1042 batches | lr 0.0001 | ms/batch 361.55 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/1042 batches | lr 0.0001 | ms/batch 357.39 | loss   nan | mse   nan |
scGPT - INFO - | epoch   3 | 600/1042 batches | lr 0.0001 | ms/batch 353.69 | loss   nan | mse   nan |
scGPT - INFO - | epoch   3 | 700/1042 batches | lr 0.0001 | ms/batch 353.77 | loss   nan | mse   nan |
scGPT - INFO - | epoch   3 | 800/1042 batches | lr 0.0001 | ms/batch 353.80 | loss   nan | mse   nan |
scGPT - INFO - | epoch   3 | 900/1042 batches | lr 0.0001 | ms/batch 353.93 | loss   nan | mse   nan |
scGPT - INFO - | epoch   3 | 1000/1042 batches | lr 0.0001 | ms/batch 353.90 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 377.35s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/1042 batches | lr 0.0001 | ms/batch 357.55 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 200/1042 batches | lr 0.0001 | ms/batch 353.70 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 300/1042 batches | lr 0.0001 | ms/batch 354.03 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 400/1042 batches | lr 0.0001 | ms/batch 354.29 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 500/1042 batches | lr 0.0001 | ms/batch 354.01 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 600/1042 batches | lr 0.0001 | ms/batch 353.88 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 700/1042 batches | lr 0.0001 | ms/batch 354.03 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 800/1042 batches | lr 0.0001 | ms/batch 353.62 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 900/1042 batches | lr 0.0001 | ms/batch 354.01 | loss   nan | mse   nan |
scGPT - INFO - | epoch   4 | 1000/1042 batches | lr 0.0001 | ms/batch 354.02 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 374.08s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/1042 batches | lr 0.0001 | ms/batch 357.45 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 200/1042 batches | lr 0.0001 | ms/batch 353.60 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 300/1042 batches | lr 0.0001 | ms/batch 351.82 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 400/1042 batches | lr 0.0001 | ms/batch 351.60 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 500/1042 batches | lr 0.0001 | ms/batch 351.77 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 600/1042 batches | lr 0.0001 | ms/batch 351.52 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 700/1042 batches | lr 0.0001 | ms/batch 351.79 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 800/1042 batches | lr 0.0001 | ms/batch 351.52 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 900/1042 batches | lr 0.0001 | ms/batch 351.88 | loss   nan | mse   nan |
scGPT - INFO - | epoch   5 | 1000/1042 batches | lr 0.0001 | ms/batch 351.70 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 372.08s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/1042 batches | lr 0.0001 | ms/batch 355.11 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 200/1042 batches | lr 0.0001 | ms/batch 351.77 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 300/1042 batches | lr 0.0001 | ms/batch 351.78 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 400/1042 batches | lr 0.0001 | ms/batch 351.70 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 500/1042 batches | lr 0.0001 | ms/batch 351.79 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 600/1042 batches | lr 0.0001 | ms/batch 351.42 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 700/1042 batches | lr 0.0001 | ms/batch 351.87 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 800/1042 batches | lr 0.0001 | ms/batch 351.49 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 900/1042 batches | lr 0.0001 | ms/batch 351.88 | loss   nan | mse   nan |
scGPT - INFO - | epoch   6 | 1000/1042 batches | lr 0.0001 | ms/batch 351.60 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 371.65s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/1042 batches | lr 0.0001 | ms/batch 355.24 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 200/1042 batches | lr 0.0001 | ms/batch 352.13 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 300/1042 batches | lr 0.0001 | ms/batch 351.90 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 400/1042 batches | lr 0.0001 | ms/batch 351.64 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 500/1042 batches | lr 0.0001 | ms/batch 351.89 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 600/1042 batches | lr 0.0001 | ms/batch 351.68 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 700/1042 batches | lr 0.0001 | ms/batch 351.89 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 800/1042 batches | lr 0.0001 | ms/batch 351.80 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 900/1042 batches | lr 0.0001 | ms/batch 351.89 | loss   nan | mse   nan |
scGPT - INFO - | epoch   7 | 1000/1042 batches | lr 0.0001 | ms/batch 351.66 | loss   nan | mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 371.79s | valid loss/mse   nan |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2019_iPSC/scgpt/split5
scGPT - INFO - Running on 2024-07-26 17:31:32
scGPT - INFO - match 4538/5020 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/872 batches | lr 0.0001 | ms/batch 364.66 | loss  0.02 | mse  0.02 |
scGPT - INFO - | epoch   1 | 200/872 batches | lr 0.0001 | ms/batch 360.21 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 300/872 batches | lr 0.0001 | ms/batch 359.72 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 400/872 batches | lr 0.0001 | ms/batch 359.92 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 500/872 batches | lr 0.0001 | ms/batch 359.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 600/872 batches | lr 0.0001 | ms/batch 360.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 700/872 batches | lr 0.0001 | ms/batch 360.73 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   1 | 800/872 batches | lr 0.0001 | ms/batch 360.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 323.36s | valid loss/mse 0.0075 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0075
scGPT - INFO - | epoch   2 | 100/872 batches | lr 0.0001 | ms/batch 363.76 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 200/872 batches | lr 0.0001 | ms/batch 360.29 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 300/872 batches | lr 0.0001 | ms/batch 361.19 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 400/872 batches | lr 0.0001 | ms/batch 361.68 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 500/872 batches | lr 0.0001 | ms/batch 361.98 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 600/872 batches | lr 0.0001 | ms/batch 361.64 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 700/872 batches | lr 0.0001 | ms/batch 362.50 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   2 | 800/872 batches | lr 0.0001 | ms/batch 362.63 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 324.45s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0071
scGPT - INFO - | epoch   3 | 100/872 batches | lr 0.0001 | ms/batch 366.85 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 200/872 batches | lr 0.0001 | ms/batch 363.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 300/872 batches | lr 0.0001 | ms/batch 363.69 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 400/872 batches | lr 0.0001 | ms/batch 363.63 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 500/872 batches | lr 0.0001 | ms/batch 363.63 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 600/872 batches | lr 0.0001 | ms/batch 363.43 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 700/872 batches | lr 0.0001 | ms/batch 363.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   3 | 800/872 batches | lr 0.0001 | ms/batch 363.42 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 326.09s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0070
scGPT - INFO - | epoch   4 | 100/872 batches | lr 0.0001 | ms/batch 366.60 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 200/872 batches | lr 0.0001 | ms/batch 362.07 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 300/872 batches | lr 0.0001 | ms/batch 362.61 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 400/872 batches | lr 0.0001 | ms/batch 362.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 500/872 batches | lr 0.0001 | ms/batch 363.01 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 600/872 batches | lr 0.0001 | ms/batch 363.25 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 700/872 batches | lr 0.0001 | ms/batch 363.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   4 | 800/872 batches | lr 0.0001 | ms/batch 363.41 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 325.78s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/872 batches | lr 0.0001 | ms/batch 367.57 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 200/872 batches | lr 0.0001 | ms/batch 363.38 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 300/872 batches | lr 0.0001 | ms/batch 363.40 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 400/872 batches | lr 0.0001 | ms/batch 363.28 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 500/872 batches | lr 0.0001 | ms/batch 362.89 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 600/872 batches | lr 0.0001 | ms/batch 362.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 700/872 batches | lr 0.0001 | ms/batch 362.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   5 | 800/872 batches | lr 0.0001 | ms/batch 362.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 325.58s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/872 batches | lr 0.0001 | ms/batch 366.13 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 200/872 batches | lr 0.0001 | ms/batch 362.54 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 300/872 batches | lr 0.0001 | ms/batch 362.44 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 400/872 batches | lr 0.0001 | ms/batch 362.06 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 500/872 batches | lr 0.0001 | ms/batch 362.87 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 600/872 batches | lr 0.0001 | ms/batch 362.63 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 700/872 batches | lr 0.0001 | ms/batch 362.97 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   6 | 800/872 batches | lr 0.0001 | ms/batch 362.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 325.30s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/872 batches | lr 0.0001 | ms/batch 365.94 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 200/872 batches | lr 0.0001 | ms/batch 362.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 300/872 batches | lr 0.0001 | ms/batch 362.26 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 400/872 batches | lr 0.0001 | ms/batch 362.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 500/872 batches | lr 0.0001 | ms/batch 363.11 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 600/872 batches | lr 0.0001 | ms/batch 363.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 700/872 batches | lr 0.0001 | ms/batch 362.83 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   7 | 800/872 batches | lr 0.0001 | ms/batch 363.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 325.45s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/872 batches | lr 0.0000 | ms/batch 366.82 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 200/872 batches | lr 0.0000 | ms/batch 363.84 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 300/872 batches | lr 0.0000 | ms/batch 364.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 400/872 batches | lr 0.0000 | ms/batch 364.54 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 500/872 batches | lr 0.0000 | ms/batch 363.78 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 600/872 batches | lr 0.0000 | ms/batch 363.68 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 700/872 batches | lr 0.0000 | ms/batch 363.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   8 | 800/872 batches | lr 0.0000 | ms/batch 363.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 326.23s | valid loss/mse 0.0069 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0069
scGPT - INFO - | epoch   9 | 100/872 batches | lr 0.0000 | ms/batch 366.49 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 200/872 batches | lr 0.0000 | ms/batch 362.90 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 300/872 batches | lr 0.0000 | ms/batch 362.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 400/872 batches | lr 0.0000 | ms/batch 362.18 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 500/872 batches | lr 0.0000 | ms/batch 362.34 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 600/872 batches | lr 0.0000 | ms/batch 362.05 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 700/872 batches | lr 0.0000 | ms/batch 362.70 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch   9 | 800/872 batches | lr 0.0000 | ms/batch 362.39 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 325.27s | valid loss/mse 0.0073 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/872 batches | lr 0.0000 | ms/batch 366.29 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 200/872 batches | lr 0.0000 | ms/batch 362.95 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 300/872 batches | lr 0.0000 | ms/batch 362.62 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 400/872 batches | lr 0.0000 | ms/batch 363.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 500/872 batches | lr 0.0000 | ms/batch 362.79 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 600/872 batches | lr 0.0000 | ms/batch 363.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 700/872 batches | lr 0.0000 | ms/batch 362.58 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  10 | 800/872 batches | lr 0.0000 | ms/batch 362.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 325.35s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/872 batches | lr 0.0000 | ms/batch 366.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 200/872 batches | lr 0.0000 | ms/batch 362.75 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 300/872 batches | lr 0.0000 | ms/batch 363.68 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 400/872 batches | lr 0.0000 | ms/batch 362.98 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 500/872 batches | lr 0.0000 | ms/batch 364.08 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 600/872 batches | lr 0.0000 | ms/batch 364.33 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 700/872 batches | lr 0.0000 | ms/batch 364.12 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  11 | 800/872 batches | lr 0.0000 | ms/batch 363.10 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 326.16s | valid loss/mse 0.0070 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/872 batches | lr 0.0000 | ms/batch 367.30 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 200/872 batches | lr 0.0000 | ms/batch 363.31 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 300/872 batches | lr 0.0000 | ms/batch 363.66 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 400/872 batches | lr 0.0000 | ms/batch 363.55 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 500/872 batches | lr 0.0000 | ms/batch 363.67 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 600/872 batches | lr 0.0000 | ms/batch 362.81 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 700/872 batches | lr 0.0000 | ms/batch 363.02 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  12 | 800/872 batches | lr 0.0000 | ms/batch 361.77 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 325.61s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/872 batches | lr 0.0000 | ms/batch 366.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 200/872 batches | lr 0.0000 | ms/batch 363.47 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 300/872 batches | lr 0.0000 | ms/batch 363.03 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 400/872 batches | lr 0.0000 | ms/batch 363.14 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 500/872 batches | lr 0.0000 | ms/batch 362.35 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 600/872 batches | lr 0.0000 | ms/batch 362.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 700/872 batches | lr 0.0000 | ms/batch 362.44 | loss  0.01 | mse  0.01 |
scGPT - INFO - | epoch  13 | 800/872 batches | lr 0.0000 | ms/batch 362.52 | loss  0.01 | mse  0.01 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 325.39s | valid loss/mse 0.0071 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 13
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRa/scgpt/split1
scGPT - INFO - Running on 2024-07-26 19:15:29
scGPT - INFO - match 3930/5034 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/372 batches | lr 0.0001 | ms/batch 374.70 | loss  0.15 | mse  0.15 |
scGPT - INFO - | epoch   1 | 200/372 batches | lr 0.0001 | ms/batch 361.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 300/372 batches | lr 0.0001 | ms/batch 361.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 140.48s | valid loss/mse 0.0701 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0701
scGPT - INFO - | epoch   2 | 100/372 batches | lr 0.0001 | ms/batch 370.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/372 batches | lr 0.0001 | ms/batch 362.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/372 batches | lr 0.0001 | ms/batch 361.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 139.97s | valid loss/mse 0.0722 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/372 batches | lr 0.0001 | ms/batch 365.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/372 batches | lr 0.0001 | ms/batch 363.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/372 batches | lr 0.0001 | ms/batch 361.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 139.54s | valid loss/mse 0.0687 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0687
scGPT - INFO - | epoch   4 | 100/372 batches | lr 0.0001 | ms/batch 365.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/372 batches | lr 0.0001 | ms/batch 362.65 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/372 batches | lr 0.0001 | ms/batch 361.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 139.52s | valid loss/mse 0.0660 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0660
scGPT - INFO - | epoch   5 | 100/372 batches | lr 0.0001 | ms/batch 365.25 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/372 batches | lr 0.0001 | ms/batch 361.83 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/372 batches | lr 0.0001 | ms/batch 363.73 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 139.76s | valid loss/mse 0.0671 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/372 batches | lr 0.0001 | ms/batch 366.20 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/372 batches | lr 0.0001 | ms/batch 362.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/372 batches | lr 0.0001 | ms/batch 361.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 139.57s | valid loss/mse 0.0672 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/372 batches | lr 0.0001 | ms/batch 366.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/372 batches | lr 0.0001 | ms/batch 361.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/372 batches | lr 0.0001 | ms/batch 361.46 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 139.41s | valid loss/mse 0.0663 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/372 batches | lr 0.0000 | ms/batch 365.06 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/372 batches | lr 0.0000 | ms/batch 361.25 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/372 batches | lr 0.0000 | ms/batch 361.40 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 139.46s | valid loss/mse 0.0673 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/372 batches | lr 0.0000 | ms/batch 365.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/372 batches | lr 0.0000 | ms/batch 361.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/372 batches | lr 0.0000 | ms/batch 361.93 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 139.47s | valid loss/mse 0.0666 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 9
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRa/scgpt/split2
scGPT - INFO - Running on 2024-07-26 19:41:32
scGPT - INFO - match 3930/5034 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/349 batches | lr 0.0001 | ms/batch 368.59 | loss  0.20 | mse  0.20 |
scGPT - INFO - | epoch   1 | 200/349 batches | lr 0.0001 | ms/batch 363.05 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/349 batches | lr 0.0001 | ms/batch 362.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 131.68s | valid loss/mse 0.0688 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0688
scGPT - INFO - | epoch   2 | 100/349 batches | lr 0.0001 | ms/batch 365.96 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/349 batches | lr 0.0001 | ms/batch 361.15 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/349 batches | lr 0.0001 | ms/batch 361.09 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 131.06s | valid loss/mse 0.0662 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0662
scGPT - INFO - | epoch   3 | 100/349 batches | lr 0.0001 | ms/batch 364.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/349 batches | lr 0.0001 | ms/batch 361.16 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/349 batches | lr 0.0001 | ms/batch 361.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 130.95s | valid loss/mse 0.0666 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/349 batches | lr 0.0001 | ms/batch 364.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/349 batches | lr 0.0001 | ms/batch 361.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/349 batches | lr 0.0001 | ms/batch 361.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 130.94s | valid loss/mse 0.0661 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0661
scGPT - INFO - | epoch   5 | 100/349 batches | lr 0.0001 | ms/batch 364.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/349 batches | lr 0.0001 | ms/batch 361.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/349 batches | lr 0.0001 | ms/batch 361.03 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 130.92s | valid loss/mse 0.0656 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0656
scGPT - INFO - | epoch   6 | 100/349 batches | lr 0.0001 | ms/batch 364.73 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/349 batches | lr 0.0001 | ms/batch 361.16 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/349 batches | lr 0.0001 | ms/batch 361.20 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 130.98s | valid loss/mse 0.0655 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0655
scGPT - INFO - | epoch   7 | 100/349 batches | lr 0.0001 | ms/batch 364.61 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/349 batches | lr 0.0001 | ms/batch 361.25 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/349 batches | lr 0.0001 | ms/batch 361.32 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 130.98s | valid loss/mse 0.0648 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0648
scGPT - INFO - | epoch   8 | 100/349 batches | lr 0.0000 | ms/batch 364.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/349 batches | lr 0.0000 | ms/batch 361.33 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/349 batches | lr 0.0000 | ms/batch 361.15 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 130.98s | valid loss/mse 0.0663 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/349 batches | lr 0.0000 | ms/batch 364.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/349 batches | lr 0.0000 | ms/batch 361.16 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/349 batches | lr 0.0000 | ms/batch 361.26 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 130.96s | valid loss/mse 0.0659 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/349 batches | lr 0.0000 | ms/batch 364.82 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/349 batches | lr 0.0000 | ms/batch 361.22 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  10 | 300/349 batches | lr 0.0000 | ms/batch 361.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 130.96s | valid loss/mse 0.0656 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/349 batches | lr 0.0000 | ms/batch 364.89 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/349 batches | lr 0.0000 | ms/batch 361.15 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/349 batches | lr 0.0000 | ms/batch 361.32 | loss  0.06 | mse  0.06 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 130.98s | valid loss/mse 0.0664 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/349 batches | lr 0.0000 | ms/batch 364.86 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/349 batches | lr 0.0000 | ms/batch 361.27 | loss  0.06 | mse  0.06 |
scGPT - INFO - | epoch  12 | 300/349 batches | lr 0.0000 | ms/batch 361.37 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 131.01s | valid loss/mse 0.0654 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 12
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRa/scgpt/split3
scGPT - INFO - Running on 2024-07-26 20:13:37
scGPT - INFO - match 3930/5034 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/350 batches | lr 0.0001 | ms/batch 364.95 | loss  0.15 | mse  0.15 |
scGPT - INFO - | epoch   1 | 200/350 batches | lr 0.0001 | ms/batch 361.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 300/350 batches | lr 0.0001 | ms/batch 361.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 134.26s | valid loss/mse 0.0707 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0707
scGPT - INFO - | epoch   2 | 100/350 batches | lr 0.0001 | ms/batch 365.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/350 batches | lr 0.0001 | ms/batch 361.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/350 batches | lr 0.0001 | ms/batch 361.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 134.27s | valid loss/mse 0.0688 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0688
scGPT - INFO - | epoch   3 | 100/350 batches | lr 0.0001 | ms/batch 365.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/350 batches | lr 0.0001 | ms/batch 361.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/350 batches | lr 0.0001 | ms/batch 361.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 134.28s | valid loss/mse 0.0676 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0676
scGPT - INFO - | epoch   4 | 100/350 batches | lr 0.0001 | ms/batch 365.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/350 batches | lr 0.0001 | ms/batch 361.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/350 batches | lr 0.0001 | ms/batch 361.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 134.28s | valid loss/mse 0.0678 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/350 batches | lr 0.0001 | ms/batch 365.05 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/350 batches | lr 0.0001 | ms/batch 361.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/350 batches | lr 0.0001 | ms/batch 361.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 134.20s | valid loss/mse 0.0675 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0675
scGPT - INFO - | epoch   6 | 100/350 batches | lr 0.0001 | ms/batch 365.06 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/350 batches | lr 0.0001 | ms/batch 361.26 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/350 batches | lr 0.0001 | ms/batch 361.38 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 134.16s | valid loss/mse 0.0675 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0675
scGPT - INFO - | epoch   7 | 100/350 batches | lr 0.0001 | ms/batch 365.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/350 batches | lr 0.0001 | ms/batch 361.47 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/350 batches | lr 0.0001 | ms/batch 361.50 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 134.20s | valid loss/mse 0.0684 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/350 batches | lr 0.0000 | ms/batch 365.16 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/350 batches | lr 0.0000 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/350 batches | lr 0.0000 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 134.23s | valid loss/mse 0.0670 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0670
scGPT - INFO - | epoch   9 | 100/350 batches | lr 0.0000 | ms/batch 365.07 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/350 batches | lr 0.0000 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/350 batches | lr 0.0000 | ms/batch 361.68 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 134.23s | valid loss/mse 0.0680 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/350 batches | lr 0.0000 | ms/batch 365.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/350 batches | lr 0.0000 | ms/batch 361.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/350 batches | lr 0.0000 | ms/batch 361.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 134.22s | valid loss/mse 0.0671 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/350 batches | lr 0.0000 | ms/batch 365.22 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/350 batches | lr 0.0000 | ms/batch 361.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/350 batches | lr 0.0000 | ms/batch 361.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 134.26s | valid loss/mse 0.0671 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/350 batches | lr 0.0000 | ms/batch 365.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/350 batches | lr 0.0000 | ms/batch 361.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/350 batches | lr 0.0000 | ms/batch 361.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 134.25s | valid loss/mse 0.0670 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/350 batches | lr 0.0000 | ms/batch 365.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/350 batches | lr 0.0000 | ms/batch 361.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 300/350 batches | lr 0.0000 | ms/batch 361.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 134.31s | valid loss/mse 0.0671 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 13
---Creating test_res
test_res saved successfully----
Split3 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRa/scgpt/split4
scGPT - INFO - Running on 2024-07-26 20:47:50
scGPT - INFO - match 3930/5034 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/348 batches | lr 0.0001 | ms/batch 365.04 | loss  0.16 | mse  0.16 |
scGPT - INFO - | epoch   1 | 200/348 batches | lr 0.0001 | ms/batch 361.41 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 300/348 batches | lr 0.0001 | ms/batch 361.20 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 133.28s | valid loss/mse 0.0689 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0689
scGPT - INFO - | epoch   2 | 100/348 batches | lr 0.0001 | ms/batch 364.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/348 batches | lr 0.0001 | ms/batch 361.20 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/348 batches | lr 0.0001 | ms/batch 361.20 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 133.20s | valid loss/mse 0.0667 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0667
scGPT - INFO - | epoch   3 | 100/348 batches | lr 0.0001 | ms/batch 364.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/348 batches | lr 0.0001 | ms/batch 361.06 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/348 batches | lr 0.0001 | ms/batch 360.93 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 133.17s | valid loss/mse 0.0648 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0648
scGPT - INFO - | epoch   4 | 100/348 batches | lr 0.0001 | ms/batch 364.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/348 batches | lr 0.0001 | ms/batch 361.32 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/348 batches | lr 0.0001 | ms/batch 361.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 133.24s | valid loss/mse 0.0643 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0643
scGPT - INFO - | epoch   5 | 100/348 batches | lr 0.0001 | ms/batch 364.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/348 batches | lr 0.0001 | ms/batch 361.33 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/348 batches | lr 0.0001 | ms/batch 361.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 133.21s | valid loss/mse 0.0649 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/348 batches | lr 0.0001 | ms/batch 365.00 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/348 batches | lr 0.0001 | ms/batch 361.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/348 batches | lr 0.0001 | ms/batch 361.42 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 133.26s | valid loss/mse 0.0649 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/348 batches | lr 0.0001 | ms/batch 365.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/348 batches | lr 0.0001 | ms/batch 361.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/348 batches | lr 0.0001 | ms/batch 361.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 133.33s | valid loss/mse 0.0651 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/348 batches | lr 0.0000 | ms/batch 364.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/348 batches | lr 0.0000 | ms/batch 361.53 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/348 batches | lr 0.0000 | ms/batch 361.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 133.27s | valid loss/mse 0.0637 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0637
scGPT - INFO - | epoch   9 | 100/348 batches | lr 0.0000 | ms/batch 365.08 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/348 batches | lr 0.0000 | ms/batch 361.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/348 batches | lr 0.0000 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 133.34s | valid loss/mse 0.0644 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/348 batches | lr 0.0000 | ms/batch 365.26 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/348 batches | lr 0.0000 | ms/batch 361.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/348 batches | lr 0.0000 | ms/batch 361.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 133.34s | valid loss/mse 0.0647 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/348 batches | lr 0.0000 | ms/batch 365.23 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/348 batches | lr 0.0000 | ms/batch 361.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/348 batches | lr 0.0000 | ms/batch 361.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 133.34s | valid loss/mse 0.0644 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/348 batches | lr 0.0000 | ms/batch 364.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/348 batches | lr 0.0000 | ms/batch 361.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/348 batches | lr 0.0000 | ms/batch 361.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 133.34s | valid loss/mse 0.0639 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/348 batches | lr 0.0000 | ms/batch 365.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/348 batches | lr 0.0000 | ms/batch 361.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 300/348 batches | lr 0.0000 | ms/batch 361.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 133.40s | valid loss/mse 0.0643 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 13
---Creating test_res
test_res saved successfully----
Split4 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRa/scgpt/split5
scGPT - INFO - Running on 2024-07-26 21:21:58
scGPT - INFO - match 3930/5034 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/344 batches | lr 0.0001 | ms/batch 365.00 | loss  0.17 | mse  0.17 |
scGPT - INFO - | epoch   1 | 200/344 batches | lr 0.0001 | ms/batch 361.11 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 300/344 batches | lr 0.0001 | ms/batch 361.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 130.29s | valid loss/mse 0.0746 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0746
scGPT - INFO - | epoch   2 | 100/344 batches | lr 0.0001 | ms/batch 364.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 200/344 batches | lr 0.0001 | ms/batch 361.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/344 batches | lr 0.0001 | ms/batch 361.19 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 130.21s | valid loss/mse 0.0676 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0676
scGPT - INFO - | epoch   3 | 100/344 batches | lr 0.0001 | ms/batch 364.53 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/344 batches | lr 0.0001 | ms/batch 361.22 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/344 batches | lr 0.0001 | ms/batch 361.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 130.19s | valid loss/mse 0.0673 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0673
scGPT - INFO - | epoch   4 | 100/344 batches | lr 0.0001 | ms/batch 364.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/344 batches | lr 0.0001 | ms/batch 361.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/344 batches | lr 0.0001 | ms/batch 361.26 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 130.22s | valid loss/mse 0.0672 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0672
scGPT - INFO - | epoch   5 | 100/344 batches | lr 0.0001 | ms/batch 364.89 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/344 batches | lr 0.0001 | ms/batch 361.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/344 batches | lr 0.0001 | ms/batch 361.30 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 130.24s | valid loss/mse 0.0663 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0663
scGPT - INFO - | epoch   6 | 100/344 batches | lr 0.0001 | ms/batch 364.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/344 batches | lr 0.0001 | ms/batch 361.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/344 batches | lr 0.0001 | ms/batch 361.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 130.22s | valid loss/mse 0.0664 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/344 batches | lr 0.0001 | ms/batch 364.92 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/344 batches | lr 0.0001 | ms/batch 361.48 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/344 batches | lr 0.0001 | ms/batch 361.42 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 130.29s | valid loss/mse 0.0664 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/344 batches | lr 0.0000 | ms/batch 365.05 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/344 batches | lr 0.0000 | ms/batch 361.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/344 batches | lr 0.0000 | ms/batch 361.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 130.30s | valid loss/mse 0.0661 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0661
scGPT - INFO - | epoch   9 | 100/344 batches | lr 0.0000 | ms/batch 365.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/344 batches | lr 0.0000 | ms/batch 361.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/344 batches | lr 0.0000 | ms/batch 361.42 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 130.32s | valid loss/mse 0.0656 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0656
scGPT - INFO - | epoch  10 | 100/344 batches | lr 0.0000 | ms/batch 364.99 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/344 batches | lr 0.0000 | ms/batch 361.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/344 batches | lr 0.0000 | ms/batch 361.13 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 130.26s | valid loss/mse 0.0665 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/344 batches | lr 0.0000 | ms/batch 364.96 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/344 batches | lr 0.0000 | ms/batch 361.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/344 batches | lr 0.0000 | ms/batch 361.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 130.31s | valid loss/mse 0.0656 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0656
scGPT - INFO - | epoch  12 | 100/344 batches | lr 0.0000 | ms/batch 365.16 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/344 batches | lr 0.0000 | ms/batch 361.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/344 batches | lr 0.0000 | ms/batch 361.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 130.38s | valid loss/mse 0.0665 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/344 batches | lr 0.0000 | ms/batch 365.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/344 batches | lr 0.0000 | ms/batch 361.71 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 300/344 batches | lr 0.0000 | ms/batch 361.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 130.38s | valid loss/mse 0.0656 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/344 batches | lr 0.0000 | ms/batch 365.37 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 200/344 batches | lr 0.0000 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 300/344 batches | lr 0.0000 | ms/batch 361.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 130.38s | valid loss/mse 0.0661 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/344 batches | lr 0.0000 | ms/batch 365.34 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 200/344 batches | lr 0.0000 | ms/batch 361.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 300/344 batches | lr 0.0000 | ms/batch 361.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 130.40s | valid loss/mse 0.0663 |
scGPT - INFO - -----------------------------------------------------------------------------------------
---Creating test_res
test_res saved successfully----
Split5 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRi/scgpt/split1
scGPT - INFO - Running on 2024-07-26 22:37:32
scGPT - INFO - match 3830/5153 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/620 batches | lr 0.0001 | ms/batch 375.20 | loss  0.16 | mse  0.16 |
scGPT - INFO - | epoch   1 | 200/620 batches | lr 0.0001 | ms/batch 363.45 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/620 batches | lr 0.0001 | ms/batch 364.28 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/620 batches | lr 0.0001 | ms/batch 360.77 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/620 batches | lr 0.0001 | ms/batch 362.92 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 600/620 batches | lr 0.0001 | ms/batch 361.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 235.77s | valid loss/mse 0.0745 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0745
scGPT - INFO - | epoch   2 | 100/620 batches | lr 0.0001 | ms/batch 366.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/620 batches | lr 0.0001 | ms/batch 363.22 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 300/620 batches | lr 0.0001 | ms/batch 361.24 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/620 batches | lr 0.0001 | ms/batch 360.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/620 batches | lr 0.0001 | ms/batch 362.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 600/620 batches | lr 0.0001 | ms/batch 360.88 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 234.37s | valid loss/mse 0.0737 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0737
scGPT - INFO - | epoch   3 | 100/620 batches | lr 0.0001 | ms/batch 364.29 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/620 batches | lr 0.0001 | ms/batch 361.66 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/620 batches | lr 0.0001 | ms/batch 362.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/620 batches | lr 0.0001 | ms/batch 363.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/620 batches | lr 0.0001 | ms/batch 362.34 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 600/620 batches | lr 0.0001 | ms/batch 362.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 234.59s | valid loss/mse 0.0741 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   4 | 100/620 batches | lr 0.0001 | ms/batch 364.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 200/620 batches | lr 0.0001 | ms/batch 361.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/620 batches | lr 0.0001 | ms/batch 361.61 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 400/620 batches | lr 0.0001 | ms/batch 360.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/620 batches | lr 0.0001 | ms/batch 363.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 600/620 batches | lr 0.0001 | ms/batch 361.30 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 234.28s | valid loss/mse 0.0739 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   5 | 100/620 batches | lr 0.0001 | ms/batch 365.86 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/620 batches | lr 0.0001 | ms/batch 362.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/620 batches | lr 0.0001 | ms/batch 362.22 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 400/620 batches | lr 0.0001 | ms/batch 363.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/620 batches | lr 0.0001 | ms/batch 363.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 600/620 batches | lr 0.0001 | ms/batch 361.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 235.03s | valid loss/mse 0.0742 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/620 batches | lr 0.0001 | ms/batch 365.34 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/620 batches | lr 0.0001 | ms/batch 363.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/620 batches | lr 0.0001 | ms/batch 362.14 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/620 batches | lr 0.0001 | ms/batch 360.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/620 batches | lr 0.0001 | ms/batch 362.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 600/620 batches | lr 0.0001 | ms/batch 361.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 234.53s | valid loss/mse 0.0745 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   7 | 100/620 batches | lr 0.0001 | ms/batch 364.96 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/620 batches | lr 0.0001 | ms/batch 363.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/620 batches | lr 0.0001 | ms/batch 363.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/620 batches | lr 0.0001 | ms/batch 362.65 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/620 batches | lr 0.0001 | ms/batch 363.83 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 600/620 batches | lr 0.0001 | ms/batch 361.23 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 234.86s | valid loss/mse 0.0740 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 7
---Creating test_res
test_res saved successfully----
Split1 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRi/scgpt/split2
scGPT - INFO - Running on 2024-07-26 23:21:20
scGPT - INFO - match 3830/5153 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/612 batches | lr 0.0001 | ms/batch 373.45 | loss  0.18 | mse  0.18 |
scGPT - INFO - | epoch   1 | 200/612 batches | lr 0.0001 | ms/batch 367.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/612 batches | lr 0.0001 | ms/batch 363.56 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/612 batches | lr 0.0001 | ms/batch 362.83 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/612 batches | lr 0.0001 | ms/batch 363.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   1 | 600/612 batches | lr 0.0001 | ms/batch 363.06 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 234.97s | valid loss/mse 0.0769 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0769
scGPT - INFO - | epoch   2 | 100/612 batches | lr 0.0001 | ms/batch 368.59 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/612 batches | lr 0.0001 | ms/batch 361.87 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/612 batches | lr 0.0001 | ms/batch 361.52 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/612 batches | lr 0.0001 | ms/batch 361.65 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/612 batches | lr 0.0001 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 600/612 batches | lr 0.0001 | ms/batch 361.80 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 233.16s | valid loss/mse 0.0782 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   3 | 100/612 batches | lr 0.0001 | ms/batch 365.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/612 batches | lr 0.0001 | ms/batch 361.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/612 batches | lr 0.0001 | ms/batch 361.51 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/612 batches | lr 0.0001 | ms/batch 361.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/612 batches | lr 0.0001 | ms/batch 361.50 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 600/612 batches | lr 0.0001 | ms/batch 361.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 232.75s | valid loss/mse 0.0768 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0768
scGPT - INFO - | epoch   4 | 100/612 batches | lr 0.0001 | ms/batch 364.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 200/612 batches | lr 0.0001 | ms/batch 361.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/612 batches | lr 0.0001 | ms/batch 361.45 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 400/612 batches | lr 0.0001 | ms/batch 361.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/612 batches | lr 0.0001 | ms/batch 361.34 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 600/612 batches | lr 0.0001 | ms/batch 361.71 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 232.70s | valid loss/mse 0.0758 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0758
scGPT - INFO - | epoch   5 | 100/612 batches | lr 0.0001 | ms/batch 365.11 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 200/612 batches | lr 0.0001 | ms/batch 361.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/612 batches | lr 0.0001 | ms/batch 361.50 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 400/612 batches | lr 0.0001 | ms/batch 361.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/612 batches | lr 0.0001 | ms/batch 361.68 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 600/612 batches | lr 0.0001 | ms/batch 361.78 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 232.82s | valid loss/mse 0.0765 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   6 | 100/612 batches | lr 0.0001 | ms/batch 365.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 200/612 batches | lr 0.0001 | ms/batch 361.68 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/612 batches | lr 0.0001 | ms/batch 361.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/612 batches | lr 0.0001 | ms/batch 361.61 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/612 batches | lr 0.0001 | ms/batch 361.41 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 600/612 batches | lr 0.0001 | ms/batch 361.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 232.72s | valid loss/mse 0.0755 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0755
scGPT - INFO - | epoch   7 | 100/612 batches | lr 0.0001 | ms/batch 365.06 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/612 batches | lr 0.0001 | ms/batch 361.62 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/612 batches | lr 0.0001 | ms/batch 361.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/612 batches | lr 0.0001 | ms/batch 361.82 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/612 batches | lr 0.0001 | ms/batch 361.79 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 600/612 batches | lr 0.0001 | ms/batch 361.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 232.82s | valid loss/mse 0.0760 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/612 batches | lr 0.0000 | ms/batch 365.38 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/612 batches | lr 0.0000 | ms/batch 361.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/612 batches | lr 0.0000 | ms/batch 361.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 400/612 batches | lr 0.0000 | ms/batch 362.04 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 500/612 batches | lr 0.0000 | ms/batch 361.60 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 600/612 batches | lr 0.0000 | ms/batch 362.02 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 232.94s | valid loss/mse 0.0758 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/612 batches | lr 0.0000 | ms/batch 365.31 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/612 batches | lr 0.0000 | ms/batch 362.06 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/612 batches | lr 0.0000 | ms/batch 361.86 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 400/612 batches | lr 0.0000 | ms/batch 362.19 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 500/612 batches | lr 0.0000 | ms/batch 361.91 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 600/612 batches | lr 0.0000 | ms/batch 362.04 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 233.01s | valid loss/mse 0.0760 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/612 batches | lr 0.0000 | ms/batch 365.32 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/612 batches | lr 0.0000 | ms/batch 361.88 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/612 batches | lr 0.0000 | ms/batch 361.96 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 400/612 batches | lr 0.0000 | ms/batch 362.01 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 500/612 batches | lr 0.0000 | ms/batch 361.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 600/612 batches | lr 0.0000 | ms/batch 362.47 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 233.04s | valid loss/mse 0.0750 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0750
scGPT - INFO - | epoch  11 | 100/612 batches | lr 0.0000 | ms/batch 365.87 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/612 batches | lr 0.0000 | ms/batch 362.53 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/612 batches | lr 0.0000 | ms/batch 362.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 400/612 batches | lr 0.0000 | ms/batch 362.36 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 500/612 batches | lr 0.0000 | ms/batch 362.00 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 600/612 batches | lr 0.0000 | ms/batch 362.01 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 233.17s | valid loss/mse 0.0759 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  12 | 100/612 batches | lr 0.0000 | ms/batch 365.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 200/612 batches | lr 0.0000 | ms/batch 361.97 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 300/612 batches | lr 0.0000 | ms/batch 361.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 400/612 batches | lr 0.0000 | ms/batch 361.92 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 500/612 batches | lr 0.0000 | ms/batch 361.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  12 | 600/612 batches | lr 0.0000 | ms/batch 361.84 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  12 | time: 232.95s | valid loss/mse 0.0757 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  13 | 100/612 batches | lr 0.0000 | ms/batch 365.58 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 200/612 batches | lr 0.0000 | ms/batch 362.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 300/612 batches | lr 0.0000 | ms/batch 362.07 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 400/612 batches | lr 0.0000 | ms/batch 361.81 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 500/612 batches | lr 0.0000 | ms/batch 361.98 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  13 | 600/612 batches | lr 0.0000 | ms/batch 362.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  13 | time: 233.06s | valid loss/mse 0.0756 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  14 | 100/612 batches | lr 0.0000 | ms/batch 365.93 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 200/612 batches | lr 0.0000 | ms/batch 362.27 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 300/612 batches | lr 0.0000 | ms/batch 362.18 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 400/612 batches | lr 0.0000 | ms/batch 362.27 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 500/612 batches | lr 0.0000 | ms/batch 362.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  14 | 600/612 batches | lr 0.0000 | ms/batch 362.37 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  14 | time: 233.19s | valid loss/mse 0.0763 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  15 | 100/612 batches | lr 0.0000 | ms/batch 365.94 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 200/612 batches | lr 0.0000 | ms/batch 362.28 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 300/612 batches | lr 0.0000 | ms/batch 362.25 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 400/612 batches | lr 0.0000 | ms/batch 362.21 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 500/612 batches | lr 0.0000 | ms/batch 362.00 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  15 | 600/612 batches | lr 0.0000 | ms/batch 361.95 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  15 | time: 233.11s | valid loss/mse 0.0762 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 15
---Creating test_res
test_res saved successfully----
Split2 computation completed
saving to /home/share/huadjyin/home/zhoumin3/zhoumin/model_benchmark/01_A_results/TianKampmann2021_CRISPRi/scgpt/split3
scGPT - INFO - Running on 2024-07-27 00:35:50
scGPT - INFO - match 3830/5153 genes in vocabulary of size 60697.
scGPT - INFO - Resume model from /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/best_model.pt, the model args will override the config /home/share/huadjyin/home/zhoumin3/zhoumin/scgpt/scGPT_human/args.json.
Using simple batchnorm instead of domain specific batchnorm
scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])
scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])
scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])
scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])
scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])
scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])
scGPT - INFO - | epoch   1 | 100/636 batches | lr 0.0001 | ms/batch 365.28 | loss  0.19 | mse  0.19 |
scGPT - INFO - | epoch   1 | 200/636 batches | lr 0.0001 | ms/batch 361.51 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 300/636 batches | lr 0.0001 | ms/batch 361.31 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 400/636 batches | lr 0.0001 | ms/batch 361.19 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 500/636 batches | lr 0.0001 | ms/batch 361.14 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   1 | 600/636 batches | lr 0.0001 | ms/batch 361.33 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   1 | time: 238.95s | valid loss/mse 0.0758 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0758
scGPT - INFO - | epoch   2 | 100/636 batches | lr 0.0001 | ms/batch 365.04 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   2 | 200/636 batches | lr 0.0001 | ms/batch 361.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 300/636 batches | lr 0.0001 | ms/batch 361.23 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 400/636 batches | lr 0.0001 | ms/batch 361.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 500/636 batches | lr 0.0001 | ms/batch 361.61 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   2 | 600/636 batches | lr 0.0001 | ms/batch 361.37 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   2 | time: 238.93s | valid loss/mse 0.0740 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0740
scGPT - INFO - | epoch   3 | 100/636 batches | lr 0.0001 | ms/batch 365.10 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 200/636 batches | lr 0.0001 | ms/batch 361.23 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 300/636 batches | lr 0.0001 | ms/batch 361.00 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 400/636 batches | lr 0.0001 | ms/batch 361.33 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 500/636 batches | lr 0.0001 | ms/batch 361.40 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   3 | 600/636 batches | lr 0.0001 | ms/batch 361.43 | loss  0.08 | mse  0.08 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   3 | time: 238.84s | valid loss/mse 0.0738 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0738
scGPT - INFO - | epoch   4 | 100/636 batches | lr 0.0001 | ms/batch 365.05 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   4 | 200/636 batches | lr 0.0001 | ms/batch 361.49 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 300/636 batches | lr 0.0001 | ms/batch 361.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 400/636 batches | lr 0.0001 | ms/batch 361.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 500/636 batches | lr 0.0001 | ms/batch 361.53 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   4 | 600/636 batches | lr 0.0001 | ms/batch 361.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   4 | time: 238.97s | valid loss/mse 0.0737 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0737
scGPT - INFO - | epoch   5 | 100/636 batches | lr 0.0001 | ms/batch 365.26 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   5 | 200/636 batches | lr 0.0001 | ms/batch 361.54 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 300/636 batches | lr 0.0001 | ms/batch 361.63 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 400/636 batches | lr 0.0001 | ms/batch 361.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 500/636 batches | lr 0.0001 | ms/batch 361.52 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   5 | 600/636 batches | lr 0.0001 | ms/batch 361.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   5 | time: 239.04s | valid loss/mse 0.0733 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0733
scGPT - INFO - | epoch   6 | 100/636 batches | lr 0.0001 | ms/batch 364.97 | loss  0.08 | mse  0.08 |
scGPT - INFO - | epoch   6 | 200/636 batches | lr 0.0001 | ms/batch 361.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 300/636 batches | lr 0.0001 | ms/batch 361.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 400/636 batches | lr 0.0001 | ms/batch 361.44 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 500/636 batches | lr 0.0001 | ms/batch 361.38 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   6 | 600/636 batches | lr 0.0001 | ms/batch 361.39 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   6 | time: 238.89s | valid loss/mse 0.0731 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Best model with score 0.0731
scGPT - INFO - | epoch   7 | 100/636 batches | lr 0.0001 | ms/batch 365.12 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 200/636 batches | lr 0.0001 | ms/batch 361.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 300/636 batches | lr 0.0001 | ms/batch 361.77 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 400/636 batches | lr 0.0001 | ms/batch 361.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 500/636 batches | lr 0.0001 | ms/batch 361.67 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   7 | 600/636 batches | lr 0.0001 | ms/batch 361.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   7 | time: 239.06s | valid loss/mse 0.0739 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   8 | 100/636 batches | lr 0.0000 | ms/batch 365.35 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 200/636 batches | lr 0.0000 | ms/batch 361.64 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 300/636 batches | lr 0.0000 | ms/batch 361.73 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 400/636 batches | lr 0.0000 | ms/batch 361.72 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 500/636 batches | lr 0.0000 | ms/batch 361.57 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   8 | 600/636 batches | lr 0.0000 | ms/batch 361.74 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   8 | time: 239.09s | valid loss/mse 0.0734 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch   9 | 100/636 batches | lr 0.0000 | ms/batch 365.27 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 200/636 batches | lr 0.0000 | ms/batch 361.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 300/636 batches | lr 0.0000 | ms/batch 361.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 400/636 batches | lr 0.0000 | ms/batch 361.69 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 500/636 batches | lr 0.0000 | ms/batch 361.55 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch   9 | 600/636 batches | lr 0.0000 | ms/batch 361.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch   9 | time: 239.04s | valid loss/mse 0.0732 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  10 | 100/636 batches | lr 0.0000 | ms/batch 365.27 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 200/636 batches | lr 0.0000 | ms/batch 361.59 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 300/636 batches | lr 0.0000 | ms/batch 362.29 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 400/636 batches | lr 0.0000 | ms/batch 362.17 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 500/636 batches | lr 0.0000 | ms/batch 361.85 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  10 | 600/636 batches | lr 0.0000 | ms/batch 361.84 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  10 | time: 239.23s | valid loss/mse 0.0737 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | epoch  11 | 100/636 batches | lr 0.0000 | ms/batch 365.47 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 200/636 batches | lr 0.0000 | ms/batch 361.76 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 300/636 batches | lr 0.0000 | ms/batch 361.83 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 400/636 batches | lr 0.0000 | ms/batch 361.68 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 500/636 batches | lr 0.0000 | ms/batch 361.75 | loss  0.07 | mse  0.07 |
scGPT - INFO - | epoch  11 | 600/636 batches | lr 0.0000 | ms/batch 361.70 | loss  0.07 | mse  0.07 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - | end of epoch  11 | time: 239.14s | valid loss/mse 0.0738 |
scGPT - INFO - -----------------------------------------------------------------------------------------
scGPT - INFO - Early stop at epoch 11
---Creating test_res
