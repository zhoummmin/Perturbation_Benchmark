Loading compilers/gcc/12.2.0
  ERROR: Module cannot be loaded due to a conflict.
    HINT: Might try "module unload compilers/gcc" first.
cmake-3.27.0 loaded successful
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_081012-xlr7kuz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRa_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/xlr7kuz3
wandb: WARNING Serializing object of type ndarray that is 8054528 bytes
  0%|                                                                                       | 0/3536 [00:00<?, ?it/s]  0%|‚ñè                                                                              | 7/3536 [00:00<00:54, 65.20it/s]  0%|‚ñé                                                                             | 15/3536 [00:00<00:49, 70.61it/s]  1%|‚ñå                                                                             | 23/3536 [00:00<00:48, 72.84it/s]  1%|‚ñã                                                                             | 32/3536 [00:00<00:44, 77.93it/s]  1%|‚ñâ                                                                             | 41/3536 [00:00<00:44, 78.85it/s]  1%|‚ñà                                                                             | 49/3536 [00:00<00:44, 77.97it/s]  2%|‚ñà‚ñé                                                                            | 58/3536 [00:00<00:44, 78.81it/s]  2%|‚ñà‚ñç                                                                            | 66/3536 [00:00<00:43, 78.92it/s]  2%|‚ñà‚ñã                                                                            | 74/3536 [00:00<00:44, 78.34it/s]  2%|‚ñà‚ñä                                                                            | 82/3536 [00:01<00:44, 78.43it/s]  3%|‚ñà‚ñâ                                                                            | 90/3536 [00:01<00:43, 78.70it/s]  3%|‚ñà‚ñà‚ñè                                                                           | 99/3536 [00:01<00:43, 79.33it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 108/3536 [00:01<00:42, 79.82it/s]  3%|‚ñà‚ñà‚ñå                                                                          | 117/3536 [00:01<00:42, 79.90it/s]  4%|‚ñà‚ñà‚ñã                                                                          | 126/3536 [00:01<00:42, 80.43it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 135/3536 [00:01<00:43, 78.28it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 145/3536 [00:01<00:41, 82.02it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 154/3536 [00:01<00:41, 82.18it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 163/3536 [00:02<00:41, 81.87it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 172/3536 [00:02<00:41, 81.34it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 181/3536 [00:02<00:40, 81.93it/s]  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                        | 190/3536 [00:02<00:41, 80.01it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 200/3536 [00:02<00:39, 83.58it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 209/3536 [00:02<00:39, 83.24it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 218/3536 [00:02<00:40, 82.64it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 227/3536 [00:02<00:40, 82.58it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 236/3536 [00:02<00:41, 80.35it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 246/3536 [00:03<00:39, 84.28it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 255/3536 [00:03<00:39, 84.02it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 264/3536 [00:03<00:38, 84.00it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 273/3536 [00:03<00:38, 83.89it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 282/3536 [00:03<00:40, 81.26it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 292/3536 [00:03<00:38, 83.87it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 301/3536 [00:03<00:39, 82.66it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 310/3536 [00:03<00:38, 82.73it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 319/3536 [00:03<00:39, 82.48it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 328/3536 [00:04<00:40, 79.57it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 337/3536 [00:04<00:39, 81.92it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 346/3536 [00:04<00:39, 80.82it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 355/3536 [00:04<00:39, 80.74it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 364/3536 [00:04<00:38, 81.52it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 373/3536 [00:04<00:38, 81.28it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 382/3536 [00:04<00:38, 81.11it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 391/3536 [00:04<00:38, 80.78it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 400/3536 [00:04<00:38, 80.68it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 409/3536 [00:05<00:38, 80.58it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 418/3536 [00:05<00:38, 80.44it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 427/3536 [00:05<00:38, 80.61it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 436/3536 [00:05<00:38, 80.45it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 445/3536 [00:05<00:38, 80.59it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 454/3536 [00:05<00:38, 81.10it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 463/3536 [00:05<00:38, 79.65it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 471/3536 [00:05<00:38, 79.69it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 480/3536 [00:05<00:38, 79.90it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 488/3536 [00:06<00:38, 79.84it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 496/3536 [00:06<00:38, 79.80it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 504/3536 [00:06<00:39, 77.19it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 514/3536 [00:06<00:38, 78.70it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 523/3536 [00:06<00:36, 81.67it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 532/3536 [00:06<00:36, 81.84it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 541/3536 [00:06<00:36, 81.52it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 550/3536 [00:06<00:36, 81.36it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 559/3536 [00:06<00:36, 81.53it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 568/3536 [00:07<00:36, 81.63it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 577/3536 [00:07<00:37, 78.80it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 587/3536 [00:07<00:35, 82.09it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 596/3536 [00:07<00:36, 81.40it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 605/3536 [00:07<00:36, 79.22it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 615/3536 [00:07<00:35, 82.80it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 624/3536 [00:07<00:35, 82.58it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 633/3536 [00:07<00:36, 78.90it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 642/3536 [00:07<00:35, 81.49it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 651/3536 [00:08<00:35, 80.48it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 660/3536 [00:08<00:35, 81.22it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 669/3536 [00:08<00:34, 82.07it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 678/3536 [00:08<00:34, 82.57it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 687/3536 [00:08<00:34, 82.83it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 696/3536 [00:08<00:34, 83.30it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 705/3536 [00:08<00:34, 83.02it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 714/3536 [00:08<00:34, 82.88it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 723/3536 [00:08<00:35, 79.80it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 733/3536 [00:09<00:33, 83.15it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 742/3536 [00:09<00:33, 82.94it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                            | 751/3536 [00:09<00:34, 80.24it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 760/3536 [00:09<00:33, 82.70it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                            | 769/3536 [00:09<00:33, 82.08it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                            | 778/3536 [00:09<00:33, 81.26it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 787/3536 [00:09<00:33, 81.18it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 796/3536 [00:09<00:33, 81.67it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 805/3536 [00:09<00:33, 81.35it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 814/3536 [00:10<00:33, 81.62it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 823/3536 [00:10<00:33, 81.30it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 832/3536 [00:10<00:33, 81.04it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 841/3536 [00:10<00:33, 81.22it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 850/3536 [00:10<00:32, 81.43it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 859/3536 [00:10<00:32, 81.14it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 868/3536 [00:10<00:32, 81.00it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 877/3536 [00:10<00:32, 80.87it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 886/3536 [00:10<00:32, 80.48it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 895/3536 [00:11<00:32, 80.81it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 904/3536 [00:11<00:32, 80.30it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                         | 913/3536 [00:11<00:32, 80.79it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 922/3536 [00:11<00:32, 81.36it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 931/3536 [00:11<00:33, 77.66it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                        | 940/3536 [00:11<00:33, 78.28it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 949/3536 [00:11<00:31, 80.95it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 958/3536 [00:11<00:32, 78.26it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 968/3536 [00:11<00:31, 81.95it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 977/3536 [00:12<00:31, 81.24it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 986/3536 [00:12<00:31, 81.26it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 995/3536 [00:12<00:32, 77.33it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 1003/3536 [00:12<00:33, 74.51it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 1011/3536 [00:12<00:34, 72.41it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 1019/3536 [00:12<00:36, 68.66it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1027/3536 [00:12<00:35, 71.21it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 1035/3536 [00:12<00:35, 70.64it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1043/3536 [00:13<00:35, 70.51it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 1051/3536 [00:13<00:35, 70.84it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1059/3536 [00:13<00:35, 70.47it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                     | 1067/3536 [00:13<00:35, 70.39it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1075/3536 [00:13<00:34, 70.45it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1083/3536 [00:13<00:34, 70.88it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1091/3536 [00:13<00:34, 70.50it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 1099/3536 [00:13<00:34, 71.05it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1107/3536 [00:13<00:34, 71.38it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 1115/3536 [00:14<00:33, 71.79it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1123/3536 [00:14<00:33, 72.10it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1131/3536 [00:14<00:33, 71.93it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1139/3536 [00:14<00:33, 72.07it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1147/3536 [00:14<00:33, 72.10it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1155/3536 [00:14<00:33, 71.85it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1163/3536 [00:14<00:33, 71.72it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1171/3536 [00:14<00:32, 71.81it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 1179/3536 [00:14<00:32, 72.11it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1187/3536 [00:15<00:32, 71.90it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 1195/3536 [00:15<00:32, 71.59it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1203/3536 [00:15<00:32, 71.79it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1211/3536 [00:15<00:32, 71.81it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1219/3536 [00:15<00:32, 72.27it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1227/3536 [00:15<00:32, 72.04it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1235/3536 [00:15<00:31, 71.99it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1243/3536 [00:15<00:33, 69.24it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 1252/3536 [00:15<00:31, 72.39it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1260/3536 [00:16<00:32, 69.94it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1269/3536 [00:16<00:30, 73.51it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 1277/3536 [00:16<00:30, 73.06it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1285/3536 [00:16<00:30, 73.14it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 1293/3536 [00:16<00:30, 72.74it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1301/3536 [00:16<00:30, 72.59it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1309/3536 [00:16<00:30, 73.02it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1317/3536 [00:16<00:30, 72.71it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1325/3536 [00:16<00:30, 72.71it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1333/3536 [00:17<00:30, 73.38it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1341/3536 [00:17<00:30, 72.99it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 1349/3536 [00:17<00:29, 73.24it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1357/3536 [00:17<00:29, 73.15it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1365/3536 [00:17<00:29, 72.53it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1373/3536 [00:17<00:29, 72.81it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                              | 1381/3536 [00:17<00:29, 72.86it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1389/3536 [00:17<00:29, 72.59it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1397/3536 [00:17<00:29, 72.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1405/3536 [00:18<00:29, 72.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                             | 1413/3536 [00:18<00:29, 72.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 1421/3536 [00:18<00:30, 69.87it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1430/3536 [00:18<00:28, 73.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1438/3536 [00:18<00:28, 73.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 1446/3536 [00:18<00:28, 73.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1454/3536 [00:18<00:28, 73.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 1462/3536 [00:18<00:28, 73.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1470/3536 [00:18<00:28, 72.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                            | 1478/3536 [00:19<00:28, 72.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1486/3536 [00:19<00:28, 72.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 1494/3536 [00:19<00:27, 72.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 1502/3536 [00:19<00:29, 69.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 1511/3536 [00:19<00:27, 73.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 1519/3536 [00:19<00:27, 73.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 1527/3536 [00:19<00:27, 73.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 1535/3536 [00:19<00:27, 72.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 1543/3536 [00:19<00:27, 71.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 1551/3536 [00:20<00:27, 71.66it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1559/3536 [00:20<00:27, 71.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 1567/3536 [00:20<00:27, 71.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1576/3536 [00:20<00:26, 73.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 1586/3536 [00:20<00:24, 79.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 1595/3536 [00:20<00:23, 81.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 1604/3536 [00:20<00:23, 82.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 1613/3536 [00:20<00:23, 82.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 1622/3536 [00:20<00:23, 81.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 1631/3536 [00:21<00:23, 81.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1640/3536 [00:21<00:23, 81.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 1649/3536 [00:21<00:23, 80.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 1658/3536 [00:21<00:27, 67.90it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 1671/3536 [00:21<00:22, 82.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1680/3536 [00:21<00:22, 81.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 1689/3536 [00:21<00:22, 81.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 1698/3536 [00:21<00:22, 81.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 1707/3536 [00:21<00:22, 81.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 1716/3536 [00:22<00:23, 78.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 1726/3536 [00:22<00:22, 82.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 1735/3536 [00:22<00:21, 82.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1744/3536 [00:22<00:21, 82.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1753/3536 [00:22<00:22, 80.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 1763/3536 [00:22<00:21, 83.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1772/3536 [00:22<00:21, 80.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1782/3536 [00:22<00:21, 83.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 1791/3536 [00:23<00:21, 82.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 1800/3536 [00:23<00:21, 82.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 1809/3536 [00:23<00:20, 82.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 1818/3536 [00:23<00:21, 79.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 1828/3536 [00:23<00:21, 79.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 1837/3536 [00:23<00:20, 82.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 1846/3536 [00:23<00:20, 81.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 1855/3536 [00:23<00:21, 78.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 1864/3536 [00:23<00:21, 79.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 1873/3536 [00:24<00:20, 80.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1882/3536 [00:24<00:20, 80.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 1891/3536 [00:24<00:20, 81.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1900/3536 [00:24<00:20, 81.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 1909/3536 [00:24<00:20, 78.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 1917/3536 [00:24<00:21, 76.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 1926/3536 [00:24<00:20, 77.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 1934/3536 [00:24<00:20, 78.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 1943/3536 [00:24<00:19, 79.69it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 1952/3536 [00:25<00:19, 80.01it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 1961/3536 [00:25<00:19, 79.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 1970/3536 [00:25<00:20, 77.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 1980/3536 [00:25<00:19, 78.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 1990/3536 [00:25<00:18, 81.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 1999/3536 [00:25<00:18, 81.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 2008/3536 [00:25<00:18, 81.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2017/3536 [00:25<00:18, 81.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 2026/3536 [00:25<00:18, 80.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2035/3536 [00:26<00:19, 78.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 2043/3536 [00:26<00:19, 77.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 2051/3536 [00:26<00:19, 76.12it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2061/3536 [00:26<00:18, 80.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2070/3536 [00:26<00:18, 80.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2079/3536 [00:26<00:17, 81.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 2088/3536 [00:26<00:17, 81.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 2097/3536 [00:26<00:17, 81.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2106/3536 [00:26<00:17, 81.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 2115/3536 [00:27<00:18, 76.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2123/3536 [00:27<00:20, 70.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 2131/3536 [00:27<00:20, 69.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2138/3536 [00:27<00:21, 66.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2145/3536 [00:27<00:22, 61.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2152/3536 [00:27<00:21, 63.41it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2159/3536 [00:27<00:21, 64.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 2169/3536 [00:27<00:18, 72.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2177/3536 [00:28<00:19, 71.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2188/3536 [00:28<00:16, 79.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2197/3536 [00:28<00:16, 81.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2206/3536 [00:28<00:16, 81.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2215/3536 [00:28<00:16, 81.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2224/3536 [00:28<00:16, 81.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2233/3536 [00:28<00:16, 79.46it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 2243/3536 [00:28<00:15, 82.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 2252/3536 [00:28<00:15, 82.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 2261/3536 [00:29<00:15, 79.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 2270/3536 [00:29<00:15, 79.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 2280/3536 [00:29<00:15, 82.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 2289/3536 [00:29<00:15, 82.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 2298/3536 [00:29<00:14, 83.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2307/3536 [00:29<00:14, 83.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 2316/3536 [00:29<00:14, 82.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 2325/3536 [00:29<00:14, 82.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 2334/3536 [00:29<00:14, 83.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 2343/3536 [00:30<00:14, 83.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 2352/3536 [00:30<00:14, 83.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 2361/3536 [00:30<00:14, 83.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 2370/3536 [00:30<00:13, 83.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 2379/3536 [00:30<00:13, 84.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2388/3536 [00:30<00:13, 83.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2397/3536 [00:30<00:14, 81.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2406/3536 [00:30<00:13, 81.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2415/3536 [00:30<00:13, 82.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2425/3536 [00:31<00:13, 82.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2435/3536 [00:31<00:12, 85.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2444/3536 [00:31<00:13, 83.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2453/3536 [00:31<00:12, 83.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2462/3536 [00:31<00:12, 83.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2471/3536 [00:31<00:12, 82.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2480/3536 [00:31<00:12, 82.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2489/3536 [00:31<00:13, 79.89it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2498/3536 [00:31<00:12, 80.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2507/3536 [00:32<00:12, 80.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2517/3536 [00:32<00:12, 83.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2526/3536 [00:32<00:12, 80.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2536/3536 [00:32<00:11, 83.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2545/3536 [00:32<00:11, 82.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2554/3536 [00:32<00:11, 83.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2563/3536 [00:32<00:11, 81.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2572/3536 [00:32<00:11, 81.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2581/3536 [00:32<00:12, 77.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2590/3536 [00:33<00:11, 79.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2598/3536 [00:33<00:12, 74.51it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2606/3536 [00:33<00:12, 75.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2614/3536 [00:33<00:12, 72.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2622/3536 [00:33<00:12, 71.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2630/3536 [00:33<00:12, 70.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2638/3536 [00:33<00:12, 70.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2646/3536 [00:33<00:12, 69.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2653/3536 [00:33<00:12, 69.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2661/3536 [00:34<00:12, 69.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2668/3536 [00:34<00:12, 69.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2676/3536 [00:34<00:12, 67.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2684/3536 [00:34<00:12, 70.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2692/3536 [00:34<00:12, 69.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2699/3536 [00:34<00:12, 69.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2706/3536 [00:34<00:11, 69.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2713/3536 [00:34<00:12, 68.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2721/3536 [00:34<00:11, 68.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2728/3536 [00:35<00:12, 64.07it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2736/3536 [00:35<00:11, 67.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2743/3536 [00:35<00:11, 67.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 2750/3536 [00:35<00:11, 68.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2758/3536 [00:35<00:11, 68.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2765/3536 [00:35<00:11, 66.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 2774/3536 [00:35<00:10, 69.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2782/3536 [00:35<00:10, 69.83it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 2790/3536 [00:35<00:10, 69.86it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2798/3536 [00:36<00:10, 70.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2806/3536 [00:36<00:10, 69.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2813/3536 [00:36<00:10, 69.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2821/3536 [00:36<00:10, 70.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2829/3536 [00:36<00:10, 70.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2837/3536 [00:36<00:10, 69.58it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 2844/3536 [00:36<00:09, 69.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2852/3536 [00:36<00:09, 69.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 2859/3536 [00:36<00:09, 69.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2866/3536 [00:37<00:09, 68.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2874/3536 [00:37<00:09, 66.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 2882/3536 [00:37<00:09, 69.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2890/3536 [00:37<00:09, 69.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 2897/3536 [00:37<00:09, 67.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2905/3536 [00:37<00:08, 70.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2913/3536 [00:37<00:08, 70.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2921/3536 [00:37<00:08, 70.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2929/3536 [00:37<00:08, 70.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2937/3536 [00:38<00:08, 69.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2945/3536 [00:38<00:08, 69.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2953/3536 [00:38<00:09, 63.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2963/3536 [00:38<00:07, 72.31it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 2971/3536 [00:38<00:07, 71.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 2979/3536 [00:38<00:07, 71.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 2987/3536 [00:38<00:07, 71.25it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 2995/3536 [00:38<00:07, 70.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3003/3536 [00:39<00:07, 68.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3010/3536 [00:39<00:07, 67.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3018/3536 [00:39<00:07, 70.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3026/3536 [00:39<00:07, 71.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3034/3536 [00:39<00:06, 73.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3042/3536 [00:39<00:06, 74.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3052/3536 [00:39<00:06, 79.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3061/3536 [00:39<00:05, 80.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3070/3536 [00:39<00:05, 81.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3079/3536 [00:39<00:05, 82.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 3088/3536 [00:40<00:05, 82.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 3097/3536 [00:40<00:05, 83.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 3106/3536 [00:40<00:05, 83.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 3115/3536 [00:40<00:05, 83.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 3124/3536 [00:40<00:05, 81.57it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 3134/3536 [00:40<00:04, 84.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 3143/3536 [00:40<00:04, 84.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 3152/3536 [00:40<00:04, 81.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 3162/3536 [00:40<00:04, 84.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 3171/3536 [00:41<00:04, 84.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 3180/3536 [00:41<00:04, 80.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 3190/3536 [00:41<00:04, 83.40it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 3199/3536 [00:41<00:04, 83.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 3208/3536 [00:41<00:04, 80.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 3217/3536 [00:41<00:03, 81.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 3226/3536 [00:41<00:03, 79.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3234/3536 [00:41<00:03, 79.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 3242/3536 [00:41<00:03, 77.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3250/3536 [00:42<00:03, 76.31it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 3258/3536 [00:42<00:03, 76.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 3266/3536 [00:42<00:03, 76.27it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3274/3536 [00:42<00:03, 75.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3282/3536 [00:42<00:03, 75.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 3290/3536 [00:42<00:03, 75.27it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3298/3536 [00:42<00:03, 75.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3306/3536 [00:42<00:03, 74.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3314/3536 [00:42<00:03, 73.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3322/3536 [00:43<00:02, 74.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3330/3536 [00:43<00:02, 74.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3338/3536 [00:43<00:02, 72.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3346/3536 [00:43<00:02, 72.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3354/3536 [00:43<00:02, 72.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3362/3536 [00:43<00:02, 70.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3371/3536 [00:43<00:02, 73.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3379/3536 [00:43<00:02, 72.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3387/3536 [00:43<00:02, 69.36it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3395/3536 [00:44<00:02, 70.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3403/3536 [00:44<00:01, 68.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3411/3536 [00:44<00:01, 70.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3419/3536 [00:44<00:01, 71.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3427/3536 [00:44<00:01, 72.60it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3435/3536 [00:44<00:01, 73.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3443/3536 [00:44<00:01, 69.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3453/3536 [00:44<00:01, 76.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3461/3536 [00:44<00:00, 76.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3469/3536 [00:45<00:00, 73.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3478/3536 [00:45<00:00, 77.41it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3486/3536 [00:45<00:00, 77.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3494/3536 [00:45<00:00, 77.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3502/3536 [00:45<00:00, 74.57it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3511/3536 [00:45<00:00, 78.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3519/3536 [00:45<00:00, 76.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3527/3536 [00:45<00:00, 76.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3535/3536 [00:45<00:00, 77.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3536/3536 [00:45<00:00, 76.97it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.4492
Epoch 1 Step 51 Train Loss: 0.5264
Epoch 1 Step 101 Train Loss: 0.5232
Epoch 1 Step 151 Train Loss: 0.4848
Epoch 1 Step 201 Train Loss: 0.4643
Epoch 1 Step 251 Train Loss: 0.4528
Epoch 1 Step 301 Train Loss: 0.4899
Epoch 1 Step 351 Train Loss: 0.4780
Epoch 1: Train Overall MSE: 0.1787 Validation Overall MSE: 0.1795. 
Train Top 20 DE MSE: 0.3914 Validation Top 20 DE MSE: 0.3552. 
Epoch 2 Step 1 Train Loss: 0.4837
Epoch 2 Step 51 Train Loss: 0.5740
Epoch 2 Step 101 Train Loss: 0.4901
Epoch 2 Step 151 Train Loss: 0.5743
Epoch 2 Step 201 Train Loss: 0.4748
Epoch 2 Step 251 Train Loss: 0.4546
Epoch 2 Step 301 Train Loss: 0.4851
Epoch 2 Step 351 Train Loss: 0.4122
Epoch 2: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0369 Validation Top 20 DE MSE: 0.0380. 
Epoch 3 Step 1 Train Loss: 0.4712
Epoch 3 Step 51 Train Loss: 0.4720
Epoch 3 Step 101 Train Loss: 0.4802
Epoch 3 Step 151 Train Loss: 0.4945
Epoch 3 Step 201 Train Loss: 0.4308
Epoch 3 Step 251 Train Loss: 0.4927
Epoch 3 Step 301 Train Loss: 0.5357
Epoch 3 Step 351 Train Loss: 0.4490
Epoch 3: Train Overall MSE: 0.0099 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.0825 Validation Top 20 DE MSE: 0.0256. 
Epoch 4 Step 1 Train Loss: 0.4373
Epoch 4 Step 51 Train Loss: 0.4462
Epoch 4 Step 101 Train Loss: 0.4760
Epoch 4 Step 151 Train Loss: 0.4785
Epoch 4 Step 201 Train Loss: 0.5009
Epoch 4 Step 251 Train Loss: 0.4452
Epoch 4 Step 301 Train Loss: 0.4320
Epoch 4 Step 351 Train Loss: 0.4489
Epoch 4: Train Overall MSE: 0.0089 Validation Overall MSE: 0.0084. 
Train Top 20 DE MSE: 0.0381 Validation Top 20 DE MSE: 0.0276. 
Epoch 5 Step 1 Train Loss: 0.4410
Epoch 5 Step 51 Train Loss: 0.5136
Epoch 5 Step 101 Train Loss: 0.4426
Epoch 5 Step 151 Train Loss: 0.4484
Epoch 5 Step 201 Train Loss: 0.4837
Epoch 5 Step 251 Train Loss: 0.4907
Epoch 5 Step 301 Train Loss: 0.5506
Epoch 5 Step 351 Train Loss: 0.4358
Epoch 5: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0271 Validation Top 20 DE MSE: 0.0356. 
Epoch 6 Step 1 Train Loss: 0.4828
Epoch 6 Step 51 Train Loss: 0.4434
Epoch 6 Step 101 Train Loss: 0.5484
Epoch 6 Step 151 Train Loss: 0.5293
Epoch 6 Step 201 Train Loss: 0.4773
Epoch 6 Step 251 Train Loss: 0.4545
Epoch 6 Step 301 Train Loss: 0.4488
Epoch 6 Step 351 Train Loss: 0.5384
Epoch 6: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0332 Validation Top 20 DE MSE: 0.0281. 
Epoch 7 Step 1 Train Loss: 0.4958
Epoch 7 Step 51 Train Loss: 0.4941
Epoch 7 Step 101 Train Loss: 0.5995
Epoch 7 Step 151 Train Loss: 0.4995
Epoch 7 Step 201 Train Loss: 0.4768
Epoch 7 Step 251 Train Loss: 0.5045
Epoch 7 Step 301 Train Loss: 0.5167
Epoch 7 Step 351 Train Loss: 0.4964
Epoch 7: Train Overall MSE: 0.0029 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0277 Validation Top 20 DE MSE: 0.0261. 
Epoch 8 Step 1 Train Loss: 0.5301
Epoch 8 Step 51 Train Loss: 0.5201
Epoch 8 Step 101 Train Loss: 0.4680
Epoch 8 Step 151 Train Loss: 0.4941
Epoch 8 Step 201 Train Loss: 0.5043
Epoch 8 Step 251 Train Loss: 0.5085
Epoch 8 Step 301 Train Loss: 0.4862
Epoch 8 Step 351 Train Loss: 0.5385
Epoch 8: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0262 Validation Top 20 DE MSE: 0.0345. 
Epoch 9 Step 1 Train Loss: 0.5598
Epoch 9 Step 51 Train Loss: 0.5342
Epoch 9 Step 101 Train Loss: 0.5273
Epoch 9 Step 151 Train Loss: 0.5005
Epoch 9 Step 201 Train Loss: 0.4647
Epoch 9 Step 251 Train Loss: 0.4238
Epoch 9 Step 301 Train Loss: 0.4890
Epoch 9 Step 351 Train Loss: 0.5423
Epoch 9: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0413 Validation Top 20 DE MSE: 0.0308. 
Epoch 10 Step 1 Train Loss: 0.5187
Epoch 10 Step 51 Train Loss: 0.5470
Epoch 10 Step 101 Train Loss: 0.5060
Epoch 10 Step 151 Train Loss: 0.4980
Epoch 10 Step 201 Train Loss: 0.4891
Epoch 10 Step 251 Train Loss: 0.4991
Epoch 10 Step 301 Train Loss: 0.4763
Epoch 10 Step 351 Train Loss: 0.4664
Epoch 10: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0274 Validation Top 20 DE MSE: 0.0304. 
Epoch 11 Step 1 Train Loss: 0.4938
Epoch 11 Step 51 Train Loss: 0.4594
Epoch 11 Step 101 Train Loss: 0.5226
Epoch 11 Step 151 Train Loss: 0.4657
Epoch 11 Step 201 Train Loss: 0.4680
Epoch 11 Step 251 Train Loss: 0.5003
Epoch 11 Step 301 Train Loss: 0.4891
Epoch 11 Step 351 Train Loss: 0.4805
Epoch 11: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0270 Validation Top 20 DE MSE: 0.0311. 
Epoch 12 Step 1 Train Loss: 0.4817
Epoch 12 Step 51 Train Loss: 0.5082
Epoch 12 Step 101 Train Loss: 0.4896
Epoch 12 Step 151 Train Loss: 0.4973
Epoch 12 Step 201 Train Loss: 0.4381
Epoch 12 Step 251 Train Loss: 0.4437
Epoch 12 Step 301 Train Loss: 0.4865
Epoch 12 Step 351 Train Loss: 0.4950
Epoch 12: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0354 Validation Top 20 DE MSE: 0.0321. 
Epoch 13 Step 1 Train Loss: 0.4823
Epoch 13 Step 51 Train Loss: 0.5042
Epoch 13 Step 101 Train Loss: 0.4255
Epoch 13 Step 151 Train Loss: 0.5210
Epoch 13 Step 201 Train Loss: 0.4641
Epoch 13 Step 251 Train Loss: 0.4701
Epoch 13 Step 301 Train Loss: 0.4740
Epoch 13 Step 351 Train Loss: 0.5246
Epoch 13: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0357 Validation Top 20 DE MSE: 0.0303. 
Epoch 14 Step 1 Train Loss: 0.4583
Epoch 14 Step 51 Train Loss: 0.5390
Epoch 14 Step 101 Train Loss: 0.4498
Epoch 14 Step 151 Train Loss: 0.4610
Epoch 14 Step 201 Train Loss: 0.4452
Epoch 14 Step 251 Train Loss: 0.4475
Epoch 14 Step 301 Train Loss: 0.4290
Epoch 14 Step 351 Train Loss: 0.4901
Epoch 14: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0350 Validation Top 20 DE MSE: 0.0322. 
Epoch 15 Step 1 Train Loss: 0.5180
Epoch 15 Step 51 Train Loss: 0.4164
Epoch 15 Step 101 Train Loss: 0.4914
Epoch 15 Step 151 Train Loss: 0.4587
Epoch 15 Step 201 Train Loss: 0.4872
Epoch 15 Step 251 Train Loss: 0.4901
Epoch 15 Step 301 Train Loss: 0.5139
Epoch 15 Step 351 Train Loss: 0.4766
Epoch 15: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0338 Validation Top 20 DE MSE: 0.0323. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0358
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.009159456
test_unseen_single_pearson: 0.9763516642661383
test_unseen_single_mse_de: 0.035762757
test_unseen_single_pearson_de: 0.9644810428024363
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.23767801675600506
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.30416666666666664
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8833333333333334
test_unseen_single_mse_top20_de_non_dropout: 0.037943378
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.011 MB of 0.022 MB uploadedwandb: / 0.011 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.03576
wandb:                                              test_de_pearson 0.96448
wandb:               test_frac_opposite_direction_top20_non_dropout 0.30417
wandb:                          test_frac_sigma_below_1_non_dropout 0.88333
wandb:                                                     test_mse 0.00916
wandb:                                test_mse_top20_de_non_dropout 0.03794
wandb:                                                 test_pearson 0.97635
wandb:                                           test_pearson_delta 0.23768
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.30417
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.88333
wandb:                                       test_unseen_single_mse 0.00916
wandb:                                    test_unseen_single_mse_de 0.03576
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.03794
wandb:                                   test_unseen_single_pearson 0.97635
wandb:                                test_unseen_single_pearson_de 0.96448
wandb:                             test_unseen_single_pearson_delta 0.23768
wandb:                                                 train_de_mse 0.03379
wandb:                                             train_de_pearson 0.94611
wandb:                                                    train_mse 0.00238
wandb:                                                train_pearson 0.99397
wandb:                                                training_loss 0.46418
wandb:                                                   val_de_mse 0.03233
wandb:                                               val_de_pearson 0.88698
wandb:                                                      val_mse 0.00231
wandb:                                                  val_pearson 0.99396
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRa_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/xlr7kuz3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_081012-xlr7kuz3/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_082442-33ofsz40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRa_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/33ofsz40
wandb: WARNING Serializing object of type ndarray that is 8054528 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5075
Epoch 1 Step 51 Train Loss: 0.4887
Epoch 1 Step 101 Train Loss: 0.4637
Epoch 1 Step 151 Train Loss: 0.5131
Epoch 1 Step 201 Train Loss: 0.4352
Epoch 1 Step 251 Train Loss: 0.5089
Epoch 1 Step 301 Train Loss: 0.4902
Epoch 1: Train Overall MSE: 1.3976 Validation Overall MSE: 1.4081. 
Train Top 20 DE MSE: 3.7855 Validation Top 20 DE MSE: 4.3802. 
Epoch 2 Step 1 Train Loss: 0.5284
Epoch 2 Step 51 Train Loss: 0.4463
Epoch 2 Step 101 Train Loss: 0.4517
Epoch 2 Step 151 Train Loss: 0.4772
Epoch 2 Step 201 Train Loss: 0.4878
Epoch 2 Step 251 Train Loss: 0.4956
Epoch 2 Step 301 Train Loss: 0.4939
Epoch 2: Train Overall MSE: 0.2298 Validation Overall MSE: 0.2279. 
Train Top 20 DE MSE: 0.6214 Validation Top 20 DE MSE: 0.5993. 
Epoch 3 Step 1 Train Loss: 0.5062
Epoch 3 Step 51 Train Loss: 0.5066
Epoch 3 Step 101 Train Loss: 0.5461
Epoch 3 Step 151 Train Loss: 0.5251
Epoch 3 Step 201 Train Loss: 0.4731
Epoch 3 Step 251 Train Loss: 0.4866
Epoch 3 Step 301 Train Loss: 0.4648
Epoch 3: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0218 Validation Top 20 DE MSE: 0.0207. 
Epoch 4 Step 1 Train Loss: 0.4740
Epoch 4 Step 51 Train Loss: 0.4778
Epoch 4 Step 101 Train Loss: 0.5766
Epoch 4 Step 151 Train Loss: 0.4962
Epoch 4 Step 201 Train Loss: 0.5114
Epoch 4 Step 251 Train Loss: 0.4594
Epoch 4 Step 301 Train Loss: 0.4429
Epoch 4: Train Overall MSE: 0.0654 Validation Overall MSE: 0.0599. 
Train Top 20 DE MSE: 0.2623 Validation Top 20 DE MSE: 0.2694. 
Epoch 5 Step 1 Train Loss: 0.4718
Epoch 5 Step 51 Train Loss: 0.4779
Epoch 5 Step 101 Train Loss: 0.4985
Epoch 5 Step 151 Train Loss: 0.4384
Epoch 5 Step 201 Train Loss: 0.4466
Epoch 5 Step 251 Train Loss: 0.5041
Epoch 5 Step 301 Train Loss: 0.5000
Epoch 5: Train Overall MSE: 0.0134 Validation Overall MSE: 0.0111. 
Train Top 20 DE MSE: 0.0606 Validation Top 20 DE MSE: 0.0541. 
Epoch 6 Step 1 Train Loss: 0.5137
Epoch 6 Step 51 Train Loss: 0.4522
Epoch 6 Step 101 Train Loss: 0.4480
Epoch 6 Step 151 Train Loss: 0.4937
Epoch 6 Step 201 Train Loss: 0.5210
Epoch 6 Step 251 Train Loss: 0.4658
Epoch 6 Step 301 Train Loss: 0.5594
Epoch 6: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0384 Validation Top 20 DE MSE: 0.0355. 
Epoch 7 Step 1 Train Loss: 0.4496
Epoch 7 Step 51 Train Loss: 0.5080
Epoch 7 Step 101 Train Loss: 0.4386
Epoch 7 Step 151 Train Loss: 0.4994
Epoch 7 Step 201 Train Loss: 0.5141
Epoch 7 Step 251 Train Loss: 0.5138
Epoch 7 Step 301 Train Loss: 0.4668
Epoch 7: Train Overall MSE: 0.0036 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0208 Validation Top 20 DE MSE: 0.0211. 
Epoch 8 Step 1 Train Loss: 0.4270
Epoch 8 Step 51 Train Loss: 0.5168
Epoch 8 Step 101 Train Loss: 0.4532
Epoch 8 Step 151 Train Loss: 0.5222
Epoch 8 Step 201 Train Loss: 0.5613
Epoch 8 Step 251 Train Loss: 0.4856
Epoch 8 Step 301 Train Loss: 0.4536
Epoch 8: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0171 Validation Top 20 DE MSE: 0.0192. 
Epoch 9 Step 1 Train Loss: 0.5011
Epoch 9 Step 51 Train Loss: 0.5050
Epoch 9 Step 101 Train Loss: 0.5389
Epoch 9 Step 151 Train Loss: 0.4932
Epoch 9 Step 201 Train Loss: 0.4586
Epoch 9 Step 251 Train Loss: 0.4586
Epoch 9 Step 301 Train Loss: 0.5943
Epoch 9: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0175 Validation Top 20 DE MSE: 0.0197. 
Epoch 10 Step 1 Train Loss: 0.4220
Epoch 10 Step 51 Train Loss: 0.4625
Epoch 10 Step 101 Train Loss: 0.5821
Epoch 10 Step 151 Train Loss: 0.4599
Epoch 10 Step 201 Train Loss: 0.4385
Epoch 10 Step 251 Train Loss: 0.5470
Epoch 10 Step 301 Train Loss: 0.5074
Epoch 10: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0175 Validation Top 20 DE MSE: 0.0202. 
Epoch 11 Step 1 Train Loss: 0.4486
Epoch 11 Step 51 Train Loss: 0.4701
Epoch 11 Step 101 Train Loss: 0.4265
Epoch 11 Step 151 Train Loss: 0.5323
Epoch 11 Step 201 Train Loss: 0.5107
Epoch 11 Step 251 Train Loss: 0.4568
Epoch 11 Step 301 Train Loss: 0.4544
Epoch 11: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0170 Validation Top 20 DE MSE: 0.0199. 
Epoch 12 Step 1 Train Loss: 0.5213
Epoch 12 Step 51 Train Loss: 0.4417
Epoch 12 Step 101 Train Loss: 0.4718
Epoch 12 Step 151 Train Loss: 0.4569
Epoch 12 Step 201 Train Loss: 0.4590
Epoch 12 Step 251 Train Loss: 0.4979
Epoch 12 Step 301 Train Loss: 0.4842
Epoch 12: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0174 Validation Top 20 DE MSE: 0.0200. 
Epoch 13 Step 1 Train Loss: 0.4936
Epoch 13 Step 51 Train Loss: 0.4254
Epoch 13 Step 101 Train Loss: 0.4913
Epoch 13 Step 151 Train Loss: 0.5138
Epoch 13 Step 201 Train Loss: 0.4775
Epoch 13 Step 251 Train Loss: 0.4726
Epoch 13 Step 301 Train Loss: 0.4800
Epoch 13: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0169 Validation Top 20 DE MSE: 0.0195. 
Epoch 14 Step 1 Train Loss: 0.4669
Epoch 14 Step 51 Train Loss: 0.4552
Epoch 14 Step 101 Train Loss: 0.4763
Epoch 14 Step 151 Train Loss: 0.4813
Epoch 14 Step 201 Train Loss: 0.4694
Epoch 14 Step 251 Train Loss: 0.5250
Epoch 14 Step 301 Train Loss: 0.4791
Epoch 14: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0169 Validation Top 20 DE MSE: 0.0194. 
Epoch 15 Step 1 Train Loss: 0.4380
Epoch 15 Step 51 Train Loss: 0.4734
Epoch 15 Step 101 Train Loss: 0.5188
Epoch 15 Step 151 Train Loss: 0.4846
Epoch 15 Step 201 Train Loss: 0.4816
Epoch 15 Step 251 Train Loss: 0.4716
Epoch 15 Step 301 Train Loss: 0.5626
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.0203. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1366
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0033808446
test_unseen_single_pearson: 0.9909703825597252
test_unseen_single_mse_de: 0.13661654
test_unseen_single_pearson_de: 0.945226594933426
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.28148013257044174
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.23750000000000002
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9666666666666668
test_unseen_single_mse_top20_de_non_dropout: 0.13739699
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.003 MB of 0.021 MB uploadedwandb: / 0.003 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.13662
wandb:                                              test_de_pearson 0.94523
wandb:               test_frac_opposite_direction_top20_non_dropout 0.2375
wandb:                          test_frac_sigma_below_1_non_dropout 0.96667
wandb:                                                     test_mse 0.00338
wandb:                                test_mse_top20_de_non_dropout 0.1374
wandb:                                                 test_pearson 0.99097
wandb:                                           test_pearson_delta 0.28148
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.2375
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.96667
wandb:                                       test_unseen_single_mse 0.00338
wandb:                                    test_unseen_single_mse_de 0.13662
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.1374
wandb:                                   test_unseen_single_pearson 0.99097
wandb:                                test_unseen_single_pearson_de 0.94523
wandb:                             test_unseen_single_pearson_delta 0.28148
wandb:                                                 train_de_mse 0.01756
wandb:                                             train_de_pearson 0.94649
wandb:                                                    train_mse 0.00166
wandb:                                                train_pearson 0.99573
wandb:                                                training_loss 0.45565
wandb:                                                   val_de_mse 0.02028
wandb:                                               val_de_pearson 0.98391
wandb:                                                      val_mse 0.00166
wandb:                                                  val_pearson 0.99563
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRa_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/33ofsz40
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_082442-33ofsz40/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_083828-8pstksje
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRa_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/8pstksje
wandb: WARNING Serializing object of type ndarray that is 8054528 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5443
Epoch 1 Step 51 Train Loss: 0.5367
Epoch 1 Step 101 Train Loss: 0.5002
Epoch 1 Step 151 Train Loss: 0.4505
Epoch 1 Step 201 Train Loss: 0.5104
Epoch 1 Step 251 Train Loss: 0.5272
Epoch 1 Step 301 Train Loss: 0.4637
Epoch 1 Step 351 Train Loss: 0.4869
Epoch 1: Train Overall MSE: 1.5501 Validation Overall MSE: 1.5970. 
Train Top 20 DE MSE: 6.1676 Validation Top 20 DE MSE: 6.2625. 
Epoch 2 Step 1 Train Loss: 0.4513
Epoch 2 Step 51 Train Loss: 0.4785
Epoch 2 Step 101 Train Loss: 0.6088
Epoch 2 Step 151 Train Loss: 0.5007
Epoch 2 Step 201 Train Loss: 0.4995
Epoch 2 Step 251 Train Loss: 0.4151
Epoch 2 Step 301 Train Loss: 0.3837
Epoch 2 Step 351 Train Loss: 0.5013
Epoch 2: Train Overall MSE: 1.5289 Validation Overall MSE: 1.5569. 
Train Top 20 DE MSE: 6.7774 Validation Top 20 DE MSE: 6.5735. 
Epoch 3 Step 1 Train Loss: 0.4947
Epoch 3 Step 51 Train Loss: 0.4540
Epoch 3 Step 101 Train Loss: 0.4365
Epoch 3 Step 151 Train Loss: 0.5250
Epoch 3 Step 201 Train Loss: 0.4777
Epoch 3 Step 251 Train Loss: 0.5117
Epoch 3 Step 301 Train Loss: 0.5222
Epoch 3 Step 351 Train Loss: 0.4964
Epoch 3: Train Overall MSE: 0.0115 Validation Overall MSE: 0.0122. 
Train Top 20 DE MSE: 0.0824 Validation Top 20 DE MSE: 0.0673. 
Epoch 4 Step 1 Train Loss: 0.4873
Epoch 4 Step 51 Train Loss: 0.4419
Epoch 4 Step 101 Train Loss: 0.4718
Epoch 4 Step 151 Train Loss: 0.5192
Epoch 4 Step 201 Train Loss: 0.5475
Epoch 4 Step 251 Train Loss: 0.5100
Epoch 4 Step 301 Train Loss: 0.5255
Epoch 4 Step 351 Train Loss: 0.4669
Epoch 4: Train Overall MSE: 0.3789 Validation Overall MSE: 0.3879. 
Train Top 20 DE MSE: 1.8620 Validation Top 20 DE MSE: 1.7427. 
Epoch 5 Step 1 Train Loss: 0.5182
Epoch 5 Step 51 Train Loss: 0.5252
Epoch 5 Step 101 Train Loss: 0.4704
Epoch 5 Step 151 Train Loss: 0.4923
Epoch 5 Step 201 Train Loss: 0.4731
Epoch 5 Step 251 Train Loss: 0.4483
Epoch 5 Step 301 Train Loss: 0.4568
Epoch 5 Step 351 Train Loss: 0.4748
Epoch 5: Train Overall MSE: 0.1036 Validation Overall MSE: 0.1108. 
Train Top 20 DE MSE: 0.4928 Validation Top 20 DE MSE: 0.3846. 
Epoch 6 Step 1 Train Loss: 0.5076
Epoch 6 Step 51 Train Loss: 0.4235
Epoch 6 Step 101 Train Loss: 0.4456
Epoch 6 Step 151 Train Loss: 0.5039
Epoch 6 Step 201 Train Loss: 0.4692
Epoch 6 Step 251 Train Loss: 0.4631
Epoch 6 Step 301 Train Loss: 0.4959
Epoch 6 Step 351 Train Loss: 0.5309
Epoch 6: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0415 Validation Top 20 DE MSE: 0.0418. 
Epoch 7 Step 1 Train Loss: 0.5092
Epoch 7 Step 51 Train Loss: 0.4408
Epoch 7 Step 101 Train Loss: 0.4801
Epoch 7 Step 151 Train Loss: 0.4476
Epoch 7 Step 201 Train Loss: 0.4970
Epoch 7 Step 251 Train Loss: 0.4461
Epoch 7 Step 301 Train Loss: 0.4820
Epoch 7 Step 351 Train Loss: 0.4537
Epoch 7: Train Overall MSE: 0.0098 Validation Overall MSE: 0.0105. 
Train Top 20 DE MSE: 0.0705 Validation Top 20 DE MSE: 0.0521. 
Epoch 8 Step 1 Train Loss: 0.4861
Epoch 8 Step 51 Train Loss: 0.5150
Epoch 8 Step 101 Train Loss: 0.5782
Epoch 8 Step 151 Train Loss: 0.4984
Epoch 8 Step 201 Train Loss: 0.5021
Epoch 8 Step 251 Train Loss: 0.4261
Epoch 8 Step 301 Train Loss: 0.5164
Epoch 8 Step 351 Train Loss: 0.5070
Epoch 8: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0270 Validation Top 20 DE MSE: 0.0401. 
Epoch 9 Step 1 Train Loss: 0.5285
Epoch 9 Step 51 Train Loss: 0.5352
Epoch 9 Step 101 Train Loss: 0.5368
Epoch 9 Step 151 Train Loss: 0.5024
Epoch 9 Step 201 Train Loss: 0.5037
Epoch 9 Step 251 Train Loss: 0.5230
Epoch 9 Step 301 Train Loss: 0.4951
Epoch 9 Step 351 Train Loss: 0.5435
Epoch 9: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0295 Validation Top 20 DE MSE: 0.0405. 
Epoch 10 Step 1 Train Loss: 0.4568
Epoch 10 Step 51 Train Loss: 0.5044
Epoch 10 Step 101 Train Loss: 0.4845
Epoch 10 Step 151 Train Loss: 0.4913
Epoch 10 Step 201 Train Loss: 0.4917
Epoch 10 Step 251 Train Loss: 0.4445
Epoch 10 Step 301 Train Loss: 0.5445
Epoch 10 Step 351 Train Loss: 0.4618
Epoch 10: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0249 Validation Top 20 DE MSE: 0.0409. 
Epoch 11 Step 1 Train Loss: 0.5839
Epoch 11 Step 51 Train Loss: 0.4886
Epoch 11 Step 101 Train Loss: 0.4474
Epoch 11 Step 151 Train Loss: 0.5102
Epoch 11 Step 201 Train Loss: 0.4542
Epoch 11 Step 251 Train Loss: 0.4728
Epoch 11 Step 301 Train Loss: 0.5657
Epoch 11 Step 351 Train Loss: 0.4723
Epoch 11: Train Overall MSE: 0.0027 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0350 Validation Top 20 DE MSE: 0.0388. 
Epoch 12 Step 1 Train Loss: 0.4419
Epoch 12 Step 51 Train Loss: 0.5279
Epoch 12 Step 101 Train Loss: 0.4578
Epoch 12 Step 151 Train Loss: 0.5547
Epoch 12 Step 201 Train Loss: 0.4175
Epoch 12 Step 251 Train Loss: 0.5013
Epoch 12 Step 301 Train Loss: 0.5286
Epoch 12 Step 351 Train Loss: 0.5580
Epoch 12: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0286 Validation Top 20 DE MSE: 0.0406. 
Epoch 13 Step 1 Train Loss: 0.4799
Epoch 13 Step 51 Train Loss: 0.5093
Epoch 13 Step 101 Train Loss: 0.4892
Epoch 13 Step 151 Train Loss: 0.5073
Epoch 13 Step 201 Train Loss: 0.4602
Epoch 13 Step 251 Train Loss: 0.5527
Epoch 13 Step 301 Train Loss: 0.4405
Epoch 13 Step 351 Train Loss: 0.5160
Epoch 13: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0255 Validation Top 20 DE MSE: 0.0403. 
Epoch 14 Step 1 Train Loss: 0.4778
Epoch 14 Step 51 Train Loss: 0.5118
Epoch 14 Step 101 Train Loss: 0.5314
Epoch 14 Step 151 Train Loss: 0.4716
Epoch 14 Step 201 Train Loss: 0.4793
Epoch 14 Step 251 Train Loss: 0.5361
Epoch 14 Step 301 Train Loss: 0.5459
Epoch 14 Step 351 Train Loss: 0.4861
Epoch 14: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0307 Validation Top 20 DE MSE: 0.0396. 
Epoch 15 Step 1 Train Loss: 0.4411
Epoch 15 Step 51 Train Loss: 0.5012
Epoch 15 Step 101 Train Loss: 0.5034
Epoch 15 Step 151 Train Loss: 0.5166
Epoch 15 Step 201 Train Loss: 0.5206
Epoch 15 Step 251 Train Loss: 0.5562
Epoch 15 Step 301 Train Loss: 0.5131
Epoch 15 Step 351 Train Loss: 0.4343
Epoch 15: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0238 Validation Top 20 DE MSE: 0.0405. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0274
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.002185515
test_unseen_single_pearson: 0.994496911264774
test_unseen_single_mse_de: 0.02740243
test_unseen_single_pearson_de: 0.9426608597265468
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.27347974155403154
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.28541666666666665
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9500000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.028928047
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.015 MB of 0.022 MB uploadedwandb: / 0.016 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb: \ 0.022 MB of 0.022 MB uploadedwandb: | 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñá‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÑ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.0274
wandb:                                              test_de_pearson 0.94266
wandb:               test_frac_opposite_direction_top20_non_dropout 0.28542
wandb:                          test_frac_sigma_below_1_non_dropout 0.95
wandb:                                                     test_mse 0.00219
wandb:                                test_mse_top20_de_non_dropout 0.02893
wandb:                                                 test_pearson 0.9945
wandb:                                           test_pearson_delta 0.27348
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.28542
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.95
wandb:                                       test_unseen_single_mse 0.00219
wandb:                                    test_unseen_single_mse_de 0.0274
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.02893
wandb:                                   test_unseen_single_pearson 0.9945
wandb:                                test_unseen_single_pearson_de 0.94266
wandb:                             test_unseen_single_pearson_delta 0.27348
wandb:                                                 train_de_mse 0.02382
wandb:                                             train_de_pearson 0.94971
wandb:                                                    train_mse 0.00222
wandb:                                                train_pearson 0.99437
wandb:                                                training_loss 0.46123
wandb:                                                   val_de_mse 0.04047
wandb:                                               val_de_pearson 0.9786
wandb:                                                      val_mse 0.0026
wandb:                                                  val_pearson 0.99343
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRa_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/8pstksje
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_083828-8pstksje/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_085316-t22qcixu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRa_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/t22qcixu
wandb: WARNING Serializing object of type ndarray that is 8054528 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4782
Epoch 1 Step 51 Train Loss: 0.4924
Epoch 1 Step 101 Train Loss: 0.5016
Epoch 1 Step 151 Train Loss: 0.5238
Epoch 1 Step 201 Train Loss: 0.5164
Epoch 1 Step 251 Train Loss: 0.5021
Epoch 1 Step 301 Train Loss: 0.4964
Epoch 1: Train Overall MSE: 0.1196 Validation Overall MSE: 0.1200. 
Train Top 20 DE MSE: 0.3040 Validation Top 20 DE MSE: 0.3108. 
Epoch 2 Step 1 Train Loss: 0.5031
Epoch 2 Step 51 Train Loss: 0.4962
Epoch 2 Step 101 Train Loss: 0.4878
Epoch 2 Step 151 Train Loss: 0.4966
Epoch 2 Step 201 Train Loss: 0.5154
Epoch 2 Step 251 Train Loss: 0.4601
Epoch 2 Step 301 Train Loss: 0.5523
Epoch 2: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0167. 
Train Top 20 DE MSE: 0.0473 Validation Top 20 DE MSE: 0.0520. 
Epoch 3 Step 1 Train Loss: 0.4790
Epoch 3 Step 51 Train Loss: 0.4846
Epoch 3 Step 101 Train Loss: 0.4510
Epoch 3 Step 151 Train Loss: 0.4658
Epoch 3 Step 201 Train Loss: 0.4832
Epoch 3 Step 251 Train Loss: 0.5182
Epoch 3 Step 301 Train Loss: 0.5000
Epoch 3: Train Overall MSE: 3.4684 Validation Overall MSE: 3.5087. 
Train Top 20 DE MSE: 18.7984 Validation Top 20 DE MSE: 15.6398. 
Epoch 4 Step 1 Train Loss: 0.4558
Epoch 4 Step 51 Train Loss: 0.5696
Epoch 4 Step 101 Train Loss: 0.4505
Epoch 4 Step 151 Train Loss: 0.5075
Epoch 4 Step 201 Train Loss: 0.4613
Epoch 4 Step 251 Train Loss: 0.5034
Epoch 4 Step 301 Train Loss: 0.5159
Epoch 4: Train Overall MSE: 1.0642 Validation Overall MSE: 1.0900. 
Train Top 20 DE MSE: 5.9078 Validation Top 20 DE MSE: 4.8096. 
Epoch 5 Step 1 Train Loss: 0.4861
Epoch 5 Step 51 Train Loss: 0.4851
Epoch 5 Step 101 Train Loss: 0.4843
Epoch 5 Step 151 Train Loss: 0.5108
Epoch 5 Step 201 Train Loss: 0.5003
Epoch 5 Step 251 Train Loss: 0.4784
Epoch 5 Step 301 Train Loss: 0.5544
Epoch 5: Train Overall MSE: 0.1953 Validation Overall MSE: 0.2070. 
Train Top 20 DE MSE: 0.9587 Validation Top 20 DE MSE: 0.7832. 
Epoch 6 Step 1 Train Loss: 0.4724
Epoch 6 Step 51 Train Loss: 0.4739
Epoch 6 Step 101 Train Loss: 0.4763
Epoch 6 Step 151 Train Loss: 0.4740
Epoch 6 Step 201 Train Loss: 0.5457
Epoch 6 Step 251 Train Loss: 0.5556
Epoch 6 Step 301 Train Loss: 0.4924
Epoch 6: Train Overall MSE: 0.0213 Validation Overall MSE: 0.0235. 
Train Top 20 DE MSE: 0.1019 Validation Top 20 DE MSE: 0.0826. 
Epoch 7 Step 1 Train Loss: 0.5190
Epoch 7 Step 51 Train Loss: 0.4800
Epoch 7 Step 101 Train Loss: 0.4394
Epoch 7 Step 151 Train Loss: 0.4717
Epoch 7 Step 201 Train Loss: 0.4702
Epoch 7 Step 251 Train Loss: 0.4927
Epoch 7 Step 301 Train Loss: 0.4972
Epoch 7: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0226 Validation Top 20 DE MSE: 0.0195. 
Epoch 8 Step 1 Train Loss: 0.5084
Epoch 8 Step 51 Train Loss: 0.5155
Epoch 8 Step 101 Train Loss: 0.4768
Epoch 8 Step 151 Train Loss: 0.4574
Epoch 8 Step 201 Train Loss: 0.5032
Epoch 8 Step 251 Train Loss: 0.4653
Epoch 8 Step 301 Train Loss: 0.4839
Epoch 8: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0222 Validation Top 20 DE MSE: 0.0150. 
Epoch 9 Step 1 Train Loss: 0.4815
Epoch 9 Step 51 Train Loss: 0.4664
Epoch 9 Step 101 Train Loss: 0.4495
Epoch 9 Step 151 Train Loss: 0.4893
Epoch 9 Step 201 Train Loss: 0.5438
Epoch 9 Step 251 Train Loss: 0.4910
Epoch 9 Step 301 Train Loss: 0.5004
Epoch 9: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0230 Validation Top 20 DE MSE: 0.0201. 
Epoch 10 Step 1 Train Loss: 0.4709
Epoch 10 Step 51 Train Loss: 0.5180
Epoch 10 Step 101 Train Loss: 0.5649
Epoch 10 Step 151 Train Loss: 0.6266
Epoch 10 Step 201 Train Loss: 0.4786
Epoch 10 Step 251 Train Loss: 0.5170
Epoch 10 Step 301 Train Loss: 0.4709
Epoch 10: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0219 Validation Top 20 DE MSE: 0.0180. 
Epoch 11 Step 1 Train Loss: 0.5707
Epoch 11 Step 51 Train Loss: 0.5077
Epoch 11 Step 101 Train Loss: 0.5196
Epoch 11 Step 151 Train Loss: 0.5009
Epoch 11 Step 201 Train Loss: 0.5438
Epoch 11 Step 251 Train Loss: 0.4699
Epoch 11 Step 301 Train Loss: 0.4923
Epoch 11: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0221 Validation Top 20 DE MSE: 0.0189. 
Epoch 12 Step 1 Train Loss: 0.4683
Epoch 12 Step 51 Train Loss: 0.4685
Epoch 12 Step 101 Train Loss: 0.4799
Epoch 12 Step 151 Train Loss: 0.4947
Epoch 12 Step 201 Train Loss: 0.5002
Epoch 12 Step 251 Train Loss: 0.4989
Epoch 12 Step 301 Train Loss: 0.5494
Epoch 12: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0221 Validation Top 20 DE MSE: 0.0189. 
Epoch 13 Step 1 Train Loss: 0.4844
Epoch 13 Step 51 Train Loss: 0.5173
Epoch 13 Step 101 Train Loss: 0.4854
Epoch 13 Step 151 Train Loss: 0.5081
Epoch 13 Step 201 Train Loss: 0.4075
Epoch 13 Step 251 Train Loss: 0.4643
Epoch 13 Step 301 Train Loss: 0.5373
Epoch 13: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0228 Validation Top 20 DE MSE: 0.0202. 
Epoch 14 Step 1 Train Loss: 0.5610
Epoch 14 Step 51 Train Loss: 0.4934
Epoch 14 Step 101 Train Loss: 0.5436
Epoch 14 Step 151 Train Loss: 0.4562
Epoch 14 Step 201 Train Loss: 0.4969
Epoch 14 Step 251 Train Loss: 0.4644
Epoch 14 Step 301 Train Loss: 0.5221
Epoch 14: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0225 Validation Top 20 DE MSE: 0.0191. 
Epoch 15 Step 1 Train Loss: 0.5415
Epoch 15 Step 51 Train Loss: 0.4944
Epoch 15 Step 101 Train Loss: 0.5271
Epoch 15 Step 151 Train Loss: 0.4968
Epoch 15 Step 201 Train Loss: 0.4662
Epoch 15 Step 251 Train Loss: 0.4410
Epoch 15 Step 301 Train Loss: 0.5341
Epoch 15: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0215 Validation Top 20 DE MSE: 0.0182. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0551
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0041841906
test_unseen_single_pearson: 0.9893256332561343
test_unseen_single_mse_de: 0.055072475
test_unseen_single_pearson_de: 0.9414495143197623
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.26096140076240526
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.28958333333333336
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9166666666666666
test_unseen_single_mse_top20_de_non_dropout: 0.058208346
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.020 MB of 0.021 MB uploadedwandb: / 0.020 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÇ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÑ
wandb:                                                   val_de_mse ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.05507
wandb:                                              test_de_pearson 0.94145
wandb:               test_frac_opposite_direction_top20_non_dropout 0.28958
wandb:                          test_frac_sigma_below_1_non_dropout 0.91667
wandb:                                                     test_mse 0.00418
wandb:                                test_mse_top20_de_non_dropout 0.05821
wandb:                                                 test_pearson 0.98933
wandb:                                           test_pearson_delta 0.26096
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.28958
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.91667
wandb:                                       test_unseen_single_mse 0.00418
wandb:                                    test_unseen_single_mse_de 0.05507
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.05821
wandb:                                   test_unseen_single_pearson 0.98933
wandb:                                test_unseen_single_pearson_de 0.94145
wandb:                             test_unseen_single_pearson_delta 0.26096
wandb:                                                 train_de_mse 0.02155
wandb:                                             train_de_pearson 0.95108
wandb:                                                    train_mse 0.00234
wandb:                                                train_pearson 0.99412
wandb:                                                training_loss 0.4885
wandb:                                                   val_de_mse 0.01819
wandb:                                               val_de_pearson 0.99123
wandb:                                                      val_mse 0.00127
wandb:                                                  val_pearson 0.9967
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRa_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/t22qcixu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_085316-t22qcixu/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:24
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_090635-6w20rqk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRa_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/6w20rqk2
wandb: WARNING Serializing object of type ndarray that is 8054528 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4663
Epoch 1 Step 51 Train Loss: 0.5080
Epoch 1 Step 101 Train Loss: 0.4533
Epoch 1 Step 151 Train Loss: 0.4625
Epoch 1 Step 201 Train Loss: 0.4702
Epoch 1 Step 251 Train Loss: 0.5726
Epoch 1 Step 301 Train Loss: 0.4577
Epoch 1: Train Overall MSE: 0.0237 Validation Overall MSE: 0.0241. 
Train Top 20 DE MSE: 0.0779 Validation Top 20 DE MSE: 0.0700. 
Epoch 2 Step 1 Train Loss: 0.5498
Epoch 2 Step 51 Train Loss: 0.4514
Epoch 2 Step 101 Train Loss: 0.5208
Epoch 2 Step 151 Train Loss: 0.5937
Epoch 2 Step 201 Train Loss: 0.5096
Epoch 2 Step 251 Train Loss: 0.5165
Epoch 2 Step 301 Train Loss: 0.4621
Epoch 2: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0632 Validation Top 20 DE MSE: 0.0544. 
Epoch 3 Step 1 Train Loss: 0.5421
Epoch 3 Step 51 Train Loss: 0.4826
Epoch 3 Step 101 Train Loss: 0.5678
Epoch 3 Step 151 Train Loss: 0.4788
Epoch 3 Step 201 Train Loss: 0.5081
Epoch 3 Step 251 Train Loss: 0.4584
Epoch 3 Step 301 Train Loss: 0.4734
Epoch 3: Train Overall MSE: 0.0035 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0236 Validation Top 20 DE MSE: 0.0338. 
Epoch 4 Step 1 Train Loss: 0.4714
Epoch 4 Step 51 Train Loss: 0.5020
Epoch 4 Step 101 Train Loss: 0.5464
Epoch 4 Step 151 Train Loss: 0.4860
Epoch 4 Step 201 Train Loss: 0.5131
Epoch 4 Step 251 Train Loss: 0.5085
Epoch 4 Step 301 Train Loss: 0.4794
Epoch 4: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0102. 
Train Top 20 DE MSE: 0.0867 Validation Top 20 DE MSE: 0.0598. 
Epoch 5 Step 1 Train Loss: 0.4963
Epoch 5 Step 51 Train Loss: 0.4723
Epoch 5 Step 101 Train Loss: 0.4295
Epoch 5 Step 151 Train Loss: 0.5258
Epoch 5 Step 201 Train Loss: 0.5308
Epoch 5 Step 251 Train Loss: 0.4497
Epoch 5 Step 301 Train Loss: 0.5025
Epoch 5: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0532 Validation Top 20 DE MSE: 0.0435. 
Epoch 6 Step 1 Train Loss: 0.4587
Epoch 6 Step 51 Train Loss: 0.4936
Epoch 6 Step 101 Train Loss: 0.4997
Epoch 6 Step 151 Train Loss: 0.4745
Epoch 6 Step 201 Train Loss: 0.4905
Epoch 6 Step 251 Train Loss: 0.5079
Epoch 6 Step 301 Train Loss: 0.4937
Epoch 6: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0263 Validation Top 20 DE MSE: 0.0389. 
Epoch 7 Step 1 Train Loss: 0.5109
Epoch 7 Step 51 Train Loss: 0.5137
Epoch 7 Step 101 Train Loss: 0.5858
Epoch 7 Step 151 Train Loss: 0.4409
Epoch 7 Step 201 Train Loss: 0.5155
Epoch 7 Step 251 Train Loss: 0.4882
Epoch 7 Step 301 Train Loss: 0.5165
Epoch 7: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0231 Validation Top 20 DE MSE: 0.0382. 
Epoch 8 Step 1 Train Loss: 0.5373
Epoch 8 Step 51 Train Loss: 0.5218
Epoch 8 Step 101 Train Loss: 0.4607
Epoch 8 Step 151 Train Loss: 0.5196
Epoch 8 Step 201 Train Loss: 0.5214
Epoch 8 Step 251 Train Loss: 0.4562
Epoch 8 Step 301 Train Loss: 0.4862
Epoch 8: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0269 Validation Top 20 DE MSE: 0.0428. 
Epoch 9 Step 1 Train Loss: 0.4389
Epoch 9 Step 51 Train Loss: 0.4758
Epoch 9 Step 101 Train Loss: 0.4469
Epoch 9 Step 151 Train Loss: 0.4661
Epoch 9 Step 201 Train Loss: 0.5196
Epoch 9 Step 251 Train Loss: 0.5133
Epoch 9 Step 301 Train Loss: 0.4741
Epoch 9: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0231 Validation Top 20 DE MSE: 0.0354. 
Epoch 10 Step 1 Train Loss: 0.4847
Epoch 10 Step 51 Train Loss: 0.4633
Epoch 10 Step 101 Train Loss: 0.5142
Epoch 10 Step 151 Train Loss: 0.4269
Epoch 10 Step 201 Train Loss: 0.5293
Epoch 10 Step 251 Train Loss: 0.5055
Epoch 10 Step 301 Train Loss: 0.4573
Epoch 10: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0217 Validation Top 20 DE MSE: 0.0348. 
Epoch 11 Step 1 Train Loss: 0.4750
Epoch 11 Step 51 Train Loss: 0.4677
Epoch 11 Step 101 Train Loss: 0.5175
Epoch 11 Step 151 Train Loss: 0.4646
Epoch 11 Step 201 Train Loss: 0.4478
Epoch 11 Step 251 Train Loss: 0.4613
Epoch 11 Step 301 Train Loss: 0.5235
Epoch 11: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0357. 
Epoch 12 Step 1 Train Loss: 0.5521
Epoch 12 Step 51 Train Loss: 0.4861
Epoch 12 Step 101 Train Loss: 0.5122
Epoch 12 Step 151 Train Loss: 0.4321
Epoch 12 Step 201 Train Loss: 0.5561
Epoch 12 Step 251 Train Loss: 0.4476
Epoch 12 Step 301 Train Loss: 0.5035
Epoch 12: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0202 Validation Top 20 DE MSE: 0.0364. 
Epoch 13 Step 1 Train Loss: 0.5218
Epoch 13 Step 51 Train Loss: 0.4871
Epoch 13 Step 101 Train Loss: 0.4828
Epoch 13 Step 151 Train Loss: 0.4528
Epoch 13 Step 201 Train Loss: 0.4890
Epoch 13 Step 251 Train Loss: 0.5060
Epoch 13 Step 301 Train Loss: 0.4943
Epoch 13: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0205 Validation Top 20 DE MSE: 0.0365. 
Epoch 14 Step 1 Train Loss: 0.4707
Epoch 14 Step 51 Train Loss: 0.4915
Epoch 14 Step 101 Train Loss: 0.4413
Epoch 14 Step 151 Train Loss: 0.5257
Epoch 14 Step 201 Train Loss: 0.4756
Epoch 14 Step 251 Train Loss: 0.4818
Epoch 14 Step 301 Train Loss: 0.4198
Epoch 14: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0231 Validation Top 20 DE MSE: 0.0366. 
Epoch 15 Step 1 Train Loss: 0.4593
Epoch 15 Step 51 Train Loss: 0.5344
Epoch 15 Step 101 Train Loss: 0.4776
Epoch 15 Step 151 Train Loss: 0.4733
Epoch 15 Step 201 Train Loss: 0.5521
Epoch 15 Step 251 Train Loss: 0.4971
Epoch 15 Step 301 Train Loss: 0.4745
Epoch 15: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0216 Validation Top 20 DE MSE: 0.0364. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0271
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0038610573
test_unseen_single_pearson: 0.990436397538817
test_unseen_single_mse_de: 0.027139729
test_unseen_single_pearson_de: 0.9514976524577298
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.25685843884922016
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2916666666666667
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9291666666666667
test_unseen_single_mse_top20_de_non_dropout: 0.030059658
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.018 MB uploadedwandb: | 0.003 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñá‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÖ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.02714
wandb:                                              test_de_pearson 0.9515
wandb:               test_frac_opposite_direction_top20_non_dropout 0.29167
wandb:                          test_frac_sigma_below_1_non_dropout 0.92917
wandb:                                                     test_mse 0.00386
wandb:                                test_mse_top20_de_non_dropout 0.03006
wandb:                                                 test_pearson 0.99044
wandb:                                           test_pearson_delta 0.25686
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.29167
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.92917
wandb:                                       test_unseen_single_mse 0.00386
wandb:                                    test_unseen_single_mse_de 0.02714
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.03006
wandb:                                   test_unseen_single_pearson 0.99044
wandb:                                test_unseen_single_pearson_de 0.9515
wandb:                             test_unseen_single_pearson_delta 0.25686
wandb:                                                 train_de_mse 0.0216
wandb:                                             train_de_pearson 0.9545
wandb:                                                    train_mse 0.00223
wandb:                                                train_pearson 0.99441
wandb:                                                training_loss 0.47165
wandb:                                                   val_de_mse 0.03641
wandb:                                               val_de_pearson 0.95435
wandb:                                                      val_mse 0.002
wandb:                                                  val_pearson 0.99478
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRa_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/6w20rqk2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_090635-6w20rqk2/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_092120-37g4j4cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRi_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/37g4j4cx
wandb: WARNING Serializing object of type ndarray that is 8244928 bytes
  0%|                                                                                       | 0/3277 [00:00<?, ?it/s]  0%|‚ñè                                                                              | 6/3277 [00:00<00:58, 56.15it/s]  0%|‚ñé                                                                             | 14/3277 [00:00<00:53, 60.71it/s]  1%|‚ñå                                                                             | 23/3277 [00:00<00:46, 70.51it/s]  1%|‚ñä                                                                             | 33/3277 [00:00<00:40, 80.68it/s]  1%|‚ñâ                                                                             | 42/3277 [00:00<00:40, 80.12it/s]  2%|‚ñà‚ñè                                                                            | 51/3277 [00:00<00:41, 77.45it/s]  2%|‚ñà‚ñç                                                                            | 61/3277 [00:00<00:40, 78.84it/s]  2%|‚ñà‚ñã                                                                            | 71/3277 [00:00<00:38, 82.28it/s]  2%|‚ñà‚ñâ                                                                            | 80/3277 [00:01<00:40, 79.26it/s]  3%|‚ñà‚ñà                                                                            | 88/3277 [00:01<00:40, 77.91it/s]  3%|‚ñà‚ñà‚ñé                                                                           | 97/3277 [00:01<00:39, 79.72it/s]  3%|‚ñà‚ñà‚ñç                                                                          | 106/3277 [00:01<00:39, 79.74it/s]  3%|‚ñà‚ñà‚ñã                                                                          | 114/3277 [00:01<00:39, 79.79it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 123/3277 [00:01<00:39, 80.43it/s]  4%|‚ñà‚ñà‚ñà                                                                          | 132/3277 [00:01<00:39, 80.59it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 141/3277 [00:01<00:38, 81.24it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 150/3277 [00:01<00:38, 81.67it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 159/3277 [00:02<00:38, 81.26it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 168/3277 [00:02<00:40, 76.76it/s]  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                        | 176/3277 [00:02<00:40, 77.36it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 184/3277 [00:02<00:39, 78.08it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 193/3277 [00:02<00:38, 79.23it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 201/3277 [00:02<00:41, 74.00it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 209/3277 [00:02<00:47, 65.14it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 216/3277 [00:02<00:48, 63.52it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 224/3277 [00:02<00:46, 65.25it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 235/3277 [00:03<00:40, 75.55it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 244/3277 [00:03<00:38, 77.96it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 253/3277 [00:03<00:37, 81.10it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 262/3277 [00:03<00:38, 77.95it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 272/3277 [00:03<00:36, 81.86it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 281/3277 [00:03<00:36, 81.25it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 290/3277 [00:03<00:40, 74.27it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 298/3277 [00:03<00:42, 70.39it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 306/3277 [00:04<00:43, 68.02it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 313/3277 [00:04<00:45, 65.82it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 320/3277 [00:04<00:45, 65.00it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 327/3277 [00:04<00:45, 64.34it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 334/3277 [00:04<00:46, 63.69it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 341/3277 [00:04<00:46, 63.40it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 348/3277 [00:04<00:46, 62.44it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 355/3277 [00:04<00:46, 62.66it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 362/3277 [00:04<00:46, 63.06it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 369/3277 [00:05<00:46, 62.90it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 376/3277 [00:05<00:48, 60.12it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 383/3277 [00:05<00:47, 60.51it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 391/3277 [00:05<00:45, 63.60it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 398/3277 [00:05<00:45, 62.71it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 405/3277 [00:05<00:45, 62.45it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 412/3277 [00:05<00:46, 61.37it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 419/3277 [00:05<00:46, 61.31it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 426/3277 [00:05<00:46, 61.29it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 433/3277 [00:06<00:46, 61.68it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 440/3277 [00:06<00:45, 62.72it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 447/3277 [00:06<00:45, 62.27it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 454/3277 [00:06<00:45, 62.38it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 461/3277 [00:06<00:47, 59.72it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 467/3277 [00:06<00:47, 59.63it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 475/3277 [00:06<00:44, 62.85it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 482/3277 [00:06<00:44, 62.63it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 489/3277 [00:07<00:45, 60.87it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 496/3277 [00:07<00:44, 62.45it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 504/3277 [00:07<00:43, 63.81it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                 | 514/3277 [00:07<00:38, 71.78it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 523/3277 [00:07<00:36, 76.37it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 532/3277 [00:07<00:35, 78.04it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 540/3277 [00:07<00:34, 78.33it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 549/3277 [00:07<00:33, 80.74it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 559/3277 [00:07<00:32, 83.78it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 568/3277 [00:07<00:32, 83.44it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 577/3277 [00:08<00:34, 78.02it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 586/3277 [00:08<00:33, 79.34it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 595/3277 [00:08<00:32, 82.22it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 604/3277 [00:08<00:33, 79.49it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 613/3277 [00:08<00:33, 80.48it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 622/3277 [00:08<00:32, 81.65it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 631/3277 [00:08<00:33, 78.72it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 640/3277 [00:08<00:33, 79.61it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 649/3277 [00:09<00:32, 80.08it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 658/3277 [00:09<00:33, 78.04it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 666/3277 [00:09<00:33, 78.11it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 674/3277 [00:09<00:35, 74.01it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 682/3277 [00:09<00:36, 70.51it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 690/3277 [00:09<00:38, 67.77it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 697/3277 [00:09<00:37, 68.19it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 704/3277 [00:09<00:37, 67.75it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                            | 711/3277 [00:09<00:39, 65.75it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 718/3277 [00:10<00:39, 65.36it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 726/3277 [00:10<00:38, 66.01it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 733/3277 [00:10<00:39, 64.25it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 740/3277 [00:10<00:39, 63.43it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 747/3277 [00:10<00:39, 64.07it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 754/3277 [00:10<00:39, 64.11it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 761/3277 [00:10<00:39, 63.30it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 768/3277 [00:10<00:39, 62.80it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 775/3277 [00:10<00:39, 62.72it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 782/3277 [00:11<00:38, 64.21it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 790/3277 [00:11<00:39, 62.79it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 797/3277 [00:11<00:39, 62.00it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 804/3277 [00:11<00:38, 63.81it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 811/3277 [00:11<00:38, 64.75it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 818/3277 [00:11<00:38, 64.68it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 825/3277 [00:11<00:38, 63.67it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 832/3277 [00:11<00:38, 64.29it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 839/3277 [00:11<00:37, 64.47it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                         | 846/3277 [00:12<00:37, 64.01it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 854/3277 [00:12<00:36, 66.07it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                        | 861/3277 [00:12<00:36, 65.84it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                        | 869/3277 [00:12<00:35, 67.91it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 878/3277 [00:12<00:33, 72.48it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 887/3277 [00:12<00:32, 73.00it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 897/3277 [00:12<00:30, 78.46it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 906/3277 [00:12<00:29, 79.23it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 916/3277 [00:12<00:29, 80.68it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 925/3277 [00:13<00:29, 80.73it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 934/3277 [00:13<00:28, 82.26it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 944/3277 [00:13<00:27, 84.78it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 954/3277 [00:13<00:27, 84.78it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 964/3277 [00:13<00:26, 85.81it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 973/3277 [00:13<00:26, 85.57it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 982/3277 [00:13<00:26, 86.74it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 991/3277 [00:13<00:26, 86.71it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1001/3277 [00:13<00:26, 85.85it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1010/3277 [00:14<00:26, 86.56it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1019/3277 [00:14<00:26, 86.54it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1029/3277 [00:14<00:25, 88.16it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1040/3277 [00:14<00:24, 91.82it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1050/3277 [00:14<00:25, 88.01it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1059/3277 [00:14<00:25, 85.98it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1069/3277 [00:14<00:25, 88.23it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1079/3277 [00:14<00:25, 87.42it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 1089/3277 [00:14<00:24, 89.26it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1099/3277 [00:15<00:24, 87.60it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 1110/3277 [00:15<00:24, 89.33it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1119/3277 [00:15<00:24, 88.48it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1128/3277 [00:15<00:24, 86.53it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1139/3277 [00:15<00:23, 90.85it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1149/3277 [00:15<00:23, 88.86it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1158/3277 [00:15<00:23, 88.85it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1167/3277 [00:15<00:23, 88.31it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1176/3277 [00:15<00:24, 86.90it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1186/3277 [00:16<00:24, 86.91it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1196/3277 [00:16<00:23, 88.58it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1205/3277 [00:16<00:23, 87.41it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1214/3277 [00:16<00:24, 84.47it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1223/3277 [00:16<00:25, 81.26it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 1234/3277 [00:16<00:23, 86.53it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1243/3277 [00:16<00:23, 87.17it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1254/3277 [00:16<00:22, 89.27it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1264/3277 [00:16<00:22, 90.27it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1274/3277 [00:17<00:22, 90.48it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1284/3277 [00:17<00:21, 90.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1295/3277 [00:17<00:21, 93.87it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                             | 1305/3277 [00:17<00:21, 92.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1315/3277 [00:17<00:21, 93.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1325/3277 [00:17<00:21, 90.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1335/3277 [00:17<00:24, 80.58it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1344/3277 [00:17<00:25, 76.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1352/3277 [00:17<00:26, 72.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1360/3277 [00:18<00:27, 69.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1368/3277 [00:18<00:27, 69.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1376/3277 [00:18<00:26, 72.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 1385/3277 [00:18<00:24, 76.98it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 1395/3277 [00:18<00:23, 81.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                           | 1405/3277 [00:18<00:22, 84.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 1414/3277 [00:18<00:22, 81.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 1423/3277 [00:18<00:23, 79.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 1432/3277 [00:19<00:22, 80.60it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 1441/3277 [00:19<00:23, 78.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1449/3277 [00:19<00:24, 75.12it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1457/3277 [00:19<00:25, 71.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 1465/3277 [00:19<00:24, 73.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 1473/3277 [00:19<00:24, 74.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 1481/3277 [00:19<00:24, 72.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1490/3277 [00:19<00:23, 75.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 1498/3277 [00:19<00:23, 75.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 1506/3277 [00:20<00:23, 74.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1516/3277 [00:20<00:21, 81.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 1525/3277 [00:20<00:21, 82.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 1535/3277 [00:20<00:20, 85.28it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 1545/3277 [00:20<00:19, 87.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1555/3277 [00:20<00:19, 88.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 1565/3277 [00:20<00:18, 91.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 1575/3277 [00:20<00:18, 91.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1585/3277 [00:20<00:18, 92.43it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 1595/3277 [00:20<00:18, 92.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 1605/3277 [00:21<00:18, 90.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1615/3277 [00:21<00:17, 92.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1625/3277 [00:21<00:20, 81.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 1634/3277 [00:21<00:20, 79.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1643/3277 [00:21<00:22, 73.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1651/3277 [00:21<00:22, 71.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 1659/3277 [00:21<00:23, 69.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 1667/3277 [00:21<00:23, 67.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 1674/3277 [00:22<00:24, 66.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 1681/3277 [00:22<00:24, 65.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 1688/3277 [00:22<00:24, 65.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 1695/3277 [00:22<00:24, 65.01it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 1702/3277 [00:22<00:23, 65.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 1709/3277 [00:22<00:23, 66.29it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 1716/3277 [00:22<00:23, 65.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 1723/3277 [00:22<00:24, 62.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1732/3277 [00:22<00:23, 67.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 1739/3277 [00:23<00:22, 67.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1746/3277 [00:23<00:22, 67.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 1753/3277 [00:23<00:22, 66.81it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1760/3277 [00:23<00:23, 64.03it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 1768/3277 [00:23<00:22, 67.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 1776/3277 [00:23<00:21, 69.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 1784/3277 [00:23<00:21, 70.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 1792/3277 [00:23<00:21, 69.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 1801/3277 [00:23<00:20, 72.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 1809/3277 [00:24<00:19, 74.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 1817/3277 [00:24<00:20, 70.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 1825/3277 [00:24<00:19, 73.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 1833/3277 [00:24<00:20, 70.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 1841/3277 [00:24<00:20, 71.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 1850/3277 [00:24<00:19, 74.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 1859/3277 [00:24<00:18, 76.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 1870/3277 [00:24<00:16, 84.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 1879/3277 [00:24<00:16, 84.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 1890/3277 [00:25<00:15, 89.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 1899/3277 [00:25<00:15, 88.95it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1908/3277 [00:25<00:15, 89.17it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1917/3277 [00:25<00:15, 88.94it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1926/3277 [00:25<00:15, 89.18it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1935/3277 [00:25<00:15, 87.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1945/3277 [00:25<00:14, 90.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1955/3277 [00:25<00:14, 90.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1965/3277 [00:25<00:14, 87.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1975/3277 [00:26<00:14, 88.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1984/3277 [00:26<00:15, 81.41it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1993/3277 [00:26<00:15, 82.77it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2002/3277 [00:26<00:15, 83.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2011/3277 [00:26<00:15, 83.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2021/3277 [00:26<00:14, 85.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2031/3277 [00:26<00:14, 87.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 2041/3277 [00:26<00:13, 88.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2052/3277 [00:26<00:13, 90.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2062/3277 [00:27<00:14, 83.15it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 2071/3277 [00:27<00:15, 76.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 2079/3277 [00:27<00:16, 73.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 2087/3277 [00:27<00:17, 69.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 2097/3277 [00:27<00:15, 75.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 2107/3277 [00:27<00:14, 81.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 2116/3277 [00:27<00:14, 82.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 2126/3277 [00:27<00:13, 84.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2135/3277 [00:27<00:13, 83.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 2144/3277 [00:28<00:13, 85.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 2154/3277 [00:28<00:12, 87.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 2164/3277 [00:28<00:12, 90.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 2174/3277 [00:28<00:12, 91.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 2184/3277 [00:28<00:11, 92.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 2194/3277 [00:28<00:11, 93.67it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2204/3277 [00:28<00:11, 91.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2214/3277 [00:28<00:11, 89.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2225/3277 [00:28<00:11, 92.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2235/3277 [00:29<00:11, 87.97it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2246/3277 [00:29<00:11, 91.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2257/3277 [00:29<00:10, 94.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2267/3277 [00:29<00:11, 89.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2278/3277 [00:29<00:10, 91.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2288/3277 [00:29<00:11, 88.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2299/3277 [00:29<00:10, 92.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2310/3277 [00:29<00:10, 95.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2320/3277 [00:29<00:10, 95.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2330/3277 [00:30<00:09, 95.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2340/3277 [00:30<00:09, 94.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2350/3277 [00:30<00:10, 90.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2360/3277 [00:30<00:10, 87.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2369/3277 [00:30<00:11, 80.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2378/3277 [00:30<00:11, 78.65it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2386/3277 [00:30<00:11, 77.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2396/3277 [00:30<00:10, 81.59it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2406/3277 [00:31<00:10, 84.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2415/3277 [00:31<00:10, 80.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2425/3277 [00:31<00:09, 85.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2434/3277 [00:31<00:09, 86.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2443/3277 [00:31<00:09, 85.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2452/3277 [00:31<00:09, 85.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2461/3277 [00:31<00:09, 84.61it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2471/3277 [00:31<00:09, 86.59it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2480/3277 [00:31<00:09, 85.88it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2490/3277 [00:32<00:09, 87.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2500/3277 [00:32<00:08, 90.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2510/3277 [00:32<00:08, 90.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2520/3277 [00:32<00:08, 85.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2531/3277 [00:32<00:08, 90.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2541/3277 [00:32<00:08, 88.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 2550/3277 [00:32<00:08, 85.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2559/3277 [00:32<00:08, 85.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 2569/3277 [00:32<00:08, 86.56it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2578/3277 [00:33<00:08, 84.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2588/3277 [00:33<00:07, 88.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2597/3277 [00:33<00:07, 88.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2606/3277 [00:33<00:07, 88.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2615/3277 [00:33<00:07, 87.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2624/3277 [00:33<00:07, 85.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2634/3277 [00:33<00:07, 86.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2645/3277 [00:33<00:06, 90.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2655/3277 [00:33<00:07, 88.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2666/3277 [00:33<00:06, 92.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2676/3277 [00:34<00:06, 89.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 2686/3277 [00:34<00:06, 92.04it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2696/3277 [00:34<00:06, 92.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2706/3277 [00:34<00:06, 92.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2716/3277 [00:34<00:06, 91.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2726/3277 [00:34<00:06, 86.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2737/3277 [00:34<00:05, 91.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2747/3277 [00:34<00:05, 89.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2757/3277 [00:34<00:05, 92.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 2767/3277 [00:35<00:05, 92.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 2777/3277 [00:35<00:05, 92.86it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 2787/3277 [00:35<00:05, 92.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 2797/3277 [00:35<00:05, 89.78it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2807/3277 [00:35<00:05, 90.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 2818/3277 [00:35<00:04, 94.33it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 2828/3277 [00:35<00:04, 91.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 2838/3277 [00:35<00:04, 93.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 2848/3277 [00:35<00:04, 93.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 2858/3277 [00:36<00:04, 93.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 2868/3277 [00:36<00:04, 93.64it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 2878/3277 [00:36<00:04, 91.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 2888/3277 [00:36<00:04, 93.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 2898/3277 [00:36<00:04, 91.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 2908/3277 [00:36<00:04, 82.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 2917/3277 [00:36<00:04, 78.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 2925/3277 [00:36<00:04, 74.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 2933/3277 [00:37<00:04, 71.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 2941/3277 [00:37<00:04, 72.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 2949/3277 [00:37<00:04, 71.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 2958/3277 [00:37<00:04, 76.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 2969/3277 [00:37<00:03, 83.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2978/3277 [00:37<00:03, 81.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 2989/3277 [00:37<00:03, 87.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 2999/3277 [00:37<00:03, 90.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3009/3277 [00:37<00:03, 85.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 3021/3277 [00:38<00:02, 93.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3031/3277 [00:38<00:02, 94.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3041/3277 [00:38<00:02, 89.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 3052/3277 [00:38<00:02, 92.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3063/3277 [00:38<00:02, 92.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3073/3277 [00:38<00:02, 93.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3083/3277 [00:38<00:02, 92.17it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3094/3277 [00:38<00:01, 94.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3104/3277 [00:38<00:01, 94.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3114/3277 [00:39<00:01, 87.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3124/3277 [00:39<00:01, 90.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3134/3277 [00:39<00:01, 88.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3144/3277 [00:39<00:01, 90.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3154/3277 [00:39<00:01, 92.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3164/3277 [00:39<00:01, 93.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3175/3277 [00:39<00:01, 93.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3185/3277 [00:39<00:00, 92.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3196/3277 [00:39<00:00, 95.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3206/3277 [00:40<00:00, 90.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3217/3277 [00:40<00:00, 94.11it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3227/3277 [00:40<00:00, 91.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3237/3277 [00:40<00:00, 90.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3247/3277 [00:40<00:00, 91.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3257/3277 [00:40<00:00, 91.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3268/3277 [00:40<00:00, 94.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3277/3277 [00:40<00:00, 80.30it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.6210
Epoch 1 Step 51 Train Loss: 0.5772
Epoch 1 Step 101 Train Loss: 0.6198
Epoch 1 Step 151 Train Loss: 0.5907
Epoch 1 Step 201 Train Loss: 0.5728
Epoch 1 Step 251 Train Loss: 0.5974
Epoch 1 Step 301 Train Loss: 0.5384
Epoch 1 Step 351 Train Loss: 0.5460
Epoch 1 Step 401 Train Loss: 0.5158
Epoch 1 Step 451 Train Loss: 0.5946
Epoch 1 Step 501 Train Loss: 0.5338
Epoch 1 Step 551 Train Loss: 0.5493
Epoch 1 Step 601 Train Loss: 0.5334
Epoch 1: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0163. 
Epoch 2 Step 1 Train Loss: 0.5847
Epoch 2 Step 51 Train Loss: 0.6384
Epoch 2 Step 101 Train Loss: 0.5874
Epoch 2 Step 151 Train Loss: 0.5260
Epoch 2 Step 201 Train Loss: 0.5260
Epoch 2 Step 251 Train Loss: 0.5368
Epoch 2 Step 301 Train Loss: 0.5033
Epoch 2 Step 351 Train Loss: 0.5857
Epoch 2 Step 401 Train Loss: 0.5653
Epoch 2 Step 451 Train Loss: 0.5340
Epoch 2 Step 501 Train Loss: 0.5559
Epoch 2 Step 551 Train Loss: 0.6043
Epoch 2 Step 601 Train Loss: 0.5559
Epoch 2: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0159. 
Epoch 3 Step 1 Train Loss: 0.5294
Epoch 3 Step 51 Train Loss: 0.5241
Epoch 3 Step 101 Train Loss: 0.5616
Epoch 3 Step 151 Train Loss: 0.5439
Epoch 3 Step 201 Train Loss: 0.5816
Epoch 3 Step 251 Train Loss: 0.6171
Epoch 3 Step 301 Train Loss: 0.5193
Epoch 3 Step 351 Train Loss: 0.5375
Epoch 3 Step 401 Train Loss: 0.5928
Epoch 3 Step 451 Train Loss: 0.5597
Epoch 3 Step 501 Train Loss: 0.5569
Epoch 3 Step 551 Train Loss: 0.5583
Epoch 3 Step 601 Train Loss: 0.5843
Epoch 3: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0155. 
Epoch 4 Step 1 Train Loss: 0.4816
Epoch 4 Step 51 Train Loss: 0.5137
Epoch 4 Step 101 Train Loss: 0.5941
Epoch 4 Step 151 Train Loss: 0.5408
Epoch 4 Step 201 Train Loss: 0.5597
Epoch 4 Step 251 Train Loss: 0.5404
Epoch 4 Step 301 Train Loss: 0.4926
Epoch 4 Step 351 Train Loss: 0.5343
Epoch 4 Step 401 Train Loss: 0.5232
Epoch 4 Step 451 Train Loss: 0.5555
Epoch 4 Step 501 Train Loss: 0.5126
Epoch 4 Step 551 Train Loss: 0.5199
Epoch 4 Step 601 Train Loss: 0.5660
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0156. 
Epoch 5 Step 1 Train Loss: 0.5244
Epoch 5 Step 51 Train Loss: 0.6283
Epoch 5 Step 101 Train Loss: 0.5934
Epoch 5 Step 151 Train Loss: 0.5013
Epoch 5 Step 201 Train Loss: 0.5444
Epoch 5 Step 251 Train Loss: 0.5058
Epoch 5 Step 301 Train Loss: 0.5457
Epoch 5 Step 351 Train Loss: 0.5378
Epoch 5 Step 401 Train Loss: 0.5176
Epoch 5 Step 451 Train Loss: 0.5669
Epoch 5 Step 501 Train Loss: 0.4916
Epoch 5 Step 551 Train Loss: 0.5681
Epoch 5 Step 601 Train Loss: 0.5734
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0158. 
Epoch 6 Step 1 Train Loss: 0.5575
Epoch 6 Step 51 Train Loss: 0.5362
Epoch 6 Step 101 Train Loss: 0.5904
Epoch 6 Step 151 Train Loss: 0.5215
Epoch 6 Step 201 Train Loss: 0.4880
Epoch 6 Step 251 Train Loss: 0.5383
Epoch 6 Step 301 Train Loss: 0.5620
Epoch 6 Step 351 Train Loss: 0.5526
Epoch 6 Step 401 Train Loss: 0.5469
Epoch 6 Step 451 Train Loss: 0.4991
Epoch 6 Step 501 Train Loss: 0.5053
Epoch 6 Step 551 Train Loss: 0.5564
Epoch 6 Step 601 Train Loss: 0.5420
Epoch 6: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0181 Validation Top 20 DE MSE: 0.0158. 
Epoch 7 Step 1 Train Loss: 0.5784
Epoch 7 Step 51 Train Loss: 0.5385
Epoch 7 Step 101 Train Loss: 0.5276
Epoch 7 Step 151 Train Loss: 0.5868
Epoch 7 Step 201 Train Loss: 0.5101
Epoch 7 Step 251 Train Loss: 0.5442
Epoch 7 Step 301 Train Loss: 0.5252
Epoch 7 Step 351 Train Loss: 0.6019
Epoch 7 Step 401 Train Loss: 0.5511
Epoch 7 Step 451 Train Loss: 0.5829
Epoch 7 Step 501 Train Loss: 0.5309
Epoch 7 Step 551 Train Loss: 0.5664
Epoch 7 Step 601 Train Loss: 0.5723
Epoch 7: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0305 Validation Top 20 DE MSE: 0.0158. 
Epoch 8 Step 1 Train Loss: 0.5116
Epoch 8 Step 51 Train Loss: 0.5670
Epoch 8 Step 101 Train Loss: 0.5247
Epoch 8 Step 151 Train Loss: 0.5877
Epoch 8 Step 201 Train Loss: 0.6309
Epoch 8 Step 251 Train Loss: 0.5850
Epoch 8 Step 301 Train Loss: 0.5773
Epoch 8 Step 351 Train Loss: 0.5063
Epoch 8 Step 401 Train Loss: 0.5655
Epoch 8 Step 451 Train Loss: 0.5548
Epoch 8 Step 501 Train Loss: 0.5599
Epoch 8 Step 551 Train Loss: 0.5004
Epoch 8 Step 601 Train Loss: 0.5117
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0173 Validation Top 20 DE MSE: 0.0158. 
Epoch 9 Step 1 Train Loss: 0.5379
Epoch 9 Step 51 Train Loss: 0.5591
Epoch 9 Step 101 Train Loss: 0.5480
Epoch 9 Step 151 Train Loss: 0.5127
Epoch 9 Step 201 Train Loss: 0.5302
Epoch 9 Step 251 Train Loss: 0.5354
Epoch 9 Step 301 Train Loss: 0.5086
Epoch 9 Step 351 Train Loss: 0.5421
Epoch 9 Step 401 Train Loss: 0.5354
Epoch 9 Step 451 Train Loss: 0.5276
Epoch 9 Step 501 Train Loss: 0.5516
Epoch 9 Step 551 Train Loss: 0.5466
Epoch 9 Step 601 Train Loss: 0.5801
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0178 Validation Top 20 DE MSE: 0.0158. 
Epoch 10 Step 1 Train Loss: 0.6009
Epoch 10 Step 51 Train Loss: 0.5988
Epoch 10 Step 101 Train Loss: 0.4921
Epoch 10 Step 151 Train Loss: 0.5315
Epoch 10 Step 201 Train Loss: 0.5524
Epoch 10 Step 251 Train Loss: 0.5504
Epoch 10 Step 301 Train Loss: 0.5053
Epoch 10 Step 351 Train Loss: 0.6055
Epoch 10 Step 401 Train Loss: 0.5430
Epoch 10 Step 451 Train Loss: 0.5690
Epoch 10 Step 501 Train Loss: 0.5410
Epoch 10 Step 551 Train Loss: 0.5017
Epoch 10 Step 601 Train Loss: 0.5065
Epoch 10: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0305 Validation Top 20 DE MSE: 0.0158. 
Epoch 11 Step 1 Train Loss: 0.4904
Epoch 11 Step 51 Train Loss: 0.5343
Epoch 11 Step 101 Train Loss: 0.5475
Epoch 11 Step 151 Train Loss: 0.5257
Epoch 11 Step 201 Train Loss: 0.5167
Epoch 11 Step 251 Train Loss: 0.5475
Epoch 11 Step 301 Train Loss: 0.6066
Epoch 11 Step 351 Train Loss: 0.5207
Epoch 11 Step 401 Train Loss: 0.5879
Epoch 11 Step 451 Train Loss: 0.6365
Epoch 11 Step 501 Train Loss: 0.5396
Epoch 11 Step 551 Train Loss: 0.5460
Epoch 11 Step 601 Train Loss: 0.5996
Epoch 11: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0208 Validation Top 20 DE MSE: 0.0159. 
Epoch 12 Step 1 Train Loss: 0.5812
Epoch 12 Step 51 Train Loss: 0.5869
Epoch 12 Step 101 Train Loss: 0.6040
Epoch 12 Step 151 Train Loss: 0.5317
Epoch 12 Step 201 Train Loss: 0.5085
Epoch 12 Step 251 Train Loss: 0.5193
Epoch 12 Step 301 Train Loss: 0.5299
Epoch 12 Step 351 Train Loss: 0.5337
Epoch 12 Step 401 Train Loss: 0.5753
Epoch 12 Step 451 Train Loss: 0.5962
Epoch 12 Step 501 Train Loss: 0.5298
Epoch 12 Step 551 Train Loss: 0.5473
Epoch 12 Step 601 Train Loss: 0.5240
Epoch 12: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0229 Validation Top 20 DE MSE: 0.0158. 
Epoch 13 Step 1 Train Loss: 0.5421
Epoch 13 Step 51 Train Loss: 0.5147
Epoch 13 Step 101 Train Loss: 0.5470
Epoch 13 Step 151 Train Loss: 0.5507
Epoch 13 Step 201 Train Loss: 0.5172
Epoch 13 Step 251 Train Loss: 0.5930
Epoch 13 Step 301 Train Loss: 0.5281
Epoch 13 Step 351 Train Loss: 0.5370
Epoch 13 Step 401 Train Loss: 0.5508
Epoch 13 Step 451 Train Loss: 0.6032
Epoch 13 Step 501 Train Loss: 0.5301
Epoch 13 Step 551 Train Loss: 0.5346
Epoch 13 Step 601 Train Loss: 0.5398
Epoch 13: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0236 Validation Top 20 DE MSE: 0.0159. 
Epoch 14 Step 1 Train Loss: 0.5281
Epoch 14 Step 51 Train Loss: 0.5067
Epoch 14 Step 101 Train Loss: 0.5729
Epoch 14 Step 151 Train Loss: 0.5221
Epoch 14 Step 201 Train Loss: 0.5450
Epoch 14 Step 251 Train Loss: 0.5628
Epoch 14 Step 301 Train Loss: 0.5353
Epoch 14 Step 351 Train Loss: 0.5484
Epoch 14 Step 401 Train Loss: 0.5487
Epoch 14 Step 451 Train Loss: 0.5254
Epoch 14 Step 501 Train Loss: 0.5527
Epoch 14 Step 551 Train Loss: 0.5539
Epoch 14 Step 601 Train Loss: 0.5368
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0443 Validation Top 20 DE MSE: 0.0158. 
Epoch 15 Step 1 Train Loss: 0.5454
Epoch 15 Step 51 Train Loss: 0.5567
Epoch 15 Step 101 Train Loss: 0.5539
Epoch 15 Step 151 Train Loss: 0.4755
Epoch 15 Step 201 Train Loss: 0.5878
Epoch 15 Step 251 Train Loss: 0.6003
Epoch 15 Step 301 Train Loss: 0.5896
Epoch 15 Step 351 Train Loss: 0.5372
Epoch 15 Step 401 Train Loss: 0.5574
Epoch 15 Step 451 Train Loss: 0.5142
Epoch 15 Step 501 Train Loss: 0.5263
Epoch 15 Step 551 Train Loss: 0.5509
Epoch 15 Step 601 Train Loss: 0.5650
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0165 Validation Top 20 DE MSE: 0.0158. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0092
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0011047802
test_unseen_single_pearson: 0.9969274433881858
test_unseen_single_mse_de: 0.0092011895
test_unseen_single_pearson_de: 0.9742415805094278
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2343757384405815
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.30326086956521736
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9847826086956523
test_unseen_single_mse_top20_de_non_dropout: 0.011506906
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.025 MB uploadedwandb: / 0.020 MB of 0.025 MB uploadedwandb: - 0.020 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÇ
wandb:                                             train_de_pearson ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÜ
wandb:                                                    train_mse ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÇ
wandb:                                                train_pearson ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñá
wandb:                                                training_loss ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.0092
wandb:                                              test_de_pearson 0.97424
wandb:               test_frac_opposite_direction_top20_non_dropout 0.30326
wandb:                          test_frac_sigma_below_1_non_dropout 0.98478
wandb:                                                     test_mse 0.0011
wandb:                                test_mse_top20_de_non_dropout 0.01151
wandb:                                                 test_pearson 0.99693
wandb:                                           test_pearson_delta 0.23438
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.30326
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.98478
wandb:                                       test_unseen_single_mse 0.0011
wandb:                                    test_unseen_single_mse_de 0.0092
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01151
wandb:                                   test_unseen_single_pearson 0.99693
wandb:                                test_unseen_single_pearson_de 0.97424
wandb:                             test_unseen_single_pearson_delta 0.23438
wandb:                                                 train_de_mse 0.01649
wandb:                                             train_de_pearson 0.96932
wandb:                                                    train_mse 0.00121
wandb:                                                train_pearson 0.99663
wandb:                                                training_loss 0.55695
wandb:                                                   val_de_mse 0.01582
wandb:                                               val_de_pearson 0.96417
wandb:                                                      val_mse 0.00121
wandb:                                                  val_pearson 0.99662
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRi_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/37g4j4cx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_092120-37g4j4cx/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_094506-egusgmpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRi_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/egusgmpq
wandb: WARNING Serializing object of type ndarray that is 8244928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5728
Epoch 1 Step 51 Train Loss: 0.5522
Epoch 1 Step 101 Train Loss: 0.5831
Epoch 1 Step 151 Train Loss: 0.6135
Epoch 1 Step 201 Train Loss: 0.5673
Epoch 1 Step 251 Train Loss: 0.5689
Epoch 1 Step 301 Train Loss: 0.5778
Epoch 1 Step 351 Train Loss: 0.5460
Epoch 1 Step 401 Train Loss: 0.5080
Epoch 1 Step 451 Train Loss: 0.5552
Epoch 1 Step 501 Train Loss: 0.5164
Epoch 1 Step 551 Train Loss: 0.5592
Epoch 1 Step 601 Train Loss: 0.5656
Epoch 1: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0398. 
Epoch 2 Step 1 Train Loss: 0.5587
Epoch 2 Step 51 Train Loss: 0.5772
Epoch 2 Step 101 Train Loss: 0.5761
Epoch 2 Step 151 Train Loss: 0.5611
Epoch 2 Step 201 Train Loss: 0.5533
Epoch 2 Step 251 Train Loss: 0.5613
Epoch 2 Step 301 Train Loss: 0.5843
Epoch 2 Step 351 Train Loss: 0.4707
Epoch 2 Step 401 Train Loss: 0.4902
Epoch 2 Step 451 Train Loss: 0.5569
Epoch 2 Step 501 Train Loss: 0.5442
Epoch 2 Step 551 Train Loss: 0.5614
Epoch 2 Step 601 Train Loss: 0.5601
Epoch 2: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0393. 
Epoch 3 Step 1 Train Loss: 0.5278
Epoch 3 Step 51 Train Loss: 0.5335
Epoch 3 Step 101 Train Loss: 0.5298
Epoch 3 Step 151 Train Loss: 0.5701
Epoch 3 Step 201 Train Loss: 0.5206
Epoch 3 Step 251 Train Loss: 0.5246
Epoch 3 Step 301 Train Loss: 0.5878
Epoch 3 Step 351 Train Loss: 0.5301
Epoch 3 Step 401 Train Loss: 0.5241
Epoch 3 Step 451 Train Loss: 0.5459
Epoch 3 Step 501 Train Loss: 0.5266
Epoch 3 Step 551 Train Loss: 0.5736
Epoch 3 Step 601 Train Loss: 0.5636
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0394. 
Epoch 4 Step 1 Train Loss: 0.5306
Epoch 4 Step 51 Train Loss: 0.5484
Epoch 4 Step 101 Train Loss: 0.5483
Epoch 4 Step 151 Train Loss: 0.5974
Epoch 4 Step 201 Train Loss: 0.5983
Epoch 4 Step 251 Train Loss: 0.5541
Epoch 4 Step 301 Train Loss: 0.6022
Epoch 4 Step 351 Train Loss: 0.5853
Epoch 4 Step 401 Train Loss: 0.5982
Epoch 4 Step 451 Train Loss: 0.5128
Epoch 4 Step 501 Train Loss: 0.5682
Epoch 4 Step 551 Train Loss: 0.5231
Epoch 4 Step 601 Train Loss: 0.5159
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.0392. 
Epoch 5 Step 1 Train Loss: 0.5630
Epoch 5 Step 51 Train Loss: 0.5325
Epoch 5 Step 101 Train Loss: 0.5204
Epoch 5 Step 151 Train Loss: 0.5097
Epoch 5 Step 201 Train Loss: 0.5966
Epoch 5 Step 251 Train Loss: 0.5177
Epoch 5 Step 301 Train Loss: 0.5591
Epoch 5 Step 351 Train Loss: 0.5606
Epoch 5 Step 401 Train Loss: 0.5052
Epoch 5 Step 451 Train Loss: 0.5005
Epoch 5 Step 501 Train Loss: 0.5809
Epoch 5 Step 551 Train Loss: 0.5962
Epoch 5 Step 601 Train Loss: 0.4994
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0393. 
Epoch 6 Step 1 Train Loss: 0.5619
Epoch 6 Step 51 Train Loss: 0.5420
Epoch 6 Step 101 Train Loss: 0.5524
Epoch 6 Step 151 Train Loss: 0.5542
Epoch 6 Step 201 Train Loss: 0.5375
Epoch 6 Step 251 Train Loss: 0.5241
Epoch 6 Step 301 Train Loss: 0.5588
Epoch 6 Step 351 Train Loss: 0.5501
Epoch 6 Step 401 Train Loss: 0.4946
Epoch 6 Step 451 Train Loss: 0.5419
Epoch 6 Step 501 Train Loss: 0.5150
Epoch 6 Step 551 Train Loss: 0.5343
Epoch 6 Step 601 Train Loss: 0.5250
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0391. 
Epoch 7 Step 1 Train Loss: 0.5107
Epoch 7 Step 51 Train Loss: 0.5282
Epoch 7 Step 101 Train Loss: 0.4873
Epoch 7 Step 151 Train Loss: 0.5741
Epoch 7 Step 201 Train Loss: 0.5503
Epoch 7 Step 251 Train Loss: 0.5191
Epoch 7 Step 301 Train Loss: 0.5617
Epoch 7 Step 351 Train Loss: 0.5677
Epoch 7 Step 401 Train Loss: 0.5491
Epoch 7 Step 451 Train Loss: 0.4719
Epoch 7 Step 501 Train Loss: 0.5641
Epoch 7 Step 551 Train Loss: 0.5934
Epoch 7 Step 601 Train Loss: 0.5439
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0392. 
Epoch 8 Step 1 Train Loss: 0.5545
Epoch 8 Step 51 Train Loss: 0.5512
Epoch 8 Step 101 Train Loss: 0.4864
Epoch 8 Step 151 Train Loss: 0.5655
Epoch 8 Step 201 Train Loss: 0.5511
Epoch 8 Step 251 Train Loss: 0.4968
Epoch 8 Step 301 Train Loss: 0.5056
Epoch 8 Step 351 Train Loss: 0.5157
Epoch 8 Step 401 Train Loss: 0.5270
Epoch 8 Step 451 Train Loss: 0.4992
Epoch 8 Step 501 Train Loss: 0.5110
Epoch 8 Step 551 Train Loss: 0.5419
Epoch 8 Step 601 Train Loss: 0.4753
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0392. 
Epoch 9 Step 1 Train Loss: 0.5714
Epoch 9 Step 51 Train Loss: 0.5355
Epoch 9 Step 101 Train Loss: 0.5502
Epoch 9 Step 151 Train Loss: 0.5098
Epoch 9 Step 201 Train Loss: 0.5626
Epoch 9 Step 251 Train Loss: 0.5534
Epoch 9 Step 301 Train Loss: 0.5117
Epoch 9 Step 351 Train Loss: 0.5583
Epoch 9 Step 401 Train Loss: 0.5344
Epoch 9 Step 451 Train Loss: 0.5227
Epoch 9 Step 501 Train Loss: 0.5056
Epoch 9 Step 551 Train Loss: 0.5520
Epoch 9 Step 601 Train Loss: 0.5038
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0392. 
Epoch 10 Step 1 Train Loss: 0.5905
Epoch 10 Step 51 Train Loss: 0.5217
Epoch 10 Step 101 Train Loss: 0.5792
Epoch 10 Step 151 Train Loss: 0.5596
Epoch 10 Step 201 Train Loss: 0.5921
Epoch 10 Step 251 Train Loss: 0.6122
Epoch 10 Step 301 Train Loss: 0.5211
Epoch 10 Step 351 Train Loss: 0.5664
Epoch 10 Step 401 Train Loss: 0.5232
Epoch 10 Step 451 Train Loss: 0.6056
Epoch 10 Step 501 Train Loss: 0.5642
Epoch 10 Step 551 Train Loss: 0.5323
Epoch 10 Step 601 Train Loss: 0.5206
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0392. 
Epoch 11 Step 1 Train Loss: 0.5113
Epoch 11 Step 51 Train Loss: 0.5735
Epoch 11 Step 101 Train Loss: 0.5880
Epoch 11 Step 151 Train Loss: 0.5167
Epoch 11 Step 201 Train Loss: 0.5685
Epoch 11 Step 251 Train Loss: 0.5491
Epoch 11 Step 301 Train Loss: 0.5246
Epoch 11 Step 351 Train Loss: 0.5285
Epoch 11 Step 401 Train Loss: 0.5627
Epoch 11 Step 451 Train Loss: 0.5895
Epoch 11 Step 501 Train Loss: 0.5383
Epoch 11 Step 551 Train Loss: 0.5366
Epoch 11 Step 601 Train Loss: 0.5509
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0392. 
Epoch 12 Step 1 Train Loss: 0.5396
Epoch 12 Step 51 Train Loss: 0.5594
Epoch 12 Step 101 Train Loss: 0.5247
Epoch 12 Step 151 Train Loss: 0.5411
Epoch 12 Step 201 Train Loss: 0.5756
Epoch 12 Step 251 Train Loss: 0.5155
Epoch 12 Step 301 Train Loss: 0.5969
Epoch 12 Step 351 Train Loss: 0.5620
Epoch 12 Step 401 Train Loss: 0.4463
Epoch 12 Step 451 Train Loss: 0.5803
Epoch 12 Step 501 Train Loss: 0.5263
Epoch 12 Step 551 Train Loss: 0.5589
Epoch 12 Step 601 Train Loss: 0.5498
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0392. 
Epoch 13 Step 1 Train Loss: 0.5387
Epoch 13 Step 51 Train Loss: 0.5076
Epoch 13 Step 101 Train Loss: 0.6005
Epoch 13 Step 151 Train Loss: 0.5479
Epoch 13 Step 201 Train Loss: 0.6212
Epoch 13 Step 251 Train Loss: 0.5501
Epoch 13 Step 301 Train Loss: 0.5511
Epoch 13 Step 351 Train Loss: 0.4824
Epoch 13 Step 401 Train Loss: 0.5253
Epoch 13 Step 451 Train Loss: 0.5408
Epoch 13 Step 501 Train Loss: 0.5626
Epoch 13 Step 551 Train Loss: 0.5579
Epoch 13 Step 601 Train Loss: 0.5918
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0392. 
Epoch 14 Step 1 Train Loss: 0.5749
Epoch 14 Step 51 Train Loss: 0.6076
Epoch 14 Step 101 Train Loss: 0.5536
Epoch 14 Step 151 Train Loss: 0.5571
Epoch 14 Step 201 Train Loss: 0.5610
Epoch 14 Step 251 Train Loss: 0.5475
Epoch 14 Step 301 Train Loss: 0.5530
Epoch 14 Step 351 Train Loss: 0.5576
Epoch 14 Step 401 Train Loss: 0.5048
Epoch 14 Step 451 Train Loss: 0.5731
Epoch 14 Step 501 Train Loss: 0.5901
Epoch 14 Step 551 Train Loss: 0.5119
Epoch 14 Step 601 Train Loss: 0.5521
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0392. 
Epoch 15 Step 1 Train Loss: 0.5413
Epoch 15 Step 51 Train Loss: 0.5414
Epoch 15 Step 101 Train Loss: 0.5150
Epoch 15 Step 151 Train Loss: 0.5370
Epoch 15 Step 201 Train Loss: 0.5421
Epoch 15 Step 251 Train Loss: 0.5000
Epoch 15 Step 301 Train Loss: 0.5139
Epoch 15 Step 351 Train Loss: 0.5380
Epoch 15 Step 401 Train Loss: 0.5737
Epoch 15 Step 451 Train Loss: 0.5608
Epoch 15 Step 501 Train Loss: 0.5443
Epoch 15 Step 551 Train Loss: 0.5552
Epoch 15 Step 601 Train Loss: 0.5661
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0392. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0085
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0010868292
test_unseen_single_pearson: 0.9969688257746256
test_unseen_single_mse_de: 0.008544495
test_unseen_single_pearson_de: 0.9752172592957181
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.26088203422773076
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2532608695652174
test_unseen_single_frac_sigma_below_1_non_dropout: 0.981521739130435
test_unseen_single_mse_top20_de_non_dropout: 0.01057401
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.025 MB uploadedwandb: | 0.001 MB of 0.025 MB uploadedwandb: / 0.001 MB of 0.025 MB uploadedwandb: - 0.017 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb: / 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñá‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ
wandb:                                                   val_de_mse ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00854
wandb:                                              test_de_pearson 0.97522
wandb:               test_frac_opposite_direction_top20_non_dropout 0.25326
wandb:                          test_frac_sigma_below_1_non_dropout 0.98152
wandb:                                                     test_mse 0.00109
wandb:                                test_mse_top20_de_non_dropout 0.01057
wandb:                                                 test_pearson 0.99697
wandb:                                           test_pearson_delta 0.26088
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.25326
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.98152
wandb:                                       test_unseen_single_mse 0.00109
wandb:                                    test_unseen_single_mse_de 0.00854
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01057
wandb:                                   test_unseen_single_pearson 0.99697
wandb:                                test_unseen_single_pearson_de 0.97522
wandb:                             test_unseen_single_pearson_delta 0.26088
wandb:                                                 train_de_mse 0.01022
wandb:                                             train_de_pearson 0.97018
wandb:                                                    train_mse 0.0011
wandb:                                                train_pearson 0.99694
wandb:                                                training_loss 0.54973
wandb:                                                   val_de_mse 0.0392
wandb:                                               val_de_pearson 0.97956
wandb:                                                      val_mse 0.00171
wandb:                                                  val_pearson 0.99521
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRi_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/egusgmpq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_094506-egusgmpq/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_100628-3pwfjx6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRi_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/3pwfjx6p
wandb: WARNING Serializing object of type ndarray that is 8244928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5890
Epoch 1 Step 51 Train Loss: 0.5647
Epoch 1 Step 101 Train Loss: 0.5860
Epoch 1 Step 151 Train Loss: 0.6069
Epoch 1 Step 201 Train Loss: 0.5911
Epoch 1 Step 251 Train Loss: 0.6521
Epoch 1 Step 301 Train Loss: 0.5800
Epoch 1 Step 351 Train Loss: 0.5065
Epoch 1 Step 401 Train Loss: 0.5505
Epoch 1 Step 451 Train Loss: 0.6006
Epoch 1 Step 501 Train Loss: 0.5149
Epoch 1 Step 551 Train Loss: 0.5583
Epoch 1 Step 601 Train Loss: 0.5990
Epoch 1: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0060. 
Epoch 2 Step 1 Train Loss: 0.5383
Epoch 2 Step 51 Train Loss: 0.5744
Epoch 2 Step 101 Train Loss: 0.5983
Epoch 2 Step 151 Train Loss: 0.5398
Epoch 2 Step 201 Train Loss: 0.6001
Epoch 2 Step 251 Train Loss: 0.5613
Epoch 2 Step 301 Train Loss: 0.5458
Epoch 2 Step 351 Train Loss: 0.4950
Epoch 2 Step 401 Train Loss: 0.5590
Epoch 2 Step 451 Train Loss: 0.6072
Epoch 2 Step 501 Train Loss: 0.5503
Epoch 2 Step 551 Train Loss: 0.5220
Epoch 2 Step 601 Train Loss: 0.5200
Epoch 2: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0131 Validation Top 20 DE MSE: 0.0055. 
Epoch 3 Step 1 Train Loss: 0.4799
Epoch 3 Step 51 Train Loss: 0.5422
Epoch 3 Step 101 Train Loss: 0.5052
Epoch 3 Step 151 Train Loss: 0.5034
Epoch 3 Step 201 Train Loss: 0.5471
Epoch 3 Step 251 Train Loss: 0.5048
Epoch 3 Step 301 Train Loss: 0.5788
Epoch 3 Step 351 Train Loss: 0.5020
Epoch 3 Step 401 Train Loss: 0.5369
Epoch 3 Step 451 Train Loss: 0.5433
Epoch 3 Step 501 Train Loss: 0.5080
Epoch 3 Step 551 Train Loss: 0.4938
Epoch 3 Step 601 Train Loss: 0.5508
Epoch 3: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0054. 
Epoch 4 Step 1 Train Loss: 0.5980
Epoch 4 Step 51 Train Loss: 0.6181
Epoch 4 Step 101 Train Loss: 0.5965
Epoch 4 Step 151 Train Loss: 0.5637
Epoch 4 Step 201 Train Loss: 0.5230
Epoch 4 Step 251 Train Loss: 0.4969
Epoch 4 Step 301 Train Loss: 0.5897
Epoch 4 Step 351 Train Loss: 0.5189
Epoch 4 Step 401 Train Loss: 0.5471
Epoch 4 Step 451 Train Loss: 0.5713
Epoch 4 Step 501 Train Loss: 0.5843
Epoch 4 Step 551 Train Loss: 0.4998
Epoch 4 Step 601 Train Loss: 0.5541
Epoch 4: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0149 Validation Top 20 DE MSE: 0.0055. 
Epoch 5 Step 1 Train Loss: 0.5147
Epoch 5 Step 51 Train Loss: 0.5746
Epoch 5 Step 101 Train Loss: 0.5411
Epoch 5 Step 151 Train Loss: 0.5640
Epoch 5 Step 201 Train Loss: 0.5074
Epoch 5 Step 251 Train Loss: 0.6807
Epoch 5 Step 301 Train Loss: 0.5300
Epoch 5 Step 351 Train Loss: 0.5061
Epoch 5 Step 401 Train Loss: 0.5556
Epoch 5 Step 451 Train Loss: 0.4940
Epoch 5 Step 501 Train Loss: 0.5401
Epoch 5 Step 551 Train Loss: 0.5880
Epoch 5 Step 601 Train Loss: 0.5453
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0054. 
Epoch 6 Step 1 Train Loss: 0.5733
Epoch 6 Step 51 Train Loss: 0.5548
Epoch 6 Step 101 Train Loss: 0.5323
Epoch 6 Step 151 Train Loss: 0.5840
Epoch 6 Step 201 Train Loss: 0.5269
Epoch 6 Step 251 Train Loss: 0.5410
Epoch 6 Step 301 Train Loss: 0.5494
Epoch 6 Step 351 Train Loss: 0.5585
Epoch 6 Step 401 Train Loss: 0.5299
Epoch 6 Step 451 Train Loss: 0.5555
Epoch 6 Step 501 Train Loss: 0.6317
Epoch 6 Step 551 Train Loss: 0.4980
Epoch 6 Step 601 Train Loss: 0.5493
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0182 Validation Top 20 DE MSE: 0.0054. 
Epoch 7 Step 1 Train Loss: 0.5463
Epoch 7 Step 51 Train Loss: 0.5118
Epoch 7 Step 101 Train Loss: 0.5318
Epoch 7 Step 151 Train Loss: 0.5960
Epoch 7 Step 201 Train Loss: 0.5211
Epoch 7 Step 251 Train Loss: 0.5546
Epoch 7 Step 301 Train Loss: 0.5076
Epoch 7 Step 351 Train Loss: 0.5410
Epoch 7 Step 401 Train Loss: 0.5450
Epoch 7 Step 451 Train Loss: 0.5486
Epoch 7 Step 501 Train Loss: 0.5979
Epoch 7 Step 551 Train Loss: 0.5028
Epoch 7 Step 601 Train Loss: 0.6028
Epoch 7: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0378 Validation Top 20 DE MSE: 0.0054. 
Epoch 8 Step 1 Train Loss: 0.5125
Epoch 8 Step 51 Train Loss: 0.5267
Epoch 8 Step 101 Train Loss: 0.5430
Epoch 8 Step 151 Train Loss: 0.5592
Epoch 8 Step 201 Train Loss: 0.5675
Epoch 8 Step 251 Train Loss: 0.5731
Epoch 8 Step 301 Train Loss: 0.5177
Epoch 8 Step 351 Train Loss: 0.5515
Epoch 8 Step 401 Train Loss: 0.5133
Epoch 8 Step 451 Train Loss: 0.5453
Epoch 8 Step 501 Train Loss: 0.5779
Epoch 8 Step 551 Train Loss: 0.5487
Epoch 8 Step 601 Train Loss: 0.5016
Epoch 8: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0418 Validation Top 20 DE MSE: 0.0054. 
Epoch 9 Step 1 Train Loss: 0.5048
Epoch 9 Step 51 Train Loss: 0.5087
Epoch 9 Step 101 Train Loss: 0.5414
Epoch 9 Step 151 Train Loss: 0.5473
Epoch 9 Step 201 Train Loss: 0.5471
Epoch 9 Step 251 Train Loss: 0.5128
Epoch 9 Step 301 Train Loss: 0.5568
Epoch 9 Step 351 Train Loss: 0.5278
Epoch 9 Step 401 Train Loss: 0.5414
Epoch 9 Step 451 Train Loss: 0.5165
Epoch 9 Step 501 Train Loss: 0.5503
Epoch 9 Step 551 Train Loss: 0.5305
Epoch 9 Step 601 Train Loss: 0.5330
Epoch 9: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0528 Validation Top 20 DE MSE: 0.0054. 
Epoch 10 Step 1 Train Loss: 0.5474
Epoch 10 Step 51 Train Loss: 0.4990
Epoch 10 Step 101 Train Loss: 0.5405
Epoch 10 Step 151 Train Loss: 0.5297
Epoch 10 Step 201 Train Loss: 0.5574
Epoch 10 Step 251 Train Loss: 0.5121
Epoch 10 Step 301 Train Loss: 0.5880
Epoch 10 Step 351 Train Loss: 0.5351
Epoch 10 Step 401 Train Loss: 0.5730
Epoch 10 Step 451 Train Loss: 0.5492
Epoch 10 Step 501 Train Loss: 0.6111
Epoch 10 Step 551 Train Loss: 0.5333
Epoch 10 Step 601 Train Loss: 0.4950
Epoch 10: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0595 Validation Top 20 DE MSE: 0.0054. 
Epoch 11 Step 1 Train Loss: 0.5218
Epoch 11 Step 51 Train Loss: 0.5205
Epoch 11 Step 101 Train Loss: 0.5534
Epoch 11 Step 151 Train Loss: 0.4937
Epoch 11 Step 201 Train Loss: 0.5748
Epoch 11 Step 251 Train Loss: 0.5548
Epoch 11 Step 301 Train Loss: 0.5366
Epoch 11 Step 351 Train Loss: 0.5286
Epoch 11 Step 401 Train Loss: 0.5173
Epoch 11 Step 451 Train Loss: 0.5245
Epoch 11 Step 501 Train Loss: 0.5364
Epoch 11 Step 551 Train Loss: 0.5437
Epoch 11 Step 601 Train Loss: 0.5186
Epoch 11: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0348 Validation Top 20 DE MSE: 0.0054. 
Epoch 12 Step 1 Train Loss: 0.5556
Epoch 12 Step 51 Train Loss: 0.5529
Epoch 12 Step 101 Train Loss: 0.5028
Epoch 12 Step 151 Train Loss: 0.5522
Epoch 12 Step 201 Train Loss: 0.5656
Epoch 12 Step 251 Train Loss: 0.5069
Epoch 12 Step 301 Train Loss: 0.5286
Epoch 12 Step 351 Train Loss: 0.5303
Epoch 12 Step 401 Train Loss: 0.5371
Epoch 12 Step 451 Train Loss: 0.5323
Epoch 12 Step 501 Train Loss: 0.4770
Epoch 12 Step 551 Train Loss: 0.6077
Epoch 12 Step 601 Train Loss: 0.5455
Epoch 12: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0696 Validation Top 20 DE MSE: 0.0054. 
Epoch 13 Step 1 Train Loss: 0.5272
Epoch 13 Step 51 Train Loss: 0.5278
Epoch 13 Step 101 Train Loss: 0.5503
Epoch 13 Step 151 Train Loss: 0.5707
Epoch 13 Step 201 Train Loss: 0.5038
Epoch 13 Step 251 Train Loss: 0.5328
Epoch 13 Step 301 Train Loss: 0.5063
Epoch 13 Step 351 Train Loss: 0.5701
Epoch 13 Step 401 Train Loss: 0.5334
Epoch 13 Step 451 Train Loss: 0.5492
Epoch 13 Step 501 Train Loss: 0.4920
Epoch 13 Step 551 Train Loss: 0.5249
Epoch 13 Step 601 Train Loss: 0.5064
Epoch 13: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0605 Validation Top 20 DE MSE: 0.0054. 
Epoch 14 Step 1 Train Loss: 0.4929
Epoch 14 Step 51 Train Loss: 0.5328
Epoch 14 Step 101 Train Loss: 0.5413
Epoch 14 Step 151 Train Loss: 0.5590
Epoch 14 Step 201 Train Loss: 0.5550
Epoch 14 Step 251 Train Loss: 0.5008
Epoch 14 Step 301 Train Loss: 0.5632
Epoch 14 Step 351 Train Loss: 0.5404
Epoch 14 Step 401 Train Loss: 0.5714
Epoch 14 Step 451 Train Loss: 0.5811
Epoch 14 Step 501 Train Loss: 0.5347
Epoch 14 Step 551 Train Loss: 0.5997
Epoch 14 Step 601 Train Loss: 0.5367
Epoch 14: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0937 Validation Top 20 DE MSE: 0.0054. 
Epoch 15 Step 1 Train Loss: 0.5274
Epoch 15 Step 51 Train Loss: 0.5567
Epoch 15 Step 101 Train Loss: 0.5655
Epoch 15 Step 151 Train Loss: 0.5691
Epoch 15 Step 201 Train Loss: 0.5731
Epoch 15 Step 251 Train Loss: 0.5257
Epoch 15 Step 301 Train Loss: 0.5876
Epoch 15 Step 351 Train Loss: 0.5635
Epoch 15 Step 401 Train Loss: 0.5364
Epoch 15 Step 451 Train Loss: 0.5323
Epoch 15 Step 501 Train Loss: 0.5637
Epoch 15 Step 551 Train Loss: 0.5582
Epoch 15 Step 601 Train Loss: 0.5158
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0196 Validation Top 20 DE MSE: 0.0054. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0122
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0012160719
test_unseen_single_pearson: 0.9966195811799774
test_unseen_single_mse_de: 0.012170235
test_unseen_single_pearson_de: 0.9694667944605809
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2317976447473716
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.26304347826086955
test_unseen_single_frac_sigma_below_1_non_dropout: 0.982608695652174
test_unseen_single_mse_top20_de_non_dropout: 0.014366439
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.001 MB of 0.025 MB uploadedwandb: / 0.003 MB of 0.025 MB uploadedwandb: - 0.023 MB of 0.025 MB uploadedwandb: \ 0.023 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÇ
wandb:                                             train_de_pearson ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÜ
wandb:                                                    train_mse ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÇ
wandb:                                                train_pearson ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñá
wandb:                                                training_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñá‚ñá‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01217
wandb:                                              test_de_pearson 0.96947
wandb:               test_frac_opposite_direction_top20_non_dropout 0.26304
wandb:                          test_frac_sigma_below_1_non_dropout 0.98261
wandb:                                                     test_mse 0.00122
wandb:                                test_mse_top20_de_non_dropout 0.01437
wandb:                                                 test_pearson 0.99662
wandb:                                           test_pearson_delta 0.2318
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.26304
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.98261
wandb:                                       test_unseen_single_mse 0.00122
wandb:                                    test_unseen_single_mse_de 0.01217
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01437
wandb:                                   test_unseen_single_pearson 0.99662
wandb:                                test_unseen_single_pearson_de 0.96947
wandb:                             test_unseen_single_pearson_delta 0.2318
wandb:                                                 train_de_mse 0.01962
wandb:                                             train_de_pearson 0.97017
wandb:                                                    train_mse 0.00124
wandb:                                                train_pearson 0.99657
wandb:                                                training_loss 0.58537
wandb:                                                   val_de_mse 0.00538
wandb:                                               val_de_pearson 0.95865
wandb:                                                      val_mse 0.00113
wandb:                                                  val_pearson 0.99684
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRi_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/3pwfjx6p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_100628-3pwfjx6p/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_103055-9q87828s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRi_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/9q87828s
wandb: WARNING Serializing object of type ndarray that is 8244928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5466
Epoch 1 Step 51 Train Loss: 0.5521
Epoch 1 Step 101 Train Loss: 0.5833
Epoch 1 Step 151 Train Loss: 0.5888
Epoch 1 Step 201 Train Loss: 0.5717
Epoch 1 Step 251 Train Loss: 0.5422
Epoch 1 Step 301 Train Loss: 0.5291
Epoch 1 Step 351 Train Loss: 0.5883
Epoch 1 Step 401 Train Loss: 0.5328
Epoch 1 Step 451 Train Loss: 0.5054
Epoch 1 Step 501 Train Loss: 0.5459
Epoch 1 Step 551 Train Loss: 0.5797
Epoch 1 Step 601 Train Loss: 0.6266
Epoch 1: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0134 Validation Top 20 DE MSE: 0.0104. 
Epoch 2 Step 1 Train Loss: 0.5290
Epoch 2 Step 51 Train Loss: 0.5249
Epoch 2 Step 101 Train Loss: 0.5509
Epoch 2 Step 151 Train Loss: 0.5467
Epoch 2 Step 201 Train Loss: 0.4596
Epoch 2 Step 251 Train Loss: 0.5712
Epoch 2 Step 301 Train Loss: 0.5766
Epoch 2 Step 351 Train Loss: 0.5336
Epoch 2 Step 401 Train Loss: 0.6208
Epoch 2 Step 451 Train Loss: 0.5884
Epoch 2 Step 501 Train Loss: 0.5351
Epoch 2 Step 551 Train Loss: 0.5448
Epoch 2 Step 601 Train Loss: 0.5471
Epoch 2: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0097. 
Epoch 3 Step 1 Train Loss: 0.4983
Epoch 3 Step 51 Train Loss: 0.5095
Epoch 3 Step 101 Train Loss: 0.5145
Epoch 3 Step 151 Train Loss: 0.5241
Epoch 3 Step 201 Train Loss: 0.4650
Epoch 3 Step 251 Train Loss: 0.5751
Epoch 3 Step 301 Train Loss: 0.5336
Epoch 3 Step 351 Train Loss: 0.5490
Epoch 3 Step 401 Train Loss: 0.6058
Epoch 3 Step 451 Train Loss: 0.5670
Epoch 3 Step 501 Train Loss: 0.5546
Epoch 3 Step 551 Train Loss: 0.5557
Epoch 3 Step 601 Train Loss: 0.5884
Epoch 3: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0100. 
Epoch 4 Step 1 Train Loss: 0.4990
Epoch 4 Step 51 Train Loss: 0.6108
Epoch 4 Step 101 Train Loss: 0.5541
Epoch 4 Step 151 Train Loss: 0.6102
Epoch 4 Step 201 Train Loss: 0.5507
Epoch 4 Step 251 Train Loss: 0.6070
Epoch 4 Step 301 Train Loss: 0.5509
Epoch 4 Step 351 Train Loss: 0.5209
Epoch 4 Step 401 Train Loss: 0.5959
Epoch 4 Step 451 Train Loss: 0.5713
Epoch 4 Step 501 Train Loss: 0.5244
Epoch 4 Step 551 Train Loss: 0.5764
Epoch 4 Step 601 Train Loss: 0.5045
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0098. 
Epoch 5 Step 1 Train Loss: 0.5263
Epoch 5 Step 51 Train Loss: 0.5547
Epoch 5 Step 101 Train Loss: 0.5345
Epoch 5 Step 151 Train Loss: 0.5400
Epoch 5 Step 201 Train Loss: 0.5465
Epoch 5 Step 251 Train Loss: 0.5464
Epoch 5 Step 301 Train Loss: 0.5465
Epoch 5 Step 351 Train Loss: 0.4935
Epoch 5 Step 401 Train Loss: 0.5728
Epoch 5 Step 451 Train Loss: 0.5732
Epoch 5 Step 501 Train Loss: 0.5783
Epoch 5 Step 551 Train Loss: 0.5572
Epoch 5 Step 601 Train Loss: 0.4764
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0098. 
Epoch 6 Step 1 Train Loss: 0.5578
Epoch 6 Step 51 Train Loss: 0.5543
Epoch 6 Step 101 Train Loss: 0.5448
Epoch 6 Step 151 Train Loss: 0.5752
Epoch 6 Step 201 Train Loss: 0.5330
Epoch 6 Step 251 Train Loss: 0.5386
Epoch 6 Step 301 Train Loss: 0.5101
Epoch 6 Step 351 Train Loss: 0.5606
Epoch 6 Step 401 Train Loss: 0.6117
Epoch 6 Step 451 Train Loss: 0.5393
Epoch 6 Step 501 Train Loss: 0.5672
Epoch 6 Step 551 Train Loss: 0.4939
Epoch 6 Step 601 Train Loss: 0.5122
Epoch 6: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0214 Validation Top 20 DE MSE: 0.0098. 
Epoch 7 Step 1 Train Loss: 0.5778
Epoch 7 Step 51 Train Loss: 0.5414
Epoch 7 Step 101 Train Loss: 0.5787
Epoch 7 Step 151 Train Loss: 0.5629
Epoch 7 Step 201 Train Loss: 0.5132
Epoch 7 Step 251 Train Loss: 0.4977
Epoch 7 Step 301 Train Loss: 0.5524
Epoch 7 Step 351 Train Loss: 0.5662
Epoch 7 Step 401 Train Loss: 0.5636
Epoch 7 Step 451 Train Loss: 0.5758
Epoch 7 Step 501 Train Loss: 0.5695
Epoch 7 Step 551 Train Loss: 0.5000
Epoch 7 Step 601 Train Loss: 0.5956
Epoch 7: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0098. 
Epoch 8 Step 1 Train Loss: 0.5233
Epoch 8 Step 51 Train Loss: 0.4959
Epoch 8 Step 101 Train Loss: 0.5077
Epoch 8 Step 151 Train Loss: 0.4999
Epoch 8 Step 201 Train Loss: 0.6011
Epoch 8 Step 251 Train Loss: 0.5711
Epoch 8 Step 301 Train Loss: 0.5384
Epoch 8 Step 351 Train Loss: 0.5404
Epoch 8 Step 401 Train Loss: 0.5101
Epoch 8 Step 451 Train Loss: 0.4957
Epoch 8 Step 501 Train Loss: 0.5383
Epoch 8 Step 551 Train Loss: 0.5076
Epoch 8 Step 601 Train Loss: 0.5470
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0158 Validation Top 20 DE MSE: 0.0098. 
Epoch 9 Step 1 Train Loss: 0.5279
Epoch 9 Step 51 Train Loss: 0.5423
Epoch 9 Step 101 Train Loss: 0.5427
Epoch 9 Step 151 Train Loss: 0.5970
Epoch 9 Step 201 Train Loss: 0.5666
Epoch 9 Step 251 Train Loss: 0.5942
Epoch 9 Step 301 Train Loss: 0.5031
Epoch 9 Step 351 Train Loss: 0.5306
Epoch 9 Step 401 Train Loss: 0.5026
Epoch 9 Step 451 Train Loss: 0.5075
Epoch 9 Step 501 Train Loss: 0.5201
Epoch 9 Step 551 Train Loss: 0.5603
Epoch 9 Step 601 Train Loss: 0.5296
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0174 Validation Top 20 DE MSE: 0.0098. 
Epoch 10 Step 1 Train Loss: 0.5112
Epoch 10 Step 51 Train Loss: 0.5668
Epoch 10 Step 101 Train Loss: 0.5358
Epoch 10 Step 151 Train Loss: 0.5565
Epoch 10 Step 201 Train Loss: 0.6499
Epoch 10 Step 251 Train Loss: 0.5779
Epoch 10 Step 301 Train Loss: 0.5261
Epoch 10 Step 351 Train Loss: 0.5652
Epoch 10 Step 401 Train Loss: 0.5786
Epoch 10 Step 451 Train Loss: 0.5881
Epoch 10 Step 501 Train Loss: 0.5607
Epoch 10 Step 551 Train Loss: 0.5230
Epoch 10 Step 601 Train Loss: 0.5352
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0153 Validation Top 20 DE MSE: 0.0098. 
Epoch 11 Step 1 Train Loss: 0.5513
Epoch 11 Step 51 Train Loss: 0.5168
Epoch 11 Step 101 Train Loss: 0.6026
Epoch 11 Step 151 Train Loss: 0.5512
Epoch 11 Step 201 Train Loss: 0.5971
Epoch 11 Step 251 Train Loss: 0.5491
Epoch 11 Step 301 Train Loss: 0.5218
Epoch 11 Step 351 Train Loss: 0.5674
Epoch 11 Step 401 Train Loss: 0.5455
Epoch 11 Step 451 Train Loss: 0.5219
Epoch 11 Step 501 Train Loss: 0.5816
Epoch 11 Step 551 Train Loss: 0.5680
Epoch 11 Step 601 Train Loss: 0.5718
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0192 Validation Top 20 DE MSE: 0.0098. 
Epoch 12 Step 1 Train Loss: 0.5501
Epoch 12 Step 51 Train Loss: 0.5858
Epoch 12 Step 101 Train Loss: 0.5613
Epoch 12 Step 151 Train Loss: 0.5281
Epoch 12 Step 201 Train Loss: 0.5428
Epoch 12 Step 251 Train Loss: 0.5727
Epoch 12 Step 301 Train Loss: 0.5472
Epoch 12 Step 351 Train Loss: 0.5513
Epoch 12 Step 401 Train Loss: 0.5249
Epoch 12 Step 451 Train Loss: 0.5153
Epoch 12 Step 501 Train Loss: 0.5609
Epoch 12 Step 551 Train Loss: 0.6255
Epoch 12 Step 601 Train Loss: 0.5605
Epoch 12: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0198 Validation Top 20 DE MSE: 0.0098. 
Epoch 13 Step 1 Train Loss: 0.4965
Epoch 13 Step 51 Train Loss: 0.4969
Epoch 13 Step 101 Train Loss: 0.4895
Epoch 13 Step 151 Train Loss: 0.5812
Epoch 13 Step 201 Train Loss: 0.5437
Epoch 13 Step 251 Train Loss: 0.5135
Epoch 13 Step 301 Train Loss: 0.5424
Epoch 13 Step 351 Train Loss: 0.5401
Epoch 13 Step 401 Train Loss: 0.5342
Epoch 13 Step 451 Train Loss: 0.5400
Epoch 13 Step 501 Train Loss: 0.5071
Epoch 13 Step 551 Train Loss: 0.5456
Epoch 13 Step 601 Train Loss: 0.5297
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0183 Validation Top 20 DE MSE: 0.0098. 
Epoch 14 Step 1 Train Loss: 0.5084
Epoch 14 Step 51 Train Loss: 0.5528
Epoch 14 Step 101 Train Loss: 0.5633
Epoch 14 Step 151 Train Loss: 0.5422
Epoch 14 Step 201 Train Loss: 0.5730
Epoch 14 Step 251 Train Loss: 0.5636
Epoch 14 Step 301 Train Loss: 0.5189
Epoch 14 Step 351 Train Loss: 0.5432
Epoch 14 Step 401 Train Loss: 0.5946
Epoch 14 Step 451 Train Loss: 0.5595
Epoch 14 Step 501 Train Loss: 0.5464
Epoch 14 Step 551 Train Loss: 0.5514
Epoch 14 Step 601 Train Loss: 0.5832
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0149 Validation Top 20 DE MSE: 0.0098. 
Epoch 15 Step 1 Train Loss: 0.5583
Epoch 15 Step 51 Train Loss: 0.5286
Epoch 15 Step 101 Train Loss: 0.5445
Epoch 15 Step 151 Train Loss: 0.5901
Epoch 15 Step 201 Train Loss: 0.5204
Epoch 15 Step 251 Train Loss: 0.5870
Epoch 15 Step 301 Train Loss: 0.6010
Epoch 15 Step 351 Train Loss: 0.5308
Epoch 15 Step 401 Train Loss: 0.4797
Epoch 15 Step 451 Train Loss: 0.5693
Epoch 15 Step 501 Train Loss: 0.5479
Epoch 15 Step 551 Train Loss: 0.5069
Epoch 15 Step 601 Train Loss: 0.5385
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0132 Validation Top 20 DE MSE: 0.0098. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0094
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0011762384
test_unseen_single_pearson: 0.996722786261872
test_unseen_single_mse_de: 0.009382309
test_unseen_single_pearson_de: 0.9718542233384574
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.26019010454467745
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2760869565217391
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9782608695652174
test_unseen_single_mse_top20_de_non_dropout: 0.010959654
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.001 MB uploadedwandb: / 0.001 MB of 0.025 MB uploadedwandb: - 0.007 MB of 0.025 MB uploadedwandb: \ 0.007 MB of 0.025 MB uploadedwandb: | 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:                                                training_loss ‚ñà‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00938
wandb:                                              test_de_pearson 0.97185
wandb:               test_frac_opposite_direction_top20_non_dropout 0.27609
wandb:                          test_frac_sigma_below_1_non_dropout 0.97826
wandb:                                                     test_mse 0.00118
wandb:                                test_mse_top20_de_non_dropout 0.01096
wandb:                                                 test_pearson 0.99672
wandb:                                           test_pearson_delta 0.26019
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.27609
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.97826
wandb:                                       test_unseen_single_mse 0.00118
wandb:                                    test_unseen_single_mse_de 0.00938
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01096
wandb:                                   test_unseen_single_pearson 0.99672
wandb:                                test_unseen_single_pearson_de 0.97185
wandb:                             test_unseen_single_pearson_delta 0.26019
wandb:                                                 train_de_mse 0.01323
wandb:                                             train_de_pearson 0.97123
wandb:                                                    train_mse 0.00115
wandb:                                                train_pearson 0.9968
wandb:                                                training_loss 0.55249
wandb:                                                   val_de_mse 0.00984
wandb:                                               val_de_pearson 0.96858
wandb:                                                      val_mse 0.0013
wandb:                                                  val_pearson 0.9964
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRi_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/9q87828s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_103055-9q87828s/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:46
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_105406-4wu0kvlw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2021_CRISPRi_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/4wu0kvlw
wandb: WARNING Serializing object of type ndarray that is 8244928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4908
Epoch 1 Step 51 Train Loss: 0.5488
Epoch 1 Step 101 Train Loss: 0.5190
Epoch 1 Step 151 Train Loss: 0.5103
Epoch 1 Step 201 Train Loss: 0.5579
Epoch 1 Step 251 Train Loss: 0.6206
Epoch 1 Step 301 Train Loss: 0.5839
Epoch 1 Step 351 Train Loss: 0.5945
Epoch 1 Step 401 Train Loss: 0.5193
Epoch 1 Step 451 Train Loss: 0.5581
Epoch 1 Step 501 Train Loss: 0.5338
Epoch 1 Step 551 Train Loss: 0.5528
Epoch 1 Step 601 Train Loss: 0.6252
Epoch 1: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0169. 
Epoch 2 Step 1 Train Loss: 0.5552
Epoch 2 Step 51 Train Loss: 0.5313
Epoch 2 Step 101 Train Loss: 0.5357
Epoch 2 Step 151 Train Loss: 0.5329
Epoch 2 Step 201 Train Loss: 0.5204
Epoch 2 Step 251 Train Loss: 0.5245
Epoch 2 Step 301 Train Loss: 0.5847
Epoch 2 Step 351 Train Loss: 0.5484
Epoch 2 Step 401 Train Loss: 0.5645
Epoch 2 Step 451 Train Loss: 0.5389
Epoch 2 Step 501 Train Loss: 0.5778
Epoch 2 Step 551 Train Loss: 0.5763
Epoch 2 Step 601 Train Loss: 0.5514
Epoch 2: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0171. 
Epoch 3 Step 1 Train Loss: 0.5713
Epoch 3 Step 51 Train Loss: 0.5952
Epoch 3 Step 101 Train Loss: 0.5831
Epoch 3 Step 151 Train Loss: 0.5619
Epoch 3 Step 201 Train Loss: 0.5269
Epoch 3 Step 251 Train Loss: 0.4877
Epoch 3 Step 301 Train Loss: 0.5192
Epoch 3 Step 351 Train Loss: 0.5434
Epoch 3 Step 401 Train Loss: 0.4773
Epoch 3 Step 451 Train Loss: 0.4897
Epoch 3 Step 501 Train Loss: 0.6043
Epoch 3 Step 551 Train Loss: 0.5079
Epoch 3 Step 601 Train Loss: 0.5526
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0172. 
Epoch 4 Step 1 Train Loss: 0.5256
Epoch 4 Step 51 Train Loss: 0.5690
Epoch 4 Step 101 Train Loss: 0.5750
Epoch 4 Step 151 Train Loss: 0.5438
Epoch 4 Step 201 Train Loss: 0.5656
Epoch 4 Step 251 Train Loss: 0.5354
Epoch 4 Step 301 Train Loss: 0.5114
Epoch 4 Step 351 Train Loss: 0.5331
Epoch 4 Step 401 Train Loss: 0.5212
Epoch 4 Step 451 Train Loss: 0.5901
Epoch 4 Step 501 Train Loss: 0.5854
Epoch 4 Step 551 Train Loss: 0.5458
Epoch 4 Step 601 Train Loss: 0.4845
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0171. 
Epoch 5 Step 1 Train Loss: 0.4886
Epoch 5 Step 51 Train Loss: 0.5261
Epoch 5 Step 101 Train Loss: 0.6273
Epoch 5 Step 151 Train Loss: 0.6102
Epoch 5 Step 201 Train Loss: 0.5391
Epoch 5 Step 251 Train Loss: 0.5399
Epoch 5 Step 301 Train Loss: 0.5293
Epoch 5 Step 351 Train Loss: 0.5730
Epoch 5 Step 401 Train Loss: 0.5307
Epoch 5 Step 451 Train Loss: 0.5287
Epoch 5 Step 501 Train Loss: 0.5724
Epoch 5 Step 551 Train Loss: 0.6171
Epoch 5 Step 601 Train Loss: 0.5205
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0169. 
Epoch 6 Step 1 Train Loss: 0.5007
Epoch 6 Step 51 Train Loss: 0.5526
Epoch 6 Step 101 Train Loss: 0.5427
Epoch 6 Step 151 Train Loss: 0.5624
Epoch 6 Step 201 Train Loss: 0.5248
Epoch 6 Step 251 Train Loss: 0.4694
Epoch 6 Step 301 Train Loss: 0.6141
Epoch 6 Step 351 Train Loss: 0.5683
Epoch 6 Step 401 Train Loss: 0.5116
Epoch 6 Step 451 Train Loss: 0.5024
Epoch 6 Step 501 Train Loss: 0.5607
Epoch 6 Step 551 Train Loss: 0.5800
Epoch 6 Step 601 Train Loss: 0.4702
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0169. 
Epoch 7 Step 1 Train Loss: 0.5143
Epoch 7 Step 51 Train Loss: 0.5108
Epoch 7 Step 101 Train Loss: 0.5497
Epoch 7 Step 151 Train Loss: 0.5530
Epoch 7 Step 201 Train Loss: 0.5304
Epoch 7 Step 251 Train Loss: 0.5401
Epoch 7 Step 301 Train Loss: 0.5111
Epoch 7 Step 351 Train Loss: 0.5871
Epoch 7 Step 401 Train Loss: 0.5432
Epoch 7 Step 451 Train Loss: 0.5445
Epoch 7 Step 501 Train Loss: 0.6198
Epoch 7 Step 551 Train Loss: 0.4957
Epoch 7 Step 601 Train Loss: 0.5485
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 8 Step 1 Train Loss: 0.4905
Epoch 8 Step 51 Train Loss: 0.5030
Epoch 8 Step 101 Train Loss: 0.5812
Epoch 8 Step 151 Train Loss: 0.5687
Epoch 8 Step 201 Train Loss: 0.5415
Epoch 8 Step 251 Train Loss: 0.5310
Epoch 8 Step 301 Train Loss: 0.5131
Epoch 8 Step 351 Train Loss: 0.6298
Epoch 8 Step 401 Train Loss: 0.5204
Epoch 8 Step 451 Train Loss: 0.5149
Epoch 8 Step 501 Train Loss: 0.5396
Epoch 8 Step 551 Train Loss: 0.4928
Epoch 8 Step 601 Train Loss: 0.5216
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 9 Step 1 Train Loss: 0.5394
Epoch 9 Step 51 Train Loss: 0.5576
Epoch 9 Step 101 Train Loss: 0.5276
Epoch 9 Step 151 Train Loss: 0.5471
Epoch 9 Step 201 Train Loss: 0.5656
Epoch 9 Step 251 Train Loss: 0.5191
Epoch 9 Step 301 Train Loss: 0.5678
Epoch 9 Step 351 Train Loss: 0.5260
Epoch 9 Step 401 Train Loss: 0.4806
Epoch 9 Step 451 Train Loss: 0.4675
Epoch 9 Step 501 Train Loss: 0.5245
Epoch 9 Step 551 Train Loss: 0.5385
Epoch 9 Step 601 Train Loss: 0.5636
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 10 Step 1 Train Loss: 0.5087
Epoch 10 Step 51 Train Loss: 0.5277
Epoch 10 Step 101 Train Loss: 0.5405
Epoch 10 Step 151 Train Loss: 0.5159
Epoch 10 Step 201 Train Loss: 0.5228
Epoch 10 Step 251 Train Loss: 0.5466
Epoch 10 Step 301 Train Loss: 0.5627
Epoch 10 Step 351 Train Loss: 0.5899
Epoch 10 Step 401 Train Loss: 0.6006
Epoch 10 Step 451 Train Loss: 0.5639
Epoch 10 Step 501 Train Loss: 0.5052
Epoch 10 Step 551 Train Loss: 0.5906
Epoch 10 Step 601 Train Loss: 0.5728
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 11 Step 1 Train Loss: 0.5485
Epoch 11 Step 51 Train Loss: 0.5291
Epoch 11 Step 101 Train Loss: 0.5359
Epoch 11 Step 151 Train Loss: 0.4821
Epoch 11 Step 201 Train Loss: 0.5571
Epoch 11 Step 251 Train Loss: 0.5364
Epoch 11 Step 301 Train Loss: 0.4773
Epoch 11 Step 351 Train Loss: 0.5758
Epoch 11 Step 401 Train Loss: 0.5362
Epoch 11 Step 451 Train Loss: 0.5233
Epoch 11 Step 501 Train Loss: 0.5064
Epoch 11 Step 551 Train Loss: 0.5417
Epoch 11 Step 601 Train Loss: 0.5380
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 12 Step 1 Train Loss: 0.6032
Epoch 12 Step 51 Train Loss: 0.5122
Epoch 12 Step 101 Train Loss: 0.5321
Epoch 12 Step 151 Train Loss: 0.5903
Epoch 12 Step 201 Train Loss: 0.5806
Epoch 12 Step 251 Train Loss: 0.5994
Epoch 12 Step 301 Train Loss: 0.4944
Epoch 12 Step 351 Train Loss: 0.5655
Epoch 12 Step 401 Train Loss: 0.5350
Epoch 12 Step 451 Train Loss: 0.5638
Epoch 12 Step 501 Train Loss: 0.5107
Epoch 12 Step 551 Train Loss: 0.5188
Epoch 12 Step 601 Train Loss: 0.5448
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 13 Step 1 Train Loss: 0.4963
Epoch 13 Step 51 Train Loss: 0.5387
Epoch 13 Step 101 Train Loss: 0.5567
Epoch 13 Step 151 Train Loss: 0.5017
Epoch 13 Step 201 Train Loss: 0.5485
Epoch 13 Step 251 Train Loss: 0.4837
Epoch 13 Step 301 Train Loss: 0.5514
Epoch 13 Step 351 Train Loss: 0.5266
Epoch 13 Step 401 Train Loss: 0.5401
Epoch 13 Step 451 Train Loss: 0.5286
Epoch 13 Step 501 Train Loss: 0.5135
Epoch 13 Step 551 Train Loss: 0.5594
Epoch 13 Step 601 Train Loss: 0.5545
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 14 Step 1 Train Loss: 0.5495
Epoch 14 Step 51 Train Loss: 0.5272
Epoch 14 Step 101 Train Loss: 0.5613
Epoch 14 Step 151 Train Loss: 0.5273
Epoch 14 Step 201 Train Loss: 0.5620
Epoch 14 Step 251 Train Loss: 0.5297
Epoch 14 Step 301 Train Loss: 0.5370
Epoch 14 Step 351 Train Loss: 0.5395
Epoch 14 Step 401 Train Loss: 0.4685
Epoch 14 Step 451 Train Loss: 0.5294
Epoch 14 Step 501 Train Loss: 0.5320
Epoch 14 Step 551 Train Loss: 0.5425
Epoch 14 Step 601 Train Loss: 0.5495
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Epoch 15 Step 1 Train Loss: 0.6093
Epoch 15 Step 51 Train Loss: 0.5596
Epoch 15 Step 101 Train Loss: 0.5361
Epoch 15 Step 151 Train Loss: 0.5152
Epoch 15 Step 201 Train Loss: 0.6038
Epoch 15 Step 251 Train Loss: 0.4799
Epoch 15 Step 301 Train Loss: 0.5268
Epoch 15 Step 351 Train Loss: 0.5171
Epoch 15 Step 401 Train Loss: 0.4672
Epoch 15 Step 451 Train Loss: 0.5762
Epoch 15 Step 501 Train Loss: 0.5423
Epoch 15 Step 551 Train Loss: 0.5507
Epoch 15 Step 601 Train Loss: 0.5509
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0089 Validation Top 20 DE MSE: 0.0169. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0194
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0013918028
test_unseen_single_pearson: 0.996106158824284
test_unseen_single_mse_de: 0.019410294
test_unseen_single_pearson_de: 0.9626290871522007
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2569139637155759
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2902173913043478
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9652173913043478
test_unseen_single_mse_top20_de_non_dropout: 0.021295073
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.025 MB uploadedwandb: | 0.001 MB of 0.025 MB uploadedwandb: / 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ
wandb:                                                   val_de_mse ‚ñÅ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñá‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01941
wandb:                                              test_de_pearson 0.96263
wandb:               test_frac_opposite_direction_top20_non_dropout 0.29022
wandb:                          test_frac_sigma_below_1_non_dropout 0.96522
wandb:                                                     test_mse 0.00139
wandb:                                test_mse_top20_de_non_dropout 0.0213
wandb:                                                 test_pearson 0.99611
wandb:                                           test_pearson_delta 0.25691
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.29022
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.96522
wandb:                                       test_unseen_single_mse 0.00139
wandb:                                    test_unseen_single_mse_de 0.01941
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.0213
wandb:                                   test_unseen_single_pearson 0.99611
wandb:                                test_unseen_single_pearson_de 0.96263
wandb:                             test_unseen_single_pearson_delta 0.25691
wandb:                                                 train_de_mse 0.00891
wandb:                                             train_de_pearson 0.97371
wandb:                                                    train_mse 0.00107
wandb:                                                train_pearson 0.99702
wandb:                                                training_loss 0.54123
wandb:                                                   val_de_mse 0.01688
wandb:                                               val_de_pearson 0.98188
wandb:                                                      val_mse 0.00126
wandb:                                                  val_pearson 0.9965
wandb: 
wandb: üöÄ View run scbert_TianKampmann2021_CRISPRi_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/4wu0kvlw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_105406-4wu0kvlw/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:16
combo_seen1:76
combo_seen2:22
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_111727-dd376ags
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_day7neuron_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/dd376ags
wandb: WARNING Serializing object of type ndarray that is 8025728 bytes
  0%|                                                                                       | 0/3459 [00:00<?, ?it/s]  0%|‚ñè                                                                             | 10/3459 [00:00<00:41, 82.64it/s]  1%|‚ñç                                                                             | 19/3459 [00:00<00:41, 83.79it/s]  1%|‚ñã                                                                             | 30/3459 [00:00<00:37, 92.12it/s]  1%|‚ñâ                                                                             | 41/3459 [00:00<00:36, 93.35it/s]  2%|‚ñà‚ñè                                                                            | 53/3459 [00:00<00:34, 99.60it/s]  2%|‚ñà‚ñç                                                                           | 64/3459 [00:00<00:33, 100.43it/s]  2%|‚ñà‚ñã                                                                           | 75/3459 [00:00<00:33, 101.26it/s]  2%|‚ñà‚ñâ                                                                           | 86/3459 [00:00<00:33, 101.91it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 97/3459 [00:00<00:32, 102.05it/s]  3%|‚ñà‚ñà‚ñé                                                                         | 108/3459 [00:01<00:32, 102.97it/s]  3%|‚ñà‚ñà‚ñå                                                                         | 119/3459 [00:01<00:32, 102.98it/s]  4%|‚ñà‚ñà‚ñä                                                                         | 130/3459 [00:01<00:32, 102.61it/s]  4%|‚ñà‚ñà‚ñà                                                                         | 141/3459 [00:01<00:32, 102.44it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                        | 152/3459 [00:01<00:32, 102.42it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                        | 163/3459 [00:01<00:31, 103.01it/s]  5%|‚ñà‚ñà‚ñà‚ñä                                                                        | 174/3459 [00:01<00:32, 102.24it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                        | 185/3459 [00:01<00:32, 102.16it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 196/3459 [00:01<00:31, 102.85it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 207/3459 [00:02<00:31, 102.77it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 218/3459 [00:02<00:31, 102.71it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 229/3459 [00:02<00:31, 102.88it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 240/3459 [00:02<00:31, 103.23it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 251/3459 [00:02<00:31, 100.30it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 263/3459 [00:02<00:30, 104.14it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 274/3459 [00:02<00:30, 103.97it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 285/3459 [00:02<00:31, 100.85it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 297/3459 [00:02<00:30, 103.76it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 308/3459 [00:03<00:30, 103.89it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 319/3459 [00:03<00:31, 100.70it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 331/3459 [00:03<00:30, 103.37it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 342/3459 [00:03<00:30, 103.21it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 353/3459 [00:03<00:30, 103.06it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 364/3459 [00:03<00:30, 100.63it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 375/3459 [00:03<00:30, 101.01it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 387/3459 [00:03<00:29, 104.37it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 398/3459 [00:03<00:29, 104.06it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 409/3459 [00:04<00:29, 103.93it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 420/3459 [00:04<00:29, 103.62it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 431/3459 [00:04<00:29, 103.36it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 442/3459 [00:04<00:29, 100.77it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 454/3459 [00:04<00:28, 104.31it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 465/3459 [00:04<00:28, 104.37it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 476/3459 [00:04<00:28, 104.26it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 487/3459 [00:04<00:29, 101.26it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 499/3459 [00:04<00:28, 104.53it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 510/3459 [00:04<00:28, 104.07it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 521/3459 [00:05<00:28, 103.95it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 532/3459 [00:05<00:28, 101.65it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 544/3459 [00:05<00:27, 104.60it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 555/3459 [00:05<00:27, 104.30it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 566/3459 [00:05<00:27, 103.94it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 577/3459 [00:05<00:27, 104.07it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 588/3459 [00:05<00:27, 103.98it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 599/3459 [00:05<00:27, 103.94it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 610/3459 [00:05<00:27, 104.42it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 621/3459 [00:06<00:27, 104.06it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 632/3459 [00:06<00:27, 104.53it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 643/3459 [00:06<00:27, 103.90it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 654/3459 [00:06<00:27, 103.66it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 665/3459 [00:06<00:26, 103.82it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 676/3459 [00:06<00:26, 103.78it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 687/3459 [00:06<00:27, 100.81it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                            | 699/3459 [00:06<00:26, 104.53it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 710/3459 [00:06<00:26, 104.79it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 721/3459 [00:07<00:26, 104.30it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 732/3459 [00:07<00:26, 104.24it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 743/3459 [00:07<00:26, 100.80it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 755/3459 [00:07<00:25, 104.39it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 766/3459 [00:07<00:25, 104.16it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 777/3459 [00:07<00:25, 104.16it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 788/3459 [00:07<00:25, 104.72it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 799/3459 [00:07<00:25, 104.56it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 810/3459 [00:07<00:25, 103.62it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 821/3459 [00:07<00:25, 103.33it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 832/3459 [00:08<00:25, 103.57it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 843/3459 [00:08<00:25, 103.61it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 854/3459 [00:08<00:25, 101.23it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 866/3459 [00:08<00:24, 104.36it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 877/3459 [00:08<00:24, 103.52it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 888/3459 [00:08<00:24, 103.56it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 899/3459 [00:08<00:24, 103.22it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 910/3459 [00:08<00:24, 103.34it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 921/3459 [00:08<00:25, 100.93it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 933/3459 [00:09<00:24, 104.58it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 944/3459 [00:09<00:24, 103.96it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 955/3459 [00:09<00:24, 103.94it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 966/3459 [00:09<00:24, 102.82it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 977/3459 [00:09<00:24, 102.56it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 988/3459 [00:09<00:23, 103.21it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 999/3459 [00:09<00:23, 103.60it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                     | 1010/3459 [00:09<00:23, 104.06it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1021/3459 [00:09<00:23, 103.56it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1032/3459 [00:10<00:23, 103.74it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 1043/3459 [00:10<00:23, 103.61it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1054/3459 [00:10<00:23, 103.50it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1065/3459 [00:10<00:23, 101.25it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1077/3459 [00:10<00:22, 104.36it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1088/3459 [00:10<00:23, 102.86it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1099/3459 [00:10<00:24, 97.12it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1109/3459 [00:10<00:25, 93.92it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1119/3459 [00:10<00:25, 92.81it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1129/3459 [00:11<00:26, 89.24it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1139/3459 [00:11<00:25, 91.90it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1149/3459 [00:11<00:25, 91.04it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1159/3459 [00:11<00:25, 90.27it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 1169/3459 [00:11<00:25, 89.05it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1178/3459 [00:11<00:25, 88.20it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1187/3459 [00:11<00:25, 87.66it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1196/3459 [00:11<00:26, 86.90it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1205/3459 [00:11<00:26, 86.20it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1214/3459 [00:12<00:25, 86.55it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1223/3459 [00:12<00:25, 86.39it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1232/3459 [00:12<00:25, 86.19it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1241/3459 [00:12<00:25, 86.03it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 1250/3459 [00:12<00:25, 85.61it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1259/3459 [00:12<00:25, 85.83it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 1268/3459 [00:12<00:25, 85.92it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1277/3459 [00:12<00:25, 86.07it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1286/3459 [00:12<00:25, 86.80it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1295/3459 [00:12<00:24, 87.11it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1304/3459 [00:13<00:24, 87.47it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1313/3459 [00:13<00:24, 87.43it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1322/3459 [00:13<00:24, 87.40it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1331/3459 [00:13<00:24, 87.59it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 1340/3459 [00:13<00:24, 87.00it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                              | 1349/3459 [00:13<00:24, 86.77it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1358/3459 [00:13<00:24, 87.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1367/3459 [00:13<00:24, 86.96it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1376/3459 [00:13<00:23, 87.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1385/3459 [00:13<00:23, 87.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1394/3459 [00:14<00:23, 87.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1403/3459 [00:14<00:23, 88.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 1412/3459 [00:14<00:23, 85.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1422/3459 [00:14<00:22, 88.66it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 1431/3459 [00:14<00:22, 88.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1440/3459 [00:14<00:22, 88.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                            | 1449/3459 [00:14<00:22, 88.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 1458/3459 [00:14<00:22, 89.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 1467/3459 [00:14<00:22, 88.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 1476/3459 [00:15<00:22, 88.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 1485/3459 [00:15<00:22, 88.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 1494/3459 [00:15<00:22, 88.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 1503/3459 [00:15<00:22, 88.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 1512/3459 [00:15<00:24, 78.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 1521/3459 [00:15<00:25, 74.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1529/3459 [00:15<00:26, 71.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1537/3459 [00:15<00:29, 65.55it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 1544/3459 [00:15<00:28, 66.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 1552/3459 [00:16<00:28, 67.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 1559/3459 [00:16<00:30, 63.30it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 1566/3459 [00:16<00:32, 57.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1573/3459 [00:16<00:31, 60.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 1580/3459 [00:16<00:39, 47.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 1590/3459 [00:16<00:32, 57.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 1597/3459 [00:16<00:31, 59.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1604/3459 [00:17<00:30, 61.53it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 1611/3459 [00:17<00:29, 63.56it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 1618/3459 [00:17<00:28, 64.20it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 1625/3459 [00:17<00:28, 64.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 1632/3459 [00:17<00:31, 58.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1641/3459 [00:17<00:28, 64.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 1648/3459 [00:17<00:27, 65.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 1657/3459 [00:17<00:26, 68.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 1665/3459 [00:17<00:25, 70.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1673/3459 [00:18<00:24, 71.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 1681/3459 [00:18<00:26, 67.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 1690/3459 [00:18<00:24, 72.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 1698/3459 [00:18<00:23, 73.42it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1706/3459 [00:18<00:27, 63.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1715/3459 [00:18<00:25, 67.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 1725/3459 [00:18<00:23, 74.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1735/3459 [00:18<00:21, 79.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1746/3459 [00:18<00:20, 83.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 1756/3459 [00:19<00:19, 86.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 1766/3459 [00:19<00:19, 87.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 1776/3459 [00:19<00:18, 89.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 1787/3459 [00:19<00:18, 89.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 1797/3459 [00:19<00:18, 90.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 1807/3459 [00:19<00:18, 88.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 1816/3459 [00:19<00:18, 89.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1828/3459 [00:19<00:17, 94.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1839/3459 [00:19<00:16, 96.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 1849/3459 [00:20<00:16, 96.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1860/3459 [00:20<00:16, 97.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 1871/3459 [00:20<00:16, 97.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 1881/3459 [00:20<00:16, 95.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 1892/3459 [00:20<00:15, 98.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 1902/3459 [00:20<00:15, 97.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 1912/3459 [00:20<00:16, 94.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 1923/3459 [00:20<00:16, 95.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 1935/3459 [00:20<00:14, 101.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 1946/3459 [00:21<00:15, 95.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 1958/3459 [00:21<00:15, 96.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 1968/3459 [00:21<00:15, 97.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 1978/3459 [00:21<00:15, 96.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 1988/3459 [00:21<00:15, 93.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 1998/3459 [00:21<00:16, 91.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 2008/3459 [00:21<00:16, 87.91it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2017/3459 [00:21<00:16, 84.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 2026/3459 [00:22<00:17, 83.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2035/3459 [00:22<00:17, 81.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 2044/3459 [00:22<00:17, 82.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 2053/3459 [00:22<00:17, 82.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2062/3459 [00:22<00:17, 81.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2071/3459 [00:22<00:17, 79.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2079/3459 [00:22<00:18, 76.46it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2088/3459 [00:22<00:17, 79.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2097/3459 [00:22<00:17, 76.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2106/3459 [00:23<00:16, 79.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2115/3459 [00:23<00:16, 81.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2124/3459 [00:23<00:17, 76.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2132/3459 [00:24<00:56, 23.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2150/3459 [00:24<00:37, 35.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2157/3459 [00:24<00:46, 27.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2167/3459 [00:25<00:55, 23.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 2284/3459 [00:25<00:09, 124.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 2317/3459 [00:25<00:09, 114.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2343/3459 [00:26<00:10, 108.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2364/3459 [00:26<00:10, 107.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2382/3459 [00:26<00:09, 108.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2398/3459 [00:26<00:09, 107.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2413/3459 [00:26<00:09, 107.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2427/3459 [00:27<00:09, 109.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2440/3459 [00:27<00:09, 109.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2453/3459 [00:27<00:09, 110.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2465/3459 [00:27<00:08, 111.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2477/3459 [00:27<00:08, 111.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2491/3459 [00:27<00:08, 113.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2504/3459 [00:27<00:08, 114.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2516/3459 [00:27<00:08, 114.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2529/3459 [00:27<00:07, 117.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2541/3459 [00:28<00:07, 116.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2553/3459 [00:28<00:07, 115.63it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2565/3459 [00:28<00:07, 115.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2577/3459 [00:28<00:07, 113.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2589/3459 [00:28<00:07, 111.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2603/3459 [00:28<00:07, 115.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2616/3459 [00:28<00:07, 117.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2629/3459 [00:28<00:07, 117.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2642/3459 [00:28<00:06, 118.47it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2655/3459 [00:28<00:06, 120.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2668/3459 [00:29<00:06, 120.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 2681/3459 [00:29<00:06, 120.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2694/3459 [00:29<00:06, 119.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2706/3459 [00:29<00:06, 119.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 2720/3459 [00:29<00:06, 122.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2733/3459 [00:29<00:06, 116.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 2746/3459 [00:29<00:05, 119.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2759/3459 [00:29<00:05, 119.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2771/3459 [00:29<00:05, 119.11it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2783/3459 [00:30<00:05, 119.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2795/3459 [00:30<00:05, 119.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2807/3459 [00:30<00:05, 118.84it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2819/3459 [00:30<00:05, 116.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2832/3459 [00:30<00:05, 119.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 2845/3459 [00:30<00:05, 119.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2857/3459 [00:30<00:05, 118.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2869/3459 [00:30<00:04, 118.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2881/3459 [00:30<00:04, 118.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2893/3459 [00:30<00:04, 118.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2905/3459 [00:31<00:04, 118.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 2918/3459 [00:31<00:04, 118.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 2930/3459 [00:31<00:04, 117.07it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 2942/3459 [00:31<00:04, 114.59it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2955/3459 [00:31<00:04, 117.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 2967/3459 [00:31<00:04, 115.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 2982/3459 [00:31<00:03, 120.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 2995/3459 [00:31<00:03, 119.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3007/3459 [00:31<00:03, 119.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 3019/3459 [00:32<00:03, 118.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 3031/3459 [00:32<00:03, 116.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 3044/3459 [00:32<00:03, 117.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 3058/3459 [00:32<00:03, 119.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 3070/3459 [00:32<00:03, 119.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 3083/3459 [00:32<00:03, 119.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 3095/3459 [00:32<00:03, 116.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 3108/3459 [00:32<00:02, 120.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 3121/3459 [00:32<00:02, 122.20it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 3134/3459 [00:33<00:02, 121.26it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 3147/3459 [00:33<00:02, 120.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3160/3459 [00:33<00:02, 117.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3172/3459 [00:33<00:02, 110.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 3185/3459 [00:33<00:02, 115.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3197/3459 [00:33<00:02, 116.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3209/3459 [00:33<00:02, 116.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 3221/3459 [00:33<00:02, 117.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3233/3459 [00:33<00:01, 117.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3246/3459 [00:33<00:01, 115.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3259/3459 [00:34<00:01, 119.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3272/3459 [00:34<00:01, 119.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3285/3459 [00:34<00:01, 119.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3298/3459 [00:34<00:01, 118.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3311/3459 [00:34<00:01, 119.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3323/3459 [00:34<00:01, 118.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3335/3459 [00:34<00:01, 119.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3348/3459 [00:34<00:00, 119.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3360/3459 [00:34<00:00, 119.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3373/3459 [00:35<00:00, 118.59it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3385/3459 [00:35<00:00, 118.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3397/3459 [00:35<00:00, 118.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3409/3459 [00:35<00:00, 117.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3421/3459 [00:35<00:00, 114.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3434/3459 [00:35<00:00, 118.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3446/3459 [00:35<00:00, 118.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3459/3459 [00:35<00:00, 120.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3459/3459 [00:35<00:00, 96.69it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.1770
Epoch 1 Step 51 Train Loss: 0.1968
Epoch 1 Step 101 Train Loss: 0.1581
Epoch 1 Step 151 Train Loss: 0.1546
Epoch 1 Step 201 Train Loss: 0.1511
Epoch 1 Step 251 Train Loss: 0.1476
Epoch 1 Step 301 Train Loss: 0.1642
Epoch 1 Step 351 Train Loss: 0.1537
Epoch 1 Step 401 Train Loss: 0.1475
Epoch 1 Step 451 Train Loss: 0.1436
Epoch 1 Step 501 Train Loss: 0.1555
Epoch 1 Step 551 Train Loss: 0.1543
Epoch 1: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0045 Validation Top 20 DE MSE: 0.0065. 
Epoch 2 Step 1 Train Loss: 0.1518
Epoch 2 Step 51 Train Loss: 0.1428
Epoch 2 Step 101 Train Loss: 0.1419
Epoch 2 Step 151 Train Loss: 0.1542
Epoch 2 Step 201 Train Loss: 0.1493
Epoch 2 Step 251 Train Loss: 0.1325
Epoch 2 Step 301 Train Loss: 0.1149
Epoch 2 Step 351 Train Loss: 0.1313
Epoch 2 Step 401 Train Loss: 0.1311
Epoch 2 Step 451 Train Loss: 0.1293
Epoch 2 Step 501 Train Loss: 0.1348
Epoch 2 Step 551 Train Loss: 0.1310
Epoch 2: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0050. 
Epoch 3 Step 1 Train Loss: 0.1343
Epoch 3 Step 51 Train Loss: 0.0974
Epoch 3 Step 101 Train Loss: 0.1085
Epoch 3 Step 151 Train Loss: 0.1017
Epoch 3 Step 201 Train Loss: 0.1172
Epoch 3 Step 251 Train Loss: 0.1033
Epoch 3 Step 301 Train Loss: 0.1139
Epoch 3 Step 351 Train Loss: 0.1192
Epoch 3 Step 401 Train Loss: 0.1122
Epoch 3 Step 451 Train Loss: 0.0976
Epoch 3 Step 501 Train Loss: 0.1149
Epoch 3 Step 551 Train Loss: 0.1080
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0044 Validation Top 20 DE MSE: 0.0058. 
Epoch 4 Step 1 Train Loss: 0.1153
Epoch 4 Step 51 Train Loss: 0.1101
Epoch 4 Step 101 Train Loss: 0.0869
Epoch 4 Step 151 Train Loss: 0.0941
Epoch 4 Step 201 Train Loss: 0.1175
Epoch 4 Step 251 Train Loss: 0.1044
Epoch 4 Step 301 Train Loss: 0.1099
Epoch 4 Step 351 Train Loss: 0.0950
Epoch 4 Step 401 Train Loss: 0.0890
Epoch 4 Step 451 Train Loss: 0.0952
Epoch 4 Step 501 Train Loss: 0.0991
Epoch 4 Step 551 Train Loss: 0.0922
Epoch 4: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0050. 
Epoch 5 Step 1 Train Loss: 0.0861
Epoch 5 Step 51 Train Loss: 0.0924
Epoch 5 Step 101 Train Loss: 0.1050
Epoch 5 Step 151 Train Loss: 0.0813
Epoch 5 Step 201 Train Loss: 0.1016
Epoch 5 Step 251 Train Loss: 0.0985
Epoch 5 Step 301 Train Loss: 0.0868
Epoch 5 Step 351 Train Loss: 0.0899
Epoch 5 Step 401 Train Loss: 0.1073
Epoch 5 Step 451 Train Loss: 0.0857
Epoch 5 Step 501 Train Loss: 0.0794
Epoch 5 Step 551 Train Loss: 0.0908
Epoch 5: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0048. 
Epoch 6 Step 1 Train Loss: 0.0887
Epoch 6 Step 51 Train Loss: 0.0936
Epoch 6 Step 101 Train Loss: 0.1107
Epoch 6 Step 151 Train Loss: 0.1041
Epoch 6 Step 201 Train Loss: 0.0905
Epoch 6 Step 251 Train Loss: 0.1007
Epoch 6 Step 301 Train Loss: 0.1159
Epoch 6 Step 351 Train Loss: 0.0952
Epoch 6 Step 401 Train Loss: 0.1073
Epoch 6 Step 451 Train Loss: 0.1086
Epoch 6 Step 501 Train Loss: 0.1201
Epoch 6 Step 551 Train Loss: 0.1033
Epoch 6: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0048. 
Epoch 7 Step 1 Train Loss: 0.0913
Epoch 7 Step 51 Train Loss: 0.1101
Epoch 7 Step 101 Train Loss: 0.1018
Epoch 7 Step 151 Train Loss: 0.1016
Epoch 7 Step 201 Train Loss: 0.1053
Epoch 7 Step 251 Train Loss: 0.0909
Epoch 7 Step 301 Train Loss: 0.0998
Epoch 7 Step 351 Train Loss: 0.1040
Epoch 7 Step 401 Train Loss: 0.0947
Epoch 7 Step 451 Train Loss: 0.1034
Epoch 7 Step 501 Train Loss: 0.1141
Epoch 7 Step 551 Train Loss: 0.0950
Epoch 7: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 8 Step 1 Train Loss: 0.1051
Epoch 8 Step 51 Train Loss: 0.0978
Epoch 8 Step 101 Train Loss: 0.0963
Epoch 8 Step 151 Train Loss: 0.0984
Epoch 8 Step 201 Train Loss: 0.0971
Epoch 8 Step 251 Train Loss: 0.1126
Epoch 8 Step 301 Train Loss: 0.1063
Epoch 8 Step 351 Train Loss: 0.0864
Epoch 8 Step 401 Train Loss: 0.0960
Epoch 8 Step 451 Train Loss: 0.0972
Epoch 8 Step 501 Train Loss: 0.0966
Epoch 8 Step 551 Train Loss: 0.0936
Epoch 8: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 9 Step 1 Train Loss: 0.1022
Epoch 9 Step 51 Train Loss: 0.0897
Epoch 9 Step 101 Train Loss: 0.1023
Epoch 9 Step 151 Train Loss: 0.0889
Epoch 9 Step 201 Train Loss: 0.0981
Epoch 9 Step 251 Train Loss: 0.1165
Epoch 9 Step 301 Train Loss: 0.0901
Epoch 9 Step 351 Train Loss: 0.0915
Epoch 9 Step 401 Train Loss: 0.1134
Epoch 9 Step 451 Train Loss: 0.1069
Epoch 9 Step 501 Train Loss: 0.0913
Epoch 9 Step 551 Train Loss: 0.1091
Epoch 9: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 10 Step 1 Train Loss: 0.0996
Epoch 10 Step 51 Train Loss: 0.0966
Epoch 10 Step 101 Train Loss: 0.0989
Epoch 10 Step 151 Train Loss: 0.1013
Epoch 10 Step 201 Train Loss: 0.1031
Epoch 10 Step 251 Train Loss: 0.1062
Epoch 10 Step 301 Train Loss: 0.1058
Epoch 10 Step 351 Train Loss: 0.1010
Epoch 10 Step 401 Train Loss: 0.0901
Epoch 10 Step 451 Train Loss: 0.1027
Epoch 10 Step 501 Train Loss: 0.0994
Epoch 10 Step 551 Train Loss: 0.1186
Epoch 10: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 11 Step 1 Train Loss: 0.1011
Epoch 11 Step 51 Train Loss: 0.1085
Epoch 11 Step 101 Train Loss: 0.1059
Epoch 11 Step 151 Train Loss: 0.0921
Epoch 11 Step 201 Train Loss: 0.0929
Epoch 11 Step 251 Train Loss: 0.0984
Epoch 11 Step 301 Train Loss: 0.1043
Epoch 11 Step 351 Train Loss: 0.1023
Epoch 11 Step 401 Train Loss: 0.0962
Epoch 11 Step 451 Train Loss: 0.1108
Epoch 11 Step 501 Train Loss: 0.1167
Epoch 11 Step 551 Train Loss: 0.0927
Epoch 11: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 12 Step 1 Train Loss: 0.0994
Epoch 12 Step 51 Train Loss: 0.0981
Epoch 12 Step 101 Train Loss: 0.1110
Epoch 12 Step 151 Train Loss: 0.1041
Epoch 12 Step 201 Train Loss: 0.1061
Epoch 12 Step 251 Train Loss: 0.1016
Epoch 12 Step 301 Train Loss: 0.1009
Epoch 12 Step 351 Train Loss: 0.1058
Epoch 12 Step 401 Train Loss: 0.0980
Epoch 12 Step 451 Train Loss: 0.0937
Epoch 12 Step 501 Train Loss: 0.1122
Epoch 12 Step 551 Train Loss: 0.0939
Epoch 12: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 13 Step 1 Train Loss: 0.0973
Epoch 13 Step 51 Train Loss: 0.1098
Epoch 13 Step 101 Train Loss: 0.0939
Epoch 13 Step 151 Train Loss: 0.1078
Epoch 13 Step 201 Train Loss: 0.0943
Epoch 13 Step 251 Train Loss: 0.0945
Epoch 13 Step 301 Train Loss: 0.0994
Epoch 13 Step 351 Train Loss: 0.0949
Epoch 13 Step 401 Train Loss: 0.1010
Epoch 13 Step 451 Train Loss: 0.0967
Epoch 13 Step 501 Train Loss: 0.0948
Epoch 13 Step 551 Train Loss: 0.1032
Epoch 13: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 14 Step 1 Train Loss: 0.1020
Epoch 14 Step 51 Train Loss: 0.1016
Epoch 14 Step 101 Train Loss: 0.1038
Epoch 14 Step 151 Train Loss: 0.1024
Epoch 14 Step 201 Train Loss: 0.1013
Epoch 14 Step 251 Train Loss: 0.0952
Epoch 14 Step 301 Train Loss: 0.0961
Epoch 14 Step 351 Train Loss: 0.0885
Epoch 14 Step 401 Train Loss: 0.0948
Epoch 14 Step 451 Train Loss: 0.1008
Epoch 14 Step 501 Train Loss: 0.1123
Epoch 14 Step 551 Train Loss: 0.0937
Epoch 14: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Epoch 15 Step 1 Train Loss: 0.0942
Epoch 15 Step 51 Train Loss: 0.1007
Epoch 15 Step 101 Train Loss: 0.0867
Epoch 15 Step 151 Train Loss: 0.0985
Epoch 15 Step 201 Train Loss: 0.1123
Epoch 15 Step 251 Train Loss: 0.0970
Epoch 15 Step 301 Train Loss: 0.0907
Epoch 15 Step 351 Train Loss: 0.0950
Epoch 15 Step 401 Train Loss: 0.1110
Epoch 15 Step 451 Train Loss: 0.0978
Epoch 15 Step 501 Train Loss: 0.1022
Epoch 15 Step 551 Train Loss: 0.1042
Epoch 15: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0047. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0032
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0011713231
test_combo_seen0_pearson: 0.8793004594115201
test_combo_seen0_mse_de: 0.0046071545
test_combo_seen0_pearson_de: 0.23495647014017565
test_combo_seen1_mse: 0.0010646549
test_combo_seen1_pearson: 0.885918005529878
test_combo_seen1_mse_de: 0.002444059
test_combo_seen1_pearson_de: 0.33027127264076556
test_combo_seen2_mse: 0.0015609995
test_combo_seen2_pearson: 0.8404587166366958
test_combo_seen2_mse_de: 0.005529624
test_combo_seen2_pearson_de: 0.23356975544862718
test_unseen_single_mse: 5.821116e-05
test_unseen_single_pearson: 0.9926790304261185
test_unseen_single_mse_de: 0.00012099179
test_unseen_single_pearson_de: 0.6675285351780237
test_combo_seen0_pearson_delta: 0.010668672852377574
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.375
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.359375
test_combo_seen0_mse_top20_de_non_dropout: 0.009806671
test_combo_seen1_pearson_delta: 0.03405531654218694
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.34868421052631576
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.2967105263157895
test_combo_seen1_mse_top20_de_non_dropout: 0.003787834
test_combo_seen2_pearson_delta: -0.007498346572147304
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.3545454545454545
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.27272727272727276
test_combo_seen2_mse_top20_de_non_dropout: 0.010788185
test_unseen_single_pearson_delta: 0.13771292667229604
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3857142857142857
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5714285714285714
test_unseen_single_mse_top20_de_non_dropout: 0.00011933049
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.025 MB uploadedwandb: | 0.004 MB of 0.025 MB uploadedwandb: / 0.004 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb:                                                    train_mse ‚ñÜ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÉ‚ñá‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                training_loss ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÉ‚ñÖ‚ñÅ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.375
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.35938
wandb:                                         test_combo_seen0_mse 0.00117
wandb:                                      test_combo_seen0_mse_de 0.00461
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.00981
wandb:                                     test_combo_seen0_pearson 0.8793
wandb:                                  test_combo_seen0_pearson_de 0.23496
wandb:                               test_combo_seen0_pearson_delta 0.01067
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.34868
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.29671
wandb:                                         test_combo_seen1_mse 0.00106
wandb:                                      test_combo_seen1_mse_de 0.00244
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00379
wandb:                                     test_combo_seen1_pearson 0.88592
wandb:                                  test_combo_seen1_pearson_de 0.33027
wandb:                               test_combo_seen1_pearson_delta 0.03406
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.35455
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.27273
wandb:                                         test_combo_seen2_mse 0.00156
wandb:                                      test_combo_seen2_mse_de 0.00553
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.01079
wandb:                                     test_combo_seen2_pearson 0.84046
wandb:                                  test_combo_seen2_pearson_de 0.23357
wandb:                               test_combo_seen2_pearson_delta -0.0075
wandb:                                                  test_de_mse 0.00316
wandb:                                              test_de_pearson 0.3196
wandb:               test_frac_opposite_direction_top20_non_dropout 0.35537
wandb:                          test_frac_sigma_below_1_non_dropout 0.31653
wandb:                                                     test_mse 0.00111
wandb:                                test_mse_top20_de_non_dropout 0.00564
wandb:                                                 test_pearson 0.88295
wandb:                                           test_pearson_delta 0.0294
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.38571
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.57143
wandb:                                       test_unseen_single_mse 6e-05
wandb:                                    test_unseen_single_mse_de 0.00012
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00012
wandb:                                   test_unseen_single_pearson 0.99268
wandb:                                test_unseen_single_pearson_de 0.66753
wandb:                             test_unseen_single_pearson_delta 0.13771
wandb:                                                 train_de_mse 0.00319
wandb:                                             train_de_pearson 0.40144
wandb:                                                    train_mse 0.00096
wandb:                                                train_pearson 0.89834
wandb:                                                training_loss 0.09945
wandb:                                                   val_de_mse 0.00468
wandb:                                               val_de_pearson 0.23301
wandb:                                                      val_mse 0.00154
wandb:                                                  val_pearson 0.83915
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_day7neuron_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/dd376ags
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_111727-dd376ags/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:18
combo_seen1:77
combo_seen2:22
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_113157-jww0llb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_day7neuron_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/jww0llb3
wandb: WARNING Serializing object of type ndarray that is 8025728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1793
Epoch 1 Step 51 Train Loss: 0.1681
Epoch 1 Step 101 Train Loss: 0.1531
Epoch 1 Step 151 Train Loss: 0.1598
Epoch 1 Step 201 Train Loss: 0.1507
Epoch 1 Step 251 Train Loss: 0.1546
Epoch 1 Step 301 Train Loss: 0.1700
Epoch 1 Step 351 Train Loss: 0.1659
Epoch 1 Step 401 Train Loss: 0.1542
Epoch 1 Step 451 Train Loss: 0.1581
Epoch 1: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0060 Validation Top 20 DE MSE: 0.0042. 
Epoch 2 Step 1 Train Loss: 0.1568
Epoch 2 Step 51 Train Loss: 0.1490
Epoch 2 Step 101 Train Loss: 0.1285
Epoch 2 Step 151 Train Loss: 0.1394
Epoch 2 Step 201 Train Loss: 0.1388
Epoch 2 Step 251 Train Loss: 0.1299
Epoch 2 Step 301 Train Loss: 0.1172
Epoch 2 Step 351 Train Loss: 0.1546
Epoch 2 Step 401 Train Loss: 0.1348
Epoch 2 Step 451 Train Loss: 0.1157
Epoch 2: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0039 Validation Top 20 DE MSE: 0.0023. 
Epoch 3 Step 1 Train Loss: 0.1265
Epoch 3 Step 51 Train Loss: 0.1151
Epoch 3 Step 101 Train Loss: 0.1348
Epoch 3 Step 151 Train Loss: 0.1175
Epoch 3 Step 201 Train Loss: 0.1253
Epoch 3 Step 251 Train Loss: 0.1155
Epoch 3 Step 301 Train Loss: 0.1014
Epoch 3 Step 351 Train Loss: 0.1021
Epoch 3 Step 401 Train Loss: 0.0987
Epoch 3 Step 451 Train Loss: 0.1168
Epoch 3: Train Overall MSE: 0.0032 Validation Overall MSE: 0.0039. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0077. 
Epoch 4 Step 1 Train Loss: 0.1366
Epoch 4 Step 51 Train Loss: 0.1166
Epoch 4 Step 101 Train Loss: 0.1204
Epoch 4 Step 151 Train Loss: 0.1323
Epoch 4 Step 201 Train Loss: 0.1049
Epoch 4 Step 251 Train Loss: 0.1059
Epoch 4 Step 301 Train Loss: 0.0921
Epoch 4 Step 351 Train Loss: 0.1073
Epoch 4 Step 401 Train Loss: 0.0958
Epoch 4 Step 451 Train Loss: 0.1204
Epoch 4: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0037 Validation Top 20 DE MSE: 0.0021. 
Epoch 5 Step 1 Train Loss: 0.1006
Epoch 5 Step 51 Train Loss: 0.1116
Epoch 5 Step 101 Train Loss: 0.1105
Epoch 5 Step 151 Train Loss: 0.1162
Epoch 5 Step 201 Train Loss: 0.1188
Epoch 5 Step 251 Train Loss: 0.1030
Epoch 5 Step 301 Train Loss: 0.1025
Epoch 5 Step 351 Train Loss: 0.0967
Epoch 5 Step 401 Train Loss: 0.0981
Epoch 5 Step 451 Train Loss: 0.0979
Epoch 5: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 6 Step 1 Train Loss: 0.0989
Epoch 6 Step 51 Train Loss: 0.1266
Epoch 6 Step 101 Train Loss: 0.1108
Epoch 6 Step 151 Train Loss: 0.1082
Epoch 6 Step 201 Train Loss: 0.0889
Epoch 6 Step 251 Train Loss: 0.1170
Epoch 6 Step 301 Train Loss: 0.1044
Epoch 6 Step 351 Train Loss: 0.1033
Epoch 6 Step 401 Train Loss: 0.0936
Epoch 6 Step 451 Train Loss: 0.1139
Epoch 6: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 7 Step 1 Train Loss: 0.1268
Epoch 7 Step 51 Train Loss: 0.0937
Epoch 7 Step 101 Train Loss: 0.1074
Epoch 7 Step 151 Train Loss: 0.0985
Epoch 7 Step 201 Train Loss: 0.1231
Epoch 7 Step 251 Train Loss: 0.0949
Epoch 7 Step 301 Train Loss: 0.0887
Epoch 7 Step 351 Train Loss: 0.1042
Epoch 7 Step 401 Train Loss: 0.1007
Epoch 7 Step 451 Train Loss: 0.1027
Epoch 7: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 8 Step 1 Train Loss: 0.0903
Epoch 8 Step 51 Train Loss: 0.1128
Epoch 8 Step 101 Train Loss: 0.0928
Epoch 8 Step 151 Train Loss: 0.1024
Epoch 8 Step 201 Train Loss: 0.1258
Epoch 8 Step 251 Train Loss: 0.0962
Epoch 8 Step 301 Train Loss: 0.0959
Epoch 8 Step 351 Train Loss: 0.1054
Epoch 8 Step 401 Train Loss: 0.0969
Epoch 8 Step 451 Train Loss: 0.1203
Epoch 8: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 9 Step 1 Train Loss: 0.1078
Epoch 9 Step 51 Train Loss: 0.0948
Epoch 9 Step 101 Train Loss: 0.0880
Epoch 9 Step 151 Train Loss: 0.1027
Epoch 9 Step 201 Train Loss: 0.1046
Epoch 9 Step 251 Train Loss: 0.1077
Epoch 9 Step 301 Train Loss: 0.1118
Epoch 9 Step 351 Train Loss: 0.1266
Epoch 9 Step 401 Train Loss: 0.0933
Epoch 9 Step 451 Train Loss: 0.1103
Epoch 9: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 10 Step 1 Train Loss: 0.0998
Epoch 10 Step 51 Train Loss: 0.0948
Epoch 10 Step 101 Train Loss: 0.1113
Epoch 10 Step 151 Train Loss: 0.1089
Epoch 10 Step 201 Train Loss: 0.1033
Epoch 10 Step 251 Train Loss: 0.0984
Epoch 10 Step 301 Train Loss: 0.1111
Epoch 10 Step 351 Train Loss: 0.1003
Epoch 10 Step 401 Train Loss: 0.1117
Epoch 10 Step 451 Train Loss: 0.1115
Epoch 10: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 11 Step 1 Train Loss: 0.1095
Epoch 11 Step 51 Train Loss: 0.1017
Epoch 11 Step 101 Train Loss: 0.1033
Epoch 11 Step 151 Train Loss: 0.1019
Epoch 11 Step 201 Train Loss: 0.1121
Epoch 11 Step 251 Train Loss: 0.0988
Epoch 11 Step 301 Train Loss: 0.1142
Epoch 11 Step 351 Train Loss: 0.0976
Epoch 11 Step 401 Train Loss: 0.1036
Epoch 11 Step 451 Train Loss: 0.1000
Epoch 11: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 12 Step 1 Train Loss: 0.0989
Epoch 12 Step 51 Train Loss: 0.0930
Epoch 12 Step 101 Train Loss: 0.0989
Epoch 12 Step 151 Train Loss: 0.1207
Epoch 12 Step 201 Train Loss: 0.1165
Epoch 12 Step 251 Train Loss: 0.0936
Epoch 12 Step 301 Train Loss: 0.0910
Epoch 12 Step 351 Train Loss: 0.1147
Epoch 12 Step 401 Train Loss: 0.1048
Epoch 12 Step 451 Train Loss: 0.1005
Epoch 12: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 13 Step 1 Train Loss: 0.0942
Epoch 13 Step 51 Train Loss: 0.1068
Epoch 13 Step 101 Train Loss: 0.0921
Epoch 13 Step 151 Train Loss: 0.0972
Epoch 13 Step 201 Train Loss: 0.1155
Epoch 13 Step 251 Train Loss: 0.1101
Epoch 13 Step 301 Train Loss: 0.1274
Epoch 13 Step 351 Train Loss: 0.0955
Epoch 13 Step 401 Train Loss: 0.1085
Epoch 13 Step 451 Train Loss: 0.0948
Epoch 13: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 14 Step 1 Train Loss: 0.1045
Epoch 14 Step 51 Train Loss: 0.1092
Epoch 14 Step 101 Train Loss: 0.0966
Epoch 14 Step 151 Train Loss: 0.1108
Epoch 14 Step 201 Train Loss: 0.0993
Epoch 14 Step 251 Train Loss: 0.1203
Epoch 14 Step 301 Train Loss: 0.1030
Epoch 14 Step 351 Train Loss: 0.1114
Epoch 14 Step 401 Train Loss: 0.1060
Epoch 14 Step 451 Train Loss: 0.1028
Epoch 14: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Epoch 15 Step 1 Train Loss: 0.0955
Epoch 15 Step 51 Train Loss: 0.1187
Epoch 15 Step 101 Train Loss: 0.1090
Epoch 15 Step 151 Train Loss: 0.1215
Epoch 15 Step 201 Train Loss: 0.1028
Epoch 15 Step 251 Train Loss: 0.0961
Epoch 15 Step 301 Train Loss: 0.1012
Epoch 15 Step 351 Train Loss: 0.1028
Epoch 15 Step 401 Train Loss: 0.1009
Epoch 15 Step 451 Train Loss: 0.1176
Epoch 15: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0020. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0035
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0010755071
test_combo_seen0_pearson: 0.8837402278026576
test_combo_seen0_mse_de: 0.0032800979
test_combo_seen0_pearson_de: 0.4035328081243887
test_combo_seen1_mse: 0.0010855914
test_combo_seen1_pearson: 0.8861154020429114
test_combo_seen1_mse_de: 0.003739088
test_combo_seen1_pearson_de: 0.4357402967202621
test_combo_seen2_mse: 0.001548589
test_combo_seen2_pearson: 0.842359284655403
test_combo_seen2_mse_de: 0.004126509
test_combo_seen2_pearson_de: 0.39365262361499737
test_unseen_single_mse: 3.9127422e-05
test_unseen_single_pearson: 0.9949503090894579
test_unseen_single_mse_de: 3.456992e-05
test_unseen_single_pearson_de: 0.6163307828385518
test_combo_seen0_pearson_delta: 0.013814014183958327
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.35277777777777775
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.37222222222222223
test_combo_seen0_mse_top20_de_non_dropout: 0.0037640755
test_combo_seen1_pearson_delta: 0.02331645895153186
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.4116883116883117
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.37727272727272726
test_combo_seen1_mse_top20_de_non_dropout: 0.0074862596
test_combo_seen2_pearson_delta: 0.016370985927105845
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.30454545454545456
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.4272727272727273
test_combo_seen2_mse_top20_de_non_dropout: 0.0083557395
test_unseen_single_pearson_delta: 0.1343053501652508
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.35000000000000003
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6642857142857144
test_unseen_single_mse_top20_de_non_dropout: 3.1365118e-05
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.024 MB uploadedwandb: | 0.004 MB of 0.024 MB uploadedwandb: / 0.004 MB of 0.024 MB uploadedwandb: - 0.024 MB of 0.024 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÖ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÉ‚ñÜ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÖ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.35278
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.37222
wandb:                                         test_combo_seen0_mse 0.00108
wandb:                                      test_combo_seen0_mse_de 0.00328
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.00376
wandb:                                     test_combo_seen0_pearson 0.88374
wandb:                                  test_combo_seen0_pearson_de 0.40353
wandb:                               test_combo_seen0_pearson_delta 0.01381
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.41169
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.37727
wandb:                                         test_combo_seen1_mse 0.00109
wandb:                                      test_combo_seen1_mse_de 0.00374
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00749
wandb:                                     test_combo_seen1_pearson 0.88612
wandb:                                  test_combo_seen1_pearson_de 0.43574
wandb:                               test_combo_seen1_pearson_delta 0.02332
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.30455
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.42727
wandb:                                         test_combo_seen2_mse 0.00155
wandb:                                      test_combo_seen2_mse_de 0.00413
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00836
wandb:                                     test_combo_seen2_pearson 0.84236
wandb:                                  test_combo_seen2_pearson_de 0.39365
wandb:                               test_combo_seen2_pearson_delta 0.01637
wandb:                                                  test_de_mse 0.00353
wandb:                                              test_de_pearson 0.43379
wandb:               test_frac_opposite_direction_top20_non_dropout 0.38065
wandb:                          test_frac_sigma_below_1_non_dropout 0.40161
wandb:                                                     test_mse 0.00111
wandb:                                test_mse_top20_de_non_dropout 0.00668
wandb:                                                 test_pearson 0.88415
wandb:                                           test_pearson_delta 0.02697
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.35
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.66429
wandb:                                       test_unseen_single_mse 4e-05
wandb:                                    test_unseen_single_mse_de 3e-05
wandb:                  test_unseen_single_mse_top20_de_non_dropout 3e-05
wandb:                                   test_unseen_single_pearson 0.99495
wandb:                                test_unseen_single_pearson_de 0.61633
wandb:                             test_unseen_single_pearson_delta 0.13431
wandb:                                                 train_de_mse 0.00356
wandb:                                             train_de_pearson 0.36987
wandb:                                                    train_mse 0.00097
wandb:                                                train_pearson 0.89838
wandb:                                                training_loss 0.10126
wandb:                                                   val_de_mse 0.00196
wandb:                                               val_de_pearson 0.39014
wandb:                                                      val_mse 0.00087
wandb:                                                  val_pearson 0.91202
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_day7neuron_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/jww0llb3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_113157-jww0llb3/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:18
combo_seen1:79
combo_seen2:21
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_114501-q2ljgad6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_day7neuron_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/q2ljgad6
wandb: WARNING Serializing object of type ndarray that is 8025728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1810
Epoch 1 Step 51 Train Loss: 0.1720
Epoch 1 Step 101 Train Loss: 0.1724
Epoch 1 Step 151 Train Loss: 0.1502
Epoch 1 Step 201 Train Loss: 0.1470
Epoch 1 Step 251 Train Loss: 0.1512
Epoch 1 Step 301 Train Loss: 0.1516
Epoch 1 Step 351 Train Loss: 0.1563
Epoch 1 Step 401 Train Loss: 0.1546
Epoch 1 Step 451 Train Loss: 0.1527
Epoch 1 Step 501 Train Loss: 0.1442
Epoch 1 Step 551 Train Loss: 0.1396
Epoch 1 Step 601 Train Loss: 0.1282
Epoch 1 Step 651 Train Loss: 0.1312
Epoch 1 Step 701 Train Loss: 0.1217
Epoch 1 Step 751 Train Loss: 0.1149
Epoch 1 Step 801 Train Loss: 0.1258
Epoch 1: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0033 Validation Top 20 DE MSE: 0.0043. 
Epoch 2 Step 1 Train Loss: 0.1306
Epoch 2 Step 51 Train Loss: 0.1115
Epoch 2 Step 101 Train Loss: 0.1112
Epoch 2 Step 151 Train Loss: 0.1063
Epoch 2 Step 201 Train Loss: 0.1123
Epoch 2 Step 251 Train Loss: 0.1123
Epoch 2 Step 301 Train Loss: 0.1210
Epoch 2 Step 351 Train Loss: 0.1036
Epoch 2 Step 401 Train Loss: 0.1081
Epoch 2 Step 451 Train Loss: 0.0959
Epoch 2 Step 501 Train Loss: 0.1030
Epoch 2 Step 551 Train Loss: 0.1113
Epoch 2 Step 601 Train Loss: 0.0860
Epoch 2 Step 651 Train Loss: 0.0897
Epoch 2 Step 701 Train Loss: 0.0872
Epoch 2 Step 751 Train Loss: 0.1111
Epoch 2 Step 801 Train Loss: 0.1011
Epoch 2: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0029 Validation Top 20 DE MSE: 0.0039. 
Epoch 3 Step 1 Train Loss: 0.0870
Epoch 3 Step 51 Train Loss: 0.1015
Epoch 3 Step 101 Train Loss: 0.0795
Epoch 3 Step 151 Train Loss: 0.0905
Epoch 3 Step 201 Train Loss: 0.0829
Epoch 3 Step 251 Train Loss: 0.0899
Epoch 3 Step 301 Train Loss: 0.0868
Epoch 3 Step 351 Train Loss: 0.0792
Epoch 3 Step 401 Train Loss: 0.0881
Epoch 3 Step 451 Train Loss: 0.0851
Epoch 3 Step 501 Train Loss: 0.0793
Epoch 3 Step 551 Train Loss: 0.0799
Epoch 3 Step 601 Train Loss: 0.0901
Epoch 3 Step 651 Train Loss: 0.0919
Epoch 3 Step 701 Train Loss: 0.0850
Epoch 3 Step 751 Train Loss: 0.0754
Epoch 3 Step 801 Train Loss: 0.0830
Epoch 3: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 4 Step 1 Train Loss: 0.0948
Epoch 4 Step 51 Train Loss: 0.0957
Epoch 4 Step 101 Train Loss: 0.0840
Epoch 4 Step 151 Train Loss: 0.0823
Epoch 4 Step 201 Train Loss: 0.0777
Epoch 4 Step 251 Train Loss: 0.0834
Epoch 4 Step 301 Train Loss: 0.0997
Epoch 4 Step 351 Train Loss: 0.0877
Epoch 4 Step 401 Train Loss: 0.0809
Epoch 4 Step 451 Train Loss: 0.1039
Epoch 4 Step 501 Train Loss: 0.0920
Epoch 4 Step 551 Train Loss: 0.0739
Epoch 4 Step 601 Train Loss: 0.0868
Epoch 4 Step 651 Train Loss: 0.0859
Epoch 4 Step 701 Train Loss: 0.0785
Epoch 4 Step 751 Train Loss: 0.0880
Epoch 4 Step 801 Train Loss: 0.0963
Epoch 4: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 5 Step 1 Train Loss: 0.0845
Epoch 5 Step 51 Train Loss: 0.0840
Epoch 5 Step 101 Train Loss: 0.0867
Epoch 5 Step 151 Train Loss: 0.0983
Epoch 5 Step 201 Train Loss: 0.0854
Epoch 5 Step 251 Train Loss: 0.0804
Epoch 5 Step 301 Train Loss: 0.1058
Epoch 5 Step 351 Train Loss: 0.0812
Epoch 5 Step 401 Train Loss: 0.0812
Epoch 5 Step 451 Train Loss: 0.0959
Epoch 5 Step 501 Train Loss: 0.0931
Epoch 5 Step 551 Train Loss: 0.0916
Epoch 5 Step 601 Train Loss: 0.0783
Epoch 5 Step 651 Train Loss: 0.0844
Epoch 5 Step 701 Train Loss: 0.1101
Epoch 5 Step 751 Train Loss: 0.0948
Epoch 5 Step 801 Train Loss: 0.1070
Epoch 5: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 6 Step 1 Train Loss: 0.0974
Epoch 6 Step 51 Train Loss: 0.0888
Epoch 6 Step 101 Train Loss: 0.0897
Epoch 6 Step 151 Train Loss: 0.0846
Epoch 6 Step 201 Train Loss: 0.0945
Epoch 6 Step 251 Train Loss: 0.0861
Epoch 6 Step 301 Train Loss: 0.0815
Epoch 6 Step 351 Train Loss: 0.0894
Epoch 6 Step 401 Train Loss: 0.0921
Epoch 6 Step 451 Train Loss: 0.1028
Epoch 6 Step 501 Train Loss: 0.0958
Epoch 6 Step 551 Train Loss: 0.0939
Epoch 6 Step 601 Train Loss: 0.0929
Epoch 6 Step 651 Train Loss: 0.1046
Epoch 6 Step 701 Train Loss: 0.0826
Epoch 6 Step 751 Train Loss: 0.1092
Epoch 6 Step 801 Train Loss: 0.0909
Epoch 6: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 7 Step 1 Train Loss: 0.0790
Epoch 7 Step 51 Train Loss: 0.1006
Epoch 7 Step 101 Train Loss: 0.0799
Epoch 7 Step 151 Train Loss: 0.0986
Epoch 7 Step 201 Train Loss: 0.1036
Epoch 7 Step 251 Train Loss: 0.0853
Epoch 7 Step 301 Train Loss: 0.0834
Epoch 7 Step 351 Train Loss: 0.1011
Epoch 7 Step 401 Train Loss: 0.1069
Epoch 7 Step 451 Train Loss: 0.0947
Epoch 7 Step 501 Train Loss: 0.0987
Epoch 7 Step 551 Train Loss: 0.0937
Epoch 7 Step 601 Train Loss: 0.0965
Epoch 7 Step 651 Train Loss: 0.0969
Epoch 7 Step 701 Train Loss: 0.0930
Epoch 7 Step 751 Train Loss: 0.0941
Epoch 7 Step 801 Train Loss: 0.0897
Epoch 7: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 8 Step 1 Train Loss: 0.0842
Epoch 8 Step 51 Train Loss: 0.0994
Epoch 8 Step 101 Train Loss: 0.0896
Epoch 8 Step 151 Train Loss: 0.0950
Epoch 8 Step 201 Train Loss: 0.1035
Epoch 8 Step 251 Train Loss: 0.0975
Epoch 8 Step 301 Train Loss: 0.0863
Epoch 8 Step 351 Train Loss: 0.0846
Epoch 8 Step 401 Train Loss: 0.0951
Epoch 8 Step 451 Train Loss: 0.0969
Epoch 8 Step 501 Train Loss: 0.0868
Epoch 8 Step 551 Train Loss: 0.0931
Epoch 8 Step 601 Train Loss: 0.0843
Epoch 8 Step 651 Train Loss: 0.0947
Epoch 8 Step 701 Train Loss: 0.0989
Epoch 8 Step 751 Train Loss: 0.0851
Epoch 8 Step 801 Train Loss: 0.1072
Epoch 8: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 9 Step 1 Train Loss: 0.1043
Epoch 9 Step 51 Train Loss: 0.0884
Epoch 9 Step 101 Train Loss: 0.0764
Epoch 9 Step 151 Train Loss: 0.0903
Epoch 9 Step 201 Train Loss: 0.1005
Epoch 9 Step 251 Train Loss: 0.0842
Epoch 9 Step 301 Train Loss: 0.1094
Epoch 9 Step 351 Train Loss: 0.0967
Epoch 9 Step 401 Train Loss: 0.0799
Epoch 9 Step 451 Train Loss: 0.0954
Epoch 9 Step 501 Train Loss: 0.0881
Epoch 9 Step 551 Train Loss: 0.1063
Epoch 9 Step 601 Train Loss: 0.0995
Epoch 9 Step 651 Train Loss: 0.1008
Epoch 9 Step 701 Train Loss: 0.0964
Epoch 9 Step 751 Train Loss: 0.1007
Epoch 9 Step 801 Train Loss: 0.1059
Epoch 9: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 10 Step 1 Train Loss: 0.0887
Epoch 10 Step 51 Train Loss: 0.0897
Epoch 10 Step 101 Train Loss: 0.0923
Epoch 10 Step 151 Train Loss: 0.1135
Epoch 10 Step 201 Train Loss: 0.0856
Epoch 10 Step 251 Train Loss: 0.0814
Epoch 10 Step 301 Train Loss: 0.0953
Epoch 10 Step 351 Train Loss: 0.1045
Epoch 10 Step 401 Train Loss: 0.0861
Epoch 10 Step 451 Train Loss: 0.0867
Epoch 10 Step 501 Train Loss: 0.1232
Epoch 10 Step 551 Train Loss: 0.0923
Epoch 10 Step 601 Train Loss: 0.1045
Epoch 10 Step 651 Train Loss: 0.1015
Epoch 10 Step 701 Train Loss: 0.0951
Epoch 10 Step 751 Train Loss: 0.0979
Epoch 10 Step 801 Train Loss: 0.1076
Epoch 10: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 11 Step 1 Train Loss: 0.0895
Epoch 11 Step 51 Train Loss: 0.0927
Epoch 11 Step 101 Train Loss: 0.1197
Epoch 11 Step 151 Train Loss: 0.1056
Epoch 11 Step 201 Train Loss: 0.0906
Epoch 11 Step 251 Train Loss: 0.0865
Epoch 11 Step 301 Train Loss: 0.0871
Epoch 11 Step 351 Train Loss: 0.0965
Epoch 11 Step 401 Train Loss: 0.1088
Epoch 11 Step 451 Train Loss: 0.0921
Epoch 11 Step 501 Train Loss: 0.1038
Epoch 11 Step 551 Train Loss: 0.0890
Epoch 11 Step 601 Train Loss: 0.0861
Epoch 11 Step 651 Train Loss: 0.1114
Epoch 11 Step 701 Train Loss: 0.1054
Epoch 11 Step 751 Train Loss: 0.1098
Epoch 11 Step 801 Train Loss: 0.1016
Epoch 11: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 12 Step 1 Train Loss: 0.0887
Epoch 12 Step 51 Train Loss: 0.1198
Epoch 12 Step 101 Train Loss: 0.1191
Epoch 12 Step 151 Train Loss: 0.1020
Epoch 12 Step 201 Train Loss: 0.0864
Epoch 12 Step 251 Train Loss: 0.0946
Epoch 12 Step 301 Train Loss: 0.0859
Epoch 12 Step 351 Train Loss: 0.1014
Epoch 12 Step 401 Train Loss: 0.1033
Epoch 12 Step 451 Train Loss: 0.0989
Epoch 12 Step 501 Train Loss: 0.0922
Epoch 12 Step 551 Train Loss: 0.0939
Epoch 12 Step 601 Train Loss: 0.1064
Epoch 12 Step 651 Train Loss: 0.0827
Epoch 12 Step 701 Train Loss: 0.1081
Epoch 12 Step 751 Train Loss: 0.0910
Epoch 12 Step 801 Train Loss: 0.1031
Epoch 12: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 13 Step 1 Train Loss: 0.0858
Epoch 13 Step 51 Train Loss: 0.1050
Epoch 13 Step 101 Train Loss: 0.0856
Epoch 13 Step 151 Train Loss: 0.1005
Epoch 13 Step 201 Train Loss: 0.0988
Epoch 13 Step 251 Train Loss: 0.0870
Epoch 13 Step 301 Train Loss: 0.0857
Epoch 13 Step 351 Train Loss: 0.0886
Epoch 13 Step 401 Train Loss: 0.1033
Epoch 13 Step 451 Train Loss: 0.0834
Epoch 13 Step 501 Train Loss: 0.0983
Epoch 13 Step 551 Train Loss: 0.1018
Epoch 13 Step 601 Train Loss: 0.0988
Epoch 13 Step 651 Train Loss: 0.0952
Epoch 13 Step 701 Train Loss: 0.0914
Epoch 13 Step 751 Train Loss: 0.0952
Epoch 13 Step 801 Train Loss: 0.0796
Epoch 13: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 14 Step 1 Train Loss: 0.0978
Epoch 14 Step 51 Train Loss: 0.0948
Epoch 14 Step 101 Train Loss: 0.0830
Epoch 14 Step 151 Train Loss: 0.0978
Epoch 14 Step 201 Train Loss: 0.0911
Epoch 14 Step 251 Train Loss: 0.0965
Epoch 14 Step 301 Train Loss: 0.0940
Epoch 14 Step 351 Train Loss: 0.0999
Epoch 14 Step 401 Train Loss: 0.0984
Epoch 14 Step 451 Train Loss: 0.1034
Epoch 14 Step 501 Train Loss: 0.0900
Epoch 14 Step 551 Train Loss: 0.1062
Epoch 14 Step 601 Train Loss: 0.0997
Epoch 14 Step 651 Train Loss: 0.1028
Epoch 14 Step 701 Train Loss: 0.0831
Epoch 14 Step 751 Train Loss: 0.1130
Epoch 14 Step 801 Train Loss: 0.0977
Epoch 14: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Epoch 15 Step 1 Train Loss: 0.0994
Epoch 15 Step 51 Train Loss: 0.0949
Epoch 15 Step 101 Train Loss: 0.1036
Epoch 15 Step 151 Train Loss: 0.0925
Epoch 15 Step 201 Train Loss: 0.0958
Epoch 15 Step 251 Train Loss: 0.1020
Epoch 15 Step 301 Train Loss: 0.0959
Epoch 15 Step 351 Train Loss: 0.1027
Epoch 15 Step 401 Train Loss: 0.1017
Epoch 15 Step 451 Train Loss: 0.0965
Epoch 15 Step 501 Train Loss: 0.1112
Epoch 15 Step 551 Train Loss: 0.1066
Epoch 15 Step 601 Train Loss: 0.0905
Epoch 15 Step 651 Train Loss: 0.0917
Epoch 15 Step 701 Train Loss: 0.1151
Epoch 15 Step 751 Train Loss: 0.0931
Epoch 15 Step 801 Train Loss: 0.1018
Epoch 15: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0039. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0035
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0014480358
test_combo_seen0_pearson: 0.8554239349137225
test_combo_seen0_mse_de: 0.0060257916
test_combo_seen0_pearson_de: 0.29946608351765214
test_combo_seen1_mse: 0.0011931349
test_combo_seen1_pearson: 0.8750404334933826
test_combo_seen1_mse_de: 0.0030591548
test_combo_seen1_pearson_de: 0.3765211388351963
test_combo_seen2_mse: 0.0012242987
test_combo_seen2_pearson: 0.8734864813859098
test_combo_seen2_mse_de: 0.003890083
test_combo_seen2_pearson_de: 0.2822679577310807
test_unseen_single_mse: 6.3941196e-05
test_unseen_single_pearson: 0.9917367236459562
test_unseen_single_mse_de: 0.00013521116
test_unseen_single_pearson_de: 0.6409245408447263
test_combo_seen0_pearson_delta: 0.03165430465137944
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.3833333333333333
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.2972222222222222
test_combo_seen0_mse_top20_de_non_dropout: 0.012870224
test_combo_seen1_pearson_delta: 0.02209877643569253
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.380379746835443
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.32151898734177214
test_combo_seen1_mse_top20_de_non_dropout: 0.0056254086
test_combo_seen2_pearson_delta: 0.009798464254675277
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.37142857142857144
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.30714285714285716
test_combo_seen2_mse_top20_de_non_dropout: 0.0077280947
test_unseen_single_pearson_delta: 0.08481200729225524
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.42857142857142855
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5857142857142856
test_unseen_single_mse_top20_de_non_dropout: 0.00014009805
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.027 MB uploadedwandb: | 0.001 MB of 0.027 MB uploadedwandb: / 0.022 MB of 0.027 MB uploadedwandb: - 0.024 MB of 0.027 MB uploadedwandb: \ 0.024 MB of 0.027 MB uploadedwandb: | 0.024 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.38333
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.29722
wandb:                                         test_combo_seen0_mse 0.00145
wandb:                                      test_combo_seen0_mse_de 0.00603
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.01287
wandb:                                     test_combo_seen0_pearson 0.85542
wandb:                                  test_combo_seen0_pearson_de 0.29947
wandb:                               test_combo_seen0_pearson_delta 0.03165
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.38038
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.32152
wandb:                                         test_combo_seen1_mse 0.00119
wandb:                                      test_combo_seen1_mse_de 0.00306
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00563
wandb:                                     test_combo_seen1_pearson 0.87504
wandb:                                  test_combo_seen1_pearson_de 0.37652
wandb:                               test_combo_seen1_pearson_delta 0.0221
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.37143
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.30714
wandb:                                         test_combo_seen2_mse 0.00122
wandb:                                      test_combo_seen2_mse_de 0.00389
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00773
wandb:                                     test_combo_seen2_pearson 0.87349
wandb:                                  test_combo_seen2_pearson_de 0.28227
wandb:                               test_combo_seen2_pearson_delta 0.0098
wandb:                                                  test_de_mse 0.00346
wandb:                                              test_de_pearson 0.3644
wandb:               test_frac_opposite_direction_top20_non_dropout 0.382
wandb:                          test_frac_sigma_below_1_non_dropout 0.3304
wandb:                                                     test_mse 0.00117
wandb:                                test_mse_top20_de_non_dropout 0.00671
wandb:                                                 test_pearson 0.87849
wandb:                                           test_pearson_delta 0.02492
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.42857
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.58571
wandb:                                       test_unseen_single_mse 6e-05
wandb:                                    test_unseen_single_mse_de 0.00014
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00014
wandb:                                   test_unseen_single_pearson 0.99174
wandb:                                test_unseen_single_pearson_de 0.64092
wandb:                             test_unseen_single_pearson_delta 0.08481
wandb:                                                 train_de_mse 0.00304
wandb:                                             train_de_pearson 0.49106
wandb:                                                    train_mse 0.00075
wandb:                                                train_pearson 0.91929
wandb:                                                training_loss 0.10379
wandb:                                                   val_de_mse 0.00393
wandb:                                               val_de_pearson 0.32023
wandb:                                                      val_mse 0.00142
wandb:                                                  val_pearson 0.85734
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_day7neuron_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/q2ljgad6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_114501-q2ljgad6/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:15
combo_seen1:81
combo_seen2:21
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_120202-1bkiybqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_day7neuron_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/1bkiybqx
wandb: WARNING Serializing object of type ndarray that is 8025728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1782
Epoch 1 Step 51 Train Loss: 0.1904
Epoch 1 Step 101 Train Loss: 0.1664
Epoch 1 Step 151 Train Loss: 0.1783
Epoch 1 Step 201 Train Loss: 0.1388
Epoch 1 Step 251 Train Loss: 0.1445
Epoch 1 Step 301 Train Loss: 0.1492
Epoch 1 Step 351 Train Loss: 0.1434
Epoch 1 Step 401 Train Loss: 0.1305
Epoch 1 Step 451 Train Loss: 0.1516
Epoch 1 Step 501 Train Loss: 0.1412
Epoch 1 Step 551 Train Loss: 0.1550
Epoch 1 Step 601 Train Loss: 0.1545
Epoch 1: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0045 Validation Top 20 DE MSE: 0.0061. 
Epoch 2 Step 1 Train Loss: 0.1422
Epoch 2 Step 51 Train Loss: 0.1485
Epoch 2 Step 101 Train Loss: 0.1394
Epoch 2 Step 151 Train Loss: 0.1251
Epoch 2 Step 201 Train Loss: 0.1209
Epoch 2 Step 251 Train Loss: 0.1204
Epoch 2 Step 301 Train Loss: 0.1157
Epoch 2 Step 351 Train Loss: 0.1261
Epoch 2 Step 401 Train Loss: 0.1263
Epoch 2 Step 451 Train Loss: 0.1093
Epoch 2 Step 501 Train Loss: 0.1112
Epoch 2 Step 551 Train Loss: 0.1114
Epoch 2 Step 601 Train Loss: 0.1043
Epoch 2: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0037 Validation Top 20 DE MSE: 0.0047. 
Epoch 3 Step 1 Train Loss: 0.1033
Epoch 3 Step 51 Train Loss: 0.1288
Epoch 3 Step 101 Train Loss: 0.1123
Epoch 3 Step 151 Train Loss: 0.1043
Epoch 3 Step 201 Train Loss: 0.1015
Epoch 3 Step 251 Train Loss: 0.1040
Epoch 3 Step 301 Train Loss: 0.0879
Epoch 3 Step 351 Train Loss: 0.0920
Epoch 3 Step 401 Train Loss: 0.1084
Epoch 3 Step 451 Train Loss: 0.1122
Epoch 3 Step 501 Train Loss: 0.0984
Epoch 3 Step 551 Train Loss: 0.1025
Epoch 3 Step 601 Train Loss: 0.0847
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0048. 
Epoch 4 Step 1 Train Loss: 0.1151
Epoch 4 Step 51 Train Loss: 0.1112
Epoch 4 Step 101 Train Loss: 0.1033
Epoch 4 Step 151 Train Loss: 0.0854
Epoch 4 Step 201 Train Loss: 0.0892
Epoch 4 Step 251 Train Loss: 0.0966
Epoch 4 Step 301 Train Loss: 0.0891
Epoch 4 Step 351 Train Loss: 0.0877
Epoch 4 Step 401 Train Loss: 0.0890
Epoch 4 Step 451 Train Loss: 0.0827
Epoch 4 Step 501 Train Loss: 0.1052
Epoch 4 Step 551 Train Loss: 0.0855
Epoch 4 Step 601 Train Loss: 0.0964
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 5 Step 1 Train Loss: 0.1012
Epoch 5 Step 51 Train Loss: 0.0818
Epoch 5 Step 101 Train Loss: 0.1017
Epoch 5 Step 151 Train Loss: 0.1012
Epoch 5 Step 201 Train Loss: 0.0820
Epoch 5 Step 251 Train Loss: 0.0886
Epoch 5 Step 301 Train Loss: 0.0983
Epoch 5 Step 351 Train Loss: 0.1122
Epoch 5 Step 401 Train Loss: 0.0937
Epoch 5 Step 451 Train Loss: 0.0836
Epoch 5 Step 501 Train Loss: 0.1008
Epoch 5 Step 551 Train Loss: 0.1042
Epoch 5 Step 601 Train Loss: 0.0856
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 6 Step 1 Train Loss: 0.0941
Epoch 6 Step 51 Train Loss: 0.0824
Epoch 6 Step 101 Train Loss: 0.0845
Epoch 6 Step 151 Train Loss: 0.0940
Epoch 6 Step 201 Train Loss: 0.0843
Epoch 6 Step 251 Train Loss: 0.0889
Epoch 6 Step 301 Train Loss: 0.0981
Epoch 6 Step 351 Train Loss: 0.0864
Epoch 6 Step 401 Train Loss: 0.0783
Epoch 6 Step 451 Train Loss: 0.0832
Epoch 6 Step 501 Train Loss: 0.0829
Epoch 6 Step 551 Train Loss: 0.0870
Epoch 6 Step 601 Train Loss: 0.1208
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 7 Step 1 Train Loss: 0.0858
Epoch 7 Step 51 Train Loss: 0.0884
Epoch 7 Step 101 Train Loss: 0.1177
Epoch 7 Step 151 Train Loss: 0.1013
Epoch 7 Step 201 Train Loss: 0.0977
Epoch 7 Step 251 Train Loss: 0.0809
Epoch 7 Step 301 Train Loss: 0.0839
Epoch 7 Step 351 Train Loss: 0.0924
Epoch 7 Step 401 Train Loss: 0.0917
Epoch 7 Step 451 Train Loss: 0.1027
Epoch 7 Step 501 Train Loss: 0.0967
Epoch 7 Step 551 Train Loss: 0.0790
Epoch 7 Step 601 Train Loss: 0.0885
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0047. 
Epoch 8 Step 1 Train Loss: 0.1305
Epoch 8 Step 51 Train Loss: 0.0814
Epoch 8 Step 101 Train Loss: 0.0881
Epoch 8 Step 151 Train Loss: 0.0970
Epoch 8 Step 201 Train Loss: 0.0892
Epoch 8 Step 251 Train Loss: 0.1223
Epoch 8 Step 301 Train Loss: 0.1030
Epoch 8 Step 351 Train Loss: 0.0992
Epoch 8 Step 401 Train Loss: 0.0858
Epoch 8 Step 451 Train Loss: 0.0866
Epoch 8 Step 501 Train Loss: 0.0891
Epoch 8 Step 551 Train Loss: 0.1023
Epoch 8 Step 601 Train Loss: 0.0979
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 9 Step 1 Train Loss: 0.0938
Epoch 9 Step 51 Train Loss: 0.0888
Epoch 9 Step 101 Train Loss: 0.0936
Epoch 9 Step 151 Train Loss: 0.0910
Epoch 9 Step 201 Train Loss: 0.0898
Epoch 9 Step 251 Train Loss: 0.0965
Epoch 9 Step 301 Train Loss: 0.0950
Epoch 9 Step 351 Train Loss: 0.0879
Epoch 9 Step 401 Train Loss: 0.0932
Epoch 9 Step 451 Train Loss: 0.0996
Epoch 9 Step 501 Train Loss: 0.1033
Epoch 9 Step 551 Train Loss: 0.0964
Epoch 9 Step 601 Train Loss: 0.1013
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 10 Step 1 Train Loss: 0.0911
Epoch 10 Step 51 Train Loss: 0.0896
Epoch 10 Step 101 Train Loss: 0.0901
Epoch 10 Step 151 Train Loss: 0.1043
Epoch 10 Step 201 Train Loss: 0.0941
Epoch 10 Step 251 Train Loss: 0.0943
Epoch 10 Step 301 Train Loss: 0.1020
Epoch 10 Step 351 Train Loss: 0.0978
Epoch 10 Step 401 Train Loss: 0.1058
Epoch 10 Step 451 Train Loss: 0.1056
Epoch 10 Step 501 Train Loss: 0.1015
Epoch 10 Step 551 Train Loss: 0.0959
Epoch 10 Step 601 Train Loss: 0.0911
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 11 Step 1 Train Loss: 0.1043
Epoch 11 Step 51 Train Loss: 0.0931
Epoch 11 Step 101 Train Loss: 0.1009
Epoch 11 Step 151 Train Loss: 0.0914
Epoch 11 Step 201 Train Loss: 0.0997
Epoch 11 Step 251 Train Loss: 0.0853
Epoch 11 Step 301 Train Loss: 0.1121
Epoch 11 Step 351 Train Loss: 0.0884
Epoch 11 Step 401 Train Loss: 0.1056
Epoch 11 Step 451 Train Loss: 0.1057
Epoch 11 Step 501 Train Loss: 0.0863
Epoch 11 Step 551 Train Loss: 0.0937
Epoch 11 Step 601 Train Loss: 0.0933
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0047. 
Epoch 12 Step 1 Train Loss: 0.0869
Epoch 12 Step 51 Train Loss: 0.1018
Epoch 12 Step 101 Train Loss: 0.1014
Epoch 12 Step 151 Train Loss: 0.1039
Epoch 12 Step 201 Train Loss: 0.0981
Epoch 12 Step 251 Train Loss: 0.1022
Epoch 12 Step 301 Train Loss: 0.0977
Epoch 12 Step 351 Train Loss: 0.0978
Epoch 12 Step 401 Train Loss: 0.0916
Epoch 12 Step 451 Train Loss: 0.1042
Epoch 12 Step 501 Train Loss: 0.1032
Epoch 12 Step 551 Train Loss: 0.0951
Epoch 12 Step 601 Train Loss: 0.0851
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 13 Step 1 Train Loss: 0.0962
Epoch 13 Step 51 Train Loss: 0.0931
Epoch 13 Step 101 Train Loss: 0.0995
Epoch 13 Step 151 Train Loss: 0.1139
Epoch 13 Step 201 Train Loss: 0.0986
Epoch 13 Step 251 Train Loss: 0.0840
Epoch 13 Step 301 Train Loss: 0.0847
Epoch 13 Step 351 Train Loss: 0.0822
Epoch 13 Step 401 Train Loss: 0.1059
Epoch 13 Step 451 Train Loss: 0.1002
Epoch 13 Step 501 Train Loss: 0.1065
Epoch 13 Step 551 Train Loss: 0.1109
Epoch 13 Step 601 Train Loss: 0.0870
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0047. 
Epoch 14 Step 1 Train Loss: 0.0935
Epoch 14 Step 51 Train Loss: 0.1041
Epoch 14 Step 101 Train Loss: 0.0885
Epoch 14 Step 151 Train Loss: 0.1048
Epoch 14 Step 201 Train Loss: 0.0971
Epoch 14 Step 251 Train Loss: 0.1034
Epoch 14 Step 301 Train Loss: 0.0975
Epoch 14 Step 351 Train Loss: 0.0957
Epoch 14 Step 401 Train Loss: 0.0976
Epoch 14 Step 451 Train Loss: 0.1092
Epoch 14 Step 501 Train Loss: 0.0950
Epoch 14 Step 551 Train Loss: 0.0953
Epoch 14 Step 601 Train Loss: 0.0920
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Epoch 15 Step 1 Train Loss: 0.0859
Epoch 15 Step 51 Train Loss: 0.0951
Epoch 15 Step 101 Train Loss: 0.0927
Epoch 15 Step 151 Train Loss: 0.0997
Epoch 15 Step 201 Train Loss: 0.1262
Epoch 15 Step 251 Train Loss: 0.1023
Epoch 15 Step 301 Train Loss: 0.1041
Epoch 15 Step 351 Train Loss: 0.0991
Epoch 15 Step 401 Train Loss: 0.0990
Epoch 15 Step 451 Train Loss: 0.1036
Epoch 15 Step 501 Train Loss: 0.0856
Epoch 15 Step 551 Train Loss: 0.0960
Epoch 15 Step 601 Train Loss: 0.1059
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0035 Validation Top 20 DE MSE: 0.0047. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0033
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0011109513
test_combo_seen0_pearson: 0.8829623637311453
test_combo_seen0_mse_de: 0.0040991516
test_combo_seen0_pearson_de: 0.3260045300136702
test_combo_seen1_mse: 0.001105055
test_combo_seen1_pearson: 0.8839344155318841
test_combo_seen1_mse_de: 0.0035290313
test_combo_seen1_pearson_de: 0.39644641583695167
test_combo_seen2_mse: 0.0012054021
test_combo_seen2_pearson: 0.8731977727502533
test_combo_seen2_mse_de: 0.0028591745
test_combo_seen2_pearson_de: 0.513831736886453
test_unseen_single_mse: 0.000112914015
test_unseen_single_pearson: 0.9861658197695806
test_unseen_single_mse_de: 0.0002247771
test_unseen_single_pearson_de: 0.6519885446440875
test_combo_seen0_pearson_delta: 0.00010652886166358603
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.43333333333333335
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.28
test_combo_seen0_mse_top20_de_non_dropout: 0.009787583
test_combo_seen1_pearson_delta: 0.01384380108348716
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.40925925925925927
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.2753086419753087
test_combo_seen1_mse_top20_de_non_dropout: 0.005980112
test_combo_seen2_pearson_delta: 0.010950196829743757
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.34047619047619043
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.29047619047619044
test_combo_seen2_mse_top20_de_non_dropout: 0.004686214
test_unseen_single_pearson_delta: 0.06457413890445421
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4785714285714286
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5142857142857143
test_unseen_single_mse_top20_de_non_dropout: 0.00023847164
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.025 MB uploadedwandb: | 0.004 MB of 0.025 MB uploadedwandb: / 0.004 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.43333
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.28
wandb:                                         test_combo_seen0_mse 0.00111
wandb:                                      test_combo_seen0_mse_de 0.0041
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.00979
wandb:                                     test_combo_seen0_pearson 0.88296
wandb:                                  test_combo_seen0_pearson_de 0.326
wandb:                               test_combo_seen0_pearson_delta 0.00011
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.40926
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.27531
wandb:                                         test_combo_seen1_mse 0.00111
wandb:                                      test_combo_seen1_mse_de 0.00353
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00598
wandb:                                     test_combo_seen1_pearson 0.88393
wandb:                                  test_combo_seen1_pearson_de 0.39645
wandb:                               test_combo_seen1_pearson_delta 0.01384
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.34048
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.29048
wandb:                                         test_combo_seen2_mse 0.00121
wandb:                                      test_combo_seen2_mse_de 0.00286
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00469
wandb:                                     test_combo_seen2_pearson 0.8732
wandb:                                  test_combo_seen2_pearson_de 0.51383
wandb:                               test_combo_seen2_pearson_delta 0.01095
wandb:                                                  test_de_mse 0.0033
wandb:                                              test_de_pearson 0.42223
wandb:               test_frac_opposite_direction_top20_non_dropout 0.40444
wandb:                          test_frac_sigma_below_1_non_dropout 0.29194
wandb:                                                     test_mse 0.00107
wandb:                                test_mse_top20_de_non_dropout 0.0059
wandb:                                                 test_pearson 0.88777
wandb:                                           test_pearson_delta 0.01456
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.47857
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.51429
wandb:                                       test_unseen_single_mse 0.00011
wandb:                                    test_unseen_single_mse_de 0.00022
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00024
wandb:                                   test_unseen_single_pearson 0.98617
wandb:                                test_unseen_single_pearson_de 0.65199
wandb:                             test_unseen_single_pearson_delta 0.06457
wandb:                                                 train_de_mse 0.00355
wandb:                                             train_de_pearson 0.44998
wandb:                                                    train_mse 0.00107
wandb:                                                train_pearson 0.89182
wandb:                                                training_loss 0.08614
wandb:                                                   val_de_mse 0.00473
wandb:                                               val_de_pearson 0.27804
wandb:                                                      val_mse 0.00122
wandb:                                                  val_pearson 0.87191
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_day7neuron_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/1bkiybqx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_120202-1bkiybqx/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:13
combo_seen1:75
combo_seen2:23
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_121610-spewzj5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_day7neuron_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/spewzj5m
wandb: WARNING Serializing object of type ndarray that is 8025728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1756
Epoch 1 Step 51 Train Loss: 0.1841
Epoch 1 Step 101 Train Loss: 0.1623
Epoch 1 Step 151 Train Loss: 0.1693
Epoch 1 Step 201 Train Loss: 0.1630
Epoch 1 Step 251 Train Loss: 0.1607
Epoch 1 Step 301 Train Loss: 0.1441
Epoch 1 Step 351 Train Loss: 0.1468
Epoch 1 Step 401 Train Loss: 0.1490
Epoch 1 Step 451 Train Loss: 0.1558
Epoch 1 Step 501 Train Loss: 0.1533
Epoch 1 Step 551 Train Loss: 0.1595
Epoch 1: Train Overall MSE: 0.0034 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0085 Validation Top 20 DE MSE: 0.0078. 
Epoch 2 Step 1 Train Loss: 0.1490
Epoch 2 Step 51 Train Loss: 0.1428
Epoch 2 Step 101 Train Loss: 0.1365
Epoch 2 Step 151 Train Loss: 0.1163
Epoch 2 Step 201 Train Loss: 0.1460
Epoch 2 Step 251 Train Loss: 0.1469
Epoch 2 Step 301 Train Loss: 0.1453
Epoch 2 Step 351 Train Loss: 0.1403
Epoch 2 Step 401 Train Loss: 0.1323
Epoch 2 Step 451 Train Loss: 0.1160
Epoch 2 Step 501 Train Loss: 0.1264
Epoch 2 Step 551 Train Loss: 0.1219
Epoch 2: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0040. 
Epoch 3 Step 1 Train Loss: 0.1109
Epoch 3 Step 51 Train Loss: 0.1052
Epoch 3 Step 101 Train Loss: 0.1200
Epoch 3 Step 151 Train Loss: 0.1350
Epoch 3 Step 201 Train Loss: 0.1197
Epoch 3 Step 251 Train Loss: 0.1191
Epoch 3 Step 301 Train Loss: 0.0943
Epoch 3 Step 351 Train Loss: 0.1097
Epoch 3 Step 401 Train Loss: 0.1004
Epoch 3 Step 451 Train Loss: 0.0965
Epoch 3 Step 501 Train Loss: 0.1052
Epoch 3 Step 551 Train Loss: 0.1000
Epoch 3: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0028 Validation Top 20 DE MSE: 0.0040. 
Epoch 4 Step 1 Train Loss: 0.1027
Epoch 4 Step 51 Train Loss: 0.1042
Epoch 4 Step 101 Train Loss: 0.1097
Epoch 4 Step 151 Train Loss: 0.0971
Epoch 4 Step 201 Train Loss: 0.1144
Epoch 4 Step 251 Train Loss: 0.1047
Epoch 4 Step 301 Train Loss: 0.0983
Epoch 4 Step 351 Train Loss: 0.1100
Epoch 4 Step 401 Train Loss: 0.0974
Epoch 4 Step 451 Train Loss: 0.0990
Epoch 4 Step 501 Train Loss: 0.0999
Epoch 4 Step 551 Train Loss: 0.0925
Epoch 4: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0027 Validation Top 20 DE MSE: 0.0038. 
Epoch 5 Step 1 Train Loss: 0.0867
Epoch 5 Step 51 Train Loss: 0.0873
Epoch 5 Step 101 Train Loss: 0.1065
Epoch 5 Step 151 Train Loss: 0.0822
Epoch 5 Step 201 Train Loss: 0.1034
Epoch 5 Step 251 Train Loss: 0.0913
Epoch 5 Step 301 Train Loss: 0.1074
Epoch 5 Step 351 Train Loss: 0.0942
Epoch 5 Step 401 Train Loss: 0.0998
Epoch 5 Step 451 Train Loss: 0.0840
Epoch 5 Step 501 Train Loss: 0.0956
Epoch 5 Step 551 Train Loss: 0.0905
Epoch 5: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 6 Step 1 Train Loss: 0.0897
Epoch 6 Step 51 Train Loss: 0.0880
Epoch 6 Step 101 Train Loss: 0.0949
Epoch 6 Step 151 Train Loss: 0.0850
Epoch 6 Step 201 Train Loss: 0.0885
Epoch 6 Step 251 Train Loss: 0.0911
Epoch 6 Step 301 Train Loss: 0.0792
Epoch 6 Step 351 Train Loss: 0.0974
Epoch 6 Step 401 Train Loss: 0.1002
Epoch 6 Step 451 Train Loss: 0.0872
Epoch 6 Step 501 Train Loss: 0.0852
Epoch 6 Step 551 Train Loss: 0.0867
Epoch 6: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 7 Step 1 Train Loss: 0.1009
Epoch 7 Step 51 Train Loss: 0.0838
Epoch 7 Step 101 Train Loss: 0.1064
Epoch 7 Step 151 Train Loss: 0.0954
Epoch 7 Step 201 Train Loss: 0.0941
Epoch 7 Step 251 Train Loss: 0.1019
Epoch 7 Step 301 Train Loss: 0.0971
Epoch 7 Step 351 Train Loss: 0.0982
Epoch 7 Step 401 Train Loss: 0.1010
Epoch 7 Step 451 Train Loss: 0.0868
Epoch 7 Step 501 Train Loss: 0.0980
Epoch 7 Step 551 Train Loss: 0.0921
Epoch 7: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 8 Step 1 Train Loss: 0.1040
Epoch 8 Step 51 Train Loss: 0.0954
Epoch 8 Step 101 Train Loss: 0.0976
Epoch 8 Step 151 Train Loss: 0.1102
Epoch 8 Step 201 Train Loss: 0.1089
Epoch 8 Step 251 Train Loss: 0.0885
Epoch 8 Step 301 Train Loss: 0.0941
Epoch 8 Step 351 Train Loss: 0.1052
Epoch 8 Step 401 Train Loss: 0.1002
Epoch 8 Step 451 Train Loss: 0.0903
Epoch 8 Step 501 Train Loss: 0.1019
Epoch 8 Step 551 Train Loss: 0.0943
Epoch 8: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 9 Step 1 Train Loss: 0.0944
Epoch 9 Step 51 Train Loss: 0.1008
Epoch 9 Step 101 Train Loss: 0.0893
Epoch 9 Step 151 Train Loss: 0.0978
Epoch 9 Step 201 Train Loss: 0.0905
Epoch 9 Step 251 Train Loss: 0.0895
Epoch 9 Step 301 Train Loss: 0.0967
Epoch 9 Step 351 Train Loss: 0.1093
Epoch 9 Step 401 Train Loss: 0.1104
Epoch 9 Step 451 Train Loss: 0.0983
Epoch 9 Step 501 Train Loss: 0.0960
Epoch 9 Step 551 Train Loss: 0.1149
Epoch 9: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 10 Step 1 Train Loss: 0.0919
Epoch 10 Step 51 Train Loss: 0.1024
Epoch 10 Step 101 Train Loss: 0.1047
Epoch 10 Step 151 Train Loss: 0.0927
Epoch 10 Step 201 Train Loss: 0.1107
Epoch 10 Step 251 Train Loss: 0.1006
Epoch 10 Step 301 Train Loss: 0.1066
Epoch 10 Step 351 Train Loss: 0.1021
Epoch 10 Step 401 Train Loss: 0.1025
Epoch 10 Step 451 Train Loss: 0.1042
Epoch 10 Step 501 Train Loss: 0.1227
Epoch 10 Step 551 Train Loss: 0.0981
Epoch 10: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0037. 
Epoch 11 Step 1 Train Loss: 0.1030
Epoch 11 Step 51 Train Loss: 0.0985
Epoch 11 Step 101 Train Loss: 0.1060
Epoch 11 Step 151 Train Loss: 0.1027
Epoch 11 Step 201 Train Loss: 0.0903
Epoch 11 Step 251 Train Loss: 0.0991
Epoch 11 Step 301 Train Loss: 0.1044
Epoch 11 Step 351 Train Loss: 0.1025
Epoch 11 Step 401 Train Loss: 0.0970
Epoch 11 Step 451 Train Loss: 0.1087
Epoch 11 Step 501 Train Loss: 0.1030
Epoch 11 Step 551 Train Loss: 0.1072
Epoch 11: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 12 Step 1 Train Loss: 0.1023
Epoch 12 Step 51 Train Loss: 0.0935
Epoch 12 Step 101 Train Loss: 0.0998
Epoch 12 Step 151 Train Loss: 0.1065
Epoch 12 Step 201 Train Loss: 0.1035
Epoch 12 Step 251 Train Loss: 0.0965
Epoch 12 Step 301 Train Loss: 0.0848
Epoch 12 Step 351 Train Loss: 0.0995
Epoch 12 Step 401 Train Loss: 0.1039
Epoch 12 Step 451 Train Loss: 0.1073
Epoch 12 Step 501 Train Loss: 0.1024
Epoch 12 Step 551 Train Loss: 0.0934
Epoch 12: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0037. 
Epoch 13 Step 1 Train Loss: 0.0921
Epoch 13 Step 51 Train Loss: 0.0943
Epoch 13 Step 101 Train Loss: 0.0811
Epoch 13 Step 151 Train Loss: 0.0831
Epoch 13 Step 201 Train Loss: 0.0979
Epoch 13 Step 251 Train Loss: 0.0871
Epoch 13 Step 301 Train Loss: 0.0947
Epoch 13 Step 351 Train Loss: 0.0859
Epoch 13 Step 401 Train Loss: 0.0927
Epoch 13 Step 451 Train Loss: 0.1143
Epoch 13 Step 501 Train Loss: 0.1092
Epoch 13 Step 551 Train Loss: 0.1002
Epoch 13: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 14 Step 1 Train Loss: 0.0979
Epoch 14 Step 51 Train Loss: 0.0967
Epoch 14 Step 101 Train Loss: 0.0940
Epoch 14 Step 151 Train Loss: 0.0985
Epoch 14 Step 201 Train Loss: 0.1063
Epoch 14 Step 251 Train Loss: 0.1142
Epoch 14 Step 301 Train Loss: 0.1009
Epoch 14 Step 351 Train Loss: 0.1060
Epoch 14 Step 401 Train Loss: 0.0962
Epoch 14 Step 451 Train Loss: 0.0828
Epoch 14 Step 501 Train Loss: 0.0945
Epoch 14 Step 551 Train Loss: 0.0975
Epoch 14: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Epoch 15 Step 1 Train Loss: 0.1046
Epoch 15 Step 51 Train Loss: 0.0904
Epoch 15 Step 101 Train Loss: 0.1186
Epoch 15 Step 151 Train Loss: 0.0970
Epoch 15 Step 201 Train Loss: 0.0826
Epoch 15 Step 251 Train Loss: 0.0891
Epoch 15 Step 301 Train Loss: 0.0819
Epoch 15 Step 351 Train Loss: 0.1075
Epoch 15 Step 401 Train Loss: 0.0856
Epoch 15 Step 451 Train Loss: 0.0957
Epoch 15 Step 501 Train Loss: 0.1106
Epoch 15 Step 551 Train Loss: 0.1110
Epoch 15: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0036. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0035
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0010095085
test_combo_seen0_pearson: 0.890824290181686
test_combo_seen0_mse_de: 0.004803132
test_combo_seen0_pearson_de: 0.2949372200725332
test_combo_seen1_mse: 0.0012263174
test_combo_seen1_pearson: 0.8720651176325503
test_combo_seen1_mse_de: 0.0035266774
test_combo_seen1_pearson_de: 0.2624866666299447
test_combo_seen2_mse: 0.0011932336
test_combo_seen2_pearson: 0.8765823674867379
test_combo_seen2_mse_de: 0.0035592406
test_combo_seen2_pearson_de: 0.24071445082942625
test_unseen_single_mse: 7.120815e-05
test_unseen_single_pearson: 0.9908202492975594
test_unseen_single_mse_de: 0.00017365513
test_unseen_single_pearson_de: 0.5958919692085809
test_combo_seen0_pearson_delta: 0.06725302591676462
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.4076923076923077
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.3076923076923077
test_combo_seen0_mse_top20_de_non_dropout: 0.011005254
test_combo_seen1_pearson_delta: 0.03388223462266769
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.3326666666666667
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.31266666666666665
test_combo_seen1_mse_top20_de_non_dropout: 0.0057260306
test_combo_seen2_pearson_delta: 0.03036560137548236
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.332608695652174
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.2826086956521739
test_combo_seen2_mse_top20_de_non_dropout: 0.008369352
test_unseen_single_pearson_delta: 0.12380484089300804
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.37142857142857144
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5428571428571429
test_unseen_single_mse_top20_de_non_dropout: 0.00017242793
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.025 MB uploadedwandb: | 0.004 MB of 0.025 MB uploadedwandb: / 0.025 MB of 0.025 MB uploadedwandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.025 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñá‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.40769
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.30769
wandb:                                         test_combo_seen0_mse 0.00101
wandb:                                      test_combo_seen0_mse_de 0.0048
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.01101
wandb:                                     test_combo_seen0_pearson 0.89082
wandb:                                  test_combo_seen0_pearson_de 0.29494
wandb:                               test_combo_seen0_pearson_delta 0.06725
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.33267
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.31267
wandb:                                         test_combo_seen1_mse 0.00123
wandb:                                      test_combo_seen1_mse_de 0.00353
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.00573
wandb:                                     test_combo_seen1_pearson 0.87207
wandb:                                  test_combo_seen1_pearson_de 0.26249
wandb:                               test_combo_seen1_pearson_delta 0.03388
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.33261
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.28261
wandb:                                         test_combo_seen2_mse 0.00119
wandb:                                      test_combo_seen2_mse_de 0.00356
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.00837
wandb:                                     test_combo_seen2_pearson 0.87658
wandb:                                  test_combo_seen2_pearson_de 0.24071
wandb:                               test_combo_seen2_pearson_delta 0.03037
wandb:                                                  test_de_mse 0.00347
wandb:                                              test_de_pearson 0.2816
wandb:               test_frac_opposite_direction_top20_non_dropout 0.34322
wandb:                          test_frac_sigma_below_1_non_dropout 0.31992
wandb:                                                     test_mse 0.00113
wandb:                                test_mse_top20_de_non_dropout 0.00649
wandb:                                                 test_pearson 0.88206
wandb:                                           test_pearson_delta 0.04221
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.37143
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.54286
wandb:                                       test_unseen_single_mse 7e-05
wandb:                                    test_unseen_single_mse_de 0.00017
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00017
wandb:                                   test_unseen_single_pearson 0.99082
wandb:                                test_unseen_single_pearson_de 0.59589
wandb:                             test_unseen_single_pearson_delta 0.1238
wandb:                                                 train_de_mse 0.00258
wandb:                                             train_de_pearson 0.3411
wandb:                                                    train_mse 0.00097
wandb:                                                train_pearson 0.89748
wandb:                                                training_loss 0.09406
wandb:                                                   val_de_mse 0.00363
wandb:                                               val_de_pearson 0.30689
wandb:                                                      val_mse 0.00146
wandb:                                                  val_pearson 0.84602
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_day7neuron_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/spewzj5m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_121610-spewzj5m/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:21
combo_seen1:100
combo_seen2:26
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_123003-c5tnk7gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_iPSC_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/c5tnk7gr
wandb: WARNING Serializing object of type ndarray that is 8032128 bytes
  0%|                                                                                       | 0/3982 [00:00<?, ?it/s]  0%|                                                                               | 5/3982 [00:00<01:31, 43.53it/s]  0%|‚ñé                                                                             | 13/3982 [00:00<01:11, 55.26it/s]  1%|‚ñç                                                                             | 20/3982 [00:00<01:05, 60.48it/s]  1%|‚ñå                                                                             | 30/3982 [00:00<00:57, 69.07it/s]  1%|‚ñä                                                                             | 39/3982 [00:00<00:52, 75.72it/s]  1%|‚ñâ                                                                             | 47/3982 [00:00<00:51, 76.24it/s]  1%|‚ñà                                                                             | 55/3982 [00:00<00:51, 76.81it/s]  2%|‚ñà‚ñè                                                                            | 63/3982 [00:00<00:50, 77.25it/s]  2%|‚ñà‚ñç                                                                            | 71/3982 [00:00<00:50, 77.24it/s]  2%|‚ñà‚ñå                                                                            | 79/3982 [00:01<00:50, 77.47it/s]  2%|‚ñà‚ñã                                                                            | 87/3982 [00:01<00:50, 77.49it/s]  2%|‚ñà‚ñä                                                                            | 95/3982 [00:01<00:50, 77.63it/s]  3%|‚ñà‚ñâ                                                                           | 103/3982 [00:01<00:53, 73.03it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 112/3982 [00:01<00:51, 75.44it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 120/3982 [00:01<00:51, 74.91it/s]  3%|‚ñà‚ñà‚ñç                                                                          | 128/3982 [00:01<00:55, 69.62it/s]  3%|‚ñà‚ñà‚ñã                                                                          | 138/3982 [00:01<00:50, 75.83it/s]  4%|‚ñà‚ñà‚ñä                                                                          | 146/3982 [00:01<00:51, 74.90it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 154/3982 [00:02<00:53, 71.79it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 163/3982 [00:02<00:50, 75.27it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 171/3982 [00:02<00:50, 76.01it/s]  4%|‚ñà‚ñà‚ñà‚ñç                                                                         | 179/3982 [00:02<00:49, 76.80it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 187/3982 [00:02<00:49, 76.76it/s]  5%|‚ñà‚ñà‚ñà‚ñä                                                                         | 195/3982 [00:02<00:49, 76.94it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 203/3982 [00:02<00:50, 74.44it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 212/3982 [00:02<00:48, 77.92it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 220/3982 [00:02<00:48, 77.71it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 228/3982 [00:03<00:49, 75.14it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 237/3982 [00:03<00:48, 77.86it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 245/3982 [00:03<00:48, 76.87it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 253/3982 [00:03<00:49, 74.72it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 262/3982 [00:03<00:47, 78.35it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 270/3982 [00:03<00:47, 78.25it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 278/3982 [00:03<00:48, 75.98it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 287/3982 [00:03<00:46, 79.59it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 295/3982 [00:03<00:48, 75.85it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 303/3982 [00:04<00:50, 72.39it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 311/3982 [00:04<00:52, 70.55it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 319/3982 [00:04<00:55, 65.97it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 326/3982 [00:04<00:57, 63.36it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 333/3982 [00:04<00:58, 61.86it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 340/3982 [00:04<00:59, 61.34it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 347/3982 [00:04<01:02, 58.00it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 354/3982 [00:04<00:59, 60.75it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 361/3982 [00:05<01:00, 59.72it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 368/3982 [00:05<01:00, 59.89it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 375/3982 [00:05<01:00, 59.44it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 382/3982 [00:05<01:03, 57.11it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 388/3982 [00:05<01:02, 57.41it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 396/3982 [00:05<01:01, 58.21it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 402/3982 [00:05<01:01, 58.14it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 408/3982 [00:05<01:01, 58.04it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 415/3982 [00:05<00:59, 59.83it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 421/3982 [00:06<01:00, 59.00it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 427/3982 [00:06<01:00, 58.55it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 433/3982 [00:06<01:00, 58.83it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 440/3982 [00:06<00:59, 59.40it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 446/3982 [00:06<00:59, 58.97it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 452/3982 [00:06<00:59, 58.99it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 458/3982 [00:06<00:59, 58.90it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 465/3982 [00:06<00:59, 59.40it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 471/3982 [00:06<00:59, 59.24it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 477/3982 [00:07<00:59, 58.54it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 483/3982 [00:07<00:59, 58.80it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 489/3982 [00:07<00:59, 58.86it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 495/3982 [00:07<00:59, 58.68it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 501/3982 [00:07<00:59, 58.99it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 507/3982 [00:07<00:59, 58.88it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 513/3982 [00:07<00:59, 58.74it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 519/3982 [00:07<00:59, 58.45it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 525/3982 [00:07<00:58, 58.69it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 531/3982 [00:07<01:02, 55.58it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 537/3982 [00:08<01:00, 56.80it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 544/3982 [00:08<00:57, 60.03it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 551/3982 [00:08<00:57, 59.54it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 557/3982 [00:08<00:57, 59.18it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 563/3982 [00:08<00:58, 58.79it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 569/3982 [00:08<00:57, 58.91it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 575/3982 [00:08<00:58, 58.61it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 581/3982 [00:08<00:58, 58.40it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 587/3982 [00:08<00:57, 58.63it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 593/3982 [00:09<01:01, 55.34it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 599/3982 [00:09<01:00, 55.70it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 606/3982 [00:09<00:57, 58.92it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 613/3982 [00:09<00:56, 59.33it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 620/3982 [00:09<00:56, 59.35it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                 | 626/3982 [00:09<00:56, 59.28it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 632/3982 [00:09<00:56, 59.35it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 638/3982 [00:09<00:56, 58.82it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 644/3982 [00:09<00:57, 58.48it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 650/3982 [00:09<00:57, 58.26it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 656/3982 [00:10<00:56, 58.52it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 662/3982 [00:10<00:56, 58.33it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 668/3982 [00:10<00:56, 58.42it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 674/3982 [00:10<00:56, 58.77it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 680/3982 [00:10<00:56, 58.47it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 687/3982 [00:10<00:55, 59.40it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 694/3982 [00:10<00:57, 57.14it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 701/3982 [00:10<00:54, 59.75it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 708/3982 [00:10<00:58, 56.36it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 714/3982 [00:11<00:57, 56.41it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 721/3982 [00:11<00:54, 59.80it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 728/3982 [00:11<00:54, 59.23it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 734/3982 [00:11<00:54, 59.10it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 740/3982 [00:11<00:54, 58.97it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 746/3982 [00:11<00:55, 58.57it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 752/3982 [00:11<00:55, 58.69it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 758/3982 [00:11<00:54, 58.66it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 764/3982 [00:11<00:54, 58.85it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 770/3982 [00:12<00:54, 59.04it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 776/3982 [00:12<00:54, 58.74it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 782/3982 [00:12<00:57, 55.92it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 789/3982 [00:12<00:53, 59.80it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 796/3982 [00:12<00:53, 59.44it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 802/3982 [00:12<00:53, 59.08it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 809/3982 [00:12<00:53, 59.57it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 815/3982 [00:12<00:53, 59.48it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 821/3982 [00:12<00:53, 59.22it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 827/3982 [00:12<00:53, 58.45it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 833/3982 [00:13<00:53, 58.69it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 840/3982 [00:13<00:52, 59.38it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                            | 846/3982 [00:13<00:53, 59.11it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 852/3982 [00:13<00:53, 58.62it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 858/3982 [00:13<00:53, 58.75it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                            | 865/3982 [00:13<00:51, 60.08it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 872/3982 [00:13<00:52, 59.38it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                            | 879/3982 [00:13<00:51, 59.81it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 885/3982 [00:13<00:52, 59.00it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 893/3982 [00:14<00:48, 63.06it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 902/3982 [00:14<00:44, 68.93it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 910/3982 [00:14<00:43, 70.64it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 918/3982 [00:14<00:42, 71.90it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 926/3982 [00:14<00:42, 72.56it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 934/3982 [00:14<00:41, 73.25it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 942/3982 [00:14<00:41, 72.59it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 950/3982 [00:14<00:42, 72.14it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 958/3982 [00:14<00:44, 68.65it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 966/3982 [00:15<00:42, 70.85it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 974/3982 [00:15<00:45, 65.77it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 981/3982 [00:15<00:47, 63.03it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 988/3982 [00:15<00:49, 61.06it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 995/3982 [00:15<00:50, 58.91it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                        | 1004/3982 [00:15<00:45, 65.25it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 1011/3982 [00:15<00:45, 64.99it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                        | 1018/3982 [00:15<00:45, 64.76it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 1027/3982 [00:16<00:42, 69.92it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 1035/3982 [00:16<00:41, 71.40it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 1043/3982 [00:16<00:40, 72.48it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 1052/3982 [00:16<00:48, 60.04it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1060/3982 [00:16<00:45, 63.68it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 1068/3982 [00:16<00:43, 66.36it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 1075/3982 [00:16<00:44, 65.35it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 1083/3982 [00:16<00:42, 67.91it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                       | 1092/3982 [00:16<00:40, 71.59it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 1100/3982 [00:17<00:40, 70.98it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 1108/3982 [00:17<00:40, 71.69it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                      | 1116/3982 [00:17<00:40, 71.48it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 1124/3982 [00:17<00:39, 71.65it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 1132/3982 [00:17<00:39, 71.96it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 1140/3982 [00:17<00:40, 71.01it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 1148/3982 [00:17<00:39, 71.28it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1156/3982 [00:17<00:40, 70.60it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 1164/3982 [00:18<00:39, 71.04it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1172/3982 [00:18<00:39, 71.98it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 1180/3982 [00:18<00:39, 71.16it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1189/3982 [00:18<00:38, 73.32it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1198/3982 [00:18<00:37, 74.60it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1206/3982 [00:18<00:36, 75.63it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1215/3982 [00:18<00:34, 79.14it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1223/3982 [00:18<00:34, 79.12it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1231/3982 [00:18<00:34, 79.15it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1239/3982 [00:18<00:34, 78.53it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1247/3982 [00:19<00:34, 78.88it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 1256/3982 [00:19<00:34, 79.37it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1264/3982 [00:19<00:34, 78.83it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1272/3982 [00:19<00:35, 75.72it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1280/3982 [00:19<00:35, 76.70it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1288/3982 [00:19<00:34, 77.63it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1297/3982 [00:19<00:34, 78.52it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1306/3982 [00:19<00:33, 79.08it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1315/3982 [00:19<00:33, 79.70it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 1323/3982 [00:20<00:33, 79.14it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1332/3982 [00:20<00:32, 81.77it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1341/3982 [00:20<00:32, 81.27it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1350/3982 [00:20<00:34, 76.61it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1358/3982 [00:20<00:35, 73.68it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1366/3982 [00:20<00:36, 71.94it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1375/3982 [00:20<00:34, 76.37it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1383/3982 [00:20<00:34, 74.62it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1391/3982 [00:20<00:34, 75.26it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1400/3982 [00:21<00:32, 79.22it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1408/3982 [00:21<00:33, 77.39it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1416/3982 [00:21<00:32, 77.98it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 1426/3982 [00:21<00:32, 79.14it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1434/3982 [00:21<00:32, 79.18it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1443/3982 [00:21<00:33, 76.64it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1453/3982 [00:21<00:31, 79.51it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1462/3982 [00:21<00:30, 81.85it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1471/3982 [00:21<00:32, 76.78it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1480/3982 [00:22<00:32, 76.43it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1489/3982 [00:22<00:32, 76.90it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 1497/3982 [00:22<00:33, 74.84it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1507/3982 [00:22<00:31, 79.18it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 1515/3982 [00:22<00:32, 75.10it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1523/3982 [00:22<00:32, 74.54it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1533/3982 [00:22<00:31, 77.07it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 1541/3982 [00:22<00:34, 71.57it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1550/3982 [00:23<00:31, 76.25it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1560/3982 [00:23<00:30, 78.97it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 1571/3982 [00:23<00:28, 85.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1582/3982 [00:23<00:27, 87.88it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1592/3982 [00:23<00:26, 89.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 1602/3982 [00:23<00:26, 89.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1612/3982 [00:23<00:26, 90.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1622/3982 [00:23<00:26, 89.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1632/3982 [00:23<00:26, 89.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1642/3982 [00:24<00:25, 91.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1652/3982 [00:24<00:25, 91.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1662/3982 [00:24<00:25, 91.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1672/3982 [00:24<00:25, 91.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 1682/3982 [00:24<00:24, 92.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 1692/3982 [00:24<00:25, 90.18it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 1702/3982 [00:24<00:25, 90.43it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 1713/3982 [00:24<00:23, 94.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 1723/3982 [00:24<00:24, 92.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 1733/3982 [00:24<00:24, 91.46it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 1743/3982 [00:25<00:24, 91.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 1753/3982 [00:25<00:24, 91.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 1763/3982 [00:25<00:24, 90.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1773/3982 [00:25<00:23, 92.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 1783/3982 [00:25<00:24, 89.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 1793/3982 [00:25<00:24, 89.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 1802/3982 [00:25<00:24, 89.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1811/3982 [00:25<00:24, 89.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 1821/3982 [00:25<00:23, 91.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 1831/3982 [00:26<00:24, 88.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1841/3982 [00:26<00:23, 89.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 1850/3982 [00:26<00:23, 89.02it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 1859/3982 [00:26<00:23, 89.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 1868/3982 [00:26<00:23, 89.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 1877/3982 [00:26<00:23, 88.89it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 1886/3982 [00:26<00:23, 89.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 1896/3982 [00:26<00:23, 89.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 1905/3982 [00:26<00:23, 88.67it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 1914/3982 [00:27<00:23, 88.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 1923/3982 [00:27<00:23, 88.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1932/3982 [00:27<00:23, 88.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 1942/3982 [00:27<00:23, 86.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 1953/3982 [00:27<00:22, 89.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1962/3982 [00:27<00:22, 88.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1973/3982 [00:27<00:22, 89.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 1983/3982 [00:27<00:22, 90.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1994/3982 [00:27<00:22, 90.20it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 2004/3982 [00:28<00:21, 91.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 2014/3982 [00:28<00:22, 88.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 2023/3982 [00:28<00:22, 86.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 2034/3982 [00:28<00:21, 90.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 2044/3982 [00:28<00:21, 91.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 2054/3982 [00:28<00:22, 87.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 2063/3982 [00:28<00:21, 87.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 2072/3982 [00:28<00:23, 82.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 2081/3982 [00:28<00:25, 75.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 2089/3982 [00:29<00:26, 70.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 2098/3982 [00:29<00:25, 73.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 2108/3982 [00:29<00:24, 76.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 2120/3982 [00:29<00:21, 85.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 2131/3982 [00:29<00:20, 89.29it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 2141/3982 [00:29<00:20, 88.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2150/3982 [00:29<00:21, 85.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 2161/3982 [00:29<00:20, 90.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 2171/3982 [00:29<00:19, 92.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 2181/3982 [00:30<00:20, 89.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 2191/3982 [00:30<00:19, 92.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 2201/3982 [00:30<00:20, 88.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 2210/3982 [00:30<00:23, 75.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 2218/3982 [00:30<00:23, 74.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 2226/3982 [00:30<00:25, 69.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 2234/3982 [00:30<00:24, 71.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 2244/3982 [00:30<00:22, 77.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 2254/3982 [00:31<00:21, 79.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 2263/3982 [00:31<00:21, 81.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2272/3982 [00:31<00:20, 82.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 2282/3982 [00:31<00:19, 85.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2292/3982 [00:31<00:19, 88.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 2301/3982 [00:31<00:20, 83.79it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 2312/3982 [00:31<00:18, 90.24it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2322/3982 [00:31<00:19, 86.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2331/3982 [00:31<00:19, 86.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2341/3982 [00:32<00:18, 89.15it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 2350/3982 [00:32<00:18, 87.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 2359/3982 [00:32<00:19, 84.85it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 2368/3982 [00:32<00:19, 84.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2377/3982 [00:32<00:18, 84.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2387/3982 [00:32<00:18, 87.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2396/3982 [00:32<00:18, 86.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2405/3982 [00:32<00:18, 84.40it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2414/3982 [00:32<00:19, 81.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 2423/3982 [00:33<00:18, 83.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2432/3982 [00:33<00:18, 83.20it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 2441/3982 [00:33<00:19, 80.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2451/3982 [00:33<00:18, 81.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 2460/3982 [00:33<00:19, 78.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2471/3982 [00:33<00:18, 80.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 2482/3982 [00:33<00:17, 85.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2491/3982 [00:33<00:17, 82.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 2500/3982 [00:33<00:18, 81.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2509/3982 [00:34<00:18, 79.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 2519/3982 [00:34<00:17, 84.64it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 2528/3982 [00:34<00:17, 80.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 2538/3982 [00:34<00:17, 81.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 2547/3982 [00:34<00:17, 82.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 2557/3982 [00:34<00:17, 82.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 2566/3982 [00:34<00:16, 83.62it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 2576/3982 [00:34<00:16, 85.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 2585/3982 [00:35<00:16, 85.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2594/3982 [00:35<00:16, 85.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 2603/3982 [00:35<00:16, 84.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 2612/3982 [00:35<00:16, 81.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 2622/3982 [00:35<00:16, 84.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 2631/3982 [00:35<00:16, 83.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 2640/3982 [00:35<00:16, 80.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 2650/3982 [00:35<00:15, 83.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 2659/3982 [00:35<00:15, 83.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 2668/3982 [00:36<00:15, 82.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2677/3982 [00:36<00:16, 80.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2687/3982 [00:36<00:15, 81.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 2697/3982 [00:36<00:15, 84.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2706/3982 [00:36<00:15, 80.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2716/3982 [00:36<00:15, 83.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2725/3982 [00:36<00:15, 83.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2734/3982 [00:36<00:15, 78.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2745/3982 [00:36<00:14, 82.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2755/3982 [00:37<00:14, 82.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2765/3982 [00:37<00:14, 84.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2774/3982 [00:37<00:14, 83.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2783/3982 [00:37<00:14, 83.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2792/3982 [00:37<00:14, 83.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2801/3982 [00:37<00:14, 83.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2810/3982 [00:37<00:14, 82.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2819/3982 [00:37<00:14, 82.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2828/3982 [00:37<00:13, 82.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2837/3982 [00:38<00:14, 80.46it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2847/3982 [00:38<00:13, 84.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2856/3982 [00:38<00:13, 84.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2865/3982 [00:38<00:14, 79.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2876/3982 [00:38<00:12, 85.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2885/3982 [00:38<00:13, 82.15it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2895/3982 [00:38<00:13, 83.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2905/3982 [00:38<00:12, 83.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2915/3982 [00:38<00:12, 85.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2924/3982 [00:39<00:12, 85.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2933/3982 [00:39<00:12, 84.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2942/3982 [00:39<00:12, 84.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2951/3982 [00:39<00:12, 83.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2960/3982 [00:39<00:12, 80.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2970/3982 [00:39<00:12, 82.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2980/3982 [00:39<00:11, 85.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2989/3982 [00:39<00:12, 82.20it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2999/3982 [00:39<00:11, 85.08it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 3008/3982 [00:40<00:11, 84.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 3017/3982 [00:40<00:11, 81.38it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 3027/3982 [00:40<00:11, 81.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 3037/3982 [00:40<00:11, 82.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3047/3982 [00:40<00:10, 85.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 3056/3982 [00:40<00:11, 84.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3065/3982 [00:40<00:10, 83.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3074/3982 [00:40<00:10, 83.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3083/3982 [00:41<00:11, 79.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3092/3982 [00:41<00:10, 82.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3101/3982 [00:41<00:10, 80.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3110/3982 [00:41<00:11, 77.45it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3119/3982 [00:41<00:11, 78.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3129/3982 [00:41<00:10, 81.69it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3138/3982 [00:41<00:11, 76.19it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3148/3982 [00:41<00:10, 82.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3157/3982 [00:41<00:10, 81.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3166/3982 [00:42<00:10, 81.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3175/3982 [00:42<00:09, 81.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3184/3982 [00:42<00:09, 81.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3193/3982 [00:42<00:09, 81.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3202/3982 [00:42<00:09, 79.18it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3210/3982 [00:42<00:09, 79.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3220/3982 [00:42<00:09, 82.69it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3229/3982 [00:42<00:09, 82.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3238/3982 [00:42<00:09, 81.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3247/3982 [00:43<00:09, 78.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3256/3982 [00:43<00:09, 78.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3264/3982 [00:43<00:09, 79.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3273/3982 [00:43<00:08, 79.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3281/3982 [00:43<00:09, 77.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3291/3982 [00:43<00:08, 81.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3300/3982 [00:43<00:08, 81.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3309/3982 [00:43<00:08, 80.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3318/3982 [00:43<00:08, 81.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3327/3982 [00:44<00:08, 81.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3336/3982 [00:44<00:08, 79.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3345/3982 [00:44<00:07, 80.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3355/3982 [00:44<00:07, 83.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3364/3982 [00:44<00:07, 80.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3374/3982 [00:44<00:07, 83.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3383/3982 [00:44<00:07, 80.07it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3393/3982 [00:44<00:07, 83.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3402/3982 [00:44<00:06, 82.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3411/3982 [00:45<00:06, 81.79it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 3420/3982 [00:45<00:06, 81.59it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3429/3982 [00:45<00:06, 81.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3438/3982 [00:45<00:06, 81.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3447/3982 [00:45<00:06, 81.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3456/3982 [00:45<00:06, 81.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3465/3982 [00:45<00:06, 80.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 3474/3982 [00:45<00:06, 81.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 3483/3982 [00:45<00:06, 81.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 3492/3982 [00:46<00:05, 81.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 3501/3982 [00:46<00:05, 81.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 3510/3982 [00:46<00:06, 78.03it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 3520/3982 [00:46<00:05, 81.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 3529/3982 [00:46<00:05, 81.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 3538/3982 [00:46<00:05, 81.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 3547/3982 [00:46<00:05, 81.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 3556/3982 [00:46<00:05, 81.38it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 3565/3982 [00:46<00:05, 81.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 3574/3982 [00:47<00:04, 81.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 3583/3982 [00:47<00:04, 81.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 3592/3982 [00:47<00:04, 81.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 3601/3982 [00:47<00:04, 80.46it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 3610/3982 [00:47<00:04, 80.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 3619/3982 [00:47<00:04, 78.36it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 3629/3982 [00:47<00:04, 82.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 3638/3982 [00:47<00:04, 81.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3647/3982 [00:47<00:04, 79.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3656/3982 [00:48<00:04, 80.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 3665/3982 [00:48<00:03, 80.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 3674/3982 [00:48<00:03, 80.93it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3683/3982 [00:48<00:03, 78.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 3693/3982 [00:48<00:03, 81.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 3702/3982 [00:48<00:03, 81.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 3711/3982 [00:48<00:03, 81.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3720/3982 [00:48<00:03, 78.16it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3730/3982 [00:49<00:03, 81.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3739/3982 [00:49<00:02, 81.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3748/3982 [00:49<00:02, 81.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3757/3982 [00:49<00:02, 79.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3767/3982 [00:49<00:02, 82.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3776/3982 [00:49<00:02, 81.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3785/3982 [00:49<00:02, 81.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3794/3982 [00:49<00:02, 81.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3803/3982 [00:49<00:02, 82.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3812/3982 [00:50<00:02, 81.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3821/3982 [00:50<00:02, 78.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3831/3982 [00:50<00:01, 82.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3840/3982 [00:50<00:01, 81.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3849/3982 [00:50<00:01, 80.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3858/3982 [00:50<00:01, 80.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3867/3982 [00:50<00:01, 80.35it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3876/3982 [00:50<00:01, 79.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3885/3982 [00:50<00:01, 77.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3894/3982 [00:51<00:01, 80.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3903/3982 [00:51<00:00, 80.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3912/3982 [00:51<00:00, 80.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3921/3982 [00:51<00:00, 79.90it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3930/3982 [00:51<00:00, 80.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3939/3982 [00:51<00:00, 80.45it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3948/3982 [00:51<00:00, 77.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3957/3982 [00:51<00:00, 79.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3966/3982 [00:51<00:00, 81.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3975/3982 [00:52<00:00, 81.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3982/3982 [00:52<00:00, 76.35it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.1758
Epoch 1 Step 51 Train Loss: 0.2009
Epoch 1 Step 101 Train Loss: 0.2004
Epoch 1 Step 151 Train Loss: 0.1889
Epoch 1 Step 201 Train Loss: 0.2014
Epoch 1 Step 251 Train Loss: 0.1667
Epoch 1 Step 301 Train Loss: 0.1866
Epoch 1 Step 351 Train Loss: 0.1832
Epoch 1 Step 401 Train Loss: 0.1915
Epoch 1 Step 451 Train Loss: 0.1839
Epoch 1 Step 501 Train Loss: 0.1652
Epoch 1 Step 551 Train Loss: 0.1803
Epoch 1 Step 601 Train Loss: 0.1721
Epoch 1 Step 651 Train Loss: 0.1973
Epoch 1 Step 701 Train Loss: 0.1803
Epoch 1 Step 751 Train Loss: 0.2186
Epoch 1: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0212 Validation Top 20 DE MSE: 0.0158. 
Epoch 2 Step 1 Train Loss: 0.1685
Epoch 2 Step 51 Train Loss: 0.1756
Epoch 2 Step 101 Train Loss: 0.1847
Epoch 2 Step 151 Train Loss: 0.1680
Epoch 2 Step 201 Train Loss: 0.1761
Epoch 2 Step 251 Train Loss: 0.1424
Epoch 2 Step 301 Train Loss: 0.1756
Epoch 2 Step 351 Train Loss: 0.1519
Epoch 2 Step 401 Train Loss: 0.1433
Epoch 2 Step 451 Train Loss: 0.1338
Epoch 2 Step 501 Train Loss: 0.1397
Epoch 2 Step 551 Train Loss: 0.2530
Epoch 2 Step 601 Train Loss: 0.1438
Epoch 2 Step 651 Train Loss: 0.1397
Epoch 2 Step 701 Train Loss: 0.1398
Epoch 2 Step 751 Train Loss: 0.1496
Epoch 2: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0144. 
Epoch 3 Step 1 Train Loss: 0.1727
Epoch 3 Step 51 Train Loss: 0.1450
Epoch 3 Step 101 Train Loss: 0.1518
Epoch 3 Step 151 Train Loss: 0.1529
Epoch 3 Step 201 Train Loss: 0.1418
Epoch 3 Step 251 Train Loss: 0.1459
Epoch 3 Step 301 Train Loss: 0.2806
Epoch 3 Step 351 Train Loss: 0.1467
Epoch 3 Step 401 Train Loss: 0.1376
Epoch 3 Step 451 Train Loss: 0.1512
Epoch 3 Step 501 Train Loss: 0.1688
Epoch 3 Step 551 Train Loss: 0.1534
Epoch 3 Step 601 Train Loss: 0.1261
Epoch 3 Step 651 Train Loss: 0.1248
Epoch 3 Step 701 Train Loss: 0.1647
Epoch 3 Step 751 Train Loss: 0.1311
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0203 Validation Top 20 DE MSE: 0.0150. 
Epoch 4 Step 1 Train Loss: 0.1474
Epoch 4 Step 51 Train Loss: 0.1480
Epoch 4 Step 101 Train Loss: 0.1532
Epoch 4 Step 151 Train Loss: 0.1582
Epoch 4 Step 201 Train Loss: 0.1394
Epoch 4 Step 251 Train Loss: 0.1338
Epoch 4 Step 301 Train Loss: 0.1531
Epoch 4 Step 351 Train Loss: 0.1632
Epoch 4 Step 401 Train Loss: 0.1400
Epoch 4 Step 451 Train Loss: 0.1191
Epoch 4 Step 501 Train Loss: 0.1403
Epoch 4 Step 551 Train Loss: 0.1407
Epoch 4 Step 601 Train Loss: 0.1587
Epoch 4 Step 651 Train Loss: 0.1427
Epoch 4 Step 701 Train Loss: 0.1515
Epoch 4 Step 751 Train Loss: 0.1285
Epoch 4: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0208 Validation Top 20 DE MSE: 0.0150. 
Epoch 5 Step 1 Train Loss: 0.1806
Epoch 5 Step 51 Train Loss: 0.1504
Epoch 5 Step 101 Train Loss: 0.1480
Epoch 5 Step 151 Train Loss: 0.1712
Epoch 5 Step 201 Train Loss: 0.1424
Epoch 5 Step 251 Train Loss: 0.1550
Epoch 5 Step 301 Train Loss: 0.1460
Epoch 5 Step 351 Train Loss: 0.1545
Epoch 5 Step 401 Train Loss: 0.1401
Epoch 5 Step 451 Train Loss: 0.1419
Epoch 5 Step 501 Train Loss: 0.1170
Epoch 5 Step 551 Train Loss: 0.1495
Epoch 5 Step 601 Train Loss: 0.1428
Epoch 5 Step 651 Train Loss: 0.1372
Epoch 5 Step 701 Train Loss: 0.1678
Epoch 5 Step 751 Train Loss: 0.1545
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0203 Validation Top 20 DE MSE: 0.0146. 
Epoch 6 Step 1 Train Loss: 0.1363
Epoch 6 Step 51 Train Loss: 0.1386
Epoch 6 Step 101 Train Loss: 0.1329
Epoch 6 Step 151 Train Loss: 0.1450
Epoch 6 Step 201 Train Loss: 0.1519
Epoch 6 Step 251 Train Loss: 0.1580
Epoch 6 Step 301 Train Loss: 0.1594
Epoch 6 Step 351 Train Loss: 0.1432
Epoch 6 Step 401 Train Loss: 0.1501
Epoch 6 Step 451 Train Loss: 0.1672
Epoch 6 Step 501 Train Loss: 0.1366
Epoch 6 Step 551 Train Loss: 0.1476
Epoch 6 Step 601 Train Loss: 0.1407
Epoch 6 Step 651 Train Loss: 0.1598
Epoch 6 Step 701 Train Loss: 0.1539
Epoch 6 Step 751 Train Loss: 0.1312
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0203 Validation Top 20 DE MSE: 0.0146. 
Epoch 7 Step 1 Train Loss: 0.1764
Epoch 7 Step 51 Train Loss: 0.1578
Epoch 7 Step 101 Train Loss: 0.1504
Epoch 7 Step 151 Train Loss: 0.1413
Epoch 7 Step 201 Train Loss: 0.1482
Epoch 7 Step 251 Train Loss: 0.1331
Epoch 7 Step 301 Train Loss: 0.1357
Epoch 7 Step 351 Train Loss: 0.1394
Epoch 7 Step 401 Train Loss: 0.1573
Epoch 7 Step 451 Train Loss: 0.1562
Epoch 7 Step 501 Train Loss: 0.1265
Epoch 7 Step 551 Train Loss: 0.1517
Epoch 7 Step 601 Train Loss: 0.1347
Epoch 7 Step 651 Train Loss: 0.1825
Epoch 7 Step 701 Train Loss: 0.1714
Epoch 7 Step 751 Train Loss: 0.1373
Epoch 7: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0205 Validation Top 20 DE MSE: 0.0147. 
Epoch 8 Step 1 Train Loss: 0.1445
Epoch 8 Step 51 Train Loss: 0.1533
Epoch 8 Step 101 Train Loss: 0.1164
Epoch 8 Step 151 Train Loss: 0.1424
Epoch 8 Step 201 Train Loss: 0.1538
Epoch 8 Step 251 Train Loss: 0.1603
Epoch 8 Step 301 Train Loss: 0.1350
Epoch 8 Step 351 Train Loss: 0.1458
Epoch 8 Step 401 Train Loss: 0.1351
Epoch 8 Step 451 Train Loss: 0.1767
Epoch 8 Step 501 Train Loss: 0.2324
Epoch 8 Step 551 Train Loss: 0.2719
Epoch 8 Step 601 Train Loss: 0.1333
Epoch 8 Step 651 Train Loss: 0.1594
Epoch 8 Step 701 Train Loss: 0.1670
Epoch 8 Step 751 Train Loss: 0.1475
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0202 Validation Top 20 DE MSE: 0.0142. 
Epoch 9 Step 1 Train Loss: 0.1557
Epoch 9 Step 51 Train Loss: 0.1406
Epoch 9 Step 101 Train Loss: 0.1464
Epoch 9 Step 151 Train Loss: 0.1751
Epoch 9 Step 201 Train Loss: 0.1395
Epoch 9 Step 251 Train Loss: 0.1791
Epoch 9 Step 301 Train Loss: 0.1520
Epoch 9 Step 351 Train Loss: 0.1500
Epoch 9 Step 401 Train Loss: 0.1502
Epoch 9 Step 451 Train Loss: 0.1546
Epoch 9 Step 501 Train Loss: 0.2177
Epoch 9 Step 551 Train Loss: 0.1534
Epoch 9 Step 601 Train Loss: 0.1555
Epoch 9 Step 651 Train Loss: 0.1502
Epoch 9 Step 701 Train Loss: 0.1429
Epoch 9 Step 751 Train Loss: 0.1396
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0206 Validation Top 20 DE MSE: 0.0148. 
Epoch 10 Step 1 Train Loss: 0.1486
Epoch 10 Step 51 Train Loss: 0.1596
Epoch 10 Step 101 Train Loss: 0.1472
Epoch 10 Step 151 Train Loss: 0.1736
Epoch 10 Step 201 Train Loss: 0.1560
Epoch 10 Step 251 Train Loss: 0.1544
Epoch 10 Step 301 Train Loss: 0.1444
Epoch 10 Step 351 Train Loss: 0.1509
Epoch 10 Step 401 Train Loss: 0.1485
Epoch 10 Step 451 Train Loss: 0.1443
Epoch 10 Step 501 Train Loss: 0.1499
Epoch 10 Step 551 Train Loss: 0.1674
Epoch 10 Step 601 Train Loss: 0.1340
Epoch 10 Step 651 Train Loss: 0.1640
Epoch 10 Step 701 Train Loss: 0.1550
Epoch 10 Step 751 Train Loss: 0.1684
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0201 Validation Top 20 DE MSE: 0.0143. 
Epoch 11 Step 1 Train Loss: 0.1568
Epoch 11 Step 51 Train Loss: 0.1864
Epoch 11 Step 101 Train Loss: 0.1418
Epoch 11 Step 151 Train Loss: 0.1360
Epoch 11 Step 201 Train Loss: 0.1578
Epoch 11 Step 251 Train Loss: 0.1667
Epoch 11 Step 301 Train Loss: 0.1455
Epoch 11 Step 351 Train Loss: 0.1462
Epoch 11 Step 401 Train Loss: 0.1438
Epoch 11 Step 451 Train Loss: 0.1641
Epoch 11 Step 501 Train Loss: 0.1507
Epoch 11 Step 551 Train Loss: 0.1533
Epoch 11 Step 601 Train Loss: 0.1525
Epoch 11 Step 651 Train Loss: 0.1562
Epoch 11 Step 701 Train Loss: 0.1419
Epoch 11 Step 751 Train Loss: 0.1351
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0204 Validation Top 20 DE MSE: 0.0146. 
Epoch 12 Step 1 Train Loss: 0.1995
Epoch 12 Step 51 Train Loss: 0.1577
Epoch 12 Step 101 Train Loss: 0.1535
Epoch 12 Step 151 Train Loss: 0.1425
Epoch 12 Step 201 Train Loss: 0.1628
Epoch 12 Step 251 Train Loss: 0.1679
Epoch 12 Step 301 Train Loss: 0.1378
Epoch 12 Step 351 Train Loss: 0.1500
Epoch 12 Step 401 Train Loss: 0.1330
Epoch 12 Step 451 Train Loss: 0.1360
Epoch 12 Step 501 Train Loss: 0.1557
Epoch 12 Step 551 Train Loss: 0.1514
Epoch 12 Step 601 Train Loss: 0.1342
Epoch 12 Step 651 Train Loss: 0.1456
Epoch 12 Step 701 Train Loss: 0.1548
Epoch 12 Step 751 Train Loss: 0.1403
Epoch 12: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0202 Validation Top 20 DE MSE: 0.0145. 
Epoch 13 Step 1 Train Loss: 0.1563
Epoch 13 Step 51 Train Loss: 0.1591
Epoch 13 Step 101 Train Loss: 0.1819
Epoch 13 Step 151 Train Loss: 0.1346
Epoch 13 Step 201 Train Loss: 0.1576
Epoch 13 Step 251 Train Loss: 0.1497
Epoch 13 Step 301 Train Loss: 0.1536
Epoch 13 Step 351 Train Loss: 0.1652
Epoch 13 Step 401 Train Loss: 0.1575
Epoch 13 Step 451 Train Loss: 0.1684
Epoch 13 Step 501 Train Loss: 0.1454
Epoch 13 Step 551 Train Loss: 0.1546
Epoch 13 Step 601 Train Loss: 0.1468
Epoch 13 Step 651 Train Loss: 0.1513
Epoch 13 Step 701 Train Loss: 0.1505
Epoch 13 Step 751 Train Loss: 0.2071
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0203 Validation Top 20 DE MSE: 0.0146. 
Epoch 14 Step 1 Train Loss: 0.1468
Epoch 14 Step 51 Train Loss: 0.1711
Epoch 14 Step 101 Train Loss: 0.1465
Epoch 14 Step 151 Train Loss: 0.1384
Epoch 14 Step 201 Train Loss: 0.1646
Epoch 14 Step 251 Train Loss: 0.1273
Epoch 14 Step 301 Train Loss: 0.1404
Epoch 14 Step 351 Train Loss: 0.1436
Epoch 14 Step 401 Train Loss: 0.1395
Epoch 14 Step 451 Train Loss: 0.1514
Epoch 14 Step 501 Train Loss: 0.1425
Epoch 14 Step 551 Train Loss: 0.1405
Epoch 14 Step 601 Train Loss: 0.1459
Epoch 14 Step 651 Train Loss: 0.1614
Epoch 14 Step 701 Train Loss: 0.1563
Epoch 14 Step 751 Train Loss: 0.1548
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0206 Validation Top 20 DE MSE: 0.0148. 
Epoch 15 Step 1 Train Loss: 0.1572
Epoch 15 Step 51 Train Loss: 0.1539
Epoch 15 Step 101 Train Loss: 0.1575
Epoch 15 Step 151 Train Loss: 0.1533
Epoch 15 Step 201 Train Loss: 0.1657
Epoch 15 Step 251 Train Loss: 0.1438
Epoch 15 Step 301 Train Loss: 0.1440
Epoch 15 Step 351 Train Loss: 0.1561
Epoch 15 Step 401 Train Loss: 0.2686
Epoch 15 Step 451 Train Loss: 0.1380
Epoch 15 Step 501 Train Loss: 0.1404
Epoch 15 Step 551 Train Loss: 0.2637
Epoch 15 Step 601 Train Loss: 0.2439
Epoch 15 Step 651 Train Loss: 0.1547
Epoch 15 Step 701 Train Loss: 0.1279
Epoch 15 Step 751 Train Loss: 0.1655
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0201 Validation Top 20 DE MSE: 0.0143. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0185
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0012583827
test_combo_seen0_pearson: 0.9440694848833727
test_combo_seen0_mse_de: 0.013138687
test_combo_seen0_pearson_de: 0.12894983715566796
test_combo_seen1_mse: 0.001347473
test_combo_seen1_pearson: 0.9406594726016388
test_combo_seen1_mse_de: 0.018092103
test_combo_seen1_pearson_de: 0.11415034281598019
test_combo_seen2_mse: 0.002084477
test_combo_seen2_pearson: 0.9094288593522053
test_combo_seen2_mse_de: 0.029256739
test_combo_seen2_pearson_de: 0.024739471083032708
test_unseen_single_mse: 3.1443975e-05
test_unseen_single_pearson: 0.9984457080933973
test_unseen_single_mse_de: 0.00012144299
test_unseen_single_pearson_de: 0.7166827403173182
test_combo_seen0_pearson_delta: 0.03221762946155532
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.5857142857142857
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.5785714285714285
test_combo_seen0_mse_top20_de_non_dropout: 0.04526048
test_combo_seen1_pearson_delta: 0.05510464974749308
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.559
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5745
test_combo_seen1_mse_top20_de_non_dropout: 0.051683236
test_combo_seen2_pearson_delta: 0.01269557988221893
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5903846153846154
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.5230769230769231
test_combo_seen2_mse_top20_de_non_dropout: 0.09671183
test_unseen_single_pearson_delta: 0.21870597026167943
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.35714285714285715
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9071428571428573
test_unseen_single_mse_top20_de_non_dropout: 0.00019690629
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.027 MB uploadedwandb: | 0.015 MB of 0.027 MB uploadedwandb: / 0.015 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                                                      val_mse ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.58571
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.57857
wandb:                                         test_combo_seen0_mse 0.00126
wandb:                                      test_combo_seen0_mse_de 0.01314
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.04526
wandb:                                     test_combo_seen0_pearson 0.94407
wandb:                                  test_combo_seen0_pearson_de 0.12895
wandb:                               test_combo_seen0_pearson_delta 0.03222
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.559
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.5745
wandb:                                         test_combo_seen1_mse 0.00135
wandb:                                      test_combo_seen1_mse_de 0.01809
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05168
wandb:                                     test_combo_seen1_pearson 0.94066
wandb:                                  test_combo_seen1_pearson_de 0.11415
wandb:                               test_combo_seen1_pearson_delta 0.0551
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.59038
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.52308
wandb:                                         test_combo_seen2_mse 0.00208
wandb:                                      test_combo_seen2_mse_de 0.02926
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.09671
wandb:                                     test_combo_seen2_pearson 0.90943
wandb:                                  test_combo_seen2_pearson_de 0.02474
wandb:                               test_combo_seen2_pearson_delta 0.0127
wandb:                                                  test_de_mse 0.01848
wandb:                                              test_de_pearson 0.12846
wandb:               test_frac_opposite_direction_top20_non_dropout 0.55877
wandb:                          test_frac_sigma_below_1_non_dropout 0.58149
wandb:                                                     test_mse 0.0014
wandb:                                test_mse_top20_de_non_dropout 0.05607
wandb:                                                 test_pearson 0.93848
wandb:                                           test_pearson_delta 0.05226
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.35714
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.90714
wandb:                                       test_unseen_single_mse 3e-05
wandb:                                    test_unseen_single_mse_de 0.00012
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.0002
wandb:                                   test_unseen_single_pearson 0.99845
wandb:                                test_unseen_single_pearson_de 0.71668
wandb:                             test_unseen_single_pearson_delta 0.21871
wandb:                                                 train_de_mse 0.02008
wandb:                                             train_de_pearson 0.19922
wandb:                                                    train_mse 0.00119
wandb:                                                train_pearson 0.94779
wandb:                                                training_loss 0.15128
wandb:                                                   val_de_mse 0.01432
wandb:                                               val_de_pearson 0.05929
wandb:                                                      val_mse 0.00135
wandb:                                                  val_pearson 0.94105
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_iPSC_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/c5tnk7gr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_123003-c5tnk7gr/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:17
combo_seen1:84
combo_seen2:31
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_124745-gui1tw9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_iPSC_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/gui1tw9v
wandb: WARNING Serializing object of type ndarray that is 8032128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1886
Epoch 1 Step 51 Train Loss: 0.1920
Epoch 1 Step 101 Train Loss: 0.1958
Epoch 1 Step 151 Train Loss: 0.2155
Epoch 1 Step 201 Train Loss: 0.2128
Epoch 1 Step 251 Train Loss: 0.1826
Epoch 1 Step 301 Train Loss: 0.2252
Epoch 1 Step 351 Train Loss: 0.1909
Epoch 1 Step 401 Train Loss: 0.2041
Epoch 1 Step 451 Train Loss: 0.1874
Epoch 1 Step 501 Train Loss: 0.1895
Epoch 1 Step 551 Train Loss: 0.1894
Epoch 1 Step 601 Train Loss: 0.1905
Epoch 1 Step 651 Train Loss: 0.1723
Epoch 1 Step 701 Train Loss: 0.2002
Epoch 1 Step 751 Train Loss: 0.2024
Epoch 1: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.0176. 
Epoch 2 Step 1 Train Loss: 0.1972
Epoch 2 Step 51 Train Loss: 0.2166
Epoch 2 Step 101 Train Loss: 0.1954
Epoch 2 Step 151 Train Loss: 0.2102
Epoch 2 Step 201 Train Loss: 0.1798
Epoch 2 Step 251 Train Loss: 0.1817
Epoch 2 Step 301 Train Loss: 0.1419
Epoch 2 Step 351 Train Loss: 0.1573
Epoch 2 Step 401 Train Loss: 0.1543
Epoch 2 Step 451 Train Loss: 0.1424
Epoch 2 Step 501 Train Loss: 0.1633
Epoch 2 Step 551 Train Loss: 0.1268
Epoch 2 Step 601 Train Loss: 0.1381
Epoch 2 Step 651 Train Loss: 0.1320
Epoch 2 Step 701 Train Loss: 0.1519
Epoch 2 Step 751 Train Loss: 0.1280
Epoch 2: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0136 Validation Top 20 DE MSE: 0.0176. 
Epoch 3 Step 1 Train Loss: 0.1559
Epoch 3 Step 51 Train Loss: 0.1652
Epoch 3 Step 101 Train Loss: 0.1425
Epoch 3 Step 151 Train Loss: 0.1408
Epoch 3 Step 201 Train Loss: 0.1384
Epoch 3 Step 251 Train Loss: 0.1261
Epoch 3 Step 301 Train Loss: 0.1400
Epoch 3 Step 351 Train Loss: 0.1191
Epoch 3 Step 401 Train Loss: 0.1316
Epoch 3 Step 451 Train Loss: 0.1442
Epoch 3 Step 501 Train Loss: 0.1274
Epoch 3 Step 551 Train Loss: 0.1518
Epoch 3 Step 601 Train Loss: 0.1741
Epoch 3 Step 651 Train Loss: 0.1462
Epoch 3 Step 701 Train Loss: 0.1437
Epoch 3 Step 751 Train Loss: 0.1421
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0131 Validation Top 20 DE MSE: 0.0170. 
Epoch 4 Step 1 Train Loss: 0.1336
Epoch 4 Step 51 Train Loss: 0.1619
Epoch 4 Step 101 Train Loss: 0.1613
Epoch 4 Step 151 Train Loss: 0.1295
Epoch 4 Step 201 Train Loss: 0.1438
Epoch 4 Step 251 Train Loss: 0.1408
Epoch 4 Step 301 Train Loss: 0.1373
Epoch 4 Step 351 Train Loss: 0.1474
Epoch 4 Step 401 Train Loss: 0.1423
Epoch 4 Step 451 Train Loss: 0.1226
Epoch 4 Step 501 Train Loss: 0.1390
Epoch 4 Step 551 Train Loss: 0.1439
Epoch 4 Step 601 Train Loss: 0.1375
Epoch 4 Step 651 Train Loss: 0.1462
Epoch 4 Step 701 Train Loss: 0.1444
Epoch 4 Step 751 Train Loss: 0.1474
Epoch 4: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0156 Validation Top 20 DE MSE: 0.0199. 
Epoch 5 Step 1 Train Loss: 0.1371
Epoch 5 Step 51 Train Loss: 0.1430
Epoch 5 Step 101 Train Loss: 0.1391
Epoch 5 Step 151 Train Loss: 0.1477
Epoch 5 Step 201 Train Loss: 0.1493
Epoch 5 Step 251 Train Loss: 0.1672
Epoch 5 Step 301 Train Loss: 0.1875
Epoch 5 Step 351 Train Loss: 0.1477
Epoch 5 Step 401 Train Loss: 0.1410
Epoch 5 Step 451 Train Loss: 0.1277
Epoch 5 Step 501 Train Loss: 0.1456
Epoch 5 Step 551 Train Loss: 0.1512
Epoch 5 Step 601 Train Loss: 0.1461
Epoch 5 Step 651 Train Loss: 0.1576
Epoch 5 Step 701 Train Loss: 0.1704
Epoch 5 Step 751 Train Loss: 0.1609
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0143 Validation Top 20 DE MSE: 0.0186. 
Epoch 6 Step 1 Train Loss: 0.1359
Epoch 6 Step 51 Train Loss: 0.1318
Epoch 6 Step 101 Train Loss: 0.1562
Epoch 6 Step 151 Train Loss: 0.1504
Epoch 6 Step 201 Train Loss: 0.1509
Epoch 6 Step 251 Train Loss: 0.1603
Epoch 6 Step 301 Train Loss: 0.1656
Epoch 6 Step 351 Train Loss: 0.1337
Epoch 6 Step 401 Train Loss: 0.1435
Epoch 6 Step 451 Train Loss: 0.1512
Epoch 6 Step 501 Train Loss: 0.1473
Epoch 6 Step 551 Train Loss: 0.1697
Epoch 6 Step 601 Train Loss: 0.1833
Epoch 6 Step 651 Train Loss: 0.1502
Epoch 6 Step 701 Train Loss: 0.1277
Epoch 6 Step 751 Train Loss: 0.1541
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0150 Validation Top 20 DE MSE: 0.0195. 
Epoch 7 Step 1 Train Loss: 0.1724
Epoch 7 Step 51 Train Loss: 0.1419
Epoch 7 Step 101 Train Loss: 0.1635
Epoch 7 Step 151 Train Loss: 0.1454
Epoch 7 Step 201 Train Loss: 0.1326
Epoch 7 Step 251 Train Loss: 0.1638
Epoch 7 Step 301 Train Loss: 0.1390
Epoch 7 Step 351 Train Loss: 0.1484
Epoch 7 Step 401 Train Loss: 0.1541
Epoch 7 Step 451 Train Loss: 0.1602
Epoch 7 Step 501 Train Loss: 0.1582
Epoch 7 Step 551 Train Loss: 0.1447
Epoch 7 Step 601 Train Loss: 0.1596
Epoch 7 Step 651 Train Loss: 0.1447
Epoch 7 Step 701 Train Loss: 0.1646
Epoch 7 Step 751 Train Loss: 0.1563
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0144 Validation Top 20 DE MSE: 0.0188. 
Epoch 8 Step 1 Train Loss: 0.1599
Epoch 8 Step 51 Train Loss: 0.1743
Epoch 8 Step 101 Train Loss: 0.1437
Epoch 8 Step 151 Train Loss: 0.1957
Epoch 8 Step 201 Train Loss: 0.1490
Epoch 8 Step 251 Train Loss: 0.1640
Epoch 8 Step 301 Train Loss: 0.1430
Epoch 8 Step 351 Train Loss: 0.1600
Epoch 8 Step 401 Train Loss: 0.1533
Epoch 8 Step 451 Train Loss: 0.1593
Epoch 8 Step 501 Train Loss: 0.1462
Epoch 8 Step 551 Train Loss: 0.1704
Epoch 8 Step 601 Train Loss: 0.1601
Epoch 8 Step 651 Train Loss: 0.1511
Epoch 8 Step 701 Train Loss: 0.1455
Epoch 8 Step 751 Train Loss: 0.1433
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0146 Validation Top 20 DE MSE: 0.0190. 
Epoch 9 Step 1 Train Loss: 0.1323
Epoch 9 Step 51 Train Loss: 0.1481
Epoch 9 Step 101 Train Loss: 0.1782
Epoch 9 Step 151 Train Loss: 0.1514
Epoch 9 Step 201 Train Loss: 0.1423
Epoch 9 Step 251 Train Loss: 0.1579
Epoch 9 Step 301 Train Loss: 0.1491
Epoch 9 Step 351 Train Loss: 0.1522
Epoch 9 Step 401 Train Loss: 0.1293
Epoch 9 Step 451 Train Loss: 0.1490
Epoch 9 Step 501 Train Loss: 0.1490
Epoch 9 Step 551 Train Loss: 0.1578
Epoch 9 Step 601 Train Loss: 0.1405
Epoch 9 Step 651 Train Loss: 0.1581
Epoch 9 Step 701 Train Loss: 0.1525
Epoch 9 Step 751 Train Loss: 0.1534
Epoch 9: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0147 Validation Top 20 DE MSE: 0.0191. 
Epoch 10 Step 1 Train Loss: 0.1970
Epoch 10 Step 51 Train Loss: 0.1562
Epoch 10 Step 101 Train Loss: 0.1625
Epoch 10 Step 151 Train Loss: 0.1518
Epoch 10 Step 201 Train Loss: 0.1540
Epoch 10 Step 251 Train Loss: 0.1648
Epoch 10 Step 301 Train Loss: 0.1685
Epoch 10 Step 351 Train Loss: 0.1677
Epoch 10 Step 401 Train Loss: 0.1369
Epoch 10 Step 451 Train Loss: 0.1451
Epoch 10 Step 501 Train Loss: 0.1635
Epoch 10 Step 551 Train Loss: 0.1719
Epoch 10 Step 601 Train Loss: 0.1610
Epoch 10 Step 651 Train Loss: 0.1870
Epoch 10 Step 701 Train Loss: 0.1380
Epoch 10 Step 751 Train Loss: 0.1756
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0146 Validation Top 20 DE MSE: 0.0190. 
Epoch 11 Step 1 Train Loss: 0.1408
Epoch 11 Step 51 Train Loss: 0.1437
Epoch 11 Step 101 Train Loss: 0.1756
Epoch 11 Step 151 Train Loss: 0.1678
Epoch 11 Step 201 Train Loss: 0.2710
Epoch 11 Step 251 Train Loss: 0.1652
Epoch 11 Step 301 Train Loss: 0.1653
Epoch 11 Step 351 Train Loss: 0.1317
Epoch 11 Step 401 Train Loss: 0.1488
Epoch 11 Step 451 Train Loss: 0.1573
Epoch 11 Step 501 Train Loss: 0.1481
Epoch 11 Step 551 Train Loss: 0.1380
Epoch 11 Step 601 Train Loss: 0.1930
Epoch 11 Step 651 Train Loss: 0.1462
Epoch 11 Step 701 Train Loss: 0.1512
Epoch 11 Step 751 Train Loss: 0.1617
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0193. 
Epoch 12 Step 1 Train Loss: 0.1580
Epoch 12 Step 51 Train Loss: 0.1589
Epoch 12 Step 101 Train Loss: 0.1637
Epoch 12 Step 151 Train Loss: 0.1596
Epoch 12 Step 201 Train Loss: 0.1566
Epoch 12 Step 251 Train Loss: 0.1480
Epoch 12 Step 301 Train Loss: 0.1641
Epoch 12 Step 351 Train Loss: 0.1680
Epoch 12 Step 401 Train Loss: 0.1642
Epoch 12 Step 451 Train Loss: 0.1561
Epoch 12 Step 501 Train Loss: 0.1573
Epoch 12 Step 551 Train Loss: 0.1703
Epoch 12 Step 601 Train Loss: 0.1421
Epoch 12 Step 651 Train Loss: 0.1567
Epoch 12 Step 701 Train Loss: 0.1386
Epoch 12 Step 751 Train Loss: 0.1548
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0190. 
Epoch 13 Step 1 Train Loss: 0.1616
Epoch 13 Step 51 Train Loss: 0.1634
Epoch 13 Step 101 Train Loss: 0.1760
Epoch 13 Step 151 Train Loss: 0.1632
Epoch 13 Step 201 Train Loss: 0.1438
Epoch 13 Step 251 Train Loss: 0.1630
Epoch 13 Step 301 Train Loss: 0.1456
Epoch 13 Step 351 Train Loss: 0.1475
Epoch 13 Step 401 Train Loss: 0.1432
Epoch 13 Step 451 Train Loss: 0.1540
Epoch 13 Step 501 Train Loss: 0.1820
Epoch 13 Step 551 Train Loss: 0.1754
Epoch 13 Step 601 Train Loss: 0.1461
Epoch 13 Step 651 Train Loss: 0.1775
Epoch 13 Step 701 Train Loss: 0.1537
Epoch 13 Step 751 Train Loss: 0.1590
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0146 Validation Top 20 DE MSE: 0.0190. 
Epoch 14 Step 1 Train Loss: 0.2008
Epoch 14 Step 51 Train Loss: 0.1805
Epoch 14 Step 101 Train Loss: 0.1409
Epoch 14 Step 151 Train Loss: 0.1298
Epoch 14 Step 201 Train Loss: 0.2038
Epoch 14 Step 251 Train Loss: 0.1715
Epoch 14 Step 301 Train Loss: 0.1635
Epoch 14 Step 351 Train Loss: 0.1404
Epoch 14 Step 401 Train Loss: 0.1748
Epoch 14 Step 451 Train Loss: 0.2176
Epoch 14 Step 501 Train Loss: 0.1458
Epoch 14 Step 551 Train Loss: 0.1497
Epoch 14 Step 601 Train Loss: 0.1768
Epoch 14 Step 651 Train Loss: 0.1532
Epoch 14 Step 701 Train Loss: 0.1468
Epoch 14 Step 751 Train Loss: 0.1590
Epoch 14: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0148 Validation Top 20 DE MSE: 0.0194. 
Epoch 15 Step 1 Train Loss: 0.1405
Epoch 15 Step 51 Train Loss: 0.1307
Epoch 15 Step 101 Train Loss: 0.1567
Epoch 15 Step 151 Train Loss: 0.1670
Epoch 15 Step 201 Train Loss: 0.1602
Epoch 15 Step 251 Train Loss: 0.1474
Epoch 15 Step 301 Train Loss: 0.1651
Epoch 15 Step 351 Train Loss: 0.1698
Epoch 15 Step 401 Train Loss: 0.1730
Epoch 15 Step 451 Train Loss: 0.1509
Epoch 15 Step 501 Train Loss: 0.1427
Epoch 15 Step 551 Train Loss: 0.1557
Epoch 15 Step 601 Train Loss: 0.1482
Epoch 15 Step 651 Train Loss: 0.1438
Epoch 15 Step 701 Train Loss: 0.1491
Epoch 15 Step 751 Train Loss: 0.1377
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0145 Validation Top 20 DE MSE: 0.0190. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0200
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0022202542
test_combo_seen0_pearson: 0.9027075062924412
test_combo_seen0_mse_de: 0.03294717
test_combo_seen0_pearson_de: 0.055775755133356315
test_combo_seen1_mse: 0.0014722913
test_combo_seen1_pearson: 0.9351506995969538
test_combo_seen1_mse_de: 0.020246647
test_combo_seen1_pearson_de: 0.04794139980394794
test_combo_seen2_mse: 0.0013801975
test_combo_seen2_pearson: 0.9394206542029077
test_combo_seen2_mse_de: 0.016544493
test_combo_seen2_pearson_de: 0.11945877808375167
test_unseen_single_mse: 5.6023175e-05
test_unseen_single_pearson: 0.9972886473372208
test_unseen_single_mse_de: 0.00014608141
test_unseen_single_pearson_de: 0.4628344742295722
test_combo_seen0_pearson_delta: 0.004671600373468483
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.4676470588235294
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.6352941176470588
test_combo_seen0_mse_top20_de_non_dropout: 0.08954252
test_combo_seen1_pearson_delta: 0.0024799095094521573
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.5285714285714286
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5946428571428571
test_combo_seen1_mse_top20_de_non_dropout: 0.053792052
test_combo_seen2_pearson_delta: 0.023856042393195883
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5370967741935485
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.5661290322580645
test_combo_seen2_mse_top20_de_non_dropout: 0.058038086
test_unseen_single_pearson_delta: 0.12612420987828543
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4928571428571429
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7999999999999999
test_unseen_single_mse_top20_de_non_dropout: 0.0002433868
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.027 MB uploadedwandb: | 0.004 MB of 0.027 MB uploadedwandb: / 0.004 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÖ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                                   val_de_mse ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb:                                               val_de_pearson ‚ñÇ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÜ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.46765
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.63529
wandb:                                         test_combo_seen0_mse 0.00222
wandb:                                      test_combo_seen0_mse_de 0.03295
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.08954
wandb:                                     test_combo_seen0_pearson 0.90271
wandb:                                  test_combo_seen0_pearson_de 0.05578
wandb:                               test_combo_seen0_pearson_delta 0.00467
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.52857
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.59464
wandb:                                         test_combo_seen1_mse 0.00147
wandb:                                      test_combo_seen1_mse_de 0.02025
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05379
wandb:                                     test_combo_seen1_pearson 0.93515
wandb:                                  test_combo_seen1_pearson_de 0.04794
wandb:                               test_combo_seen1_pearson_delta 0.00248
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.5371
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.56613
wandb:                                         test_combo_seen2_mse 0.00138
wandb:                                      test_combo_seen2_mse_de 0.01654
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.05804
wandb:                                     test_combo_seen2_pearson 0.93942
wandb:                                  test_combo_seen2_pearson_de 0.11946
wandb:                               test_combo_seen2_pearson_delta 0.02386
wandb:                                                  test_de_mse 0.01996
wandb:                                              test_de_pearson 0.08574
wandb:               test_frac_opposite_direction_top20_non_dropout 0.52122
wandb:                          test_frac_sigma_below_1_non_dropout 0.6036
wandb:                                                     test_mse 0.00147
wandb:                                test_mse_top20_de_non_dropout 0.05641
wandb:                                                 test_pearson 0.93526
wandb:                                           test_pearson_delta 0.01374
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.49286
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.8
wandb:                                       test_unseen_single_mse 6e-05
wandb:                                    test_unseen_single_mse_de 0.00015
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00024
wandb:                                   test_unseen_single_pearson 0.99729
wandb:                                test_unseen_single_pearson_de 0.46283
wandb:                             test_unseen_single_pearson_delta 0.12612
wandb:                                                 train_de_mse 0.01451
wandb:                                             train_de_pearson 0.19179
wandb:                                                    train_mse 0.00115
wandb:                                                train_pearson 0.94967
wandb:                                                training_loss 0.13768
wandb:                                                   val_de_mse 0.01897
wandb:                                               val_de_pearson 0.25204
wandb:                                                      val_mse 0.00113
wandb:                                                  val_pearson 0.95028
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_iPSC_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/gui1tw9v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_124745-gui1tw9v/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:17
combo_seen1:90
combo_seen2:29
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_130452-wugbckwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_iPSC_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/wugbckwp
wandb: WARNING Serializing object of type ndarray that is 8032128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1854
Epoch 1 Step 51 Train Loss: 0.2080
Epoch 1 Step 101 Train Loss: 0.2008
Epoch 1 Step 151 Train Loss: 0.2086
Epoch 1 Step 201 Train Loss: 0.1829
Epoch 1 Step 251 Train Loss: 0.1859
Epoch 1 Step 301 Train Loss: 0.1831
Epoch 1 Step 351 Train Loss: 0.1802
Epoch 1 Step 401 Train Loss: 0.1851
Epoch 1 Step 451 Train Loss: 0.1774
Epoch 1 Step 501 Train Loss: 0.1818
Epoch 1 Step 551 Train Loss: 0.1614
Epoch 1 Step 601 Train Loss: 0.2023
Epoch 1 Step 651 Train Loss: 0.1613
Epoch 1 Step 701 Train Loss: 0.1901
Epoch 1 Step 751 Train Loss: 0.1741
Epoch 1 Step 801 Train Loss: 0.1712
Epoch 1 Step 851 Train Loss: 0.1539
Epoch 1 Step 901 Train Loss: 0.1424
Epoch 1: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.0158. 
Epoch 2 Step 1 Train Loss: 0.1478
Epoch 2 Step 51 Train Loss: 0.1659
Epoch 2 Step 101 Train Loss: 0.1511
Epoch 2 Step 151 Train Loss: 0.1442
Epoch 2 Step 201 Train Loss: 0.1635
Epoch 2 Step 251 Train Loss: 0.1403
Epoch 2 Step 301 Train Loss: 0.1524
Epoch 2 Step 351 Train Loss: 0.1695
Epoch 2 Step 401 Train Loss: 0.1480
Epoch 2 Step 451 Train Loss: 0.1417
Epoch 2 Step 501 Train Loss: 0.1637
Epoch 2 Step 551 Train Loss: 0.1618
Epoch 2 Step 601 Train Loss: 0.1313
Epoch 2 Step 651 Train Loss: 0.1336
Epoch 2 Step 701 Train Loss: 0.1316
Epoch 2 Step 751 Train Loss: 0.1352
Epoch 2 Step 801 Train Loss: 0.1376
Epoch 2 Step 851 Train Loss: 0.1393
Epoch 2 Step 901 Train Loss: 0.1129
Epoch 2: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0178 Validation Top 20 DE MSE: 0.0161. 
Epoch 3 Step 1 Train Loss: 0.1338
Epoch 3 Step 51 Train Loss: 0.1333
Epoch 3 Step 101 Train Loss: 0.1306
Epoch 3 Step 151 Train Loss: 0.1860
Epoch 3 Step 201 Train Loss: 0.1344
Epoch 3 Step 251 Train Loss: 0.1498
Epoch 3 Step 301 Train Loss: 0.1395
Epoch 3 Step 351 Train Loss: 0.1252
Epoch 3 Step 401 Train Loss: 0.1416
Epoch 3 Step 451 Train Loss: 0.1276
Epoch 3 Step 501 Train Loss: 0.1439
Epoch 3 Step 551 Train Loss: 0.1268
Epoch 3 Step 601 Train Loss: 0.1351
Epoch 3 Step 651 Train Loss: 0.1315
Epoch 3 Step 701 Train Loss: 0.1471
Epoch 3 Step 751 Train Loss: 0.2262
Epoch 3 Step 801 Train Loss: 0.1305
Epoch 3 Step 851 Train Loss: 0.1354
Epoch 3 Step 901 Train Loss: 0.1336
Epoch 3: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0184 Validation Top 20 DE MSE: 0.0163. 
Epoch 4 Step 1 Train Loss: 0.1896
Epoch 4 Step 51 Train Loss: 0.1800
Epoch 4 Step 101 Train Loss: 0.1271
Epoch 4 Step 151 Train Loss: 0.1365
Epoch 4 Step 201 Train Loss: 0.1244
Epoch 4 Step 251 Train Loss: 0.1214
Epoch 4 Step 301 Train Loss: 0.1273
Epoch 4 Step 351 Train Loss: 0.1283
Epoch 4 Step 401 Train Loss: 0.2261
Epoch 4 Step 451 Train Loss: 0.1237
Epoch 4 Step 501 Train Loss: 0.1274
Epoch 4 Step 551 Train Loss: 0.1752
Epoch 4 Step 601 Train Loss: 0.1235
Epoch 4 Step 651 Train Loss: 0.1286
Epoch 4 Step 701 Train Loss: 0.1256
Epoch 4 Step 751 Train Loss: 0.1284
Epoch 4 Step 801 Train Loss: 0.1300
Epoch 4 Step 851 Train Loss: 0.1349
Epoch 4 Step 901 Train Loss: 0.1266
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.0158. 
Epoch 5 Step 1 Train Loss: 0.1871
Epoch 5 Step 51 Train Loss: 0.1297
Epoch 5 Step 101 Train Loss: 0.1333
Epoch 5 Step 151 Train Loss: 0.1291
Epoch 5 Step 201 Train Loss: 0.1353
Epoch 5 Step 251 Train Loss: 0.1834
Epoch 5 Step 301 Train Loss: 0.1290
Epoch 5 Step 351 Train Loss: 0.1512
Epoch 5 Step 401 Train Loss: 0.1316
Epoch 5 Step 451 Train Loss: 0.1266
Epoch 5 Step 501 Train Loss: 0.1439
Epoch 5 Step 551 Train Loss: 0.1277
Epoch 5 Step 601 Train Loss: 0.1278
Epoch 5 Step 651 Train Loss: 0.1268
Epoch 5 Step 701 Train Loss: 0.1312
Epoch 5 Step 751 Train Loss: 0.1394
Epoch 5 Step 801 Train Loss: 0.1261
Epoch 5 Step 851 Train Loss: 0.1268
Epoch 5 Step 901 Train Loss: 0.1273
Epoch 5: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 6 Step 1 Train Loss: 0.1395
Epoch 6 Step 51 Train Loss: 0.1262
Epoch 6 Step 101 Train Loss: 0.1297
Epoch 6 Step 151 Train Loss: 0.1276
Epoch 6 Step 201 Train Loss: 0.1295
Epoch 6 Step 251 Train Loss: 0.1274
Epoch 6 Step 301 Train Loss: 0.1258
Epoch 6 Step 351 Train Loss: 0.1306
Epoch 6 Step 401 Train Loss: 0.1791
Epoch 6 Step 451 Train Loss: 0.1287
Epoch 6 Step 501 Train Loss: 0.1236
Epoch 6 Step 551 Train Loss: 0.1243
Epoch 6 Step 601 Train Loss: 0.1545
Epoch 6 Step 651 Train Loss: 0.1270
Epoch 6 Step 701 Train Loss: 0.1273
Epoch 6 Step 751 Train Loss: 0.1272
Epoch 6 Step 801 Train Loss: 0.1274
Epoch 6 Step 851 Train Loss: 0.1298
Epoch 6 Step 901 Train Loss: 0.1371
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 7 Step 1 Train Loss: 0.1353
Epoch 7 Step 51 Train Loss: 0.1606
Epoch 7 Step 101 Train Loss: 0.1318
Epoch 7 Step 151 Train Loss: 0.1360
Epoch 7 Step 201 Train Loss: 0.1278
Epoch 7 Step 251 Train Loss: 0.1668
Epoch 7 Step 301 Train Loss: 0.1264
Epoch 7 Step 351 Train Loss: 0.1377
Epoch 7 Step 401 Train Loss: 0.1282
Epoch 7 Step 451 Train Loss: 0.1279
Epoch 7 Step 501 Train Loss: 0.1336
Epoch 7 Step 551 Train Loss: 0.1285
Epoch 7 Step 601 Train Loss: 0.1374
Epoch 7 Step 651 Train Loss: 0.1408
Epoch 7 Step 701 Train Loss: 0.1272
Epoch 7 Step 751 Train Loss: 0.1312
Epoch 7 Step 801 Train Loss: 0.1565
Epoch 7 Step 851 Train Loss: 0.1281
Epoch 7 Step 901 Train Loss: 0.1275
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 8 Step 1 Train Loss: 0.1420
Epoch 8 Step 51 Train Loss: 0.1315
Epoch 8 Step 101 Train Loss: 0.1414
Epoch 8 Step 151 Train Loss: 0.1342
Epoch 8 Step 201 Train Loss: 0.1292
Epoch 8 Step 251 Train Loss: 0.1337
Epoch 8 Step 301 Train Loss: 0.1344
Epoch 8 Step 351 Train Loss: 0.1392
Epoch 8 Step 401 Train Loss: 0.1391
Epoch 8 Step 451 Train Loss: 0.1292
Epoch 8 Step 501 Train Loss: 0.1309
Epoch 8 Step 551 Train Loss: 0.1278
Epoch 8 Step 601 Train Loss: 0.1291
Epoch 8 Step 651 Train Loss: 0.1528
Epoch 8 Step 701 Train Loss: 0.1265
Epoch 8 Step 751 Train Loss: 0.1293
Epoch 8 Step 801 Train Loss: 0.1304
Epoch 8 Step 851 Train Loss: 0.1548
Epoch 8 Step 901 Train Loss: 0.1400
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 9 Step 1 Train Loss: 0.1299
Epoch 9 Step 51 Train Loss: 0.1405
Epoch 9 Step 101 Train Loss: 0.1361
Epoch 9 Step 151 Train Loss: 0.1317
Epoch 9 Step 201 Train Loss: 0.1439
Epoch 9 Step 251 Train Loss: 0.1472
Epoch 9 Step 301 Train Loss: 0.1277
Epoch 9 Step 351 Train Loss: 0.1298
Epoch 9 Step 401 Train Loss: 0.1538
Epoch 9 Step 451 Train Loss: 0.1349
Epoch 9 Step 501 Train Loss: 0.1399
Epoch 9 Step 551 Train Loss: 0.1288
Epoch 9 Step 601 Train Loss: 0.1264
Epoch 9 Step 651 Train Loss: 0.1544
Epoch 9 Step 701 Train Loss: 0.1433
Epoch 9 Step 751 Train Loss: 0.1569
Epoch 9 Step 801 Train Loss: 0.1315
Epoch 9 Step 851 Train Loss: 0.1284
Epoch 9 Step 901 Train Loss: 0.1355
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 10 Step 1 Train Loss: 0.1280
Epoch 10 Step 51 Train Loss: 0.1273
Epoch 10 Step 101 Train Loss: 0.1295
Epoch 10 Step 151 Train Loss: 0.1290
Epoch 10 Step 201 Train Loss: 0.1305
Epoch 10 Step 251 Train Loss: 0.1245
Epoch 10 Step 301 Train Loss: 0.1319
Epoch 10 Step 351 Train Loss: 0.1343
Epoch 10 Step 401 Train Loss: 0.1301
Epoch 10 Step 451 Train Loss: 0.1261
Epoch 10 Step 501 Train Loss: 0.1271
Epoch 10 Step 551 Train Loss: 0.1311
Epoch 10 Step 601 Train Loss: 0.1396
Epoch 10 Step 651 Train Loss: 0.1563
Epoch 10 Step 701 Train Loss: 0.1262
Epoch 10 Step 751 Train Loss: 0.1368
Epoch 10 Step 801 Train Loss: 0.2069
Epoch 10 Step 851 Train Loss: 0.1231
Epoch 10 Step 901 Train Loss: 0.1246
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 11 Step 1 Train Loss: 0.1673
Epoch 11 Step 51 Train Loss: 0.1240
Epoch 11 Step 101 Train Loss: 0.1379
Epoch 11 Step 151 Train Loss: 0.1222
Epoch 11 Step 201 Train Loss: 0.1297
Epoch 11 Step 251 Train Loss: 0.1276
Epoch 11 Step 301 Train Loss: 0.1487
Epoch 11 Step 351 Train Loss: 0.1628
Epoch 11 Step 401 Train Loss: 0.1303
Epoch 11 Step 451 Train Loss: 0.1337
Epoch 11 Step 501 Train Loss: 0.1282
Epoch 11 Step 551 Train Loss: 0.1351
Epoch 11 Step 601 Train Loss: 0.1263
Epoch 11 Step 651 Train Loss: 0.1248
Epoch 11 Step 701 Train Loss: 0.1277
Epoch 11 Step 751 Train Loss: 0.1323
Epoch 11 Step 801 Train Loss: 0.1258
Epoch 11 Step 851 Train Loss: 0.1513
Epoch 11 Step 901 Train Loss: 0.1345
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 12 Step 1 Train Loss: 0.1361
Epoch 12 Step 51 Train Loss: 0.1345
Epoch 12 Step 101 Train Loss: 0.1278
Epoch 12 Step 151 Train Loss: 0.1422
Epoch 12 Step 201 Train Loss: 0.1272
Epoch 12 Step 251 Train Loss: 0.1529
Epoch 12 Step 301 Train Loss: 0.1302
Epoch 12 Step 351 Train Loss: 0.1292
Epoch 12 Step 401 Train Loss: 0.1328
Epoch 12 Step 451 Train Loss: 0.1523
Epoch 12 Step 501 Train Loss: 0.1306
Epoch 12 Step 551 Train Loss: 0.1277
Epoch 12 Step 601 Train Loss: 0.1310
Epoch 12 Step 651 Train Loss: 0.1358
Epoch 12 Step 701 Train Loss: 0.1333
Epoch 12 Step 751 Train Loss: 0.1299
Epoch 12 Step 801 Train Loss: 0.1359
Epoch 12 Step 851 Train Loss: 0.1549
Epoch 12 Step 901 Train Loss: 0.1342
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 13 Step 1 Train Loss: 0.1296
Epoch 13 Step 51 Train Loss: 0.1275
Epoch 13 Step 101 Train Loss: 0.1355
Epoch 13 Step 151 Train Loss: 0.1353
Epoch 13 Step 201 Train Loss: 0.1294
Epoch 13 Step 251 Train Loss: 0.1282
Epoch 13 Step 301 Train Loss: 0.1288
Epoch 13 Step 351 Train Loss: 0.1320
Epoch 13 Step 401 Train Loss: 0.2908
Epoch 13 Step 451 Train Loss: 0.1580
Epoch 13 Step 501 Train Loss: 0.1287
Epoch 13 Step 551 Train Loss: 0.1326
Epoch 13 Step 601 Train Loss: 0.1269
Epoch 13 Step 651 Train Loss: 0.1470
Epoch 13 Step 701 Train Loss: 0.1287
Epoch 13 Step 751 Train Loss: 0.1277
Epoch 13 Step 801 Train Loss: 0.1302
Epoch 13 Step 851 Train Loss: 0.1310
Epoch 13 Step 901 Train Loss: 0.1419
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 14 Step 1 Train Loss: 0.1329
Epoch 14 Step 51 Train Loss: 0.1312
Epoch 14 Step 101 Train Loss: 0.1269
Epoch 14 Step 151 Train Loss: 0.1319
Epoch 14 Step 201 Train Loss: 0.1309
Epoch 14 Step 251 Train Loss: 0.2112
Epoch 14 Step 301 Train Loss: 0.1381
Epoch 14 Step 351 Train Loss: 0.1713
Epoch 14 Step 401 Train Loss: 0.1290
Epoch 14 Step 451 Train Loss: 0.1328
Epoch 14 Step 501 Train Loss: 0.1284
Epoch 14 Step 551 Train Loss: 0.1526
Epoch 14 Step 601 Train Loss: 0.1335
Epoch 14 Step 651 Train Loss: 0.1307
Epoch 14 Step 701 Train Loss: 0.1232
Epoch 14 Step 751 Train Loss: 0.1247
Epoch 14 Step 801 Train Loss: 0.1446
Epoch 14 Step 851 Train Loss: 0.1381
Epoch 14 Step 901 Train Loss: 0.1844
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Epoch 15 Step 1 Train Loss: 0.1320
Epoch 15 Step 51 Train Loss: 0.1279
Epoch 15 Step 101 Train Loss: 0.1318
Epoch 15 Step 151 Train Loss: 0.2280
Epoch 15 Step 201 Train Loss: 0.1449
Epoch 15 Step 251 Train Loss: 0.1508
Epoch 15 Step 301 Train Loss: 0.1448
Epoch 15 Step 351 Train Loss: 0.1266
Epoch 15 Step 401 Train Loss: 0.1242
Epoch 15 Step 451 Train Loss: 0.1279
Epoch 15 Step 501 Train Loss: 0.1445
Epoch 15 Step 551 Train Loss: 0.1463
Epoch 15 Step 601 Train Loss: 0.1524
Epoch 15 Step 651 Train Loss: 0.1281
Epoch 15 Step 701 Train Loss: 0.1351
Epoch 15 Step 751 Train Loss: 0.1573
Epoch 15 Step 801 Train Loss: 0.1349
Epoch 15 Step 851 Train Loss: 0.3834
Epoch 15 Step 901 Train Loss: 0.1357
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.0159. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0173
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0020505586
test_combo_seen0_pearson: 0.9108078129297736
test_combo_seen0_mse_de: 0.025952497
test_combo_seen0_pearson_de: 0.0380167153151338
test_combo_seen1_mse: 0.0015124773
test_combo_seen1_pearson: 0.9331352862602011
test_combo_seen1_mse_de: 0.016144268
test_combo_seen1_pearson_de: -0.014968431462957149
test_combo_seen2_mse: 0.0016942734
test_combo_seen2_pearson: 0.9243311593591642
test_combo_seen2_mse_de: 0.019837582
test_combo_seen2_pearson_de: 0.018324995008493165
test_unseen_single_mse: 0.00026836852
test_unseen_single_pearson: 0.9868833547393782
test_unseen_single_mse_de: 0.00055939396
test_unseen_single_pearson_de: 0.3837472906896901
test_combo_seen0_pearson_delta: -0.0009288456743584648
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.4764705882352942
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.5911764705882352
test_combo_seen0_mse_top20_de_non_dropout: 0.074852906
test_combo_seen1_pearson_delta: -0.01669269541473538
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.4938888888888888
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.611111111111111
test_combo_seen1_mse_top20_de_non_dropout: 0.054842923
test_combo_seen2_pearson_delta: -0.013599595530496339
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5189655172413794
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.5948275862068966
test_combo_seen2_mse_top20_de_non_dropout: 0.06610139
test_unseen_single_pearson_delta: 0.029634277826013914
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.40714285714285714
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7714285714285715
test_unseen_single_mse_top20_de_non_dropout: 0.0005362269
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.004 MB of 0.028 MB uploadedwandb: / 0.004 MB of 0.028 MB uploadedwandb: - 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ
wandb:                                                   val_de_mse ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.47647
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.59118
wandb:                                         test_combo_seen0_mse 0.00205
wandb:                                      test_combo_seen0_mse_de 0.02595
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.07485
wandb:                                     test_combo_seen0_pearson 0.91081
wandb:                                  test_combo_seen0_pearson_de 0.03802
wandb:                               test_combo_seen0_pearson_delta -0.00093
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.49389
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.61111
wandb:                                         test_combo_seen1_mse 0.00151
wandb:                                      test_combo_seen1_mse_de 0.01614
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05484
wandb:                                     test_combo_seen1_pearson 0.93314
wandb:                                  test_combo_seen1_pearson_de -0.01497
wandb:                               test_combo_seen1_pearson_delta -0.01669
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.51897
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.59483
wandb:                                         test_combo_seen2_mse 0.00169
wandb:                                      test_combo_seen2_mse_de 0.01984
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.0661
wandb:                                     test_combo_seen2_pearson 0.92433
wandb:                                  test_combo_seen2_pearson_de 0.01832
wandb:                               test_combo_seen2_pearson_delta -0.0136
wandb:                                                  test_de_mse 0.0173
wandb:                                              test_de_pearson 0.0176
wandb:               test_frac_opposite_direction_top20_non_dropout 0.49266
wandb:                          test_frac_sigma_below_1_non_dropout 0.61329
wandb:                                                     test_mse 0.00155
wandb:                                test_mse_top20_de_non_dropout 0.05685
wandb:                                                 test_pearson 0.93133
wandb:                                           test_pearson_delta -0.01192
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.40714
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.77143
wandb:                                       test_unseen_single_mse 0.00027
wandb:                                    test_unseen_single_mse_de 0.00056
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00054
wandb:                                   test_unseen_single_pearson 0.98688
wandb:                                test_unseen_single_pearson_de 0.38375
wandb:                             test_unseen_single_pearson_delta 0.02963
wandb:                                                 train_de_mse 0.01773
wandb:                                             train_de_pearson 0.22497
wandb:                                                    train_mse 0.00114
wandb:                                                train_pearson 0.94952
wandb:                                                training_loss 0.12389
wandb:                                                   val_de_mse 0.01592
wandb:                                               val_de_pearson 0.19033
wandb:                                                      val_mse 0.00124
wandb:                                                  val_pearson 0.94535
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_iPSC_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/wugbckwp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_130452-wugbckwp/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:19
combo_seen1:92
combo_seen2:28
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_132343-5jd5wc1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_iPSC_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/5jd5wc1q
wandb: WARNING Serializing object of type ndarray that is 8032128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1929
Epoch 1 Step 51 Train Loss: 0.1772
Epoch 1 Step 101 Train Loss: 0.1788
Epoch 1 Step 151 Train Loss: 0.1780
Epoch 1 Step 201 Train Loss: 0.1970
Epoch 1 Step 251 Train Loss: 0.1717
Epoch 1 Step 301 Train Loss: 0.1938
Epoch 1 Step 351 Train Loss: 0.1761
Epoch 1 Step 401 Train Loss: 0.1728
Epoch 1 Step 451 Train Loss: 0.1828
Epoch 1 Step 501 Train Loss: 0.1622
Epoch 1 Step 551 Train Loss: 0.1644
Epoch 1 Step 601 Train Loss: 0.1745
Epoch 1 Step 651 Train Loss: 0.1603
Epoch 1 Step 701 Train Loss: 0.1623
Epoch 1 Step 751 Train Loss: 0.1656
Epoch 1 Step 801 Train Loss: 0.1671
Epoch 1 Step 851 Train Loss: 0.1454
Epoch 1 Step 901 Train Loss: 0.1514
Epoch 1 Step 951 Train Loss: 0.1550
Epoch 1 Step 1001 Train Loss: 0.1612
Epoch 1: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0257. 
Epoch 2 Step 1 Train Loss: 0.1353
Epoch 2 Step 51 Train Loss: 0.1578
Epoch 2 Step 101 Train Loss: 0.1469
Epoch 2 Step 151 Train Loss: 0.1532
Epoch 2 Step 201 Train Loss: 0.1388
Epoch 2 Step 251 Train Loss: 0.1279
Epoch 2 Step 301 Train Loss: 0.1370
Epoch 2 Step 351 Train Loss: 0.1205
Epoch 2 Step 401 Train Loss: 0.1288
Epoch 2 Step 451 Train Loss: 0.1257
Epoch 2 Step 501 Train Loss: 0.1137
Epoch 2 Step 551 Train Loss: 0.1254
Epoch 2 Step 601 Train Loss: 0.1258
Epoch 2 Step 651 Train Loss: 0.1233
Epoch 2 Step 701 Train Loss: 0.1235
Epoch 2 Step 751 Train Loss: 0.1227
Epoch 2 Step 801 Train Loss: 0.1208
Epoch 2 Step 851 Train Loss: 0.1182
Epoch 2 Step 901 Train Loss: 0.1377
Epoch 2 Step 951 Train Loss: 0.1200
Epoch 2 Step 1001 Train Loss: 0.1484
Epoch 2: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0257. 
Epoch 3 Step 1 Train Loss: 0.1251
Epoch 3 Step 51 Train Loss: 0.1388
Epoch 3 Step 101 Train Loss: 0.1145
Epoch 3 Step 151 Train Loss: 0.1233
Epoch 3 Step 201 Train Loss: 0.1350
Epoch 3 Step 251 Train Loss: 0.1395
Epoch 3 Step 301 Train Loss: 0.1187
Epoch 3 Step 351 Train Loss: 0.1400
Epoch 3 Step 401 Train Loss: 0.1185
Epoch 3 Step 451 Train Loss: 0.1161
Epoch 3 Step 501 Train Loss: 0.1149
Epoch 3 Step 551 Train Loss: 0.1144
Epoch 3 Step 601 Train Loss: 0.1196
Epoch 3 Step 651 Train Loss: 0.1250
Epoch 3 Step 701 Train Loss: 0.1194
Epoch 3 Step 751 Train Loss: 0.1187
Epoch 3 Step 801 Train Loss: 0.1267
Epoch 3 Step 851 Train Loss: 0.1188
Epoch 3 Step 901 Train Loss: 0.1241
Epoch 3 Step 951 Train Loss: 0.1203
Epoch 3 Step 1001 Train Loss: 0.1198
Epoch 3: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 4 Step 1 Train Loss: 0.1228
Epoch 4 Step 51 Train Loss: 0.1138
Epoch 4 Step 101 Train Loss: 0.1426
Epoch 4 Step 151 Train Loss: 0.1275
Epoch 4 Step 201 Train Loss: 0.1276
Epoch 4 Step 251 Train Loss: 0.1287
Epoch 4 Step 301 Train Loss: 0.1408
Epoch 4 Step 351 Train Loss: 0.1265
Epoch 4 Step 401 Train Loss: 0.1254
Epoch 4 Step 451 Train Loss: 0.1452
Epoch 4 Step 501 Train Loss: 0.1218
Epoch 4 Step 551 Train Loss: 0.1240
Epoch 4 Step 601 Train Loss: 0.1295
Epoch 4 Step 651 Train Loss: 0.1389
Epoch 4 Step 701 Train Loss: 0.1318
Epoch 4 Step 751 Train Loss: 0.1283
Epoch 4 Step 801 Train Loss: 0.1135
Epoch 4 Step 851 Train Loss: 0.1137
Epoch 4 Step 901 Train Loss: 0.1298
Epoch 4 Step 951 Train Loss: 0.1265
Epoch 4 Step 1001 Train Loss: 0.1264
Epoch 4: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 5 Step 1 Train Loss: 0.1211
Epoch 5 Step 51 Train Loss: 0.1353
Epoch 5 Step 101 Train Loss: 0.1247
Epoch 5 Step 151 Train Loss: 0.1203
Epoch 5 Step 201 Train Loss: 0.1584
Epoch 5 Step 251 Train Loss: 0.1217
Epoch 5 Step 301 Train Loss: 0.1208
Epoch 5 Step 351 Train Loss: 0.1529
Epoch 5 Step 401 Train Loss: 0.1260
Epoch 5 Step 451 Train Loss: 0.1242
Epoch 5 Step 501 Train Loss: 0.1236
Epoch 5 Step 551 Train Loss: 0.1289
Epoch 5 Step 601 Train Loss: 0.1208
Epoch 5 Step 651 Train Loss: 0.1851
Epoch 5 Step 701 Train Loss: 0.1201
Epoch 5 Step 751 Train Loss: 0.1229
Epoch 5 Step 801 Train Loss: 0.1274
Epoch 5 Step 851 Train Loss: 0.1274
Epoch 5 Step 901 Train Loss: 0.1251
Epoch 5 Step 951 Train Loss: 0.4509
Epoch 5 Step 1001 Train Loss: 0.1266
Epoch 5: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 6 Step 1 Train Loss: 0.1257
Epoch 6 Step 51 Train Loss: 0.1216
Epoch 6 Step 101 Train Loss: 0.1394
Epoch 6 Step 151 Train Loss: 0.1244
Epoch 6 Step 201 Train Loss: 0.1167
Epoch 6 Step 251 Train Loss: 0.1190
Epoch 6 Step 301 Train Loss: 0.1371
Epoch 6 Step 351 Train Loss: 0.1179
Epoch 6 Step 401 Train Loss: 0.1263
Epoch 6 Step 451 Train Loss: 0.1135
Epoch 6 Step 501 Train Loss: 0.1243
Epoch 6 Step 551 Train Loss: 0.1327
Epoch 6 Step 601 Train Loss: 0.1186
Epoch 6 Step 651 Train Loss: 0.1281
Epoch 6 Step 701 Train Loss: 0.1195
Epoch 6 Step 751 Train Loss: 0.1608
Epoch 6 Step 801 Train Loss: 0.1183
Epoch 6 Step 851 Train Loss: 0.1341
Epoch 6 Step 901 Train Loss: 0.1194
Epoch 6 Step 951 Train Loss: 0.1501
Epoch 6 Step 1001 Train Loss: 0.1454
Epoch 6: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 7 Step 1 Train Loss: 0.1179
Epoch 7 Step 51 Train Loss: 0.1254
Epoch 7 Step 101 Train Loss: 0.1147
Epoch 7 Step 151 Train Loss: 0.1179
Epoch 7 Step 201 Train Loss: 0.1302
Epoch 7 Step 251 Train Loss: 0.1296
Epoch 7 Step 301 Train Loss: 0.1449
Epoch 7 Step 351 Train Loss: 0.1261
Epoch 7 Step 401 Train Loss: 0.1391
Epoch 7 Step 451 Train Loss: 0.1182
Epoch 7 Step 501 Train Loss: 0.1194
Epoch 7 Step 551 Train Loss: 0.1187
Epoch 7 Step 601 Train Loss: 0.1860
Epoch 7 Step 651 Train Loss: 0.1190
Epoch 7 Step 701 Train Loss: 0.1280
Epoch 7 Step 751 Train Loss: 0.1281
Epoch 7 Step 801 Train Loss: 0.1187
Epoch 7 Step 851 Train Loss: 0.1206
Epoch 7 Step 901 Train Loss: 0.1324
Epoch 7 Step 951 Train Loss: 0.1246
Epoch 7 Step 1001 Train Loss: 0.1279
Epoch 7: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 8 Step 1 Train Loss: 0.1224
Epoch 8 Step 51 Train Loss: 0.1175
Epoch 8 Step 101 Train Loss: 0.1340
Epoch 8 Step 151 Train Loss: 0.1152
Epoch 8 Step 201 Train Loss: 0.1392
Epoch 8 Step 251 Train Loss: 0.1151
Epoch 8 Step 301 Train Loss: 0.1198
Epoch 8 Step 351 Train Loss: 0.1241
Epoch 8 Step 401 Train Loss: 0.1218
Epoch 8 Step 451 Train Loss: 0.1298
Epoch 8 Step 501 Train Loss: 0.1216
Epoch 8 Step 551 Train Loss: 0.1275
Epoch 8 Step 601 Train Loss: 0.1191
Epoch 8 Step 651 Train Loss: 0.1193
Epoch 8 Step 701 Train Loss: 0.1288
Epoch 8 Step 751 Train Loss: 0.1223
Epoch 8 Step 801 Train Loss: 0.1261
Epoch 8 Step 851 Train Loss: 0.1176
Epoch 8 Step 901 Train Loss: 0.1164
Epoch 8 Step 951 Train Loss: 0.1424
Epoch 8 Step 1001 Train Loss: 0.1838
Epoch 8: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 9 Step 1 Train Loss: 0.1230
Epoch 9 Step 51 Train Loss: 0.1396
Epoch 9 Step 101 Train Loss: 0.1178
Epoch 9 Step 151 Train Loss: 0.1216
Epoch 9 Step 201 Train Loss: 0.1147
Epoch 9 Step 251 Train Loss: 0.1329
Epoch 9 Step 301 Train Loss: 0.1386
Epoch 9 Step 351 Train Loss: 0.1364
Epoch 9 Step 401 Train Loss: 0.1225
Epoch 9 Step 451 Train Loss: 0.1175
Epoch 9 Step 501 Train Loss: 0.1203
Epoch 9 Step 551 Train Loss: 0.1199
Epoch 9 Step 601 Train Loss: 0.1221
Epoch 9 Step 651 Train Loss: 0.1422
Epoch 9 Step 701 Train Loss: 0.1149
Epoch 9 Step 751 Train Loss: 0.1237
Epoch 9 Step 801 Train Loss: 0.1144
Epoch 9 Step 851 Train Loss: 0.1169
Epoch 9 Step 901 Train Loss: 0.1153
Epoch 9 Step 951 Train Loss: 0.1135
Epoch 9 Step 1001 Train Loss: 0.1383
Epoch 9: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 10 Step 1 Train Loss: 0.1378
Epoch 10 Step 51 Train Loss: 0.1175
Epoch 10 Step 101 Train Loss: 0.1261
Epoch 10 Step 151 Train Loss: 0.1236
Epoch 10 Step 201 Train Loss: 0.1342
Epoch 10 Step 251 Train Loss: 0.1193
Epoch 10 Step 301 Train Loss: 0.1142
Epoch 10 Step 351 Train Loss: 0.1251
Epoch 10 Step 401 Train Loss: 0.1153
Epoch 10 Step 451 Train Loss: 0.1197
Epoch 10 Step 501 Train Loss: 0.1142
Epoch 10 Step 551 Train Loss: 0.1366
Epoch 10 Step 601 Train Loss: 0.1386
Epoch 10 Step 651 Train Loss: 0.1283
Epoch 10 Step 701 Train Loss: 0.1188
Epoch 10 Step 751 Train Loss: 0.1129
Epoch 10 Step 801 Train Loss: 0.1193
Epoch 10 Step 851 Train Loss: 0.1222
Epoch 10 Step 901 Train Loss: 0.1223
Epoch 10 Step 951 Train Loss: 0.1170
Epoch 10 Step 1001 Train Loss: 0.1205
Epoch 10: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 11 Step 1 Train Loss: 0.1262
Epoch 11 Step 51 Train Loss: 0.1198
Epoch 11 Step 101 Train Loss: 0.1163
Epoch 11 Step 151 Train Loss: 0.1201
Epoch 11 Step 201 Train Loss: 0.1187
Epoch 11 Step 251 Train Loss: 0.1221
Epoch 11 Step 301 Train Loss: 0.1223
Epoch 11 Step 351 Train Loss: 0.1203
Epoch 11 Step 401 Train Loss: 0.1190
Epoch 11 Step 451 Train Loss: 0.1160
Epoch 11 Step 501 Train Loss: 0.1315
Epoch 11 Step 551 Train Loss: 0.1174
Epoch 11 Step 601 Train Loss: 0.1178
Epoch 11 Step 651 Train Loss: 0.1165
Epoch 11 Step 701 Train Loss: 0.1254
Epoch 11 Step 751 Train Loss: 0.1141
Epoch 11 Step 801 Train Loss: 0.1193
Epoch 11 Step 851 Train Loss: 0.1178
Epoch 11 Step 901 Train Loss: 0.1172
Epoch 11 Step 951 Train Loss: 0.1128
Epoch 11 Step 1001 Train Loss: 0.1237
Epoch 11: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 12 Step 1 Train Loss: 0.1171
Epoch 12 Step 51 Train Loss: 0.1221
Epoch 12 Step 101 Train Loss: 0.1224
Epoch 12 Step 151 Train Loss: 0.1178
Epoch 12 Step 201 Train Loss: 0.1223
Epoch 12 Step 251 Train Loss: 0.1125
Epoch 12 Step 301 Train Loss: 0.1292
Epoch 12 Step 351 Train Loss: 0.1179
Epoch 12 Step 401 Train Loss: 0.1174
Epoch 12 Step 451 Train Loss: 0.1221
Epoch 12 Step 501 Train Loss: 0.1204
Epoch 12 Step 551 Train Loss: 0.1263
Epoch 12 Step 601 Train Loss: 0.1238
Epoch 12 Step 651 Train Loss: 0.1168
Epoch 12 Step 701 Train Loss: 0.1207
Epoch 12 Step 751 Train Loss: 0.1146
Epoch 12 Step 801 Train Loss: 0.1157
Epoch 12 Step 851 Train Loss: 0.1165
Epoch 12 Step 901 Train Loss: 0.1203
Epoch 12 Step 951 Train Loss: 0.1295
Epoch 12 Step 1001 Train Loss: 0.1162
Epoch 12: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 13 Step 1 Train Loss: 0.1129
Epoch 13 Step 51 Train Loss: 0.1206
Epoch 13 Step 101 Train Loss: 0.1227
Epoch 13 Step 151 Train Loss: 0.1193
Epoch 13 Step 201 Train Loss: 0.1175
Epoch 13 Step 251 Train Loss: 0.1313
Epoch 13 Step 301 Train Loss: 0.1217
Epoch 13 Step 351 Train Loss: 0.1357
Epoch 13 Step 401 Train Loss: 0.1172
Epoch 13 Step 451 Train Loss: 0.1201
Epoch 13 Step 501 Train Loss: 0.1144
Epoch 13 Step 551 Train Loss: 0.1298
Epoch 13 Step 601 Train Loss: 0.1637
Epoch 13 Step 651 Train Loss: 0.1401
Epoch 13 Step 701 Train Loss: 0.1471
Epoch 13 Step 751 Train Loss: 0.1396
Epoch 13 Step 801 Train Loss: 0.1346
Epoch 13 Step 851 Train Loss: 0.1144
Epoch 13 Step 901 Train Loss: 0.1381
Epoch 13 Step 951 Train Loss: 0.1335
Epoch 13 Step 1001 Train Loss: 0.1255
Epoch 13: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 14 Step 1 Train Loss: 0.1154
Epoch 14 Step 51 Train Loss: 0.1188
Epoch 14 Step 101 Train Loss: 0.1501
Epoch 14 Step 151 Train Loss: 0.1437
Epoch 14 Step 201 Train Loss: 0.1202
Epoch 14 Step 251 Train Loss: 0.1668
Epoch 14 Step 301 Train Loss: 0.1153
Epoch 14 Step 351 Train Loss: 0.1203
Epoch 14 Step 401 Train Loss: 0.1315
Epoch 14 Step 451 Train Loss: 0.1366
Epoch 14 Step 501 Train Loss: 0.1365
Epoch 14 Step 551 Train Loss: 0.1560
Epoch 14 Step 601 Train Loss: 0.1170
Epoch 14 Step 651 Train Loss: 0.1215
Epoch 14 Step 701 Train Loss: 0.1172
Epoch 14 Step 751 Train Loss: 0.1159
Epoch 14 Step 801 Train Loss: 0.1217
Epoch 14 Step 851 Train Loss: 0.1152
Epoch 14 Step 901 Train Loss: 0.1312
Epoch 14 Step 951 Train Loss: 0.1200
Epoch 14 Step 1001 Train Loss: 0.1135
Epoch 14: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Epoch 15 Step 1 Train Loss: 0.1160
Epoch 15 Step 51 Train Loss: 0.1228
Epoch 15 Step 101 Train Loss: 0.1183
Epoch 15 Step 151 Train Loss: 0.1220
Epoch 15 Step 201 Train Loss: 0.1163
Epoch 15 Step 251 Train Loss: 0.1202
Epoch 15 Step 301 Train Loss: 0.1122
Epoch 15 Step 351 Train Loss: 0.1361
Epoch 15 Step 401 Train Loss: 0.1141
Epoch 15 Step 451 Train Loss: 0.1202
Epoch 15 Step 501 Train Loss: 0.1371
Epoch 15 Step 551 Train Loss: 0.1185
Epoch 15 Step 601 Train Loss: 0.1213
Epoch 15 Step 651 Train Loss: 0.1290
Epoch 15 Step 701 Train Loss: 0.1430
Epoch 15 Step 751 Train Loss: 0.1186
Epoch 15 Step 801 Train Loss: 0.1178
Epoch 15 Step 851 Train Loss: 0.1262
Epoch 15 Step 901 Train Loss: 0.1177
Epoch 15 Step 951 Train Loss: 0.1350
Epoch 15 Step 1001 Train Loss: 0.1178
Epoch 15: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0261. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0184
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.001805721
test_combo_seen0_pearson: 0.9190939977850271
test_combo_seen0_mse_de: 0.02220389
test_combo_seen0_pearson_de: 0.03813981833363841
test_combo_seen1_mse: 0.0014031028
test_combo_seen1_pearson: 0.9375254658890798
test_combo_seen1_mse_de: 0.01872584
test_combo_seen1_pearson_de: 0.10511944668900361
test_combo_seen2_mse: 0.0014345924
test_combo_seen2_pearson: 0.935838854931821
test_combo_seen2_mse_de: 0.019306688
test_combo_seen2_pearson_de: 0.09499469787044552
test_unseen_single_mse: 8.5003594e-05
test_unseen_single_pearson: 0.9958672109240456
test_unseen_single_mse_de: 0.0004651715
test_unseen_single_pearson_de: 0.6011986056512949
test_combo_seen0_pearson_delta: 0.007097669877431317
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.5078947368421053
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.6368421052631579
test_combo_seen0_mse_top20_de_non_dropout: 0.086249776
test_combo_seen1_pearson_delta: 0.015464526443420131
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.4728260869565217
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.6130434782608696
test_combo_seen1_mse_top20_de_non_dropout: 0.05488915
test_combo_seen2_pearson_delta: 0.017398116431489516
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5214285714285715
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.6839285714285713
test_combo_seen2_mse_top20_de_non_dropout: 0.062334765
test_unseen_single_pearson_delta: 0.11711799762658437
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.37857142857142856
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9000000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.0003500694
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.029 MB uploadedwandb: | 0.015 MB of 0.029 MB uploadedwandb: / 0.015 MB of 0.029 MB uploadedwandb: - 0.029 MB of 0.029 MB uploadedwandb: \ 0.029 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÇ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                             train_de_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                   val_de_mse ‚ñÅ‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                               val_de_pearson ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.50789
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.63684
wandb:                                         test_combo_seen0_mse 0.00181
wandb:                                      test_combo_seen0_mse_de 0.0222
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.08625
wandb:                                     test_combo_seen0_pearson 0.91909
wandb:                                  test_combo_seen0_pearson_de 0.03814
wandb:                               test_combo_seen0_pearson_delta 0.0071
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.47283
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.61304
wandb:                                         test_combo_seen1_mse 0.0014
wandb:                                      test_combo_seen1_mse_de 0.01873
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.05489
wandb:                                     test_combo_seen1_pearson 0.93753
wandb:                                  test_combo_seen1_pearson_de 0.10512
wandb:                               test_combo_seen1_pearson_delta 0.01546
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.52143
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.68393
wandb:                                         test_combo_seen2_mse 0.00143
wandb:                                      test_combo_seen2_mse_de 0.01931
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.06233
wandb:                                     test_combo_seen2_pearson 0.93584
wandb:                                  test_combo_seen2_pearson_de 0.09499
wandb:                               test_combo_seen2_pearson_delta 0.0174
wandb:                                                  test_de_mse 0.01841
wandb:                                              test_de_pearson 0.11825
wandb:               test_frac_opposite_direction_top20_non_dropout 0.48219
wandb:                          test_frac_sigma_below_1_non_dropout 0.64349
wandb:                                                     test_mse 0.0014
wandb:                                test_mse_top20_de_non_dropout 0.05778
wandb:                                                 test_pearson 0.9376
wandb:                                           test_pearson_delta 0.01962
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.37857
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.9
wandb:                                       test_unseen_single_mse 9e-05
wandb:                                    test_unseen_single_mse_de 0.00047
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00035
wandb:                                   test_unseen_single_pearson 0.99587
wandb:                                test_unseen_single_pearson_de 0.6012
wandb:                             test_unseen_single_pearson_delta 0.11712
wandb:                                                 train_de_mse 0.01194
wandb:                                             train_de_pearson 0.22852
wandb:                                                    train_mse 0.00092
wandb:                                                train_pearson 0.95938
wandb:                                                training_loss 0.12765
wandb:                                                   val_de_mse 0.02608
wandb:                                               val_de_pearson 0.07738
wandb:                                                      val_mse 0.00168
wandb:                                                  val_pearson 0.92628
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_iPSC_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/5jd5wc1q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_132343-5jd5wc1q/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:12
combo_seen1:91
combo_seen2:30
unseen_single:7
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_134432-8bejganw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_TianKampmann2019_iPSC_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/8bejganw
wandb: WARNING Serializing object of type ndarray that is 8032128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.1932
Epoch 1 Step 51 Train Loss: 0.1926
Epoch 1 Step 101 Train Loss: 0.2377
Epoch 1 Step 151 Train Loss: 0.1848
Epoch 1 Step 201 Train Loss: 0.1953
Epoch 1 Step 251 Train Loss: 0.2477
Epoch 1 Step 301 Train Loss: 0.1854
Epoch 1 Step 351 Train Loss: 0.1808
Epoch 1 Step 401 Train Loss: 0.1826
Epoch 1 Step 451 Train Loss: 0.1815
Epoch 1 Step 501 Train Loss: 0.1766
Epoch 1 Step 551 Train Loss: 0.1655
Epoch 1 Step 601 Train Loss: 0.1720
Epoch 1 Step 651 Train Loss: 0.1639
Epoch 1 Step 701 Train Loss: 0.1656
Epoch 1 Step 751 Train Loss: 0.1656
Epoch 1 Step 801 Train Loss: 0.1896
Epoch 1 Step 851 Train Loss: 0.1626
Epoch 1: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0138 Validation Top 20 DE MSE: 0.0372. 
Epoch 2 Step 1 Train Loss: 0.1755
Epoch 2 Step 51 Train Loss: 0.1768
Epoch 2 Step 101 Train Loss: 0.1408
Epoch 2 Step 151 Train Loss: 0.1246
Epoch 2 Step 201 Train Loss: 0.1397
Epoch 2 Step 251 Train Loss: 0.1830
Epoch 2 Step 301 Train Loss: 0.1458
Epoch 2 Step 351 Train Loss: 0.1609
Epoch 2 Step 401 Train Loss: 0.1574
Epoch 2 Step 451 Train Loss: 0.1652
Epoch 2 Step 501 Train Loss: 0.1453
Epoch 2 Step 551 Train Loss: 0.1390
Epoch 2 Step 601 Train Loss: 0.1341
Epoch 2 Step 651 Train Loss: 0.1417
Epoch 2 Step 701 Train Loss: 0.1509
Epoch 2 Step 751 Train Loss: 0.1431
Epoch 2 Step 801 Train Loss: 0.1137
Epoch 2 Step 851 Train Loss: 0.1696
Epoch 2: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0277. 
Epoch 3 Step 1 Train Loss: 0.1442
Epoch 3 Step 51 Train Loss: 0.1090
Epoch 3 Step 101 Train Loss: 0.1390
Epoch 3 Step 151 Train Loss: 0.1215
Epoch 3 Step 201 Train Loss: 0.1645
Epoch 3 Step 251 Train Loss: 0.1430
Epoch 3 Step 301 Train Loss: 0.1609
Epoch 3 Step 351 Train Loss: 0.1423
Epoch 3 Step 401 Train Loss: 0.1350
Epoch 3 Step 451 Train Loss: 0.1451
Epoch 3 Step 501 Train Loss: 0.1449
Epoch 3 Step 551 Train Loss: 0.1501
Epoch 3 Step 601 Train Loss: 0.1304
Epoch 3 Step 651 Train Loss: 0.1363
Epoch 3 Step 701 Train Loss: 0.1294
Epoch 3 Step 751 Train Loss: 0.1493
Epoch 3 Step 801 Train Loss: 0.1375
Epoch 3 Step 851 Train Loss: 0.2404
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0020. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0336. 
Epoch 4 Step 1 Train Loss: 0.1574
Epoch 4 Step 51 Train Loss: 0.1228
Epoch 4 Step 101 Train Loss: 0.1534
Epoch 4 Step 151 Train Loss: 0.1283
Epoch 4 Step 201 Train Loss: 0.1324
Epoch 4 Step 251 Train Loss: 0.2222
Epoch 4 Step 301 Train Loss: 0.1451
Epoch 4 Step 351 Train Loss: 0.1433
Epoch 4 Step 401 Train Loss: 0.1418
Epoch 4 Step 451 Train Loss: 0.1445
Epoch 4 Step 501 Train Loss: 0.1434
Epoch 4 Step 551 Train Loss: 0.1545
Epoch 4 Step 601 Train Loss: 0.1477
Epoch 4 Step 651 Train Loss: 0.1534
Epoch 4 Step 701 Train Loss: 0.1364
Epoch 4 Step 751 Train Loss: 0.1404
Epoch 4 Step 801 Train Loss: 0.1585
Epoch 4 Step 851 Train Loss: 0.1396
Epoch 4: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0285. 
Epoch 5 Step 1 Train Loss: 0.1575
Epoch 5 Step 51 Train Loss: 0.1440
Epoch 5 Step 101 Train Loss: 0.1639
Epoch 5 Step 151 Train Loss: 0.1525
Epoch 5 Step 201 Train Loss: 0.1546
Epoch 5 Step 251 Train Loss: 0.1473
Epoch 5 Step 301 Train Loss: 0.1512
Epoch 5 Step 351 Train Loss: 0.1385
Epoch 5 Step 401 Train Loss: 0.1486
Epoch 5 Step 451 Train Loss: 0.1649
Epoch 5 Step 501 Train Loss: 0.1512
Epoch 5 Step 551 Train Loss: 0.1495
Epoch 5 Step 601 Train Loss: 0.1335
Epoch 5 Step 651 Train Loss: 0.1438
Epoch 5 Step 701 Train Loss: 0.1554
Epoch 5 Step 751 Train Loss: 0.1602
Epoch 5 Step 801 Train Loss: 0.1720
Epoch 5 Step 851 Train Loss: 0.1547
Epoch 5: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0295. 
Epoch 6 Step 1 Train Loss: 0.1485
Epoch 6 Step 51 Train Loss: 0.1407
Epoch 6 Step 101 Train Loss: 0.1586
Epoch 6 Step 151 Train Loss: 0.1522
Epoch 6 Step 201 Train Loss: 0.1423
Epoch 6 Step 251 Train Loss: 0.1660
Epoch 6 Step 301 Train Loss: 0.1517
Epoch 6 Step 351 Train Loss: 0.1424
Epoch 6 Step 401 Train Loss: 0.1439
Epoch 6 Step 451 Train Loss: 0.1514
Epoch 6 Step 501 Train Loss: 0.1432
Epoch 6 Step 551 Train Loss: 0.1600
Epoch 6 Step 601 Train Loss: 0.1468
Epoch 6 Step 651 Train Loss: 0.1538
Epoch 6 Step 701 Train Loss: 0.1732
Epoch 6 Step 751 Train Loss: 0.1573
Epoch 6 Step 801 Train Loss: 0.1555
Epoch 6 Step 851 Train Loss: 0.1456
Epoch 6: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0292. 
Epoch 7 Step 1 Train Loss: 0.1446
Epoch 7 Step 51 Train Loss: 0.1511
Epoch 7 Step 101 Train Loss: 0.1741
Epoch 7 Step 151 Train Loss: 0.1416
Epoch 7 Step 201 Train Loss: 0.1429
Epoch 7 Step 251 Train Loss: 0.1506
Epoch 7 Step 301 Train Loss: 0.1475
Epoch 7 Step 351 Train Loss: 0.1565
Epoch 7 Step 401 Train Loss: 0.1784
Epoch 7 Step 451 Train Loss: 0.1453
Epoch 7 Step 501 Train Loss: 0.1429
Epoch 7 Step 551 Train Loss: 0.1734
Epoch 7 Step 601 Train Loss: 0.1594
Epoch 7 Step 651 Train Loss: 0.1470
Epoch 7 Step 701 Train Loss: 0.1406
Epoch 7 Step 751 Train Loss: 0.1727
Epoch 7 Step 801 Train Loss: 0.1510
Epoch 7 Step 851 Train Loss: 0.2541
Epoch 7: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0293. 
Epoch 8 Step 1 Train Loss: 0.1715
Epoch 8 Step 51 Train Loss: 0.1460
Epoch 8 Step 101 Train Loss: 0.1488
Epoch 8 Step 151 Train Loss: 0.1556
Epoch 8 Step 201 Train Loss: 0.1404
Epoch 8 Step 251 Train Loss: 0.1537
Epoch 8 Step 301 Train Loss: 0.1667
Epoch 8 Step 351 Train Loss: 0.1499
Epoch 8 Step 401 Train Loss: 0.1516
Epoch 8 Step 451 Train Loss: 0.1506
Epoch 8 Step 501 Train Loss: 0.1417
Epoch 8 Step 551 Train Loss: 0.1457
Epoch 8 Step 601 Train Loss: 0.1487
Epoch 8 Step 651 Train Loss: 0.1469
Epoch 8 Step 701 Train Loss: 0.2009
Epoch 8 Step 751 Train Loss: 0.1710
Epoch 8 Step 801 Train Loss: 0.1507
Epoch 8 Step 851 Train Loss: 0.1618
Epoch 8: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0292. 
Epoch 9 Step 1 Train Loss: 0.1452
Epoch 9 Step 51 Train Loss: 0.1421
Epoch 9 Step 101 Train Loss: 0.1561
Epoch 9 Step 151 Train Loss: 0.1478
Epoch 9 Step 201 Train Loss: 0.1597
Epoch 9 Step 251 Train Loss: 0.1615
Epoch 9 Step 301 Train Loss: 0.1434
Epoch 9 Step 351 Train Loss: 0.1440
Epoch 9 Step 401 Train Loss: 0.1461
Epoch 9 Step 451 Train Loss: 0.1414
Epoch 9 Step 501 Train Loss: 0.1625
Epoch 9 Step 551 Train Loss: 0.1401
Epoch 9 Step 601 Train Loss: 0.1429
Epoch 9 Step 651 Train Loss: 0.1488
Epoch 9 Step 701 Train Loss: 0.1445
Epoch 9 Step 751 Train Loss: 0.1445
Epoch 9 Step 801 Train Loss: 0.1477
Epoch 9 Step 851 Train Loss: 0.1577
Epoch 9: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0292. 
Epoch 10 Step 1 Train Loss: 0.1461
Epoch 10 Step 51 Train Loss: 0.1615
Epoch 10 Step 101 Train Loss: 0.1425
Epoch 10 Step 151 Train Loss: 0.1502
Epoch 10 Step 201 Train Loss: 0.1399
Epoch 10 Step 251 Train Loss: 0.1625
Epoch 10 Step 301 Train Loss: 0.1631
Epoch 10 Step 351 Train Loss: 0.1833
Epoch 10 Step 401 Train Loss: 0.1495
Epoch 10 Step 451 Train Loss: 0.1411
Epoch 10 Step 501 Train Loss: 0.1426
Epoch 10 Step 551 Train Loss: 0.1482
Epoch 10 Step 601 Train Loss: 0.1471
Epoch 10 Step 651 Train Loss: 0.1503
Epoch 10 Step 701 Train Loss: 0.1559
Epoch 10 Step 751 Train Loss: 0.1476
Epoch 10 Step 801 Train Loss: 0.1509
Epoch 10 Step 851 Train Loss: 0.1370
Epoch 10: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0289. 
Epoch 11 Step 1 Train Loss: 0.1424
Epoch 11 Step 51 Train Loss: 0.1499
Epoch 11 Step 101 Train Loss: 0.1506
Epoch 11 Step 151 Train Loss: 0.1505
Epoch 11 Step 201 Train Loss: 0.1475
Epoch 11 Step 251 Train Loss: 0.1461
Epoch 11 Step 301 Train Loss: 0.1474
Epoch 11 Step 351 Train Loss: 0.1562
Epoch 11 Step 401 Train Loss: 0.1512
Epoch 11 Step 451 Train Loss: 0.1473
Epoch 11 Step 501 Train Loss: 0.1651
Epoch 11 Step 551 Train Loss: 0.1610
Epoch 11 Step 601 Train Loss: 0.1451
Epoch 11 Step 651 Train Loss: 0.1499
Epoch 11 Step 701 Train Loss: 0.1436
Epoch 11 Step 751 Train Loss: 0.1668
Epoch 11 Step 801 Train Loss: 0.1472
Epoch 11 Step 851 Train Loss: 0.1491
Epoch 11: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0289. 
Epoch 12 Step 1 Train Loss: 0.1645
Epoch 12 Step 51 Train Loss: 0.1404
Epoch 12 Step 101 Train Loss: 0.1526
Epoch 12 Step 151 Train Loss: 0.1419
Epoch 12 Step 201 Train Loss: 0.1642
Epoch 12 Step 251 Train Loss: 0.1466
Epoch 12 Step 301 Train Loss: 0.1432
Epoch 12 Step 351 Train Loss: 0.1423
Epoch 12 Step 401 Train Loss: 0.1528
Epoch 12 Step 451 Train Loss: 0.1470
Epoch 12 Step 501 Train Loss: 0.1433
Epoch 12 Step 551 Train Loss: 0.1451
Epoch 12 Step 601 Train Loss: 0.1494
Epoch 12 Step 651 Train Loss: 0.1517
Epoch 12 Step 701 Train Loss: 0.1717
Epoch 12 Step 751 Train Loss: 0.1520
Epoch 12 Step 801 Train Loss: 0.1503
Epoch 12 Step 851 Train Loss: 0.1484
Epoch 12: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0289. 
Epoch 13 Step 1 Train Loss: 0.1887
Epoch 13 Step 51 Train Loss: 0.1458
Epoch 13 Step 101 Train Loss: 0.1431
Epoch 13 Step 151 Train Loss: 0.1422
Epoch 13 Step 201 Train Loss: 0.1468
Epoch 13 Step 251 Train Loss: 0.1378
Epoch 13 Step 301 Train Loss: 0.1609
Epoch 13 Step 351 Train Loss: 0.1475
Epoch 13 Step 401 Train Loss: 0.1632
Epoch 13 Step 451 Train Loss: 0.1446
Epoch 13 Step 501 Train Loss: 0.1543
Epoch 13 Step 551 Train Loss: 0.1477
Epoch 13 Step 601 Train Loss: 0.1557
Epoch 13 Step 651 Train Loss: 0.1437
Epoch 13 Step 701 Train Loss: 0.1706
Epoch 13 Step 751 Train Loss: 0.1411
Epoch 13 Step 801 Train Loss: 0.1428
Epoch 13 Step 851 Train Loss: 0.2614
Epoch 13: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0290. 
Epoch 14 Step 1 Train Loss: 0.1506
Epoch 14 Step 51 Train Loss: 0.1772
Epoch 14 Step 101 Train Loss: 0.1460
Epoch 14 Step 151 Train Loss: 0.1421
Epoch 14 Step 201 Train Loss: 0.1439
Epoch 14 Step 251 Train Loss: 0.1579
Epoch 14 Step 301 Train Loss: 0.1999
Epoch 14 Step 351 Train Loss: 0.1594
Epoch 14 Step 401 Train Loss: 0.1676
Epoch 14 Step 451 Train Loss: 0.1554
Epoch 14 Step 501 Train Loss: 0.1495
Epoch 14 Step 551 Train Loss: 0.1387
Epoch 14 Step 601 Train Loss: 0.1421
Epoch 14 Step 651 Train Loss: 0.1454
Epoch 14 Step 701 Train Loss: 0.1486
Epoch 14 Step 751 Train Loss: 0.1402
Epoch 14 Step 801 Train Loss: 0.1527
Epoch 14 Step 851 Train Loss: 0.1550
Epoch 14: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0289. 
Epoch 15 Step 1 Train Loss: 0.1599
Epoch 15 Step 51 Train Loss: 0.1468
Epoch 15 Step 101 Train Loss: 0.1416
Epoch 15 Step 151 Train Loss: 0.1443
Epoch 15 Step 201 Train Loss: 0.1454
Epoch 15 Step 251 Train Loss: 0.1543
Epoch 15 Step 301 Train Loss: 0.1527
Epoch 15 Step 351 Train Loss: 0.1419
Epoch 15 Step 401 Train Loss: 0.1599
Epoch 15 Step 451 Train Loss: 0.1510
Epoch 15 Step 501 Train Loss: 0.1481
Epoch 15 Step 551 Train Loss: 0.1501
Epoch 15 Step 601 Train Loss: 0.1465
Epoch 15 Step 651 Train Loss: 0.1410
Epoch 15 Step 701 Train Loss: 0.1486
Epoch 15 Step 751 Train Loss: 0.1517
Epoch 15 Step 801 Train Loss: 0.1422
Epoch 15 Step 851 Train Loss: 0.1437
Epoch 15: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0290. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0211
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 0.0011246445
test_combo_seen0_pearson: 0.9478672383353284
test_combo_seen0_mse_de: 0.012259672
test_combo_seen0_pearson_de: 0.025983116904131385
test_combo_seen1_mse: 0.0018305423
test_combo_seen1_pearson: 0.9202778375129803
test_combo_seen1_mse_de: 0.022432825
test_combo_seen1_pearson_de: 0.08961321066824252
test_combo_seen2_mse: 0.0016101607
test_combo_seen2_pearson: 0.9290415043290097
test_combo_seen2_mse_de: 0.025445117
test_combo_seen2_pearson_de: 0.11187745374888443
test_unseen_single_mse: 7.7917066e-05
test_unseen_single_pearson: 0.996136585936372
test_unseen_single_mse_de: 0.00015753077
test_unseen_single_pearson_de: 0.3982799025420631
test_combo_seen0_pearson_delta: 0.04151514406906636
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.4875
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.6
test_combo_seen0_mse_top20_de_non_dropout: 0.028076282
test_combo_seen1_pearson_delta: 0.018859764687218696
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.528021978021978
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.5527472527472527
test_combo_seen1_mse_top20_de_non_dropout: 0.07084021
test_combo_seen2_pearson_delta: 0.0055945178793674255
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.5449999999999999
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.515
test_combo_seen2_mse_top20_de_non_dropout: 0.06096727
test_unseen_single_pearson_delta: 0.05353594249432562
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.33571428571428574
test_unseen_single_frac_sigma_below_1_non_dropout: 0.85
test_unseen_single_mse_top20_de_non_dropout: 0.0003429802
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.028 MB uploadedwandb: | 0.004 MB of 0.028 MB uploadedwandb: / 0.028 MB of 0.028 MB uploadedwandb: - 0.028 MB of 0.028 MB uploadedwandb: \ 0.028 MB of 0.028 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.4875
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.6
wandb:                                         test_combo_seen0_mse 0.00112
wandb:                                      test_combo_seen0_mse_de 0.01226
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 0.02808
wandb:                                     test_combo_seen0_pearson 0.94787
wandb:                                  test_combo_seen0_pearson_de 0.02598
wandb:                               test_combo_seen0_pearson_delta 0.04152
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.52802
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.55275
wandb:                                         test_combo_seen1_mse 0.00183
wandb:                                      test_combo_seen1_mse_de 0.02243
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.07084
wandb:                                     test_combo_seen1_pearson 0.92028
wandb:                                  test_combo_seen1_pearson_de 0.08961
wandb:                               test_combo_seen1_pearson_delta 0.01886
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.545
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.515
wandb:                                         test_combo_seen2_mse 0.00161
wandb:                                      test_combo_seen2_mse_de 0.02545
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.06097
wandb:                                     test_combo_seen2_pearson 0.92904
wandb:                                  test_combo_seen2_pearson_de 0.11188
wandb:                               test_combo_seen2_pearson_delta 0.00559
wandb:                                                  test_de_mse 0.02109
wandb:                                              test_de_pearson 0.10436
wandb:               test_frac_opposite_direction_top20_non_dropout 0.51857
wandb:                          test_frac_sigma_below_1_non_dropout 0.56357
wandb:                                                     test_mse 0.00164
wandb:                                test_mse_top20_de_non_dropout 0.06153
wandb:                                                 test_pearson 0.92831
wandb:                                           test_pearson_delta 0.01969
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.33571
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.85
wandb:                                       test_unseen_single_mse 8e-05
wandb:                                    test_unseen_single_mse_de 0.00016
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00034
wandb:                                   test_unseen_single_pearson 0.99614
wandb:                                test_unseen_single_pearson_de 0.39828
wandb:                             test_unseen_single_pearson_delta 0.05354
wandb:                                                 train_de_mse 0.00973
wandb:                                             train_de_pearson 0.18904
wandb:                                                    train_mse 0.00082
wandb:                                                train_pearson 0.96268
wandb:                                                training_loss 0.15617
wandb:                                                   val_de_mse 0.02897
wandb:                                               val_de_pearson 0.09933
wandb:                                                      val_mse 0.00166
wandb:                                                  val_pearson 0.92759
wandb: 
wandb: üöÄ View run scbert_TianKampmann2019_iPSC_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/8bejganw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_134432-8bejganw/logs
