Loading compilers/gcc/12.2.0
  ERROR: Module cannot be loaded due to a conflict.
    HINT: Might try "module unload compilers/gcc" first.
cmake-3.27.0 loaded successful
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240923_005054-r5tbipmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_DatlingerBock2017_stimulated_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/r5tbipmb
wandb: WARNING Serializing object of type ndarray that is 20553856 bytes
  0%|                                                                 | 0/3118 [00:00<?, ?it/s]  0%|                                                         | 1/3118 [00:00<13:40,  3.80it/s]  0%|‚ñè                                                       | 12/3118 [00:00<01:22, 37.59it/s]  1%|‚ñé                                                       | 18/3118 [00:00<01:17, 40.19it/s]  1%|‚ñã                                                       | 37/3118 [00:00<00:37, 82.12it/s]  2%|‚ñâ                                                       | 50/3118 [00:00<00:32, 94.29it/s]  2%|‚ñà                                                       | 61/3118 [00:00<00:31, 98.29it/s]  2%|‚ñà‚ñé                                                     | 73/3118 [00:00<00:29, 103.49it/s]  3%|‚ñà‚ñç                                                     | 85/3118 [00:01<00:28, 106.51it/s]  3%|‚ñà‚ñã                                                     | 97/3118 [00:01<00:27, 108.35it/s]  3%|‚ñà‚ñâ                                                    | 109/3118 [00:01<00:27, 109.03it/s]  4%|‚ñà‚ñà                                                    | 121/3118 [00:01<00:28, 105.98it/s]  4%|‚ñà‚ñà‚ñé                                                   | 135/3118 [00:01<00:26, 113.37it/s]  5%|‚ñà‚ñà‚ñå                                                   | 147/3118 [00:01<00:26, 113.68it/s]  5%|‚ñà‚ñà‚ñä                                                   | 159/3118 [00:01<00:26, 113.34it/s]  5%|‚ñà‚ñà‚ñâ                                                   | 171/3118 [00:01<00:26, 111.12it/s]  6%|‚ñà‚ñà‚ñà‚ñè                                                  | 184/3118 [00:01<00:25, 114.13it/s]  6%|‚ñà‚ñà‚ñà‚ñç                                                  | 196/3118 [00:02<00:25, 115.05it/s]  7%|‚ñà‚ñà‚ñà‚ñå                                                  | 208/3118 [00:02<00:25, 114.09it/s]  7%|‚ñà‚ñà‚ñà‚ñä                                                  | 220/3118 [00:02<00:25, 114.95it/s]  7%|‚ñà‚ñà‚ñà‚ñà                                                  | 232/3118 [00:02<00:25, 114.35it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 244/3118 [00:02<00:25, 112.29it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 256/3118 [00:02<00:25, 112.78it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 268/3118 [00:02<00:24, 114.83it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 280/3118 [00:02<00:24, 114.65it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 292/3118 [00:02<00:24, 114.59it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 304/3118 [00:02<00:24, 113.92it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 316/3118 [00:03<00:24, 113.60it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 328/3118 [00:03<00:24, 113.26it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 340/3118 [00:03<00:24, 113.50it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 352/3118 [00:03<00:24, 113.77it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 364/3118 [00:03<00:24, 114.04it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 376/3118 [00:03<00:24, 113.35it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 388/3118 [00:03<00:24, 111.22it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 401/3118 [00:03<00:24, 111.72it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 414/3118 [00:03<00:23, 114.97it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 426/3118 [00:04<00:24, 112.08it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 439/3118 [00:04<00:23, 114.89it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 451/3118 [00:04<00:23, 114.48it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 463/3118 [00:04<00:23, 112.28it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 476/3118 [00:04<00:22, 115.10it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 488/3118 [00:04<00:23, 114.11it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 500/3118 [00:04<00:22, 114.33it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 512/3118 [00:04<00:22, 114.11it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 524/3118 [00:04<00:22, 114.17it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 536/3118 [00:05<00:23, 111.25it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 548/3118 [00:05<00:22, 112.00it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 560/3118 [00:05<00:23, 108.91it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 572/3118 [00:05<00:23, 107.73it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 584/3118 [00:05<00:22, 110.87it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 596/3118 [00:05<00:22, 111.87it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                           | 608/3118 [00:05<00:22, 109.38it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 621/3118 [00:05<00:22, 110.56it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 634/3118 [00:05<00:21, 114.03it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 646/3118 [00:06<00:21, 114.57it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 658/3118 [00:06<00:21, 113.98it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 670/3118 [00:06<00:21, 111.30it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 683/3118 [00:06<00:21, 115.20it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 695/3118 [00:06<00:21, 114.05it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 707/3118 [00:06<00:21, 114.20it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 719/3118 [00:06<00:21, 113.59it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 731/3118 [00:06<00:20, 113.94it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 743/3118 [00:06<00:20, 113.59it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 755/3118 [00:06<00:20, 113.81it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 767/3118 [00:07<00:21, 110.70it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 779/3118 [00:07<00:21, 111.03it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 792/3118 [00:07<00:20, 114.46it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 804/3118 [00:07<00:20, 113.92it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 816/3118 [00:07<00:20, 111.35it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 829/3118 [00:07<00:20, 113.83it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 841/3118 [00:07<00:20, 113.60it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 853/3118 [00:07<00:20, 113.17it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 865/3118 [00:07<00:20, 112.60it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 877/3118 [00:08<00:19, 112.50it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 889/3118 [00:08<00:20, 108.04it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 901/3118 [00:08<00:20, 108.79it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 914/3118 [00:08<00:20, 109.85it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 926/3118 [00:08<00:19, 110.82it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 938/3118 [00:08<00:19, 112.96it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 950/3118 [00:08<00:19, 112.25it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 962/3118 [00:08<00:19, 112.23it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 974/3118 [00:08<00:18, 113.14it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 986/3118 [00:09<00:19, 110.26it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 998/3118 [00:09<00:19, 110.65it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1011/3118 [00:09<00:18, 113.83it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1023/3118 [00:09<00:18, 113.85it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 1035/3118 [00:09<00:18, 113.78it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1047/3118 [00:09<00:18, 110.71it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 1060/3118 [00:09<00:18, 113.80it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 1072/3118 [00:09<00:18, 110.27it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 1084/3118 [00:09<00:18, 110.83it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 1097/3118 [00:10<00:17, 113.93it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 1109/3118 [00:10<00:17, 111.89it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 1121/3118 [00:10<00:17, 111.79it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 1133/3118 [00:10<00:17, 110.50it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 1145/3118 [00:10<00:17, 110.82it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 1157/3118 [00:10<00:17, 110.54it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 1169/3118 [00:10<00:17, 110.81it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 1181/3118 [00:10<00:17, 110.07it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 1193/3118 [00:10<00:17, 109.70it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 1204/3118 [00:11<00:17, 106.68it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 1216/3118 [00:11<00:17, 109.34it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 1227/3118 [00:11<00:17, 109.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 1238/3118 [00:11<00:17, 106.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1251/3118 [00:11<00:17, 107.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1263/3118 [00:11<00:17, 108.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1274/3118 [00:11<00:16, 108.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1285/3118 [00:11<00:17, 104.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1297/3118 [00:11<00:17, 106.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1308/3118 [00:11<00:17, 102.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1319/3118 [00:12<00:17, 103.17it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1331/3118 [00:12<00:16, 106.95it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1342/3118 [00:12<00:17, 101.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1353/3118 [00:12<00:17, 103.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1364/3118 [00:12<00:17, 101.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1375/3118 [00:12<00:17, 99.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1386/3118 [00:12<00:17, 99.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1397/3118 [00:13<00:37, 46.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1409/3118 [00:13<00:32, 52.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1417/3118 [00:13<00:35, 47.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1433/3118 [00:13<00:25, 65.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1446/3118 [00:13<00:22, 75.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1488/3118 [00:14<00:11, 146.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1507/3118 [00:14<00:12, 128.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1524/3118 [00:14<00:13, 116.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1539/3118 [00:14<00:13, 113.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1553/3118 [00:14<00:14, 108.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1566/3118 [00:14<00:14, 106.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1578/3118 [00:15<00:17, 87.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1589/3118 [00:15<00:16, 90.62it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1600/3118 [00:15<00:16, 94.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1611/3118 [00:15<00:15, 97.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1622/3118 [00:15<00:15, 95.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1632/3118 [00:15<00:15, 95.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1642/3118 [00:15<00:15, 94.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1653/3118 [00:15<00:15, 96.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1664/3118 [00:15<00:14, 99.81it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1675/3118 [00:15<00:14, 101.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1686/3118 [00:16<00:18, 77.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1702/3118 [00:16<00:15, 91.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1716/3118 [00:16<00:13, 100.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 1727/3118 [00:16<00:15, 88.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 1737/3118 [00:16<00:16, 81.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1746/3118 [00:16<00:17, 77.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 1758/3118 [00:17<00:18, 74.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 1770/3118 [00:17<00:17, 78.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 1779/3118 [00:17<00:19, 67.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 1787/3118 [00:17<00:19, 68.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 1803/3118 [00:17<00:17, 74.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 1811/3118 [00:17<00:18, 72.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 1822/3118 [00:17<00:17, 73.23it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 1838/3118 [00:18<00:13, 91.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 1848/3118 [00:18<00:13, 91.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 1860/3118 [00:18<00:12, 97.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 1871/3118 [00:18<00:13, 94.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 1882/3118 [00:18<00:13, 94.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 1894/3118 [00:18<00:12, 98.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 1905/3118 [00:18<00:12, 97.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 1915/3118 [00:18<00:12, 93.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 1925/3118 [00:18<00:13, 91.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 1936/3118 [00:19<00:12, 94.56it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 1947/3118 [00:19<00:12, 96.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 1957/3118 [00:19<00:13, 85.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 1970/3118 [00:19<00:12, 95.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 1982/3118 [00:19<00:11, 97.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 1993/3118 [00:19<00:11, 96.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2004/3118 [00:19<00:11, 100.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2016/3118 [00:19<00:10, 104.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2027/3118 [00:19<00:10, 104.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2038/3118 [00:20<00:10, 103.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2051/3118 [00:20<00:18, 57.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2063/3118 [00:20<00:16, 64.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2072/3118 [00:20<00:19, 53.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2140/3118 [00:21<00:06, 159.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2165/3118 [00:21<00:06, 147.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2186/3118 [00:21<00:06, 140.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2205/3118 [00:21<00:06, 138.68it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2222/3118 [00:21<00:06, 133.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2238/3118 [00:21<00:06, 132.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2253/3118 [00:21<00:06, 128.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2267/3118 [00:22<00:06, 129.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2281/3118 [00:22<00:06, 127.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2295/3118 [00:22<00:06, 123.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 2309/3118 [00:22<00:06, 123.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2322/3118 [00:22<00:06, 123.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 2336/3118 [00:22<00:06, 125.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2349/3118 [00:22<00:06, 122.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2362/3118 [00:22<00:06, 122.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2375/3118 [00:22<00:06, 123.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 2388/3118 [00:23<00:05, 125.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 2401/3118 [00:23<00:05, 124.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 2414/3118 [00:23<00:05, 122.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 2427/3118 [00:23<00:05, 121.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 2440/3118 [00:23<00:05, 119.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 2453/3118 [00:23<00:05, 117.05it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 2466/3118 [00:23<00:05, 118.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2478/3118 [00:23<00:05, 108.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 2497/3118 [00:23<00:04, 129.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 2511/3118 [00:24<00:04, 125.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 2524/3118 [00:24<00:04, 125.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 2537/3118 [00:24<00:04, 123.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 2550/3118 [00:24<00:04, 123.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 2563/3118 [00:24<00:04, 123.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 2576/3118 [00:24<00:04, 124.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 2589/3118 [00:24<00:04, 124.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 2602/3118 [00:24<00:04, 124.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 2616/3118 [00:24<00:03, 126.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 2629/3118 [00:24<00:03, 123.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 2643/3118 [00:25<00:03, 126.14it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 2656/3118 [00:25<00:03, 120.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 2670/3118 [00:25<00:03, 123.14it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 2683/3118 [00:25<00:03, 120.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 2697/3118 [00:25<00:03, 124.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2710/3118 [00:25<00:03, 122.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 2723/3118 [00:25<00:03, 124.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 2736/3118 [00:25<00:03, 125.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 2749/3118 [00:25<00:02, 125.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 2762/3118 [00:26<00:02, 124.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 2775/3118 [00:26<00:03, 111.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 2787/3118 [00:26<00:03, 105.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 2798/3118 [00:26<00:03, 105.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 2809/3118 [00:26<00:03, 94.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 2825/3118 [00:26<00:02, 109.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2838/3118 [00:26<00:02, 111.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2850/3118 [00:26<00:02, 107.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2863/3118 [00:27<00:02, 111.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2876/3118 [00:27<00:02, 115.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2888/3118 [00:27<00:02, 113.63it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2900/3118 [00:27<00:01, 114.32it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2912/3118 [00:27<00:01, 115.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2925/3118 [00:27<00:01, 117.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2938/3118 [00:27<00:01, 118.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2950/3118 [00:27<00:01, 116.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2964/3118 [00:27<00:01, 120.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2978/3118 [00:27<00:01, 121.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2991/3118 [00:28<00:01, 120.50it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3004/3118 [00:28<00:00, 120.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3017/3118 [00:28<00:00, 120.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3030/3118 [00:28<00:00, 120.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3043/3118 [00:28<00:00, 120.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3056/3118 [00:28<00:00, 121.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3069/3118 [00:28<00:00, 123.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3118 [00:28<00:00, 117.50it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3094/3118 [00:28<00:00, 113.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3106/3118 [00:29<00:00, 105.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3118/3118 [00:29<00:00, 106.97it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.6220
Epoch 1 Step 51 Train Loss: 0.5024
Epoch 1: Train Overall MSE: 0.0054 Validation Overall MSE: 0.0046. 
Train Top 20 DE MSE: 0.0079 Validation Top 20 DE MSE: 0.0056. 
Epoch 2 Step 1 Train Loss: 0.4872
Epoch 2 Step 51 Train Loss: 0.5878
Epoch 2: Train Overall MSE: 0.0054 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0090. 
Epoch 3 Step 1 Train Loss: 0.5477
Epoch 3 Step 51 Train Loss: 0.5391
Epoch 3: Train Overall MSE: 0.0065 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0098. 
Epoch 4 Step 1 Train Loss: 0.4417
Epoch 4 Step 51 Train Loss: 0.4650
Epoch 4: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0095. 
Epoch 5 Step 1 Train Loss: 0.5284
Epoch 5 Step 51 Train Loss: 0.6283
Epoch 5: Train Overall MSE: 0.0064 Validation Overall MSE: 0.0070. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0100. 
Epoch 6 Step 1 Train Loss: 0.4622
Epoch 6 Step 51 Train Loss: 0.5483
Epoch 6: Train Overall MSE: 0.0062 Validation Overall MSE: 0.0068. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0093. 
Epoch 7 Step 1 Train Loss: 0.5946
Epoch 7 Step 51 Train Loss: 0.5342
Epoch 7: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0103. 
Epoch 8 Step 1 Train Loss: 0.5351
Epoch 8 Step 51 Train Loss: 0.5790
Epoch 8: Train Overall MSE: 0.0063 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0102. 
Epoch 9 Step 1 Train Loss: 0.6280
Epoch 9 Step 51 Train Loss: 0.4713
Epoch 9: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0077. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0108. 
Epoch 10 Step 1 Train Loss: 0.5204
Epoch 10 Step 51 Train Loss: 0.5587
Epoch 10: Train Overall MSE: 0.0062 Validation Overall MSE: 0.0071. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0099. 
Epoch 11 Step 1 Train Loss: 0.5218
Epoch 11 Step 51 Train Loss: 0.4733
Epoch 11: Train Overall MSE: 0.0063 Validation Overall MSE: 0.0072. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0098. 
Epoch 12 Step 1 Train Loss: 0.6976
Epoch 12 Step 51 Train Loss: 0.4710
Epoch 12: Train Overall MSE: 0.0064 Validation Overall MSE: 0.0075. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0105. 
Epoch 13 Step 1 Train Loss: 0.4682
Epoch 13 Step 51 Train Loss: 0.5239
Epoch 13: Train Overall MSE: 0.0063 Validation Overall MSE: 0.0075. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0104. 
Epoch 14 Step 1 Train Loss: 0.5933
Epoch 14 Step 51 Train Loss: 0.5012
Epoch 14: Train Overall MSE: 0.0065 Validation Overall MSE: 0.0075. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0104. 
Epoch 15 Step 1 Train Loss: 0.5527
Epoch 15 Step 51 Train Loss: 0.5414
Epoch 15: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0074. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0102. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0148
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0058845887
test_unseen_single_pearson: 0.9531086768359736
test_unseen_single_mse_de: 0.0147756785
test_unseen_single_pearson_de: 0.3288933107606824
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.06470931492092988
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4375
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5
test_unseen_single_mse_top20_de_non_dropout: 0.01858244
Done!
wandb: - 0.001 MB of 0.019 MB uploadedwandb: \ 0.011 MB of 0.019 MB uploadedwandb: | 0.011 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:                                             train_de_pearson ‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                    train_mse ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:                                                train_pearson ‚ñà‚ñÜ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                training_loss ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÖ
wandb:                                                   val_de_mse ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá
wandb:                                               val_de_pearson ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                      val_mse ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:                                                  val_pearson ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01478
wandb:                                              test_de_pearson 0.32889
wandb:               test_frac_opposite_direction_top20_non_dropout 0.4375
wandb:                          test_frac_sigma_below_1_non_dropout 0.5
wandb:                                                     test_mse 0.00588
wandb:                                test_mse_top20_de_non_dropout 0.01858
wandb:                                                 test_pearson 0.95311
wandb:                                           test_pearson_delta 0.06471
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.4375
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.5
wandb:                                       test_unseen_single_mse 0.00588
wandb:                                    test_unseen_single_mse_de 0.01478
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01858
wandb:                                   test_unseen_single_pearson 0.95311
wandb:                                test_unseen_single_pearson_de 0.32889
wandb:                             test_unseen_single_pearson_delta 0.06471
wandb:                                                 train_de_mse 0.00988
wandb:                                             train_de_pearson 0.34788
wandb:                                                    train_mse 0.00664
wandb:                                                train_pearson 0.95006
wandb:                                                training_loss 0.58179
wandb:                                                   val_de_mse 0.01021
wandb:                                               val_de_pearson 0.28121
wandb:                                                      val_mse 0.00742
wandb:                                                  val_pearson 0.9436
wandb: 
wandb: üöÄ View run geneformer_DatlingerBock2017_stimulated_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/r5tbipmb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_005054-r5tbipmb/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240923_005403-94od5104
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_DatlingerBock2017_stimulated_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/94od5104
wandb: WARNING Serializing object of type ndarray that is 20553856 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5616
Epoch 1 Step 51 Train Loss: 0.5730
Epoch 1: Train Overall MSE: 0.0039 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0046. 
Epoch 2 Step 1 Train Loss: 0.5395
Epoch 2 Step 51 Train Loss: 0.6008
Epoch 2: Train Overall MSE: 0.0064 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0071. 
Epoch 3 Step 1 Train Loss: 0.5251
Epoch 3 Step 51 Train Loss: 0.5055
Epoch 3: Train Overall MSE: 0.0063 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0083. 
Epoch 4 Step 1 Train Loss: 0.4638
Epoch 4 Step 51 Train Loss: 0.5900
Epoch 4: Train Overall MSE: 0.0068 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0086. 
Epoch 5 Step 1 Train Loss: 0.4872
Epoch 5 Step 51 Train Loss: 0.5061
Epoch 5: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0052. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0092. 
Epoch 6 Step 1 Train Loss: 0.5499
Epoch 6 Step 51 Train Loss: 0.6349
Epoch 6: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0088. 
Epoch 7 Step 1 Train Loss: 0.5079
Epoch 7 Step 51 Train Loss: 0.6223
Epoch 7: Train Overall MSE: 0.0070 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0097. 
Epoch 8 Step 1 Train Loss: 0.4769
Epoch 8 Step 51 Train Loss: 0.5428
Epoch 8: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0098. 
Epoch 9 Step 1 Train Loss: 0.5447
Epoch 9 Step 51 Train Loss: 0.4992
Epoch 9: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0128 Validation Top 20 DE MSE: 0.0108. 
Epoch 10 Step 1 Train Loss: 0.7141
Epoch 10 Step 51 Train Loss: 0.4691
Epoch 10: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0094. 
Epoch 11 Step 1 Train Loss: 0.5795
Epoch 11 Step 51 Train Loss: 0.6155
Epoch 11: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0054. 
Train Top 20 DE MSE: 0.0128 Validation Top 20 DE MSE: 0.0094. 
Epoch 12 Step 1 Train Loss: 0.5474
Epoch 12 Step 51 Train Loss: 0.4850
Epoch 12: Train Overall MSE: 0.0071 Validation Overall MSE: 0.0055. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0099. 
Epoch 13 Step 1 Train Loss: 0.6599
Epoch 13 Step 51 Train Loss: 0.7191
Epoch 13: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0056. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0100. 
Epoch 14 Step 1 Train Loss: 0.4687
Epoch 14 Step 51 Train Loss: 0.7748
Epoch 14: Train Overall MSE: 0.0071 Validation Overall MSE: 0.0053. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0094. 
Epoch 15 Step 1 Train Loss: 0.5155
Epoch 15 Step 51 Train Loss: 0.6239
Epoch 15: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0057. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0103. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0044
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0028658747
test_unseen_single_pearson: 0.9764469388766678
test_unseen_single_mse_de: 0.0043872264
test_unseen_single_pearson_de: 0.5252153578697718
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.03644076901577945
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.45
test_unseen_single_frac_sigma_below_1_non_dropout: 0.625
test_unseen_single_mse_top20_de_non_dropout: 0.0086421175
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.010 MB of 0.019 MB uploadedwandb: / 0.010 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá
wandb:                                             train_de_pearson ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                    train_mse ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                                                train_pearson ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                training_loss ‚ñÖ‚ñÖ‚ñÅ‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñà‚ñÉ
wandb:                                                   val_de_mse ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá
wandb:                                               val_de_pearson ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                      val_mse ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                  val_pearson ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00439
wandb:                                              test_de_pearson 0.52522
wandb:               test_frac_opposite_direction_top20_non_dropout 0.45
wandb:                          test_frac_sigma_below_1_non_dropout 0.625
wandb:                                                     test_mse 0.00287
wandb:                                test_mse_top20_de_non_dropout 0.00864
wandb:                                                 test_pearson 0.97645
wandb:                                           test_pearson_delta 0.03644
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.45
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.625
wandb:                                       test_unseen_single_mse 0.00287
wandb:                                    test_unseen_single_mse_de 0.00439
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00864
wandb:                                   test_unseen_single_pearson 0.97645
wandb:                                test_unseen_single_pearson_de 0.52522
wandb:                             test_unseen_single_pearson_delta 0.03644
wandb:                                                 train_de_mse 0.01251
wandb:                                             train_de_pearson 0.26693
wandb:                                                    train_mse 0.00775
wandb:                                                train_pearson 0.94222
wandb:                                                training_loss 0.669
wandb:                                                   val_de_mse 0.01034
wandb:                                               val_de_pearson 0.42217
wandb:                                                      val_mse 0.0057
wandb:                                                  val_pearson 0.95641
wandb: 
wandb: üöÄ View run geneformer_DatlingerBock2017_stimulated_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/94od5104
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_005403-94od5104/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240923_005607-efnw81yb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_DatlingerBock2017_stimulated_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/efnw81yb
wandb: WARNING Serializing object of type ndarray that is 20553856 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6132
Epoch 1 Step 51 Train Loss: 0.6741
Epoch 1: Train Overall MSE: 0.0047 Validation Overall MSE: 0.0044. 
Train Top 20 DE MSE: 0.0077 Validation Top 20 DE MSE: 0.0053. 
Epoch 2 Step 1 Train Loss: 0.5764
Epoch 2 Step 51 Train Loss: 0.5473
Epoch 2: Train Overall MSE: 0.0064 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0048. 
Epoch 3 Step 1 Train Loss: 0.5487
Epoch 3 Step 51 Train Loss: 0.6255
Epoch 3: Train Overall MSE: 0.0060 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0056. 
Epoch 4 Step 1 Train Loss: 0.6114
Epoch 4 Step 51 Train Loss: 0.5615
Epoch 4: Train Overall MSE: 0.0068 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0056. 
Epoch 5 Step 1 Train Loss: 0.5445
Epoch 5 Step 51 Train Loss: 0.6041
Epoch 5: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0062. 
Epoch 6 Step 1 Train Loss: 0.4948
Epoch 6 Step 51 Train Loss: 0.5957
Epoch 6: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0060. 
Epoch 7 Step 1 Train Loss: 0.5347
Epoch 7 Step 51 Train Loss: 0.6091
Epoch 7: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0039. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0060. 
Epoch 8 Step 1 Train Loss: 0.5055
Epoch 8 Step 51 Train Loss: 0.5169
Epoch 8: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0066. 
Epoch 9 Step 1 Train Loss: 0.5770
Epoch 9 Step 51 Train Loss: 0.6584
Epoch 9: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0063. 
Epoch 10 Step 1 Train Loss: 0.5018
Epoch 10 Step 51 Train Loss: 0.6679
Epoch 10: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0062. 
Epoch 11 Step 1 Train Loss: 0.4224
Epoch 11 Step 51 Train Loss: 0.4888
Epoch 11: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0061. 
Epoch 12 Step 1 Train Loss: 0.5698
Epoch 12 Step 51 Train Loss: 0.4090
Epoch 12: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.0066. 
Epoch 13 Step 1 Train Loss: 0.5628
Epoch 13 Step 51 Train Loss: 0.5135
Epoch 13: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0061. 
Epoch 14 Step 1 Train Loss: 0.6456
Epoch 14 Step 51 Train Loss: 0.5198
Epoch 14: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0069. 
Epoch 15 Step 1 Train Loss: 0.5708
Epoch 15 Step 51 Train Loss: 0.5085
Epoch 15: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0063. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0149
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0047673243
test_unseen_single_pearson: 0.9634934475366881
test_unseen_single_mse_de: 0.01490783
test_unseen_single_pearson_de: 0.6837181567642528
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.0030682505240745743
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.45625000000000004
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6125
test_unseen_single_mse_top20_de_non_dropout: 0.02029139
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.003 MB of 0.019 MB uploadedwandb: | 0.013 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb: \ 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá
wandb:                                             train_de_pearson ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                    train_mse ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá
wandb:                                                train_pearson ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ
wandb:                                                training_loss ‚ñÅ‚ñá‚ñÖ‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÉ
wandb:                                                   val_de_mse ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñà‚ñÜ
wandb:                                               val_de_pearson ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                                                      val_mse ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñà‚ñÖ
wandb:                                                  val_pearson ‚ñÉ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÑ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01491
wandb:                                              test_de_pearson 0.68372
wandb:               test_frac_opposite_direction_top20_non_dropout 0.45625
wandb:                          test_frac_sigma_below_1_non_dropout 0.6125
wandb:                                                     test_mse 0.00477
wandb:                                test_mse_top20_de_non_dropout 0.02029
wandb:                                                 test_pearson 0.96349
wandb:                                           test_pearson_delta -0.00307
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.45625
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.6125
wandb:                                       test_unseen_single_mse 0.00477
wandb:                                    test_unseen_single_mse_de 0.01491
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.02029
wandb:                                   test_unseen_single_pearson 0.96349
wandb:                                test_unseen_single_pearson_de 0.68372
wandb:                             test_unseen_single_pearson_delta -0.00307
wandb:                                                 train_de_mse 0.01115
wandb:                                             train_de_pearson 0.23918
wandb:                                                    train_mse 0.00753
wandb:                                                train_pearson 0.94485
wandb:                                                training_loss 0.55789
wandb:                                                   val_de_mse 0.00627
wandb:                                               val_de_pearson 0.19741
wandb:                                                      val_mse 0.00401
wandb:                                                  val_pearson 0.96815
wandb: 
wandb: üöÄ View run geneformer_DatlingerBock2017_stimulated_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/efnw81yb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_005607-efnw81yb/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240923_005813-r5fuuvut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_DatlingerBock2017_stimulated_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/r5fuuvut
wandb: WARNING Serializing object of type ndarray that is 20553856 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4988
Epoch 1 Step 51 Train Loss: 0.4328
Epoch 1: Train Overall MSE: 0.0042 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.0038. 
Epoch 2 Step 1 Train Loss: 0.5189
Epoch 2 Step 51 Train Loss: 0.5485
Epoch 2: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0060. 
Epoch 3 Step 1 Train Loss: 0.4776
Epoch 3 Step 51 Train Loss: 0.6260
Epoch 3: Train Overall MSE: 0.0053 Validation Overall MSE: 0.0040. 
Train Top 20 DE MSE: 0.0112 Validation Top 20 DE MSE: 0.0055. 
Epoch 4 Step 1 Train Loss: 0.5502
Epoch 4 Step 51 Train Loss: 0.5690
Epoch 4: Train Overall MSE: 0.0059 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0063. 
Epoch 5 Step 1 Train Loss: 0.5482
Epoch 5 Step 51 Train Loss: 0.5345
Epoch 5: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0044. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0064. 
Epoch 6 Step 1 Train Loss: 0.5121
Epoch 6 Step 51 Train Loss: 0.5058
Epoch 6: Train Overall MSE: 0.0067 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0071. 
Epoch 7 Step 1 Train Loss: 0.5850
Epoch 7 Step 51 Train Loss: 0.5483
Epoch 7: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0077. 
Epoch 8 Step 1 Train Loss: 0.6004
Epoch 8 Step 51 Train Loss: 0.5682
Epoch 8: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0044. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0070. 
Epoch 9 Step 1 Train Loss: 0.5421
Epoch 9 Step 51 Train Loss: 0.4084
Epoch 9: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0066. 
Epoch 10 Step 1 Train Loss: 0.5863
Epoch 10 Step 51 Train Loss: 0.5102
Epoch 10: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0046. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0072. 
Epoch 11 Step 1 Train Loss: 0.5350
Epoch 11 Step 51 Train Loss: 0.4628
Epoch 11: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0070. 
Epoch 12 Step 1 Train Loss: 0.5687
Epoch 12 Step 51 Train Loss: 0.4379
Epoch 12: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0044. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0068. 
Epoch 13 Step 1 Train Loss: 0.4505
Epoch 13 Step 51 Train Loss: 0.5384
Epoch 13: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0044. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0070. 
Epoch 14 Step 1 Train Loss: 0.6075
Epoch 14 Step 51 Train Loss: 0.5596
Epoch 14: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0045. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0071. 
Epoch 15 Step 1 Train Loss: 0.5057
Epoch 15 Step 51 Train Loss: 0.5425
Epoch 15: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0046. 
Train Top 20 DE MSE: 0.0125 Validation Top 20 DE MSE: 0.0071. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0055
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.003945495
test_unseen_single_pearson: 0.9680391661489197
test_unseen_single_mse_de: 0.0054536737
test_unseen_single_pearson_de: 0.5244129036449399
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.0169608560156705
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4625
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6125
test_unseen_single_mse_top20_de_non_dropout: 0.010630357
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.015 MB uploadedwandb: | 0.009 MB of 0.019 MB uploadedwandb: / 0.009 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà
wandb:                                             train_de_pearson ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                    train_mse ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà
wandb:                                                train_pearson ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                training_loss ‚ñá‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÑ
wandb:                                                   val_de_mse ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:                                                      val_mse ‚ñá‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:                                                  val_pearson ‚ñÇ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00545
wandb:                                              test_de_pearson 0.52441
wandb:               test_frac_opposite_direction_top20_non_dropout 0.4625
wandb:                          test_frac_sigma_below_1_non_dropout 0.6125
wandb:                                                     test_mse 0.00395
wandb:                                test_mse_top20_de_non_dropout 0.01063
wandb:                                                 test_pearson 0.96804
wandb:                                           test_pearson_delta -0.01696
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.4625
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.6125
wandb:                                       test_unseen_single_mse 0.00395
wandb:                                    test_unseen_single_mse_de 0.00545
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01063
wandb:                                   test_unseen_single_pearson 0.96804
wandb:                                test_unseen_single_pearson_de 0.52441
wandb:                             test_unseen_single_pearson_delta -0.01696
wandb:                                                 train_de_mse 0.01251
wandb:                                             train_de_pearson 0.43495
wandb:                                                    train_mse 0.00767
wandb:                                                train_pearson 0.94458
wandb:                                                training_loss 0.55103
wandb:                                                   val_de_mse 0.00706
wandb:                                               val_de_pearson 0.36552
wandb:                                                      val_mse 0.00464
wandb:                                                  val_pearson 0.96248
wandb: 
wandb: üöÄ View run geneformer_DatlingerBock2017_stimulated_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/r5fuuvut
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_005813-r5fuuvut/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:8
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240923_010023-gshw7n5v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_DatlingerBock2017_stimulated_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/gshw7n5v
wandb: WARNING Serializing object of type ndarray that is 20553856 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6326
Epoch 1 Step 51 Train Loss: 0.5241
Epoch 1: Train Overall MSE: 0.0052 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0121 Validation Top 20 DE MSE: 0.0120. 
Epoch 2 Step 1 Train Loss: 0.5408
Epoch 2 Step 51 Train Loss: 0.5548
Epoch 2: Train Overall MSE: 0.0048 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0099 Validation Top 20 DE MSE: 0.0061. 
Epoch 3 Step 1 Train Loss: 0.5025
Epoch 3 Step 51 Train Loss: 0.5659
Epoch 3: Train Overall MSE: 0.0064 Validation Overall MSE: 0.0056. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0102. 
Epoch 4 Step 1 Train Loss: 0.4693
Epoch 4 Step 51 Train Loss: 0.5365
Epoch 4: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0057. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0094. 
Epoch 5 Step 1 Train Loss: 0.5694
Epoch 5 Step 51 Train Loss: 0.4358
Epoch 5: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0058. 
Train Top 20 DE MSE: 0.0115 Validation Top 20 DE MSE: 0.0101. 
Epoch 6 Step 1 Train Loss: 0.5661
Epoch 6 Step 51 Train Loss: 0.5193
Epoch 6: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0103. 
Epoch 7 Step 1 Train Loss: 0.4921
Epoch 7 Step 51 Train Loss: 0.5476
Epoch 7: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0103. 
Epoch 8 Step 1 Train Loss: 0.4030
Epoch 8 Step 51 Train Loss: 0.5981
Epoch 8: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0123 Validation Top 20 DE MSE: 0.0100. 
Epoch 9 Step 1 Train Loss: 0.5330
Epoch 9 Step 51 Train Loss: 0.4979
Epoch 9: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0062. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0101. 
Epoch 10 Step 1 Train Loss: 0.5415
Epoch 10 Step 51 Train Loss: 0.5254
Epoch 10: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0066. 
Train Top 20 DE MSE: 0.0129 Validation Top 20 DE MSE: 0.0102. 
Epoch 11 Step 1 Train Loss: 0.4462
Epoch 11 Step 51 Train Loss: 0.4936
Epoch 11: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0063. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0106. 
Epoch 12 Step 1 Train Loss: 0.6073
Epoch 12 Step 51 Train Loss: 0.5136
Epoch 12: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0101. 
Epoch 13 Step 1 Train Loss: 0.5540
Epoch 13 Step 51 Train Loss: 0.4862
Epoch 13: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0066. 
Train Top 20 DE MSE: 0.0128 Validation Top 20 DE MSE: 0.0108. 
Epoch 14 Step 1 Train Loss: 0.5796
Epoch 14 Step 51 Train Loss: 0.5067
Epoch 14: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0060. 
Train Top 20 DE MSE: 0.0122 Validation Top 20 DE MSE: 0.0099. 
Epoch 15 Step 1 Train Loss: 0.6202
Epoch 15 Step 51 Train Loss: 0.5862
Epoch 15: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0068. 
Train Top 20 DE MSE: 0.0127 Validation Top 20 DE MSE: 0.0111. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0068
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0038212726
test_unseen_single_pearson: 0.9700086252802143
test_unseen_single_mse_de: 0.006788705
test_unseen_single_pearson_de: 0.4074334060612007
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.025262094053247763
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5125
test_unseen_single_frac_sigma_below_1_non_dropout: 0.54375
test_unseen_single_mse_top20_de_non_dropout: 0.013313023
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.009 MB of 0.019 MB uploadedwandb: / 0.009 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñá
wandb:                                             train_de_pearson ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                    train_mse ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñá‚ñá
wandb:                                                train_pearson ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:                                                training_loss ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñá‚ñÖ‚ñá‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá
wandb:                                               val_de_pearson ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:                                                      val_mse ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñà
wandb:                                                  val_pearson ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00679
wandb:                                              test_de_pearson 0.40743
wandb:               test_frac_opposite_direction_top20_non_dropout 0.5125
wandb:                          test_frac_sigma_below_1_non_dropout 0.54375
wandb:                                                     test_mse 0.00382
wandb:                                test_mse_top20_de_non_dropout 0.01331
wandb:                                                 test_pearson 0.97001
wandb:                                           test_pearson_delta 0.02526
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5125
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.54375
wandb:                                       test_unseen_single_mse 0.00382
wandb:                                    test_unseen_single_mse_de 0.00679
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01331
wandb:                                   test_unseen_single_pearson 0.97001
wandb:                                test_unseen_single_pearson_de 0.40743
wandb:                             test_unseen_single_pearson_delta 0.02526
wandb:                                                 train_de_mse 0.01269
wandb:                                             train_de_pearson 0.29401
wandb:                                                    train_mse 0.00758
wandb:                                                train_pearson 0.94265
wandb:                                                training_loss 0.52223
wandb:                                                   val_de_mse 0.01109
wandb:                                               val_de_pearson 0.39004
wandb:                                                      val_mse 0.00677
wandb:                                                  val_pearson 0.94568
wandb: 
wandb: üöÄ View run geneformer_DatlingerBock2017_stimulated_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/gshw7n5v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_010023-gshw7n5v/logs
