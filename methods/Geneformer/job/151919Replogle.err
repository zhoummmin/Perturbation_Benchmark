Loading compilers/gcc/12.2.0
  ERROR: Module cannot be loaded due to a conflict.
    HINT: Might try "module unload compilers/gcc" first.
cmake-3.27.0 loaded successful
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:267
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_013635-s8xu12m8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_k562_essential_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/s8xu12m8
wandb: WARNING Serializing object of type ndarray that is 23167104 bytes
  0%|                                                  | 0/5311 [00:00<?, ?it/s]  0%|                                          | 1/5311 [00:00<20:54,  4.23it/s]  0%|                                          | 3/5311 [00:00<08:57,  9.87it/s]  0%|                                          | 6/5311 [00:00<07:12, 12.25it/s]  0%|                                          | 8/5311 [00:00<07:30, 11.76it/s]  0%|                                         | 10/5311 [00:00<08:00, 11.04it/s]  0%|                                         | 12/5311 [00:01<11:41,  7.56it/s]  0%|                                         | 13/5311 [00:01<14:51,  5.94it/s]  0%|‚ñè                                        | 26/5311 [00:01<04:01, 21.93it/s]  1%|‚ñè                                        | 30/5311 [00:02<04:06, 21.40it/s]  1%|‚ñé                                        | 33/5311 [00:02<03:54, 22.48it/s]  1%|‚ñé                                        | 38/5311 [00:02<03:11, 27.49it/s]  1%|‚ñé                                        | 42/5311 [00:02<02:56, 29.93it/s]  1%|‚ñé                                        | 46/5311 [00:02<02:43, 32.19it/s]  1%|‚ñç                                        | 50/5311 [00:02<02:39, 32.93it/s]  1%|‚ñç                                        | 54/5311 [00:02<02:36, 33.55it/s]  1%|‚ñç                                        | 59/5311 [00:02<02:24, 36.46it/s]  1%|‚ñç                                        | 63/5311 [00:02<02:30, 34.78it/s]  1%|‚ñå                                        | 69/5311 [00:03<02:13, 39.23it/s]  1%|‚ñå                                        | 74/5311 [00:03<02:15, 38.57it/s]  1%|‚ñå                                        | 78/5311 [00:03<02:14, 38.83it/s]  2%|‚ñã                                        | 82/5311 [00:03<02:18, 37.62it/s]  2%|‚ñã                                        | 86/5311 [00:03<02:36, 33.28it/s]  2%|‚ñã                                        | 90/5311 [00:03<02:56, 29.59it/s]  2%|‚ñã                                        | 97/5311 [00:03<02:15, 38.46it/s]  2%|‚ñä                                       | 102/5311 [00:03<02:18, 37.62it/s]  2%|‚ñä                                       | 107/5311 [00:04<02:12, 39.33it/s]  2%|‚ñä                                       | 112/5311 [00:04<02:32, 34.17it/s]  2%|‚ñä                                       | 116/5311 [00:04<02:28, 34.89it/s]  2%|‚ñâ                                       | 121/5311 [00:04<02:17, 37.78it/s]  2%|‚ñâ                                       | 125/5311 [00:04<02:17, 37.83it/s]  2%|‚ñâ                                       | 129/5311 [00:04<02:22, 36.27it/s]  3%|‚ñà                                       | 133/5311 [00:04<02:58, 29.08it/s]  3%|‚ñà                                       | 140/5311 [00:05<02:30, 34.43it/s]  3%|‚ñà                                       | 145/5311 [00:05<02:19, 37.09it/s]  3%|‚ñà                                       | 149/5311 [00:05<02:17, 37.55it/s]  3%|‚ñà‚ñè                                      | 153/5311 [00:05<02:15, 37.94it/s]  3%|‚ñà‚ñè                                      | 157/5311 [00:05<02:35, 33.13it/s]  3%|‚ñà‚ñè                                      | 162/5311 [00:05<02:18, 37.25it/s]  3%|‚ñà‚ñé                                      | 166/5311 [00:05<02:27, 34.93it/s]  3%|‚ñà‚ñé                                      | 170/5311 [00:05<02:25, 35.36it/s]  3%|‚ñà‚ñé                                      | 174/5311 [00:05<02:20, 36.47it/s]  3%|‚ñà‚ñé                                      | 178/5311 [00:06<02:18, 37.09it/s]  3%|‚ñà‚ñç                                      | 183/5311 [00:06<02:26, 35.01it/s]  4%|‚ñà‚ñç                                      | 187/5311 [00:06<03:24, 25.11it/s]  4%|‚ñà‚ñç                                      | 196/5311 [00:06<02:15, 37.62it/s]  4%|‚ñà‚ñå                                      | 201/5311 [00:06<02:11, 38.78it/s]  4%|‚ñà‚ñå                                      | 206/5311 [00:06<02:08, 39.63it/s]  4%|‚ñà‚ñå                                      | 211/5311 [00:07<02:09, 39.40it/s]  4%|‚ñà‚ñã                                      | 216/5311 [00:07<02:05, 40.44it/s]  4%|‚ñà‚ñã                                      | 221/5311 [00:07<02:12, 38.49it/s]  4%|‚ñà‚ñã                                      | 227/5311 [00:07<02:05, 40.43it/s]  4%|‚ñà‚ñã                                      | 232/5311 [00:07<02:03, 41.12it/s]  4%|‚ñà‚ñä                                      | 238/5311 [00:07<02:00, 42.11it/s]  5%|‚ñà‚ñä                                      | 244/5311 [00:07<01:54, 44.37it/s]  5%|‚ñà‚ñâ                                      | 249/5311 [00:07<02:13, 38.04it/s]  5%|‚ñà‚ñâ                                      | 256/5311 [00:08<01:57, 43.11it/s]  5%|‚ñà‚ñâ                                      | 261/5311 [00:08<01:57, 42.92it/s]  5%|‚ñà‚ñà                                      | 266/5311 [00:08<02:04, 40.50it/s]  5%|‚ñà‚ñà                                      | 272/5311 [00:08<01:56, 43.36it/s]  5%|‚ñà‚ñà                                      | 277/5311 [00:08<02:00, 41.75it/s]  5%|‚ñà‚ñà                                      | 282/5311 [00:08<02:02, 40.95it/s]  5%|‚ñà‚ñà‚ñè                                     | 287/5311 [00:08<02:16, 36.93it/s]  6%|‚ñà‚ñà‚ñè                                     | 294/5311 [00:08<01:55, 43.28it/s]  6%|‚ñà‚ñà‚ñé                                     | 300/5311 [00:09<01:48, 46.24it/s]  6%|‚ñà‚ñà‚ñé                                     | 305/5311 [00:09<02:12, 37.78it/s]  6%|‚ñà‚ñà‚ñé                                     | 313/5311 [00:09<01:55, 43.40it/s]  6%|‚ñà‚ñà‚ñç                                     | 319/5311 [00:09<01:49, 45.60it/s]  6%|‚ñà‚ñà‚ñç                                     | 324/5311 [00:09<02:14, 37.13it/s]  6%|‚ñà‚ñà‚ñå                                     | 333/5311 [00:09<01:46, 46.82it/s]  6%|‚ñà‚ñà‚ñå                                     | 339/5311 [00:10<01:49, 45.25it/s]  6%|‚ñà‚ñà‚ñå                                     | 344/5311 [00:10<01:55, 42.82it/s]  7%|‚ñà‚ñà‚ñã                                     | 349/5311 [00:10<01:54, 43.24it/s]  7%|‚ñà‚ñà‚ñã                                     | 354/5311 [00:10<01:56, 42.73it/s]  7%|‚ñà‚ñà‚ñã                                     | 359/5311 [00:10<01:54, 43.25it/s]  7%|‚ñà‚ñà‚ñã                                     | 365/5311 [00:10<01:46, 46.38it/s]  7%|‚ñà‚ñà‚ñä                                     | 370/5311 [00:10<01:52, 43.78it/s]  7%|‚ñà‚ñà‚ñä                                     | 376/5311 [00:10<01:44, 47.25it/s]  7%|‚ñà‚ñà‚ñä                                     | 381/5311 [00:10<01:43, 47.64it/s]  7%|‚ñà‚ñà‚ñâ                                     | 386/5311 [00:11<01:45, 46.64it/s]  7%|‚ñà‚ñà‚ñâ                                     | 391/5311 [00:11<01:53, 43.34it/s]  7%|‚ñà‚ñà‚ñâ                                     | 396/5311 [00:11<01:50, 44.29it/s]  8%|‚ñà‚ñà‚ñà                                     | 402/5311 [00:11<01:42, 48.01it/s]  8%|‚ñà‚ñà‚ñà                                     | 407/5311 [00:11<01:42, 48.08it/s]  8%|‚ñà‚ñà‚ñà                                     | 412/5311 [00:11<01:50, 44.34it/s]  8%|‚ñà‚ñà‚ñà‚ñè                                    | 418/5311 [00:11<01:43, 47.45it/s]  8%|‚ñà‚ñà‚ñà‚ñè                                    | 423/5311 [00:11<01:42, 47.49it/s]  8%|‚ñà‚ñà‚ñà‚ñè                                    | 428/5311 [00:12<02:09, 37.59it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                    | 436/5311 [00:12<01:45, 46.15it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                    | 441/5311 [00:12<01:45, 46.05it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                    | 446/5311 [00:12<02:01, 40.01it/s]  9%|‚ñà‚ñà‚ñà‚ñç                                    | 455/5311 [00:12<01:35, 50.93it/s]  9%|‚ñà‚ñà‚ñà‚ñç                                    | 461/5311 [00:12<02:06, 38.27it/s]  9%|‚ñà‚ñà‚ñà‚ñå                                    | 471/5311 [00:12<01:36, 50.16it/s]  9%|‚ñà‚ñà‚ñà‚ñå                                    | 477/5311 [00:13<01:38, 49.01it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                    | 483/5311 [00:13<01:41, 47.52it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                    | 489/5311 [00:13<01:37, 49.66it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                    | 495/5311 [00:13<01:43, 46.73it/s]  9%|‚ñà‚ñà‚ñà‚ñä                                    | 501/5311 [00:13<01:43, 46.68it/s] 10%|‚ñà‚ñà‚ñà‚ñä                                    | 507/5311 [00:13<01:39, 48.52it/s] 10%|‚ñà‚ñà‚ñà‚ñä                                    | 513/5311 [00:13<01:40, 47.81it/s] 10%|‚ñà‚ñà‚ñà‚ñâ                                    | 518/5311 [00:13<01:40, 47.92it/s] 10%|‚ñà‚ñà‚ñà‚ñâ                                    | 523/5311 [00:14<02:04, 38.32it/s] 10%|‚ñà‚ñà‚ñà‚ñâ                                    | 531/5311 [00:14<01:42, 46.55it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                    | 537/5311 [00:14<01:48, 44.13it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                    | 542/5311 [00:14<01:45, 45.00it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                    | 547/5311 [00:14<02:05, 37.97it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 556/5311 [00:14<01:38, 48.37it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 562/5311 [00:14<01:45, 45.01it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 568/5311 [00:15<01:39, 47.60it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 574/5311 [00:15<01:40, 47.36it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 579/5311 [00:15<01:41, 46.67it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 584/5311 [00:15<01:42, 46.16it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 589/5311 [00:15<01:46, 44.48it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 594/5311 [00:15<02:07, 36.87it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 601/5311 [00:15<01:48, 43.50it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 608/5311 [00:15<01:36, 48.54it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 614/5311 [00:16<01:39, 47.04it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 619/5311 [00:16<01:41, 46.02it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 624/5311 [00:16<01:44, 45.00it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 629/5311 [00:16<01:43, 45.12it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 634/5311 [00:16<01:43, 45.01it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 640/5311 [00:16<01:51, 41.95it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 645/5311 [00:16<01:54, 40.90it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 650/5311 [00:16<02:02, 38.16it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 658/5311 [00:17<01:43, 45.13it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 663/5311 [00:17<01:42, 45.47it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 668/5311 [00:17<02:04, 37.42it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 676/5311 [00:17<01:55, 40.10it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 684/5311 [00:17<01:47, 42.89it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 692/5311 [00:17<01:32, 49.73it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 698/5311 [00:17<01:29, 51.63it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 704/5311 [00:18<01:31, 50.29it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 710/5311 [00:18<01:33, 49.14it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 716/5311 [00:18<01:34, 48.52it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 721/5311 [00:18<01:38, 46.43it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 727/5311 [00:18<01:35, 48.09it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 732/5311 [00:18<01:42, 44.57it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 738/5311 [00:18<01:42, 44.56it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 744/5311 [00:18<01:41, 44.94it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 750/5311 [00:19<01:41, 44.95it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 755/5311 [00:19<01:40, 45.35it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 761/5311 [00:19<01:35, 47.66it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 766/5311 [00:19<01:37, 46.69it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 771/5311 [00:19<02:23, 31.63it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 782/5311 [00:19<01:36, 47.06it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 788/5311 [00:20<01:48, 41.74it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 796/5311 [00:20<01:34, 47.67it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 802/5311 [00:20<01:35, 47.33it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 808/5311 [00:20<01:41, 44.30it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 814/5311 [00:20<01:37, 46.14it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 819/5311 [00:20<01:48, 41.37it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 825/5311 [00:20<01:59, 37.45it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 834/5311 [00:21<01:34, 47.40it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 840/5311 [00:21<01:36, 46.57it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 845/5311 [00:21<01:40, 44.48it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 850/5311 [00:21<01:48, 41.10it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 858/5311 [00:21<01:31, 48.66it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 864/5311 [00:21<01:29, 49.49it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 870/5311 [00:21<01:34, 47.15it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 875/5311 [00:21<01:34, 47.11it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 880/5311 [00:22<01:38, 44.98it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 886/5311 [00:22<01:38, 44.88it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 891/5311 [00:22<01:38, 44.90it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 896/5311 [00:22<02:19, 31.58it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 908/5311 [00:22<01:30, 48.79it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 915/5311 [00:22<01:28, 49.64it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 921/5311 [00:23<01:57, 37.38it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 929/5311 [00:23<01:40, 43.39it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 940/5311 [00:23<01:18, 55.60it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 947/5311 [00:23<01:21, 53.68it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 954/5311 [00:23<01:23, 52.45it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 960/5311 [00:23<01:24, 51.44it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 966/5311 [00:23<01:37, 44.69it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 971/5311 [00:24<01:38, 44.26it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 977/5311 [00:24<01:34, 45.72it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 982/5311 [00:24<02:13, 32.37it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 991/5311 [00:24<01:41, 42.66it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 997/5311 [00:24<02:10, 32.94it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1011/5311 [00:24<01:25, 50.42it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1018/5311 [00:25<01:27, 49.06it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 1024/5311 [00:25<01:27, 48.89it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 1030/5311 [00:25<01:28, 48.42it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 1036/5311 [00:25<01:31, 46.96it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1042/5311 [00:25<01:35, 44.85it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1047/5311 [00:25<01:39, 42.87it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1052/5311 [00:25<01:40, 42.39it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1057/5311 [00:26<01:40, 42.48it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1062/5311 [00:26<01:40, 42.23it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1067/5311 [00:26<01:41, 41.68it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1072/5311 [00:26<01:47, 39.50it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1079/5311 [00:26<01:37, 43.54it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1084/5311 [00:26<01:49, 38.64it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1092/5311 [00:26<01:30, 46.60it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1097/5311 [00:26<01:36, 43.52it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1103/5311 [00:27<01:32, 45.61it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1108/5311 [00:27<01:41, 41.25it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1113/5311 [00:27<01:57, 35.74it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1117/5311 [00:27<02:00, 34.87it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1122/5311 [00:27<01:54, 36.43it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1126/5311 [00:27<01:55, 36.36it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1133/5311 [00:27<01:39, 42.10it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1139/5311 [00:28<01:36, 43.41it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1145/5311 [00:28<01:32, 44.91it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1151/5311 [00:28<01:26, 47.97it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1157/5311 [00:28<01:30, 45.98it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1162/5311 [00:28<01:49, 38.05it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1171/5311 [00:28<01:27, 47.39it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1177/5311 [00:28<01:22, 50.19it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1183/5311 [00:28<01:23, 49.54it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1189/5311 [00:29<01:24, 48.93it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1195/5311 [00:29<01:23, 49.06it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1201/5311 [00:29<01:19, 51.57it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1207/5311 [00:29<01:25, 48.14it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1212/5311 [00:29<01:26, 47.45it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1217/5311 [00:29<01:26, 47.12it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1222/5311 [00:29<01:26, 47.51it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1227/5311 [00:29<01:32, 44.28it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1232/5311 [00:30<01:48, 37.71it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1237/5311 [00:30<01:42, 39.91it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1242/5311 [00:30<01:37, 41.88it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1249/5311 [00:30<01:25, 47.35it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1254/5311 [00:30<01:24, 47.92it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1260/5311 [00:30<01:23, 48.52it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1265/5311 [00:30<01:24, 48.07it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1270/5311 [00:30<01:23, 48.17it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1275/5311 [00:30<01:24, 48.04it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1281/5311 [00:31<01:22, 48.91it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1286/5311 [00:31<01:22, 48.66it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1291/5311 [00:31<01:23, 48.09it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1297/5311 [00:31<01:22, 48.77it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1302/5311 [00:31<01:26, 46.44it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1308/5311 [00:31<01:20, 49.53it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1313/5311 [00:31<01:27, 45.94it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1319/5311 [00:31<01:21, 48.81it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1324/5311 [00:31<01:21, 49.06it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1329/5311 [00:32<01:22, 48.43it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1334/5311 [00:32<01:21, 48.75it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1339/5311 [00:32<01:23, 47.84it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1344/5311 [00:32<01:23, 47.65it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1350/5311 [00:32<01:21, 48.37it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1356/5311 [00:32<01:20, 49.19it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1361/5311 [00:32<01:20, 49.26it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1366/5311 [00:32<01:21, 48.60it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1371/5311 [00:32<01:24, 46.37it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1377/5311 [00:33<01:23, 47.33it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1384/5311 [00:33<01:17, 50.65it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1390/5311 [00:33<01:19, 49.09it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1395/5311 [00:33<01:20, 48.76it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1400/5311 [00:33<01:20, 48.65it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1405/5311 [00:33<01:20, 48.70it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1410/5311 [00:33<01:19, 48.77it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1415/5311 [00:33<01:21, 47.74it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1420/5311 [00:33<01:21, 47.80it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1426/5311 [00:34<01:19, 48.64it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1432/5311 [00:34<01:18, 49.16it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1437/5311 [00:34<01:19, 48.52it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1442/5311 [00:34<01:20, 48.14it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1448/5311 [00:34<01:19, 48.86it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1453/5311 [00:34<01:24, 45.92it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1458/5311 [00:34<01:31, 41.90it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1463/5311 [00:34<01:40, 38.15it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1467/5311 [00:35<01:45, 36.46it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1471/5311 [00:35<01:47, 35.58it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1475/5311 [00:35<01:46, 35.88it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1480/5311 [00:35<01:41, 37.68it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1486/5311 [00:35<01:38, 38.97it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1493/5311 [00:35<01:23, 45.88it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1498/5311 [00:35<01:22, 46.22it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1504/5311 [00:35<01:20, 47.13it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1509/5311 [00:35<01:20, 47.47it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1514/5311 [00:36<01:24, 45.00it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1520/5311 [00:36<01:17, 48.66it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1525/5311 [00:36<01:18, 48.43it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1530/5311 [00:36<01:22, 45.87it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1535/5311 [00:36<01:24, 44.80it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1540/5311 [00:36<01:22, 45.57it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1545/5311 [00:36<01:21, 46.39it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1550/5311 [00:36<01:20, 46.92it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1556/5311 [00:36<01:17, 48.23it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1561/5311 [00:37<01:17, 48.47it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1566/5311 [00:37<01:17, 48.11it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1571/5311 [00:37<01:25, 43.79it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1578/5311 [00:37<01:17, 47.90it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1583/5311 [00:37<01:18, 47.75it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1588/5311 [00:37<01:22, 45.07it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1594/5311 [00:37<01:17, 48.21it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1599/5311 [00:37<01:16, 48.56it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1604/5311 [00:38<01:15, 48.91it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1610/5311 [00:38<01:15, 49.22it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1615/5311 [00:38<01:16, 48.04it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1620/5311 [00:38<01:16, 47.97it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1625/5311 [00:38<01:17, 47.33it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1630/5311 [00:38<01:16, 48.02it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1635/5311 [00:38<01:16, 48.32it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1640/5311 [00:38<01:18, 46.87it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1645/5311 [00:38<01:26, 42.33it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1650/5311 [00:39<01:32, 39.60it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1655/5311 [00:39<01:32, 39.49it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1660/5311 [00:39<01:27, 41.84it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1665/5311 [00:39<01:24, 43.32it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1670/5311 [00:39<01:23, 43.60it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1675/5311 [00:39<01:21, 44.55it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1680/5311 [00:39<01:19, 45.94it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1685/5311 [00:39<01:25, 42.61it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1690/5311 [00:39<01:22, 43.94it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1695/5311 [00:40<01:20, 45.04it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1700/5311 [00:40<01:18, 46.10it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1705/5311 [00:40<01:17, 46.76it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1710/5311 [00:40<01:16, 47.26it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1715/5311 [00:40<01:21, 44.17it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1721/5311 [00:40<01:14, 48.20it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1726/5311 [00:40<01:14, 48.17it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1731/5311 [00:40<01:14, 48.29it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1736/5311 [00:40<01:14, 48.17it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1741/5311 [00:41<01:15, 47.55it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1746/5311 [00:41<01:18, 45.26it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1752/5311 [00:41<01:17, 45.87it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1757/5311 [00:41<01:15, 46.96it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1762/5311 [00:41<01:16, 46.61it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1768/5311 [00:41<01:12, 48.85it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1774/5311 [00:41<01:11, 49.34it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1779/5311 [00:41<01:12, 48.96it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1785/5311 [00:41<01:11, 49.23it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1790/5311 [00:42<01:16, 46.02it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1796/5311 [00:42<01:11, 49.05it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1801/5311 [00:42<01:12, 48.29it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1807/5311 [00:42<01:10, 49.37it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1812/5311 [00:42<01:11, 48.75it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1817/5311 [00:42<01:13, 47.55it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1823/5311 [00:42<01:12, 48.27it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1828/5311 [00:42<01:15, 45.95it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1835/5311 [00:42<01:10, 49.65it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1840/5311 [00:43<01:14, 46.28it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1845/5311 [00:43<01:13, 47.05it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1851/5311 [00:43<01:09, 49.99it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1857/5311 [00:43<01:12, 47.97it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1862/5311 [00:43<01:12, 47.53it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1868/5311 [00:43<01:10, 49.18it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1874/5311 [00:43<01:09, 49.22it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1879/5311 [00:43<01:09, 49.18it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1884/5311 [00:43<01:09, 49.26it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1889/5311 [00:44<01:12, 47.37it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1894/5311 [00:44<01:19, 43.00it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1899/5311 [00:44<01:20, 42.62it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1905/5311 [00:44<01:19, 42.71it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1911/5311 [00:44<01:13, 45.97it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1916/5311 [00:44<01:14, 45.58it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1921/5311 [00:44<01:12, 46.74it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1926/5311 [00:44<01:17, 43.95it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1932/5311 [00:45<01:11, 47.54it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1937/5311 [00:45<01:16, 44.36it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1943/5311 [00:45<01:11, 47.26it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1949/5311 [00:45<01:09, 48.35it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1954/5311 [00:45<01:09, 48.02it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1959/5311 [00:45<01:10, 47.78it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1964/5311 [00:45<01:10, 47.81it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1969/5311 [00:45<01:10, 47.47it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 1975/5311 [00:45<01:09, 48.11it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 1981/5311 [00:46<01:07, 49.06it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 1986/5311 [00:46<01:07, 49.00it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 1991/5311 [00:46<01:09, 48.05it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 1996/5311 [00:46<01:09, 47.71it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2002/5311 [00:46<01:08, 48.57it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2007/5311 [00:46<01:08, 48.21it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2012/5311 [00:46<01:10, 46.50it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2017/5311 [00:46<01:12, 45.73it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2022/5311 [00:46<01:12, 45.25it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2027/5311 [00:47<01:17, 42.17it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2033/5311 [00:47<01:16, 42.62it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2039/5311 [00:47<01:12, 45.31it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2044/5311 [00:47<01:13, 44.61it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2049/5311 [00:47<01:19, 40.88it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2054/5311 [00:47<01:17, 42.13it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2059/5311 [00:47<01:14, 43.50it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2064/5311 [00:47<01:13, 44.09it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2069/5311 [00:48<01:12, 44.64it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2074/5311 [00:48<01:11, 45.23it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2079/5311 [00:48<01:10, 46.02it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2084/5311 [00:48<01:08, 46.91it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2089/5311 [00:48<01:08, 47.01it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2094/5311 [00:48<01:09, 46.57it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2099/5311 [00:48<01:11, 45.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2104/5311 [00:48<01:37, 32.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2116/5311 [00:49<01:03, 50.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2122/5311 [00:49<01:01, 52.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2128/5311 [00:49<01:05, 48.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2134/5311 [00:49<01:01, 51.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2140/5311 [00:49<01:03, 50.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2146/5311 [00:49<01:06, 47.73it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2151/5311 [00:49<01:10, 44.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2156/5311 [00:49<01:12, 43.79it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2162/5311 [00:50<01:06, 47.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2167/5311 [00:50<01:06, 47.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2172/5311 [00:50<01:09, 45.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2178/5311 [00:50<01:04, 48.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2184/5311 [00:50<01:02, 49.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2190/5311 [00:50<01:03, 49.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2195/5311 [00:50<01:04, 48.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2201/5311 [00:50<01:03, 49.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2206/5311 [00:50<01:04, 48.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2212/5311 [00:51<01:00, 51.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2218/5311 [00:51<01:01, 50.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2224/5311 [00:51<01:01, 50.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2230/5311 [00:51<01:00, 50.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2236/5311 [00:51<01:00, 50.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2242/5311 [00:51<01:04, 47.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2249/5311 [00:51<01:00, 50.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2255/5311 [00:51<01:02, 48.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2261/5311 [00:52<01:00, 50.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2267/5311 [00:52<01:05, 46.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2273/5311 [00:52<01:03, 47.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2278/5311 [00:52<01:09, 43.73it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2284/5311 [00:52<01:05, 46.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2289/5311 [00:52<01:04, 46.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2294/5311 [00:52<01:11, 42.19it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2299/5311 [00:53<01:25, 35.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2303/5311 [00:53<01:23, 36.16it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2307/5311 [00:53<01:31, 32.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2311/5311 [00:53<01:31, 32.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2315/5311 [00:53<01:31, 32.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2319/5311 [00:53<01:33, 32.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2323/5311 [00:53<01:34, 31.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2327/5311 [00:53<01:31, 32.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2331/5311 [00:53<01:27, 34.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2337/5311 [00:54<01:13, 40.45it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2342/5311 [00:54<01:12, 41.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2347/5311 [00:54<01:09, 42.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2353/5311 [00:54<01:05, 45.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2358/5311 [00:54<01:04, 45.74it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2363/5311 [00:54<01:14, 39.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2370/5311 [00:54<01:03, 46.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2376/5311 [00:54<01:01, 47.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2382/5311 [00:55<00:59, 48.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2388/5311 [00:55<01:03, 46.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2393/5311 [00:55<01:04, 45.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2398/5311 [00:55<01:12, 40.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2403/5311 [00:55<01:14, 39.29it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2408/5311 [00:55<01:18, 36.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2413/5311 [00:55<01:15, 38.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2418/5311 [00:55<01:12, 39.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2423/5311 [00:56<01:10, 41.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2428/5311 [00:56<01:12, 39.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2434/5311 [00:56<01:06, 43.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2439/5311 [00:56<01:06, 43.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2444/5311 [00:56<01:09, 41.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2450/5311 [00:56<01:02, 45.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2455/5311 [00:56<01:02, 45.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2460/5311 [00:56<01:01, 45.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2465/5311 [00:57<01:05, 43.28it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2471/5311 [00:57<01:00, 46.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2476/5311 [00:57<01:05, 43.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2482/5311 [00:57<01:21, 34.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2487/5311 [00:57<01:14, 37.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2492/5311 [00:57<01:10, 39.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2497/5311 [00:57<01:06, 42.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2502/5311 [00:57<01:07, 41.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2507/5311 [00:58<01:04, 43.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2513/5311 [00:58<00:59, 47.30it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2518/5311 [00:58<00:59, 47.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2523/5311 [00:58<01:01, 45.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2528/5311 [00:58<01:02, 44.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2534/5311 [00:58<00:57, 47.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2539/5311 [00:58<00:57, 47.90it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2544/5311 [00:58<00:58, 47.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2549/5311 [00:59<01:11, 38.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2556/5311 [00:59<01:02, 44.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2562/5311 [00:59<00:59, 45.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2567/5311 [00:59<01:01, 44.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2572/5311 [00:59<01:02, 44.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2577/5311 [00:59<01:02, 43.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2582/5311 [00:59<01:06, 41.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2588/5311 [00:59<01:01, 44.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2593/5311 [01:00<01:02, 43.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2598/5311 [01:00<01:04, 42.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2603/5311 [01:00<01:11, 37.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2607/5311 [01:00<01:14, 36.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2611/5311 [01:00<01:16, 35.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2615/5311 [01:00<01:23, 32.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2620/5311 [01:00<01:17, 34.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2624/5311 [01:00<01:17, 34.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2630/5311 [01:01<01:12, 36.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2635/5311 [01:01<01:10, 38.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2641/5311 [01:01<01:02, 42.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2646/5311 [01:01<01:04, 41.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2652/5311 [01:01<00:57, 46.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2657/5311 [01:01<00:57, 46.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2662/5311 [01:01<00:56, 46.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2667/5311 [01:01<00:56, 46.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2672/5311 [01:01<00:56, 47.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2678/5311 [01:02<00:54, 48.24it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2683/5311 [01:02<00:54, 48.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2688/5311 [01:02<00:53, 48.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2693/5311 [01:02<00:55, 47.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2698/5311 [01:02<00:54, 47.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2703/5311 [01:02<00:54, 47.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2709/5311 [01:02<00:54, 48.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2714/5311 [01:02<00:54, 48.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2719/5311 [01:02<00:54, 47.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2725/5311 [01:03<00:56, 46.06it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2731/5311 [01:03<00:53, 48.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2736/5311 [01:03<00:58, 43.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2741/5311 [01:03<01:18, 32.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2748/5311 [01:03<01:04, 39.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2753/5311 [01:03<01:06, 38.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2758/5311 [01:03<01:07, 37.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2763/5311 [01:04<01:15, 33.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2767/5311 [01:04<01:14, 34.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2771/5311 [01:04<01:21, 31.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2776/5311 [01:04<01:17, 32.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2780/5311 [01:04<01:15, 33.36it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2785/5311 [01:04<01:08, 37.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2789/5311 [01:05<01:35, 26.37it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2804/5311 [01:05<00:50, 49.22it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2810/5311 [01:05<00:50, 49.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2816/5311 [01:05<00:51, 48.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2822/5311 [01:05<01:02, 40.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2827/5311 [01:05<01:02, 39.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2833/5311 [01:05<00:56, 43.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2838/5311 [01:05<00:56, 44.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2843/5311 [01:06<00:55, 44.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2849/5311 [01:06<00:52, 46.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2854/5311 [01:06<00:53, 46.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2859/5311 [01:06<00:52, 47.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2864/5311 [01:06<00:52, 46.78it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2869/5311 [01:06<00:52, 46.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2874/5311 [01:06<00:53, 45.59it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2879/5311 [01:06<00:53, 45.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2885/5311 [01:06<00:51, 47.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2890/5311 [01:07<00:51, 46.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2895/5311 [01:07<00:51, 47.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2901/5311 [01:07<00:49, 48.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2906/5311 [01:07<00:51, 46.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2911/5311 [01:07<00:51, 46.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2917/5311 [01:07<00:50, 46.96it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2922/5311 [01:07<00:56, 42.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2927/5311 [01:07<01:00, 39.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2932/5311 [01:08<01:02, 37.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2936/5311 [01:08<01:05, 36.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2940/5311 [01:08<01:07, 35.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2944/5311 [01:08<01:08, 34.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2948/5311 [01:08<01:07, 34.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2953/5311 [01:08<01:01, 38.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2958/5311 [01:08<00:59, 39.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2963/5311 [01:08<00:58, 40.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2968/5311 [01:09<00:59, 39.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2974/5311 [01:09<00:54, 42.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2979/5311 [01:09<00:52, 44.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2984/5311 [01:09<00:51, 45.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2989/5311 [01:09<00:53, 43.56it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2995/5311 [01:09<00:48, 47.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3000/5311 [01:09<00:54, 42.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3005/5311 [01:09<00:53, 43.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3010/5311 [01:10<00:52, 43.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3015/5311 [01:10<00:52, 43.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3020/5311 [01:10<00:51, 44.74it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3026/5311 [01:10<00:48, 46.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3031/5311 [01:10<00:48, 47.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3036/5311 [01:10<00:51, 44.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3042/5311 [01:10<00:48, 46.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3047/5311 [01:10<00:49, 45.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3052/5311 [01:10<00:50, 45.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3057/5311 [01:11<00:50, 44.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3062/5311 [01:11<00:49, 45.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3067/5311 [01:11<00:48, 45.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3072/5311 [01:11<00:48, 46.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3078/5311 [01:11<00:46, 47.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3083/5311 [01:11<00:49, 44.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3089/5311 [01:11<00:48, 45.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3095/5311 [01:11<00:45, 49.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3101/5311 [01:11<00:44, 49.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3106/5311 [01:12<00:47, 46.75it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3112/5311 [01:12<00:44, 49.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3118/5311 [01:12<00:45, 48.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3124/5311 [01:12<00:43, 50.22it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3130/5311 [01:12<00:45, 47.77it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3136/5311 [01:12<00:43, 50.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3142/5311 [01:12<00:43, 49.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3148/5311 [01:12<00:44, 48.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3155/5311 [01:13<00:43, 49.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3161/5311 [01:13<00:41, 51.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3167/5311 [01:13<00:44, 48.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3172/5311 [01:13<00:48, 43.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3177/5311 [01:13<00:49, 43.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3183/5311 [01:13<00:49, 43.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3189/5311 [01:13<00:46, 45.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3194/5311 [01:13<00:48, 43.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3199/5311 [01:14<00:53, 39.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3205/5311 [01:14<00:47, 44.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3210/5311 [01:14<00:46, 44.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3215/5311 [01:14<00:45, 45.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3220/5311 [01:14<00:45, 46.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3225/5311 [01:14<00:46, 45.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3231/5311 [01:14<00:42, 48.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3236/5311 [01:14<00:46, 44.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3242/5311 [01:14<00:43, 47.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3249/5311 [01:15<00:39, 51.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3255/5311 [01:15<00:40, 51.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3261/5311 [01:15<00:40, 50.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3267/5311 [01:15<00:47, 42.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3272/5311 [01:15<00:49, 41.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3277/5311 [01:15<00:50, 40.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3282/5311 [01:15<00:57, 35.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3286/5311 [01:16<00:56, 35.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3291/5311 [01:16<00:53, 37.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3295/5311 [01:16<00:54, 36.88it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3301/5311 [01:16<00:48, 41.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3308/5311 [01:16<00:43, 46.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3313/5311 [01:16<00:43, 45.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3318/5311 [01:16<00:43, 45.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3323/5311 [01:16<00:42, 46.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3329/5311 [01:16<00:41, 47.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3334/5311 [01:17<00:41, 47.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3339/5311 [01:17<00:41, 47.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3344/5311 [01:17<00:42, 46.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3349/5311 [01:17<00:41, 47.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3355/5311 [01:17<00:40, 48.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3360/5311 [01:17<00:40, 48.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3365/5311 [01:17<00:40, 47.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3370/5311 [01:17<00:41, 47.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3375/5311 [01:17<00:41, 46.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3380/5311 [01:18<00:40, 47.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3385/5311 [01:18<00:40, 47.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3390/5311 [01:18<00:40, 47.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3395/5311 [01:18<00:45, 42.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3400/5311 [01:18<00:46, 41.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3409/5311 [01:18<00:36, 51.62it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3415/5311 [01:18<00:38, 48.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3420/5311 [01:19<00:53, 35.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3429/5311 [01:19<00:41, 45.14it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3435/5311 [01:19<00:39, 47.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3441/5311 [01:19<00:39, 46.79it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3447/5311 [01:19<00:41, 44.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3453/5311 [01:19<00:40, 45.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3459/5311 [01:19<00:38, 48.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3464/5311 [01:19<00:38, 48.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3469/5311 [01:20<00:38, 47.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3474/5311 [01:20<00:40, 45.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3481/5311 [01:20<00:38, 46.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3487/5311 [01:20<00:39, 46.58it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3492/5311 [01:20<00:42, 42.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3497/5311 [01:20<00:44, 41.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3502/5311 [01:20<00:47, 38.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3506/5311 [01:20<00:46, 38.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3512/5311 [01:21<00:43, 40.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3518/5311 [01:21<00:40, 44.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3524/5311 [01:21<00:38, 46.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3529/5311 [01:21<00:39, 45.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3534/5311 [01:21<00:42, 41.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3539/5311 [01:21<00:46, 38.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3543/5311 [01:21<00:49, 35.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3547/5311 [01:21<00:48, 36.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3551/5311 [01:22<00:52, 33.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3556/5311 [01:22<00:47, 37.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3561/5311 [01:22<00:46, 37.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3567/5311 [01:22<00:41, 41.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3573/5311 [01:22<00:40, 42.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3579/5311 [01:22<00:38, 45.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3585/5311 [01:22<00:35, 48.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3590/5311 [01:22<00:36, 47.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3595/5311 [01:23<00:35, 47.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3601/5311 [01:23<00:35, 48.64it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3607/5311 [01:23<00:34, 49.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3612/5311 [01:23<00:34, 48.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3617/5311 [01:23<00:35, 47.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3623/5311 [01:23<00:36, 46.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3629/5311 [01:23<00:35, 47.59it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3634/5311 [01:23<00:38, 43.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3639/5311 [01:24<00:41, 40.24it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3644/5311 [01:24<00:44, 37.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3649/5311 [01:24<00:44, 37.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3656/5311 [01:24<00:38, 43.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3661/5311 [01:24<00:36, 44.76it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3666/5311 [01:24<00:36, 45.18it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3671/5311 [01:24<00:38, 42.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3677/5311 [01:24<00:35, 45.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3682/5311 [01:25<00:37, 42.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3688/5311 [01:25<00:37, 42.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3693/5311 [01:25<00:39, 41.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3698/5311 [01:25<00:43, 36.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3702/5311 [01:25<00:44, 35.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3706/5311 [01:25<00:47, 33.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3710/5311 [01:25<00:48, 33.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3716/5311 [01:25<00:41, 38.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3721/5311 [01:26<00:39, 39.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3726/5311 [01:26<00:38, 40.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3732/5311 [01:26<00:34, 45.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3737/5311 [01:26<00:35, 43.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3743/5311 [01:26<00:33, 46.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3748/5311 [01:26<00:34, 45.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3754/5311 [01:26<00:31, 49.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3760/5311 [01:26<00:31, 49.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3765/5311 [01:26<00:31, 48.76it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3770/5311 [01:27<00:33, 45.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3777/5311 [01:27<00:30, 49.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3782/5311 [01:27<00:33, 45.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3788/5311 [01:27<00:31, 48.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3794/5311 [01:27<00:31, 47.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3800/5311 [01:27<00:29, 51.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3806/5311 [01:27<00:29, 50.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3812/5311 [01:27<00:30, 49.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3818/5311 [01:28<00:32, 46.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3825/5311 [01:28<00:29, 49.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3831/5311 [01:28<00:32, 45.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3836/5311 [01:28<00:33, 44.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3841/5311 [01:28<00:36, 40.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3846/5311 [01:28<00:38, 37.69it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 3852/5311 [01:28<00:34, 42.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 3858/5311 [01:29<00:33, 42.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 3864/5311 [01:29<00:31, 46.52it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3869/5311 [01:29<00:30, 46.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3874/5311 [01:29<00:30, 47.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3880/5311 [01:29<00:29, 48.53it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3885/5311 [01:29<00:30, 46.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3891/5311 [01:29<00:28, 49.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3896/5311 [01:29<00:31, 44.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 3902/5311 [01:29<00:30, 46.23it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 3907/5311 [01:30<00:30, 45.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 3912/5311 [01:30<00:30, 45.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3917/5311 [01:30<00:30, 45.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3922/5311 [01:30<00:30, 46.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3927/5311 [01:30<00:32, 42.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3933/5311 [01:30<00:32, 42.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3939/5311 [01:30<00:30, 45.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3944/5311 [01:30<00:29, 45.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 3950/5311 [01:31<00:28, 47.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 3955/5311 [01:31<00:30, 44.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 3960/5311 [01:31<00:31, 43.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 3965/5311 [01:31<00:30, 44.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3970/5311 [01:31<00:29, 45.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3976/5311 [01:31<00:28, 47.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3981/5311 [01:31<00:27, 47.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 3986/5311 [01:31<00:28, 46.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 3991/5311 [01:31<00:28, 46.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 3997/5311 [01:32<00:27, 48.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4003/5311 [01:32<00:26, 49.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4009/5311 [01:32<00:26, 49.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4014/5311 [01:32<00:26, 49.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4019/5311 [01:32<00:26, 48.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4025/5311 [01:32<00:25, 50.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4031/5311 [01:32<00:25, 50.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4037/5311 [01:32<00:25, 49.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4042/5311 [01:32<00:26, 47.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4048/5311 [01:33<00:26, 46.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4054/5311 [01:33<00:25, 49.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4060/5311 [01:33<00:25, 49.62it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4065/5311 [01:33<00:26, 47.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4070/5311 [01:33<00:29, 42.44it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4075/5311 [01:33<00:30, 41.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4080/5311 [01:33<00:29, 42.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4085/5311 [01:33<00:29, 41.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4090/5311 [01:34<00:29, 41.63it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4095/5311 [01:34<00:29, 41.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4100/5311 [01:34<00:28, 43.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4105/5311 [01:34<00:26, 44.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4110/5311 [01:34<00:28, 42.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4115/5311 [01:34<00:27, 44.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4120/5311 [01:34<00:26, 45.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4126/5311 [01:34<00:24, 49.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4132/5311 [01:34<00:23, 49.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4138/5311 [01:35<00:23, 49.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4143/5311 [01:35<00:24, 48.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4148/5311 [01:35<00:24, 46.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4154/5311 [01:35<00:23, 50.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4160/5311 [01:35<00:23, 50.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4166/5311 [01:35<00:23, 49.08it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4172/5311 [01:35<00:24, 47.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4178/5311 [01:35<00:22, 50.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4184/5311 [01:35<00:22, 50.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4190/5311 [01:36<00:22, 49.83it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4196/5311 [01:36<00:22, 49.71it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4202/5311 [01:36<00:24, 45.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4207/5311 [01:36<00:25, 43.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4212/5311 [01:36<00:29, 37.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4217/5311 [01:36<00:27, 39.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4222/5311 [01:36<00:26, 40.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4228/5311 [01:37<00:23, 45.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4233/5311 [01:37<00:24, 44.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4239/5311 [01:37<00:22, 48.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4244/5311 [01:37<00:22, 47.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4249/5311 [01:37<00:23, 45.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4254/5311 [01:37<00:25, 40.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4259/5311 [01:37<00:27, 38.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4263/5311 [01:37<00:28, 36.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4268/5311 [01:38<00:27, 37.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4273/5311 [01:38<00:27, 38.08it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4278/5311 [01:38<00:26, 38.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4282/5311 [01:38<00:29, 35.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4286/5311 [01:38<00:33, 30.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4290/5311 [01:38<00:33, 30.54it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4295/5311 [01:38<00:31, 32.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4299/5311 [01:39<00:33, 30.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4305/5311 [01:39<00:29, 34.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4311/5311 [01:39<00:25, 38.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4317/5311 [01:39<00:22, 43.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4323/5311 [01:39<00:21, 46.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4328/5311 [01:39<00:20, 46.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4333/5311 [01:39<00:20, 46.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4339/5311 [01:39<00:19, 49.85it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4345/5311 [01:39<00:19, 48.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4351/5311 [01:40<00:19, 49.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4357/5311 [01:40<00:18, 50.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4363/5311 [01:40<00:18, 50.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4369/5311 [01:40<00:19, 48.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4375/5311 [01:40<00:18, 50.04it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4381/5311 [01:40<00:18, 51.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4387/5311 [01:40<00:18, 50.06it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4393/5311 [01:40<00:18, 48.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4398/5311 [01:41<00:19, 47.83it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4404/5311 [01:41<00:17, 51.01it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4410/5311 [01:41<00:17, 50.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4416/5311 [01:41<00:18, 49.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4421/5311 [01:41<00:18, 49.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4427/5311 [01:41<00:17, 49.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4433/5311 [01:41<00:18, 48.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4439/5311 [01:41<00:17, 50.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4445/5311 [01:41<00:17, 49.64it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4450/5311 [01:42<00:17, 48.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4456/5311 [01:42<00:17, 49.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4461/5311 [01:42<00:17, 49.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4466/5311 [01:42<00:18, 45.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4473/5311 [01:42<00:16, 50.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4479/5311 [01:42<00:16, 50.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4485/5311 [01:42<00:16, 50.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4491/5311 [01:42<00:17, 46.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4496/5311 [01:43<00:17, 45.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4502/5311 [01:43<00:17, 47.13it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4508/5311 [01:43<00:16, 48.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4513/5311 [01:43<00:16, 48.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4518/5311 [01:43<00:16, 47.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4523/5311 [01:43<00:17, 44.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4528/5311 [01:43<00:17, 45.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4534/5311 [01:43<00:15, 48.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4539/5311 [01:43<00:16, 47.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4544/5311 [01:44<00:16, 46.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4549/5311 [01:44<00:17, 43.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4554/5311 [01:44<00:16, 44.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4560/5311 [01:44<00:15, 48.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4565/5311 [01:44<00:15, 47.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4570/5311 [01:44<00:15, 47.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4575/5311 [01:44<00:16, 44.25it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4582/5311 [01:44<00:14, 48.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4587/5311 [01:44<00:14, 48.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4592/5311 [01:45<00:15, 45.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4598/5311 [01:45<00:14, 48.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4603/5311 [01:45<00:14, 48.48it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4608/5311 [01:45<00:14, 48.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4613/5311 [01:45<00:14, 47.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4618/5311 [01:45<00:14, 47.38it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4623/5311 [01:45<00:14, 47.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4628/5311 [01:45<00:14, 47.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4633/5311 [01:45<00:14, 47.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4638/5311 [01:46<00:14, 47.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4643/5311 [01:46<00:14, 47.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4649/5311 [01:46<00:13, 48.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4654/5311 [01:46<00:13, 48.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4659/5311 [01:46<00:13, 48.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4664/5311 [01:46<00:13, 47.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4669/5311 [01:46<00:14, 45.79it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4674/5311 [01:46<00:15, 42.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4679/5311 [01:46<00:14, 42.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4685/5311 [01:47<00:13, 45.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4690/5311 [01:47<00:14, 44.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4695/5311 [01:47<00:13, 44.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4700/5311 [01:47<00:13, 44.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4705/5311 [01:47<00:13, 44.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4710/5311 [01:47<00:13, 45.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4715/5311 [01:47<00:14, 42.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4721/5311 [01:47<00:13, 43.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4727/5311 [01:47<00:12, 47.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4733/5311 [01:48<00:11, 48.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4738/5311 [01:48<00:11, 48.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4743/5311 [01:48<00:12, 47.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4749/5311 [01:48<00:11, 48.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4754/5311 [01:48<00:11, 48.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4760/5311 [01:48<00:11, 49.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4765/5311 [01:48<00:12, 44.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4772/5311 [01:48<00:10, 49.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4777/5311 [01:49<00:10, 48.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4783/5311 [01:49<00:10, 49.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4788/5311 [01:49<00:10, 48.03it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4793/5311 [01:49<00:10, 47.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4799/5311 [01:49<00:10, 48.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4805/5311 [01:49<00:10, 49.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4810/5311 [01:49<00:10, 48.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4815/5311 [01:49<00:10, 45.36it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4820/5311 [01:49<00:12, 40.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4825/5311 [01:50<00:12, 37.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4830/5311 [01:50<00:11, 40.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4835/5311 [01:50<00:11, 42.87it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4840/5311 [01:50<00:10, 43.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4845/5311 [01:50<00:10, 45.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4851/5311 [01:50<00:09, 47.28it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4857/5311 [01:50<00:09, 46.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4863/5311 [01:50<00:09, 49.27it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4868/5311 [01:51<00:09, 48.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4873/5311 [01:51<00:09, 45.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4878/5311 [01:51<00:10, 41.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4883/5311 [01:51<00:11, 38.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4887/5311 [01:51<00:11, 38.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4891/5311 [01:51<00:11, 37.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4895/5311 [01:51<00:11, 35.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4899/5311 [01:51<00:12, 31.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4904/5311 [01:52<00:11, 34.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4908/5311 [01:52<00:11, 35.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4914/5311 [01:52<00:09, 41.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4919/5311 [01:52<00:09, 43.45it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4925/5311 [01:52<00:08, 44.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4932/5311 [01:52<00:07, 48.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4937/5311 [01:52<00:07, 48.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4942/5311 [01:52<00:07, 48.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4948/5311 [01:52<00:07, 49.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4953/5311 [01:53<00:07, 49.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4959/5311 [01:53<00:07, 49.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4964/5311 [01:53<00:07, 49.09it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4969/5311 [01:53<00:07, 48.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4974/5311 [01:53<00:08, 39.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4984/5311 [01:53<00:06, 51.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4990/5311 [01:53<00:06, 49.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4996/5311 [01:53<00:06, 49.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5002/5311 [01:54<00:06, 45.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5009/5311 [01:54<00:05, 50.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5015/5311 [01:54<00:06, 48.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5021/5311 [01:54<00:05, 49.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5027/5311 [01:54<00:05, 49.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5033/5311 [01:54<00:05, 49.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5039/5311 [01:54<00:05, 48.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5044/5311 [01:54<00:05, 48.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5050/5311 [01:55<00:05, 49.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5055/5311 [01:55<00:05, 47.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5060/5311 [01:55<00:06, 41.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5065/5311 [01:55<00:06, 38.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5069/5311 [01:55<00:06, 37.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5074/5311 [01:55<00:05, 39.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5079/5311 [01:55<00:05, 42.05it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5084/5311 [01:55<00:05, 43.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5089/5311 [01:56<00:05, 44.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5094/5311 [01:56<00:04, 44.53it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5100/5311 [01:56<00:04, 46.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5105/5311 [01:56<00:04, 47.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5110/5311 [01:56<00:04, 46.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5115/5311 [01:56<00:04, 46.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5120/5311 [01:56<00:04, 47.46it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5126/5311 [01:56<00:03, 47.99it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5131/5311 [01:56<00:04, 43.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5136/5311 [01:57<00:04, 43.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5141/5311 [01:57<00:04, 39.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5146/5311 [01:57<00:04, 38.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5150/5311 [01:57<00:04, 34.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5155/5311 [01:57<00:04, 36.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5159/5311 [01:57<00:04, 32.03it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5164/5311 [01:57<00:04, 35.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5169/5311 [01:57<00:03, 38.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5175/5311 [01:58<00:03, 42.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5180/5311 [01:58<00:02, 44.13it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5185/5311 [01:58<00:02, 44.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5190/5311 [01:58<00:02, 45.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5195/5311 [01:58<00:02, 45.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5200/5311 [01:58<00:02, 46.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5206/5311 [01:58<00:02, 47.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5211/5311 [01:58<00:02, 47.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5216/5311 [01:58<00:02, 47.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5222/5311 [01:59<00:01, 45.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5228/5311 [01:59<00:01, 49.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5234/5311 [01:59<00:01, 49.38it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5239/5311 [01:59<00:01, 48.57it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5244/5311 [01:59<00:01, 48.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5249/5311 [01:59<00:01, 46.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5255/5311 [01:59<00:01, 50.40it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5261/5311 [01:59<00:01, 49.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5267/5311 [02:00<00:00, 46.14it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5274/5311 [02:00<00:00, 50.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5280/5311 [02:00<00:00, 49.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5286/5311 [02:00<00:00, 49.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5291/5311 [02:00<00:00, 48.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5297/5311 [02:00<00:00, 49.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5302/5311 [02:00<00:00, 48.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5307/5311 [02:00<00:00, 44.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5311/5311 [02:00<00:00, 43.92it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.5694
Epoch 1 Step 51 Train Loss: 0.5752
Epoch 1 Step 101 Train Loss: 0.6291
Epoch 1 Step 151 Train Loss: 0.6113
Epoch 1 Step 201 Train Loss: 0.6365
Epoch 1 Step 251 Train Loss: 0.5792
Epoch 1 Step 301 Train Loss: 0.6114
Epoch 1 Step 351 Train Loss: 0.5207
Epoch 1 Step 401 Train Loss: 0.5919
Epoch 1 Step 451 Train Loss: 0.5533
Epoch 1 Step 501 Train Loss: 0.5270
Epoch 1 Step 551 Train Loss: 0.5828
Epoch 1 Step 601 Train Loss: 0.5816
Epoch 1 Step 651 Train Loss: 0.5638
Epoch 1 Step 701 Train Loss: 0.6140
Epoch 1 Step 751 Train Loss: 0.5836
Epoch 1 Step 801 Train Loss: 0.5556
Epoch 1 Step 851 Train Loss: 0.5869
Epoch 1 Step 901 Train Loss: 0.6276
Epoch 1 Step 951 Train Loss: 0.5151
Epoch 1 Step 1001 Train Loss: 0.5694
Epoch 1 Step 1051 Train Loss: 0.5933
Epoch 1 Step 1101 Train Loss: 0.5674
Epoch 1 Step 1151 Train Loss: 0.5357
Epoch 1 Step 1201 Train Loss: 0.5657
Epoch 1 Step 1251 Train Loss: 0.5337
Epoch 1 Step 1301 Train Loss: 0.5989
Epoch 1 Step 1351 Train Loss: 0.6012
Epoch 1 Step 1401 Train Loss: 0.6111
Epoch 1 Step 1451 Train Loss: 0.5363
Epoch 1 Step 1501 Train Loss: 0.5860
Epoch 1 Step 1551 Train Loss: 0.5226
Epoch 1 Step 1601 Train Loss: 0.5463
Epoch 1 Step 1651 Train Loss: 0.5552
Epoch 1 Step 1701 Train Loss: 0.6867
Epoch 1 Step 1751 Train Loss: 0.5511
Epoch 1 Step 1801 Train Loss: 0.4910
Epoch 1 Step 1851 Train Loss: 0.5227
Epoch 1 Step 1901 Train Loss: 0.5941
Epoch 1 Step 1951 Train Loss: 0.5775
Epoch 1 Step 2001 Train Loss: 0.5055
Epoch 1 Step 2051 Train Loss: 0.5567
Epoch 1 Step 2101 Train Loss: 0.5245
Epoch 1 Step 2151 Train Loss: 0.5436
Epoch 1 Step 2201 Train Loss: 0.6260
Epoch 1 Step 2251 Train Loss: 0.5626
Epoch 1 Step 2301 Train Loss: 0.5324
Epoch 1 Step 2351 Train Loss: 0.5665
Epoch 1 Step 2401 Train Loss: 0.5857
Epoch 1 Step 2451 Train Loss: 0.5400
Epoch 1 Step 2501 Train Loss: 0.6523
Epoch 1 Step 2551 Train Loss: 0.5815
Epoch 1 Step 2601 Train Loss: 0.5902
Epoch 1 Step 2651 Train Loss: 0.5890
Epoch 1 Step 2701 Train Loss: 0.6079
Epoch 1 Step 2751 Train Loss: 0.6361
Epoch 1 Step 2801 Train Loss: 0.5914
Epoch 1 Step 2851 Train Loss: 0.6513
Epoch 1 Step 2901 Train Loss: 0.5634
Epoch 1 Step 2951 Train Loss: 0.5554
Epoch 1 Step 3001 Train Loss: 0.6168
Epoch 1 Step 3051 Train Loss: 0.5418
Epoch 1 Step 3101 Train Loss: 0.6352
Epoch 1 Step 3151 Train Loss: 0.5772
Epoch 1 Step 3201 Train Loss: 0.5625
Epoch 1 Step 3251 Train Loss: 0.5847
Epoch 1 Step 3301 Train Loss: 0.5785
Epoch 1 Step 3351 Train Loss: 0.5623
Epoch 1: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0094. 
Train Top 20 DE MSE: 0.1688 Validation Top 20 DE MSE: 0.1856. 
Epoch 2 Step 1 Train Loss: 0.5238
Epoch 2 Step 51 Train Loss: 0.5499
Epoch 2 Step 101 Train Loss: 0.5447
Epoch 2 Step 151 Train Loss: 0.5501
Epoch 2 Step 201 Train Loss: 0.5832
Epoch 2 Step 251 Train Loss: 0.5781
Epoch 2 Step 301 Train Loss: 0.6237
Epoch 2 Step 351 Train Loss: 0.5866
Epoch 2 Step 401 Train Loss: 0.5560
Epoch 2 Step 451 Train Loss: 0.5134
Epoch 2 Step 501 Train Loss: 0.6191
Epoch 2 Step 551 Train Loss: 0.5608
Epoch 2 Step 601 Train Loss: 0.5951
Epoch 2 Step 651 Train Loss: 0.5883
Epoch 2 Step 701 Train Loss: 0.5827
Epoch 2 Step 751 Train Loss: 0.6329
Epoch 2 Step 801 Train Loss: 0.5514
Epoch 2 Step 851 Train Loss: 0.6350
Epoch 2 Step 901 Train Loss: 0.5443
Epoch 2 Step 951 Train Loss: 0.5594
Epoch 2 Step 1001 Train Loss: 0.6300
Epoch 2 Step 1051 Train Loss: 0.6018
Epoch 2 Step 1101 Train Loss: 0.5226
Epoch 2 Step 1151 Train Loss: 0.5498
Epoch 2 Step 1201 Train Loss: 0.5658
Epoch 2 Step 1251 Train Loss: 0.5802
Epoch 2 Step 1301 Train Loss: 0.5170
Epoch 2 Step 1351 Train Loss: 0.5756
Epoch 2 Step 1401 Train Loss: 0.5540
Epoch 2 Step 1451 Train Loss: 0.5272
Epoch 2 Step 1501 Train Loss: 0.6321
Epoch 2 Step 1551 Train Loss: 0.5783
Epoch 2 Step 1601 Train Loss: 0.5883
Epoch 2 Step 1651 Train Loss: 0.5642
Epoch 2 Step 1701 Train Loss: 0.5844
Epoch 2 Step 1751 Train Loss: 0.5330
Epoch 2 Step 1801 Train Loss: 0.5470
Epoch 2 Step 1851 Train Loss: 0.6434
Epoch 2 Step 1901 Train Loss: 0.5989
Epoch 2 Step 1951 Train Loss: 0.5358
Epoch 2 Step 2001 Train Loss: 0.6334
Epoch 2 Step 2051 Train Loss: 0.5709
Epoch 2 Step 2101 Train Loss: 0.5675
Epoch 2 Step 2151 Train Loss: 0.6538
Epoch 2 Step 2201 Train Loss: 0.5449
Epoch 2 Step 2251 Train Loss: 0.5929
Epoch 2 Step 2301 Train Loss: 0.6206
Epoch 2 Step 2351 Train Loss: 0.5941
Epoch 2 Step 2401 Train Loss: 0.5762
Epoch 2 Step 2451 Train Loss: 0.5529
Epoch 2 Step 2501 Train Loss: 0.5924
Epoch 2 Step 2551 Train Loss: 0.5948
Epoch 2 Step 2601 Train Loss: 0.5746
Epoch 2 Step 2651 Train Loss: 0.5763
Epoch 2 Step 2701 Train Loss: 0.6025
Epoch 2 Step 2751 Train Loss: 0.5415
Epoch 2 Step 2801 Train Loss: 0.6250
Epoch 2 Step 2851 Train Loss: 0.6111
Epoch 2 Step 2901 Train Loss: 0.5391
Epoch 2 Step 2951 Train Loss: 0.5527
Epoch 2 Step 3001 Train Loss: 0.5907
Epoch 2 Step 3051 Train Loss: 0.5916
Epoch 2 Step 3101 Train Loss: 0.6305
Epoch 2 Step 3151 Train Loss: 0.5753
Epoch 2 Step 3201 Train Loss: 0.5834
Epoch 2 Step 3251 Train Loss: 0.6052
Epoch 2 Step 3301 Train Loss: 0.5590
Epoch 2 Step 3351 Train Loss: 0.5832
Epoch 2: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1643 Validation Top 20 DE MSE: 0.1860. 
Epoch 3 Step 1 Train Loss: 0.5822
Epoch 3 Step 51 Train Loss: 0.5710
Epoch 3 Step 101 Train Loss: 0.6065
Epoch 3 Step 151 Train Loss: 0.5766
Epoch 3 Step 201 Train Loss: 0.6116
Epoch 3 Step 251 Train Loss: 0.5771
Epoch 3 Step 301 Train Loss: 0.5684
Epoch 3 Step 351 Train Loss: 0.5660
Epoch 3 Step 401 Train Loss: 0.5639
Epoch 3 Step 451 Train Loss: 0.5656
Epoch 3 Step 501 Train Loss: 0.5738
Epoch 3 Step 551 Train Loss: 0.5682
Epoch 3 Step 601 Train Loss: 0.5651
Epoch 3 Step 651 Train Loss: 0.6188
Epoch 3 Step 701 Train Loss: 0.5498
Epoch 3 Step 751 Train Loss: 0.6440
Epoch 3 Step 801 Train Loss: 0.6054
Epoch 3 Step 851 Train Loss: 0.5949
Epoch 3 Step 901 Train Loss: 0.6440
Epoch 3 Step 951 Train Loss: 0.5589
Epoch 3 Step 1001 Train Loss: 0.5934
Epoch 3 Step 1051 Train Loss: 0.5760
Epoch 3 Step 1101 Train Loss: 0.5555
Epoch 3 Step 1151 Train Loss: 0.5457
Epoch 3 Step 1201 Train Loss: 0.6402
Epoch 3 Step 1251 Train Loss: 0.6348
Epoch 3 Step 1301 Train Loss: 0.5967
Epoch 3 Step 1351 Train Loss: 0.5772
Epoch 3 Step 1401 Train Loss: 0.6356
Epoch 3 Step 1451 Train Loss: 0.5869
Epoch 3 Step 1501 Train Loss: 0.5495
Epoch 3 Step 1551 Train Loss: 0.5383
Epoch 3 Step 1601 Train Loss: 0.5849
Epoch 3 Step 1651 Train Loss: 0.6726
Epoch 3 Step 1701 Train Loss: 0.6014
Epoch 3 Step 1751 Train Loss: 0.5827
Epoch 3 Step 1801 Train Loss: 0.5863
Epoch 3 Step 1851 Train Loss: 0.5428
Epoch 3 Step 1901 Train Loss: 0.6075
Epoch 3 Step 1951 Train Loss: 0.5849
Epoch 3 Step 2001 Train Loss: 0.5620
Epoch 3 Step 2051 Train Loss: 0.6021
Epoch 3 Step 2101 Train Loss: 0.5934
Epoch 3 Step 2151 Train Loss: 0.5597
Epoch 3 Step 2201 Train Loss: 0.5839
Epoch 3 Step 2251 Train Loss: 0.5307
Epoch 3 Step 2301 Train Loss: 0.5555
Epoch 3 Step 2351 Train Loss: 0.6124
Epoch 3 Step 2401 Train Loss: 0.6267
Epoch 3 Step 2451 Train Loss: 0.5576
Epoch 3 Step 2501 Train Loss: 0.5927
Epoch 3 Step 2551 Train Loss: 0.5601
Epoch 3 Step 2601 Train Loss: 0.5485
Epoch 3 Step 2651 Train Loss: 0.6017
Epoch 3 Step 2701 Train Loss: 0.6373
Epoch 3 Step 2751 Train Loss: 0.5945
Epoch 3 Step 2801 Train Loss: 0.5775
Epoch 3 Step 2851 Train Loss: 0.6331
Epoch 3 Step 2901 Train Loss: 0.5977
Epoch 3 Step 2951 Train Loss: 0.5736
Epoch 3 Step 3001 Train Loss: 0.5344
Epoch 3 Step 3051 Train Loss: 0.5045
Epoch 3 Step 3101 Train Loss: 0.5643
Epoch 3 Step 3151 Train Loss: 0.5663
Epoch 3 Step 3201 Train Loss: 0.6112
Epoch 3 Step 3251 Train Loss: 0.6439
Epoch 3 Step 3301 Train Loss: 0.6235
Epoch 3 Step 3351 Train Loss: 0.5611
Epoch 3: Train Overall MSE: 0.0106 Validation Overall MSE: 0.0115. 
Train Top 20 DE MSE: 0.1812 Validation Top 20 DE MSE: 0.1894. 
Epoch 4 Step 1 Train Loss: 0.5744
Epoch 4 Step 51 Train Loss: 0.5900
Epoch 4 Step 101 Train Loss: 0.6557
Epoch 4 Step 151 Train Loss: 0.5295
Epoch 4 Step 201 Train Loss: 0.4766
Epoch 4 Step 251 Train Loss: 0.6385
Epoch 4 Step 301 Train Loss: 0.6630
Epoch 4 Step 351 Train Loss: 0.6273
Epoch 4 Step 401 Train Loss: 0.5537
Epoch 4 Step 451 Train Loss: 0.6282
Epoch 4 Step 501 Train Loss: 0.5618
Epoch 4 Step 551 Train Loss: 0.5897
Epoch 4 Step 601 Train Loss: 0.5774
Epoch 4 Step 651 Train Loss: 0.5487
Epoch 4 Step 701 Train Loss: 0.5086
Epoch 4 Step 751 Train Loss: 0.6152
Epoch 4 Step 801 Train Loss: 0.5450
Epoch 4 Step 851 Train Loss: 0.5870
Epoch 4 Step 901 Train Loss: 0.6029
Epoch 4 Step 951 Train Loss: 0.5851
Epoch 4 Step 1001 Train Loss: 0.6339
Epoch 4 Step 1051 Train Loss: 0.5765
Epoch 4 Step 1101 Train Loss: 0.5782
Epoch 4 Step 1151 Train Loss: 0.6352
Epoch 4 Step 1201 Train Loss: 0.5679
Epoch 4 Step 1251 Train Loss: 0.6002
Epoch 4 Step 1301 Train Loss: 0.6285
Epoch 4 Step 1351 Train Loss: 0.6092
Epoch 4 Step 1401 Train Loss: 0.6019
Epoch 4 Step 1451 Train Loss: 0.6052
Epoch 4 Step 1501 Train Loss: 0.5934
Epoch 4 Step 1551 Train Loss: 0.5970
Epoch 4 Step 1601 Train Loss: 0.5460
Epoch 4 Step 1651 Train Loss: 0.5484
Epoch 4 Step 1701 Train Loss: 0.6092
Epoch 4 Step 1751 Train Loss: 0.5748
Epoch 4 Step 1801 Train Loss: 0.5827
Epoch 4 Step 1851 Train Loss: 0.5723
Epoch 4 Step 1901 Train Loss: 0.6311
Epoch 4 Step 1951 Train Loss: 0.5666
Epoch 4 Step 2001 Train Loss: 0.5385
Epoch 4 Step 2051 Train Loss: 0.5324
Epoch 4 Step 2101 Train Loss: 0.6314
Epoch 4 Step 2151 Train Loss: 0.5921
Epoch 4 Step 2201 Train Loss: 0.5991
Epoch 4 Step 2251 Train Loss: 0.5392
Epoch 4 Step 2301 Train Loss: 0.6070
Epoch 4 Step 2351 Train Loss: 0.6383
Epoch 4 Step 2401 Train Loss: 0.6517
Epoch 4 Step 2451 Train Loss: 0.5729
Epoch 4 Step 2501 Train Loss: 0.5446
Epoch 4 Step 2551 Train Loss: 0.5399
Epoch 4 Step 2601 Train Loss: 0.6375
Epoch 4 Step 2651 Train Loss: 0.6102
Epoch 4 Step 2701 Train Loss: 0.6692
Epoch 4 Step 2751 Train Loss: 0.6126
Epoch 4 Step 2801 Train Loss: 0.5287
Epoch 4 Step 2851 Train Loss: 0.5872
Epoch 4 Step 2901 Train Loss: 0.5769
Epoch 4 Step 2951 Train Loss: 0.5739
Epoch 4 Step 3001 Train Loss: 0.6024
Epoch 4 Step 3051 Train Loss: 0.5855
Epoch 4 Step 3101 Train Loss: 0.5878
Epoch 4 Step 3151 Train Loss: 0.5551
Epoch 4 Step 3201 Train Loss: 0.5410
Epoch 4 Step 3251 Train Loss: 0.5642
Epoch 4 Step 3301 Train Loss: 0.5322
Epoch 4 Step 3351 Train Loss: 0.5727
Epoch 4: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0093. 
Train Top 20 DE MSE: 0.1620 Validation Top 20 DE MSE: 0.1876. 
Epoch 5 Step 1 Train Loss: 0.5726
Epoch 5 Step 51 Train Loss: 0.5776
Epoch 5 Step 101 Train Loss: 0.5951
Epoch 5 Step 151 Train Loss: 0.5984
Epoch 5 Step 201 Train Loss: 0.5326
Epoch 5 Step 251 Train Loss: 0.5265
Epoch 5 Step 301 Train Loss: 0.5821
Epoch 5 Step 351 Train Loss: 0.6606
Epoch 5 Step 401 Train Loss: 0.6131
Epoch 5 Step 451 Train Loss: 0.6162
Epoch 5 Step 501 Train Loss: 0.5472
Epoch 5 Step 551 Train Loss: 0.5726
Epoch 5 Step 601 Train Loss: 0.6043
Epoch 5 Step 651 Train Loss: 0.5783
Epoch 5 Step 701 Train Loss: 0.5700
Epoch 5 Step 751 Train Loss: 0.5517
Epoch 5 Step 801 Train Loss: 0.5563
Epoch 5 Step 851 Train Loss: 0.5598
Epoch 5 Step 901 Train Loss: 0.5795
Epoch 5 Step 951 Train Loss: 0.6132
Epoch 5 Step 1001 Train Loss: 0.5481
Epoch 5 Step 1051 Train Loss: 0.6135
Epoch 5 Step 1101 Train Loss: 0.6372
Epoch 5 Step 1151 Train Loss: 0.6080
Epoch 5 Step 1201 Train Loss: 0.6166
Epoch 5 Step 1251 Train Loss: 0.5809
Epoch 5 Step 1301 Train Loss: 0.5986
Epoch 5 Step 1351 Train Loss: 0.5957
Epoch 5 Step 1401 Train Loss: 0.5354
Epoch 5 Step 1451 Train Loss: 0.5950
Epoch 5 Step 1501 Train Loss: 0.5664
Epoch 5 Step 1551 Train Loss: 0.5613
Epoch 5 Step 1601 Train Loss: 0.6011
Epoch 5 Step 1651 Train Loss: 0.5486
Epoch 5 Step 1701 Train Loss: 0.6285
Epoch 5 Step 1751 Train Loss: 0.6389
Epoch 5 Step 1801 Train Loss: 0.5789
Epoch 5 Step 1851 Train Loss: 0.5991
Epoch 5 Step 1901 Train Loss: 0.5929
Epoch 5 Step 1951 Train Loss: 0.5292
Epoch 5 Step 2001 Train Loss: 0.5307
Epoch 5 Step 2051 Train Loss: 0.6412
Epoch 5 Step 2101 Train Loss: 0.5641
Epoch 5 Step 2151 Train Loss: 0.5744
Epoch 5 Step 2201 Train Loss: 0.6103
Epoch 5 Step 2251 Train Loss: 0.5663
Epoch 5 Step 2301 Train Loss: 0.5719
Epoch 5 Step 2351 Train Loss: 0.5520
Epoch 5 Step 2401 Train Loss: 0.5496
Epoch 5 Step 2451 Train Loss: 0.5747
Epoch 5 Step 2501 Train Loss: 0.6128
Epoch 5 Step 2551 Train Loss: 0.5893
Epoch 5 Step 2601 Train Loss: 0.5312
Epoch 5 Step 2651 Train Loss: 0.5919
Epoch 5 Step 2701 Train Loss: 0.5635
Epoch 5 Step 2751 Train Loss: 0.6023
Epoch 5 Step 2801 Train Loss: 0.6118
Epoch 5 Step 2851 Train Loss: 0.5566
Epoch 5 Step 2901 Train Loss: 0.5800
Epoch 5 Step 2951 Train Loss: 0.5580
Epoch 5 Step 3001 Train Loss: 0.5558
Epoch 5 Step 3051 Train Loss: 0.5716
Epoch 5 Step 3101 Train Loss: 0.5176
Epoch 5 Step 3151 Train Loss: 0.6427
Epoch 5 Step 3201 Train Loss: 0.6407
Epoch 5 Step 3251 Train Loss: 0.5722
Epoch 5 Step 3301 Train Loss: 0.5667
Epoch 5 Step 3351 Train Loss: 0.5773
Epoch 5: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0091. 
Train Top 20 DE MSE: 0.1628 Validation Top 20 DE MSE: 0.1868. 
Epoch 6 Step 1 Train Loss: 0.5922
Epoch 6 Step 51 Train Loss: 0.5163
Epoch 6 Step 101 Train Loss: 0.6043
Epoch 6 Step 151 Train Loss: 0.6073
Epoch 6 Step 201 Train Loss: 0.6124
Epoch 6 Step 251 Train Loss: 0.5736
Epoch 6 Step 301 Train Loss: 0.5593
Epoch 6 Step 351 Train Loss: 0.5693
Epoch 6 Step 401 Train Loss: 0.5267
Epoch 6 Step 451 Train Loss: 0.5918
Epoch 6 Step 501 Train Loss: 0.5666
Epoch 6 Step 551 Train Loss: 0.5967
Epoch 6 Step 601 Train Loss: 0.5849
Epoch 6 Step 651 Train Loss: 0.5918
Epoch 6 Step 701 Train Loss: 0.6240
Epoch 6 Step 751 Train Loss: 0.5818
Epoch 6 Step 801 Train Loss: 0.6079
Epoch 6 Step 851 Train Loss: 0.5657
Epoch 6 Step 901 Train Loss: 0.5387
Epoch 6 Step 951 Train Loss: 0.5595
Epoch 6 Step 1001 Train Loss: 0.5744
Epoch 6 Step 1051 Train Loss: 0.6183
Epoch 6 Step 1101 Train Loss: 0.5801
Epoch 6 Step 1151 Train Loss: 0.6161
Epoch 6 Step 1201 Train Loss: 0.5963
Epoch 6 Step 1251 Train Loss: 0.5910
Epoch 6 Step 1301 Train Loss: 0.5925
Epoch 6 Step 1351 Train Loss: 0.6031
Epoch 6 Step 1401 Train Loss: 0.5924
Epoch 6 Step 1451 Train Loss: 0.5267
Epoch 6 Step 1501 Train Loss: 0.5235
Epoch 6 Step 1551 Train Loss: 0.6231
Epoch 6 Step 1601 Train Loss: 0.5739
Epoch 6 Step 1651 Train Loss: 0.5486
Epoch 6 Step 1701 Train Loss: 0.5889
Epoch 6 Step 1751 Train Loss: 0.6376
Epoch 6 Step 1801 Train Loss: 0.5395
Epoch 6 Step 1851 Train Loss: 0.5844
Epoch 6 Step 1901 Train Loss: 0.5802
Epoch 6 Step 1951 Train Loss: 0.6375
Epoch 6 Step 2001 Train Loss: 0.6190
Epoch 6 Step 2051 Train Loss: 0.5739
Epoch 6 Step 2101 Train Loss: 0.5901
Epoch 6 Step 2151 Train Loss: 0.6028
Epoch 6 Step 2201 Train Loss: 0.5495
Epoch 6 Step 2251 Train Loss: 0.5889
Epoch 6 Step 2301 Train Loss: 0.5867
Epoch 6 Step 2351 Train Loss: 0.5733
Epoch 6 Step 2401 Train Loss: 0.5859
Epoch 6 Step 2451 Train Loss: 0.6156
Epoch 6 Step 2501 Train Loss: 0.5142
Epoch 6 Step 2551 Train Loss: 0.5577
Epoch 6 Step 2601 Train Loss: 0.5627
Epoch 6 Step 2651 Train Loss: 0.5522
Epoch 6 Step 2701 Train Loss: 0.5786
Epoch 6 Step 2751 Train Loss: 0.6311
Epoch 6 Step 2801 Train Loss: 0.6224
Epoch 6 Step 2851 Train Loss: 0.6366
Epoch 6 Step 2901 Train Loss: 0.5734
Epoch 6 Step 2951 Train Loss: 0.6226
Epoch 6 Step 3001 Train Loss: 0.6040
Epoch 6 Step 3051 Train Loss: 0.5749
Epoch 6 Step 3101 Train Loss: 0.5300
Epoch 6 Step 3151 Train Loss: 0.6903
Epoch 6 Step 3201 Train Loss: 0.5979
Epoch 6 Step 3251 Train Loss: 0.5371
Epoch 6 Step 3301 Train Loss: 0.6090
Epoch 6 Step 3351 Train Loss: 0.5574
Epoch 6: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0093. 
Train Top 20 DE MSE: 0.1596 Validation Top 20 DE MSE: 0.1836. 
Epoch 7 Step 1 Train Loss: 0.6239
Epoch 7 Step 51 Train Loss: 0.5904
Epoch 7 Step 101 Train Loss: 0.5810
Epoch 7 Step 151 Train Loss: 0.5599
Epoch 7 Step 201 Train Loss: 0.5802
Epoch 7 Step 251 Train Loss: 0.5958
Epoch 7 Step 301 Train Loss: 0.5893
Epoch 7 Step 351 Train Loss: 0.5588
Epoch 7 Step 401 Train Loss: 0.5497
Epoch 7 Step 451 Train Loss: 0.5677
Epoch 7 Step 501 Train Loss: 0.6475
Epoch 7 Step 551 Train Loss: 0.5903
Epoch 7 Step 601 Train Loss: 0.5710
Epoch 7 Step 651 Train Loss: 0.5301
Epoch 7 Step 701 Train Loss: 0.5569
Epoch 7 Step 751 Train Loss: 0.5689
Epoch 7 Step 801 Train Loss: 0.5300
Epoch 7 Step 851 Train Loss: 0.5921
Epoch 7 Step 901 Train Loss: 0.6439
Epoch 7 Step 951 Train Loss: 0.5610
Epoch 7 Step 1001 Train Loss: 0.6953
Epoch 7 Step 1051 Train Loss: 0.5367
Epoch 7 Step 1101 Train Loss: 0.5512
Epoch 7 Step 1151 Train Loss: 0.5467
Epoch 7 Step 1201 Train Loss: 0.5787
Epoch 7 Step 1251 Train Loss: 0.6205
Epoch 7 Step 1301 Train Loss: 0.5572
Epoch 7 Step 1351 Train Loss: 0.6115
Epoch 7 Step 1401 Train Loss: 0.5827
Epoch 7 Step 1451 Train Loss: 0.5476
Epoch 7 Step 1501 Train Loss: 0.5539
Epoch 7 Step 1551 Train Loss: 0.5242
Epoch 7 Step 1601 Train Loss: 0.5963
Epoch 7 Step 1651 Train Loss: 0.5967
Epoch 7 Step 1701 Train Loss: 0.6110
Epoch 7 Step 1751 Train Loss: 0.5431
Epoch 7 Step 1801 Train Loss: 0.5861
Epoch 7 Step 1851 Train Loss: 0.5559
Epoch 7 Step 1901 Train Loss: 0.5587
Epoch 7 Step 1951 Train Loss: 0.6273
Epoch 7 Step 2001 Train Loss: 0.5342
Epoch 7 Step 2051 Train Loss: 0.6404
Epoch 7 Step 2101 Train Loss: 0.5916
Epoch 7 Step 2151 Train Loss: 0.5822
Epoch 7 Step 2201 Train Loss: 0.6008
Epoch 7 Step 2251 Train Loss: 0.6264
Epoch 7 Step 2301 Train Loss: 0.5316
Epoch 7 Step 2351 Train Loss: 0.5842
Epoch 7 Step 2401 Train Loss: 0.5747
Epoch 7 Step 2451 Train Loss: 0.6069
Epoch 7 Step 2501 Train Loss: 0.5922
Epoch 7 Step 2551 Train Loss: 0.6412
Epoch 7 Step 2601 Train Loss: 0.5835
Epoch 7 Step 2651 Train Loss: 0.6161
Epoch 7 Step 2701 Train Loss: 0.5728
Epoch 7 Step 2751 Train Loss: 0.5634
Epoch 7 Step 2801 Train Loss: 0.5691
Epoch 7 Step 2851 Train Loss: 0.6228
Epoch 7 Step 2901 Train Loss: 0.5551
Epoch 7 Step 2951 Train Loss: 0.6334
Epoch 7 Step 3001 Train Loss: 0.5824
Epoch 7 Step 3051 Train Loss: 0.5910
Epoch 7 Step 3101 Train Loss: 0.5629
Epoch 7 Step 3151 Train Loss: 0.5232
Epoch 7 Step 3201 Train Loss: 0.5949
Epoch 7 Step 3251 Train Loss: 0.5800
Epoch 7 Step 3301 Train Loss: 0.5964
Epoch 7 Step 3351 Train Loss: 0.5630
Epoch 7: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1611 Validation Top 20 DE MSE: 0.1876. 
Epoch 8 Step 1 Train Loss: 0.5690
Epoch 8 Step 51 Train Loss: 0.5879
Epoch 8 Step 101 Train Loss: 0.5423
Epoch 8 Step 151 Train Loss: 0.5898
Epoch 8 Step 201 Train Loss: 0.5276
Epoch 8 Step 251 Train Loss: 0.5606
Epoch 8 Step 301 Train Loss: 0.6123
Epoch 8 Step 351 Train Loss: 0.5225
Epoch 8 Step 401 Train Loss: 0.5535
Epoch 8 Step 451 Train Loss: 0.5704
Epoch 8 Step 501 Train Loss: 0.5613
Epoch 8 Step 551 Train Loss: 0.6011
Epoch 8 Step 601 Train Loss: 0.5571
Epoch 8 Step 651 Train Loss: 0.5583
Epoch 8 Step 701 Train Loss: 0.5803
Epoch 8 Step 751 Train Loss: 0.5032
Epoch 8 Step 801 Train Loss: 0.5529
Epoch 8 Step 851 Train Loss: 0.5716
Epoch 8 Step 901 Train Loss: 0.5488
Epoch 8 Step 951 Train Loss: 0.5549
Epoch 8 Step 1001 Train Loss: 0.6145
Epoch 8 Step 1051 Train Loss: 0.5424
Epoch 8 Step 1101 Train Loss: 0.5778
Epoch 8 Step 1151 Train Loss: 0.6088
Epoch 8 Step 1201 Train Loss: 0.6382
Epoch 8 Step 1251 Train Loss: 0.6014
Epoch 8 Step 1301 Train Loss: 0.6290
Epoch 8 Step 1351 Train Loss: 0.5488
Epoch 8 Step 1401 Train Loss: 0.5331
Epoch 8 Step 1451 Train Loss: 0.5696
Epoch 8 Step 1501 Train Loss: 0.5924
Epoch 8 Step 1551 Train Loss: 0.5845
Epoch 8 Step 1601 Train Loss: 0.6254
Epoch 8 Step 1651 Train Loss: 0.5707
Epoch 8 Step 1701 Train Loss: 0.6374
Epoch 8 Step 1751 Train Loss: 0.6083
Epoch 8 Step 1801 Train Loss: 0.5575
Epoch 8 Step 1851 Train Loss: 0.5691
Epoch 8 Step 1901 Train Loss: 0.5242
Epoch 8 Step 1951 Train Loss: 0.6043
Epoch 8 Step 2001 Train Loss: 0.5830
Epoch 8 Step 2051 Train Loss: 0.6297
Epoch 8 Step 2101 Train Loss: 0.5873
Epoch 8 Step 2151 Train Loss: 0.6040
Epoch 8 Step 2201 Train Loss: 0.5400
Epoch 8 Step 2251 Train Loss: 0.5536
Epoch 8 Step 2301 Train Loss: 0.5384
Epoch 8 Step 2351 Train Loss: 0.6032
Epoch 8 Step 2401 Train Loss: 0.6004
Epoch 8 Step 2451 Train Loss: 0.5753
Epoch 8 Step 2501 Train Loss: 0.6144
Epoch 8 Step 2551 Train Loss: 0.5954
Epoch 8 Step 2601 Train Loss: 0.5891
Epoch 8 Step 2651 Train Loss: 0.6334
Epoch 8 Step 2701 Train Loss: 0.5741
Epoch 8 Step 2751 Train Loss: 0.6209
Epoch 8 Step 2801 Train Loss: 0.6059
Epoch 8 Step 2851 Train Loss: 0.5964
Epoch 8 Step 2901 Train Loss: 0.5976
Epoch 8 Step 2951 Train Loss: 0.5968
Epoch 8 Step 3001 Train Loss: 0.5920
Epoch 8 Step 3051 Train Loss: 0.5619
Epoch 8 Step 3101 Train Loss: 0.5956
Epoch 8 Step 3151 Train Loss: 0.5821
Epoch 8 Step 3201 Train Loss: 0.5701
Epoch 8 Step 3251 Train Loss: 0.5630
Epoch 8 Step 3301 Train Loss: 0.5666
Epoch 8 Step 3351 Train Loss: 0.5814
Epoch 8: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0091. 
Train Top 20 DE MSE: 0.1623 Validation Top 20 DE MSE: 0.1874. 
Epoch 9 Step 1 Train Loss: 0.5945
Epoch 9 Step 51 Train Loss: 0.5698
Epoch 9 Step 101 Train Loss: 0.5988
Epoch 9 Step 151 Train Loss: 0.6025
Epoch 9 Step 201 Train Loss: 0.5595
Epoch 9 Step 251 Train Loss: 0.6285
Epoch 9 Step 301 Train Loss: 0.5574
Epoch 9 Step 351 Train Loss: 0.5878
Epoch 9 Step 401 Train Loss: 0.5534
Epoch 9 Step 451 Train Loss: 0.5547
Epoch 9 Step 501 Train Loss: 0.6298
Epoch 9 Step 551 Train Loss: 0.5329
Epoch 9 Step 601 Train Loss: 0.6192
Epoch 9 Step 651 Train Loss: 0.6198
Epoch 9 Step 701 Train Loss: 0.5617
Epoch 9 Step 751 Train Loss: 0.5252
Epoch 9 Step 801 Train Loss: 0.5691
Epoch 9 Step 851 Train Loss: 0.5641
Epoch 9 Step 901 Train Loss: 0.5739
Epoch 9 Step 951 Train Loss: 0.5349
Epoch 9 Step 1001 Train Loss: 0.5856
Epoch 9 Step 1051 Train Loss: 0.6024
Epoch 9 Step 1101 Train Loss: 0.5341
Epoch 9 Step 1151 Train Loss: 0.6002
Epoch 9 Step 1201 Train Loss: 0.5641
Epoch 9 Step 1251 Train Loss: 0.5926
Epoch 9 Step 1301 Train Loss: 0.5453
Epoch 9 Step 1351 Train Loss: 0.5991
Epoch 9 Step 1401 Train Loss: 0.5463
Epoch 9 Step 1451 Train Loss: 0.5991
Epoch 9 Step 1501 Train Loss: 0.5435
Epoch 9 Step 1551 Train Loss: 0.5858
Epoch 9 Step 1601 Train Loss: 0.5846
Epoch 9 Step 1651 Train Loss: 0.5957
Epoch 9 Step 1701 Train Loss: 0.5655
Epoch 9 Step 1751 Train Loss: 0.5947
Epoch 9 Step 1801 Train Loss: 0.5616
Epoch 9 Step 1851 Train Loss: 0.5598
Epoch 9 Step 1901 Train Loss: 0.6061
Epoch 9 Step 1951 Train Loss: 0.6183
Epoch 9 Step 2001 Train Loss: 0.5587
Epoch 9 Step 2051 Train Loss: 0.5676
Epoch 9 Step 2101 Train Loss: 0.6513
Epoch 9 Step 2151 Train Loss: 0.5719
Epoch 9 Step 2201 Train Loss: 0.6317
Epoch 9 Step 2251 Train Loss: 0.5597
Epoch 9 Step 2301 Train Loss: 0.6367
Epoch 9 Step 2351 Train Loss: 0.6091
Epoch 9 Step 2401 Train Loss: 0.6466
Epoch 9 Step 2451 Train Loss: 0.5871
Epoch 9 Step 2501 Train Loss: 0.5323
Epoch 9 Step 2551 Train Loss: 0.6235
Epoch 9 Step 2601 Train Loss: 0.5767
Epoch 9 Step 2651 Train Loss: 0.6049
Epoch 9 Step 2701 Train Loss: 0.5558
Epoch 9 Step 2751 Train Loss: 0.5682
Epoch 9 Step 2801 Train Loss: 0.5675
Epoch 9 Step 2851 Train Loss: 0.5506
Epoch 9 Step 2901 Train Loss: 0.5513
Epoch 9 Step 2951 Train Loss: 0.5434
Epoch 9 Step 3001 Train Loss: 0.5440
Epoch 9 Step 3051 Train Loss: 0.5331
Epoch 9 Step 3101 Train Loss: 0.6268
Epoch 9 Step 3151 Train Loss: 0.6137
Epoch 9 Step 3201 Train Loss: 0.5935
Epoch 9 Step 3251 Train Loss: 0.5673
Epoch 9 Step 3301 Train Loss: 0.5928
Epoch 9 Step 3351 Train Loss: 0.6173
Epoch 9: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1616 Validation Top 20 DE MSE: 0.1868. 
Epoch 10 Step 1 Train Loss: 0.5814
Epoch 10 Step 51 Train Loss: 0.5733
Epoch 10 Step 101 Train Loss: 0.6012
Epoch 10 Step 151 Train Loss: 0.5688
Epoch 10 Step 201 Train Loss: 0.5667
Epoch 10 Step 251 Train Loss: 0.5588
Epoch 10 Step 301 Train Loss: 0.5975
Epoch 10 Step 351 Train Loss: 0.5190
Epoch 10 Step 401 Train Loss: 0.5824
Epoch 10 Step 451 Train Loss: 0.5544
Epoch 10 Step 501 Train Loss: 0.5775
Epoch 10 Step 551 Train Loss: 0.5827
Epoch 10 Step 601 Train Loss: 0.5833
Epoch 10 Step 651 Train Loss: 0.5818
Epoch 10 Step 701 Train Loss: 0.5609
Epoch 10 Step 751 Train Loss: 0.6439
Epoch 10 Step 801 Train Loss: 0.5754
Epoch 10 Step 851 Train Loss: 0.6142
Epoch 10 Step 901 Train Loss: 0.5824
Epoch 10 Step 951 Train Loss: 0.5666
Epoch 10 Step 1001 Train Loss: 0.5934
Epoch 10 Step 1051 Train Loss: 0.5421
Epoch 10 Step 1101 Train Loss: 0.6482
Epoch 10 Step 1151 Train Loss: 0.5768
Epoch 10 Step 1201 Train Loss: 0.5651
Epoch 10 Step 1251 Train Loss: 0.5779
Epoch 10 Step 1301 Train Loss: 0.5950
Epoch 10 Step 1351 Train Loss: 0.5821
Epoch 10 Step 1401 Train Loss: 0.6284
Epoch 10 Step 1451 Train Loss: 0.6086
Epoch 10 Step 1501 Train Loss: 0.5863
Epoch 10 Step 1551 Train Loss: 0.5261
Epoch 10 Step 1601 Train Loss: 0.5662
Epoch 10 Step 1651 Train Loss: 0.6157
Epoch 10 Step 1701 Train Loss: 0.6090
Epoch 10 Step 1751 Train Loss: 0.5483
Epoch 10 Step 1801 Train Loss: 0.5596
Epoch 10 Step 1851 Train Loss: 0.5256
Epoch 10 Step 1901 Train Loss: 0.5807
Epoch 10 Step 1951 Train Loss: 0.5421
Epoch 10 Step 2001 Train Loss: 0.6462
Epoch 10 Step 2051 Train Loss: 0.5317
Epoch 10 Step 2101 Train Loss: 0.5898
Epoch 10 Step 2151 Train Loss: 0.5409
Epoch 10 Step 2201 Train Loss: 0.6444
Epoch 10 Step 2251 Train Loss: 0.5264
Epoch 10 Step 2301 Train Loss: 0.5198
Epoch 10 Step 2351 Train Loss: 0.5855
Epoch 10 Step 2401 Train Loss: 0.6218
Epoch 10 Step 2451 Train Loss: 0.5510
Epoch 10 Step 2501 Train Loss: 0.6516
Epoch 10 Step 2551 Train Loss: 0.6289
Epoch 10 Step 2601 Train Loss: 0.5837
Epoch 10 Step 2651 Train Loss: 0.6005
Epoch 10 Step 2701 Train Loss: 0.5905
Epoch 10 Step 2751 Train Loss: 0.5105
Epoch 10 Step 2801 Train Loss: 0.5911
Epoch 10 Step 2851 Train Loss: 0.5666
Epoch 10 Step 2901 Train Loss: 0.5417
Epoch 10 Step 2951 Train Loss: 0.6029
Epoch 10 Step 3001 Train Loss: 0.5483
Epoch 10 Step 3051 Train Loss: 0.5796
Epoch 10 Step 3101 Train Loss: 0.6213
Epoch 10 Step 3151 Train Loss: 0.5266
Epoch 10 Step 3201 Train Loss: 0.5672
Epoch 10 Step 3251 Train Loss: 0.5764
Epoch 10 Step 3301 Train Loss: 0.5796
Epoch 10 Step 3351 Train Loss: 0.6177
Epoch 10: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1592 Validation Top 20 DE MSE: 0.1860. 
Epoch 11 Step 1 Train Loss: 0.5382
Epoch 11 Step 51 Train Loss: 0.5687
Epoch 11 Step 101 Train Loss: 0.6210
Epoch 11 Step 151 Train Loss: 0.6282
Epoch 11 Step 201 Train Loss: 0.6483
Epoch 11 Step 251 Train Loss: 0.5808
Epoch 11 Step 301 Train Loss: 0.5802
Epoch 11 Step 351 Train Loss: 0.5609
Epoch 11 Step 401 Train Loss: 0.5528
Epoch 11 Step 451 Train Loss: 0.5797
Epoch 11 Step 501 Train Loss: 0.5655
Epoch 11 Step 551 Train Loss: 0.6369
Epoch 11 Step 601 Train Loss: 0.5853
Epoch 11 Step 651 Train Loss: 0.5172
Epoch 11 Step 701 Train Loss: 0.4992
Epoch 11 Step 751 Train Loss: 0.5760
Epoch 11 Step 801 Train Loss: 0.5636
Epoch 11 Step 851 Train Loss: 0.5291
Epoch 11 Step 901 Train Loss: 0.5723
Epoch 11 Step 951 Train Loss: 0.6244
Epoch 11 Step 1001 Train Loss: 0.6201
Epoch 11 Step 1051 Train Loss: 0.5706
Epoch 11 Step 1101 Train Loss: 0.6086
Epoch 11 Step 1151 Train Loss: 0.5858
Epoch 11 Step 1201 Train Loss: 0.6141
Epoch 11 Step 1251 Train Loss: 0.5635
Epoch 11 Step 1301 Train Loss: 0.5597
Epoch 11 Step 1351 Train Loss: 0.5775
Epoch 11 Step 1401 Train Loss: 0.5878
Epoch 11 Step 1451 Train Loss: 0.5857
Epoch 11 Step 1501 Train Loss: 0.5879
Epoch 11 Step 1551 Train Loss: 0.5962
Epoch 11 Step 1601 Train Loss: 0.5939
Epoch 11 Step 1651 Train Loss: 0.5888
Epoch 11 Step 1701 Train Loss: 0.5902
Epoch 11 Step 1751 Train Loss: 0.6011
Epoch 11 Step 1801 Train Loss: 0.5361
Epoch 11 Step 1851 Train Loss: 0.5615
Epoch 11 Step 1901 Train Loss: 0.5351
Epoch 11 Step 1951 Train Loss: 0.5596
Epoch 11 Step 2001 Train Loss: 0.5302
Epoch 11 Step 2051 Train Loss: 0.5788
Epoch 11 Step 2101 Train Loss: 0.5338
Epoch 11 Step 2151 Train Loss: 0.5956
Epoch 11 Step 2201 Train Loss: 0.6915
Epoch 11 Step 2251 Train Loss: 0.6483
Epoch 11 Step 2301 Train Loss: 0.5808
Epoch 11 Step 2351 Train Loss: 0.5915
Epoch 11 Step 2401 Train Loss: 0.6185
Epoch 11 Step 2451 Train Loss: 0.5755
Epoch 11 Step 2501 Train Loss: 0.5892
Epoch 11 Step 2551 Train Loss: 0.5756
Epoch 11 Step 2601 Train Loss: 0.6393
Epoch 11 Step 2651 Train Loss: 0.5611
Epoch 11 Step 2701 Train Loss: 0.5983
Epoch 11 Step 2751 Train Loss: 0.6031
Epoch 11 Step 2801 Train Loss: 0.5256
Epoch 11 Step 2851 Train Loss: 0.6343
Epoch 11 Step 2901 Train Loss: 0.5662
Epoch 11 Step 2951 Train Loss: 0.5813
Epoch 11 Step 3001 Train Loss: 0.5728
Epoch 11 Step 3051 Train Loss: 0.6326
Epoch 11 Step 3101 Train Loss: 0.6154
Epoch 11 Step 3151 Train Loss: 0.5924
Epoch 11 Step 3201 Train Loss: 0.6043
Epoch 11 Step 3251 Train Loss: 0.5727
Epoch 11 Step 3301 Train Loss: 0.5164
Epoch 11 Step 3351 Train Loss: 0.6219
Epoch 11: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1618 Validation Top 20 DE MSE: 0.1877. 
Epoch 12 Step 1 Train Loss: 0.5858
Epoch 12 Step 51 Train Loss: 0.5289
Epoch 12 Step 101 Train Loss: 0.5609
Epoch 12 Step 151 Train Loss: 0.5790
Epoch 12 Step 201 Train Loss: 0.5468
Epoch 12 Step 251 Train Loss: 0.6206
Epoch 12 Step 301 Train Loss: 0.5522
Epoch 12 Step 351 Train Loss: 0.6130
Epoch 12 Step 401 Train Loss: 0.5816
Epoch 12 Step 451 Train Loss: 0.6033
Epoch 12 Step 501 Train Loss: 0.7137
Epoch 12 Step 551 Train Loss: 0.5765
Epoch 12 Step 601 Train Loss: 0.6029
Epoch 12 Step 651 Train Loss: 0.6017
Epoch 12 Step 701 Train Loss: 0.5527
Epoch 12 Step 751 Train Loss: 0.5794
Epoch 12 Step 801 Train Loss: 0.5186
Epoch 12 Step 851 Train Loss: 0.5570
Epoch 12 Step 901 Train Loss: 0.5647
Epoch 12 Step 951 Train Loss: 0.6304
Epoch 12 Step 1001 Train Loss: 0.6833
Epoch 12 Step 1051 Train Loss: 0.5547
Epoch 12 Step 1101 Train Loss: 0.5215
Epoch 12 Step 1151 Train Loss: 0.5978
Epoch 12 Step 1201 Train Loss: 0.5760
Epoch 12 Step 1251 Train Loss: 0.5927
Epoch 12 Step 1301 Train Loss: 0.5558
Epoch 12 Step 1351 Train Loss: 0.5868
Epoch 12 Step 1401 Train Loss: 0.5499
Epoch 12 Step 1451 Train Loss: 0.5790
Epoch 12 Step 1501 Train Loss: 0.6146
Epoch 12 Step 1551 Train Loss: 0.5637
Epoch 12 Step 1601 Train Loss: 0.6168
Epoch 12 Step 1651 Train Loss: 0.5518
Epoch 12 Step 1701 Train Loss: 0.6090
Epoch 12 Step 1751 Train Loss: 0.6255
Epoch 12 Step 1801 Train Loss: 0.5299
Epoch 12 Step 1851 Train Loss: 0.6161
Epoch 12 Step 1901 Train Loss: 0.5614
Epoch 12 Step 1951 Train Loss: 0.6140
Epoch 12 Step 2001 Train Loss: 0.5878
Epoch 12 Step 2051 Train Loss: 0.5780
Epoch 12 Step 2101 Train Loss: 0.5352
Epoch 12 Step 2151 Train Loss: 0.5985
Epoch 12 Step 2201 Train Loss: 0.5479
Epoch 12 Step 2251 Train Loss: 0.6572
Epoch 12 Step 2301 Train Loss: 0.5964
Epoch 12 Step 2351 Train Loss: 0.6564
Epoch 12 Step 2401 Train Loss: 0.6332
Epoch 12 Step 2451 Train Loss: 0.6031
Epoch 12 Step 2501 Train Loss: 0.5740
Epoch 12 Step 2551 Train Loss: 0.5758
Epoch 12 Step 2601 Train Loss: 0.5740
Epoch 12 Step 2651 Train Loss: 0.5949
Epoch 12 Step 2701 Train Loss: 0.5517
Epoch 12 Step 2751 Train Loss: 0.5538
Epoch 12 Step 2801 Train Loss: 0.5087
Epoch 12 Step 2851 Train Loss: 0.6301
Epoch 12 Step 2901 Train Loss: 0.5300
Epoch 12 Step 2951 Train Loss: 0.5834
Epoch 12 Step 3001 Train Loss: 0.5800
Epoch 12 Step 3051 Train Loss: 0.5861
Epoch 12 Step 3101 Train Loss: 0.5557
Epoch 12 Step 3151 Train Loss: 0.5785
Epoch 12 Step 3201 Train Loss: 0.5824
Epoch 12 Step 3251 Train Loss: 0.6282
Epoch 12 Step 3301 Train Loss: 0.6097
Epoch 12 Step 3351 Train Loss: 0.5634
Epoch 12: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0093. 
Train Top 20 DE MSE: 0.1591 Validation Top 20 DE MSE: 0.1866. 
Epoch 13 Step 1 Train Loss: 0.5818
Epoch 13 Step 51 Train Loss: 0.5910
Epoch 13 Step 101 Train Loss: 0.5565
Epoch 13 Step 151 Train Loss: 0.5361
Epoch 13 Step 201 Train Loss: 0.5101
Epoch 13 Step 251 Train Loss: 0.5708
Epoch 13 Step 301 Train Loss: 0.5993
Epoch 13 Step 351 Train Loss: 0.5601
Epoch 13 Step 401 Train Loss: 0.5716
Epoch 13 Step 451 Train Loss: 0.5615
Epoch 13 Step 501 Train Loss: 0.5606
Epoch 13 Step 551 Train Loss: 0.5292
Epoch 13 Step 601 Train Loss: 0.5704
Epoch 13 Step 651 Train Loss: 0.5341
Epoch 13 Step 701 Train Loss: 0.5411
Epoch 13 Step 751 Train Loss: 0.5424
Epoch 13 Step 801 Train Loss: 0.5824
Epoch 13 Step 851 Train Loss: 0.5606
Epoch 13 Step 901 Train Loss: 0.5593
Epoch 13 Step 951 Train Loss: 0.6028
Epoch 13 Step 1001 Train Loss: 0.6101
Epoch 13 Step 1051 Train Loss: 0.6123
Epoch 13 Step 1101 Train Loss: 0.6065
Epoch 13 Step 1151 Train Loss: 0.5314
Epoch 13 Step 1201 Train Loss: 0.5671
Epoch 13 Step 1251 Train Loss: 0.5317
Epoch 13 Step 1301 Train Loss: 0.5885
Epoch 13 Step 1351 Train Loss: 0.6394
Epoch 13 Step 1401 Train Loss: 0.5873
Epoch 13 Step 1451 Train Loss: 0.6486
Epoch 13 Step 1501 Train Loss: 0.5470
Epoch 13 Step 1551 Train Loss: 0.6832
Epoch 13 Step 1601 Train Loss: 0.5981
Epoch 13 Step 1651 Train Loss: 0.5602
Epoch 13 Step 1701 Train Loss: 0.5698
Epoch 13 Step 1751 Train Loss: 0.5611
Epoch 13 Step 1801 Train Loss: 0.5638
Epoch 13 Step 1851 Train Loss: 0.6521
Epoch 13 Step 1901 Train Loss: 0.5479
Epoch 13 Step 1951 Train Loss: 0.5921
Epoch 13 Step 2001 Train Loss: 0.6292
Epoch 13 Step 2051 Train Loss: 0.5775
Epoch 13 Step 2101 Train Loss: 0.5706
Epoch 13 Step 2151 Train Loss: 0.5518
Epoch 13 Step 2201 Train Loss: 0.6639
Epoch 13 Step 2251 Train Loss: 0.5957
Epoch 13 Step 2301 Train Loss: 0.5417
Epoch 13 Step 2351 Train Loss: 0.5608
Epoch 13 Step 2401 Train Loss: 0.5762
Epoch 13 Step 2451 Train Loss: 0.5923
Epoch 13 Step 2501 Train Loss: 0.6102
Epoch 13 Step 2551 Train Loss: 0.5753
Epoch 13 Step 2601 Train Loss: 0.5765
Epoch 13 Step 2651 Train Loss: 0.6248
Epoch 13 Step 2701 Train Loss: 0.6285
Epoch 13 Step 2751 Train Loss: 0.6537
Epoch 13 Step 2801 Train Loss: 0.5547
Epoch 13 Step 2851 Train Loss: 0.5799
Epoch 13 Step 2901 Train Loss: 0.5890
Epoch 13 Step 2951 Train Loss: 0.5639
Epoch 13 Step 3001 Train Loss: 0.5928
Epoch 13 Step 3051 Train Loss: 0.6086
Epoch 13 Step 3101 Train Loss: 0.5917
Epoch 13 Step 3151 Train Loss: 0.5843
Epoch 13 Step 3201 Train Loss: 0.5965
Epoch 13 Step 3251 Train Loss: 0.5414
Epoch 13 Step 3301 Train Loss: 0.5980
Epoch 13 Step 3351 Train Loss: 0.5641
Epoch 13: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1621 Validation Top 20 DE MSE: 0.1878. 
Epoch 14 Step 1 Train Loss: 0.6121
Epoch 14 Step 51 Train Loss: 0.5571
Epoch 14 Step 101 Train Loss: 0.6003
Epoch 14 Step 151 Train Loss: 0.5710
Epoch 14 Step 201 Train Loss: 0.5544
Epoch 14 Step 251 Train Loss: 0.5213
Epoch 14 Step 301 Train Loss: 0.6183
Epoch 14 Step 351 Train Loss: 0.5789
Epoch 14 Step 401 Train Loss: 0.5687
Epoch 14 Step 451 Train Loss: 0.5418
Epoch 14 Step 501 Train Loss: 0.5425
Epoch 14 Step 551 Train Loss: 0.5277
Epoch 14 Step 601 Train Loss: 0.6235
Epoch 14 Step 651 Train Loss: 0.6180
Epoch 14 Step 701 Train Loss: 0.6254
Epoch 14 Step 751 Train Loss: 0.5811
Epoch 14 Step 801 Train Loss: 0.5839
Epoch 14 Step 851 Train Loss: 0.5862
Epoch 14 Step 901 Train Loss: 0.5392
Epoch 14 Step 951 Train Loss: 0.5745
Epoch 14 Step 1001 Train Loss: 0.6042
Epoch 14 Step 1051 Train Loss: 0.5729
Epoch 14 Step 1101 Train Loss: 0.5803
Epoch 14 Step 1151 Train Loss: 0.6278
Epoch 14 Step 1201 Train Loss: 0.5878
Epoch 14 Step 1251 Train Loss: 0.6106
Epoch 14 Step 1301 Train Loss: 0.5751
Epoch 14 Step 1351 Train Loss: 0.5961
Epoch 14 Step 1401 Train Loss: 0.5485
Epoch 14 Step 1451 Train Loss: 0.6411
Epoch 14 Step 1501 Train Loss: 0.5937
Epoch 14 Step 1551 Train Loss: 0.5848
Epoch 14 Step 1601 Train Loss: 0.5526
Epoch 14 Step 1651 Train Loss: 0.5926
Epoch 14 Step 1701 Train Loss: 0.5607
Epoch 14 Step 1751 Train Loss: 0.5431
Epoch 14 Step 1801 Train Loss: 0.5976
Epoch 14 Step 1851 Train Loss: 0.5590
Epoch 14 Step 1901 Train Loss: 0.5717
Epoch 14 Step 1951 Train Loss: 0.6110
Epoch 14 Step 2001 Train Loss: 0.5810
Epoch 14 Step 2051 Train Loss: 0.5849
Epoch 14 Step 2101 Train Loss: 0.5763
Epoch 14 Step 2151 Train Loss: 0.6236
Epoch 14 Step 2201 Train Loss: 0.7022
Epoch 14 Step 2251 Train Loss: 0.6217
Epoch 14 Step 2301 Train Loss: 0.5542
Epoch 14 Step 2351 Train Loss: 0.5873
Epoch 14 Step 2401 Train Loss: 0.6021
Epoch 14 Step 2451 Train Loss: 0.6041
Epoch 14 Step 2501 Train Loss: 0.5778
Epoch 14 Step 2551 Train Loss: 0.5972
Epoch 14 Step 2601 Train Loss: 0.5255
Epoch 14 Step 2651 Train Loss: 0.5780
Epoch 14 Step 2701 Train Loss: 0.5863
Epoch 14 Step 2751 Train Loss: 0.6040
Epoch 14 Step 2801 Train Loss: 0.5485
Epoch 14 Step 2851 Train Loss: 0.5437
Epoch 14 Step 2901 Train Loss: 0.5383
Epoch 14 Step 2951 Train Loss: 0.5085
Epoch 14 Step 3001 Train Loss: 0.5777
Epoch 14 Step 3051 Train Loss: 0.4992
Epoch 14 Step 3101 Train Loss: 0.6049
Epoch 14 Step 3151 Train Loss: 0.6136
Epoch 14 Step 3201 Train Loss: 0.6060
Epoch 14 Step 3251 Train Loss: 0.5259
Epoch 14 Step 3301 Train Loss: 0.5941
Epoch 14 Step 3351 Train Loss: 0.5791
Epoch 14: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1592 Validation Top 20 DE MSE: 0.1860. 
Epoch 15 Step 1 Train Loss: 0.6124
Epoch 15 Step 51 Train Loss: 0.6047
Epoch 15 Step 101 Train Loss: 0.5887
Epoch 15 Step 151 Train Loss: 0.6283
Epoch 15 Step 201 Train Loss: 0.5516
Epoch 15 Step 251 Train Loss: 0.5764
Epoch 15 Step 301 Train Loss: 0.5571
Epoch 15 Step 351 Train Loss: 0.5611
Epoch 15 Step 401 Train Loss: 0.5329
Epoch 15 Step 451 Train Loss: 0.6212
Epoch 15 Step 501 Train Loss: 0.6068
Epoch 15 Step 551 Train Loss: 0.5470
Epoch 15 Step 601 Train Loss: 0.5775
Epoch 15 Step 651 Train Loss: 0.6432
Epoch 15 Step 701 Train Loss: 0.5884
Epoch 15 Step 751 Train Loss: 0.5678
Epoch 15 Step 801 Train Loss: 0.5457
Epoch 15 Step 851 Train Loss: 0.4974
Epoch 15 Step 901 Train Loss: 0.5750
Epoch 15 Step 951 Train Loss: 0.5677
Epoch 15 Step 1001 Train Loss: 0.5622
Epoch 15 Step 1051 Train Loss: 0.6035
Epoch 15 Step 1101 Train Loss: 0.5632
Epoch 15 Step 1151 Train Loss: 0.5786
Epoch 15 Step 1201 Train Loss: 0.6347
Epoch 15 Step 1251 Train Loss: 0.5086
Epoch 15 Step 1301 Train Loss: 0.6037
Epoch 15 Step 1351 Train Loss: 0.5638
Epoch 15 Step 1401 Train Loss: 0.5710
Epoch 15 Step 1451 Train Loss: 0.5479
Epoch 15 Step 1501 Train Loss: 0.6321
Epoch 15 Step 1551 Train Loss: 0.5851
Epoch 15 Step 1601 Train Loss: 0.6265
Epoch 15 Step 1651 Train Loss: 0.6040
Epoch 15 Step 1701 Train Loss: 0.6034
Epoch 15 Step 1751 Train Loss: 0.6188
Epoch 15 Step 1801 Train Loss: 0.5666
Epoch 15 Step 1851 Train Loss: 0.5859
Epoch 15 Step 1901 Train Loss: 0.5959
Epoch 15 Step 1951 Train Loss: 0.5410
Epoch 15 Step 2001 Train Loss: 0.5862
Epoch 15 Step 2051 Train Loss: 0.5520
Epoch 15 Step 2101 Train Loss: 0.5614
Epoch 15 Step 2151 Train Loss: 0.6211
Epoch 15 Step 2201 Train Loss: 0.5374
Epoch 15 Step 2251 Train Loss: 0.6251
Epoch 15 Step 2301 Train Loss: 0.6162
Epoch 15 Step 2351 Train Loss: 0.5366
Epoch 15 Step 2401 Train Loss: 0.5615
Epoch 15 Step 2451 Train Loss: 0.5486
Epoch 15 Step 2501 Train Loss: 0.6474
Epoch 15 Step 2551 Train Loss: 0.5873
Epoch 15 Step 2601 Train Loss: 0.5461
Epoch 15 Step 2651 Train Loss: 0.5950
Epoch 15 Step 2701 Train Loss: 0.5904
Epoch 15 Step 2751 Train Loss: 0.5745
Epoch 15 Step 2801 Train Loss: 0.5918
Epoch 15 Step 2851 Train Loss: 0.6073
Epoch 15 Step 2901 Train Loss: 0.6122
Epoch 15 Step 2951 Train Loss: 0.5727
Epoch 15 Step 3001 Train Loss: 0.6795
Epoch 15 Step 3051 Train Loss: 0.5631
Epoch 15 Step 3101 Train Loss: 0.5196
Epoch 15 Step 3151 Train Loss: 0.5529
Epoch 15 Step 3201 Train Loss: 0.5894
Epoch 15 Step 3251 Train Loss: 0.5771
Epoch 15 Step 3301 Train Loss: 0.5988
Epoch 15 Step 3351 Train Loss: 0.5464
Epoch 15: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1607 Validation Top 20 DE MSE: 0.1867. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1751
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.008965265
test_unseen_single_pearson: 0.9876119202064562
test_unseen_single_mse_de: 0.17505966
test_unseen_single_pearson_de: 0.8960708101670023
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.29412177587987587
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.33614232209737827
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6895131086142322
test_unseen_single_mse_top20_de_non_dropout: 0.18752441
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.054 MB uploadedwandb: | 0.053 MB of 0.054 MB uploadedwandb: / 0.053 MB of 0.054 MB uploadedwandb: - 0.054 MB of 0.054 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb:                                                    train_mse ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÜ‚ñá‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñà
wandb:                                                   val_de_mse ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ
wandb:                                               val_de_pearson ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                                                      val_mse ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñá‚ñá‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.17506
wandb:                                              test_de_pearson 0.89607
wandb:               test_frac_opposite_direction_top20_non_dropout 0.33614
wandb:                          test_frac_sigma_below_1_non_dropout 0.68951
wandb:                                                     test_mse 0.00897
wandb:                                test_mse_top20_de_non_dropout 0.18752
wandb:                                                 test_pearson 0.98761
wandb:                                           test_pearson_delta 0.29412
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.33614
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.68951
wandb:                                       test_unseen_single_mse 0.00897
wandb:                                    test_unseen_single_mse_de 0.17506
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.18752
wandb:                                   test_unseen_single_pearson 0.98761
wandb:                                test_unseen_single_pearson_de 0.89607
wandb:                             test_unseen_single_pearson_delta 0.29412
wandb:                                                 train_de_mse 0.16074
wandb:                                             train_de_pearson 0.91872
wandb:                                                    train_mse 0.00749
wandb:                                                train_pearson 0.98954
wandb:                                                training_loss 0.60259
wandb:                                                   val_de_mse 0.18666
wandb:                                               val_de_pearson 0.85521
wandb:                                                      val_mse 0.0092
wandb:                                                  val_pearson 0.98727
wandb: 
wandb: üöÄ View run geneformer_Replogle_k562_essential_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/s8xu12m8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_013635-s8xu12m8/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:267
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_042006-dwt0x149
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_k562_essential_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/dwt0x149
wandb: WARNING Serializing object of type ndarray that is 23167104 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5784
Epoch 1 Step 51 Train Loss: 0.5797
Epoch 1 Step 101 Train Loss: 0.5767
Epoch 1 Step 151 Train Loss: 0.5582
Epoch 1 Step 201 Train Loss: 0.6090
Epoch 1 Step 251 Train Loss: 0.6117
Epoch 1 Step 301 Train Loss: 0.5926
Epoch 1 Step 351 Train Loss: 0.5470
Epoch 1 Step 401 Train Loss: 0.6197
Epoch 1 Step 451 Train Loss: 0.6626
Epoch 1 Step 501 Train Loss: 0.6249
Epoch 1 Step 551 Train Loss: 0.6460
Epoch 1 Step 601 Train Loss: 0.6391
Epoch 1 Step 651 Train Loss: 0.5974
Epoch 1 Step 701 Train Loss: 0.5786
Epoch 1 Step 751 Train Loss: 0.5579
Epoch 1 Step 801 Train Loss: 0.5047
Epoch 1 Step 851 Train Loss: 0.6089
Epoch 1 Step 901 Train Loss: 0.5783
Epoch 1 Step 951 Train Loss: 0.5227
Epoch 1 Step 1001 Train Loss: 0.5824
Epoch 1 Step 1051 Train Loss: 0.5847
Epoch 1 Step 1101 Train Loss: 0.5868
Epoch 1 Step 1151 Train Loss: 0.6186
Epoch 1 Step 1201 Train Loss: 0.6272
Epoch 1 Step 1251 Train Loss: 0.5687
Epoch 1 Step 1301 Train Loss: 0.5819
Epoch 1 Step 1351 Train Loss: 0.5557
Epoch 1 Step 1401 Train Loss: 0.6086
Epoch 1 Step 1451 Train Loss: 0.5694
Epoch 1 Step 1501 Train Loss: 0.5824
Epoch 1 Step 1551 Train Loss: 0.5799
Epoch 1 Step 1601 Train Loss: 0.4694
Epoch 1 Step 1651 Train Loss: 0.5783
Epoch 1 Step 1701 Train Loss: 0.6659
Epoch 1 Step 1751 Train Loss: 0.5702
Epoch 1 Step 1801 Train Loss: 0.5503
Epoch 1 Step 1851 Train Loss: 0.6328
Epoch 1 Step 1901 Train Loss: 0.5883
Epoch 1 Step 1951 Train Loss: 0.5378
Epoch 1 Step 2001 Train Loss: 0.6662
Epoch 1 Step 2051 Train Loss: 0.6122
Epoch 1 Step 2101 Train Loss: 0.5498
Epoch 1 Step 2151 Train Loss: 0.5300
Epoch 1 Step 2201 Train Loss: 0.5385
Epoch 1 Step 2251 Train Loss: 0.5771
Epoch 1 Step 2301 Train Loss: 0.5825
Epoch 1 Step 2351 Train Loss: 0.6251
Epoch 1 Step 2401 Train Loss: 0.6117
Epoch 1 Step 2451 Train Loss: 0.5776
Epoch 1 Step 2501 Train Loss: 0.6473
Epoch 1 Step 2551 Train Loss: 0.5982
Epoch 1 Step 2601 Train Loss: 0.5263
Epoch 1 Step 2651 Train Loss: 0.5746
Epoch 1 Step 2701 Train Loss: 0.5736
Epoch 1 Step 2751 Train Loss: 0.6231
Epoch 1 Step 2801 Train Loss: 0.5412
Epoch 1 Step 2851 Train Loss: 0.5436
Epoch 1 Step 2901 Train Loss: 0.5083
Epoch 1 Step 2951 Train Loss: 0.5921
Epoch 1 Step 3001 Train Loss: 0.6075
Epoch 1 Step 3051 Train Loss: 0.5456
Epoch 1 Step 3101 Train Loss: 0.5910
Epoch 1 Step 3151 Train Loss: 0.5374
Epoch 1 Step 3201 Train Loss: 0.5938
Epoch 1 Step 3251 Train Loss: 0.5879
Epoch 1 Step 3301 Train Loss: 0.4949
Epoch 1 Step 3351 Train Loss: 0.6010
Epoch 1: Train Overall MSE: 0.0082 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1722 Validation Top 20 DE MSE: 0.1618. 
Epoch 2 Step 1 Train Loss: 0.5721
Epoch 2 Step 51 Train Loss: 0.6130
Epoch 2 Step 101 Train Loss: 0.5719
Epoch 2 Step 151 Train Loss: 0.5640
Epoch 2 Step 201 Train Loss: 0.5945
Epoch 2 Step 251 Train Loss: 0.5877
Epoch 2 Step 301 Train Loss: 0.5557
Epoch 2 Step 351 Train Loss: 0.5870
Epoch 2 Step 401 Train Loss: 0.5440
Epoch 2 Step 451 Train Loss: 0.6390
Epoch 2 Step 501 Train Loss: 0.5509
Epoch 2 Step 551 Train Loss: 0.5608
Epoch 2 Step 601 Train Loss: 0.6549
Epoch 2 Step 651 Train Loss: 0.5579
Epoch 2 Step 701 Train Loss: 0.5943
Epoch 2 Step 751 Train Loss: 0.5749
Epoch 2 Step 801 Train Loss: 0.5685
Epoch 2 Step 851 Train Loss: 0.5890
Epoch 2 Step 901 Train Loss: 0.5449
Epoch 2 Step 951 Train Loss: 0.6363
Epoch 2 Step 1001 Train Loss: 0.5789
Epoch 2 Step 1051 Train Loss: 0.5630
Epoch 2 Step 1101 Train Loss: 0.6788
Epoch 2 Step 1151 Train Loss: 0.5173
Epoch 2 Step 1201 Train Loss: 0.5711
Epoch 2 Step 1251 Train Loss: 0.5508
Epoch 2 Step 1301 Train Loss: 0.6020
Epoch 2 Step 1351 Train Loss: 0.5425
Epoch 2 Step 1401 Train Loss: 0.5873
Epoch 2 Step 1451 Train Loss: 0.6012
Epoch 2 Step 1501 Train Loss: 0.5454
Epoch 2 Step 1551 Train Loss: 0.6234
Epoch 2 Step 1601 Train Loss: 0.6085
Epoch 2 Step 1651 Train Loss: 0.5605
Epoch 2 Step 1701 Train Loss: 0.5953
Epoch 2 Step 1751 Train Loss: 0.6030
Epoch 2 Step 1801 Train Loss: 0.6067
Epoch 2 Step 1851 Train Loss: 0.5514
Epoch 2 Step 1901 Train Loss: 0.5153
Epoch 2 Step 1951 Train Loss: 0.5331
Epoch 2 Step 2001 Train Loss: 0.6066
Epoch 2 Step 2051 Train Loss: 0.5775
Epoch 2 Step 2101 Train Loss: 0.5656
Epoch 2 Step 2151 Train Loss: 0.6100
Epoch 2 Step 2201 Train Loss: 0.6013
Epoch 2 Step 2251 Train Loss: 0.5414
Epoch 2 Step 2301 Train Loss: 0.5759
Epoch 2 Step 2351 Train Loss: 0.5995
Epoch 2 Step 2401 Train Loss: 0.5792
Epoch 2 Step 2451 Train Loss: 0.5947
Epoch 2 Step 2501 Train Loss: 0.5267
Epoch 2 Step 2551 Train Loss: 0.6209
Epoch 2 Step 2601 Train Loss: 0.5677
Epoch 2 Step 2651 Train Loss: 0.5513
Epoch 2 Step 2701 Train Loss: 0.6016
Epoch 2 Step 2751 Train Loss: 0.6392
Epoch 2 Step 2801 Train Loss: 0.5990
Epoch 2 Step 2851 Train Loss: 0.5931
Epoch 2 Step 2901 Train Loss: 0.6006
Epoch 2 Step 2951 Train Loss: 0.5592
Epoch 2 Step 3001 Train Loss: 0.5806
Epoch 2 Step 3051 Train Loss: 0.5884
Epoch 2 Step 3101 Train Loss: 0.5999
Epoch 2 Step 3151 Train Loss: 0.6239
Epoch 2 Step 3201 Train Loss: 0.6289
Epoch 2 Step 3251 Train Loss: 0.5853
Epoch 2 Step 3301 Train Loss: 0.5637
Epoch 2 Step 3351 Train Loss: 0.6068
Epoch 2: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0090. 
Train Top 20 DE MSE: 0.1709 Validation Top 20 DE MSE: 0.1630. 
Epoch 3 Step 1 Train Loss: 0.5541
Epoch 3 Step 51 Train Loss: 0.5814
Epoch 3 Step 101 Train Loss: 0.5541
Epoch 3 Step 151 Train Loss: 0.5755
Epoch 3 Step 201 Train Loss: 0.5844
Epoch 3 Step 251 Train Loss: 0.6290
Epoch 3 Step 301 Train Loss: 0.6231
Epoch 3 Step 351 Train Loss: 0.5727
Epoch 3 Step 401 Train Loss: 0.5886
Epoch 3 Step 451 Train Loss: 0.5983
Epoch 3 Step 501 Train Loss: 0.5189
Epoch 3 Step 551 Train Loss: 0.5716
Epoch 3 Step 601 Train Loss: 0.6060
Epoch 3 Step 651 Train Loss: 0.5245
Epoch 3 Step 701 Train Loss: 0.5434
Epoch 3 Step 751 Train Loss: 0.6228
Epoch 3 Step 801 Train Loss: 0.5728
Epoch 3 Step 851 Train Loss: 0.5338
Epoch 3 Step 901 Train Loss: 0.5900
Epoch 3 Step 951 Train Loss: 0.5577
Epoch 3 Step 1001 Train Loss: 0.5573
Epoch 3 Step 1051 Train Loss: 0.5586
Epoch 3 Step 1101 Train Loss: 0.5506
Epoch 3 Step 1151 Train Loss: 0.5891
Epoch 3 Step 1201 Train Loss: 0.6478
Epoch 3 Step 1251 Train Loss: 0.5669
Epoch 3 Step 1301 Train Loss: 0.6341
Epoch 3 Step 1351 Train Loss: 0.5945
Epoch 3 Step 1401 Train Loss: 0.5339
Epoch 3 Step 1451 Train Loss: 0.5814
Epoch 3 Step 1501 Train Loss: 0.6032
Epoch 3 Step 1551 Train Loss: 0.5679
Epoch 3 Step 1601 Train Loss: 0.5692
Epoch 3 Step 1651 Train Loss: 0.4963
Epoch 3 Step 1701 Train Loss: 0.5777
Epoch 3 Step 1751 Train Loss: 0.5950
Epoch 3 Step 1801 Train Loss: 0.5230
Epoch 3 Step 1851 Train Loss: 0.6241
Epoch 3 Step 1901 Train Loss: 0.5889
Epoch 3 Step 1951 Train Loss: 0.5371
Epoch 3 Step 2001 Train Loss: 0.5728
Epoch 3 Step 2051 Train Loss: 0.6531
Epoch 3 Step 2101 Train Loss: 0.6475
Epoch 3 Step 2151 Train Loss: 0.5843
Epoch 3 Step 2201 Train Loss: 0.6314
Epoch 3 Step 2251 Train Loss: 0.5639
Epoch 3 Step 2301 Train Loss: 0.5153
Epoch 3 Step 2351 Train Loss: 0.5701
Epoch 3 Step 2401 Train Loss: 0.5486
Epoch 3 Step 2451 Train Loss: 0.6108
Epoch 3 Step 2501 Train Loss: 0.5423
Epoch 3 Step 2551 Train Loss: 0.5889
Epoch 3 Step 2601 Train Loss: 0.5548
Epoch 3 Step 2651 Train Loss: 0.5432
Epoch 3 Step 2701 Train Loss: 0.5994
Epoch 3 Step 2751 Train Loss: 0.6114
Epoch 3 Step 2801 Train Loss: 0.5653
Epoch 3 Step 2851 Train Loss: 0.5533
Epoch 3 Step 2901 Train Loss: 0.5963
Epoch 3 Step 2951 Train Loss: 0.5146
Epoch 3 Step 3001 Train Loss: 0.5235
Epoch 3 Step 3051 Train Loss: 0.5971
Epoch 3 Step 3101 Train Loss: 0.5537
Epoch 3 Step 3151 Train Loss: 0.5986
Epoch 3 Step 3201 Train Loss: 0.6039
Epoch 3 Step 3251 Train Loss: 0.5703
Epoch 3 Step 3301 Train Loss: 0.5962
Epoch 3 Step 3351 Train Loss: 0.6255
Epoch 3: Train Overall MSE: 0.0090 Validation Overall MSE: 0.0100. 
Train Top 20 DE MSE: 0.1577 Validation Top 20 DE MSE: 0.1501. 
Epoch 4 Step 1 Train Loss: 0.5854
Epoch 4 Step 51 Train Loss: 0.6143
Epoch 4 Step 101 Train Loss: 0.6085
Epoch 4 Step 151 Train Loss: 0.5959
Epoch 4 Step 201 Train Loss: 0.5998
Epoch 4 Step 251 Train Loss: 0.6242
Epoch 4 Step 301 Train Loss: 0.5597
Epoch 4 Step 351 Train Loss: 0.5460
Epoch 4 Step 401 Train Loss: 0.5134
Epoch 4 Step 451 Train Loss: 0.5607
Epoch 4 Step 501 Train Loss: 0.5652
Epoch 4 Step 551 Train Loss: 0.5668
Epoch 4 Step 601 Train Loss: 0.5456
Epoch 4 Step 651 Train Loss: 0.5500
Epoch 4 Step 701 Train Loss: 0.5567
Epoch 4 Step 751 Train Loss: 0.5582
Epoch 4 Step 801 Train Loss: 0.5971
Epoch 4 Step 851 Train Loss: 0.5386
Epoch 4 Step 901 Train Loss: 0.5539
Epoch 4 Step 951 Train Loss: 0.6006
Epoch 4 Step 1001 Train Loss: 0.5268
Epoch 4 Step 1051 Train Loss: 0.5802
Epoch 4 Step 1101 Train Loss: 0.5778
Epoch 4 Step 1151 Train Loss: 0.5453
Epoch 4 Step 1201 Train Loss: 0.6064
Epoch 4 Step 1251 Train Loss: 0.6266
Epoch 4 Step 1301 Train Loss: 0.6046
Epoch 4 Step 1351 Train Loss: 0.5904
Epoch 4 Step 1401 Train Loss: 0.6355
Epoch 4 Step 1451 Train Loss: 0.5679
Epoch 4 Step 1501 Train Loss: 0.5754
Epoch 4 Step 1551 Train Loss: 0.5741
Epoch 4 Step 1601 Train Loss: 0.5265
Epoch 4 Step 1651 Train Loss: 0.5511
Epoch 4 Step 1701 Train Loss: 0.5687
Epoch 4 Step 1751 Train Loss: 0.6182
Epoch 4 Step 1801 Train Loss: 0.5515
Epoch 4 Step 1851 Train Loss: 0.5559
Epoch 4 Step 1901 Train Loss: 0.5862
Epoch 4 Step 1951 Train Loss: 0.5595
Epoch 4 Step 2001 Train Loss: 0.6410
Epoch 4 Step 2051 Train Loss: 0.4996
Epoch 4 Step 2101 Train Loss: 0.5850
Epoch 4 Step 2151 Train Loss: 0.5668
Epoch 4 Step 2201 Train Loss: 0.5543
Epoch 4 Step 2251 Train Loss: 0.5657
Epoch 4 Step 2301 Train Loss: 0.5701
Epoch 4 Step 2351 Train Loss: 0.5343
Epoch 4 Step 2401 Train Loss: 0.6050
Epoch 4 Step 2451 Train Loss: 0.5365
Epoch 4 Step 2501 Train Loss: 0.6054
Epoch 4 Step 2551 Train Loss: 0.5412
Epoch 4 Step 2601 Train Loss: 0.5719
Epoch 4 Step 2651 Train Loss: 0.6205
Epoch 4 Step 2701 Train Loss: 0.5987
Epoch 4 Step 2751 Train Loss: 0.5765
Epoch 4 Step 2801 Train Loss: 0.6670
Epoch 4 Step 2851 Train Loss: 0.6290
Epoch 4 Step 2901 Train Loss: 0.5989
Epoch 4 Step 2951 Train Loss: 0.5573
Epoch 4 Step 3001 Train Loss: 0.5748
Epoch 4 Step 3051 Train Loss: 0.6012
Epoch 4 Step 3101 Train Loss: 0.5359
Epoch 4 Step 3151 Train Loss: 0.6327
Epoch 4 Step 3201 Train Loss: 0.5605
Epoch 4 Step 3251 Train Loss: 0.5793
Epoch 4 Step 3301 Train Loss: 0.5947
Epoch 4 Step 3351 Train Loss: 0.6035
Epoch 4: Train Overall MSE: 0.0089 Validation Overall MSE: 0.0098. 
Train Top 20 DE MSE: 0.1704 Validation Top 20 DE MSE: 0.1616. 
Epoch 5 Step 1 Train Loss: 0.5902
Epoch 5 Step 51 Train Loss: 0.5554
Epoch 5 Step 101 Train Loss: 0.5620
Epoch 5 Step 151 Train Loss: 0.6175
Epoch 5 Step 201 Train Loss: 0.5904
Epoch 5 Step 251 Train Loss: 0.5677
Epoch 5 Step 301 Train Loss: 0.5588
Epoch 5 Step 351 Train Loss: 0.5939
Epoch 5 Step 401 Train Loss: 0.5801
Epoch 5 Step 451 Train Loss: 0.5296
Epoch 5 Step 501 Train Loss: 0.5621
Epoch 5 Step 551 Train Loss: 0.6142
Epoch 5 Step 601 Train Loss: 0.5645
Epoch 5 Step 651 Train Loss: 0.5481
Epoch 5 Step 701 Train Loss: 0.5843
Epoch 5 Step 751 Train Loss: 0.6667
Epoch 5 Step 801 Train Loss: 0.5794
Epoch 5 Step 851 Train Loss: 0.6133
Epoch 5 Step 901 Train Loss: 0.6265
Epoch 5 Step 951 Train Loss: 0.6116
Epoch 5 Step 1001 Train Loss: 0.5956
Epoch 5 Step 1051 Train Loss: 0.5602
Epoch 5 Step 1101 Train Loss: 0.5931
Epoch 5 Step 1151 Train Loss: 0.6512
Epoch 5 Step 1201 Train Loss: 0.5954
Epoch 5 Step 1251 Train Loss: 0.5448
Epoch 5 Step 1301 Train Loss: 0.5856
Epoch 5 Step 1351 Train Loss: 0.6021
Epoch 5 Step 1401 Train Loss: 0.5646
Epoch 5 Step 1451 Train Loss: 0.5595
Epoch 5 Step 1501 Train Loss: 0.5816
Epoch 5 Step 1551 Train Loss: 0.6171
Epoch 5 Step 1601 Train Loss: 0.5445
Epoch 5 Step 1651 Train Loss: 0.6223
Epoch 5 Step 1701 Train Loss: 0.5846
Epoch 5 Step 1751 Train Loss: 0.5899
Epoch 5 Step 1801 Train Loss: 0.6414
Epoch 5 Step 1851 Train Loss: 0.5724
Epoch 5 Step 1901 Train Loss: 0.5599
Epoch 5 Step 1951 Train Loss: 0.5624
Epoch 5 Step 2001 Train Loss: 0.6014
Epoch 5 Step 2051 Train Loss: 0.5783
Epoch 5 Step 2101 Train Loss: 0.5533
Epoch 5 Step 2151 Train Loss: 0.5764
Epoch 5 Step 2201 Train Loss: 0.5586
Epoch 5 Step 2251 Train Loss: 0.5754
Epoch 5 Step 2301 Train Loss: 0.5617
Epoch 5 Step 2351 Train Loss: 0.5847
Epoch 5 Step 2401 Train Loss: 0.6039
Epoch 5 Step 2451 Train Loss: 0.6141
Epoch 5 Step 2501 Train Loss: 0.5865
Epoch 5 Step 2551 Train Loss: 0.5776
Epoch 5 Step 2601 Train Loss: 0.5022
Epoch 5 Step 2651 Train Loss: 0.5728
Epoch 5 Step 2701 Train Loss: 0.5357
Epoch 5 Step 2751 Train Loss: 0.5461
Epoch 5 Step 2801 Train Loss: 0.5330
Epoch 5 Step 2851 Train Loss: 0.6973
Epoch 5 Step 2901 Train Loss: 0.6469
Epoch 5 Step 2951 Train Loss: 0.5558
Epoch 5 Step 3001 Train Loss: 0.5632
Epoch 5 Step 3051 Train Loss: 0.5885
Epoch 5 Step 3101 Train Loss: 0.5960
Epoch 5 Step 3151 Train Loss: 0.5826
Epoch 5 Step 3201 Train Loss: 0.5475
Epoch 5 Step 3251 Train Loss: 0.6024
Epoch 5 Step 3301 Train Loss: 0.5965
Epoch 5 Step 3351 Train Loss: 0.5750
Epoch 5: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1532 Validation Top 20 DE MSE: 0.1506. 
Epoch 6 Step 1 Train Loss: 0.5855
Epoch 6 Step 51 Train Loss: 0.5565
Epoch 6 Step 101 Train Loss: 0.6127
Epoch 6 Step 151 Train Loss: 0.5562
Epoch 6 Step 201 Train Loss: 0.6236
Epoch 6 Step 251 Train Loss: 0.5818
Epoch 6 Step 301 Train Loss: 0.5785
Epoch 6 Step 351 Train Loss: 0.5656
Epoch 6 Step 401 Train Loss: 0.5896
Epoch 6 Step 451 Train Loss: 0.5598
Epoch 6 Step 501 Train Loss: 0.5286
Epoch 6 Step 551 Train Loss: 0.6892
Epoch 6 Step 601 Train Loss: 0.5943
Epoch 6 Step 651 Train Loss: 0.5929
Epoch 6 Step 701 Train Loss: 0.6096
Epoch 6 Step 751 Train Loss: 0.5554
Epoch 6 Step 801 Train Loss: 0.5699
Epoch 6 Step 851 Train Loss: 0.6098
Epoch 6 Step 901 Train Loss: 0.5134
Epoch 6 Step 951 Train Loss: 0.5550
Epoch 6 Step 1001 Train Loss: 0.6164
Epoch 6 Step 1051 Train Loss: 0.5920
Epoch 6 Step 1101 Train Loss: 0.5578
Epoch 6 Step 1151 Train Loss: 0.6416
Epoch 6 Step 1201 Train Loss: 0.5674
Epoch 6 Step 1251 Train Loss: 0.5324
Epoch 6 Step 1301 Train Loss: 0.5097
Epoch 6 Step 1351 Train Loss: 0.5487
Epoch 6 Step 1401 Train Loss: 0.5184
Epoch 6 Step 1451 Train Loss: 0.6096
Epoch 6 Step 1501 Train Loss: 0.5701
Epoch 6 Step 1551 Train Loss: 0.6087
Epoch 6 Step 1601 Train Loss: 0.6089
Epoch 6 Step 1651 Train Loss: 0.6006
Epoch 6 Step 1701 Train Loss: 0.5747
Epoch 6 Step 1751 Train Loss: 0.6228
Epoch 6 Step 1801 Train Loss: 0.5629
Epoch 6 Step 1851 Train Loss: 0.5750
Epoch 6 Step 1901 Train Loss: 0.6015
Epoch 6 Step 1951 Train Loss: 0.5945
Epoch 6 Step 2001 Train Loss: 0.5254
Epoch 6 Step 2051 Train Loss: 0.5947
Epoch 6 Step 2101 Train Loss: 0.5880
Epoch 6 Step 2151 Train Loss: 0.5466
Epoch 6 Step 2201 Train Loss: 0.5091
Epoch 6 Step 2251 Train Loss: 0.5062
Epoch 6 Step 2301 Train Loss: 0.5625
Epoch 6 Step 2351 Train Loss: 0.5618
Epoch 6 Step 2401 Train Loss: 0.5624
Epoch 6 Step 2451 Train Loss: 0.6264
Epoch 6 Step 2501 Train Loss: 0.6153
Epoch 6 Step 2551 Train Loss: 0.5846
Epoch 6 Step 2601 Train Loss: 0.6299
Epoch 6 Step 2651 Train Loss: 0.5907
Epoch 6 Step 2701 Train Loss: 0.5251
Epoch 6 Step 2751 Train Loss: 0.5742
Epoch 6 Step 2801 Train Loss: 0.5667
Epoch 6 Step 2851 Train Loss: 0.5372
Epoch 6 Step 2901 Train Loss: 0.6182
Epoch 6 Step 2951 Train Loss: 0.7025
Epoch 6 Step 3001 Train Loss: 0.5054
Epoch 6 Step 3051 Train Loss: 0.5481
Epoch 6 Step 3101 Train Loss: 0.5500
Epoch 6 Step 3151 Train Loss: 0.5639
Epoch 6 Step 3201 Train Loss: 0.5808
Epoch 6 Step 3251 Train Loss: 0.6297
Epoch 6 Step 3301 Train Loss: 0.6025
Epoch 6 Step 3351 Train Loss: 0.5499
Epoch 6: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1530 Validation Top 20 DE MSE: 0.1527. 
Epoch 7 Step 1 Train Loss: 0.5830
Epoch 7 Step 51 Train Loss: 0.6186
Epoch 7 Step 101 Train Loss: 0.5874
Epoch 7 Step 151 Train Loss: 0.5831
Epoch 7 Step 201 Train Loss: 0.6156
Epoch 7 Step 251 Train Loss: 0.5560
Epoch 7 Step 301 Train Loss: 0.5012
Epoch 7 Step 351 Train Loss: 0.5930
Epoch 7 Step 401 Train Loss: 0.5951
Epoch 7 Step 451 Train Loss: 0.5869
Epoch 7 Step 501 Train Loss: 0.5492
Epoch 7 Step 551 Train Loss: 0.6439
Epoch 7 Step 601 Train Loss: 0.5811
Epoch 7 Step 651 Train Loss: 0.6389
Epoch 7 Step 701 Train Loss: 0.5419
Epoch 7 Step 751 Train Loss: 0.5558
Epoch 7 Step 801 Train Loss: 0.5468
Epoch 7 Step 851 Train Loss: 0.6072
Epoch 7 Step 901 Train Loss: 0.5864
Epoch 7 Step 951 Train Loss: 0.5802
Epoch 7 Step 1001 Train Loss: 0.6170
Epoch 7 Step 1051 Train Loss: 0.6256
Epoch 7 Step 1101 Train Loss: 0.5986
Epoch 7 Step 1151 Train Loss: 0.5990
Epoch 7 Step 1201 Train Loss: 0.6267
Epoch 7 Step 1251 Train Loss: 0.5676
Epoch 7 Step 1301 Train Loss: 0.5827
Epoch 7 Step 1351 Train Loss: 0.5752
Epoch 7 Step 1401 Train Loss: 0.5842
Epoch 7 Step 1451 Train Loss: 0.6462
Epoch 7 Step 1501 Train Loss: 0.5695
Epoch 7 Step 1551 Train Loss: 0.5696
Epoch 7 Step 1601 Train Loss: 0.5816
Epoch 7 Step 1651 Train Loss: 0.5134
Epoch 7 Step 1701 Train Loss: 0.5609
Epoch 7 Step 1751 Train Loss: 0.5984
Epoch 7 Step 1801 Train Loss: 0.5770
Epoch 7 Step 1851 Train Loss: 0.5899
Epoch 7 Step 1901 Train Loss: 0.6250
Epoch 7 Step 1951 Train Loss: 0.5738
Epoch 7 Step 2001 Train Loss: 0.5406
Epoch 7 Step 2051 Train Loss: 0.5728
Epoch 7 Step 2101 Train Loss: 0.5377
Epoch 7 Step 2151 Train Loss: 0.6589
Epoch 7 Step 2201 Train Loss: 0.5775
Epoch 7 Step 2251 Train Loss: 0.5867
Epoch 7 Step 2301 Train Loss: 0.5829
Epoch 7 Step 2351 Train Loss: 0.5684
Epoch 7 Step 2401 Train Loss: 0.5962
Epoch 7 Step 2451 Train Loss: 0.5961
Epoch 7 Step 2501 Train Loss: 0.6210
Epoch 7 Step 2551 Train Loss: 0.5813
Epoch 7 Step 2601 Train Loss: 0.5475
Epoch 7 Step 2651 Train Loss: 0.5750
Epoch 7 Step 2701 Train Loss: 0.5932
Epoch 7 Step 2751 Train Loss: 0.6388
Epoch 7 Step 2801 Train Loss: 0.6015
Epoch 7 Step 2851 Train Loss: 0.5571
Epoch 7 Step 2901 Train Loss: 0.6361
Epoch 7 Step 2951 Train Loss: 0.5748
Epoch 7 Step 3001 Train Loss: 0.6186
Epoch 7 Step 3051 Train Loss: 0.5730
Epoch 7 Step 3101 Train Loss: 0.5825
Epoch 7 Step 3151 Train Loss: 0.6369
Epoch 7 Step 3201 Train Loss: 0.5678
Epoch 7 Step 3251 Train Loss: 0.6703
Epoch 7 Step 3301 Train Loss: 0.5670
Epoch 7 Step 3351 Train Loss: 0.5882
Epoch 7: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1547 Validation Top 20 DE MSE: 0.1547. 
Epoch 8 Step 1 Train Loss: 0.5670
Epoch 8 Step 51 Train Loss: 0.5842
Epoch 8 Step 101 Train Loss: 0.5645
Epoch 8 Step 151 Train Loss: 0.5233
Epoch 8 Step 201 Train Loss: 0.5718
Epoch 8 Step 251 Train Loss: 0.6077
Epoch 8 Step 301 Train Loss: 0.5561
Epoch 8 Step 351 Train Loss: 0.5859
Epoch 8 Step 401 Train Loss: 0.5525
Epoch 8 Step 451 Train Loss: 0.5500
Epoch 8 Step 501 Train Loss: 0.5465
Epoch 8 Step 551 Train Loss: 0.5724
Epoch 8 Step 601 Train Loss: 0.5595
Epoch 8 Step 651 Train Loss: 0.5484
Epoch 8 Step 701 Train Loss: 0.5709
Epoch 8 Step 751 Train Loss: 0.5545
Epoch 8 Step 801 Train Loss: 0.5717
Epoch 8 Step 851 Train Loss: 0.5674
Epoch 8 Step 901 Train Loss: 0.5739
Epoch 8 Step 951 Train Loss: 0.5776
Epoch 8 Step 1001 Train Loss: 0.5806
Epoch 8 Step 1051 Train Loss: 0.6131
Epoch 8 Step 1101 Train Loss: 0.5382
Epoch 8 Step 1151 Train Loss: 0.5866
Epoch 8 Step 1201 Train Loss: 0.5889
Epoch 8 Step 1251 Train Loss: 0.6190
Epoch 8 Step 1301 Train Loss: 0.6649
Epoch 8 Step 1351 Train Loss: 0.5416
Epoch 8 Step 1401 Train Loss: 0.5932
Epoch 8 Step 1451 Train Loss: 0.5801
Epoch 8 Step 1501 Train Loss: 0.5592
Epoch 8 Step 1551 Train Loss: 0.5906
Epoch 8 Step 1601 Train Loss: 0.5433
Epoch 8 Step 1651 Train Loss: 0.5529
Epoch 8 Step 1701 Train Loss: 0.5544
Epoch 8 Step 1751 Train Loss: 0.5620
Epoch 8 Step 1801 Train Loss: 0.6142
Epoch 8 Step 1851 Train Loss: 0.5517
Epoch 8 Step 1901 Train Loss: 0.5642
Epoch 8 Step 1951 Train Loss: 0.5673
Epoch 8 Step 2001 Train Loss: 0.6156
Epoch 8 Step 2051 Train Loss: 0.5468
Epoch 8 Step 2101 Train Loss: 0.5967
Epoch 8 Step 2151 Train Loss: 0.6029
Epoch 8 Step 2201 Train Loss: 0.5612
Epoch 8 Step 2251 Train Loss: 0.5660
Epoch 8 Step 2301 Train Loss: 0.5791
Epoch 8 Step 2351 Train Loss: 0.5951
Epoch 8 Step 2401 Train Loss: 0.6022
Epoch 8 Step 2451 Train Loss: 0.6216
Epoch 8 Step 2501 Train Loss: 0.5697
Epoch 8 Step 2551 Train Loss: 0.5756
Epoch 8 Step 2601 Train Loss: 0.5975
Epoch 8 Step 2651 Train Loss: 0.5984
Epoch 8 Step 2701 Train Loss: 0.6158
Epoch 8 Step 2751 Train Loss: 0.6059
Epoch 8 Step 2801 Train Loss: 0.5929
Epoch 8 Step 2851 Train Loss: 0.5955
Epoch 8 Step 2901 Train Loss: 0.5878
Epoch 8 Step 2951 Train Loss: 0.6120
Epoch 8 Step 3001 Train Loss: 0.5439
Epoch 8 Step 3051 Train Loss: 0.5838
Epoch 8 Step 3101 Train Loss: 0.5636
Epoch 8 Step 3151 Train Loss: 0.5937
Epoch 8 Step 3201 Train Loss: 0.6567
Epoch 8 Step 3251 Train Loss: 0.6345
Epoch 8 Step 3301 Train Loss: 0.5385
Epoch 8 Step 3351 Train Loss: 0.5659
Epoch 8: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0090. 
Train Top 20 DE MSE: 0.1574 Validation Top 20 DE MSE: 0.1565. 
Epoch 9 Step 1 Train Loss: 0.6219
Epoch 9 Step 51 Train Loss: 0.5847
Epoch 9 Step 101 Train Loss: 0.5575
Epoch 9 Step 151 Train Loss: 0.5561
Epoch 9 Step 201 Train Loss: 0.5457
Epoch 9 Step 251 Train Loss: 0.5620
Epoch 9 Step 301 Train Loss: 0.5848
Epoch 9 Step 351 Train Loss: 0.6258
Epoch 9 Step 401 Train Loss: 0.6018
Epoch 9 Step 451 Train Loss: 0.5921
Epoch 9 Step 501 Train Loss: 0.5699
Epoch 9 Step 551 Train Loss: 0.5832
Epoch 9 Step 601 Train Loss: 0.5497
Epoch 9 Step 651 Train Loss: 0.5699
Epoch 9 Step 701 Train Loss: 0.5721
Epoch 9 Step 751 Train Loss: 0.5755
Epoch 9 Step 801 Train Loss: 0.5748
Epoch 9 Step 851 Train Loss: 0.5297
Epoch 9 Step 901 Train Loss: 0.5936
Epoch 9 Step 951 Train Loss: 0.6086
Epoch 9 Step 1001 Train Loss: 0.5827
Epoch 9 Step 1051 Train Loss: 0.5996
Epoch 9 Step 1101 Train Loss: 0.5503
Epoch 9 Step 1151 Train Loss: 0.6617
Epoch 9 Step 1201 Train Loss: 0.5832
Epoch 9 Step 1251 Train Loss: 0.5698
Epoch 9 Step 1301 Train Loss: 0.5368
Epoch 9 Step 1351 Train Loss: 0.5737
Epoch 9 Step 1401 Train Loss: 0.6323
Epoch 9 Step 1451 Train Loss: 0.5768
Epoch 9 Step 1501 Train Loss: 0.5676
Epoch 9 Step 1551 Train Loss: 0.5416
Epoch 9 Step 1601 Train Loss: 0.5766
Epoch 9 Step 1651 Train Loss: 0.5913
Epoch 9 Step 1701 Train Loss: 0.5914
Epoch 9 Step 1751 Train Loss: 0.6318
Epoch 9 Step 1801 Train Loss: 0.6126
Epoch 9 Step 1851 Train Loss: 0.5529
Epoch 9 Step 1901 Train Loss: 0.5493
Epoch 9 Step 1951 Train Loss: 0.6180
Epoch 9 Step 2001 Train Loss: 0.5243
Epoch 9 Step 2051 Train Loss: 0.5736
Epoch 9 Step 2101 Train Loss: 0.5676
Epoch 9 Step 2151 Train Loss: 0.5732
Epoch 9 Step 2201 Train Loss: 0.5316
Epoch 9 Step 2251 Train Loss: 0.5886
Epoch 9 Step 2301 Train Loss: 0.5496
Epoch 9 Step 2351 Train Loss: 0.6076
Epoch 9 Step 2401 Train Loss: 0.5193
Epoch 9 Step 2451 Train Loss: 0.5762
Epoch 9 Step 2501 Train Loss: 0.5883
Epoch 9 Step 2551 Train Loss: 0.5824
Epoch 9 Step 2601 Train Loss: 0.5832
Epoch 9 Step 2651 Train Loss: 0.6296
Epoch 9 Step 2701 Train Loss: 0.5805
Epoch 9 Step 2751 Train Loss: 0.5950
Epoch 9 Step 2801 Train Loss: 0.5758
Epoch 9 Step 2851 Train Loss: 0.5886
Epoch 9 Step 2901 Train Loss: 0.5708
Epoch 9 Step 2951 Train Loss: 0.5581
Epoch 9 Step 3001 Train Loss: 0.5602
Epoch 9 Step 3051 Train Loss: 0.5513
Epoch 9 Step 3101 Train Loss: 0.5502
Epoch 9 Step 3151 Train Loss: 0.5359
Epoch 9 Step 3201 Train Loss: 0.5996
Epoch 9 Step 3251 Train Loss: 0.6024
Epoch 9 Step 3301 Train Loss: 0.5664
Epoch 9 Step 3351 Train Loss: 0.5475
Epoch 9: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.1586 Validation Top 20 DE MSE: 0.1577. 
Epoch 10 Step 1 Train Loss: 0.6128
Epoch 10 Step 51 Train Loss: 0.6108
Epoch 10 Step 101 Train Loss: 0.5883
Epoch 10 Step 151 Train Loss: 0.5724
Epoch 10 Step 201 Train Loss: 0.5981
Epoch 10 Step 251 Train Loss: 0.6161
Epoch 10 Step 301 Train Loss: 0.5814
Epoch 10 Step 351 Train Loss: 0.5839
Epoch 10 Step 401 Train Loss: 0.5605
Epoch 10 Step 451 Train Loss: 0.5443
Epoch 10 Step 501 Train Loss: 0.5380
Epoch 10 Step 551 Train Loss: 0.5873
Epoch 10 Step 601 Train Loss: 0.5838
Epoch 10 Step 651 Train Loss: 0.6328
Epoch 10 Step 701 Train Loss: 0.5591
Epoch 10 Step 751 Train Loss: 0.5368
Epoch 10 Step 801 Train Loss: 0.5201
Epoch 10 Step 851 Train Loss: 0.5808
Epoch 10 Step 901 Train Loss: 0.5929
Epoch 10 Step 951 Train Loss: 0.5160
Epoch 10 Step 1001 Train Loss: 0.6372
Epoch 10 Step 1051 Train Loss: 0.6255
Epoch 10 Step 1101 Train Loss: 0.5599
Epoch 10 Step 1151 Train Loss: 0.5690
Epoch 10 Step 1201 Train Loss: 0.5918
Epoch 10 Step 1251 Train Loss: 0.5903
Epoch 10 Step 1301 Train Loss: 0.5729
Epoch 10 Step 1351 Train Loss: 0.6368
Epoch 10 Step 1401 Train Loss: 0.5695
Epoch 10 Step 1451 Train Loss: 0.6115
Epoch 10 Step 1501 Train Loss: 0.5367
Epoch 10 Step 1551 Train Loss: 0.5675
Epoch 10 Step 1601 Train Loss: 0.5887
Epoch 10 Step 1651 Train Loss: 0.5590
Epoch 10 Step 1701 Train Loss: 0.6410
Epoch 10 Step 1751 Train Loss: 0.6071
Epoch 10 Step 1801 Train Loss: 0.5714
Epoch 10 Step 1851 Train Loss: 0.5205
Epoch 10 Step 1901 Train Loss: 0.5731
Epoch 10 Step 1951 Train Loss: 0.6223
Epoch 10 Step 2001 Train Loss: 0.6399
Epoch 10 Step 2051 Train Loss: 0.6403
Epoch 10 Step 2101 Train Loss: 0.5516
Epoch 10 Step 2151 Train Loss: 0.5577
Epoch 10 Step 2201 Train Loss: 0.5503
Epoch 10 Step 2251 Train Loss: 0.5982
Epoch 10 Step 2301 Train Loss: 0.5109
Epoch 10 Step 2351 Train Loss: 0.5788
Epoch 10 Step 2401 Train Loss: 0.5250
Epoch 10 Step 2451 Train Loss: 0.6287
Epoch 10 Step 2501 Train Loss: 0.6280
Epoch 10 Step 2551 Train Loss: 0.5894
Epoch 10 Step 2601 Train Loss: 0.6253
Epoch 10 Step 2651 Train Loss: 0.5641
Epoch 10 Step 2701 Train Loss: 0.6096
Epoch 10 Step 2751 Train Loss: 0.6324
Epoch 10 Step 2801 Train Loss: 0.6266
Epoch 10 Step 2851 Train Loss: 0.6212
Epoch 10 Step 2901 Train Loss: 0.5553
Epoch 10 Step 2951 Train Loss: 0.6004
Epoch 10 Step 3001 Train Loss: 0.6334
Epoch 10 Step 3051 Train Loss: 0.5687
Epoch 10 Step 3101 Train Loss: 0.6073
Epoch 10 Step 3151 Train Loss: 0.6369
Epoch 10 Step 3201 Train Loss: 0.5297
Epoch 10 Step 3251 Train Loss: 0.5274
Epoch 10 Step 3301 Train Loss: 0.5894
Epoch 10 Step 3351 Train Loss: 0.5801
Epoch 10: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1596 Validation Top 20 DE MSE: 0.1585. 
Epoch 11 Step 1 Train Loss: 0.5864
Epoch 11 Step 51 Train Loss: 0.5488
Epoch 11 Step 101 Train Loss: 0.5514
Epoch 11 Step 151 Train Loss: 0.5942
Epoch 11 Step 201 Train Loss: 0.5994
Epoch 11 Step 251 Train Loss: 0.5456
Epoch 11 Step 301 Train Loss: 0.5819
Epoch 11 Step 351 Train Loss: 0.5844
Epoch 11 Step 401 Train Loss: 0.5687
Epoch 11 Step 451 Train Loss: 0.5831
Epoch 11 Step 501 Train Loss: 0.6372
Epoch 11 Step 551 Train Loss: 0.6024
Epoch 11 Step 601 Train Loss: 0.5405
Epoch 11 Step 651 Train Loss: 0.5908
Epoch 11 Step 701 Train Loss: 0.6164
Epoch 11 Step 751 Train Loss: 0.5896
Epoch 11 Step 801 Train Loss: 0.6155
Epoch 11 Step 851 Train Loss: 0.5954
Epoch 11 Step 901 Train Loss: 0.5579
Epoch 11 Step 951 Train Loss: 0.5559
Epoch 11 Step 1001 Train Loss: 0.6203
Epoch 11 Step 1051 Train Loss: 0.5384
Epoch 11 Step 1101 Train Loss: 0.5822
Epoch 11 Step 1151 Train Loss: 0.5606
Epoch 11 Step 1201 Train Loss: 0.6025
Epoch 11 Step 1251 Train Loss: 0.5934
Epoch 11 Step 1301 Train Loss: 0.5857
Epoch 11 Step 1351 Train Loss: 0.6121
Epoch 11 Step 1401 Train Loss: 0.5497
Epoch 11 Step 1451 Train Loss: 0.6202
Epoch 11 Step 1501 Train Loss: 0.6110
Epoch 11 Step 1551 Train Loss: 0.6140
Epoch 11 Step 1601 Train Loss: 0.5805
Epoch 11 Step 1651 Train Loss: 0.5180
Epoch 11 Step 1701 Train Loss: 0.5767
Epoch 11 Step 1751 Train Loss: 0.5733
Epoch 11 Step 1801 Train Loss: 0.6068
Epoch 11 Step 1851 Train Loss: 0.5678
Epoch 11 Step 1901 Train Loss: 0.5857
Epoch 11 Step 1951 Train Loss: 0.6167
Epoch 11 Step 2001 Train Loss: 0.5862
Epoch 11 Step 2051 Train Loss: 0.5751
Epoch 11 Step 2101 Train Loss: 0.5705
Epoch 11 Step 2151 Train Loss: 0.5838
Epoch 11 Step 2201 Train Loss: 0.5730
Epoch 11 Step 2251 Train Loss: 0.5710
Epoch 11 Step 2301 Train Loss: 0.5171
Epoch 11 Step 2351 Train Loss: 0.5229
Epoch 11 Step 2401 Train Loss: 0.5987
Epoch 11 Step 2451 Train Loss: 0.5700
Epoch 11 Step 2501 Train Loss: 0.6325
Epoch 11 Step 2551 Train Loss: 0.5689
Epoch 11 Step 2601 Train Loss: 0.5807
Epoch 11 Step 2651 Train Loss: 0.6231
Epoch 11 Step 2701 Train Loss: 0.5471
Epoch 11 Step 2751 Train Loss: 0.5634
Epoch 11 Step 2801 Train Loss: 0.5016
Epoch 11 Step 2851 Train Loss: 0.5767
Epoch 11 Step 2901 Train Loss: 0.6125
Epoch 11 Step 2951 Train Loss: 0.5880
Epoch 11 Step 3001 Train Loss: 0.5687
Epoch 11 Step 3051 Train Loss: 0.5631
Epoch 11 Step 3101 Train Loss: 0.5680
Epoch 11 Step 3151 Train Loss: 0.5882
Epoch 11 Step 3201 Train Loss: 0.5708
Epoch 11 Step 3251 Train Loss: 0.5496
Epoch 11 Step 3301 Train Loss: 0.6126
Epoch 11 Step 3351 Train Loss: 0.5944
Epoch 11: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.1579 Validation Top 20 DE MSE: 0.1570. 
Epoch 12 Step 1 Train Loss: 0.5260
Epoch 12 Step 51 Train Loss: 0.6016
Epoch 12 Step 101 Train Loss: 0.6049
Epoch 12 Step 151 Train Loss: 0.6054
Epoch 12 Step 201 Train Loss: 0.6179
Epoch 12 Step 251 Train Loss: 0.5531
Epoch 12 Step 301 Train Loss: 0.6181
Epoch 12 Step 351 Train Loss: 0.5642
Epoch 12 Step 401 Train Loss: 0.5697
Epoch 12 Step 451 Train Loss: 0.6117
Epoch 12 Step 501 Train Loss: 0.4990
Epoch 12 Step 551 Train Loss: 0.5796
Epoch 12 Step 601 Train Loss: 0.5573
Epoch 12 Step 651 Train Loss: 0.5465
Epoch 12 Step 701 Train Loss: 0.5875
Epoch 12 Step 751 Train Loss: 0.5525
Epoch 12 Step 801 Train Loss: 0.6253
Epoch 12 Step 851 Train Loss: 0.6176
Epoch 12 Step 901 Train Loss: 0.5520
Epoch 12 Step 951 Train Loss: 0.5953
Epoch 12 Step 1001 Train Loss: 0.5732
Epoch 12 Step 1051 Train Loss: 0.5751
Epoch 12 Step 1101 Train Loss: 0.5131
Epoch 12 Step 1151 Train Loss: 0.5455
Epoch 12 Step 1201 Train Loss: 0.5378
Epoch 12 Step 1251 Train Loss: 0.5852
Epoch 12 Step 1301 Train Loss: 0.5911
Epoch 12 Step 1351 Train Loss: 0.5896
Epoch 12 Step 1401 Train Loss: 0.5793
Epoch 12 Step 1451 Train Loss: 0.5820
Epoch 12 Step 1501 Train Loss: 0.5829
Epoch 12 Step 1551 Train Loss: 0.5656
Epoch 12 Step 1601 Train Loss: 0.5399
Epoch 12 Step 1651 Train Loss: 0.5456
Epoch 12 Step 1701 Train Loss: 0.6134
Epoch 12 Step 1751 Train Loss: 0.5812
Epoch 12 Step 1801 Train Loss: 0.5294
Epoch 12 Step 1851 Train Loss: 0.5571
Epoch 12 Step 1901 Train Loss: 0.5733
Epoch 12 Step 1951 Train Loss: 0.5770
Epoch 12 Step 2001 Train Loss: 0.6704
Epoch 12 Step 2051 Train Loss: 0.5948
Epoch 12 Step 2101 Train Loss: 0.5553
Epoch 12 Step 2151 Train Loss: 0.5201
Epoch 12 Step 2201 Train Loss: 0.5713
Epoch 12 Step 2251 Train Loss: 0.6084
Epoch 12 Step 2301 Train Loss: 0.6159
Epoch 12 Step 2351 Train Loss: 0.5883
Epoch 12 Step 2401 Train Loss: 0.5627
Epoch 12 Step 2451 Train Loss: 0.5699
Epoch 12 Step 2501 Train Loss: 0.5701
Epoch 12 Step 2551 Train Loss: 0.5714
Epoch 12 Step 2601 Train Loss: 0.6092
Epoch 12 Step 2651 Train Loss: 0.5759
Epoch 12 Step 2701 Train Loss: 0.5487
Epoch 12 Step 2751 Train Loss: 0.6202
Epoch 12 Step 2801 Train Loss: 0.5493
Epoch 12 Step 2851 Train Loss: 0.6155
Epoch 12 Step 2901 Train Loss: 0.5955
Epoch 12 Step 2951 Train Loss: 0.6050
Epoch 12 Step 3001 Train Loss: 0.5148
Epoch 12 Step 3051 Train Loss: 0.6399
Epoch 12 Step 3101 Train Loss: 0.5069
Epoch 12 Step 3151 Train Loss: 0.5619
Epoch 12 Step 3201 Train Loss: 0.6483
Epoch 12 Step 3251 Train Loss: 0.5893
Epoch 12 Step 3301 Train Loss: 0.5584
Epoch 12 Step 3351 Train Loss: 0.5623
Epoch 12: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1597 Validation Top 20 DE MSE: 0.1585. 
Epoch 13 Step 1 Train Loss: 0.5575
Epoch 13 Step 51 Train Loss: 0.5406
Epoch 13 Step 101 Train Loss: 0.6017
Epoch 13 Step 151 Train Loss: 0.6007
Epoch 13 Step 201 Train Loss: 0.6422
Epoch 13 Step 251 Train Loss: 0.5603
Epoch 13 Step 301 Train Loss: 0.5738
Epoch 13 Step 351 Train Loss: 0.6062
Epoch 13 Step 401 Train Loss: 0.6538
Epoch 13 Step 451 Train Loss: 0.5734
Epoch 13 Step 501 Train Loss: 0.5481
Epoch 13 Step 551 Train Loss: 0.5883
Epoch 13 Step 601 Train Loss: 0.5866
Epoch 13 Step 651 Train Loss: 0.6238
Epoch 13 Step 701 Train Loss: 0.6139
Epoch 13 Step 751 Train Loss: 0.5863
Epoch 13 Step 801 Train Loss: 0.5939
Epoch 13 Step 851 Train Loss: 0.6153
Epoch 13 Step 901 Train Loss: 0.6004
Epoch 13 Step 951 Train Loss: 0.5451
Epoch 13 Step 1001 Train Loss: 0.6121
Epoch 13 Step 1051 Train Loss: 0.5770
Epoch 13 Step 1101 Train Loss: 0.5925
Epoch 13 Step 1151 Train Loss: 0.5661
Epoch 13 Step 1201 Train Loss: 0.5600
Epoch 13 Step 1251 Train Loss: 0.5751
Epoch 13 Step 1301 Train Loss: 0.7064
Epoch 13 Step 1351 Train Loss: 0.6006
Epoch 13 Step 1401 Train Loss: 0.6556
Epoch 13 Step 1451 Train Loss: 0.6238
Epoch 13 Step 1501 Train Loss: 0.5751
Epoch 13 Step 1551 Train Loss: 0.5684
Epoch 13 Step 1601 Train Loss: 0.5855
Epoch 13 Step 1651 Train Loss: 0.5585
Epoch 13 Step 1701 Train Loss: 0.5390
Epoch 13 Step 1751 Train Loss: 0.5651
Epoch 13 Step 1801 Train Loss: 0.6144
Epoch 13 Step 1851 Train Loss: 0.5724
Epoch 13 Step 1901 Train Loss: 0.5835
Epoch 13 Step 1951 Train Loss: 0.6091
Epoch 13 Step 2001 Train Loss: 0.6374
Epoch 13 Step 2051 Train Loss: 0.6211
Epoch 13 Step 2101 Train Loss: 0.5731
Epoch 13 Step 2151 Train Loss: 0.5902
Epoch 13 Step 2201 Train Loss: 0.5528
Epoch 13 Step 2251 Train Loss: 0.5905
Epoch 13 Step 2301 Train Loss: 0.5402
Epoch 13 Step 2351 Train Loss: 0.5690
Epoch 13 Step 2401 Train Loss: 0.5592
Epoch 13 Step 2451 Train Loss: 0.5588
Epoch 13 Step 2501 Train Loss: 0.5625
Epoch 13 Step 2551 Train Loss: 0.5936
Epoch 13 Step 2601 Train Loss: 0.5657
Epoch 13 Step 2651 Train Loss: 0.5782
Epoch 13 Step 2701 Train Loss: 0.6420
Epoch 13 Step 2751 Train Loss: 0.6022
Epoch 13 Step 2801 Train Loss: 0.6366
Epoch 13 Step 2851 Train Loss: 0.5620
Epoch 13 Step 2901 Train Loss: 0.5523
Epoch 13 Step 2951 Train Loss: 0.5839
Epoch 13 Step 3001 Train Loss: 0.5723
Epoch 13 Step 3051 Train Loss: 0.5412
Epoch 13 Step 3101 Train Loss: 0.5628
Epoch 13 Step 3151 Train Loss: 0.5512
Epoch 13 Step 3201 Train Loss: 0.5537
Epoch 13 Step 3251 Train Loss: 0.5796
Epoch 13 Step 3301 Train Loss: 0.6789
Epoch 13 Step 3351 Train Loss: 0.6077
Epoch 13: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1587 Validation Top 20 DE MSE: 0.1579. 
Epoch 14 Step 1 Train Loss: 0.6000
Epoch 14 Step 51 Train Loss: 0.5624
Epoch 14 Step 101 Train Loss: 0.6025
Epoch 14 Step 151 Train Loss: 0.5771
Epoch 14 Step 201 Train Loss: 0.5757
Epoch 14 Step 251 Train Loss: 0.6458
Epoch 14 Step 301 Train Loss: 0.5570
Epoch 14 Step 351 Train Loss: 0.5337
Epoch 14 Step 401 Train Loss: 0.5961
Epoch 14 Step 451 Train Loss: 0.6266
Epoch 14 Step 501 Train Loss: 0.5953
Epoch 14 Step 551 Train Loss: 0.5896
Epoch 14 Step 601 Train Loss: 0.5428
Epoch 14 Step 651 Train Loss: 0.6095
Epoch 14 Step 701 Train Loss: 0.6041
Epoch 14 Step 751 Train Loss: 0.6767
Epoch 14 Step 801 Train Loss: 0.5815
Epoch 14 Step 851 Train Loss: 0.5705
Epoch 14 Step 901 Train Loss: 0.5976
Epoch 14 Step 951 Train Loss: 0.5353
Epoch 14 Step 1001 Train Loss: 0.6449
Epoch 14 Step 1051 Train Loss: 0.6364
Epoch 14 Step 1101 Train Loss: 0.5975
Epoch 14 Step 1151 Train Loss: 0.5625
Epoch 14 Step 1201 Train Loss: 0.5257
Epoch 14 Step 1251 Train Loss: 0.6199
Epoch 14 Step 1301 Train Loss: 0.6655
Epoch 14 Step 1351 Train Loss: 0.5822
Epoch 14 Step 1401 Train Loss: 0.6164
Epoch 14 Step 1451 Train Loss: 0.6354
Epoch 14 Step 1501 Train Loss: 0.5160
Epoch 14 Step 1551 Train Loss: 0.6685
Epoch 14 Step 1601 Train Loss: 0.6659
Epoch 14 Step 1651 Train Loss: 0.5495
Epoch 14 Step 1701 Train Loss: 0.5647
Epoch 14 Step 1751 Train Loss: 0.6015
Epoch 14 Step 1801 Train Loss: 0.6011
Epoch 14 Step 1851 Train Loss: 0.5672
Epoch 14 Step 1901 Train Loss: 0.6229
Epoch 14 Step 1951 Train Loss: 0.5610
Epoch 14 Step 2001 Train Loss: 0.5518
Epoch 14 Step 2051 Train Loss: 0.5722
Epoch 14 Step 2101 Train Loss: 0.6094
Epoch 14 Step 2151 Train Loss: 0.5924
Epoch 14 Step 2201 Train Loss: 0.5357
Epoch 14 Step 2251 Train Loss: 0.5425
Epoch 14 Step 2301 Train Loss: 0.5744
Epoch 14 Step 2351 Train Loss: 0.5784
Epoch 14 Step 2401 Train Loss: 0.6205
Epoch 14 Step 2451 Train Loss: 0.5763
Epoch 14 Step 2501 Train Loss: 0.5349
Epoch 14 Step 2551 Train Loss: 0.6326
Epoch 14 Step 2601 Train Loss: 0.5854
Epoch 14 Step 2651 Train Loss: 0.5715
Epoch 14 Step 2701 Train Loss: 0.5600
Epoch 14 Step 2751 Train Loss: 0.6123
Epoch 14 Step 2801 Train Loss: 0.5784
Epoch 14 Step 2851 Train Loss: 0.5773
Epoch 14 Step 2901 Train Loss: 0.5334
Epoch 14 Step 2951 Train Loss: 0.5654
Epoch 14 Step 3001 Train Loss: 0.5622
Epoch 14 Step 3051 Train Loss: 0.5543
Epoch 14 Step 3101 Train Loss: 0.5858
Epoch 14 Step 3151 Train Loss: 0.5333
Epoch 14 Step 3201 Train Loss: 0.5860
Epoch 14 Step 3251 Train Loss: 0.6097
Epoch 14 Step 3301 Train Loss: 0.6048
Epoch 14 Step 3351 Train Loss: 0.5393
Epoch 14: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1573 Validation Top 20 DE MSE: 0.1572. 
Epoch 15 Step 1 Train Loss: 0.6431
Epoch 15 Step 51 Train Loss: 0.5519
Epoch 15 Step 101 Train Loss: 0.5901
Epoch 15 Step 151 Train Loss: 0.6169
Epoch 15 Step 201 Train Loss: 0.5611
Epoch 15 Step 251 Train Loss: 0.5838
Epoch 15 Step 301 Train Loss: 0.5152
Epoch 15 Step 351 Train Loss: 0.5540
Epoch 15 Step 401 Train Loss: 0.6199
Epoch 15 Step 451 Train Loss: 0.5561
Epoch 15 Step 501 Train Loss: 0.6415
Epoch 15 Step 551 Train Loss: 0.5494
Epoch 15 Step 601 Train Loss: 0.6637
Epoch 15 Step 651 Train Loss: 0.6438
Epoch 15 Step 701 Train Loss: 0.5803
Epoch 15 Step 751 Train Loss: 0.6120
Epoch 15 Step 801 Train Loss: 0.5844
Epoch 15 Step 851 Train Loss: 0.5466
Epoch 15 Step 901 Train Loss: 0.6288
Epoch 15 Step 951 Train Loss: 0.5978
Epoch 15 Step 1001 Train Loss: 0.5894
Epoch 15 Step 1051 Train Loss: 0.5900
Epoch 15 Step 1101 Train Loss: 0.5438
Epoch 15 Step 1151 Train Loss: 0.6143
Epoch 15 Step 1201 Train Loss: 0.5592
Epoch 15 Step 1251 Train Loss: 0.5691
Epoch 15 Step 1301 Train Loss: 0.5572
Epoch 15 Step 1351 Train Loss: 0.6206
Epoch 15 Step 1401 Train Loss: 0.5951
Epoch 15 Step 1451 Train Loss: 0.5116
Epoch 15 Step 1501 Train Loss: 0.5351
Epoch 15 Step 1551 Train Loss: 0.5487
Epoch 15 Step 1601 Train Loss: 0.5822
Epoch 15 Step 1651 Train Loss: 0.6020
Epoch 15 Step 1701 Train Loss: 0.5176
Epoch 15 Step 1751 Train Loss: 0.5657
Epoch 15 Step 1801 Train Loss: 0.5813
Epoch 15 Step 1851 Train Loss: 0.5579
Epoch 15 Step 1901 Train Loss: 0.5558
Epoch 15 Step 1951 Train Loss: 0.5233
Epoch 15 Step 2001 Train Loss: 0.5287
Epoch 15 Step 2051 Train Loss: 0.5261
Epoch 15 Step 2101 Train Loss: 0.5380
Epoch 15 Step 2151 Train Loss: 0.5226
Epoch 15 Step 2201 Train Loss: 0.6040
Epoch 15 Step 2251 Train Loss: 0.5919
Epoch 15 Step 2301 Train Loss: 0.5883
Epoch 15 Step 2351 Train Loss: 0.5580
Epoch 15 Step 2401 Train Loss: 0.5935
Epoch 15 Step 2451 Train Loss: 0.5781
Epoch 15 Step 2501 Train Loss: 0.5383
Epoch 15 Step 2551 Train Loss: 0.5749
Epoch 15 Step 2601 Train Loss: 0.6321
Epoch 15 Step 2651 Train Loss: 0.5684
Epoch 15 Step 2701 Train Loss: 0.5305
Epoch 15 Step 2751 Train Loss: 0.5986
Epoch 15 Step 2801 Train Loss: 0.5710
Epoch 15 Step 2851 Train Loss: 0.6004
Epoch 15 Step 2901 Train Loss: 0.5686
Epoch 15 Step 2951 Train Loss: 0.5865
Epoch 15 Step 3001 Train Loss: 0.5717
Epoch 15 Step 3051 Train Loss: 0.6053
Epoch 15 Step 3101 Train Loss: 0.6061
Epoch 15 Step 3151 Train Loss: 0.5642
Epoch 15 Step 3201 Train Loss: 0.5932
Epoch 15 Step 3251 Train Loss: 0.5718
Epoch 15 Step 3301 Train Loss: 0.5241
Epoch 15 Step 3351 Train Loss: 0.5565
Epoch 15: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.1574 Validation Top 20 DE MSE: 0.1569. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1847
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.009666379
test_unseen_single_pearson: 0.9870667119784888
test_unseen_single_mse_de: 0.18465813
test_unseen_single_pearson_de: 0.9029329905627381
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3340842081822155
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.32003745318352067
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7076779026217228
test_unseen_single_mse_top20_de_non_dropout: 0.19325553
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.054 MB uploadedwandb: | 0.003 MB of 0.054 MB uploadedwandb: / 0.054 MB of 0.054 MB uploadedwandb: - 0.054 MB of 0.054 MB uploadedwandb: \ 0.054 MB of 0.054 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñà‚ñÉ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                             train_de_pearson ‚ñÇ‚ñÉ‚ñá‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                                                    train_mse ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ
wandb:                                                   val_de_mse ‚ñá‚ñà‚ñÅ‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:                                               val_de_pearson ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                                                      val_mse ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.18466
wandb:                                              test_de_pearson 0.90293
wandb:               test_frac_opposite_direction_top20_non_dropout 0.32004
wandb:                          test_frac_sigma_below_1_non_dropout 0.70768
wandb:                                                     test_mse 0.00967
wandb:                                test_mse_top20_de_non_dropout 0.19326
wandb:                                                 test_pearson 0.98707
wandb:                                           test_pearson_delta 0.33408
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.32004
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.70768
wandb:                                       test_unseen_single_mse 0.00967
wandb:                                    test_unseen_single_mse_de 0.18466
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.19326
wandb:                                   test_unseen_single_pearson 0.98707
wandb:                                test_unseen_single_pearson_de 0.90293
wandb:                             test_unseen_single_pearson_delta 0.33408
wandb:                                                 train_de_mse 0.1574
wandb:                                             train_de_pearson 0.91431
wandb:                                                    train_mse 0.00759
wandb:                                                train_pearson 0.98941
wandb:                                                training_loss 0.54074
wandb:                                                   val_de_mse 0.15692
wandb:                                               val_de_pearson 0.88148
wandb:                                                      val_mse 0.00885
wandb:                                                  val_pearson 0.9877
wandb: 
wandb: üöÄ View run geneformer_Replogle_k562_essential_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/dwt0x149
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_042006-dwt0x149/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:267
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_070102-xkyt449m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_k562_essential_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/xkyt449m
wandb: WARNING Serializing object of type ndarray that is 23167104 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5626
Epoch 1 Step 51 Train Loss: 0.5835
Epoch 1 Step 101 Train Loss: 0.6183
Epoch 1 Step 151 Train Loss: 0.5925
Epoch 1 Step 201 Train Loss: 0.5274
Epoch 1 Step 251 Train Loss: 0.5724
Epoch 1 Step 301 Train Loss: 0.5556
Epoch 1 Step 351 Train Loss: 0.5736
Epoch 1 Step 401 Train Loss: 0.6109
Epoch 1 Step 451 Train Loss: 0.5803
Epoch 1 Step 501 Train Loss: 0.5793
Epoch 1 Step 551 Train Loss: 0.6124
Epoch 1 Step 601 Train Loss: 0.5874
Epoch 1 Step 651 Train Loss: 0.5448
Epoch 1 Step 701 Train Loss: 0.6075
Epoch 1 Step 751 Train Loss: 0.5780
Epoch 1 Step 801 Train Loss: 0.5586
Epoch 1 Step 851 Train Loss: 0.6436
Epoch 1 Step 901 Train Loss: 0.5438
Epoch 1 Step 951 Train Loss: 0.6417
Epoch 1 Step 1001 Train Loss: 0.5454
Epoch 1 Step 1051 Train Loss: 0.5700
Epoch 1 Step 1101 Train Loss: 0.5413
Epoch 1 Step 1151 Train Loss: 0.5145
Epoch 1 Step 1201 Train Loss: 0.5670
Epoch 1 Step 1251 Train Loss: 0.5824
Epoch 1 Step 1301 Train Loss: 0.6437
Epoch 1 Step 1351 Train Loss: 0.6380
Epoch 1 Step 1401 Train Loss: 0.5657
Epoch 1 Step 1451 Train Loss: 0.5391
Epoch 1 Step 1501 Train Loss: 0.6100
Epoch 1 Step 1551 Train Loss: 0.5940
Epoch 1 Step 1601 Train Loss: 0.5876
Epoch 1 Step 1651 Train Loss: 0.5842
Epoch 1 Step 1701 Train Loss: 0.6343
Epoch 1 Step 1751 Train Loss: 0.5628
Epoch 1 Step 1801 Train Loss: 0.5744
Epoch 1 Step 1851 Train Loss: 0.5688
Epoch 1 Step 1901 Train Loss: 0.5690
Epoch 1 Step 1951 Train Loss: 0.5657
Epoch 1 Step 2001 Train Loss: 0.5723
Epoch 1 Step 2051 Train Loss: 0.6447
Epoch 1 Step 2101 Train Loss: 0.5506
Epoch 1 Step 2151 Train Loss: 0.6100
Epoch 1 Step 2201 Train Loss: 0.5430
Epoch 1 Step 2251 Train Loss: 0.6135
Epoch 1 Step 2301 Train Loss: 0.5653
Epoch 1 Step 2351 Train Loss: 0.6182
Epoch 1 Step 2401 Train Loss: 0.6202
Epoch 1 Step 2451 Train Loss: 0.6256
Epoch 1 Step 2501 Train Loss: 0.5970
Epoch 1 Step 2551 Train Loss: 0.6374
Epoch 1 Step 2601 Train Loss: 0.5741
Epoch 1 Step 2651 Train Loss: 0.5457
Epoch 1 Step 2701 Train Loss: 0.5310
Epoch 1 Step 2751 Train Loss: 0.6217
Epoch 1 Step 2801 Train Loss: 0.6153
Epoch 1 Step 2851 Train Loss: 0.5874
Epoch 1 Step 2901 Train Loss: 0.5943
Epoch 1 Step 2951 Train Loss: 0.6037
Epoch 1 Step 3001 Train Loss: 0.5558
Epoch 1 Step 3051 Train Loss: 0.6153
Epoch 1 Step 3101 Train Loss: 0.5794
Epoch 1 Step 3151 Train Loss: 0.5170
Epoch 1 Step 3201 Train Loss: 0.5607
Epoch 1 Step 3251 Train Loss: 0.5718
Epoch 1 Step 3301 Train Loss: 0.6062
Epoch 1 Step 3351 Train Loss: 0.5722
Epoch 1 Step 3401 Train Loss: 0.5622
Epoch 1: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0098. 
Train Top 20 DE MSE: 0.1706 Validation Top 20 DE MSE: 0.2010. 
Epoch 2 Step 1 Train Loss: 0.5940
Epoch 2 Step 51 Train Loss: 0.5642
Epoch 2 Step 101 Train Loss: 0.5207
Epoch 2 Step 151 Train Loss: 0.6356
Epoch 2 Step 201 Train Loss: 0.6244
Epoch 2 Step 251 Train Loss: 0.5181
Epoch 2 Step 301 Train Loss: 0.5022
Epoch 2 Step 351 Train Loss: 0.5615
Epoch 2 Step 401 Train Loss: 0.6226
Epoch 2 Step 451 Train Loss: 0.6217
Epoch 2 Step 501 Train Loss: 0.6317
Epoch 2 Step 551 Train Loss: 0.5833
Epoch 2 Step 601 Train Loss: 0.5797
Epoch 2 Step 651 Train Loss: 0.5199
Epoch 2 Step 701 Train Loss: 0.5218
Epoch 2 Step 751 Train Loss: 0.5968
Epoch 2 Step 801 Train Loss: 0.5407
Epoch 2 Step 851 Train Loss: 0.5678
Epoch 2 Step 901 Train Loss: 0.5810
Epoch 2 Step 951 Train Loss: 0.6191
Epoch 2 Step 1001 Train Loss: 0.5996
Epoch 2 Step 1051 Train Loss: 0.5621
Epoch 2 Step 1101 Train Loss: 0.5309
Epoch 2 Step 1151 Train Loss: 0.5899
Epoch 2 Step 1201 Train Loss: 0.5547
Epoch 2 Step 1251 Train Loss: 0.6154
Epoch 2 Step 1301 Train Loss: 0.6421
Epoch 2 Step 1351 Train Loss: 0.6257
Epoch 2 Step 1401 Train Loss: 0.5287
Epoch 2 Step 1451 Train Loss: 0.6072
Epoch 2 Step 1501 Train Loss: 0.5679
Epoch 2 Step 1551 Train Loss: 0.5722
Epoch 2 Step 1601 Train Loss: 0.5840
Epoch 2 Step 1651 Train Loss: 0.5871
Epoch 2 Step 1701 Train Loss: 0.6314
Epoch 2 Step 1751 Train Loss: 0.6049
Epoch 2 Step 1801 Train Loss: 0.5215
Epoch 2 Step 1851 Train Loss: 0.5728
Epoch 2 Step 1901 Train Loss: 0.6136
Epoch 2 Step 1951 Train Loss: 0.5702
Epoch 2 Step 2001 Train Loss: 0.5964
Epoch 2 Step 2051 Train Loss: 0.6452
Epoch 2 Step 2101 Train Loss: 0.5568
Epoch 2 Step 2151 Train Loss: 0.5794
Epoch 2 Step 2201 Train Loss: 0.5381
Epoch 2 Step 2251 Train Loss: 0.5718
Epoch 2 Step 2301 Train Loss: 0.5889
Epoch 2 Step 2351 Train Loss: 0.5608
Epoch 2 Step 2401 Train Loss: 0.5782
Epoch 2 Step 2451 Train Loss: 0.5958
Epoch 2 Step 2501 Train Loss: 0.6366
Epoch 2 Step 2551 Train Loss: 0.5836
Epoch 2 Step 2601 Train Loss: 0.5372
Epoch 2 Step 2651 Train Loss: 0.5799
Epoch 2 Step 2701 Train Loss: 0.5278
Epoch 2 Step 2751 Train Loss: 0.5419
Epoch 2 Step 2801 Train Loss: 0.5701
Epoch 2 Step 2851 Train Loss: 0.5479
Epoch 2 Step 2901 Train Loss: 0.5649
Epoch 2 Step 2951 Train Loss: 0.5900
Epoch 2 Step 3001 Train Loss: 0.5811
Epoch 2 Step 3051 Train Loss: 0.5954
Epoch 2 Step 3101 Train Loss: 0.6092
Epoch 2 Step 3151 Train Loss: 0.6003
Epoch 2 Step 3201 Train Loss: 0.5659
Epoch 2 Step 3251 Train Loss: 0.6056
Epoch 2 Step 3301 Train Loss: 0.6270
Epoch 2 Step 3351 Train Loss: 0.5881
Epoch 2 Step 3401 Train Loss: 0.6172
Epoch 2: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0104. 
Train Top 20 DE MSE: 0.1556 Validation Top 20 DE MSE: 0.1925. 
Epoch 3 Step 1 Train Loss: 0.5571
Epoch 3 Step 51 Train Loss: 0.5070
Epoch 3 Step 101 Train Loss: 0.5718
Epoch 3 Step 151 Train Loss: 0.6830
Epoch 3 Step 201 Train Loss: 0.5697
Epoch 3 Step 251 Train Loss: 0.6012
Epoch 3 Step 301 Train Loss: 0.5554
Epoch 3 Step 351 Train Loss: 0.5987
Epoch 3 Step 401 Train Loss: 0.5757
Epoch 3 Step 451 Train Loss: 0.5145
Epoch 3 Step 501 Train Loss: 0.6128
Epoch 3 Step 551 Train Loss: 0.5776
Epoch 3 Step 601 Train Loss: 0.5972
Epoch 3 Step 651 Train Loss: 0.6086
Epoch 3 Step 701 Train Loss: 0.5371
Epoch 3 Step 751 Train Loss: 0.5345
Epoch 3 Step 801 Train Loss: 0.5892
Epoch 3 Step 851 Train Loss: 0.5888
Epoch 3 Step 901 Train Loss: 0.5863
Epoch 3 Step 951 Train Loss: 0.5938
Epoch 3 Step 1001 Train Loss: 0.6568
Epoch 3 Step 1051 Train Loss: 0.5338
Epoch 3 Step 1101 Train Loss: 0.5942
Epoch 3 Step 1151 Train Loss: 0.5793
Epoch 3 Step 1201 Train Loss: 0.5796
Epoch 3 Step 1251 Train Loss: 0.5669
Epoch 3 Step 1301 Train Loss: 0.6280
Epoch 3 Step 1351 Train Loss: 0.5828
Epoch 3 Step 1401 Train Loss: 0.5716
Epoch 3 Step 1451 Train Loss: 0.5545
Epoch 3 Step 1501 Train Loss: 0.5535
Epoch 3 Step 1551 Train Loss: 0.5585
Epoch 3 Step 1601 Train Loss: 0.5132
Epoch 3 Step 1651 Train Loss: 0.5513
Epoch 3 Step 1701 Train Loss: 0.5760
Epoch 3 Step 1751 Train Loss: 0.5842
Epoch 3 Step 1801 Train Loss: 0.5518
Epoch 3 Step 1851 Train Loss: 0.5811
Epoch 3 Step 1901 Train Loss: 0.6388
Epoch 3 Step 1951 Train Loss: 0.5369
Epoch 3 Step 2001 Train Loss: 0.5668
Epoch 3 Step 2051 Train Loss: 0.5940
Epoch 3 Step 2101 Train Loss: 0.5626
Epoch 3 Step 2151 Train Loss: 0.5803
Epoch 3 Step 2201 Train Loss: 0.5558
Epoch 3 Step 2251 Train Loss: 0.5863
Epoch 3 Step 2301 Train Loss: 0.5518
Epoch 3 Step 2351 Train Loss: 0.5592
Epoch 3 Step 2401 Train Loss: 0.6381
Epoch 3 Step 2451 Train Loss: 0.6117
Epoch 3 Step 2501 Train Loss: 0.5839
Epoch 3 Step 2551 Train Loss: 0.5723
Epoch 3 Step 2601 Train Loss: 0.5753
Epoch 3 Step 2651 Train Loss: 0.5895
Epoch 3 Step 2701 Train Loss: 0.5719
Epoch 3 Step 2751 Train Loss: 0.5637
Epoch 3 Step 2801 Train Loss: 0.5914
Epoch 3 Step 2851 Train Loss: 0.6022
Epoch 3 Step 2901 Train Loss: 0.5641
Epoch 3 Step 2951 Train Loss: 0.6088
Epoch 3 Step 3001 Train Loss: 0.5633
Epoch 3 Step 3051 Train Loss: 0.5876
Epoch 3 Step 3101 Train Loss: 0.5602
Epoch 3 Step 3151 Train Loss: 0.5485
Epoch 3 Step 3201 Train Loss: 0.6218
Epoch 3 Step 3251 Train Loss: 0.6169
Epoch 3 Step 3301 Train Loss: 0.5423
Epoch 3 Step 3351 Train Loss: 0.5914
Epoch 3 Step 3401 Train Loss: 0.5169
Epoch 3: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0101. 
Train Top 20 DE MSE: 0.1562 Validation Top 20 DE MSE: 0.1935. 
Epoch 4 Step 1 Train Loss: 0.5703
Epoch 4 Step 51 Train Loss: 0.5227
Epoch 4 Step 101 Train Loss: 0.5610
Epoch 4 Step 151 Train Loss: 0.5860
Epoch 4 Step 201 Train Loss: 0.5870
Epoch 4 Step 251 Train Loss: 0.5722
Epoch 4 Step 301 Train Loss: 0.5147
Epoch 4 Step 351 Train Loss: 0.5853
Epoch 4 Step 401 Train Loss: 0.5616
Epoch 4 Step 451 Train Loss: 0.5951
Epoch 4 Step 501 Train Loss: 0.5763
Epoch 4 Step 551 Train Loss: 0.6009
Epoch 4 Step 601 Train Loss: 0.6353
Epoch 4 Step 651 Train Loss: 0.6040
Epoch 4 Step 701 Train Loss: 0.6148
Epoch 4 Step 751 Train Loss: 0.5396
Epoch 4 Step 801 Train Loss: 0.5758
Epoch 4 Step 851 Train Loss: 0.5967
Epoch 4 Step 901 Train Loss: 0.5373
Epoch 4 Step 951 Train Loss: 0.5847
Epoch 4 Step 1001 Train Loss: 0.6040
Epoch 4 Step 1051 Train Loss: 0.5666
Epoch 4 Step 1101 Train Loss: 0.5894
Epoch 4 Step 1151 Train Loss: 0.5865
Epoch 4 Step 1201 Train Loss: 0.5306
Epoch 4 Step 1251 Train Loss: 0.5886
Epoch 4 Step 1301 Train Loss: 0.5897
Epoch 4 Step 1351 Train Loss: 0.5926
Epoch 4 Step 1401 Train Loss: 0.5803
Epoch 4 Step 1451 Train Loss: 0.5645
Epoch 4 Step 1501 Train Loss: 0.5775
Epoch 4 Step 1551 Train Loss: 0.6138
Epoch 4 Step 1601 Train Loss: 0.5403
Epoch 4 Step 1651 Train Loss: 0.6035
Epoch 4 Step 1701 Train Loss: 0.5471
Epoch 4 Step 1751 Train Loss: 0.6149
Epoch 4 Step 1801 Train Loss: 0.6112
Epoch 4 Step 1851 Train Loss: 0.6322
Epoch 4 Step 1901 Train Loss: 0.5839
Epoch 4 Step 1951 Train Loss: 0.6234
Epoch 4 Step 2001 Train Loss: 0.6501
Epoch 4 Step 2051 Train Loss: 0.5549
Epoch 4 Step 2101 Train Loss: 0.5564
Epoch 4 Step 2151 Train Loss: 0.5730
Epoch 4 Step 2201 Train Loss: 0.5782
Epoch 4 Step 2251 Train Loss: 0.6236
Epoch 4 Step 2301 Train Loss: 0.5298
Epoch 4 Step 2351 Train Loss: 0.5590
Epoch 4 Step 2401 Train Loss: 0.5704
Epoch 4 Step 2451 Train Loss: 0.5849
Epoch 4 Step 2501 Train Loss: 0.5693
Epoch 4 Step 2551 Train Loss: 0.5528
Epoch 4 Step 2601 Train Loss: 0.5813
Epoch 4 Step 2651 Train Loss: 0.5641
Epoch 4 Step 2701 Train Loss: 0.6344
Epoch 4 Step 2751 Train Loss: 0.5512
Epoch 4 Step 2801 Train Loss: 0.5673
Epoch 4 Step 2851 Train Loss: 0.5858
Epoch 4 Step 2901 Train Loss: 0.5854
Epoch 4 Step 2951 Train Loss: 0.5638
Epoch 4 Step 3001 Train Loss: 0.5448
Epoch 4 Step 3051 Train Loss: 0.5732
Epoch 4 Step 3101 Train Loss: 0.5868
Epoch 4 Step 3151 Train Loss: 0.6021
Epoch 4 Step 3201 Train Loss: 0.5759
Epoch 4 Step 3251 Train Loss: 0.5616
Epoch 4 Step 3301 Train Loss: 0.5539
Epoch 4 Step 3351 Train Loss: 0.6100
Epoch 4 Step 3401 Train Loss: 0.6332
Epoch 4: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0096. 
Train Top 20 DE MSE: 0.1586 Validation Top 20 DE MSE: 0.1925. 
Epoch 5 Step 1 Train Loss: 0.6081
Epoch 5 Step 51 Train Loss: 0.5514
Epoch 5 Step 101 Train Loss: 0.5516
Epoch 5 Step 151 Train Loss: 0.6134
Epoch 5 Step 201 Train Loss: 0.5694
Epoch 5 Step 251 Train Loss: 0.6596
Epoch 5 Step 301 Train Loss: 0.5965
Epoch 5 Step 351 Train Loss: 0.6261
Epoch 5 Step 401 Train Loss: 0.5383
Epoch 5 Step 451 Train Loss: 0.5558
Epoch 5 Step 501 Train Loss: 0.5820
Epoch 5 Step 551 Train Loss: 0.5641
Epoch 5 Step 601 Train Loss: 0.5949
Epoch 5 Step 651 Train Loss: 0.5140
Epoch 5 Step 701 Train Loss: 0.5990
Epoch 5 Step 751 Train Loss: 0.5568
Epoch 5 Step 801 Train Loss: 0.5113
Epoch 5 Step 851 Train Loss: 0.5748
Epoch 5 Step 901 Train Loss: 0.6402
Epoch 5 Step 951 Train Loss: 0.6268
Epoch 5 Step 1001 Train Loss: 0.5552
Epoch 5 Step 1051 Train Loss: 0.5584
Epoch 5 Step 1101 Train Loss: 0.5592
Epoch 5 Step 1151 Train Loss: 0.6038
Epoch 5 Step 1201 Train Loss: 0.5860
Epoch 5 Step 1251 Train Loss: 0.5854
Epoch 5 Step 1301 Train Loss: 0.5216
Epoch 5 Step 1351 Train Loss: 0.5890
Epoch 5 Step 1401 Train Loss: 0.6557
Epoch 5 Step 1451 Train Loss: 0.5534
Epoch 5 Step 1501 Train Loss: 0.5466
Epoch 5 Step 1551 Train Loss: 0.5869
Epoch 5 Step 1601 Train Loss: 0.6081
Epoch 5 Step 1651 Train Loss: 0.5640
Epoch 5 Step 1701 Train Loss: 0.5886
Epoch 5 Step 1751 Train Loss: 0.5166
Epoch 5 Step 1801 Train Loss: 0.5815
Epoch 5 Step 1851 Train Loss: 0.5479
Epoch 5 Step 1901 Train Loss: 0.5833
Epoch 5 Step 1951 Train Loss: 0.5822
Epoch 5 Step 2001 Train Loss: 0.5786
Epoch 5 Step 2051 Train Loss: 0.5386
Epoch 5 Step 2101 Train Loss: 0.6290
Epoch 5 Step 2151 Train Loss: 0.5913
Epoch 5 Step 2201 Train Loss: 0.5923
Epoch 5 Step 2251 Train Loss: 0.5503
Epoch 5 Step 2301 Train Loss: 0.5328
Epoch 5 Step 2351 Train Loss: 0.5646
Epoch 5 Step 2401 Train Loss: 0.5744
Epoch 5 Step 2451 Train Loss: 0.5661
Epoch 5 Step 2501 Train Loss: 0.5507
Epoch 5 Step 2551 Train Loss: 0.6080
Epoch 5 Step 2601 Train Loss: 0.6461
Epoch 5 Step 2651 Train Loss: 0.5559
Epoch 5 Step 2701 Train Loss: 0.5743
Epoch 5 Step 2751 Train Loss: 0.5708
Epoch 5 Step 2801 Train Loss: 0.5363
Epoch 5 Step 2851 Train Loss: 0.5688
Epoch 5 Step 2901 Train Loss: 0.5301
Epoch 5 Step 2951 Train Loss: 0.5751
Epoch 5 Step 3001 Train Loss: 0.5851
Epoch 5 Step 3051 Train Loss: 0.6082
Epoch 5 Step 3101 Train Loss: 0.5734
Epoch 5 Step 3151 Train Loss: 0.5865
Epoch 5 Step 3201 Train Loss: 0.5799
Epoch 5 Step 3251 Train Loss: 0.6098
Epoch 5 Step 3301 Train Loss: 0.5956
Epoch 5 Step 3351 Train Loss: 0.5039
Epoch 5 Step 3401 Train Loss: 0.5870
Epoch 5: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0113. 
Train Top 20 DE MSE: 0.1642 Validation Top 20 DE MSE: 0.2003. 
Epoch 6 Step 1 Train Loss: 0.5652
Epoch 6 Step 51 Train Loss: 0.5994
Epoch 6 Step 101 Train Loss: 0.5684
Epoch 6 Step 151 Train Loss: 0.6012
Epoch 6 Step 201 Train Loss: 0.4893
Epoch 6 Step 251 Train Loss: 0.6009
Epoch 6 Step 301 Train Loss: 0.6516
Epoch 6 Step 351 Train Loss: 0.5256
Epoch 6 Step 401 Train Loss: 0.5447
Epoch 6 Step 451 Train Loss: 0.5492
Epoch 6 Step 501 Train Loss: 0.6133
Epoch 6 Step 551 Train Loss: 0.5933
Epoch 6 Step 601 Train Loss: 0.6343
Epoch 6 Step 651 Train Loss: 0.5646
Epoch 6 Step 701 Train Loss: 0.6002
Epoch 6 Step 751 Train Loss: 0.5416
Epoch 6 Step 801 Train Loss: 0.5527
Epoch 6 Step 851 Train Loss: 0.6198
Epoch 6 Step 901 Train Loss: 0.5772
Epoch 6 Step 951 Train Loss: 0.5889
Epoch 6 Step 1001 Train Loss: 0.5751
Epoch 6 Step 1051 Train Loss: 0.6073
Epoch 6 Step 1101 Train Loss: 0.5517
Epoch 6 Step 1151 Train Loss: 0.6226
Epoch 6 Step 1201 Train Loss: 0.6301
Epoch 6 Step 1251 Train Loss: 0.5665
Epoch 6 Step 1301 Train Loss: 0.5539
Epoch 6 Step 1351 Train Loss: 0.5791
Epoch 6 Step 1401 Train Loss: 0.5374
Epoch 6 Step 1451 Train Loss: 0.5811
Epoch 6 Step 1501 Train Loss: 0.5814
Epoch 6 Step 1551 Train Loss: 0.5890
Epoch 6 Step 1601 Train Loss: 0.6245
Epoch 6 Step 1651 Train Loss: 0.6576
Epoch 6 Step 1701 Train Loss: 0.5501
Epoch 6 Step 1751 Train Loss: 0.6065
Epoch 6 Step 1801 Train Loss: 0.5774
Epoch 6 Step 1851 Train Loss: 0.5662
Epoch 6 Step 1901 Train Loss: 0.5874
Epoch 6 Step 1951 Train Loss: 0.5744
Epoch 6 Step 2001 Train Loss: 0.5980
Epoch 6 Step 2051 Train Loss: 0.5685
Epoch 6 Step 2101 Train Loss: 0.5872
Epoch 6 Step 2151 Train Loss: 0.5784
Epoch 6 Step 2201 Train Loss: 0.5298
Epoch 6 Step 2251 Train Loss: 0.5935
Epoch 6 Step 2301 Train Loss: 0.6037
Epoch 6 Step 2351 Train Loss: 0.5535
Epoch 6 Step 2401 Train Loss: 0.5530
Epoch 6 Step 2451 Train Loss: 0.6052
Epoch 6 Step 2501 Train Loss: 0.5300
Epoch 6 Step 2551 Train Loss: 0.6200
Epoch 6 Step 2601 Train Loss: 0.5900
Epoch 6 Step 2651 Train Loss: 0.6095
Epoch 6 Step 2701 Train Loss: 0.6585
Epoch 6 Step 2751 Train Loss: 0.5246
Epoch 6 Step 2801 Train Loss: 0.5763
Epoch 6 Step 2851 Train Loss: 0.6080
Epoch 6 Step 2901 Train Loss: 0.5779
Epoch 6 Step 2951 Train Loss: 0.6474
Epoch 6 Step 3001 Train Loss: 0.5632
Epoch 6 Step 3051 Train Loss: 0.5522
Epoch 6 Step 3101 Train Loss: 0.5465
Epoch 6 Step 3151 Train Loss: 0.6231
Epoch 6 Step 3201 Train Loss: 0.5494
Epoch 6 Step 3251 Train Loss: 0.5751
Epoch 6 Step 3301 Train Loss: 0.5447
Epoch 6 Step 3351 Train Loss: 0.5721
Epoch 6 Step 3401 Train Loss: 0.5269
Epoch 6: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0097. 
Train Top 20 DE MSE: 0.1672 Validation Top 20 DE MSE: 0.2016. 
Epoch 7 Step 1 Train Loss: 0.6096
Epoch 7 Step 51 Train Loss: 0.5372
Epoch 7 Step 101 Train Loss: 0.5476
Epoch 7 Step 151 Train Loss: 0.5318
Epoch 7 Step 201 Train Loss: 0.5889
Epoch 7 Step 251 Train Loss: 0.5840
Epoch 7 Step 301 Train Loss: 0.5540
Epoch 7 Step 351 Train Loss: 0.6161
Epoch 7 Step 401 Train Loss: 0.5613
Epoch 7 Step 451 Train Loss: 0.6841
Epoch 7 Step 501 Train Loss: 0.5728
Epoch 7 Step 551 Train Loss: 0.5326
Epoch 7 Step 601 Train Loss: 0.5672
Epoch 7 Step 651 Train Loss: 0.5437
Epoch 7 Step 701 Train Loss: 0.5878
Epoch 7 Step 751 Train Loss: 0.5539
Epoch 7 Step 801 Train Loss: 0.5723
Epoch 7 Step 851 Train Loss: 0.5611
Epoch 7 Step 901 Train Loss: 0.5558
Epoch 7 Step 951 Train Loss: 0.5901
Epoch 7 Step 1001 Train Loss: 0.5522
Epoch 7 Step 1051 Train Loss: 0.5737
Epoch 7 Step 1101 Train Loss: 0.5971
Epoch 7 Step 1151 Train Loss: 0.5368
Epoch 7 Step 1201 Train Loss: 0.5450
Epoch 7 Step 1251 Train Loss: 0.6018
Epoch 7 Step 1301 Train Loss: 0.5571
Epoch 7 Step 1351 Train Loss: 0.6218
Epoch 7 Step 1401 Train Loss: 0.5464
Epoch 7 Step 1451 Train Loss: 0.5825
Epoch 7 Step 1501 Train Loss: 0.6014
Epoch 7 Step 1551 Train Loss: 0.6165
Epoch 7 Step 1601 Train Loss: 0.5949
Epoch 7 Step 1651 Train Loss: 0.6448
Epoch 7 Step 1701 Train Loss: 0.6173
Epoch 7 Step 1751 Train Loss: 0.6230
Epoch 7 Step 1801 Train Loss: 0.6005
Epoch 7 Step 1851 Train Loss: 0.5443
Epoch 7 Step 1901 Train Loss: 0.6228
Epoch 7 Step 1951 Train Loss: 0.5677
Epoch 7 Step 2001 Train Loss: 0.6352
Epoch 7 Step 2051 Train Loss: 0.5815
Epoch 7 Step 2101 Train Loss: 0.6358
Epoch 7 Step 2151 Train Loss: 0.5607
Epoch 7 Step 2201 Train Loss: 0.6661
Epoch 7 Step 2251 Train Loss: 0.5334
Epoch 7 Step 2301 Train Loss: 0.5590
Epoch 7 Step 2351 Train Loss: 0.5773
Epoch 7 Step 2401 Train Loss: 0.5605
Epoch 7 Step 2451 Train Loss: 0.5406
Epoch 7 Step 2501 Train Loss: 0.6173
Epoch 7 Step 2551 Train Loss: 0.5947
Epoch 7 Step 2601 Train Loss: 0.5210
Epoch 7 Step 2651 Train Loss: 0.6105
Epoch 7 Step 2701 Train Loss: 0.6124
Epoch 7 Step 2751 Train Loss: 0.5491
Epoch 7 Step 2801 Train Loss: 0.5232
Epoch 7 Step 2851 Train Loss: 0.5618
Epoch 7 Step 2901 Train Loss: 0.6228
Epoch 7 Step 2951 Train Loss: 0.6259
Epoch 7 Step 3001 Train Loss: 0.6047
Epoch 7 Step 3051 Train Loss: 0.5844
Epoch 7 Step 3101 Train Loss: 0.5699
Epoch 7 Step 3151 Train Loss: 0.5808
Epoch 7 Step 3201 Train Loss: 0.6002
Epoch 7 Step 3251 Train Loss: 0.5913
Epoch 7 Step 3301 Train Loss: 0.5491
Epoch 7 Step 3351 Train Loss: 0.5394
Epoch 7 Step 3401 Train Loss: 0.5598
Epoch 7: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0097. 
Train Top 20 DE MSE: 0.1608 Validation Top 20 DE MSE: 0.1968. 
Epoch 8 Step 1 Train Loss: 0.6254
Epoch 8 Step 51 Train Loss: 0.5619
Epoch 8 Step 101 Train Loss: 0.5463
Epoch 8 Step 151 Train Loss: 0.5433
Epoch 8 Step 201 Train Loss: 0.5731
Epoch 8 Step 251 Train Loss: 0.6409
Epoch 8 Step 301 Train Loss: 0.5979
Epoch 8 Step 351 Train Loss: 0.5526
Epoch 8 Step 401 Train Loss: 0.5335
Epoch 8 Step 451 Train Loss: 0.5951
Epoch 8 Step 501 Train Loss: 0.6057
Epoch 8 Step 551 Train Loss: 0.6150
Epoch 8 Step 601 Train Loss: 0.5622
Epoch 8 Step 651 Train Loss: 0.5491
Epoch 8 Step 701 Train Loss: 0.5506
Epoch 8 Step 751 Train Loss: 0.5486
Epoch 8 Step 801 Train Loss: 0.5371
Epoch 8 Step 851 Train Loss: 0.5203
Epoch 8 Step 901 Train Loss: 0.6266
Epoch 8 Step 951 Train Loss: 0.6069
Epoch 8 Step 1001 Train Loss: 0.5457
Epoch 8 Step 1051 Train Loss: 0.6225
Epoch 8 Step 1101 Train Loss: 0.5955
Epoch 8 Step 1151 Train Loss: 0.5497
Epoch 8 Step 1201 Train Loss: 0.5225
Epoch 8 Step 1251 Train Loss: 0.5822
Epoch 8 Step 1301 Train Loss: 0.5767
Epoch 8 Step 1351 Train Loss: 0.5623
Epoch 8 Step 1401 Train Loss: 0.5455
Epoch 8 Step 1451 Train Loss: 0.5647
Epoch 8 Step 1501 Train Loss: 0.5663
Epoch 8 Step 1551 Train Loss: 0.6103
Epoch 8 Step 1601 Train Loss: 0.5389
Epoch 8 Step 1651 Train Loss: 0.6226
Epoch 8 Step 1701 Train Loss: 0.6251
Epoch 8 Step 1751 Train Loss: 0.5620
Epoch 8 Step 1801 Train Loss: 0.5843
Epoch 8 Step 1851 Train Loss: 0.5713
Epoch 8 Step 1901 Train Loss: 0.5563
Epoch 8 Step 1951 Train Loss: 0.5266
Epoch 8 Step 2001 Train Loss: 0.5613
Epoch 8 Step 2051 Train Loss: 0.5497
Epoch 8 Step 2101 Train Loss: 0.5502
Epoch 8 Step 2151 Train Loss: 0.5953
Epoch 8 Step 2201 Train Loss: 0.6472
Epoch 8 Step 2251 Train Loss: 0.5985
Epoch 8 Step 2301 Train Loss: 0.6042
Epoch 8 Step 2351 Train Loss: 0.6707
Epoch 8 Step 2401 Train Loss: 0.6030
Epoch 8 Step 2451 Train Loss: 0.5823
Epoch 8 Step 2501 Train Loss: 0.6077
Epoch 8 Step 2551 Train Loss: 0.6050
Epoch 8 Step 2601 Train Loss: 0.5795
Epoch 8 Step 2651 Train Loss: 0.6130
Epoch 8 Step 2701 Train Loss: 0.5666
Epoch 8 Step 2751 Train Loss: 0.5814
Epoch 8 Step 2801 Train Loss: 0.5070
Epoch 8 Step 2851 Train Loss: 0.6211
Epoch 8 Step 2901 Train Loss: 0.5787
Epoch 8 Step 2951 Train Loss: 0.6592
Epoch 8 Step 3001 Train Loss: 0.6041
Epoch 8 Step 3051 Train Loss: 0.5494
Epoch 8 Step 3101 Train Loss: 0.5238
Epoch 8 Step 3151 Train Loss: 0.6040
Epoch 8 Step 3201 Train Loss: 0.5583
Epoch 8 Step 3251 Train Loss: 0.6001
Epoch 8 Step 3301 Train Loss: 0.5363
Epoch 8 Step 3351 Train Loss: 0.5589
Epoch 8 Step 3401 Train Loss: 0.6044
Epoch 8: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0100. 
Train Top 20 DE MSE: 0.1558 Validation Top 20 DE MSE: 0.1944. 
Epoch 9 Step 1 Train Loss: 0.5186
Epoch 9 Step 51 Train Loss: 0.5865
Epoch 9 Step 101 Train Loss: 0.6163
Epoch 9 Step 151 Train Loss: 0.5494
Epoch 9 Step 201 Train Loss: 0.5786
Epoch 9 Step 251 Train Loss: 0.5162
Epoch 9 Step 301 Train Loss: 0.6127
Epoch 9 Step 351 Train Loss: 0.5910
Epoch 9 Step 401 Train Loss: 0.6074
Epoch 9 Step 451 Train Loss: 0.5285
Epoch 9 Step 501 Train Loss: 0.5835
Epoch 9 Step 551 Train Loss: 0.5931
Epoch 9 Step 601 Train Loss: 0.5657
Epoch 9 Step 651 Train Loss: 0.5644
Epoch 9 Step 701 Train Loss: 0.6502
Epoch 9 Step 751 Train Loss: 0.5925
Epoch 9 Step 801 Train Loss: 0.5719
Epoch 9 Step 851 Train Loss: 0.5624
Epoch 9 Step 901 Train Loss: 0.6069
Epoch 9 Step 951 Train Loss: 0.6198
Epoch 9 Step 1001 Train Loss: 0.5500
Epoch 9 Step 1051 Train Loss: 0.5615
Epoch 9 Step 1101 Train Loss: 0.5897
Epoch 9 Step 1151 Train Loss: 0.5918
Epoch 9 Step 1201 Train Loss: 0.6054
Epoch 9 Step 1251 Train Loss: 0.5915
Epoch 9 Step 1301 Train Loss: 0.5713
Epoch 9 Step 1351 Train Loss: 0.6508
Epoch 9 Step 1401 Train Loss: 0.5391
Epoch 9 Step 1451 Train Loss: 0.5684
Epoch 9 Step 1501 Train Loss: 0.5322
Epoch 9 Step 1551 Train Loss: 0.5422
Epoch 9 Step 1601 Train Loss: 0.5544
Epoch 9 Step 1651 Train Loss: 0.5837
Epoch 9 Step 1701 Train Loss: 0.5190
Epoch 9 Step 1751 Train Loss: 0.5708
Epoch 9 Step 1801 Train Loss: 0.4943
Epoch 9 Step 1851 Train Loss: 0.5649
Epoch 9 Step 1901 Train Loss: 0.5522
Epoch 9 Step 1951 Train Loss: 0.5457
Epoch 9 Step 2001 Train Loss: 0.5612
Epoch 9 Step 2051 Train Loss: 0.6553
Epoch 9 Step 2101 Train Loss: 0.5523
Epoch 9 Step 2151 Train Loss: 0.5285
Epoch 9 Step 2201 Train Loss: 0.5660
Epoch 9 Step 2251 Train Loss: 0.5394
Epoch 9 Step 2301 Train Loss: 0.5385
Epoch 9 Step 2351 Train Loss: 0.6244
Epoch 9 Step 2401 Train Loss: 0.5771
Epoch 9 Step 2451 Train Loss: 0.5809
Epoch 9 Step 2501 Train Loss: 0.6164
Epoch 9 Step 2551 Train Loss: 0.5615
Epoch 9 Step 2601 Train Loss: 0.5637
Epoch 9 Step 2651 Train Loss: 0.5545
Epoch 9 Step 2701 Train Loss: 0.5541
Epoch 9 Step 2751 Train Loss: 0.5644
Epoch 9 Step 2801 Train Loss: 0.5395
Epoch 9 Step 2851 Train Loss: 0.5402
Epoch 9 Step 2901 Train Loss: 0.5944
Epoch 9 Step 2951 Train Loss: 0.5274
Epoch 9 Step 3001 Train Loss: 0.5531
Epoch 9 Step 3051 Train Loss: 0.5849
Epoch 9 Step 3101 Train Loss: 0.5223
Epoch 9 Step 3151 Train Loss: 0.5488
Epoch 9 Step 3201 Train Loss: 0.5671
Epoch 9 Step 3251 Train Loss: 0.6275
Epoch 9 Step 3301 Train Loss: 0.5586
Epoch 9 Step 3351 Train Loss: 0.5570
Epoch 9 Step 3401 Train Loss: 0.5259
Epoch 9: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0100. 
Train Top 20 DE MSE: 0.1554 Validation Top 20 DE MSE: 0.1936. 
Epoch 10 Step 1 Train Loss: 0.6402
Epoch 10 Step 51 Train Loss: 0.5114
Epoch 10 Step 101 Train Loss: 0.5970
Epoch 10 Step 151 Train Loss: 0.5252
Epoch 10 Step 201 Train Loss: 0.6180
Epoch 10 Step 251 Train Loss: 0.6207
Epoch 10 Step 301 Train Loss: 0.5995
Epoch 10 Step 351 Train Loss: 0.5482
Epoch 10 Step 401 Train Loss: 0.6037
Epoch 10 Step 451 Train Loss: 0.5807
Epoch 10 Step 501 Train Loss: 0.5784
Epoch 10 Step 551 Train Loss: 0.5519
Epoch 10 Step 601 Train Loss: 0.5381
Epoch 10 Step 651 Train Loss: 0.5821
Epoch 10 Step 701 Train Loss: 0.6205
Epoch 10 Step 751 Train Loss: 0.5620
Epoch 10 Step 801 Train Loss: 0.5877
Epoch 10 Step 851 Train Loss: 0.6853
Epoch 10 Step 901 Train Loss: 0.5906
Epoch 10 Step 951 Train Loss: 0.6076
Epoch 10 Step 1001 Train Loss: 0.5000
Epoch 10 Step 1051 Train Loss: 0.6061
Epoch 10 Step 1101 Train Loss: 0.6004
Epoch 10 Step 1151 Train Loss: 0.5897
Epoch 10 Step 1201 Train Loss: 0.5734
Epoch 10 Step 1251 Train Loss: 0.5759
Epoch 10 Step 1301 Train Loss: 0.6108
Epoch 10 Step 1351 Train Loss: 0.5706
Epoch 10 Step 1401 Train Loss: 0.5964
Epoch 10 Step 1451 Train Loss: 0.5665
Epoch 10 Step 1501 Train Loss: 0.5857
Epoch 10 Step 1551 Train Loss: 0.5771
Epoch 10 Step 1601 Train Loss: 0.5738
Epoch 10 Step 1651 Train Loss: 0.5628
Epoch 10 Step 1701 Train Loss: 0.5423
Epoch 10 Step 1751 Train Loss: 0.5767
Epoch 10 Step 1801 Train Loss: 0.5946
Epoch 10 Step 1851 Train Loss: 0.6070
Epoch 10 Step 1901 Train Loss: 0.5791
Epoch 10 Step 1951 Train Loss: 0.6016
Epoch 10 Step 2001 Train Loss: 0.5690
Epoch 10 Step 2051 Train Loss: 0.5333
Epoch 10 Step 2101 Train Loss: 0.5330
Epoch 10 Step 2151 Train Loss: 0.6848
Epoch 10 Step 2201 Train Loss: 0.6193
Epoch 10 Step 2251 Train Loss: 0.5713
Epoch 10 Step 2301 Train Loss: 0.6085
Epoch 10 Step 2351 Train Loss: 0.5657
Epoch 10 Step 2401 Train Loss: 0.5415
Epoch 10 Step 2451 Train Loss: 0.6384
Epoch 10 Step 2501 Train Loss: 0.5542
Epoch 10 Step 2551 Train Loss: 0.5388
Epoch 10 Step 2601 Train Loss: 0.6153
Epoch 10 Step 2651 Train Loss: 0.5306
Epoch 10 Step 2701 Train Loss: 0.5894
Epoch 10 Step 2751 Train Loss: 0.6160
Epoch 10 Step 2801 Train Loss: 0.5563
Epoch 10 Step 2851 Train Loss: 0.5983
Epoch 10 Step 2901 Train Loss: 0.5636
Epoch 10 Step 2951 Train Loss: 0.6432
Epoch 10 Step 3001 Train Loss: 0.5696
Epoch 10 Step 3051 Train Loss: 0.6514
Epoch 10 Step 3101 Train Loss: 0.6329
Epoch 10 Step 3151 Train Loss: 0.5073
Epoch 10 Step 3201 Train Loss: 0.5393
Epoch 10 Step 3251 Train Loss: 0.5895
Epoch 10 Step 3301 Train Loss: 0.6282
Epoch 10 Step 3351 Train Loss: 0.5868
Epoch 10 Step 3401 Train Loss: 0.6211
Epoch 10: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0099. 
Train Top 20 DE MSE: 0.1531 Validation Top 20 DE MSE: 0.1918. 
Epoch 11 Step 1 Train Loss: 0.6069
Epoch 11 Step 51 Train Loss: 0.6170
Epoch 11 Step 101 Train Loss: 0.5799
Epoch 11 Step 151 Train Loss: 0.6911
Epoch 11 Step 201 Train Loss: 0.5517
Epoch 11 Step 251 Train Loss: 0.5894
Epoch 11 Step 301 Train Loss: 0.5036
Epoch 11 Step 351 Train Loss: 0.5334
Epoch 11 Step 401 Train Loss: 0.5798
Epoch 11 Step 451 Train Loss: 0.4993
Epoch 11 Step 501 Train Loss: 0.6056
Epoch 11 Step 551 Train Loss: 0.5265
Epoch 11 Step 601 Train Loss: 0.5929
Epoch 11 Step 651 Train Loss: 0.5294
Epoch 11 Step 701 Train Loss: 0.6290
Epoch 11 Step 751 Train Loss: 0.6427
Epoch 11 Step 801 Train Loss: 0.5736
Epoch 11 Step 851 Train Loss: 0.5844
Epoch 11 Step 901 Train Loss: 0.5903
Epoch 11 Step 951 Train Loss: 0.6560
Epoch 11 Step 1001 Train Loss: 0.5159
Epoch 11 Step 1051 Train Loss: 0.5748
Epoch 11 Step 1101 Train Loss: 0.6076
Epoch 11 Step 1151 Train Loss: 0.5854
Epoch 11 Step 1201 Train Loss: 0.5270
Epoch 11 Step 1251 Train Loss: 0.5790
Epoch 11 Step 1301 Train Loss: 0.6169
Epoch 11 Step 1351 Train Loss: 0.5435
Epoch 11 Step 1401 Train Loss: 0.5228
Epoch 11 Step 1451 Train Loss: 0.6947
Epoch 11 Step 1501 Train Loss: 0.5820
Epoch 11 Step 1551 Train Loss: 0.5439
Epoch 11 Step 1601 Train Loss: 0.6409
Epoch 11 Step 1651 Train Loss: 0.5408
Epoch 11 Step 1701 Train Loss: 0.5621
Epoch 11 Step 1751 Train Loss: 0.6240
Epoch 11 Step 1801 Train Loss: 0.5617
Epoch 11 Step 1851 Train Loss: 0.5794
Epoch 11 Step 1901 Train Loss: 0.5552
Epoch 11 Step 1951 Train Loss: 0.5939
Epoch 11 Step 2001 Train Loss: 0.6620
Epoch 11 Step 2051 Train Loss: 0.5763
Epoch 11 Step 2101 Train Loss: 0.6351
Epoch 11 Step 2151 Train Loss: 0.6060
Epoch 11 Step 2201 Train Loss: 0.5404
Epoch 11 Step 2251 Train Loss: 0.6063
Epoch 11 Step 2301 Train Loss: 0.5508
Epoch 11 Step 2351 Train Loss: 0.5669
Epoch 11 Step 2401 Train Loss: 0.5375
Epoch 11 Step 2451 Train Loss: 0.6146
Epoch 11 Step 2501 Train Loss: 0.5875
Epoch 11 Step 2551 Train Loss: 0.6537
Epoch 11 Step 2601 Train Loss: 0.5389
Epoch 11 Step 2651 Train Loss: 0.5433
Epoch 11 Step 2701 Train Loss: 0.5691
Epoch 11 Step 2751 Train Loss: 0.5724
Epoch 11 Step 2801 Train Loss: 0.5503
Epoch 11 Step 2851 Train Loss: 0.5625
Epoch 11 Step 2901 Train Loss: 0.5266
Epoch 11 Step 2951 Train Loss: 0.6014
Epoch 11 Step 3001 Train Loss: 0.5718
Epoch 11 Step 3051 Train Loss: 0.5996
Epoch 11 Step 3101 Train Loss: 0.5963
Epoch 11 Step 3151 Train Loss: 0.5937
Epoch 11 Step 3201 Train Loss: 0.5549
Epoch 11 Step 3251 Train Loss: 0.5461
Epoch 11 Step 3301 Train Loss: 0.6154
Epoch 11 Step 3351 Train Loss: 0.6194
Epoch 11 Step 3401 Train Loss: 0.5877
Epoch 11: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0099. 
Train Top 20 DE MSE: 0.1556 Validation Top 20 DE MSE: 0.1935. 
Epoch 12 Step 1 Train Loss: 0.6327
Epoch 12 Step 51 Train Loss: 0.6232
Epoch 12 Step 101 Train Loss: 0.5708
Epoch 12 Step 151 Train Loss: 0.5687
Epoch 12 Step 201 Train Loss: 0.5771
Epoch 12 Step 251 Train Loss: 0.6083
Epoch 12 Step 301 Train Loss: 0.6160
Epoch 12 Step 351 Train Loss: 0.5536
Epoch 12 Step 401 Train Loss: 0.5861
Epoch 12 Step 451 Train Loss: 0.5664
Epoch 12 Step 501 Train Loss: 0.5886
Epoch 12 Step 551 Train Loss: 0.6010
Epoch 12 Step 601 Train Loss: 0.6043
Epoch 12 Step 651 Train Loss: 0.5851
Epoch 12 Step 701 Train Loss: 0.5953
Epoch 12 Step 751 Train Loss: 0.6007
Epoch 12 Step 801 Train Loss: 0.6042
Epoch 12 Step 851 Train Loss: 0.5303
Epoch 12 Step 901 Train Loss: 0.5394
Epoch 12 Step 951 Train Loss: 0.5587
Epoch 12 Step 1001 Train Loss: 0.5258
Epoch 12 Step 1051 Train Loss: 0.5948
Epoch 12 Step 1101 Train Loss: 0.5997
Epoch 12 Step 1151 Train Loss: 0.6138
Epoch 12 Step 1201 Train Loss: 0.6291
Epoch 12 Step 1251 Train Loss: 0.5516
Epoch 12 Step 1301 Train Loss: 0.5589
Epoch 12 Step 1351 Train Loss: 0.6146
Epoch 12 Step 1401 Train Loss: 0.6270
Epoch 12 Step 1451 Train Loss: 0.5618
Epoch 12 Step 1501 Train Loss: 0.5679
Epoch 12 Step 1551 Train Loss: 0.5814
Epoch 12 Step 1601 Train Loss: 0.5747
Epoch 12 Step 1651 Train Loss: 0.6056
Epoch 12 Step 1701 Train Loss: 0.5767
Epoch 12 Step 1751 Train Loss: 0.5644
Epoch 12 Step 1801 Train Loss: 0.6075
Epoch 12 Step 1851 Train Loss: 0.5332
Epoch 12 Step 1901 Train Loss: 0.5570
Epoch 12 Step 1951 Train Loss: 0.6971
Epoch 12 Step 2001 Train Loss: 0.5081
Epoch 12 Step 2051 Train Loss: 0.6271
Epoch 12 Step 2101 Train Loss: 0.5329
Epoch 12 Step 2151 Train Loss: 0.6287
Epoch 12 Step 2201 Train Loss: 0.5671
Epoch 12 Step 2251 Train Loss: 0.6122
Epoch 12 Step 2301 Train Loss: 0.6481
Epoch 12 Step 2351 Train Loss: 0.5551
Epoch 12 Step 2401 Train Loss: 0.5471
Epoch 12 Step 2451 Train Loss: 0.6543
Epoch 12 Step 2501 Train Loss: 0.5621
Epoch 12 Step 2551 Train Loss: 0.5932
Epoch 12 Step 2601 Train Loss: 0.6053
Epoch 12 Step 2651 Train Loss: 0.5663
Epoch 12 Step 2701 Train Loss: 0.6432
Epoch 12 Step 2751 Train Loss: 0.5901
Epoch 12 Step 2801 Train Loss: 0.6291
Epoch 12 Step 2851 Train Loss: 0.5123
Epoch 12 Step 2901 Train Loss: 0.5715
Epoch 12 Step 2951 Train Loss: 0.6227
Epoch 12 Step 3001 Train Loss: 0.5590
Epoch 12 Step 3051 Train Loss: 0.5692
Epoch 12 Step 3101 Train Loss: 0.6124
Epoch 12 Step 3151 Train Loss: 0.5929
Epoch 12 Step 3201 Train Loss: 0.5784
Epoch 12 Step 3251 Train Loss: 0.5785
Epoch 12 Step 3301 Train Loss: 0.6072
Epoch 12 Step 3351 Train Loss: 0.6061
Epoch 12 Step 3401 Train Loss: 0.5547
Epoch 12: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0098. 
Train Top 20 DE MSE: 0.1578 Validation Top 20 DE MSE: 0.1950. 
Epoch 13 Step 1 Train Loss: 0.5629
Epoch 13 Step 51 Train Loss: 0.6290
Epoch 13 Step 101 Train Loss: 0.5599
Epoch 13 Step 151 Train Loss: 0.5967
Epoch 13 Step 201 Train Loss: 0.5705
Epoch 13 Step 251 Train Loss: 0.6165
Epoch 13 Step 301 Train Loss: 0.6398
Epoch 13 Step 351 Train Loss: 0.5936
Epoch 13 Step 401 Train Loss: 0.7042
Epoch 13 Step 451 Train Loss: 0.6461
Epoch 13 Step 501 Train Loss: 0.5621
Epoch 13 Step 551 Train Loss: 0.5806
Epoch 13 Step 601 Train Loss: 0.5767
Epoch 13 Step 651 Train Loss: 0.5881
Epoch 13 Step 701 Train Loss: 0.5677
Epoch 13 Step 751 Train Loss: 0.5575
Epoch 13 Step 801 Train Loss: 0.5626
Epoch 13 Step 851 Train Loss: 0.6140
Epoch 13 Step 901 Train Loss: 0.4984
Epoch 13 Step 951 Train Loss: 0.5492
Epoch 13 Step 1001 Train Loss: 0.5305
Epoch 13 Step 1051 Train Loss: 0.5928
Epoch 13 Step 1101 Train Loss: 0.5669
Epoch 13 Step 1151 Train Loss: 0.6549
Epoch 13 Step 1201 Train Loss: 0.5312
Epoch 13 Step 1251 Train Loss: 0.5879
Epoch 13 Step 1301 Train Loss: 0.5552
Epoch 13 Step 1351 Train Loss: 0.6379
Epoch 13 Step 1401 Train Loss: 0.5374
Epoch 13 Step 1451 Train Loss: 0.5769
Epoch 13 Step 1501 Train Loss: 0.6313
Epoch 13 Step 1551 Train Loss: 0.5276
Epoch 13 Step 1601 Train Loss: 0.5631
Epoch 13 Step 1651 Train Loss: 0.5608
Epoch 13 Step 1701 Train Loss: 0.6211
Epoch 13 Step 1751 Train Loss: 0.5398
Epoch 13 Step 1801 Train Loss: 0.5860
Epoch 13 Step 1851 Train Loss: 0.5671
Epoch 13 Step 1901 Train Loss: 0.6114
Epoch 13 Step 1951 Train Loss: 0.5560
Epoch 13 Step 2001 Train Loss: 0.6078
Epoch 13 Step 2051 Train Loss: 0.6162
Epoch 13 Step 2101 Train Loss: 0.6023
Epoch 13 Step 2151 Train Loss: 0.5358
Epoch 13 Step 2201 Train Loss: 0.5468
Epoch 13 Step 2251 Train Loss: 0.5682
Epoch 13 Step 2301 Train Loss: 0.5235
Epoch 13 Step 2351 Train Loss: 0.5747
Epoch 13 Step 2401 Train Loss: 0.5485
Epoch 13 Step 2451 Train Loss: 0.5368
Epoch 13 Step 2501 Train Loss: 0.6293
Epoch 13 Step 2551 Train Loss: 0.6311
Epoch 13 Step 2601 Train Loss: 0.5815
Epoch 13 Step 2651 Train Loss: 0.6710
Epoch 13 Step 2701 Train Loss: 0.5537
Epoch 13 Step 2751 Train Loss: 0.5524
Epoch 13 Step 2801 Train Loss: 0.5808
Epoch 13 Step 2851 Train Loss: 0.5561
Epoch 13 Step 2901 Train Loss: 0.5813
Epoch 13 Step 2951 Train Loss: 0.5612
Epoch 13 Step 3001 Train Loss: 0.5667
Epoch 13 Step 3051 Train Loss: 0.6172
Epoch 13 Step 3101 Train Loss: 0.5893
Epoch 13 Step 3151 Train Loss: 0.5607
Epoch 13 Step 3201 Train Loss: 0.5798
Epoch 13 Step 3251 Train Loss: 0.5953
Epoch 13 Step 3301 Train Loss: 0.5419
Epoch 13 Step 3351 Train Loss: 0.5264
Epoch 13 Step 3401 Train Loss: 0.5819
Epoch 13: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0098. 
Train Top 20 DE MSE: 0.1561 Validation Top 20 DE MSE: 0.1934. 
Epoch 14 Step 1 Train Loss: 0.5787
Epoch 14 Step 51 Train Loss: 0.5873
Epoch 14 Step 101 Train Loss: 0.5482
Epoch 14 Step 151 Train Loss: 0.5313
Epoch 14 Step 201 Train Loss: 0.5868
Epoch 14 Step 251 Train Loss: 0.5261
Epoch 14 Step 301 Train Loss: 0.5886
Epoch 14 Step 351 Train Loss: 0.5380
Epoch 14 Step 401 Train Loss: 0.5963
Epoch 14 Step 451 Train Loss: 0.6048
Epoch 14 Step 501 Train Loss: 0.5196
Epoch 14 Step 551 Train Loss: 0.5274
Epoch 14 Step 601 Train Loss: 0.6129
Epoch 14 Step 651 Train Loss: 0.5873
Epoch 14 Step 701 Train Loss: 0.5711
Epoch 14 Step 751 Train Loss: 0.6124
Epoch 14 Step 801 Train Loss: 0.6726
Epoch 14 Step 851 Train Loss: 0.5508
Epoch 14 Step 901 Train Loss: 0.5325
Epoch 14 Step 951 Train Loss: 0.6099
Epoch 14 Step 1001 Train Loss: 0.5608
Epoch 14 Step 1051 Train Loss: 0.6004
Epoch 14 Step 1101 Train Loss: 0.5596
Epoch 14 Step 1151 Train Loss: 0.5723
Epoch 14 Step 1201 Train Loss: 0.5983
Epoch 14 Step 1251 Train Loss: 0.5998
Epoch 14 Step 1301 Train Loss: 0.6356
Epoch 14 Step 1351 Train Loss: 0.5567
Epoch 14 Step 1401 Train Loss: 0.5492
Epoch 14 Step 1451 Train Loss: 0.6242
Epoch 14 Step 1501 Train Loss: 0.5860
Epoch 14 Step 1551 Train Loss: 0.6101
Epoch 14 Step 1601 Train Loss: 0.5809
Epoch 14 Step 1651 Train Loss: 0.5513
Epoch 14 Step 1701 Train Loss: 0.5805
Epoch 14 Step 1751 Train Loss: 0.5714
Epoch 14 Step 1801 Train Loss: 0.5969
Epoch 14 Step 1851 Train Loss: 0.5436
Epoch 14 Step 1901 Train Loss: 0.5405
Epoch 14 Step 1951 Train Loss: 0.6026
Epoch 14 Step 2001 Train Loss: 0.5780
Epoch 14 Step 2051 Train Loss: 0.5891
Epoch 14 Step 2101 Train Loss: 0.5964
Epoch 14 Step 2151 Train Loss: 0.6179
Epoch 14 Step 2201 Train Loss: 0.5780
Epoch 14 Step 2251 Train Loss: 0.5606
Epoch 14 Step 2301 Train Loss: 0.5638
Epoch 14 Step 2351 Train Loss: 0.5965
Epoch 14 Step 2401 Train Loss: 0.5843
Epoch 14 Step 2451 Train Loss: 0.5386
Epoch 14 Step 2501 Train Loss: 0.5702
Epoch 14 Step 2551 Train Loss: 0.5707
Epoch 14 Step 2601 Train Loss: 0.6404
Epoch 14 Step 2651 Train Loss: 0.5142
Epoch 14 Step 2701 Train Loss: 0.5586
Epoch 14 Step 2751 Train Loss: 0.6165
Epoch 14 Step 2801 Train Loss: 0.5824
Epoch 14 Step 2851 Train Loss: 0.5620
Epoch 14 Step 2901 Train Loss: 0.5540
Epoch 14 Step 2951 Train Loss: 0.5528
Epoch 14 Step 3001 Train Loss: 0.5690
Epoch 14 Step 3051 Train Loss: 0.5947
Epoch 14 Step 3101 Train Loss: 0.5705
Epoch 14 Step 3151 Train Loss: 0.5520
Epoch 14 Step 3201 Train Loss: 0.5599
Epoch 14 Step 3251 Train Loss: 0.5860
Epoch 14 Step 3301 Train Loss: 0.5770
Epoch 14 Step 3351 Train Loss: 0.5511
Epoch 14 Step 3401 Train Loss: 0.5514
Epoch 14: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0098. 
Train Top 20 DE MSE: 0.1556 Validation Top 20 DE MSE: 0.1931. 
Epoch 15 Step 1 Train Loss: 0.6047
Epoch 15 Step 51 Train Loss: 0.6005
Epoch 15 Step 101 Train Loss: 0.5598
Epoch 15 Step 151 Train Loss: 0.6246
Epoch 15 Step 201 Train Loss: 0.6866
Epoch 15 Step 251 Train Loss: 0.5962
Epoch 15 Step 301 Train Loss: 0.5794
Epoch 15 Step 351 Train Loss: 0.6046
Epoch 15 Step 401 Train Loss: 0.5797
Epoch 15 Step 451 Train Loss: 0.5746
Epoch 15 Step 501 Train Loss: 0.5845
Epoch 15 Step 551 Train Loss: 0.5225
Epoch 15 Step 601 Train Loss: 0.5482
Epoch 15 Step 651 Train Loss: 0.5615
Epoch 15 Step 701 Train Loss: 0.5945
Epoch 15 Step 751 Train Loss: 0.5515
Epoch 15 Step 801 Train Loss: 0.5709
Epoch 15 Step 851 Train Loss: 0.6098
Epoch 15 Step 901 Train Loss: 0.6059
Epoch 15 Step 951 Train Loss: 0.6143
Epoch 15 Step 1001 Train Loss: 0.5794
Epoch 15 Step 1051 Train Loss: 0.6545
Epoch 15 Step 1101 Train Loss: 0.5726
Epoch 15 Step 1151 Train Loss: 0.6198
Epoch 15 Step 1201 Train Loss: 0.5479
Epoch 15 Step 1251 Train Loss: 0.6006
Epoch 15 Step 1301 Train Loss: 0.6037
Epoch 15 Step 1351 Train Loss: 0.6678
Epoch 15 Step 1401 Train Loss: 0.6020
Epoch 15 Step 1451 Train Loss: 0.5518
Epoch 15 Step 1501 Train Loss: 0.6002
Epoch 15 Step 1551 Train Loss: 0.5598
Epoch 15 Step 1601 Train Loss: 0.6267
Epoch 15 Step 1651 Train Loss: 0.6333
Epoch 15 Step 1701 Train Loss: 0.6141
Epoch 15 Step 1751 Train Loss: 0.6268
Epoch 15 Step 1801 Train Loss: 0.6602
Epoch 15 Step 1851 Train Loss: 0.5817
Epoch 15 Step 1901 Train Loss: 0.5824
Epoch 15 Step 1951 Train Loss: 0.5419
Epoch 15 Step 2001 Train Loss: 0.5705
Epoch 15 Step 2051 Train Loss: 0.5656
Epoch 15 Step 2101 Train Loss: 0.5645
Epoch 15 Step 2151 Train Loss: 0.5896
Epoch 15 Step 2201 Train Loss: 0.6320
Epoch 15 Step 2251 Train Loss: 0.5701
Epoch 15 Step 2301 Train Loss: 0.5660
Epoch 15 Step 2351 Train Loss: 0.5487
Epoch 15 Step 2401 Train Loss: 0.5701
Epoch 15 Step 2451 Train Loss: 0.6004
Epoch 15 Step 2501 Train Loss: 0.5628
Epoch 15 Step 2551 Train Loss: 0.6095
Epoch 15 Step 2601 Train Loss: 0.5532
Epoch 15 Step 2651 Train Loss: 0.5339
Epoch 15 Step 2701 Train Loss: 0.5818
Epoch 15 Step 2751 Train Loss: 0.6055
Epoch 15 Step 2801 Train Loss: 0.5552
Epoch 15 Step 2851 Train Loss: 0.6131
Epoch 15 Step 2901 Train Loss: 0.5377
Epoch 15 Step 2951 Train Loss: 0.6366
Epoch 15 Step 3001 Train Loss: 0.5582
Epoch 15 Step 3051 Train Loss: 0.5854
Epoch 15 Step 3101 Train Loss: 0.5534
Epoch 15 Step 3151 Train Loss: 0.6151
Epoch 15 Step 3201 Train Loss: 0.5686
Epoch 15 Step 3251 Train Loss: 0.6129
Epoch 15 Step 3301 Train Loss: 0.6017
Epoch 15 Step 3351 Train Loss: 0.6195
Epoch 15 Step 3401 Train Loss: 0.6281
Epoch 15: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0098. 
Train Top 20 DE MSE: 0.1533 Validation Top 20 DE MSE: 0.1917. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1796
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.008482322
test_unseen_single_pearson: 0.9881259502880416
test_unseen_single_mse_de: 0.17960821
test_unseen_single_pearson_de: 0.8952302581419807
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.28077254882026903
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3402621722846442
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7254681647940074
test_unseen_single_mse_top20_de_non_dropout: 0.1867908
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.055 MB uploadedwandb: | 0.001 MB of 0.055 MB uploadedwandb: / 0.015 MB of 0.055 MB uploadedwandb: - 0.015 MB of 0.055 MB uploadedwandb: \ 0.055 MB of 0.055 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñá‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:                                                    train_mse ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñá‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñá
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:                                               val_de_pearson ‚ñÇ‚ñà‚ñá‚ñÜ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                                                      val_mse ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                                  val_pearson ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.17961
wandb:                                              test_de_pearson 0.89523
wandb:               test_frac_opposite_direction_top20_non_dropout 0.34026
wandb:                          test_frac_sigma_below_1_non_dropout 0.72547
wandb:                                                     test_mse 0.00848
wandb:                                test_mse_top20_de_non_dropout 0.18679
wandb:                                                 test_pearson 0.98813
wandb:                                           test_pearson_delta 0.28077
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.34026
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.72547
wandb:                                       test_unseen_single_mse 0.00848
wandb:                                    test_unseen_single_mse_de 0.17961
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.18679
wandb:                                   test_unseen_single_pearson 0.98813
wandb:                                test_unseen_single_pearson_de 0.89523
wandb:                             test_unseen_single_pearson_delta 0.28077
wandb:                                                 train_de_mse 0.15334
wandb:                                             train_de_pearson 0.9177
wandb:                                                    train_mse 0.00747
wandb:                                                train_pearson 0.98956
wandb:                                                training_loss 0.6316
wandb:                                                   val_de_mse 0.19171
wandb:                                               val_de_pearson 0.87987
wandb:                                                      val_mse 0.00983
wandb:                                                  val_pearson 0.98636
wandb: 
wandb: üöÄ View run geneformer_Replogle_k562_essential_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/xkyt449m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_070102-xkyt449m/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:267
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_094430-6b659imm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_k562_essential_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/6b659imm
wandb: WARNING Serializing object of type ndarray that is 23167104 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6060
Epoch 1 Step 51 Train Loss: 0.5895
Epoch 1 Step 101 Train Loss: 0.6111
Epoch 1 Step 151 Train Loss: 0.5784
Epoch 1 Step 201 Train Loss: 0.6448
Epoch 1 Step 251 Train Loss: 0.5552
Epoch 1 Step 301 Train Loss: 0.5558
Epoch 1 Step 351 Train Loss: 0.5706
Epoch 1 Step 401 Train Loss: 0.5808
Epoch 1 Step 451 Train Loss: 0.6992
Epoch 1 Step 501 Train Loss: 0.5926
Epoch 1 Step 551 Train Loss: 0.5962
Epoch 1 Step 601 Train Loss: 0.5365
Epoch 1 Step 651 Train Loss: 0.5120
Epoch 1 Step 701 Train Loss: 0.5702
Epoch 1 Step 751 Train Loss: 0.5771
Epoch 1 Step 801 Train Loss: 0.5462
Epoch 1 Step 851 Train Loss: 0.5631
Epoch 1 Step 901 Train Loss: 0.5512
Epoch 1 Step 951 Train Loss: 0.5456
Epoch 1 Step 1001 Train Loss: 0.5611
Epoch 1 Step 1051 Train Loss: 0.5919
Epoch 1 Step 1101 Train Loss: 0.5709
Epoch 1 Step 1151 Train Loss: 0.6471
Epoch 1 Step 1201 Train Loss: 0.5885
Epoch 1 Step 1251 Train Loss: 0.5638
Epoch 1 Step 1301 Train Loss: 0.5794
Epoch 1 Step 1351 Train Loss: 0.6117
Epoch 1 Step 1401 Train Loss: 0.5361
Epoch 1 Step 1451 Train Loss: 0.5748
Epoch 1 Step 1501 Train Loss: 0.5691
Epoch 1 Step 1551 Train Loss: 0.6089
Epoch 1 Step 1601 Train Loss: 0.6046
Epoch 1 Step 1651 Train Loss: 0.5890
Epoch 1 Step 1701 Train Loss: 0.6402
Epoch 1 Step 1751 Train Loss: 0.6550
Epoch 1 Step 1801 Train Loss: 0.5679
Epoch 1 Step 1851 Train Loss: 0.5820
Epoch 1 Step 1901 Train Loss: 0.5789
Epoch 1 Step 1951 Train Loss: 0.5503
Epoch 1 Step 2001 Train Loss: 0.6021
Epoch 1 Step 2051 Train Loss: 0.5692
Epoch 1 Step 2101 Train Loss: 0.5645
Epoch 1 Step 2151 Train Loss: 0.6061
Epoch 1 Step 2201 Train Loss: 0.6348
Epoch 1 Step 2251 Train Loss: 0.5618
Epoch 1 Step 2301 Train Loss: 0.5824
Epoch 1 Step 2351 Train Loss: 0.5191
Epoch 1 Step 2401 Train Loss: 0.5837
Epoch 1 Step 2451 Train Loss: 0.5532
Epoch 1 Step 2501 Train Loss: 0.6243
Epoch 1 Step 2551 Train Loss: 0.6101
Epoch 1 Step 2601 Train Loss: 0.5619
Epoch 1 Step 2651 Train Loss: 0.4883
Epoch 1 Step 2701 Train Loss: 0.5701
Epoch 1 Step 2751 Train Loss: 0.5767
Epoch 1 Step 2801 Train Loss: 0.6079
Epoch 1 Step 2851 Train Loss: 0.5649
Epoch 1 Step 2901 Train Loss: 0.5582
Epoch 1 Step 2951 Train Loss: 0.5404
Epoch 1 Step 3001 Train Loss: 0.5844
Epoch 1 Step 3051 Train Loss: 0.5520
Epoch 1 Step 3101 Train Loss: 0.6298
Epoch 1 Step 3151 Train Loss: 0.6253
Epoch 1 Step 3201 Train Loss: 0.6535
Epoch 1 Step 3251 Train Loss: 0.6185
Epoch 1 Step 3301 Train Loss: 0.5597
Epoch 1 Step 3351 Train Loss: 0.5333
Epoch 1: Train Overall MSE: 0.3985 Validation Overall MSE: 0.3923. 
Train Top 20 DE MSE: 1.8450 Validation Top 20 DE MSE: 1.9329. 
Epoch 2 Step 1 Train Loss: 0.5820
Epoch 2 Step 51 Train Loss: 0.6262
Epoch 2 Step 101 Train Loss: 0.6180
Epoch 2 Step 151 Train Loss: 0.5476
Epoch 2 Step 201 Train Loss: 0.5442
Epoch 2 Step 251 Train Loss: 0.5914
Epoch 2 Step 301 Train Loss: 0.5623
Epoch 2 Step 351 Train Loss: 0.5907
Epoch 2 Step 401 Train Loss: 0.6572
Epoch 2 Step 451 Train Loss: 0.6268
Epoch 2 Step 501 Train Loss: 0.5924
Epoch 2 Step 551 Train Loss: 0.5378
Epoch 2 Step 601 Train Loss: 0.5683
Epoch 2 Step 651 Train Loss: 0.6287
Epoch 2 Step 701 Train Loss: 0.5801
Epoch 2 Step 751 Train Loss: 0.5534
Epoch 2 Step 801 Train Loss: 0.5970
Epoch 2 Step 851 Train Loss: 0.5746
Epoch 2 Step 901 Train Loss: 0.6150
Epoch 2 Step 951 Train Loss: 0.6123
Epoch 2 Step 1001 Train Loss: 0.5739
Epoch 2 Step 1051 Train Loss: 0.5888
Epoch 2 Step 1101 Train Loss: 0.5340
Epoch 2 Step 1151 Train Loss: 0.5300
Epoch 2 Step 1201 Train Loss: 0.5778
Epoch 2 Step 1251 Train Loss: 0.6309
Epoch 2 Step 1301 Train Loss: 0.5817
Epoch 2 Step 1351 Train Loss: 0.6420
Epoch 2 Step 1401 Train Loss: 0.5870
Epoch 2 Step 1451 Train Loss: 0.5204
Epoch 2 Step 1501 Train Loss: 0.5479
Epoch 2 Step 1551 Train Loss: 0.6250
Epoch 2 Step 1601 Train Loss: 0.5686
Epoch 2 Step 1651 Train Loss: 0.5341
Epoch 2 Step 1701 Train Loss: 0.5733
Epoch 2 Step 1751 Train Loss: 0.5459
Epoch 2 Step 1801 Train Loss: 0.5714
Epoch 2 Step 1851 Train Loss: 0.5700
Epoch 2 Step 1901 Train Loss: 0.5558
Epoch 2 Step 1951 Train Loss: 0.5939
Epoch 2 Step 2001 Train Loss: 0.5933
Epoch 2 Step 2051 Train Loss: 0.5606
Epoch 2 Step 2101 Train Loss: 0.5613
Epoch 2 Step 2151 Train Loss: 0.6643
Epoch 2 Step 2201 Train Loss: 0.5497
Epoch 2 Step 2251 Train Loss: 0.5745
Epoch 2 Step 2301 Train Loss: 0.5520
Epoch 2 Step 2351 Train Loss: 0.5696
Epoch 2 Step 2401 Train Loss: 0.6104
Epoch 2 Step 2451 Train Loss: 0.6001
Epoch 2 Step 2501 Train Loss: 0.5845
Epoch 2 Step 2551 Train Loss: 0.5906
Epoch 2 Step 2601 Train Loss: 0.6300
Epoch 2 Step 2651 Train Loss: 0.5785
Epoch 2 Step 2701 Train Loss: 0.5688
Epoch 2 Step 2751 Train Loss: 0.6084
Epoch 2 Step 2801 Train Loss: 0.5780
Epoch 2 Step 2851 Train Loss: 0.6143
Epoch 2 Step 2901 Train Loss: 0.5807
Epoch 2 Step 2951 Train Loss: 0.6030
Epoch 2 Step 3001 Train Loss: 0.5711
Epoch 2 Step 3051 Train Loss: 0.5590
Epoch 2 Step 3101 Train Loss: 0.5566
Epoch 2 Step 3151 Train Loss: 0.5992
Epoch 2 Step 3201 Train Loss: 0.5156
Epoch 2 Step 3251 Train Loss: 0.5594
Epoch 2 Step 3301 Train Loss: 0.5250
Epoch 2 Step 3351 Train Loss: 0.5670
Epoch 2: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0082. 
Train Top 20 DE MSE: 0.1529 Validation Top 20 DE MSE: 0.2052. 
Epoch 3 Step 1 Train Loss: 0.5467
Epoch 3 Step 51 Train Loss: 0.5708
Epoch 3 Step 101 Train Loss: 0.5942
Epoch 3 Step 151 Train Loss: 0.5986
Epoch 3 Step 201 Train Loss: 0.5957
Epoch 3 Step 251 Train Loss: 0.5767
Epoch 3 Step 301 Train Loss: 0.5988
Epoch 3 Step 351 Train Loss: 0.6288
Epoch 3 Step 401 Train Loss: 0.5703
Epoch 3 Step 451 Train Loss: 0.5367
Epoch 3 Step 501 Train Loss: 0.5840
Epoch 3 Step 551 Train Loss: 0.6310
Epoch 3 Step 601 Train Loss: 0.5789
Epoch 3 Step 651 Train Loss: 0.6306
Epoch 3 Step 701 Train Loss: 0.5376
Epoch 3 Step 751 Train Loss: 0.5899
Epoch 3 Step 801 Train Loss: 0.6113
Epoch 3 Step 851 Train Loss: 0.6060
Epoch 3 Step 901 Train Loss: 0.5909
Epoch 3 Step 951 Train Loss: 0.5651
Epoch 3 Step 1001 Train Loss: 0.5928
Epoch 3 Step 1051 Train Loss: 0.5885
Epoch 3 Step 1101 Train Loss: 0.6344
Epoch 3 Step 1151 Train Loss: 0.5830
Epoch 3 Step 1201 Train Loss: 0.5657
Epoch 3 Step 1251 Train Loss: 0.5818
Epoch 3 Step 1301 Train Loss: 0.5962
Epoch 3 Step 1351 Train Loss: 0.6406
Epoch 3 Step 1401 Train Loss: 0.6351
Epoch 3 Step 1451 Train Loss: 0.5391
Epoch 3 Step 1501 Train Loss: 0.5734
Epoch 3 Step 1551 Train Loss: 0.6069
Epoch 3 Step 1601 Train Loss: 0.6057
Epoch 3 Step 1651 Train Loss: 0.5078
Epoch 3 Step 1701 Train Loss: 0.5503
Epoch 3 Step 1751 Train Loss: 0.6043
Epoch 3 Step 1801 Train Loss: 0.5667
Epoch 3 Step 1851 Train Loss: 0.5072
Epoch 3 Step 1901 Train Loss: 0.5814
Epoch 3 Step 1951 Train Loss: 0.6292
Epoch 3 Step 2001 Train Loss: 0.5257
Epoch 3 Step 2051 Train Loss: 0.5732
Epoch 3 Step 2101 Train Loss: 0.6434
Epoch 3 Step 2151 Train Loss: 0.6141
Epoch 3 Step 2201 Train Loss: 0.5887
Epoch 3 Step 2251 Train Loss: 0.5409
Epoch 3 Step 2301 Train Loss: 0.6286
Epoch 3 Step 2351 Train Loss: 0.5902
Epoch 3 Step 2401 Train Loss: 0.5929
Epoch 3 Step 2451 Train Loss: 0.5683
Epoch 3 Step 2501 Train Loss: 0.5870
Epoch 3 Step 2551 Train Loss: 0.5795
Epoch 3 Step 2601 Train Loss: 0.6185
Epoch 3 Step 2651 Train Loss: 0.6453
Epoch 3 Step 2701 Train Loss: 0.5678
Epoch 3 Step 2751 Train Loss: 0.5894
Epoch 3 Step 2801 Train Loss: 0.6163
Epoch 3 Step 2851 Train Loss: 0.5694
Epoch 3 Step 2901 Train Loss: 0.5564
Epoch 3 Step 2951 Train Loss: 0.5710
Epoch 3 Step 3001 Train Loss: 0.5911
Epoch 3 Step 3051 Train Loss: 0.5739
Epoch 3 Step 3101 Train Loss: 0.5661
Epoch 3 Step 3151 Train Loss: 0.5424
Epoch 3 Step 3201 Train Loss: 0.5742
Epoch 3 Step 3251 Train Loss: 0.6028
Epoch 3 Step 3301 Train Loss: 0.5893
Epoch 3 Step 3351 Train Loss: 0.5669
Epoch 3: Train Overall MSE: 0.0081 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.1684 Validation Top 20 DE MSE: 0.2176. 
Epoch 4 Step 1 Train Loss: 0.5790
Epoch 4 Step 51 Train Loss: 0.5983
Epoch 4 Step 101 Train Loss: 0.6214
Epoch 4 Step 151 Train Loss: 0.5497
Epoch 4 Step 201 Train Loss: 0.6466
Epoch 4 Step 251 Train Loss: 0.5383
Epoch 4 Step 301 Train Loss: 0.5512
Epoch 4 Step 351 Train Loss: 0.5879
Epoch 4 Step 401 Train Loss: 0.6252
Epoch 4 Step 451 Train Loss: 0.5549
Epoch 4 Step 501 Train Loss: 0.6155
Epoch 4 Step 551 Train Loss: 0.6017
Epoch 4 Step 601 Train Loss: 0.5407
Epoch 4 Step 651 Train Loss: 0.5885
Epoch 4 Step 701 Train Loss: 0.5708
Epoch 4 Step 751 Train Loss: 0.5980
Epoch 4 Step 801 Train Loss: 0.5484
Epoch 4 Step 851 Train Loss: 0.6081
Epoch 4 Step 901 Train Loss: 0.5328
Epoch 4 Step 951 Train Loss: 0.5460
Epoch 4 Step 1001 Train Loss: 0.6032
Epoch 4 Step 1051 Train Loss: 0.5722
Epoch 4 Step 1101 Train Loss: 0.5725
Epoch 4 Step 1151 Train Loss: 0.5367
Epoch 4 Step 1201 Train Loss: 0.5535
Epoch 4 Step 1251 Train Loss: 0.5659
Epoch 4 Step 1301 Train Loss: 0.5677
Epoch 4 Step 1351 Train Loss: 0.6457
Epoch 4 Step 1401 Train Loss: 0.5845
Epoch 4 Step 1451 Train Loss: 0.5651
Epoch 4 Step 1501 Train Loss: 0.5966
Epoch 4 Step 1551 Train Loss: 0.5982
Epoch 4 Step 1601 Train Loss: 0.6087
Epoch 4 Step 1651 Train Loss: 0.6038
Epoch 4 Step 1701 Train Loss: 0.5741
Epoch 4 Step 1751 Train Loss: 0.5658
Epoch 4 Step 1801 Train Loss: 0.5925
Epoch 4 Step 1851 Train Loss: 0.5407
Epoch 4 Step 1901 Train Loss: 0.5381
Epoch 4 Step 1951 Train Loss: 0.5388
Epoch 4 Step 2001 Train Loss: 0.5599
Epoch 4 Step 2051 Train Loss: 0.5903
Epoch 4 Step 2101 Train Loss: 0.5628
Epoch 4 Step 2151 Train Loss: 0.5796
Epoch 4 Step 2201 Train Loss: 0.5450
Epoch 4 Step 2251 Train Loss: 0.5641
Epoch 4 Step 2301 Train Loss: 0.5269
Epoch 4 Step 2351 Train Loss: 0.6657
Epoch 4 Step 2401 Train Loss: 0.6138
Epoch 4 Step 2451 Train Loss: 0.5887
Epoch 4 Step 2501 Train Loss: 0.5873
Epoch 4 Step 2551 Train Loss: 0.5518
Epoch 4 Step 2601 Train Loss: 0.5643
Epoch 4 Step 2651 Train Loss: 0.6196
Epoch 4 Step 2701 Train Loss: 0.5501
Epoch 4 Step 2751 Train Loss: 0.6125
Epoch 4 Step 2801 Train Loss: 0.5603
Epoch 4 Step 2851 Train Loss: 0.5652
Epoch 4 Step 2901 Train Loss: 0.6034
Epoch 4 Step 2951 Train Loss: 0.5926
Epoch 4 Step 3001 Train Loss: 0.5635
Epoch 4 Step 3051 Train Loss: 0.5471
Epoch 4 Step 3101 Train Loss: 0.5568
Epoch 4 Step 3151 Train Loss: 0.5724
Epoch 4 Step 3201 Train Loss: 0.6416
Epoch 4 Step 3251 Train Loss: 0.5733
Epoch 4 Step 3301 Train Loss: 0.6393
Epoch 4 Step 3351 Train Loss: 0.5389
Epoch 4: Train Overall MSE: 0.0084 Validation Overall MSE: 0.0090. 
Train Top 20 DE MSE: 0.1488 Validation Top 20 DE MSE: 0.2068. 
Epoch 5 Step 1 Train Loss: 0.6700
Epoch 5 Step 51 Train Loss: 0.5887
Epoch 5 Step 101 Train Loss: 0.5538
Epoch 5 Step 151 Train Loss: 0.5876
Epoch 5 Step 201 Train Loss: 0.6271
Epoch 5 Step 251 Train Loss: 0.5766
Epoch 5 Step 301 Train Loss: 0.5804
Epoch 5 Step 351 Train Loss: 0.6041
Epoch 5 Step 401 Train Loss: 0.5920
Epoch 5 Step 451 Train Loss: 0.5773
Epoch 5 Step 501 Train Loss: 0.5683
Epoch 5 Step 551 Train Loss: 0.5448
Epoch 5 Step 601 Train Loss: 0.5624
Epoch 5 Step 651 Train Loss: 0.5362
Epoch 5 Step 701 Train Loss: 0.5856
Epoch 5 Step 751 Train Loss: 0.5803
Epoch 5 Step 801 Train Loss: 0.5389
Epoch 5 Step 851 Train Loss: 0.6137
Epoch 5 Step 901 Train Loss: 0.5780
Epoch 5 Step 951 Train Loss: 0.5057
Epoch 5 Step 1001 Train Loss: 0.5509
Epoch 5 Step 1051 Train Loss: 0.6033
Epoch 5 Step 1101 Train Loss: 0.5537
Epoch 5 Step 1151 Train Loss: 0.5851
Epoch 5 Step 1201 Train Loss: 0.5379
Epoch 5 Step 1251 Train Loss: 0.5707
Epoch 5 Step 1301 Train Loss: 0.6151
Epoch 5 Step 1351 Train Loss: 0.6511
Epoch 5 Step 1401 Train Loss: 0.5755
Epoch 5 Step 1451 Train Loss: 0.5895
Epoch 5 Step 1501 Train Loss: 0.6369
Epoch 5 Step 1551 Train Loss: 0.6148
Epoch 5 Step 1601 Train Loss: 0.5319
Epoch 5 Step 1651 Train Loss: 0.5875
Epoch 5 Step 1701 Train Loss: 0.5690
Epoch 5 Step 1751 Train Loss: 0.5667
Epoch 5 Step 1801 Train Loss: 0.5882
Epoch 5 Step 1851 Train Loss: 0.5762
Epoch 5 Step 1901 Train Loss: 0.5893
Epoch 5 Step 1951 Train Loss: 0.5613
Epoch 5 Step 2001 Train Loss: 0.6421
Epoch 5 Step 2051 Train Loss: 0.5495
Epoch 5 Step 2101 Train Loss: 0.5462
Epoch 5 Step 2151 Train Loss: 0.6094
Epoch 5 Step 2201 Train Loss: 0.5364
Epoch 5 Step 2251 Train Loss: 0.5064
Epoch 5 Step 2301 Train Loss: 0.5959
Epoch 5 Step 2351 Train Loss: 0.5825
Epoch 5 Step 2401 Train Loss: 0.6142
Epoch 5 Step 2451 Train Loss: 0.6321
Epoch 5 Step 2501 Train Loss: 0.6593
Epoch 5 Step 2551 Train Loss: 0.5654
Epoch 5 Step 2601 Train Loss: 0.5731
Epoch 5 Step 2651 Train Loss: 0.5708
Epoch 5 Step 2701 Train Loss: 0.5712
Epoch 5 Step 2751 Train Loss: 0.5735
Epoch 5 Step 2801 Train Loss: 0.5867
Epoch 5 Step 2851 Train Loss: 0.5067
Epoch 5 Step 2901 Train Loss: 0.5697
Epoch 5 Step 2951 Train Loss: 0.5482
Epoch 5 Step 3001 Train Loss: 0.5334
Epoch 5 Step 3051 Train Loss: 0.5565
Epoch 5 Step 3101 Train Loss: 0.6069
Epoch 5 Step 3151 Train Loss: 0.5422
Epoch 5 Step 3201 Train Loss: 0.5851
Epoch 5 Step 3251 Train Loss: 0.5512
Epoch 5 Step 3301 Train Loss: 0.6099
Epoch 5 Step 3351 Train Loss: 0.5278
Epoch 5: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0081. 
Train Top 20 DE MSE: 0.1400 Validation Top 20 DE MSE: 0.1996. 
Epoch 6 Step 1 Train Loss: 0.5775
Epoch 6 Step 51 Train Loss: 0.5429
Epoch 6 Step 101 Train Loss: 0.5243
Epoch 6 Step 151 Train Loss: 0.5952
Epoch 6 Step 201 Train Loss: 0.5711
Epoch 6 Step 251 Train Loss: 0.6304
Epoch 6 Step 301 Train Loss: 0.5467
Epoch 6 Step 351 Train Loss: 0.6147
Epoch 6 Step 401 Train Loss: 0.5626
Epoch 6 Step 451 Train Loss: 0.5976
Epoch 6 Step 501 Train Loss: 0.6022
Epoch 6 Step 551 Train Loss: 0.5815
Epoch 6 Step 601 Train Loss: 0.5467
Epoch 6 Step 651 Train Loss: 0.5815
Epoch 6 Step 701 Train Loss: 0.5762
Epoch 6 Step 751 Train Loss: 0.5764
Epoch 6 Step 801 Train Loss: 0.6306
Epoch 6 Step 851 Train Loss: 0.5664
Epoch 6 Step 901 Train Loss: 0.6012
Epoch 6 Step 951 Train Loss: 0.6343
Epoch 6 Step 1001 Train Loss: 0.5677
Epoch 6 Step 1051 Train Loss: 0.5692
Epoch 6 Step 1101 Train Loss: 0.5842
Epoch 6 Step 1151 Train Loss: 0.5895
Epoch 6 Step 1201 Train Loss: 0.5821
Epoch 6 Step 1251 Train Loss: 0.6202
Epoch 6 Step 1301 Train Loss: 0.5124
Epoch 6 Step 1351 Train Loss: 0.5576
Epoch 6 Step 1401 Train Loss: 0.6125
Epoch 6 Step 1451 Train Loss: 0.6222
Epoch 6 Step 1501 Train Loss: 0.5515
Epoch 6 Step 1551 Train Loss: 0.6356
Epoch 6 Step 1601 Train Loss: 0.5795
Epoch 6 Step 1651 Train Loss: 0.5687
Epoch 6 Step 1701 Train Loss: 0.5372
Epoch 6 Step 1751 Train Loss: 0.5609
Epoch 6 Step 1801 Train Loss: 0.5985
Epoch 6 Step 1851 Train Loss: 0.5472
Epoch 6 Step 1901 Train Loss: 0.5833
Epoch 6 Step 1951 Train Loss: 0.5782
Epoch 6 Step 2001 Train Loss: 0.5258
Epoch 6 Step 2051 Train Loss: 0.5457
Epoch 6 Step 2101 Train Loss: 0.5686
Epoch 6 Step 2151 Train Loss: 0.5460
Epoch 6 Step 2201 Train Loss: 0.5775
Epoch 6 Step 2251 Train Loss: 0.6102
Epoch 6 Step 2301 Train Loss: 0.6511
Epoch 6 Step 2351 Train Loss: 0.5681
Epoch 6 Step 2401 Train Loss: 0.5742
Epoch 6 Step 2451 Train Loss: 0.5830
Epoch 6 Step 2501 Train Loss: 0.5492
Epoch 6 Step 2551 Train Loss: 0.6520
Epoch 6 Step 2601 Train Loss: 0.5750
Epoch 6 Step 2651 Train Loss: 0.5894
Epoch 6 Step 2701 Train Loss: 0.5555
Epoch 6 Step 2751 Train Loss: 0.5724
Epoch 6 Step 2801 Train Loss: 0.5531
Epoch 6 Step 2851 Train Loss: 0.5765
Epoch 6 Step 2901 Train Loss: 0.6265
Epoch 6 Step 2951 Train Loss: 0.5697
Epoch 6 Step 3001 Train Loss: 0.5731
Epoch 6 Step 3051 Train Loss: 0.6610
Epoch 6 Step 3101 Train Loss: 0.5831
Epoch 6 Step 3151 Train Loss: 0.5760
Epoch 6 Step 3201 Train Loss: 0.5861
Epoch 6 Step 3251 Train Loss: 0.6665
Epoch 6 Step 3301 Train Loss: 0.5653
Epoch 6 Step 3351 Train Loss: 0.5519
Epoch 6: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0080. 
Train Top 20 DE MSE: 0.1412 Validation Top 20 DE MSE: 0.2016. 
Epoch 7 Step 1 Train Loss: 0.6689
Epoch 7 Step 51 Train Loss: 0.5953
Epoch 7 Step 101 Train Loss: 0.5915
Epoch 7 Step 151 Train Loss: 0.5769
Epoch 7 Step 201 Train Loss: 0.5922
Epoch 7 Step 251 Train Loss: 0.5332
Epoch 7 Step 301 Train Loss: 0.5903
Epoch 7 Step 351 Train Loss: 0.5778
Epoch 7 Step 401 Train Loss: 0.5379
Epoch 7 Step 451 Train Loss: 0.5389
Epoch 7 Step 501 Train Loss: 0.5930
Epoch 7 Step 551 Train Loss: 0.5907
Epoch 7 Step 601 Train Loss: 0.5620
Epoch 7 Step 651 Train Loss: 0.5600
Epoch 7 Step 701 Train Loss: 0.5737
Epoch 7 Step 751 Train Loss: 0.5932
Epoch 7 Step 801 Train Loss: 0.5987
Epoch 7 Step 851 Train Loss: 0.5535
Epoch 7 Step 901 Train Loss: 0.5825
Epoch 7 Step 951 Train Loss: 0.5783
Epoch 7 Step 1001 Train Loss: 0.5549
Epoch 7 Step 1051 Train Loss: 0.5400
Epoch 7 Step 1101 Train Loss: 0.6276
Epoch 7 Step 1151 Train Loss: 0.5938
Epoch 7 Step 1201 Train Loss: 0.6260
Epoch 7 Step 1251 Train Loss: 0.5405
Epoch 7 Step 1301 Train Loss: 0.5697
Epoch 7 Step 1351 Train Loss: 0.5596
Epoch 7 Step 1401 Train Loss: 0.5443
Epoch 7 Step 1451 Train Loss: 0.6081
Epoch 7 Step 1501 Train Loss: 0.6108
Epoch 7 Step 1551 Train Loss: 0.6119
Epoch 7 Step 1601 Train Loss: 0.5650
Epoch 7 Step 1651 Train Loss: 0.6192
Epoch 7 Step 1701 Train Loss: 0.6606
Epoch 7 Step 1751 Train Loss: 0.6230
Epoch 7 Step 1801 Train Loss: 0.5803
Epoch 7 Step 1851 Train Loss: 0.6308
Epoch 7 Step 1901 Train Loss: 0.5986
Epoch 7 Step 1951 Train Loss: 0.5853
Epoch 7 Step 2001 Train Loss: 0.5848
Epoch 7 Step 2051 Train Loss: 0.5792
Epoch 7 Step 2101 Train Loss: 0.6284
Epoch 7 Step 2151 Train Loss: 0.6192
Epoch 7 Step 2201 Train Loss: 0.5396
Epoch 7 Step 2251 Train Loss: 0.5855
Epoch 7 Step 2301 Train Loss: 0.5871
Epoch 7 Step 2351 Train Loss: 0.5799
Epoch 7 Step 2401 Train Loss: 0.5711
Epoch 7 Step 2451 Train Loss: 0.6373
Epoch 7 Step 2501 Train Loss: 0.5829
Epoch 7 Step 2551 Train Loss: 0.5749
Epoch 7 Step 2601 Train Loss: 0.5656
Epoch 7 Step 2651 Train Loss: 0.5613
Epoch 7 Step 2701 Train Loss: 0.5759
Epoch 7 Step 2751 Train Loss: 0.5886
Epoch 7 Step 2801 Train Loss: 0.5576
Epoch 7 Step 2851 Train Loss: 0.5649
Epoch 7 Step 2901 Train Loss: 0.5821
Epoch 7 Step 2951 Train Loss: 0.6249
Epoch 7 Step 3001 Train Loss: 0.6002
Epoch 7 Step 3051 Train Loss: 0.6183
Epoch 7 Step 3101 Train Loss: 0.5823
Epoch 7 Step 3151 Train Loss: 0.5837
Epoch 7 Step 3201 Train Loss: 0.6180
Epoch 7 Step 3251 Train Loss: 0.6339
Epoch 7 Step 3301 Train Loss: 0.5351
Epoch 7 Step 3351 Train Loss: 0.5490
Epoch 7: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0080. 
Train Top 20 DE MSE: 0.1437 Validation Top 20 DE MSE: 0.2043. 
Epoch 8 Step 1 Train Loss: 0.6229
Epoch 8 Step 51 Train Loss: 0.5834
Epoch 8 Step 101 Train Loss: 0.5840
Epoch 8 Step 151 Train Loss: 0.5951
Epoch 8 Step 201 Train Loss: 0.5371
Epoch 8 Step 251 Train Loss: 0.5823
Epoch 8 Step 301 Train Loss: 0.6225
Epoch 8 Step 351 Train Loss: 0.5394
Epoch 8 Step 401 Train Loss: 0.5238
Epoch 8 Step 451 Train Loss: 0.5635
Epoch 8 Step 501 Train Loss: 0.5965
Epoch 8 Step 551 Train Loss: 0.5369
Epoch 8 Step 601 Train Loss: 0.6054
Epoch 8 Step 651 Train Loss: 0.5997
Epoch 8 Step 701 Train Loss: 0.5578
Epoch 8 Step 751 Train Loss: 0.6192
Epoch 8 Step 801 Train Loss: 0.5101
Epoch 8 Step 851 Train Loss: 0.5746
Epoch 8 Step 901 Train Loss: 0.5194
Epoch 8 Step 951 Train Loss: 0.6556
Epoch 8 Step 1001 Train Loss: 0.6306
Epoch 8 Step 1051 Train Loss: 0.5369
Epoch 8 Step 1101 Train Loss: 0.6234
Epoch 8 Step 1151 Train Loss: 0.6145
Epoch 8 Step 1201 Train Loss: 0.6555
Epoch 8 Step 1251 Train Loss: 0.6872
Epoch 8 Step 1301 Train Loss: 0.5335
Epoch 8 Step 1351 Train Loss: 0.5935
Epoch 8 Step 1401 Train Loss: 0.5801
Epoch 8 Step 1451 Train Loss: 0.5402
Epoch 8 Step 1501 Train Loss: 0.5626
Epoch 8 Step 1551 Train Loss: 0.5773
Epoch 8 Step 1601 Train Loss: 0.6259
Epoch 8 Step 1651 Train Loss: 0.5146
Epoch 8 Step 1701 Train Loss: 0.5717
Epoch 8 Step 1751 Train Loss: 0.6347
Epoch 8 Step 1801 Train Loss: 0.5520
Epoch 8 Step 1851 Train Loss: 0.5850
Epoch 8 Step 1901 Train Loss: 0.5435
Epoch 8 Step 1951 Train Loss: 0.6188
Epoch 8 Step 2001 Train Loss: 0.5698
Epoch 8 Step 2051 Train Loss: 0.5574
Epoch 8 Step 2101 Train Loss: 0.5907
Epoch 8 Step 2151 Train Loss: 0.5751
Epoch 8 Step 2201 Train Loss: 0.5893
Epoch 8 Step 2251 Train Loss: 0.5712
Epoch 8 Step 2301 Train Loss: 0.5697
Epoch 8 Step 2351 Train Loss: 0.5660
Epoch 8 Step 2401 Train Loss: 0.5340
Epoch 8 Step 2451 Train Loss: 0.5770
Epoch 8 Step 2501 Train Loss: 0.5955
Epoch 8 Step 2551 Train Loss: 0.5530
Epoch 8 Step 2601 Train Loss: 0.5703
Epoch 8 Step 2651 Train Loss: 0.6244
Epoch 8 Step 2701 Train Loss: 0.5869
Epoch 8 Step 2751 Train Loss: 0.5628
Epoch 8 Step 2801 Train Loss: 0.5975
Epoch 8 Step 2851 Train Loss: 0.5289
Epoch 8 Step 2901 Train Loss: 0.5323
Epoch 8 Step 2951 Train Loss: 0.6618
Epoch 8 Step 3001 Train Loss: 0.5697
Epoch 8 Step 3051 Train Loss: 0.5129
Epoch 8 Step 3101 Train Loss: 0.5721
Epoch 8 Step 3151 Train Loss: 0.5809
Epoch 8 Step 3201 Train Loss: 0.5923
Epoch 8 Step 3251 Train Loss: 0.6330
Epoch 8 Step 3301 Train Loss: 0.5936
Epoch 8 Step 3351 Train Loss: 0.5690
Epoch 8: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1448 Validation Top 20 DE MSE: 0.2054. 
Epoch 9 Step 1 Train Loss: 0.5528
Epoch 9 Step 51 Train Loss: 0.5301
Epoch 9 Step 101 Train Loss: 0.5664
Epoch 9 Step 151 Train Loss: 0.5380
Epoch 9 Step 201 Train Loss: 0.5716
Epoch 9 Step 251 Train Loss: 0.5597
Epoch 9 Step 301 Train Loss: 0.5507
Epoch 9 Step 351 Train Loss: 0.6043
Epoch 9 Step 401 Train Loss: 0.5720
Epoch 9 Step 451 Train Loss: 0.5474
Epoch 9 Step 501 Train Loss: 0.5800
Epoch 9 Step 551 Train Loss: 0.5502
Epoch 9 Step 601 Train Loss: 0.5875
Epoch 9 Step 651 Train Loss: 0.6041
Epoch 9 Step 701 Train Loss: 0.6234
Epoch 9 Step 751 Train Loss: 0.5345
Epoch 9 Step 801 Train Loss: 0.5618
Epoch 9 Step 851 Train Loss: 0.6384
Epoch 9 Step 901 Train Loss: 0.5602
Epoch 9 Step 951 Train Loss: 0.6076
Epoch 9 Step 1001 Train Loss: 0.5744
Epoch 9 Step 1051 Train Loss: 0.6356
Epoch 9 Step 1101 Train Loss: 0.5889
Epoch 9 Step 1151 Train Loss: 0.5391
Epoch 9 Step 1201 Train Loss: 0.6176
Epoch 9 Step 1251 Train Loss: 0.5646
Epoch 9 Step 1301 Train Loss: 0.6010
Epoch 9 Step 1351 Train Loss: 0.5772
Epoch 9 Step 1401 Train Loss: 0.5828
Epoch 9 Step 1451 Train Loss: 0.5982
Epoch 9 Step 1501 Train Loss: 0.5933
Epoch 9 Step 1551 Train Loss: 0.6025
Epoch 9 Step 1601 Train Loss: 0.5231
Epoch 9 Step 1651 Train Loss: 0.5686
Epoch 9 Step 1701 Train Loss: 0.6930
Epoch 9 Step 1751 Train Loss: 0.6064
Epoch 9 Step 1801 Train Loss: 0.5680
Epoch 9 Step 1851 Train Loss: 0.5250
Epoch 9 Step 1901 Train Loss: 0.5602
Epoch 9 Step 1951 Train Loss: 0.5848
Epoch 9 Step 2001 Train Loss: 0.6123
Epoch 9 Step 2051 Train Loss: 0.6017
Epoch 9 Step 2101 Train Loss: 0.5905
Epoch 9 Step 2151 Train Loss: 0.5986
Epoch 9 Step 2201 Train Loss: 0.5975
Epoch 9 Step 2251 Train Loss: 0.6278
Epoch 9 Step 2301 Train Loss: 0.6124
Epoch 9 Step 2351 Train Loss: 0.6104
Epoch 9 Step 2401 Train Loss: 0.5636
Epoch 9 Step 2451 Train Loss: 0.6394
Epoch 9 Step 2501 Train Loss: 0.5316
Epoch 9 Step 2551 Train Loss: 0.6038
Epoch 9 Step 2601 Train Loss: 0.5609
Epoch 9 Step 2651 Train Loss: 0.5860
Epoch 9 Step 2701 Train Loss: 0.6004
Epoch 9 Step 2751 Train Loss: 0.5844
Epoch 9 Step 2801 Train Loss: 0.5770
Epoch 9 Step 2851 Train Loss: 0.6822
Epoch 9 Step 2901 Train Loss: 0.6287
Epoch 9 Step 2951 Train Loss: 0.5691
Epoch 9 Step 3001 Train Loss: 0.5469
Epoch 9 Step 3051 Train Loss: 0.5105
Epoch 9 Step 3101 Train Loss: 0.5806
Epoch 9 Step 3151 Train Loss: 0.5085
Epoch 9 Step 3201 Train Loss: 0.5634
Epoch 9 Step 3251 Train Loss: 0.5648
Epoch 9 Step 3301 Train Loss: 0.5851
Epoch 9 Step 3351 Train Loss: 0.5739
Epoch 9: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1420 Validation Top 20 DE MSE: 0.2032. 
Epoch 10 Step 1 Train Loss: 0.5125
Epoch 10 Step 51 Train Loss: 0.6463
Epoch 10 Step 101 Train Loss: 0.5542
Epoch 10 Step 151 Train Loss: 0.6211
Epoch 10 Step 201 Train Loss: 0.5961
Epoch 10 Step 251 Train Loss: 0.5867
Epoch 10 Step 301 Train Loss: 0.6274
Epoch 10 Step 351 Train Loss: 0.6431
Epoch 10 Step 401 Train Loss: 0.5610
Epoch 10 Step 451 Train Loss: 0.5606
Epoch 10 Step 501 Train Loss: 0.6099
Epoch 10 Step 551 Train Loss: 0.5570
Epoch 10 Step 601 Train Loss: 0.5875
Epoch 10 Step 651 Train Loss: 0.5677
Epoch 10 Step 701 Train Loss: 0.6118
Epoch 10 Step 751 Train Loss: 0.5837
Epoch 10 Step 801 Train Loss: 0.5495
Epoch 10 Step 851 Train Loss: 0.5711
Epoch 10 Step 901 Train Loss: 0.5561
Epoch 10 Step 951 Train Loss: 0.6346
Epoch 10 Step 1001 Train Loss: 0.5924
Epoch 10 Step 1051 Train Loss: 0.5899
Epoch 10 Step 1101 Train Loss: 0.6275
Epoch 10 Step 1151 Train Loss: 0.5565
Epoch 10 Step 1201 Train Loss: 0.6030
Epoch 10 Step 1251 Train Loss: 0.5848
Epoch 10 Step 1301 Train Loss: 0.5747
Epoch 10 Step 1351 Train Loss: 0.5751
Epoch 10 Step 1401 Train Loss: 0.5697
Epoch 10 Step 1451 Train Loss: 0.6266
Epoch 10 Step 1501 Train Loss: 0.5726
Epoch 10 Step 1551 Train Loss: 0.5625
Epoch 10 Step 1601 Train Loss: 0.5427
Epoch 10 Step 1651 Train Loss: 0.5292
Epoch 10 Step 1701 Train Loss: 0.6012
Epoch 10 Step 1751 Train Loss: 0.6350
Epoch 10 Step 1801 Train Loss: 0.5495
Epoch 10 Step 1851 Train Loss: 0.5558
Epoch 10 Step 1901 Train Loss: 0.5657
Epoch 10 Step 1951 Train Loss: 0.6028
Epoch 10 Step 2001 Train Loss: 0.5900
Epoch 10 Step 2051 Train Loss: 0.5760
Epoch 10 Step 2101 Train Loss: 0.6039
Epoch 10 Step 2151 Train Loss: 0.5523
Epoch 10 Step 2201 Train Loss: 0.6070
Epoch 10 Step 2251 Train Loss: 0.5584
Epoch 10 Step 2301 Train Loss: 0.5489
Epoch 10 Step 2351 Train Loss: 0.5759
Epoch 10 Step 2401 Train Loss: 0.6043
Epoch 10 Step 2451 Train Loss: 0.5553
Epoch 10 Step 2501 Train Loss: 0.5617
Epoch 10 Step 2551 Train Loss: 0.5714
Epoch 10 Step 2601 Train Loss: 0.5310
Epoch 10 Step 2651 Train Loss: 0.5993
Epoch 10 Step 2701 Train Loss: 0.5157
Epoch 10 Step 2751 Train Loss: 0.5850
Epoch 10 Step 2801 Train Loss: 0.6235
Epoch 10 Step 2851 Train Loss: 0.5319
Epoch 10 Step 2901 Train Loss: 0.5160
Epoch 10 Step 2951 Train Loss: 0.6499
Epoch 10 Step 3001 Train Loss: 0.5938
Epoch 10 Step 3051 Train Loss: 0.5122
Epoch 10 Step 3101 Train Loss: 0.6059
Epoch 10 Step 3151 Train Loss: 0.6107
Epoch 10 Step 3201 Train Loss: 0.5573
Epoch 10 Step 3251 Train Loss: 0.5899
Epoch 10 Step 3301 Train Loss: 0.5632
Epoch 10 Step 3351 Train Loss: 0.5784
Epoch 10: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1405 Validation Top 20 DE MSE: 0.2026. 
Epoch 11 Step 1 Train Loss: 0.5406
Epoch 11 Step 51 Train Loss: 0.5500
Epoch 11 Step 101 Train Loss: 0.6276
Epoch 11 Step 151 Train Loss: 0.5801
Epoch 11 Step 201 Train Loss: 0.5971
Epoch 11 Step 251 Train Loss: 0.5955
Epoch 11 Step 301 Train Loss: 0.5802
Epoch 11 Step 351 Train Loss: 0.6096
Epoch 11 Step 401 Train Loss: 0.6626
Epoch 11 Step 451 Train Loss: 0.5219
Epoch 11 Step 501 Train Loss: 0.5397
Epoch 11 Step 551 Train Loss: 0.6117
Epoch 11 Step 601 Train Loss: 0.5695
Epoch 11 Step 651 Train Loss: 0.5545
Epoch 11 Step 701 Train Loss: 0.6054
Epoch 11 Step 751 Train Loss: 0.5493
Epoch 11 Step 801 Train Loss: 0.5795
Epoch 11 Step 851 Train Loss: 0.5521
Epoch 11 Step 901 Train Loss: 0.5622
Epoch 11 Step 951 Train Loss: 0.5880
Epoch 11 Step 1001 Train Loss: 0.5825
Epoch 11 Step 1051 Train Loss: 0.5200
Epoch 11 Step 1101 Train Loss: 0.5845
Epoch 11 Step 1151 Train Loss: 0.5863
Epoch 11 Step 1201 Train Loss: 0.5733
Epoch 11 Step 1251 Train Loss: 0.5540
Epoch 11 Step 1301 Train Loss: 0.5466
Epoch 11 Step 1351 Train Loss: 0.5991
Epoch 11 Step 1401 Train Loss: 0.5676
Epoch 11 Step 1451 Train Loss: 0.5678
Epoch 11 Step 1501 Train Loss: 0.5855
Epoch 11 Step 1551 Train Loss: 0.5819
Epoch 11 Step 1601 Train Loss: 0.5526
Epoch 11 Step 1651 Train Loss: 0.5957
Epoch 11 Step 1701 Train Loss: 0.5857
Epoch 11 Step 1751 Train Loss: 0.5330
Epoch 11 Step 1801 Train Loss: 0.6243
Epoch 11 Step 1851 Train Loss: 0.5564
Epoch 11 Step 1901 Train Loss: 0.5859
Epoch 11 Step 1951 Train Loss: 0.5860
Epoch 11 Step 2001 Train Loss: 0.5693
Epoch 11 Step 2051 Train Loss: 0.6234
Epoch 11 Step 2101 Train Loss: 0.5463
Epoch 11 Step 2151 Train Loss: 0.5881
Epoch 11 Step 2201 Train Loss: 0.6087
Epoch 11 Step 2251 Train Loss: 0.5877
Epoch 11 Step 2301 Train Loss: 0.6473
Epoch 11 Step 2351 Train Loss: 0.5947
Epoch 11 Step 2401 Train Loss: 0.6365
Epoch 11 Step 2451 Train Loss: 0.5844
Epoch 11 Step 2501 Train Loss: 0.5713
Epoch 11 Step 2551 Train Loss: 0.6072
Epoch 11 Step 2601 Train Loss: 0.5565
Epoch 11 Step 2651 Train Loss: 0.6213
Epoch 11 Step 2701 Train Loss: 0.5489
Epoch 11 Step 2751 Train Loss: 0.5959
Epoch 11 Step 2801 Train Loss: 0.6256
Epoch 11 Step 2851 Train Loss: 0.5581
Epoch 11 Step 2901 Train Loss: 0.5624
Epoch 11 Step 2951 Train Loss: 0.5818
Epoch 11 Step 3001 Train Loss: 0.5261
Epoch 11 Step 3051 Train Loss: 0.5393
Epoch 11 Step 3101 Train Loss: 0.5423
Epoch 11 Step 3151 Train Loss: 0.6095
Epoch 11 Step 3201 Train Loss: 0.5541
Epoch 11 Step 3251 Train Loss: 0.5895
Epoch 11 Step 3301 Train Loss: 0.6509
Epoch 11 Step 3351 Train Loss: 0.5935
Epoch 11: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1420 Validation Top 20 DE MSE: 0.2037. 
Epoch 12 Step 1 Train Loss: 0.6101
Epoch 12 Step 51 Train Loss: 0.5459
Epoch 12 Step 101 Train Loss: 0.5915
Epoch 12 Step 151 Train Loss: 0.5541
Epoch 12 Step 201 Train Loss: 0.5650
Epoch 12 Step 251 Train Loss: 0.6266
Epoch 12 Step 301 Train Loss: 0.6502
Epoch 12 Step 351 Train Loss: 0.5256
Epoch 12 Step 401 Train Loss: 0.5511
Epoch 12 Step 451 Train Loss: 0.5987
Epoch 12 Step 501 Train Loss: 0.6011
Epoch 12 Step 551 Train Loss: 0.6000
Epoch 12 Step 601 Train Loss: 0.5963
Epoch 12 Step 651 Train Loss: 0.5961
Epoch 12 Step 701 Train Loss: 0.6923
Epoch 12 Step 751 Train Loss: 0.5936
Epoch 12 Step 801 Train Loss: 0.5054
Epoch 12 Step 851 Train Loss: 0.6089
Epoch 12 Step 901 Train Loss: 0.6021
Epoch 12 Step 951 Train Loss: 0.6192
Epoch 12 Step 1001 Train Loss: 0.5761
Epoch 12 Step 1051 Train Loss: 0.5932
Epoch 12 Step 1101 Train Loss: 0.5740
Epoch 12 Step 1151 Train Loss: 0.6012
Epoch 12 Step 1201 Train Loss: 0.6161
Epoch 12 Step 1251 Train Loss: 0.5287
Epoch 12 Step 1301 Train Loss: 0.5577
Epoch 12 Step 1351 Train Loss: 0.6336
Epoch 12 Step 1401 Train Loss: 0.6318
Epoch 12 Step 1451 Train Loss: 0.5576
Epoch 12 Step 1501 Train Loss: 0.5828
Epoch 12 Step 1551 Train Loss: 0.5099
Epoch 12 Step 1601 Train Loss: 0.5618
Epoch 12 Step 1651 Train Loss: 0.6147
Epoch 12 Step 1701 Train Loss: 0.5740
Epoch 12 Step 1751 Train Loss: 0.6149
Epoch 12 Step 1801 Train Loss: 0.5257
Epoch 12 Step 1851 Train Loss: 0.5947
Epoch 12 Step 1901 Train Loss: 0.5445
Epoch 12 Step 1951 Train Loss: 0.5467
Epoch 12 Step 2001 Train Loss: 0.5001
Epoch 12 Step 2051 Train Loss: 0.5592
Epoch 12 Step 2101 Train Loss: 0.5717
Epoch 12 Step 2151 Train Loss: 0.6208
Epoch 12 Step 2201 Train Loss: 0.5717
Epoch 12 Step 2251 Train Loss: 0.5955
Epoch 12 Step 2301 Train Loss: 0.6132
Epoch 12 Step 2351 Train Loss: 0.5876
Epoch 12 Step 2401 Train Loss: 0.6042
Epoch 12 Step 2451 Train Loss: 0.5841
Epoch 12 Step 2501 Train Loss: 0.6085
Epoch 12 Step 2551 Train Loss: 0.5394
Epoch 12 Step 2601 Train Loss: 0.5372
Epoch 12 Step 2651 Train Loss: 0.5494
Epoch 12 Step 2701 Train Loss: 0.6007
Epoch 12 Step 2751 Train Loss: 0.6026
Epoch 12 Step 2801 Train Loss: 0.6475
Epoch 12 Step 2851 Train Loss: 0.6029
Epoch 12 Step 2901 Train Loss: 0.5965
Epoch 12 Step 2951 Train Loss: 0.5678
Epoch 12 Step 3001 Train Loss: 0.5423
Epoch 12 Step 3051 Train Loss: 0.6140
Epoch 12 Step 3101 Train Loss: 0.6197
Epoch 12 Step 3151 Train Loss: 0.5935
Epoch 12 Step 3201 Train Loss: 0.5750
Epoch 12 Step 3251 Train Loss: 0.6124
Epoch 12 Step 3301 Train Loss: 0.5645
Epoch 12 Step 3351 Train Loss: 0.5794
Epoch 12: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1455 Validation Top 20 DE MSE: 0.2058. 
Epoch 13 Step 1 Train Loss: 0.5368
Epoch 13 Step 51 Train Loss: 0.5238
Epoch 13 Step 101 Train Loss: 0.5430
Epoch 13 Step 151 Train Loss: 0.5705
Epoch 13 Step 201 Train Loss: 0.5514
Epoch 13 Step 251 Train Loss: 0.5332
Epoch 13 Step 301 Train Loss: 0.6094
Epoch 13 Step 351 Train Loss: 0.6019
Epoch 13 Step 401 Train Loss: 0.5528
Epoch 13 Step 451 Train Loss: 0.5747
Epoch 13 Step 501 Train Loss: 0.5978
Epoch 13 Step 551 Train Loss: 0.5566
Epoch 13 Step 601 Train Loss: 0.5306
Epoch 13 Step 651 Train Loss: 0.5908
Epoch 13 Step 701 Train Loss: 0.5643
Epoch 13 Step 751 Train Loss: 0.5724
Epoch 13 Step 801 Train Loss: 0.6175
Epoch 13 Step 851 Train Loss: 0.5801
Epoch 13 Step 901 Train Loss: 0.5577
Epoch 13 Step 951 Train Loss: 0.5977
Epoch 13 Step 1001 Train Loss: 0.5571
Epoch 13 Step 1051 Train Loss: 0.5606
Epoch 13 Step 1101 Train Loss: 0.5733
Epoch 13 Step 1151 Train Loss: 0.5454
Epoch 13 Step 1201 Train Loss: 0.5728
Epoch 13 Step 1251 Train Loss: 0.5242
Epoch 13 Step 1301 Train Loss: 0.5930
Epoch 13 Step 1351 Train Loss: 0.6253
Epoch 13 Step 1401 Train Loss: 0.5781
Epoch 13 Step 1451 Train Loss: 0.5629
Epoch 13 Step 1501 Train Loss: 0.5977
Epoch 13 Step 1551 Train Loss: 0.6075
Epoch 13 Step 1601 Train Loss: 0.5992
Epoch 13 Step 1651 Train Loss: 0.5617
Epoch 13 Step 1701 Train Loss: 0.5566
Epoch 13 Step 1751 Train Loss: 0.6190
Epoch 13 Step 1801 Train Loss: 0.5612
Epoch 13 Step 1851 Train Loss: 0.6274
Epoch 13 Step 1901 Train Loss: 0.4972
Epoch 13 Step 1951 Train Loss: 0.5698
Epoch 13 Step 2001 Train Loss: 0.5819
Epoch 13 Step 2051 Train Loss: 0.6080
Epoch 13 Step 2101 Train Loss: 0.6093
Epoch 13 Step 2151 Train Loss: 0.6265
Epoch 13 Step 2201 Train Loss: 0.5861
Epoch 13 Step 2251 Train Loss: 0.6069
Epoch 13 Step 2301 Train Loss: 0.5581
Epoch 13 Step 2351 Train Loss: 0.5859
Epoch 13 Step 2401 Train Loss: 0.5786
Epoch 13 Step 2451 Train Loss: 0.5411
Epoch 13 Step 2501 Train Loss: 0.5899
Epoch 13 Step 2551 Train Loss: 0.5269
Epoch 13 Step 2601 Train Loss: 0.5292
Epoch 13 Step 2651 Train Loss: 0.5621
Epoch 13 Step 2701 Train Loss: 0.5684
Epoch 13 Step 2751 Train Loss: 0.5763
Epoch 13 Step 2801 Train Loss: 0.5739
Epoch 13 Step 2851 Train Loss: 0.6530
Epoch 13 Step 2901 Train Loss: 0.6320
Epoch 13 Step 2951 Train Loss: 0.5704
Epoch 13 Step 3001 Train Loss: 0.5559
Epoch 13 Step 3051 Train Loss: 0.5746
Epoch 13 Step 3101 Train Loss: 0.5149
Epoch 13 Step 3151 Train Loss: 0.5633
Epoch 13 Step 3201 Train Loss: 0.5117
Epoch 13 Step 3251 Train Loss: 0.5765
Epoch 13 Step 3301 Train Loss: 0.5230
Epoch 13 Step 3351 Train Loss: 0.5590
Epoch 13: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1420 Validation Top 20 DE MSE: 0.2035. 
Epoch 14 Step 1 Train Loss: 0.6324
Epoch 14 Step 51 Train Loss: 0.5719
Epoch 14 Step 101 Train Loss: 0.6249
Epoch 14 Step 151 Train Loss: 0.5777
Epoch 14 Step 201 Train Loss: 0.5708
Epoch 14 Step 251 Train Loss: 0.5982
Epoch 14 Step 301 Train Loss: 0.5129
Epoch 14 Step 351 Train Loss: 0.5584
Epoch 14 Step 401 Train Loss: 0.5383
Epoch 14 Step 451 Train Loss: 0.5505
Epoch 14 Step 501 Train Loss: 0.6619
Epoch 14 Step 551 Train Loss: 0.5428
Epoch 14 Step 601 Train Loss: 0.5424
Epoch 14 Step 651 Train Loss: 0.5680
Epoch 14 Step 701 Train Loss: 0.5939
Epoch 14 Step 751 Train Loss: 0.5890
Epoch 14 Step 801 Train Loss: 0.6247
Epoch 14 Step 851 Train Loss: 0.6214
Epoch 14 Step 901 Train Loss: 0.5077
Epoch 14 Step 951 Train Loss: 0.5583
Epoch 14 Step 1001 Train Loss: 0.6075
Epoch 14 Step 1051 Train Loss: 0.5574
Epoch 14 Step 1101 Train Loss: 0.6215
Epoch 14 Step 1151 Train Loss: 0.5073
Epoch 14 Step 1201 Train Loss: 0.5942
Epoch 14 Step 1251 Train Loss: 0.6227
Epoch 14 Step 1301 Train Loss: 0.5467
Epoch 14 Step 1351 Train Loss: 0.5463
Epoch 14 Step 1401 Train Loss: 0.6365
Epoch 14 Step 1451 Train Loss: 0.6024
Epoch 14 Step 1501 Train Loss: 0.5835
Epoch 14 Step 1551 Train Loss: 0.5623
Epoch 14 Step 1601 Train Loss: 0.5749
Epoch 14 Step 1651 Train Loss: 0.5809
Epoch 14 Step 1701 Train Loss: 0.5679
Epoch 14 Step 1751 Train Loss: 0.5861
Epoch 14 Step 1801 Train Loss: 0.6408
Epoch 14 Step 1851 Train Loss: 0.5774
Epoch 14 Step 1901 Train Loss: 0.5267
Epoch 14 Step 1951 Train Loss: 0.6046
Epoch 14 Step 2001 Train Loss: 0.5480
Epoch 14 Step 2051 Train Loss: 0.6334
Epoch 14 Step 2101 Train Loss: 0.6003
Epoch 14 Step 2151 Train Loss: 0.5617
Epoch 14 Step 2201 Train Loss: 0.5820
Epoch 14 Step 2251 Train Loss: 0.6037
Epoch 14 Step 2301 Train Loss: 0.6023
Epoch 14 Step 2351 Train Loss: 0.5961
Epoch 14 Step 2401 Train Loss: 0.5711
Epoch 14 Step 2451 Train Loss: 0.5592
Epoch 14 Step 2501 Train Loss: 0.6114
Epoch 14 Step 2551 Train Loss: 0.5764
Epoch 14 Step 2601 Train Loss: 0.5574
Epoch 14 Step 2651 Train Loss: 0.5458
Epoch 14 Step 2701 Train Loss: 0.5958
Epoch 14 Step 2751 Train Loss: 0.5906
Epoch 14 Step 2801 Train Loss: 0.6103
Epoch 14 Step 2851 Train Loss: 0.5886
Epoch 14 Step 2901 Train Loss: 0.5628
Epoch 14 Step 2951 Train Loss: 0.5951
Epoch 14 Step 3001 Train Loss: 0.5607
Epoch 14 Step 3051 Train Loss: 0.5628
Epoch 14 Step 3101 Train Loss: 0.6043
Epoch 14 Step 3151 Train Loss: 0.5643
Epoch 14 Step 3201 Train Loss: 0.5640
Epoch 14 Step 3251 Train Loss: 0.6911
Epoch 14 Step 3301 Train Loss: 0.6210
Epoch 14 Step 3351 Train Loss: 0.5862
Epoch 14: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1439 Validation Top 20 DE MSE: 0.2051. 
Epoch 15 Step 1 Train Loss: 0.5206
Epoch 15 Step 51 Train Loss: 0.5954
Epoch 15 Step 101 Train Loss: 0.5570
Epoch 15 Step 151 Train Loss: 0.5842
Epoch 15 Step 201 Train Loss: 0.6143
Epoch 15 Step 251 Train Loss: 0.5937
Epoch 15 Step 301 Train Loss: 0.5917
Epoch 15 Step 351 Train Loss: 0.5805
Epoch 15 Step 401 Train Loss: 0.5904
Epoch 15 Step 451 Train Loss: 0.5693
Epoch 15 Step 501 Train Loss: 0.5784
Epoch 15 Step 551 Train Loss: 0.6688
Epoch 15 Step 601 Train Loss: 0.5936
Epoch 15 Step 651 Train Loss: 0.5323
Epoch 15 Step 701 Train Loss: 0.6258
Epoch 15 Step 751 Train Loss: 0.5486
Epoch 15 Step 801 Train Loss: 0.6171
Epoch 15 Step 851 Train Loss: 0.6063
Epoch 15 Step 901 Train Loss: 0.6505
Epoch 15 Step 951 Train Loss: 0.5838
Epoch 15 Step 1001 Train Loss: 0.6195
Epoch 15 Step 1051 Train Loss: 0.5923
Epoch 15 Step 1101 Train Loss: 0.5734
Epoch 15 Step 1151 Train Loss: 0.5630
Epoch 15 Step 1201 Train Loss: 0.5654
Epoch 15 Step 1251 Train Loss: 0.6268
Epoch 15 Step 1301 Train Loss: 0.5834
Epoch 15 Step 1351 Train Loss: 0.5928
Epoch 15 Step 1401 Train Loss: 0.5568
Epoch 15 Step 1451 Train Loss: 0.6149
Epoch 15 Step 1501 Train Loss: 0.6215
Epoch 15 Step 1551 Train Loss: 0.5306
Epoch 15 Step 1601 Train Loss: 0.6546
Epoch 15 Step 1651 Train Loss: 0.5685
Epoch 15 Step 1701 Train Loss: 0.5001
Epoch 15 Step 1751 Train Loss: 0.5717
Epoch 15 Step 1801 Train Loss: 0.5791
Epoch 15 Step 1851 Train Loss: 0.5693
Epoch 15 Step 1901 Train Loss: 0.5752
Epoch 15 Step 1951 Train Loss: 0.5266
Epoch 15 Step 2001 Train Loss: 0.5564
Epoch 15 Step 2051 Train Loss: 0.5568
Epoch 15 Step 2101 Train Loss: 0.5888
Epoch 15 Step 2151 Train Loss: 0.5975
Epoch 15 Step 2201 Train Loss: 0.5500
Epoch 15 Step 2251 Train Loss: 0.5724
Epoch 15 Step 2301 Train Loss: 0.5574
Epoch 15 Step 2351 Train Loss: 0.6016
Epoch 15 Step 2401 Train Loss: 0.5694
Epoch 15 Step 2451 Train Loss: 0.5276
Epoch 15 Step 2501 Train Loss: 0.5489
Epoch 15 Step 2551 Train Loss: 0.5859
Epoch 15 Step 2601 Train Loss: 0.5534
Epoch 15 Step 2651 Train Loss: 0.5843
Epoch 15 Step 2701 Train Loss: 0.5996
Epoch 15 Step 2751 Train Loss: 0.5918
Epoch 15 Step 2801 Train Loss: 0.5810
Epoch 15 Step 2851 Train Loss: 0.5413
Epoch 15 Step 2901 Train Loss: 0.6204
Epoch 15 Step 2951 Train Loss: 0.5737
Epoch 15 Step 3001 Train Loss: 0.5613
Epoch 15 Step 3051 Train Loss: 0.5882
Epoch 15 Step 3101 Train Loss: 0.6217
Epoch 15 Step 3151 Train Loss: 0.6081
Epoch 15 Step 3201 Train Loss: 0.5744
Epoch 15 Step 3251 Train Loss: 0.5902
Epoch 15 Step 3301 Train Loss: 0.5693
Epoch 15 Step 3351 Train Loss: 0.5346
Epoch 15: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.1415 Validation Top 20 DE MSE: 0.2034. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1612
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.008770077
test_unseen_single_pearson: 0.98795000004513
test_unseen_single_mse_de: 0.16122565
test_unseen_single_pearson_de: 0.9064044665051899
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3314233892050401
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2891385767790262
test_unseen_single_frac_sigma_below_1_non_dropout: 0.7303370786516854
test_unseen_single_mse_top20_de_non_dropout: 0.16692607
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.054 MB uploadedwandb: | 0.013 MB of 0.054 MB uploadedwandb: / 0.013 MB of 0.054 MB uploadedwandb: - 0.054 MB of 0.054 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.16123
wandb:                                              test_de_pearson 0.9064
wandb:               test_frac_opposite_direction_top20_non_dropout 0.28914
wandb:                          test_frac_sigma_below_1_non_dropout 0.73034
wandb:                                                     test_mse 0.00877
wandb:                                test_mse_top20_de_non_dropout 0.16693
wandb:                                                 test_pearson 0.98795
wandb:                                           test_pearson_delta 0.33142
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.28914
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.73034
wandb:                                       test_unseen_single_mse 0.00877
wandb:                                    test_unseen_single_mse_de 0.16123
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.16693
wandb:                                   test_unseen_single_pearson 0.98795
wandb:                                test_unseen_single_pearson_de 0.9064
wandb:                             test_unseen_single_pearson_delta 0.33142
wandb:                                                 train_de_mse 0.14151
wandb:                                             train_de_pearson 0.91213
wandb:                                                    train_mse 0.00718
wandb:                                                train_pearson 0.99001
wandb:                                                training_loss 0.57498
wandb:                                                   val_de_mse 0.20342
wandb:                                               val_de_pearson 0.93017
wandb:                                                      val_mse 0.00793
wandb:                                                  val_pearson 0.9888
wandb: 
wandb: üöÄ View run geneformer_Replogle_k562_essential_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/6b659imm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_094430-6b659imm/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:267
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_121906-5ru286q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_k562_essential_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/5ru286q1
wandb: WARNING Serializing object of type ndarray that is 23167104 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6289
Epoch 1 Step 51 Train Loss: 0.6179
Epoch 1 Step 101 Train Loss: 0.5701
Epoch 1 Step 151 Train Loss: 0.6375
Epoch 1 Step 201 Train Loss: 0.5797
Epoch 1 Step 251 Train Loss: 0.5773
Epoch 1 Step 301 Train Loss: 0.5982
Epoch 1 Step 351 Train Loss: 0.6233
Epoch 1 Step 401 Train Loss: 0.6175
Epoch 1 Step 451 Train Loss: 0.5512
Epoch 1 Step 501 Train Loss: 0.5872
Epoch 1 Step 551 Train Loss: 0.5709
Epoch 1 Step 601 Train Loss: 0.6574
Epoch 1 Step 651 Train Loss: 0.5776
Epoch 1 Step 701 Train Loss: 0.6310
Epoch 1 Step 751 Train Loss: 0.6034
Epoch 1 Step 801 Train Loss: 0.5405
Epoch 1 Step 851 Train Loss: 0.5655
Epoch 1 Step 901 Train Loss: 0.5627
Epoch 1 Step 951 Train Loss: 0.5910
Epoch 1 Step 1001 Train Loss: 0.6242
Epoch 1 Step 1051 Train Loss: 0.5887
Epoch 1 Step 1101 Train Loss: 0.5418
Epoch 1 Step 1151 Train Loss: 0.5897
Epoch 1 Step 1201 Train Loss: 0.5631
Epoch 1 Step 1251 Train Loss: 0.5600
Epoch 1 Step 1301 Train Loss: 0.5847
Epoch 1 Step 1351 Train Loss: 0.6010
Epoch 1 Step 1401 Train Loss: 0.5593
Epoch 1 Step 1451 Train Loss: 0.5773
Epoch 1 Step 1501 Train Loss: 0.5667
Epoch 1 Step 1551 Train Loss: 0.5558
Epoch 1 Step 1601 Train Loss: 0.5676
Epoch 1 Step 1651 Train Loss: 0.5635
Epoch 1 Step 1701 Train Loss: 0.5935
Epoch 1 Step 1751 Train Loss: 0.5924
Epoch 1 Step 1801 Train Loss: 0.6425
Epoch 1 Step 1851 Train Loss: 0.7216
Epoch 1 Step 1901 Train Loss: 0.6547
Epoch 1 Step 1951 Train Loss: 0.5598
Epoch 1 Step 2001 Train Loss: 0.5941
Epoch 1 Step 2051 Train Loss: 0.6195
Epoch 1 Step 2101 Train Loss: 0.6006
Epoch 1 Step 2151 Train Loss: 0.5798
Epoch 1 Step 2201 Train Loss: 0.5739
Epoch 1 Step 2251 Train Loss: 0.5438
Epoch 1 Step 2301 Train Loss: 0.5690
Epoch 1 Step 2351 Train Loss: 0.6374
Epoch 1 Step 2401 Train Loss: 0.5924
Epoch 1 Step 2451 Train Loss: 0.6059
Epoch 1 Step 2501 Train Loss: 0.5458
Epoch 1 Step 2551 Train Loss: 0.5784
Epoch 1 Step 2601 Train Loss: 0.6378
Epoch 1 Step 2651 Train Loss: 0.6303
Epoch 1 Step 2701 Train Loss: 0.6427
Epoch 1 Step 2751 Train Loss: 0.6815
Epoch 1 Step 2801 Train Loss: 0.5145
Epoch 1 Step 2851 Train Loss: 0.5663
Epoch 1 Step 2901 Train Loss: 0.6209
Epoch 1 Step 2951 Train Loss: 0.5605
Epoch 1 Step 3001 Train Loss: 0.5432
Epoch 1 Step 3051 Train Loss: 0.5593
Epoch 1 Step 3101 Train Loss: 0.5570
Epoch 1 Step 3151 Train Loss: 0.5443
Epoch 1 Step 3201 Train Loss: 0.5229
Epoch 1 Step 3251 Train Loss: 0.6296
Epoch 1 Step 3301 Train Loss: 0.5859
Epoch 1: Train Overall MSE: 0.0172 Validation Overall MSE: 0.0181. 
Train Top 20 DE MSE: 0.1903 Validation Top 20 DE MSE: 0.1826. 
Epoch 2 Step 1 Train Loss: 0.5729
Epoch 2 Step 51 Train Loss: 0.6722
Epoch 2 Step 101 Train Loss: 0.5682
Epoch 2 Step 151 Train Loss: 0.6248
Epoch 2 Step 201 Train Loss: 0.5841
Epoch 2 Step 251 Train Loss: 0.5581
Epoch 2 Step 301 Train Loss: 0.5535
Epoch 2 Step 351 Train Loss: 0.5541
Epoch 2 Step 401 Train Loss: 0.6238
Epoch 2 Step 451 Train Loss: 0.6108
Epoch 2 Step 501 Train Loss: 0.5803
Epoch 2 Step 551 Train Loss: 0.5935
Epoch 2 Step 601 Train Loss: 0.5901
Epoch 2 Step 651 Train Loss: 0.5408
Epoch 2 Step 701 Train Loss: 0.5772
Epoch 2 Step 751 Train Loss: 0.5747
Epoch 2 Step 801 Train Loss: 0.5830
Epoch 2 Step 851 Train Loss: 0.6102
Epoch 2 Step 901 Train Loss: 0.5599
Epoch 2 Step 951 Train Loss: 0.5551
Epoch 2 Step 1001 Train Loss: 0.6003
Epoch 2 Step 1051 Train Loss: 0.5958
Epoch 2 Step 1101 Train Loss: 0.6731
Epoch 2 Step 1151 Train Loss: 0.5806
Epoch 2 Step 1201 Train Loss: 0.5889
Epoch 2 Step 1251 Train Loss: 0.6114
Epoch 2 Step 1301 Train Loss: 0.6018
Epoch 2 Step 1351 Train Loss: 0.5822
Epoch 2 Step 1401 Train Loss: 0.6189
Epoch 2 Step 1451 Train Loss: 0.5767
Epoch 2 Step 1501 Train Loss: 0.6164
Epoch 2 Step 1551 Train Loss: 0.6152
Epoch 2 Step 1601 Train Loss: 0.5375
Epoch 2 Step 1651 Train Loss: 0.6709
Epoch 2 Step 1701 Train Loss: 0.5778
Epoch 2 Step 1751 Train Loss: 0.6289
Epoch 2 Step 1801 Train Loss: 0.5620
Epoch 2 Step 1851 Train Loss: 0.5797
Epoch 2 Step 1901 Train Loss: 0.5518
Epoch 2 Step 1951 Train Loss: 0.5524
Epoch 2 Step 2001 Train Loss: 0.5662
Epoch 2 Step 2051 Train Loss: 0.5946
Epoch 2 Step 2101 Train Loss: 0.5861
Epoch 2 Step 2151 Train Loss: 0.5730
Epoch 2 Step 2201 Train Loss: 0.5874
Epoch 2 Step 2251 Train Loss: 0.6477
Epoch 2 Step 2301 Train Loss: 0.5366
Epoch 2 Step 2351 Train Loss: 0.6373
Epoch 2 Step 2401 Train Loss: 0.5557
Epoch 2 Step 2451 Train Loss: 0.5915
Epoch 2 Step 2501 Train Loss: 0.5479
Epoch 2 Step 2551 Train Loss: 0.5536
Epoch 2 Step 2601 Train Loss: 0.6290
Epoch 2 Step 2651 Train Loss: 0.5761
Epoch 2 Step 2701 Train Loss: 0.5459
Epoch 2 Step 2751 Train Loss: 0.5615
Epoch 2 Step 2801 Train Loss: 0.5466
Epoch 2 Step 2851 Train Loss: 0.5585
Epoch 2 Step 2901 Train Loss: 0.6729
Epoch 2 Step 2951 Train Loss: 0.5530
Epoch 2 Step 3001 Train Loss: 0.5377
Epoch 2 Step 3051 Train Loss: 0.5543
Epoch 2 Step 3101 Train Loss: 0.6107
Epoch 2 Step 3151 Train Loss: 0.5442
Epoch 2 Step 3201 Train Loss: 0.5576
Epoch 2 Step 3251 Train Loss: 0.5566
Epoch 2 Step 3301 Train Loss: 0.5602
Epoch 2: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0095. 
Train Top 20 DE MSE: 0.1626 Validation Top 20 DE MSE: 0.1752. 
Epoch 3 Step 1 Train Loss: 0.5744
Epoch 3 Step 51 Train Loss: 0.5527
Epoch 3 Step 101 Train Loss: 0.5364
Epoch 3 Step 151 Train Loss: 0.5214
Epoch 3 Step 201 Train Loss: 0.5724
Epoch 3 Step 251 Train Loss: 0.5674
Epoch 3 Step 301 Train Loss: 0.5107
Epoch 3 Step 351 Train Loss: 0.5871
Epoch 3 Step 401 Train Loss: 0.6282
Epoch 3 Step 451 Train Loss: 0.5766
Epoch 3 Step 501 Train Loss: 0.5424
Epoch 3 Step 551 Train Loss: 0.5798
Epoch 3 Step 601 Train Loss: 0.6099
Epoch 3 Step 651 Train Loss: 0.5512
Epoch 3 Step 701 Train Loss: 0.5546
Epoch 3 Step 751 Train Loss: 0.5995
Epoch 3 Step 801 Train Loss: 0.5594
Epoch 3 Step 851 Train Loss: 0.6242
Epoch 3 Step 901 Train Loss: 0.5515
Epoch 3 Step 951 Train Loss: 0.5773
Epoch 3 Step 1001 Train Loss: 0.5960
Epoch 3 Step 1051 Train Loss: 0.6082
Epoch 3 Step 1101 Train Loss: 0.5603
Epoch 3 Step 1151 Train Loss: 0.5895
Epoch 3 Step 1201 Train Loss: 0.6217
Epoch 3 Step 1251 Train Loss: 0.5368
Epoch 3 Step 1301 Train Loss: 0.5877
Epoch 3 Step 1351 Train Loss: 0.5773
Epoch 3 Step 1401 Train Loss: 0.5648
Epoch 3 Step 1451 Train Loss: 0.5625
Epoch 3 Step 1501 Train Loss: 0.5777
Epoch 3 Step 1551 Train Loss: 0.5804
Epoch 3 Step 1601 Train Loss: 0.6232
Epoch 3 Step 1651 Train Loss: 0.6305
Epoch 3 Step 1701 Train Loss: 0.6171
Epoch 3 Step 1751 Train Loss: 0.5569
Epoch 3 Step 1801 Train Loss: 0.5537
Epoch 3 Step 1851 Train Loss: 0.5197
Epoch 3 Step 1901 Train Loss: 0.5506
Epoch 3 Step 1951 Train Loss: 0.6091
Epoch 3 Step 2001 Train Loss: 0.5765
Epoch 3 Step 2051 Train Loss: 0.5109
Epoch 3 Step 2101 Train Loss: 0.6648
Epoch 3 Step 2151 Train Loss: 0.6117
Epoch 3 Step 2201 Train Loss: 0.5308
Epoch 3 Step 2251 Train Loss: 0.6003
Epoch 3 Step 2301 Train Loss: 0.5877
Epoch 3 Step 2351 Train Loss: 0.5694
Epoch 3 Step 2401 Train Loss: 0.5535
Epoch 3 Step 2451 Train Loss: 0.6744
Epoch 3 Step 2501 Train Loss: 0.5778
Epoch 3 Step 2551 Train Loss: 0.5510
Epoch 3 Step 2601 Train Loss: 0.6057
Epoch 3 Step 2651 Train Loss: 0.5510
Epoch 3 Step 2701 Train Loss: 0.5849
Epoch 3 Step 2751 Train Loss: 0.5848
Epoch 3 Step 2801 Train Loss: 0.5471
Epoch 3 Step 2851 Train Loss: 0.6200
Epoch 3 Step 2901 Train Loss: 0.6151
Epoch 3 Step 2951 Train Loss: 0.5214
Epoch 3 Step 3001 Train Loss: 0.5482
Epoch 3 Step 3051 Train Loss: 0.5573
Epoch 3 Step 3101 Train Loss: 0.6357
Epoch 3 Step 3151 Train Loss: 0.6189
Epoch 3 Step 3201 Train Loss: 0.5447
Epoch 3 Step 3251 Train Loss: 0.5756
Epoch 3 Step 3301 Train Loss: 0.6506
Epoch 3: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1652 Validation Top 20 DE MSE: 0.1810. 
Epoch 4 Step 1 Train Loss: 0.6086
Epoch 4 Step 51 Train Loss: 0.5363
Epoch 4 Step 101 Train Loss: 0.5465
Epoch 4 Step 151 Train Loss: 0.5407
Epoch 4 Step 201 Train Loss: 0.5527
Epoch 4 Step 251 Train Loss: 0.6023
Epoch 4 Step 301 Train Loss: 0.5323
Epoch 4 Step 351 Train Loss: 0.5652
Epoch 4 Step 401 Train Loss: 0.6222
Epoch 4 Step 451 Train Loss: 0.5483
Epoch 4 Step 501 Train Loss: 0.6517
Epoch 4 Step 551 Train Loss: 0.5963
Epoch 4 Step 601 Train Loss: 0.5788
Epoch 4 Step 651 Train Loss: 0.5906
Epoch 4 Step 701 Train Loss: 0.5909
Epoch 4 Step 751 Train Loss: 0.5497
Epoch 4 Step 801 Train Loss: 0.5703
Epoch 4 Step 851 Train Loss: 0.5396
Epoch 4 Step 901 Train Loss: 0.5586
Epoch 4 Step 951 Train Loss: 0.6358
Epoch 4 Step 1001 Train Loss: 0.5732
Epoch 4 Step 1051 Train Loss: 0.6125
Epoch 4 Step 1101 Train Loss: 0.5666
Epoch 4 Step 1151 Train Loss: 0.5306
Epoch 4 Step 1201 Train Loss: 0.5723
Epoch 4 Step 1251 Train Loss: 0.5479
Epoch 4 Step 1301 Train Loss: 0.5760
Epoch 4 Step 1351 Train Loss: 0.5649
Epoch 4 Step 1401 Train Loss: 0.5998
Epoch 4 Step 1451 Train Loss: 0.5723
Epoch 4 Step 1501 Train Loss: 0.5801
Epoch 4 Step 1551 Train Loss: 0.5948
Epoch 4 Step 1601 Train Loss: 0.5577
Epoch 4 Step 1651 Train Loss: 0.5858
Epoch 4 Step 1701 Train Loss: 0.5536
Epoch 4 Step 1751 Train Loss: 0.6257
Epoch 4 Step 1801 Train Loss: 0.5700
Epoch 4 Step 1851 Train Loss: 0.6519
Epoch 4 Step 1901 Train Loss: 0.5864
Epoch 4 Step 1951 Train Loss: 0.5545
Epoch 4 Step 2001 Train Loss: 0.5508
Epoch 4 Step 2051 Train Loss: 0.5851
Epoch 4 Step 2101 Train Loss: 0.5746
Epoch 4 Step 2151 Train Loss: 0.5891
Epoch 4 Step 2201 Train Loss: 0.5806
Epoch 4 Step 2251 Train Loss: 0.5632
Epoch 4 Step 2301 Train Loss: 0.5986
Epoch 4 Step 2351 Train Loss: 0.5794
Epoch 4 Step 2401 Train Loss: 0.6158
Epoch 4 Step 2451 Train Loss: 0.6715
Epoch 4 Step 2501 Train Loss: 0.4969
Epoch 4 Step 2551 Train Loss: 0.5982
Epoch 4 Step 2601 Train Loss: 0.5777
Epoch 4 Step 2651 Train Loss: 0.5486
Epoch 4 Step 2701 Train Loss: 0.5402
Epoch 4 Step 2751 Train Loss: 0.5226
Epoch 4 Step 2801 Train Loss: 0.5405
Epoch 4 Step 2851 Train Loss: 0.5298
Epoch 4 Step 2901 Train Loss: 0.5752
Epoch 4 Step 2951 Train Loss: 0.5182
Epoch 4 Step 3001 Train Loss: 0.5517
Epoch 4 Step 3051 Train Loss: 0.6010
Epoch 4 Step 3101 Train Loss: 0.5970
Epoch 4 Step 3151 Train Loss: 0.5622
Epoch 4 Step 3201 Train Loss: 0.5594
Epoch 4 Step 3251 Train Loss: 0.6132
Epoch 4 Step 3301 Train Loss: 0.6252
Epoch 4: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0089. 
Train Top 20 DE MSE: 0.1598 Validation Top 20 DE MSE: 0.1796. 
Epoch 5 Step 1 Train Loss: 0.5684
Epoch 5 Step 51 Train Loss: 0.5751
Epoch 5 Step 101 Train Loss: 0.5592
Epoch 5 Step 151 Train Loss: 0.6256
Epoch 5 Step 201 Train Loss: 0.5783
Epoch 5 Step 251 Train Loss: 0.5727
Epoch 5 Step 301 Train Loss: 0.5612
Epoch 5 Step 351 Train Loss: 0.6119
Epoch 5 Step 401 Train Loss: 0.5946
Epoch 5 Step 451 Train Loss: 0.5498
Epoch 5 Step 501 Train Loss: 0.5696
Epoch 5 Step 551 Train Loss: 0.5750
Epoch 5 Step 601 Train Loss: 0.5653
Epoch 5 Step 651 Train Loss: 0.5738
Epoch 5 Step 701 Train Loss: 0.6204
Epoch 5 Step 751 Train Loss: 0.5933
Epoch 5 Step 801 Train Loss: 0.5422
Epoch 5 Step 851 Train Loss: 0.5555
Epoch 5 Step 901 Train Loss: 0.5380
Epoch 5 Step 951 Train Loss: 0.5190
Epoch 5 Step 1001 Train Loss: 0.6032
Epoch 5 Step 1051 Train Loss: 0.5850
Epoch 5 Step 1101 Train Loss: 0.6029
Epoch 5 Step 1151 Train Loss: 0.5724
Epoch 5 Step 1201 Train Loss: 0.5306
Epoch 5 Step 1251 Train Loss: 0.5709
Epoch 5 Step 1301 Train Loss: 0.5895
Epoch 5 Step 1351 Train Loss: 0.5681
Epoch 5 Step 1401 Train Loss: 0.5536
Epoch 5 Step 1451 Train Loss: 0.5896
Epoch 5 Step 1501 Train Loss: 0.5112
Epoch 5 Step 1551 Train Loss: 0.6352
Epoch 5 Step 1601 Train Loss: 0.5461
Epoch 5 Step 1651 Train Loss: 0.5770
Epoch 5 Step 1701 Train Loss: 0.5759
Epoch 5 Step 1751 Train Loss: 0.6053
Epoch 5 Step 1801 Train Loss: 0.6101
Epoch 5 Step 1851 Train Loss: 0.5209
Epoch 5 Step 1901 Train Loss: 0.5919
Epoch 5 Step 1951 Train Loss: 0.6400
Epoch 5 Step 2001 Train Loss: 0.6181
Epoch 5 Step 2051 Train Loss: 0.5670
Epoch 5 Step 2101 Train Loss: 0.5876
Epoch 5 Step 2151 Train Loss: 0.5475
Epoch 5 Step 2201 Train Loss: 0.6415
Epoch 5 Step 2251 Train Loss: 0.5457
Epoch 5 Step 2301 Train Loss: 0.5444
Epoch 5 Step 2351 Train Loss: 0.6032
Epoch 5 Step 2401 Train Loss: 0.5400
Epoch 5 Step 2451 Train Loss: 0.5538
Epoch 5 Step 2501 Train Loss: 0.6264
Epoch 5 Step 2551 Train Loss: 0.5811
Epoch 5 Step 2601 Train Loss: 0.6102
Epoch 5 Step 2651 Train Loss: 0.6382
Epoch 5 Step 2701 Train Loss: 0.5516
Epoch 5 Step 2751 Train Loss: 0.5766
Epoch 5 Step 2801 Train Loss: 0.5790
Epoch 5 Step 2851 Train Loss: 0.5274
Epoch 5 Step 2901 Train Loss: 0.5413
Epoch 5 Step 2951 Train Loss: 0.5642
Epoch 5 Step 3001 Train Loss: 0.5833
Epoch 5 Step 3051 Train Loss: 0.5751
Epoch 5 Step 3101 Train Loss: 0.5931
Epoch 5 Step 3151 Train Loss: 0.5523
Epoch 5 Step 3201 Train Loss: 0.5629
Epoch 5 Step 3251 Train Loss: 0.5502
Epoch 5 Step 3301 Train Loss: 0.5987
Epoch 5: Train Overall MSE: 0.0085 Validation Overall MSE: 0.0092. 
Train Top 20 DE MSE: 0.1687 Validation Top 20 DE MSE: 0.1887. 
Epoch 6 Step 1 Train Loss: 0.5563
Epoch 6 Step 51 Train Loss: 0.5737
Epoch 6 Step 101 Train Loss: 0.5320
Epoch 6 Step 151 Train Loss: 0.5679
Epoch 6 Step 201 Train Loss: 0.5542
Epoch 6 Step 251 Train Loss: 0.5803
Epoch 6 Step 301 Train Loss: 0.5258
Epoch 6 Step 351 Train Loss: 0.5761
Epoch 6 Step 401 Train Loss: 0.5849
Epoch 6 Step 451 Train Loss: 0.5758
Epoch 6 Step 501 Train Loss: 0.5630
Epoch 6 Step 551 Train Loss: 0.5538
Epoch 6 Step 601 Train Loss: 0.5726
Epoch 6 Step 651 Train Loss: 0.6144
Epoch 6 Step 701 Train Loss: 0.5584
Epoch 6 Step 751 Train Loss: 0.5588
Epoch 6 Step 801 Train Loss: 0.5097
Epoch 6 Step 851 Train Loss: 0.6222
Epoch 6 Step 901 Train Loss: 0.6164
Epoch 6 Step 951 Train Loss: 0.5350
Epoch 6 Step 1001 Train Loss: 0.5811
Epoch 6 Step 1051 Train Loss: 0.6090
Epoch 6 Step 1101 Train Loss: 0.5439
Epoch 6 Step 1151 Train Loss: 0.6422
Epoch 6 Step 1201 Train Loss: 0.5812
Epoch 6 Step 1251 Train Loss: 0.5904
Epoch 6 Step 1301 Train Loss: 0.5961
Epoch 6 Step 1351 Train Loss: 0.5600
Epoch 6 Step 1401 Train Loss: 0.5391
Epoch 6 Step 1451 Train Loss: 0.5706
Epoch 6 Step 1501 Train Loss: 0.5588
Epoch 6 Step 1551 Train Loss: 0.6692
Epoch 6 Step 1601 Train Loss: 0.5485
Epoch 6 Step 1651 Train Loss: 0.5767
Epoch 6 Step 1701 Train Loss: 0.5856
Epoch 6 Step 1751 Train Loss: 0.5717
Epoch 6 Step 1801 Train Loss: 0.5894
Epoch 6 Step 1851 Train Loss: 0.5111
Epoch 6 Step 1901 Train Loss: 0.5361
Epoch 6 Step 1951 Train Loss: 0.5548
Epoch 6 Step 2001 Train Loss: 0.5668
Epoch 6 Step 2051 Train Loss: 0.5706
Epoch 6 Step 2101 Train Loss: 0.6010
Epoch 6 Step 2151 Train Loss: 0.6194
Epoch 6 Step 2201 Train Loss: 0.5985
Epoch 6 Step 2251 Train Loss: 0.5531
Epoch 6 Step 2301 Train Loss: 0.5459
Epoch 6 Step 2351 Train Loss: 0.6087
Epoch 6 Step 2401 Train Loss: 0.5506
Epoch 6 Step 2451 Train Loss: 0.5642
Epoch 6 Step 2501 Train Loss: 0.5618
Epoch 6 Step 2551 Train Loss: 0.5522
Epoch 6 Step 2601 Train Loss: 0.5773
Epoch 6 Step 2651 Train Loss: 0.5269
Epoch 6 Step 2701 Train Loss: 0.5596
Epoch 6 Step 2751 Train Loss: 0.6440
Epoch 6 Step 2801 Train Loss: 0.5452
Epoch 6 Step 2851 Train Loss: 0.5425
Epoch 6 Step 2901 Train Loss: 0.5961
Epoch 6 Step 2951 Train Loss: 0.5858
Epoch 6 Step 3001 Train Loss: 0.5705
Epoch 6 Step 3051 Train Loss: 0.5161
Epoch 6 Step 3101 Train Loss: 0.5938
Epoch 6 Step 3151 Train Loss: 0.5451
Epoch 6 Step 3201 Train Loss: 0.5987
Epoch 6 Step 3251 Train Loss: 0.6601
Epoch 6 Step 3301 Train Loss: 0.5407
Epoch 6: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0088. 
Train Top 20 DE MSE: 0.1556 Validation Top 20 DE MSE: 0.1792. 
Epoch 7 Step 1 Train Loss: 0.5189
Epoch 7 Step 51 Train Loss: 0.5811
Epoch 7 Step 101 Train Loss: 0.6086
Epoch 7 Step 151 Train Loss: 0.6101
Epoch 7 Step 201 Train Loss: 0.5436
Epoch 7 Step 251 Train Loss: 0.6329
Epoch 7 Step 301 Train Loss: 0.5270
Epoch 7 Step 351 Train Loss: 0.6058
Epoch 7 Step 401 Train Loss: 0.5397
Epoch 7 Step 451 Train Loss: 0.5923
Epoch 7 Step 501 Train Loss: 0.5685
Epoch 7 Step 551 Train Loss: 0.5165
Epoch 7 Step 601 Train Loss: 0.6206
Epoch 7 Step 651 Train Loss: 0.5656
Epoch 7 Step 701 Train Loss: 0.5528
Epoch 7 Step 751 Train Loss: 0.5178
Epoch 7 Step 801 Train Loss: 0.5242
Epoch 7 Step 851 Train Loss: 0.5899
Epoch 7 Step 901 Train Loss: 0.6128
Epoch 7 Step 951 Train Loss: 0.6138
Epoch 7 Step 1001 Train Loss: 0.5901
Epoch 7 Step 1051 Train Loss: 0.5836
Epoch 7 Step 1101 Train Loss: 0.6092
Epoch 7 Step 1151 Train Loss: 0.5738
Epoch 7 Step 1201 Train Loss: 0.5931
Epoch 7 Step 1251 Train Loss: 0.6053
Epoch 7 Step 1301 Train Loss: 0.5461
Epoch 7 Step 1351 Train Loss: 0.6250
Epoch 7 Step 1401 Train Loss: 0.5615
Epoch 7 Step 1451 Train Loss: 0.5299
Epoch 7 Step 1501 Train Loss: 0.5058
Epoch 7 Step 1551 Train Loss: 0.5674
Epoch 7 Step 1601 Train Loss: 0.6183
Epoch 7 Step 1651 Train Loss: 0.5353
Epoch 7 Step 1701 Train Loss: 0.5560
Epoch 7 Step 1751 Train Loss: 0.6234
Epoch 7 Step 1801 Train Loss: 0.6687
Epoch 7 Step 1851 Train Loss: 0.5595
Epoch 7 Step 1901 Train Loss: 0.5287
Epoch 7 Step 1951 Train Loss: 0.6022
Epoch 7 Step 2001 Train Loss: 0.6008
Epoch 7 Step 2051 Train Loss: 0.6129
Epoch 7 Step 2101 Train Loss: 0.5228
Epoch 7 Step 2151 Train Loss: 0.5683
Epoch 7 Step 2201 Train Loss: 0.5850
Epoch 7 Step 2251 Train Loss: 0.6063
Epoch 7 Step 2301 Train Loss: 0.5381
Epoch 7 Step 2351 Train Loss: 0.6192
Epoch 7 Step 2401 Train Loss: 0.5703
Epoch 7 Step 2451 Train Loss: 0.5515
Epoch 7 Step 2501 Train Loss: 0.5809
Epoch 7 Step 2551 Train Loss: 0.5502
Epoch 7 Step 2601 Train Loss: 0.5741
Epoch 7 Step 2651 Train Loss: 0.5684
Epoch 7 Step 2701 Train Loss: 0.5081
Epoch 7 Step 2751 Train Loss: 0.5430
Epoch 7 Step 2801 Train Loss: 0.5623
Epoch 7 Step 2851 Train Loss: 0.5817
Epoch 7 Step 2901 Train Loss: 0.5730
Epoch 7 Step 2951 Train Loss: 0.6096
Epoch 7 Step 3001 Train Loss: 0.5756
Epoch 7 Step 3051 Train Loss: 0.5269
Epoch 7 Step 3101 Train Loss: 0.5936
Epoch 7 Step 3151 Train Loss: 0.5571
Epoch 7 Step 3201 Train Loss: 0.5523
Epoch 7 Step 3251 Train Loss: 0.5578
Epoch 7 Step 3301 Train Loss: 0.6055
Epoch 7: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.1616 Validation Top 20 DE MSE: 0.1817. 
Epoch 8 Step 1 Train Loss: 0.6732
Epoch 8 Step 51 Train Loss: 0.6440
Epoch 8 Step 101 Train Loss: 0.5667
Epoch 8 Step 151 Train Loss: 0.5708
Epoch 8 Step 201 Train Loss: 0.5527
Epoch 8 Step 251 Train Loss: 0.5626
Epoch 8 Step 301 Train Loss: 0.5489
Epoch 8 Step 351 Train Loss: 0.5485
Epoch 8 Step 401 Train Loss: 0.6008
Epoch 8 Step 451 Train Loss: 0.5850
Epoch 8 Step 501 Train Loss: 0.5668
Epoch 8 Step 551 Train Loss: 0.5317
Epoch 8 Step 601 Train Loss: 0.5834
Epoch 8 Step 651 Train Loss: 0.5574
Epoch 8 Step 701 Train Loss: 0.5222
Epoch 8 Step 751 Train Loss: 0.5838
Epoch 8 Step 801 Train Loss: 0.5507
Epoch 8 Step 851 Train Loss: 0.6568
Epoch 8 Step 901 Train Loss: 0.6360
Epoch 8 Step 951 Train Loss: 0.5689
Epoch 8 Step 1001 Train Loss: 0.5831
Epoch 8 Step 1051 Train Loss: 0.5864
Epoch 8 Step 1101 Train Loss: 0.6297
Epoch 8 Step 1151 Train Loss: 0.5534
Epoch 8 Step 1201 Train Loss: 0.6146
Epoch 8 Step 1251 Train Loss: 0.5487
Epoch 8 Step 1301 Train Loss: 0.5692
Epoch 8 Step 1351 Train Loss: 0.5767
Epoch 8 Step 1401 Train Loss: 0.5591
Epoch 8 Step 1451 Train Loss: 0.5808
Epoch 8 Step 1501 Train Loss: 0.5625
Epoch 8 Step 1551 Train Loss: 0.5703
Epoch 8 Step 1601 Train Loss: 0.5636
Epoch 8 Step 1651 Train Loss: 0.5848
Epoch 8 Step 1701 Train Loss: 0.6036
Epoch 8 Step 1751 Train Loss: 0.5746
Epoch 8 Step 1801 Train Loss: 0.5387
Epoch 8 Step 1851 Train Loss: 0.5545
Epoch 8 Step 1901 Train Loss: 0.5448
Epoch 8 Step 1951 Train Loss: 0.5726
Epoch 8 Step 2001 Train Loss: 0.6268
Epoch 8 Step 2051 Train Loss: 0.5536
Epoch 8 Step 2101 Train Loss: 0.6023
Epoch 8 Step 2151 Train Loss: 0.5555
Epoch 8 Step 2201 Train Loss: 0.5995
Epoch 8 Step 2251 Train Loss: 0.5903
Epoch 8 Step 2301 Train Loss: 0.5609
Epoch 8 Step 2351 Train Loss: 0.6422
Epoch 8 Step 2401 Train Loss: 0.5002
Epoch 8 Step 2451 Train Loss: 0.5669
Epoch 8 Step 2501 Train Loss: 0.6105
Epoch 8 Step 2551 Train Loss: 0.6046
Epoch 8 Step 2601 Train Loss: 0.6197
Epoch 8 Step 2651 Train Loss: 0.5377
Epoch 8 Step 2701 Train Loss: 0.6500
Epoch 8 Step 2751 Train Loss: 0.6499
Epoch 8 Step 2801 Train Loss: 0.5255
Epoch 8 Step 2851 Train Loss: 0.5992
Epoch 8 Step 2901 Train Loss: 0.5738
Epoch 8 Step 2951 Train Loss: 0.5943
Epoch 8 Step 3001 Train Loss: 0.5786
Epoch 8 Step 3051 Train Loss: 0.5668
Epoch 8 Step 3101 Train Loss: 0.6689
Epoch 8 Step 3151 Train Loss: 0.5626
Epoch 8 Step 3201 Train Loss: 0.6141
Epoch 8 Step 3251 Train Loss: 0.5780
Epoch 8 Step 3301 Train Loss: 0.5742
Epoch 8: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.1612 Validation Top 20 DE MSE: 0.1822. 
Epoch 9 Step 1 Train Loss: 0.5228
Epoch 9 Step 51 Train Loss: 0.5713
Epoch 9 Step 101 Train Loss: 0.5786
Epoch 9 Step 151 Train Loss: 0.5823
Epoch 9 Step 201 Train Loss: 0.5414
Epoch 9 Step 251 Train Loss: 0.5875
Epoch 9 Step 301 Train Loss: 0.5950
Epoch 9 Step 351 Train Loss: 0.5529
Epoch 9 Step 401 Train Loss: 0.6716
Epoch 9 Step 451 Train Loss: 0.5527
Epoch 9 Step 501 Train Loss: 0.5672
Epoch 9 Step 551 Train Loss: 0.5955
Epoch 9 Step 601 Train Loss: 0.5931
Epoch 9 Step 651 Train Loss: 0.6383
Epoch 9 Step 701 Train Loss: 0.6076
Epoch 9 Step 751 Train Loss: 0.5607
Epoch 9 Step 801 Train Loss: 0.5469
Epoch 9 Step 851 Train Loss: 0.5771
Epoch 9 Step 901 Train Loss: 0.5943
Epoch 9 Step 951 Train Loss: 0.5362
Epoch 9 Step 1001 Train Loss: 0.5282
Epoch 9 Step 1051 Train Loss: 0.5374
Epoch 9 Step 1101 Train Loss: 0.5676
Epoch 9 Step 1151 Train Loss: 0.6152
Epoch 9 Step 1201 Train Loss: 0.5348
Epoch 9 Step 1251 Train Loss: 0.6373
Epoch 9 Step 1301 Train Loss: 0.5751
Epoch 9 Step 1351 Train Loss: 0.5745
Epoch 9 Step 1401 Train Loss: 0.5268
Epoch 9 Step 1451 Train Loss: 0.5801
Epoch 9 Step 1501 Train Loss: 0.6092
Epoch 9 Step 1551 Train Loss: 0.5929
Epoch 9 Step 1601 Train Loss: 0.6251
Epoch 9 Step 1651 Train Loss: 0.5829
Epoch 9 Step 1701 Train Loss: 0.5548
Epoch 9 Step 1751 Train Loss: 0.6029
Epoch 9 Step 1801 Train Loss: 0.5681
Epoch 9 Step 1851 Train Loss: 0.5704
Epoch 9 Step 1901 Train Loss: 0.6662
Epoch 9 Step 1951 Train Loss: 0.5989
Epoch 9 Step 2001 Train Loss: 0.5855
Epoch 9 Step 2051 Train Loss: 0.6297
Epoch 9 Step 2101 Train Loss: 0.5300
Epoch 9 Step 2151 Train Loss: 0.5809
Epoch 9 Step 2201 Train Loss: 0.6093
Epoch 9 Step 2251 Train Loss: 0.5565
Epoch 9 Step 2301 Train Loss: 0.5610
Epoch 9 Step 2351 Train Loss: 0.5851
Epoch 9 Step 2401 Train Loss: 0.5398
Epoch 9 Step 2451 Train Loss: 0.5362
Epoch 9 Step 2501 Train Loss: 0.6157
Epoch 9 Step 2551 Train Loss: 0.5109
Epoch 9 Step 2601 Train Loss: 0.5550
Epoch 9 Step 2651 Train Loss: 0.5941
Epoch 9 Step 2701 Train Loss: 0.6026
Epoch 9 Step 2751 Train Loss: 0.5848
Epoch 9 Step 2801 Train Loss: 0.5901
Epoch 9 Step 2851 Train Loss: 0.5824
Epoch 9 Step 2901 Train Loss: 0.5908
Epoch 9 Step 2951 Train Loss: 0.5556
Epoch 9 Step 3001 Train Loss: 0.6273
Epoch 9 Step 3051 Train Loss: 0.5850
Epoch 9 Step 3101 Train Loss: 0.5926
Epoch 9 Step 3151 Train Loss: 0.5884
Epoch 9 Step 3201 Train Loss: 0.6058
Epoch 9 Step 3251 Train Loss: 0.5860
Epoch 9 Step 3301 Train Loss: 0.5363
Epoch 9: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.1612 Validation Top 20 DE MSE: 0.1818. 
Epoch 10 Step 1 Train Loss: 0.5870
Epoch 10 Step 51 Train Loss: 0.5893
Epoch 10 Step 101 Train Loss: 0.6243
Epoch 10 Step 151 Train Loss: 0.6288
Epoch 10 Step 201 Train Loss: 0.7184
Epoch 10 Step 251 Train Loss: 0.5584
Epoch 10 Step 301 Train Loss: 0.6042
Epoch 10 Step 351 Train Loss: 0.5370
Epoch 10 Step 401 Train Loss: 0.5588
Epoch 10 Step 451 Train Loss: 0.5732
Epoch 10 Step 501 Train Loss: 0.6172
Epoch 10 Step 551 Train Loss: 0.5708
Epoch 10 Step 601 Train Loss: 0.5718
Epoch 10 Step 651 Train Loss: 0.6016
Epoch 10 Step 701 Train Loss: 0.5458
Epoch 10 Step 751 Train Loss: 0.6384
Epoch 10 Step 801 Train Loss: 0.6052
Epoch 10 Step 851 Train Loss: 0.5586
Epoch 10 Step 901 Train Loss: 0.5569
Epoch 10 Step 951 Train Loss: 0.5984
Epoch 10 Step 1001 Train Loss: 0.5915
Epoch 10 Step 1051 Train Loss: 0.5630
Epoch 10 Step 1101 Train Loss: 0.6078
Epoch 10 Step 1151 Train Loss: 0.6197
Epoch 10 Step 1201 Train Loss: 0.5233
Epoch 10 Step 1251 Train Loss: 0.5860
Epoch 10 Step 1301 Train Loss: 0.5660
Epoch 10 Step 1351 Train Loss: 0.5596
Epoch 10 Step 1401 Train Loss: 0.5634
Epoch 10 Step 1451 Train Loss: 0.5904
Epoch 10 Step 1501 Train Loss: 0.5957
Epoch 10 Step 1551 Train Loss: 0.5783
Epoch 10 Step 1601 Train Loss: 0.5401
Epoch 10 Step 1651 Train Loss: 0.5932
Epoch 10 Step 1701 Train Loss: 0.5831
Epoch 10 Step 1751 Train Loss: 0.6727
Epoch 10 Step 1801 Train Loss: 0.5694
Epoch 10 Step 1851 Train Loss: 0.5569
Epoch 10 Step 1901 Train Loss: 0.5692
Epoch 10 Step 1951 Train Loss: 0.5075
Epoch 10 Step 2001 Train Loss: 0.5389
Epoch 10 Step 2051 Train Loss: 0.5781
Epoch 10 Step 2101 Train Loss: 0.5679
Epoch 10 Step 2151 Train Loss: 0.5906
Epoch 10 Step 2201 Train Loss: 0.6311
Epoch 10 Step 2251 Train Loss: 0.5684
Epoch 10 Step 2301 Train Loss: 0.5485
Epoch 10 Step 2351 Train Loss: 0.5698
Epoch 10 Step 2401 Train Loss: 0.5774
Epoch 10 Step 2451 Train Loss: 0.5725
Epoch 10 Step 2501 Train Loss: 0.5750
Epoch 10 Step 2551 Train Loss: 0.5328
Epoch 10 Step 2601 Train Loss: 0.5271
Epoch 10 Step 2651 Train Loss: 0.6016
Epoch 10 Step 2701 Train Loss: 0.6186
Epoch 10 Step 2751 Train Loss: 0.5475
Epoch 10 Step 2801 Train Loss: 0.6397
Epoch 10 Step 2851 Train Loss: 0.5365
Epoch 10 Step 2901 Train Loss: 0.5504
Epoch 10 Step 2951 Train Loss: 0.5546
Epoch 10 Step 3001 Train Loss: 0.6100
Epoch 10 Step 3051 Train Loss: 0.5669
Epoch 10 Step 3101 Train Loss: 0.5886
Epoch 10 Step 3151 Train Loss: 0.6396
Epoch 10 Step 3201 Train Loss: 0.5443
Epoch 10 Step 3251 Train Loss: 0.6179
Epoch 10 Step 3301 Train Loss: 0.5317
Epoch 10: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.1615 Validation Top 20 DE MSE: 0.1818. 
Epoch 11 Step 1 Train Loss: 0.6235
Epoch 11 Step 51 Train Loss: 0.5687
Epoch 11 Step 101 Train Loss: 0.5601
Epoch 11 Step 151 Train Loss: 0.6671
Epoch 11 Step 201 Train Loss: 0.5440
Epoch 11 Step 251 Train Loss: 0.5607
Epoch 11 Step 301 Train Loss: 0.5791
Epoch 11 Step 351 Train Loss: 0.5834
Epoch 11 Step 401 Train Loss: 0.5658
Epoch 11 Step 451 Train Loss: 0.5246
Epoch 11 Step 501 Train Loss: 0.5965
Epoch 11 Step 551 Train Loss: 0.5988
Epoch 11 Step 601 Train Loss: 0.5798
Epoch 11 Step 651 Train Loss: 0.5972
Epoch 11 Step 701 Train Loss: 0.5993
Epoch 11 Step 751 Train Loss: 0.6037
Epoch 11 Step 801 Train Loss: 0.5649
Epoch 11 Step 851 Train Loss: 0.5834
Epoch 11 Step 901 Train Loss: 0.5848
Epoch 11 Step 951 Train Loss: 0.5953
Epoch 11 Step 1001 Train Loss: 0.4979
Epoch 11 Step 1051 Train Loss: 0.5767
Epoch 11 Step 1101 Train Loss: 0.5676
Epoch 11 Step 1151 Train Loss: 0.6778
Epoch 11 Step 1201 Train Loss: 0.5818
Epoch 11 Step 1251 Train Loss: 0.5843
Epoch 11 Step 1301 Train Loss: 0.5816
Epoch 11 Step 1351 Train Loss: 0.6155
Epoch 11 Step 1401 Train Loss: 0.5964
Epoch 11 Step 1451 Train Loss: 0.5662
Epoch 11 Step 1501 Train Loss: 0.6196
Epoch 11 Step 1551 Train Loss: 0.6147
Epoch 11 Step 1601 Train Loss: 0.5625
Epoch 11 Step 1651 Train Loss: 0.5446
Epoch 11 Step 1701 Train Loss: 0.5114
Epoch 11 Step 1751 Train Loss: 0.5343
Epoch 11 Step 1801 Train Loss: 0.5782
Epoch 11 Step 1851 Train Loss: 0.5719
Epoch 11 Step 1901 Train Loss: 0.6232
Epoch 11 Step 1951 Train Loss: 0.5788
Epoch 11 Step 2001 Train Loss: 0.5684
Epoch 11 Step 2051 Train Loss: 0.5894
Epoch 11 Step 2101 Train Loss: 0.5992
Epoch 11 Step 2151 Train Loss: 0.5862
Epoch 11 Step 2201 Train Loss: 0.5677
Epoch 11 Step 2251 Train Loss: 0.5624
Epoch 11 Step 2301 Train Loss: 0.5807
Epoch 11 Step 2351 Train Loss: 0.5849
Epoch 11 Step 2401 Train Loss: 0.5821
Epoch 11 Step 2451 Train Loss: 0.6215
Epoch 11 Step 2501 Train Loss: 0.5919
Epoch 11 Step 2551 Train Loss: 0.5983
Epoch 11 Step 2601 Train Loss: 0.5377
Epoch 11 Step 2651 Train Loss: 0.5538
Epoch 11 Step 2701 Train Loss: 0.5193
Epoch 11 Step 2751 Train Loss: 0.6169
Epoch 11 Step 2801 Train Loss: 0.6400
Epoch 11 Step 2851 Train Loss: 0.5886
Epoch 11 Step 2901 Train Loss: 0.5392
Epoch 11 Step 2951 Train Loss: 0.6065
Epoch 11 Step 3001 Train Loss: 0.5370
Epoch 11 Step 3051 Train Loss: 0.5721
Epoch 11 Step 3101 Train Loss: 0.5560
Epoch 11 Step 3151 Train Loss: 0.5680
Epoch 11 Step 3201 Train Loss: 0.6097
Epoch 11 Step 3251 Train Loss: 0.5113
Epoch 11 Step 3301 Train Loss: 0.5849
Epoch 11: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.1579 Validation Top 20 DE MSE: 0.1808. 
Epoch 12 Step 1 Train Loss: 0.5592
Epoch 12 Step 51 Train Loss: 0.5676
Epoch 12 Step 101 Train Loss: 0.5816
Epoch 12 Step 151 Train Loss: 0.5950
Epoch 12 Step 201 Train Loss: 0.5730
Epoch 12 Step 251 Train Loss: 0.6138
Epoch 12 Step 301 Train Loss: 0.5975
Epoch 12 Step 351 Train Loss: 0.5478
Epoch 12 Step 401 Train Loss: 0.5731
Epoch 12 Step 451 Train Loss: 0.5505
Epoch 12 Step 501 Train Loss: 0.6457
Epoch 12 Step 551 Train Loss: 0.5853
Epoch 12 Step 601 Train Loss: 0.5335
Epoch 12 Step 651 Train Loss: 0.5683
Epoch 12 Step 701 Train Loss: 0.5347
Epoch 12 Step 751 Train Loss: 0.5671
Epoch 12 Step 801 Train Loss: 0.5705
Epoch 12 Step 851 Train Loss: 0.5824
Epoch 12 Step 901 Train Loss: 0.5810
Epoch 12 Step 951 Train Loss: 0.6204
Epoch 12 Step 1001 Train Loss: 0.5608
Epoch 12 Step 1051 Train Loss: 0.5692
Epoch 12 Step 1101 Train Loss: 0.5705
Epoch 12 Step 1151 Train Loss: 0.6194
Epoch 12 Step 1201 Train Loss: 0.5838
Epoch 12 Step 1251 Train Loss: 0.5574
Epoch 12 Step 1301 Train Loss: 0.5393
Epoch 12 Step 1351 Train Loss: 0.5823
Epoch 12 Step 1401 Train Loss: 0.6183
Epoch 12 Step 1451 Train Loss: 0.5658
Epoch 12 Step 1501 Train Loss: 0.5846
Epoch 12 Step 1551 Train Loss: 0.5486
Epoch 12 Step 1601 Train Loss: 0.4914
Epoch 12 Step 1651 Train Loss: 0.5679
Epoch 12 Step 1701 Train Loss: 0.5830
Epoch 12 Step 1751 Train Loss: 0.5400
Epoch 12 Step 1801 Train Loss: 0.5318
Epoch 12 Step 1851 Train Loss: 0.5765
Epoch 12 Step 1901 Train Loss: 0.5981
Epoch 12 Step 1951 Train Loss: 0.6354
Epoch 12 Step 2001 Train Loss: 0.5627
Epoch 12 Step 2051 Train Loss: 0.6119
Epoch 12 Step 2101 Train Loss: 0.5844
Epoch 12 Step 2151 Train Loss: 0.5466
Epoch 12 Step 2201 Train Loss: 0.5852
Epoch 12 Step 2251 Train Loss: 0.5599
Epoch 12 Step 2301 Train Loss: 0.5931
Epoch 12 Step 2351 Train Loss: 0.5352
Epoch 12 Step 2401 Train Loss: 0.5514
Epoch 12 Step 2451 Train Loss: 0.6338
Epoch 12 Step 2501 Train Loss: 0.6062
Epoch 12 Step 2551 Train Loss: 0.5254
Epoch 12 Step 2601 Train Loss: 0.5604
Epoch 12 Step 2651 Train Loss: 0.6067
Epoch 12 Step 2701 Train Loss: 0.6492
Epoch 12 Step 2751 Train Loss: 0.5937
Epoch 12 Step 2801 Train Loss: 0.5749
Epoch 12 Step 2851 Train Loss: 0.5927
Epoch 12 Step 2901 Train Loss: 0.6040
Epoch 12 Step 2951 Train Loss: 0.5852
Epoch 12 Step 3001 Train Loss: 0.6017
Epoch 12 Step 3051 Train Loss: 0.5576
Epoch 12 Step 3101 Train Loss: 0.5912
Epoch 12 Step 3151 Train Loss: 0.5335
Epoch 12 Step 3201 Train Loss: 0.5396
Epoch 12 Step 3251 Train Loss: 0.5979
Epoch 12 Step 3301 Train Loss: 0.5741
Epoch 12: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.1604 Validation Top 20 DE MSE: 0.1822. 
Epoch 13 Step 1 Train Loss: 0.5605
Epoch 13 Step 51 Train Loss: 0.6021
Epoch 13 Step 101 Train Loss: 0.5866
Epoch 13 Step 151 Train Loss: 0.5969
Epoch 13 Step 201 Train Loss: 0.6257
Epoch 13 Step 251 Train Loss: 0.6313
Epoch 13 Step 301 Train Loss: 0.5845
Epoch 13 Step 351 Train Loss: 0.5491
Epoch 13 Step 401 Train Loss: 0.6121
Epoch 13 Step 451 Train Loss: 0.6340
Epoch 13 Step 501 Train Loss: 0.5814
Epoch 13 Step 551 Train Loss: 0.5417
Epoch 13 Step 601 Train Loss: 0.5860
Epoch 13 Step 651 Train Loss: 0.5846
Epoch 13 Step 701 Train Loss: 0.5289
Epoch 13 Step 751 Train Loss: 0.6084
Epoch 13 Step 801 Train Loss: 0.5803
Epoch 13 Step 851 Train Loss: 0.5654
Epoch 13 Step 901 Train Loss: 0.5497
Epoch 13 Step 951 Train Loss: 0.5728
Epoch 13 Step 1001 Train Loss: 0.5479
Epoch 13 Step 1051 Train Loss: 0.5552
Epoch 13 Step 1101 Train Loss: 0.5736
Epoch 13 Step 1151 Train Loss: 0.5676
Epoch 13 Step 1201 Train Loss: 0.5073
Epoch 13 Step 1251 Train Loss: 0.6058
Epoch 13 Step 1301 Train Loss: 0.5586
Epoch 13 Step 1351 Train Loss: 0.5747
Epoch 13 Step 1401 Train Loss: 0.5756
Epoch 13 Step 1451 Train Loss: 0.6122
Epoch 13 Step 1501 Train Loss: 0.5587
Epoch 13 Step 1551 Train Loss: 0.6005
Epoch 13 Step 1601 Train Loss: 0.5795
Epoch 13 Step 1651 Train Loss: 0.5537
Epoch 13 Step 1701 Train Loss: 0.5354
Epoch 13 Step 1751 Train Loss: 0.5543
Epoch 13 Step 1801 Train Loss: 0.5069
Epoch 13 Step 1851 Train Loss: 0.5668
Epoch 13 Step 1901 Train Loss: 0.6353
Epoch 13 Step 1951 Train Loss: 0.6144
Epoch 13 Step 2001 Train Loss: 0.6051
Epoch 13 Step 2051 Train Loss: 0.5631
Epoch 13 Step 2101 Train Loss: 0.5747
Epoch 13 Step 2151 Train Loss: 0.5503
Epoch 13 Step 2201 Train Loss: 0.5205
Epoch 13 Step 2251 Train Loss: 0.5445
Epoch 13 Step 2301 Train Loss: 0.6121
Epoch 13 Step 2351 Train Loss: 0.5565
Epoch 13 Step 2401 Train Loss: 0.5975
Epoch 13 Step 2451 Train Loss: 0.6022
Epoch 13 Step 2501 Train Loss: 0.5541
Epoch 13 Step 2551 Train Loss: 0.5994
Epoch 13 Step 2601 Train Loss: 0.6189
Epoch 13 Step 2651 Train Loss: 0.5404
Epoch 13 Step 2701 Train Loss: 0.5866
Epoch 13 Step 2751 Train Loss: 0.5812
Epoch 13 Step 2801 Train Loss: 0.6529
Epoch 13 Step 2851 Train Loss: 0.5714
Epoch 13 Step 2901 Train Loss: 0.5673
Epoch 13 Step 2951 Train Loss: 0.5653
Epoch 13 Step 3001 Train Loss: 0.5571
Epoch 13 Step 3051 Train Loss: 0.5726
Epoch 13 Step 3101 Train Loss: 0.5484
Epoch 13 Step 3151 Train Loss: 0.5433
Epoch 13 Step 3201 Train Loss: 0.6237
Epoch 13 Step 3251 Train Loss: 0.5376
Epoch 13 Step 3301 Train Loss: 0.5475
Epoch 13: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0086. 
Train Top 20 DE MSE: 0.1604 Validation Top 20 DE MSE: 0.1828. 
Epoch 14 Step 1 Train Loss: 0.5748
Epoch 14 Step 51 Train Loss: 0.5380
Epoch 14 Step 101 Train Loss: 0.5556
Epoch 14 Step 151 Train Loss: 0.6127
Epoch 14 Step 201 Train Loss: 0.5418
Epoch 14 Step 251 Train Loss: 0.5781
Epoch 14 Step 301 Train Loss: 0.5703
Epoch 14 Step 351 Train Loss: 0.5283
Epoch 14 Step 401 Train Loss: 0.6050
Epoch 14 Step 451 Train Loss: 0.6440
Epoch 14 Step 501 Train Loss: 0.5810
Epoch 14 Step 551 Train Loss: 0.6280
Epoch 14 Step 601 Train Loss: 0.6071
Epoch 14 Step 651 Train Loss: 0.6352
Epoch 14 Step 701 Train Loss: 0.5632
Epoch 14 Step 751 Train Loss: 0.6417
Epoch 14 Step 801 Train Loss: 0.5249
Epoch 14 Step 851 Train Loss: 0.6089
Epoch 14 Step 901 Train Loss: 0.5871
Epoch 14 Step 951 Train Loss: 0.5701
Epoch 14 Step 1001 Train Loss: 0.5591
Epoch 14 Step 1051 Train Loss: 0.5872
Epoch 14 Step 1101 Train Loss: 0.6089
Epoch 14 Step 1151 Train Loss: 0.5646
Epoch 14 Step 1201 Train Loss: 0.5914
Epoch 14 Step 1251 Train Loss: 0.5589
Epoch 14 Step 1301 Train Loss: 0.5971
Epoch 14 Step 1351 Train Loss: 0.5235
Epoch 14 Step 1401 Train Loss: 0.5865
Epoch 14 Step 1451 Train Loss: 0.6037
Epoch 14 Step 1501 Train Loss: 0.5849
Epoch 14 Step 1551 Train Loss: 0.6098
Epoch 14 Step 1601 Train Loss: 0.5390
Epoch 14 Step 1651 Train Loss: 0.5749
Epoch 14 Step 1701 Train Loss: 0.5921
Epoch 14 Step 1751 Train Loss: 0.5572
Epoch 14 Step 1801 Train Loss: 0.5478
Epoch 14 Step 1851 Train Loss: 0.5993
Epoch 14 Step 1901 Train Loss: 0.5872
Epoch 14 Step 1951 Train Loss: 0.5984
Epoch 14 Step 2001 Train Loss: 0.5761
Epoch 14 Step 2051 Train Loss: 0.5801
Epoch 14 Step 2101 Train Loss: 0.5778
Epoch 14 Step 2151 Train Loss: 0.6030
Epoch 14 Step 2201 Train Loss: 0.5740
Epoch 14 Step 2251 Train Loss: 0.5666
Epoch 14 Step 2301 Train Loss: 0.5716
Epoch 14 Step 2351 Train Loss: 0.5511
Epoch 14 Step 2401 Train Loss: 0.5000
Epoch 14 Step 2451 Train Loss: 0.6103
Epoch 14 Step 2501 Train Loss: 0.5790
Epoch 14 Step 2551 Train Loss: 0.5767
Epoch 14 Step 2601 Train Loss: 0.5811
Epoch 14 Step 2651 Train Loss: 0.5676
Epoch 14 Step 2701 Train Loss: 0.5635
Epoch 14 Step 2751 Train Loss: 0.5590
Epoch 14 Step 2801 Train Loss: 0.5529
Epoch 14 Step 2851 Train Loss: 0.5763
Epoch 14 Step 2901 Train Loss: 0.6213
Epoch 14 Step 2951 Train Loss: 0.6003
Epoch 14 Step 3001 Train Loss: 0.5210
Epoch 14 Step 3051 Train Loss: 0.5695
Epoch 14 Step 3101 Train Loss: 0.5891
Epoch 14 Step 3151 Train Loss: 0.5148
Epoch 14 Step 3201 Train Loss: 0.6184
Epoch 14 Step 3251 Train Loss: 0.5614
Epoch 14 Step 3301 Train Loss: 0.5556
Epoch 14: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.1604 Validation Top 20 DE MSE: 0.1815. 
Epoch 15 Step 1 Train Loss: 0.5841
Epoch 15 Step 51 Train Loss: 0.5673
Epoch 15 Step 101 Train Loss: 0.5813
Epoch 15 Step 151 Train Loss: 0.5525
Epoch 15 Step 201 Train Loss: 0.6498
Epoch 15 Step 251 Train Loss: 0.5776
Epoch 15 Step 301 Train Loss: 0.6085
Epoch 15 Step 351 Train Loss: 0.6235
Epoch 15 Step 401 Train Loss: 0.5730
Epoch 15 Step 451 Train Loss: 0.5830
Epoch 15 Step 501 Train Loss: 0.5730
Epoch 15 Step 551 Train Loss: 0.5744
Epoch 15 Step 601 Train Loss: 0.5806
Epoch 15 Step 651 Train Loss: 0.5872
Epoch 15 Step 701 Train Loss: 0.6324
Epoch 15 Step 751 Train Loss: 0.5849
Epoch 15 Step 801 Train Loss: 0.6520
Epoch 15 Step 851 Train Loss: 0.5396
Epoch 15 Step 901 Train Loss: 0.5709
Epoch 15 Step 951 Train Loss: 0.5854
Epoch 15 Step 1001 Train Loss: 0.6142
Epoch 15 Step 1051 Train Loss: 0.5788
Epoch 15 Step 1101 Train Loss: 0.5938
Epoch 15 Step 1151 Train Loss: 0.5559
Epoch 15 Step 1201 Train Loss: 0.5483
Epoch 15 Step 1251 Train Loss: 0.6206
Epoch 15 Step 1301 Train Loss: 0.5965
Epoch 15 Step 1351 Train Loss: 0.6194
Epoch 15 Step 1401 Train Loss: 0.5571
Epoch 15 Step 1451 Train Loss: 0.6136
Epoch 15 Step 1501 Train Loss: 0.5533
Epoch 15 Step 1551 Train Loss: 0.5737
Epoch 15 Step 1601 Train Loss: 0.6209
Epoch 15 Step 1651 Train Loss: 0.5658
Epoch 15 Step 1701 Train Loss: 0.5925
Epoch 15 Step 1751 Train Loss: 0.5819
Epoch 15 Step 1801 Train Loss: 0.5386
Epoch 15 Step 1851 Train Loss: 0.6170
Epoch 15 Step 1901 Train Loss: 0.6169
Epoch 15 Step 1951 Train Loss: 0.5872
Epoch 15 Step 2001 Train Loss: 0.4853
Epoch 15 Step 2051 Train Loss: 0.5400
Epoch 15 Step 2101 Train Loss: 0.5816
Epoch 15 Step 2151 Train Loss: 0.6266
Epoch 15 Step 2201 Train Loss: 0.5921
Epoch 15 Step 2251 Train Loss: 0.6192
Epoch 15 Step 2301 Train Loss: 0.5988
Epoch 15 Step 2351 Train Loss: 0.5826
Epoch 15 Step 2401 Train Loss: 0.5533
Epoch 15 Step 2451 Train Loss: 0.5786
Epoch 15 Step 2501 Train Loss: 0.5336
Epoch 15 Step 2551 Train Loss: 0.5878
Epoch 15 Step 2601 Train Loss: 0.5675
Epoch 15 Step 2651 Train Loss: 0.5638
Epoch 15 Step 2701 Train Loss: 0.5970
Epoch 15 Step 2751 Train Loss: 0.5396
Epoch 15 Step 2801 Train Loss: 0.5756
Epoch 15 Step 2851 Train Loss: 0.5550
Epoch 15 Step 2901 Train Loss: 0.5693
Epoch 15 Step 2951 Train Loss: 0.5893
Epoch 15 Step 3001 Train Loss: 0.5889
Epoch 15 Step 3051 Train Loss: 0.5506
Epoch 15 Step 3101 Train Loss: 0.5688
Epoch 15 Step 3151 Train Loss: 0.5759
Epoch 15 Step 3201 Train Loss: 0.6299
Epoch 15 Step 3251 Train Loss: 0.5662
Epoch 15 Step 3301 Train Loss: 0.5773
Epoch 15: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0087. 
Train Top 20 DE MSE: 0.1579 Validation Top 20 DE MSE: 0.1802. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1717
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.009370077
test_unseen_single_pearson: 0.9871134509363728
test_unseen_single_mse_de: 0.17170984
test_unseen_single_pearson_de: 0.9008542779013959
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3329787151160038
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3226591760299626
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6947565543071161
test_unseen_single_mse_top20_de_non_dropout: 0.18254907
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.054 MB uploadedwandb: | 0.003 MB of 0.054 MB uploadedwandb: / 0.050 MB of 0.054 MB uploadedwandb: - 0.050 MB of 0.054 MB uploadedwandb: \ 0.050 MB of 0.054 MB uploadedwandb: | 0.050 MB of 0.054 MB uploadedwandb: / 0.054 MB of 0.054 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñà‚ñá‚ñà‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñá
wandb:                                                   val_de_mse ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:                                               val_de_pearson ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.17171
wandb:                                              test_de_pearson 0.90085
wandb:               test_frac_opposite_direction_top20_non_dropout 0.32266
wandb:                          test_frac_sigma_below_1_non_dropout 0.69476
wandb:                                                     test_mse 0.00937
wandb:                                test_mse_top20_de_non_dropout 0.18255
wandb:                                                 test_pearson 0.98711
wandb:                                           test_pearson_delta 0.33298
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.32266
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.69476
wandb:                                       test_unseen_single_mse 0.00937
wandb:                                    test_unseen_single_mse_de 0.17171
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.18255
wandb:                                   test_unseen_single_pearson 0.98711
wandb:                                test_unseen_single_pearson_de 0.90085
wandb:                             test_unseen_single_pearson_delta 0.33298
wandb:                                                 train_de_mse 0.15787
wandb:                                             train_de_pearson 0.91198
wandb:                                                    train_mse 0.00763
wandb:                                                train_pearson 0.98937
wandb:                                                training_loss 0.54873
wandb:                                                   val_de_mse 0.18025
wandb:                                               val_de_pearson 0.91739
wandb:                                                      val_mse 0.00873
wandb:                                                  val_pearson 0.98796
wandb: 
wandb: üöÄ View run geneformer_Replogle_k562_essential_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/5ru286q1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_121906-5ru286q1/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:359
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_150135-09cmhkbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_rpe1_essential_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/09cmhkbp
wandb: WARNING Serializing object of type ndarray that is 23564416 bytes
  0%|                                                  | 0/5529 [00:00<?, ?it/s]  0%|                                        | 1/5529 [00:01<1:50:29,  1.20s/it]  0%|                                          | 2/5529 [00:01<56:20,  1.63it/s]  0%|                                        | 3/5529 [00:02<1:03:43,  1.45it/s]  0%|                                         | 10/5529 [00:02<12:40,  7.26it/s]  0%|                                         | 13/5529 [00:02<09:54,  9.27it/s]  1%|‚ñé                                        | 46/5529 [00:02<01:53, 48.44it/s]  1%|‚ñç                                        | 56/5529 [00:02<02:04, 43.98it/s]  1%|‚ñç                                        | 64/5529 [00:03<02:08, 42.39it/s]  1%|‚ñå                                        | 71/5529 [00:03<02:11, 41.61it/s]  1%|‚ñå                                        | 77/5529 [00:03<02:05, 43.45it/s]  2%|‚ñå                                        | 83/5529 [00:03<02:06, 43.17it/s]  2%|‚ñã                                        | 89/5529 [00:03<02:19, 38.99it/s]  2%|‚ñã                                        | 94/5529 [00:03<02:28, 36.59it/s]  2%|‚ñã                                        | 99/5529 [00:04<02:37, 34.42it/s]  2%|‚ñã                                       | 103/5529 [00:04<02:42, 33.42it/s]  2%|‚ñä                                       | 107/5529 [00:04<02:49, 32.04it/s]  2%|‚ñä                                       | 112/5529 [00:04<02:37, 34.38it/s]  2%|‚ñä                                       | 117/5529 [00:04<02:28, 36.46it/s]  2%|‚ñâ                                       | 123/5529 [00:04<02:15, 40.02it/s]  2%|‚ñâ                                       | 128/5529 [00:04<02:47, 32.29it/s]  2%|‚ñâ                                       | 137/5529 [00:05<02:12, 40.84it/s]  3%|‚ñà                                       | 142/5529 [00:05<02:32, 35.24it/s]  3%|‚ñà                                       | 146/5529 [00:05<02:29, 36.08it/s]  3%|‚ñà                                       | 154/5529 [00:05<02:01, 44.21it/s]  3%|‚ñà‚ñè                                      | 160/5529 [00:05<01:57, 45.86it/s]  3%|‚ñà‚ñè                                      | 165/5529 [00:05<02:06, 42.51it/s]  3%|‚ñà‚ñè                                      | 170/5529 [00:05<02:06, 42.50it/s]  3%|‚ñà‚ñé                                      | 175/5529 [00:05<02:05, 42.56it/s]  3%|‚ñà‚ñé                                      | 180/5529 [00:06<02:08, 41.67it/s]  3%|‚ñà‚ñé                                      | 185/5529 [00:06<02:08, 41.68it/s]  3%|‚ñà‚ñé                                      | 190/5529 [00:06<02:14, 39.68it/s]  4%|‚ñà‚ñç                                      | 195/5529 [00:06<02:13, 39.98it/s]  4%|‚ñà‚ñç                                      | 201/5529 [00:06<02:03, 43.26it/s]  4%|‚ñà‚ñç                                      | 206/5529 [00:06<02:02, 43.30it/s]  4%|‚ñà‚ñå                                      | 211/5529 [00:06<02:03, 42.94it/s]  4%|‚ñà‚ñå                                      | 216/5529 [00:06<02:11, 40.33it/s]  4%|‚ñà‚ñå                                      | 222/5529 [00:07<02:03, 43.04it/s]  4%|‚ñà‚ñã                                      | 227/5529 [00:07<02:04, 42.65it/s]  4%|‚ñà‚ñã                                      | 232/5529 [00:07<02:05, 42.37it/s]  4%|‚ñà‚ñã                                      | 237/5529 [00:07<02:12, 39.79it/s]  4%|‚ñà‚ñä                                      | 243/5529 [00:07<02:05, 41.96it/s]  4%|‚ñà‚ñä                                      | 248/5529 [00:07<02:05, 42.08it/s]  5%|‚ñà‚ñä                                      | 253/5529 [00:07<02:05, 41.98it/s]  5%|‚ñà‚ñä                                      | 258/5529 [00:07<02:12, 39.66it/s]  5%|‚ñà‚ñâ                                      | 263/5529 [00:08<02:10, 40.34it/s]  5%|‚ñà‚ñâ                                      | 269/5529 [00:08<02:02, 42.89it/s]  5%|‚ñà‚ñâ                                      | 274/5529 [00:08<02:02, 42.73it/s]  5%|‚ñà‚ñà                                      | 279/5529 [00:08<02:10, 40.21it/s]  5%|‚ñà‚ñà                                      | 284/5529 [00:08<02:08, 40.96it/s]  5%|‚ñà‚ñà                                      | 289/5529 [00:08<02:06, 41.27it/s]  5%|‚ñà‚ñà‚ñè                                     | 295/5529 [00:08<01:58, 43.98it/s]  5%|‚ñà‚ñà‚ñè                                     | 300/5529 [00:08<02:00, 43.37it/s]  6%|‚ñà‚ñà‚ñè                                     | 305/5529 [00:09<02:00, 43.25it/s]  6%|‚ñà‚ñà‚ñè                                     | 310/5529 [00:09<02:01, 42.79it/s]  6%|‚ñà‚ñà‚ñé                                     | 315/5529 [00:09<02:01, 42.82it/s]  6%|‚ñà‚ñà‚ñé                                     | 320/5529 [00:09<02:02, 42.63it/s]  6%|‚ñà‚ñà‚ñé                                     | 325/5529 [00:09<02:01, 42.75it/s]  6%|‚ñà‚ñà‚ñç                                     | 330/5529 [00:09<02:01, 42.74it/s]  6%|‚ñà‚ñà‚ñç                                     | 335/5529 [00:09<02:01, 42.81it/s]  6%|‚ñà‚ñà‚ñç                                     | 340/5529 [00:09<02:08, 40.49it/s]  6%|‚ñà‚ñà‚ñç                                     | 345/5529 [00:10<02:06, 41.06it/s]  6%|‚ñà‚ñà‚ñå                                     | 350/5529 [00:10<02:05, 41.26it/s]  6%|‚ñà‚ñà‚ñå                                     | 355/5529 [00:10<02:04, 41.57it/s]  7%|‚ñà‚ñà‚ñå                                     | 361/5529 [00:10<02:04, 41.40it/s]  7%|‚ñà‚ñà‚ñã                                     | 367/5529 [00:10<01:58, 43.73it/s]  7%|‚ñà‚ñà‚ñã                                     | 372/5529 [00:10<01:59, 43.02it/s]  7%|‚ñà‚ñà‚ñã                                     | 377/5529 [00:10<02:25, 35.49it/s]  7%|‚ñà‚ñà‚ñä                                     | 384/5529 [00:10<02:04, 41.26it/s]  7%|‚ñà‚ñà‚ñä                                     | 389/5529 [00:11<02:05, 40.96it/s]  7%|‚ñà‚ñà‚ñä                                     | 394/5529 [00:11<02:15, 37.80it/s]  7%|‚ñà‚ñà‚ñâ                                     | 398/5529 [00:11<02:25, 35.16it/s]  7%|‚ñà‚ñà‚ñâ                                     | 402/5529 [00:11<02:31, 33.89it/s]  7%|‚ñà‚ñà‚ñâ                                     | 407/5529 [00:11<02:22, 35.92it/s]  7%|‚ñà‚ñà‚ñâ                                     | 411/5529 [00:11<02:25, 35.22it/s]  8%|‚ñà‚ñà‚ñà                                     | 417/5529 [00:11<02:09, 39.38it/s]  8%|‚ñà‚ñà‚ñà                                     | 421/5529 [00:12<02:15, 37.71it/s]  8%|‚ñà‚ñà‚ñà                                     | 425/5529 [00:12<02:23, 35.51it/s]  8%|‚ñà‚ñà‚ñà                                     | 429/5529 [00:12<03:13, 26.36it/s]  8%|‚ñà‚ñà‚ñà‚ñè                                    | 442/5529 [00:12<01:50, 45.97it/s]  8%|‚ñà‚ñà‚ñà‚ñè                                    | 448/5529 [00:12<02:10, 39.02it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                    | 455/5529 [00:12<01:56, 43.47it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                    | 460/5529 [00:12<01:54, 44.15it/s]  8%|‚ñà‚ñà‚ñà‚ñé                                    | 465/5529 [00:13<01:58, 42.66it/s]  9%|‚ñà‚ñà‚ñà‚ñç                                    | 470/5529 [00:13<02:06, 40.09it/s]  9%|‚ñà‚ñà‚ñà‚ñç                                    | 475/5529 [00:13<02:19, 36.10it/s]  9%|‚ñà‚ñà‚ñà‚ñç                                    | 482/5529 [00:13<02:01, 41.57it/s]  9%|‚ñà‚ñà‚ñà‚ñå                                    | 488/5529 [00:13<01:55, 43.74it/s]  9%|‚ñà‚ñà‚ñà‚ñå                                    | 493/5529 [00:13<01:57, 42.92it/s]  9%|‚ñà‚ñà‚ñà‚ñå                                    | 498/5529 [00:13<02:21, 35.63it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                    | 502/5529 [00:14<02:19, 36.15it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                    | 509/5529 [00:14<01:54, 43.73it/s]  9%|‚ñà‚ñà‚ñà‚ñã                                    | 514/5529 [00:14<02:14, 37.34it/s]  9%|‚ñà‚ñà‚ñà‚ñä                                    | 519/5529 [00:14<02:08, 38.85it/s] 10%|‚ñà‚ñà‚ñà‚ñä                                    | 526/5529 [00:14<02:23, 34.81it/s] 10%|‚ñà‚ñà‚ñà‚ñä                                    | 532/5529 [00:14<02:09, 38.62it/s] 10%|‚ñà‚ñà‚ñà‚ñâ                                    | 539/5529 [00:15<02:11, 37.97it/s] 10%|‚ñà‚ñà‚ñà‚ñâ                                    | 544/5529 [00:15<02:08, 38.78it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                    | 554/5529 [00:15<01:39, 49.95it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                    | 560/5529 [00:15<02:06, 39.35it/s] 10%|‚ñà‚ñà‚ñà‚ñà                                    | 568/5529 [00:15<01:47, 46.00it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 574/5529 [00:15<02:06, 39.26it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 580/5529 [00:15<02:03, 39.98it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 589/5529 [00:16<01:41, 48.86it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 595/5529 [00:16<01:49, 44.88it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 600/5529 [00:16<01:50, 44.78it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 605/5529 [00:16<01:50, 44.56it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 610/5529 [00:16<02:04, 39.47it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 615/5529 [00:16<02:11, 37.30it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 620/5529 [00:16<02:09, 37.99it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 628/5529 [00:17<01:45, 46.67it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 633/5529 [00:17<01:45, 46.33it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 638/5529 [00:17<01:49, 44.84it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 643/5529 [00:17<02:22, 34.25it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 648/5529 [00:17<02:16, 35.85it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 657/5529 [00:17<01:50, 43.93it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 662/5529 [00:17<02:10, 37.39it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 670/5529 [00:18<02:12, 36.60it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 680/5529 [00:18<01:54, 42.29it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 686/5529 [00:18<01:53, 42.82it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 691/5529 [00:18<02:06, 38.13it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 697/5529 [00:18<01:57, 41.29it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 702/5529 [00:19<02:26, 32.88it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 710/5529 [00:19<01:56, 41.26it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 715/5529 [00:19<01:55, 41.83it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 720/5529 [00:19<01:52, 42.89it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 725/5529 [00:19<02:01, 39.67it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 732/5529 [00:19<01:45, 45.57it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 738/5529 [00:19<01:40, 47.78it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 744/5529 [00:19<01:46, 44.74it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 749/5529 [00:20<02:13, 35.84it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 759/5529 [00:20<01:37, 49.10it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 765/5529 [00:20<01:39, 47.79it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 771/5529 [00:20<01:59, 39.79it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 778/5529 [00:20<01:57, 40.35it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 788/5529 [00:20<01:31, 51.72it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 794/5529 [00:21<01:34, 50.03it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 800/5529 [00:21<01:36, 49.02it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 806/5529 [00:21<01:36, 49.14it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 812/5529 [00:21<01:41, 46.62it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 818/5529 [00:21<01:36, 48.75it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 824/5529 [00:21<01:42, 45.75it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 830/5529 [00:21<01:38, 47.88it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 835/5529 [00:21<01:38, 47.83it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 840/5529 [00:22<01:45, 44.59it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 846/5529 [00:22<01:43, 45.25it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 852/5529 [00:22<01:53, 41.16it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 857/5529 [00:22<02:00, 38.81it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 867/5529 [00:22<01:30, 51.28it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 873/5529 [00:22<01:38, 47.23it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 878/5529 [00:22<01:38, 47.41it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 883/5529 [00:23<01:57, 39.45it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 893/5529 [00:23<01:28, 52.13it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 899/5529 [00:23<01:35, 48.49it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 905/5529 [00:23<01:35, 48.35it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 911/5529 [00:23<01:36, 48.03it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 917/5529 [00:23<01:32, 50.03it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 923/5529 [00:23<01:38, 46.62it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 928/5529 [00:23<01:38, 46.54it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 934/5529 [00:23<01:33, 49.03it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 940/5529 [00:24<01:35, 47.87it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 945/5529 [00:24<01:40, 45.52it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 951/5529 [00:24<01:37, 47.14it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 956/5529 [00:24<01:43, 44.05it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 961/5529 [00:24<01:43, 44.07it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 967/5529 [00:24<01:38, 46.46it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 972/5529 [00:24<01:44, 43.74it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 978/5529 [00:24<01:42, 44.54it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 984/5529 [00:25<01:36, 47.05it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 989/5529 [00:25<01:43, 43.78it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 995/5529 [00:25<01:41, 44.81it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 1001/5529 [00:25<01:37, 46.60it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 1006/5529 [00:25<01:43, 43.85it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 1011/5529 [00:25<01:48, 41.80it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 1017/5529 [00:25<01:40, 44.80it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 1022/5529 [00:25<01:44, 43.03it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1028/5529 [00:26<01:42, 43.85it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1034/5529 [00:26<01:36, 46.53it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1039/5529 [00:26<01:43, 43.50it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1045/5529 [00:26<01:40, 44.74it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1051/5529 [00:26<01:40, 44.63it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1056/5529 [00:26<01:39, 44.86it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1061/5529 [00:26<01:38, 45.26it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 1066/5529 [00:26<01:40, 44.41it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 1071/5529 [00:27<01:39, 44.89it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 1077/5529 [00:27<01:34, 47.05it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1082/5529 [00:27<01:35, 46.61it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1087/5529 [00:27<01:40, 44.09it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1093/5529 [00:27<01:34, 46.73it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1098/5529 [00:27<01:41, 43.63it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1104/5529 [00:27<01:39, 44.46it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1109/5529 [00:27<01:38, 44.75it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 1115/5529 [00:28<01:33, 47.21it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1120/5529 [00:28<01:42, 43.03it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1125/5529 [00:28<01:41, 43.39it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1131/5529 [00:28<01:38, 44.56it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1136/5529 [00:28<01:36, 45.42it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1142/5529 [00:28<01:31, 48.19it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 1147/5529 [00:28<01:30, 48.57it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1152/5529 [00:28<01:32, 47.41it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1157/5529 [00:28<01:32, 47.18it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1162/5529 [00:29<01:32, 47.43it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1167/5529 [00:29<01:32, 46.93it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1172/5529 [00:29<01:31, 47.46it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1177/5529 [00:29<01:32, 46.96it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1182/5529 [00:29<01:32, 47.18it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 1187/5529 [00:29<01:42, 42.53it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1192/5529 [00:29<01:53, 38.06it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1196/5529 [00:30<02:25, 29.85it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1202/5529 [00:30<02:05, 34.44it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1206/5529 [00:30<02:02, 35.19it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1211/5529 [00:30<01:59, 36.28it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1217/5529 [00:30<01:45, 40.79it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1223/5529 [00:30<01:41, 42.61it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1228/5529 [00:30<01:38, 43.49it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1234/5529 [00:30<01:36, 44.63it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1240/5529 [00:30<01:33, 46.06it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1245/5529 [00:31<01:37, 44.02it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1250/5529 [00:31<01:40, 42.53it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 1255/5529 [00:31<01:54, 37.20it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1259/5529 [00:31<02:00, 35.29it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1266/5529 [00:31<01:40, 42.44it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1271/5529 [00:31<01:51, 38.25it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1276/5529 [00:31<01:51, 38.30it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1281/5529 [00:32<01:44, 40.63it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1286/5529 [00:32<01:39, 42.43it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1291/5529 [00:32<01:38, 43.21it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1297/5529 [00:32<01:32, 45.96it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1302/5529 [00:32<01:41, 41.63it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 1308/5529 [00:32<01:31, 45.94it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1313/5529 [00:32<01:31, 46.23it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1319/5529 [00:32<01:26, 48.52it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1324/5529 [00:32<01:32, 45.33it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 1329/5529 [00:33<01:31, 46.15it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1334/5529 [00:33<01:30, 46.58it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1340/5529 [00:33<01:25, 48.84it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 1345/5529 [00:33<01:32, 45.22it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1351/5529 [00:33<01:26, 48.55it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1356/5529 [00:33<01:32, 45.16it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1362/5529 [00:33<01:25, 48.58it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1367/5529 [00:33<01:27, 47.55it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1372/5529 [00:33<01:28, 47.19it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1377/5529 [00:34<01:28, 47.13it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 1382/5529 [00:34<01:28, 46.63it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1387/5529 [00:34<01:28, 46.99it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1392/5529 [00:34<01:29, 46.46it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 1397/5529 [00:34<01:28, 46.52it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1402/5529 [00:34<01:27, 46.96it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1407/5529 [00:34<01:27, 47.35it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1412/5529 [00:34<01:26, 47.52it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1417/5529 [00:34<01:29, 46.07it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1422/5529 [00:35<01:34, 43.49it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1427/5529 [00:35<01:32, 44.31it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 1432/5529 [00:35<01:31, 44.62it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1437/5529 [00:35<01:35, 42.74it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1443/5529 [00:35<01:29, 45.63it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1448/5529 [00:35<01:35, 42.96it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 1453/5529 [00:35<01:32, 44.26it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1459/5529 [00:35<01:26, 47.05it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1464/5529 [00:35<01:28, 45.82it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1469/5529 [00:36<01:29, 45.36it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1474/5529 [00:36<01:33, 43.22it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1480/5529 [00:36<01:31, 44.44it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 1485/5529 [00:36<01:30, 44.65it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1491/5529 [00:36<01:25, 47.11it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1496/5529 [00:36<01:27, 46.24it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1501/5529 [00:36<01:25, 46.95it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 1506/5529 [00:36<01:25, 47.00it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1511/5529 [00:37<01:31, 43.77it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1517/5529 [00:37<01:25, 47.03it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 1522/5529 [00:37<01:33, 42.66it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1527/5529 [00:37<01:30, 44.38it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1532/5529 [00:37<01:38, 40.78it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1538/5529 [00:37<01:29, 44.66it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1543/5529 [00:37<01:29, 44.46it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1548/5529 [00:37<01:35, 41.79it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1553/5529 [00:38<01:34, 42.21it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 1559/5529 [00:38<01:38, 40.40it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1566/5529 [00:38<01:25, 46.19it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1571/5529 [00:38<01:29, 43.99it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 1577/5529 [00:38<01:29, 44.18it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1582/5529 [00:38<01:29, 43.96it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1588/5529 [00:38<01:24, 46.47it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 1593/5529 [00:38<01:25, 46.00it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1598/5529 [00:39<01:30, 43.48it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1603/5529 [00:39<01:28, 44.60it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1608/5529 [00:39<01:33, 42.06it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1614/5529 [00:39<01:26, 45.09it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1620/5529 [00:39<01:26, 45.13it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 1626/5529 [00:39<01:32, 42.07it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1631/5529 [00:39<01:30, 43.18it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1637/5529 [00:39<01:24, 45.95it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1642/5529 [00:40<01:24, 45.80it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 1647/5529 [00:40<01:28, 43.83it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1653/5529 [00:40<01:22, 46.96it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1658/5529 [00:40<01:22, 46.71it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1663/5529 [00:40<01:23, 46.42it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1668/5529 [00:40<01:22, 46.66it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1673/5529 [00:40<01:28, 43.79it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1679/5529 [00:40<01:26, 44.57it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1684/5529 [00:40<01:26, 44.60it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1689/5529 [00:41<01:25, 44.92it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1695/5529 [00:41<01:24, 45.54it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1700/5529 [00:41<01:23, 45.84it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1705/5529 [00:41<01:30, 42.24it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1710/5529 [00:41<01:29, 42.88it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1715/5529 [00:41<01:27, 43.57it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1720/5529 [00:41<01:25, 44.71it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1726/5529 [00:41<01:20, 47.27it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1731/5529 [00:42<01:42, 37.16it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1736/5529 [00:42<01:37, 38.98it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1741/5529 [00:42<01:33, 40.68it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1746/5529 [00:42<01:38, 38.28it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1751/5529 [00:42<01:34, 39.81it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1756/5529 [00:42<01:31, 41.42it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1761/5529 [00:42<01:34, 39.89it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1766/5529 [00:42<01:35, 39.25it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 1772/5529 [00:43<01:26, 43.29it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1778/5529 [00:43<01:21, 46.15it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1783/5529 [00:43<01:25, 43.72it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1788/5529 [00:43<01:25, 43.91it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1794/5529 [00:43<01:19, 46.95it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1799/5529 [00:43<01:25, 43.66it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1805/5529 [00:43<01:23, 44.42it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1811/5529 [00:43<01:19, 46.84it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1816/5529 [00:44<01:23, 44.30it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1821/5529 [00:44<01:23, 44.59it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1827/5529 [00:44<01:18, 47.24it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1832/5529 [00:44<01:22, 44.78it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1838/5529 [00:44<01:22, 44.84it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1844/5529 [00:44<01:17, 47.77it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1849/5529 [00:44<01:23, 44.10it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1855/5529 [00:44<01:21, 44.86it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1860/5529 [00:44<01:22, 44.72it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1866/5529 [00:45<01:17, 47.57it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1871/5529 [00:45<01:22, 44.44it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1877/5529 [00:45<01:17, 47.04it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1882/5529 [00:45<01:17, 47.14it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1887/5529 [00:45<01:18, 46.31it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1892/5529 [00:45<01:18, 46.28it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1897/5529 [00:45<01:24, 43.20it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1903/5529 [00:45<01:18, 46.20it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1908/5529 [00:46<01:18, 45.98it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1913/5529 [00:46<01:23, 43.35it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1919/5529 [00:46<01:17, 46.30it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1924/5529 [00:46<01:23, 43.14it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1930/5529 [00:46<01:21, 44.08it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1935/5529 [00:46<01:26, 41.50it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1940/5529 [00:46<01:25, 42.21it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 1946/5529 [00:46<01:18, 45.91it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1952/5529 [00:47<01:14, 48.14it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1957/5529 [00:47<01:14, 47.94it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1962/5529 [00:47<01:20, 44.43it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1968/5529 [00:47<01:15, 47.06it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1973/5529 [00:47<01:25, 41.64it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1980/5529 [00:47<01:18, 45.22it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1986/5529 [00:47<01:17, 45.43it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1991/5529 [00:47<01:27, 40.38it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1996/5529 [00:48<01:28, 40.03it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2002/5529 [00:48<01:24, 41.70it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 2008/5529 [00:48<01:21, 43.18it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 2013/5529 [00:48<01:20, 43.78it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 2019/5529 [00:48<01:14, 47.38it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2024/5529 [00:48<01:18, 44.38it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2030/5529 [00:48<01:17, 45.22it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2036/5529 [00:48<01:17, 45.07it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 2042/5529 [00:49<01:12, 47.89it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 2047/5529 [00:49<01:18, 44.49it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 2053/5529 [00:49<01:13, 47.19it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2058/5529 [00:49<01:18, 44.43it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2064/5529 [00:49<01:20, 43.03it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2070/5529 [00:49<01:15, 46.00it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2076/5529 [00:49<01:11, 48.30it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2081/5529 [00:49<01:11, 48.11it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2086/5529 [00:49<01:11, 48.02it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2091/5529 [00:50<01:13, 46.63it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2096/5529 [00:50<01:18, 43.63it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2102/5529 [00:50<01:17, 44.14it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2108/5529 [00:50<01:16, 44.67it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2114/5529 [00:50<01:15, 45.17it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2120/5529 [00:50<01:15, 44.94it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2126/5529 [00:50<01:12, 46.80it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2131/5529 [00:50<01:14, 45.54it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2136/5529 [00:51<01:17, 43.54it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2141/5529 [00:51<01:21, 41.49it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2148/5529 [00:51<01:17, 43.43it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2154/5529 [00:51<01:13, 46.06it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2159/5529 [00:51<01:16, 43.80it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2164/5529 [00:51<01:21, 41.23it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2170/5529 [00:51<01:15, 44.55it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 2176/5529 [00:52<01:11, 46.78it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2181/5529 [00:52<01:12, 46.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2186/5529 [00:52<01:20, 41.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2192/5529 [00:52<01:14, 44.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2197/5529 [00:52<01:14, 45.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2202/5529 [00:52<01:13, 45.47it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2207/5529 [00:52<01:16, 43.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2213/5529 [00:52<01:19, 41.57it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2219/5529 [00:53<01:14, 44.42it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2224/5529 [00:53<01:26, 38.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2228/5529 [00:53<01:33, 35.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2232/5529 [00:53<01:35, 34.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2236/5529 [00:53<01:33, 35.41it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2242/5529 [00:53<01:25, 38.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2247/5529 [00:53<01:21, 40.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2253/5529 [00:53<01:13, 44.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2258/5529 [00:54<01:15, 43.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2263/5529 [00:54<01:13, 44.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2268/5529 [00:54<01:13, 44.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2273/5529 [00:54<01:12, 44.88it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2279/5529 [00:54<01:14, 43.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2285/5529 [00:54<01:09, 46.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2290/5529 [00:54<01:09, 46.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2295/5529 [00:54<01:10, 45.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2301/5529 [00:54<01:06, 48.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2306/5529 [00:55<01:06, 48.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2311/5529 [00:55<01:07, 47.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2316/5529 [00:55<01:07, 47.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2321/5529 [00:55<01:14, 43.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2327/5529 [00:55<01:08, 46.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2332/5529 [00:55<01:11, 44.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2337/5529 [00:55<01:10, 45.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2343/5529 [00:55<01:07, 46.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2348/5529 [00:55<01:13, 43.48it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2354/5529 [00:56<01:11, 44.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2359/5529 [00:56<01:09, 45.48it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2364/5529 [00:56<01:09, 45.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2369/5529 [00:56<01:10, 44.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2374/5529 [00:56<01:10, 44.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2380/5529 [00:56<01:08, 45.78it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2386/5529 [00:56<01:07, 46.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2392/5529 [00:56<01:04, 48.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2397/5529 [00:57<01:10, 44.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2403/5529 [00:57<01:06, 47.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2408/5529 [00:57<01:05, 47.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2413/5529 [00:57<01:06, 46.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2418/5529 [00:57<01:07, 46.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2423/5529 [00:57<01:11, 43.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2428/5529 [00:57<01:25, 36.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2438/5529 [00:57<01:01, 50.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2444/5529 [00:58<01:06, 46.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2449/5529 [00:58<01:07, 45.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2454/5529 [00:58<01:06, 45.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2460/5529 [00:58<01:05, 46.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2465/5529 [00:58<01:06, 46.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2470/5529 [00:58<01:05, 46.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2475/5529 [00:58<01:10, 43.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2481/5529 [00:58<01:07, 44.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2486/5529 [00:59<01:06, 45.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2492/5529 [00:59<01:03, 48.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2497/5529 [00:59<01:08, 44.29it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2503/5529 [00:59<01:04, 47.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2509/5529 [00:59<01:02, 48.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2514/5529 [00:59<01:03, 47.49it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2519/5529 [00:59<01:08, 43.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2525/5529 [00:59<01:04, 46.38it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2530/5529 [00:59<01:11, 41.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2535/5529 [01:00<01:10, 42.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2540/5529 [01:00<01:13, 40.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2546/5529 [01:00<01:07, 44.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2552/5529 [01:00<01:03, 47.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2557/5529 [01:00<01:06, 44.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2562/5529 [01:00<01:06, 44.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2568/5529 [01:00<01:06, 44.56it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2573/5529 [01:00<01:06, 44.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2579/5529 [01:01<01:05, 44.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2585/5529 [01:01<01:05, 44.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2590/5529 [01:01<01:05, 44.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2596/5529 [01:01<01:09, 42.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2603/5529 [01:01<01:01, 47.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2608/5529 [01:01<01:08, 42.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2615/5529 [01:01<01:03, 45.58it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2621/5529 [01:02<01:04, 45.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2627/5529 [01:02<01:01, 47.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2632/5529 [01:02<01:00, 47.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2637/5529 [01:02<01:01, 46.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2642/5529 [01:02<01:02, 46.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2647/5529 [01:02<01:11, 40.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2654/5529 [01:02<01:02, 46.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2659/5529 [01:02<01:05, 44.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2665/5529 [01:03<01:04, 44.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2671/5529 [01:03<01:04, 44.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2677/5529 [01:03<01:04, 44.14it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2683/5529 [01:03<00:59, 47.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2688/5529 [01:03<01:01, 46.54it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2693/5529 [01:03<01:05, 43.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2699/5529 [01:03<01:01, 46.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2704/5529 [01:03<01:07, 41.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2709/5529 [01:04<01:06, 42.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2715/5529 [01:04<01:01, 45.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2721/5529 [01:04<01:02, 45.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2727/5529 [01:04<00:59, 47.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2732/5529 [01:04<01:01, 45.33it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2737/5529 [01:04<01:02, 44.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2743/5529 [01:04<01:02, 44.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2748/5529 [01:04<01:02, 44.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2754/5529 [01:04<01:01, 44.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2759/5529 [01:05<01:00, 45.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2765/5529 [01:05<00:58, 47.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2770/5529 [01:05<01:03, 43.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2776/5529 [01:05<00:59, 46.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2781/5529 [01:05<00:59, 46.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2786/5529 [01:05<01:02, 44.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2792/5529 [01:05<00:58, 46.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2797/5529 [01:05<01:00, 45.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2802/5529 [01:06<01:00, 45.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2807/5529 [01:06<00:58, 46.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2812/5529 [01:06<00:58, 46.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2817/5529 [01:06<00:59, 45.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2822/5529 [01:06<00:59, 45.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2827/5529 [01:06<01:03, 42.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2834/5529 [01:06<01:00, 44.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2839/5529 [01:06<01:03, 42.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2846/5529 [01:06<00:56, 47.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2851/5529 [01:07<00:58, 46.14it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2856/5529 [01:07<01:00, 44.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2861/5529 [01:07<00:59, 44.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2867/5529 [01:07<00:56, 47.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2872/5529 [01:07<01:01, 43.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2878/5529 [01:07<00:58, 45.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2883/5529 [01:07<00:56, 46.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2888/5529 [01:07<00:57, 46.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2893/5529 [01:08<01:01, 43.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2898/5529 [01:08<01:00, 43.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2904/5529 [01:08<00:59, 44.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2909/5529 [01:08<00:58, 44.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2914/5529 [01:08<00:58, 44.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2920/5529 [01:08<00:55, 47.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2925/5529 [01:08<00:56, 46.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2930/5529 [01:08<00:55, 46.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2935/5529 [01:08<00:55, 46.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2940/5529 [01:09<00:59, 43.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2946/5529 [01:09<01:00, 42.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2952/5529 [01:09<00:56, 45.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2957/5529 [01:09<00:54, 46.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2962/5529 [01:09<00:54, 46.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2967/5529 [01:09<01:01, 41.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2973/5529 [01:09<00:57, 44.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2979/5529 [01:09<00:56, 45.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2984/5529 [01:10<00:55, 45.86it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2989/5529 [01:10<00:55, 45.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2994/5529 [01:10<00:55, 45.41it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3000/5529 [01:10<00:53, 47.37it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3005/5529 [01:10<00:56, 44.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3010/5529 [01:10<00:55, 45.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 3016/5529 [01:10<00:52, 47.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 3021/5529 [01:10<00:54, 46.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 3026/5529 [01:10<00:54, 45.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3031/5529 [01:11<00:56, 44.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3036/5529 [01:11<00:55, 44.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3041/5529 [01:11<00:55, 44.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3046/5529 [01:11<00:55, 44.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 3051/5529 [01:11<00:55, 44.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 3056/5529 [01:11<00:56, 43.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 3061/5529 [01:11<00:55, 44.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3067/5529 [01:11<00:55, 44.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3072/5529 [01:12<00:55, 44.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3078/5529 [01:12<00:52, 46.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3083/5529 [01:12<00:54, 45.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3089/5529 [01:12<00:54, 45.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3095/5529 [01:12<00:51, 47.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3100/5529 [01:12<00:55, 44.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 3105/5529 [01:12<00:53, 45.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 3110/5529 [01:12<00:52, 45.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 3116/5529 [01:12<00:50, 48.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3121/5529 [01:13<00:54, 44.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3127/5529 [01:13<00:51, 46.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3133/5529 [01:13<00:52, 45.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3139/5529 [01:13<00:53, 44.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3145/5529 [01:13<00:50, 46.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3150/5529 [01:13<00:51, 45.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3155/5529 [01:13<00:53, 44.11it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3161/5529 [01:13<00:52, 44.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3166/5529 [01:14<00:52, 44.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3172/5529 [01:14<00:52, 44.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3177/5529 [01:14<00:52, 44.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3183/5529 [01:14<00:50, 46.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3189/5529 [01:14<00:51, 45.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3195/5529 [01:14<00:49, 47.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3200/5529 [01:14<00:49, 46.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3205/5529 [01:14<00:49, 47.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3210/5529 [01:15<00:52, 44.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3216/5529 [01:15<00:49, 47.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3221/5529 [01:15<00:49, 46.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3226/5529 [01:15<00:50, 45.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3231/5529 [01:15<00:48, 46.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3236/5529 [01:15<00:51, 44.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3242/5529 [01:15<00:51, 44.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3247/5529 [01:15<00:51, 44.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3253/5529 [01:15<00:48, 46.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3258/5529 [01:16<00:47, 47.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3263/5529 [01:16<00:48, 46.70it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3268/5529 [01:16<00:49, 46.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3273/5529 [01:16<00:49, 46.03it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3278/5529 [01:16<00:49, 45.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3283/5529 [01:16<00:48, 46.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3288/5529 [01:16<00:48, 46.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3293/5529 [01:16<00:52, 42.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3298/5529 [01:16<00:51, 43.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3304/5529 [01:17<00:47, 46.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3309/5529 [01:17<00:47, 47.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3314/5529 [01:17<00:50, 43.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3320/5529 [01:17<00:47, 46.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3325/5529 [01:17<00:47, 46.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3330/5529 [01:17<00:47, 46.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3335/5529 [01:17<00:48, 45.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3340/5529 [01:17<00:56, 38.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3346/5529 [01:18<00:51, 42.77it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3351/5529 [01:18<00:53, 41.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3357/5529 [01:18<00:47, 45.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3362/5529 [01:18<00:48, 45.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3367/5529 [01:18<00:50, 42.80it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3372/5529 [01:18<00:49, 43.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3378/5529 [01:18<00:46, 46.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3383/5529 [01:18<00:48, 43.87it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3388/5529 [01:19<00:49, 43.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3393/5529 [01:19<00:48, 43.61it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3398/5529 [01:19<00:48, 44.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3403/5529 [01:19<00:47, 44.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3408/5529 [01:19<00:46, 45.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3413/5529 [01:19<00:46, 45.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3418/5529 [01:19<00:49, 42.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3424/5529 [01:19<00:45, 46.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3429/5529 [01:19<00:45, 46.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3434/5529 [01:20<00:45, 46.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3439/5529 [01:20<00:50, 41.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3446/5529 [01:20<00:46, 44.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3452/5529 [01:20<00:43, 47.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3457/5529 [01:20<00:43, 47.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3462/5529 [01:20<00:44, 46.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3467/5529 [01:20<00:47, 43.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3472/5529 [01:20<00:46, 44.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3478/5529 [01:20<00:43, 47.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3483/5529 [01:21<00:44, 46.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3488/5529 [01:21<00:44, 45.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3493/5529 [01:21<00:44, 45.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3498/5529 [01:21<00:44, 45.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3503/5529 [01:21<00:44, 45.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3508/5529 [01:21<00:44, 45.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3513/5529 [01:21<00:48, 41.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3518/5529 [01:21<00:54, 36.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3522/5529 [01:22<00:56, 35.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3526/5529 [01:22<00:58, 34.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3530/5529 [01:22<00:58, 33.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3534/5529 [01:22<00:59, 33.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3538/5529 [01:22<01:02, 32.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3542/5529 [01:22<01:03, 31.36it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3546/5529 [01:22<01:03, 31.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3550/5529 [01:22<01:04, 30.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3554/5529 [01:23<01:03, 30.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3558/5529 [01:23<01:02, 31.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3562/5529 [01:23<01:03, 31.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3566/5529 [01:23<01:03, 30.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3570/5529 [01:23<01:03, 30.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3574/5529 [01:23<01:03, 30.75it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3578/5529 [01:23<01:02, 31.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3582/5529 [01:24<00:59, 32.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3586/5529 [01:24<00:58, 32.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3591/5529 [01:24<00:53, 36.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3596/5529 [01:24<00:49, 38.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3602/5529 [01:24<00:47, 40.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3607/5529 [01:24<00:46, 41.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3613/5529 [01:24<00:42, 44.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3618/5529 [01:24<00:42, 44.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3623/5529 [01:24<00:44, 42.75it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3629/5529 [01:25<00:40, 46.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3634/5529 [01:25<00:43, 43.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3639/5529 [01:25<00:42, 44.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3645/5529 [01:25<00:41, 45.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3650/5529 [01:25<00:46, 40.72it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3655/5529 [01:25<00:44, 42.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3660/5529 [01:25<00:46, 40.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3666/5529 [01:25<00:44, 42.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3672/5529 [01:26<00:41, 45.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3677/5529 [01:26<00:41, 44.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3682/5529 [01:26<00:40, 45.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3687/5529 [01:26<00:40, 45.67it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3692/5529 [01:26<00:42, 43.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3697/5529 [01:26<00:42, 43.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3702/5529 [01:26<00:42, 42.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3707/5529 [01:26<00:43, 42.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3712/5529 [01:26<00:42, 43.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3717/5529 [01:27<00:41, 43.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3723/5529 [01:27<00:38, 47.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3728/5529 [01:27<00:40, 43.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3733/5529 [01:27<00:40, 44.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3738/5529 [01:27<00:41, 43.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3743/5529 [01:27<00:42, 42.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3748/5529 [01:27<00:42, 41.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3753/5529 [01:27<00:42, 41.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3758/5529 [01:28<00:45, 38.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3762/5529 [01:28<00:45, 38.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3767/5529 [01:28<00:42, 41.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3772/5529 [01:28<00:43, 40.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3777/5529 [01:28<00:45, 38.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3781/5529 [01:28<00:49, 35.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3785/5529 [01:28<00:52, 32.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3789/5529 [01:29<00:55, 31.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3793/5529 [01:29<00:57, 30.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3797/5529 [01:29<00:58, 29.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3801/5529 [01:29<00:58, 29.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3805/5529 [01:29<00:55, 31.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3809/5529 [01:29<01:00, 28.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3812/5529 [01:29<01:00, 28.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3816/5529 [01:29<00:56, 30.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3821/5529 [01:30<00:49, 34.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3826/5529 [01:30<00:45, 37.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3832/5529 [01:30<00:43, 38.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3838/5529 [01:30<00:39, 43.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3843/5529 [01:30<00:39, 42.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3848/5529 [01:30<00:43, 38.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3852/5529 [01:30<00:46, 35.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3856/5529 [01:30<00:47, 35.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3860/5529 [01:31<00:48, 34.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3864/5529 [01:31<00:49, 33.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3868/5529 [01:31<00:50, 32.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3872/5529 [01:31<00:51, 32.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3876/5529 [01:31<00:50, 32.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3880/5529 [01:31<00:49, 33.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3884/5529 [01:31<00:49, 33.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3888/5529 [01:31<00:50, 32.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3892/5529 [01:32<00:52, 31.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3896/5529 [01:32<00:49, 33.23it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3900/5529 [01:32<00:56, 28.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3904/5529 [01:32<00:56, 28.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3907/5529 [01:32<00:56, 28.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3910/5529 [01:32<00:56, 28.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3913/5529 [01:32<00:56, 28.49it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3917/5529 [01:32<00:53, 30.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3922/5529 [01:33<00:46, 34.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3928/5529 [01:33<00:39, 40.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3933/5529 [01:33<00:37, 42.69it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3938/5529 [01:33<00:36, 43.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3943/5529 [01:33<00:35, 44.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3948/5529 [01:33<00:35, 44.29it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3953/5529 [01:33<00:37, 42.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3959/5529 [01:33<00:33, 46.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3964/5529 [01:33<00:33, 46.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3969/5529 [01:34<00:34, 45.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3974/5529 [01:34<00:34, 45.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3979/5529 [01:34<00:33, 45.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3984/5529 [01:34<00:33, 45.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3989/5529 [01:34<00:33, 45.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3994/5529 [01:34<00:33, 45.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3999/5529 [01:34<00:33, 45.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 4004/5529 [01:34<00:34, 43.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4010/5529 [01:34<00:32, 46.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4015/5529 [01:35<00:32, 46.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4020/5529 [01:35<00:32, 46.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4025/5529 [01:35<00:32, 45.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4030/5529 [01:35<00:31, 46.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4035/5529 [01:35<00:32, 46.26it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4040/5529 [01:35<00:32, 45.97it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 4045/5529 [01:35<00:32, 45.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 4050/5529 [01:35<00:32, 45.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 4055/5529 [01:35<00:31, 46.07it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 4060/5529 [01:36<00:34, 42.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 4066/5529 [01:36<00:31, 46.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 4071/5529 [01:36<00:31, 46.16it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4076/5529 [01:36<00:31, 45.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4081/5529 [01:36<00:34, 42.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4086/5529 [01:36<00:38, 37.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4090/5529 [01:36<00:40, 35.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4094/5529 [01:36<00:41, 34.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4099/5529 [01:37<00:38, 37.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4104/5529 [01:37<00:35, 39.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4109/5529 [01:37<00:34, 41.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 4114/5529 [01:37<00:35, 40.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 4120/5529 [01:37<00:31, 44.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 4125/5529 [01:37<00:31, 44.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4130/5529 [01:37<00:31, 44.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4135/5529 [01:37<00:35, 39.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4140/5529 [01:38<00:38, 36.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4144/5529 [01:38<00:38, 36.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4148/5529 [01:38<00:37, 37.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4153/5529 [01:38<00:38, 36.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4157/5529 [01:38<00:37, 37.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4163/5529 [01:38<00:35, 38.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4169/5529 [01:38<00:33, 41.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4174/5529 [01:38<00:32, 41.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4179/5529 [01:39<00:34, 38.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4184/5529 [01:39<00:32, 41.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4189/5529 [01:39<00:32, 41.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4194/5529 [01:39<00:32, 41.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4199/5529 [01:39<00:32, 40.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4204/5529 [01:39<00:36, 36.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4208/5529 [01:39<00:38, 34.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4212/5529 [01:39<00:37, 35.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4216/5529 [01:40<00:38, 33.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4222/5529 [01:40<00:35, 37.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4228/5529 [01:40<00:30, 42.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4233/5529 [01:40<00:29, 43.69it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4238/5529 [01:40<00:28, 44.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4243/5529 [01:40<00:29, 43.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4248/5529 [01:40<00:30, 41.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4253/5529 [01:40<00:29, 42.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4258/5529 [01:40<00:28, 43.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4263/5529 [01:41<00:28, 45.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4268/5529 [01:41<00:29, 42.40it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4274/5529 [01:41<00:27, 45.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4279/5529 [01:41<00:27, 45.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4284/5529 [01:41<00:27, 45.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4289/5529 [01:41<00:28, 43.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4295/5529 [01:41<00:27, 44.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4301/5529 [01:41<00:26, 46.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4306/5529 [01:42<00:27, 44.99it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4312/5529 [01:42<00:26, 45.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4318/5529 [01:42<00:26, 45.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4324/5529 [01:42<00:26, 45.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4330/5529 [01:42<00:26, 45.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4335/5529 [01:42<00:26, 45.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4341/5529 [01:42<00:24, 47.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4346/5529 [01:42<00:25, 47.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4351/5529 [01:43<00:25, 45.99it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4356/5529 [01:43<00:25, 46.86it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4361/5529 [01:43<00:25, 46.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4366/5529 [01:43<00:25, 45.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4371/5529 [01:43<00:26, 43.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4377/5529 [01:43<00:25, 45.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4382/5529 [01:43<00:25, 44.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4388/5529 [01:43<00:25, 45.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4393/5529 [01:43<00:25, 45.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4398/5529 [01:44<00:25, 44.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4404/5529 [01:44<00:23, 48.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4409/5529 [01:44<00:23, 47.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4414/5529 [01:44<00:25, 43.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4419/5529 [01:44<00:28, 38.44it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4423/5529 [01:44<00:31, 35.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4429/5529 [01:44<00:26, 40.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4434/5529 [01:44<00:25, 42.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4439/5529 [01:45<00:26, 40.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4445/5529 [01:45<00:24, 44.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4450/5529 [01:45<00:24, 43.59it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4455/5529 [01:45<00:23, 44.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4460/5529 [01:45<00:23, 45.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4465/5529 [01:45<00:23, 45.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4470/5529 [01:45<00:23, 45.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4475/5529 [01:45<00:23, 44.79it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4480/5529 [01:45<00:24, 43.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4486/5529 [01:46<00:22, 46.47it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4491/5529 [01:46<00:22, 46.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4496/5529 [01:46<00:22, 46.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4501/5529 [01:46<00:22, 45.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4506/5529 [01:46<00:23, 43.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4512/5529 [01:46<00:21, 46.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4517/5529 [01:46<00:22, 45.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4522/5529 [01:46<00:23, 43.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4528/5529 [01:47<00:21, 46.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4533/5529 [01:47<00:21, 46.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4538/5529 [01:47<00:21, 46.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4543/5529 [01:47<00:21, 45.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4548/5529 [01:47<00:21, 45.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4553/5529 [01:47<00:21, 45.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4558/5529 [01:47<00:21, 46.12it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4563/5529 [01:47<00:21, 45.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4568/5529 [01:47<00:20, 46.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4573/5529 [01:48<00:21, 45.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4578/5529 [01:48<00:21, 44.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4583/5529 [01:48<00:20, 45.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4588/5529 [01:48<00:21, 42.81it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4594/5529 [01:48<00:20, 45.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4599/5529 [01:48<00:20, 45.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4604/5529 [01:48<00:20, 44.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4610/5529 [01:48<00:19, 46.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4615/5529 [01:48<00:19, 46.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4620/5529 [01:49<00:19, 46.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4625/5529 [01:49<00:21, 42.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4631/5529 [01:49<00:19, 46.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4636/5529 [01:49<00:19, 45.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4641/5529 [01:49<00:19, 45.12it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4646/5529 [01:49<00:19, 45.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4651/5529 [01:49<00:19, 44.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4657/5529 [01:49<00:18, 46.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4662/5529 [01:49<00:18, 46.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4667/5529 [01:50<00:18, 45.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4672/5529 [01:50<00:21, 40.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4678/5529 [01:50<00:18, 44.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4684/5529 [01:50<00:17, 47.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4689/5529 [01:50<00:17, 47.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4694/5529 [01:50<00:17, 46.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4699/5529 [01:50<00:17, 46.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4704/5529 [01:50<00:18, 43.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4709/5529 [01:51<00:20, 39.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4714/5529 [01:51<00:26, 31.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4720/5529 [01:51<00:22, 36.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4725/5529 [01:51<00:20, 38.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4730/5529 [01:51<00:20, 38.21it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4736/5529 [01:51<00:19, 39.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4741/5529 [01:51<00:19, 39.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4746/5529 [01:52<00:19, 41.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4752/5529 [01:52<00:17, 44.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4757/5529 [01:52<00:18, 42.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4762/5529 [01:52<00:18, 41.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4768/5529 [01:52<00:16, 45.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4773/5529 [01:52<00:16, 45.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4778/5529 [01:52<00:16, 45.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4783/5529 [01:52<00:16, 45.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4788/5529 [01:52<00:16, 46.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4793/5529 [01:53<00:15, 46.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4798/5529 [01:53<00:15, 46.03it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4803/5529 [01:53<00:15, 46.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4808/5529 [01:53<00:15, 46.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4813/5529 [01:53<00:15, 46.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4818/5529 [01:53<00:15, 46.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4823/5529 [01:53<00:15, 46.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4828/5529 [01:53<00:15, 46.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4833/5529 [01:53<00:15, 45.88it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4838/5529 [01:54<00:15, 46.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4843/5529 [01:54<00:15, 44.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4849/5529 [01:54<00:14, 46.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4854/5529 [01:54<00:14, 45.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4859/5529 [01:54<00:17, 39.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4864/5529 [01:54<00:18, 36.67it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4868/5529 [01:54<00:18, 35.03it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4872/5529 [01:54<00:18, 35.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4876/5529 [01:55<00:18, 36.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4880/5529 [01:55<00:18, 35.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4885/5529 [01:55<00:17, 36.65it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4890/5529 [01:55<00:16, 39.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4895/5529 [01:55<00:15, 40.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4900/5529 [01:55<00:15, 40.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4905/5529 [01:55<00:16, 37.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4911/5529 [01:55<00:14, 41.55it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4917/5529 [01:56<00:13, 44.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4922/5529 [01:56<00:13, 44.69it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4927/5529 [01:56<00:13, 44.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4932/5529 [01:56<00:14, 42.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4937/5529 [01:56<00:13, 43.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4943/5529 [01:56<00:13, 43.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4949/5529 [01:56<00:12, 46.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4954/5529 [01:56<00:12, 46.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4959/5529 [01:56<00:12, 45.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4964/5529 [01:57<00:12, 45.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4969/5529 [01:57<00:12, 46.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4974/5529 [01:57<00:12, 45.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4979/5529 [01:57<00:11, 45.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4984/5529 [01:57<00:12, 43.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4990/5529 [01:57<00:11, 46.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4995/5529 [01:57<00:11, 46.17it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5000/5529 [01:57<00:11, 45.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5005/5529 [01:57<00:11, 45.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5010/5529 [01:58<00:11, 46.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5015/5529 [01:58<00:11, 45.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5020/5529 [01:58<00:11, 46.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5025/5529 [01:58<00:11, 45.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5030/5529 [01:58<00:10, 45.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5035/5529 [01:58<00:10, 46.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5040/5529 [01:58<00:10, 45.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5045/5529 [01:58<00:10, 46.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5050/5529 [01:58<00:10, 45.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5055/5529 [01:59<00:10, 45.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5060/5529 [01:59<00:10, 46.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5065/5529 [01:59<00:10, 45.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5070/5529 [01:59<00:09, 46.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5075/5529 [01:59<00:09, 45.73it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5080/5529 [01:59<00:09, 45.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5085/5529 [01:59<00:10, 43.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5091/5529 [01:59<00:09, 46.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5096/5529 [01:59<00:09, 46.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5101/5529 [02:00<00:09, 45.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5106/5529 [02:00<00:09, 46.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5111/5529 [02:00<00:09, 44.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5117/5529 [02:00<00:08, 47.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5122/5529 [02:00<00:09, 43.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5128/5529 [02:00<00:08, 47.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5133/5529 [02:00<00:08, 46.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5138/5529 [02:00<00:08, 46.39it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5143/5529 [02:00<00:08, 43.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5148/5529 [02:01<00:09, 38.47it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5153/5529 [02:01<00:09, 40.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 5158/5529 [02:01<00:08, 42.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 5163/5529 [02:01<00:08, 40.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 5169/5529 [02:01<00:08, 42.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5175/5529 [02:01<00:07, 45.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5180/5529 [02:01<00:07, 45.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5185/5529 [02:01<00:07, 46.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5190/5529 [02:02<00:07, 45.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5195/5529 [02:02<00:07, 45.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5200/5529 [02:02<00:07, 45.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5205/5529 [02:02<00:06, 46.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5210/5529 [02:02<00:06, 46.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5215/5529 [02:02<00:06, 46.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5220/5529 [02:02<00:06, 46.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5225/5529 [02:02<00:06, 46.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5230/5529 [02:02<00:06, 46.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5235/5529 [02:03<00:06, 46.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5240/5529 [02:03<00:06, 45.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5245/5529 [02:03<00:06, 45.48it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5250/5529 [02:03<00:06, 45.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5255/5529 [02:03<00:05, 45.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5260/5529 [02:03<00:05, 45.69it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5265/5529 [02:03<00:05, 45.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5270/5529 [02:03<00:05, 45.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5275/5529 [02:03<00:05, 44.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5280/5529 [02:04<00:05, 45.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5285/5529 [02:04<00:05, 46.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5290/5529 [02:04<00:05, 45.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5295/5529 [02:04<00:05, 45.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5300/5529 [02:04<00:05, 44.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5305/5529 [02:04<00:04, 45.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5310/5529 [02:04<00:04, 45.05it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5315/5529 [02:04<00:04, 44.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5320/5529 [02:04<00:04, 45.52it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5325/5529 [02:05<00:04, 45.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5330/5529 [02:05<00:04, 45.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5335/5529 [02:05<00:04, 45.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5340/5529 [02:05<00:04, 45.27it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5345/5529 [02:05<00:04, 45.48it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5350/5529 [02:05<00:03, 45.42it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5355/5529 [02:05<00:03, 45.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5360/5529 [02:05<00:03, 44.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5366/5529 [02:05<00:03, 47.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5371/5529 [02:06<00:03, 46.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5376/5529 [02:06<00:03, 46.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5381/5529 [02:06<00:03, 44.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5387/5529 [02:06<00:03, 45.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5393/5529 [02:06<00:02, 48.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5398/5529 [02:06<00:02, 44.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5404/5529 [02:06<00:02, 47.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5409/5529 [02:06<00:02, 42.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5416/5529 [02:07<00:02, 48.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5422/5529 [02:07<00:02, 47.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5427/5529 [02:07<00:02, 44.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5433/5529 [02:07<00:01, 48.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5438/5529 [02:07<00:01, 47.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5443/5529 [02:07<00:01, 47.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5448/5529 [02:07<00:01, 45.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5453/5529 [02:07<00:01, 45.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5458/5529 [02:07<00:01, 43.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5463/5529 [02:08<00:01, 43.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5469/5529 [02:08<00:01, 46.97it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5474/5529 [02:08<00:01, 45.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5479/5529 [02:08<00:01, 45.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5484/5529 [02:08<00:01, 44.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5490/5529 [02:08<00:00, 46.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5495/5529 [02:08<00:00, 46.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5500/5529 [02:08<00:00, 45.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5505/5529 [02:08<00:00, 45.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5510/5529 [02:09<00:00, 44.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5516/5529 [02:09<00:00, 45.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5521/5529 [02:09<00:00, 40.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5526/5529 [02:09<00:00, 32.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5529/5529 [02:09<00:00, 42.65it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.6151
Epoch 1 Step 51 Train Loss: 0.6193
Epoch 1 Step 101 Train Loss: 0.6139
Epoch 1 Step 151 Train Loss: 0.6022
Epoch 1 Step 201 Train Loss: 0.6172
Epoch 1 Step 251 Train Loss: 0.6293
Epoch 1 Step 301 Train Loss: 0.5489
Epoch 1 Step 351 Train Loss: 0.5907
Epoch 1 Step 401 Train Loss: 0.6273
Epoch 1 Step 451 Train Loss: 0.6101
Epoch 1 Step 501 Train Loss: 0.5847
Epoch 1 Step 551 Train Loss: 0.6575
Epoch 1 Step 601 Train Loss: 0.6242
Epoch 1 Step 651 Train Loss: 0.5798
Epoch 1 Step 701 Train Loss: 0.6185
Epoch 1 Step 751 Train Loss: 0.5916
Epoch 1 Step 801 Train Loss: 0.5970
Epoch 1 Step 851 Train Loss: 0.6309
Epoch 1 Step 901 Train Loss: 0.6151
Epoch 1 Step 951 Train Loss: 0.5730
Epoch 1 Step 1001 Train Loss: 0.6195
Epoch 1 Step 1051 Train Loss: 0.6016
Epoch 1 Step 1101 Train Loss: 0.6058
Epoch 1 Step 1151 Train Loss: 0.6849
Epoch 1 Step 1201 Train Loss: 0.6633
Epoch 1 Step 1251 Train Loss: 0.6175
Epoch 1 Step 1301 Train Loss: 0.6479
Epoch 1 Step 1351 Train Loss: 0.6185
Epoch 1 Step 1401 Train Loss: 0.5418
Epoch 1 Step 1451 Train Loss: 0.5626
Epoch 1 Step 1501 Train Loss: 0.5594
Epoch 1 Step 1551 Train Loss: 0.6223
Epoch 1 Step 1601 Train Loss: 0.5530
Epoch 1 Step 1651 Train Loss: 0.5460
Epoch 1 Step 1701 Train Loss: 0.6296
Epoch 1 Step 1751 Train Loss: 0.6285
Epoch 1 Step 1801 Train Loss: 0.5941
Epoch 1 Step 1851 Train Loss: 0.5748
Epoch 1 Step 1901 Train Loss: 0.5892
Epoch 1 Step 1951 Train Loss: 0.6201
Epoch 1 Step 2001 Train Loss: 0.6177
Epoch 1 Step 2051 Train Loss: 0.5631
Epoch 1 Step 2101 Train Loss: 0.6568
Epoch 1 Step 2151 Train Loss: 0.6207
Epoch 1 Step 2201 Train Loss: 0.7119
Epoch 1 Step 2251 Train Loss: 0.6771
Epoch 1 Step 2301 Train Loss: 0.6084
Epoch 1 Step 2351 Train Loss: 0.5828
Epoch 1 Step 2401 Train Loss: 0.6270
Epoch 1 Step 2451 Train Loss: 0.5884
Epoch 1 Step 2501 Train Loss: 0.6480
Epoch 1 Step 2551 Train Loss: 0.5974
Epoch 1 Step 2601 Train Loss: 0.6333
Epoch 1 Step 2651 Train Loss: 0.6026
Epoch 1 Step 2701 Train Loss: 0.6066
Epoch 1 Step 2751 Train Loss: 0.6154
Epoch 1 Step 2801 Train Loss: 0.5862
Epoch 1 Step 2851 Train Loss: 0.5604
Epoch 1 Step 2901 Train Loss: 0.6039
Epoch 1 Step 2951 Train Loss: 0.6321
Epoch 1 Step 3001 Train Loss: 0.5943
Epoch 1 Step 3051 Train Loss: 0.6120
Epoch 1 Step 3101 Train Loss: 0.6266
Epoch 1 Step 3151 Train Loss: 0.6904
Epoch 1 Step 3201 Train Loss: 0.5815
Epoch 1: Train Overall MSE: 0.0149 Validation Overall MSE: 0.0155. 
Train Top 20 DE MSE: 0.1404 Validation Top 20 DE MSE: 0.1254. 
Epoch 2 Step 1 Train Loss: 0.5818
Epoch 2 Step 51 Train Loss: 0.6058
Epoch 2 Step 101 Train Loss: 0.6070
Epoch 2 Step 151 Train Loss: 0.5780
Epoch 2 Step 201 Train Loss: 0.5965
Epoch 2 Step 251 Train Loss: 0.5765
Epoch 2 Step 301 Train Loss: 0.6302
Epoch 2 Step 351 Train Loss: 0.6870
Epoch 2 Step 401 Train Loss: 0.5564
Epoch 2 Step 451 Train Loss: 0.6074
Epoch 2 Step 501 Train Loss: 0.6380
Epoch 2 Step 551 Train Loss: 0.5901
Epoch 2 Step 601 Train Loss: 0.5616
Epoch 2 Step 651 Train Loss: 0.5992
Epoch 2 Step 701 Train Loss: 0.5707
Epoch 2 Step 751 Train Loss: 0.6046
Epoch 2 Step 801 Train Loss: 0.5987
Epoch 2 Step 851 Train Loss: 0.6612
Epoch 2 Step 901 Train Loss: 0.5646
Epoch 2 Step 951 Train Loss: 0.6237
Epoch 2 Step 1001 Train Loss: 0.6189
Epoch 2 Step 1051 Train Loss: 0.5735
Epoch 2 Step 1101 Train Loss: 0.5956
Epoch 2 Step 1151 Train Loss: 0.6506
Epoch 2 Step 1201 Train Loss: 0.5858
Epoch 2 Step 1251 Train Loss: 0.6048
Epoch 2 Step 1301 Train Loss: 0.5617
Epoch 2 Step 1351 Train Loss: 0.6119
Epoch 2 Step 1401 Train Loss: 0.6451
Epoch 2 Step 1451 Train Loss: 0.6083
Epoch 2 Step 1501 Train Loss: 0.6237
Epoch 2 Step 1551 Train Loss: 0.5988
Epoch 2 Step 1601 Train Loss: 0.5901
Epoch 2 Step 1651 Train Loss: 0.5627
Epoch 2 Step 1701 Train Loss: 0.5670
Epoch 2 Step 1751 Train Loss: 0.5964
Epoch 2 Step 1801 Train Loss: 0.5976
Epoch 2 Step 1851 Train Loss: 0.6131
Epoch 2 Step 1901 Train Loss: 0.5790
Epoch 2 Step 1951 Train Loss: 0.6488
Epoch 2 Step 2001 Train Loss: 0.5992
Epoch 2 Step 2051 Train Loss: 0.6494
Epoch 2 Step 2101 Train Loss: 0.6262
Epoch 2 Step 2151 Train Loss: 0.6196
Epoch 2 Step 2201 Train Loss: 0.5970
Epoch 2 Step 2251 Train Loss: 0.5662
Epoch 2 Step 2301 Train Loss: 0.6087
Epoch 2 Step 2351 Train Loss: 0.5664
Epoch 2 Step 2401 Train Loss: 0.5724
Epoch 2 Step 2451 Train Loss: 0.5771
Epoch 2 Step 2501 Train Loss: 0.6721
Epoch 2 Step 2551 Train Loss: 0.6219
Epoch 2 Step 2601 Train Loss: 0.5668
Epoch 2 Step 2651 Train Loss: 0.5688
Epoch 2 Step 2701 Train Loss: 0.6267
Epoch 2 Step 2751 Train Loss: 0.5930
Epoch 2 Step 2801 Train Loss: 0.5960
Epoch 2 Step 2851 Train Loss: 0.5621
Epoch 2 Step 2901 Train Loss: 0.6494
Epoch 2 Step 2951 Train Loss: 0.6268
Epoch 2 Step 3001 Train Loss: 0.6081
Epoch 2 Step 3051 Train Loss: 0.5734
Epoch 2 Step 3101 Train Loss: 0.6372
Epoch 2 Step 3151 Train Loss: 0.6525
Epoch 2 Step 3201 Train Loss: 0.5713
Epoch 2: Train Overall MSE: 0.0141 Validation Overall MSE: 0.0153. 
Train Top 20 DE MSE: 0.1325 Validation Top 20 DE MSE: 0.1210. 
Epoch 3 Step 1 Train Loss: 0.5576
Epoch 3 Step 51 Train Loss: 0.6251
Epoch 3 Step 101 Train Loss: 0.6241
Epoch 3 Step 151 Train Loss: 0.5927
Epoch 3 Step 201 Train Loss: 0.5978
Epoch 3 Step 251 Train Loss: 0.6124
Epoch 3 Step 301 Train Loss: 0.7048
Epoch 3 Step 351 Train Loss: 0.6352
Epoch 3 Step 401 Train Loss: 0.5646
Epoch 3 Step 451 Train Loss: 0.5848
Epoch 3 Step 501 Train Loss: 0.6183
Epoch 3 Step 551 Train Loss: 0.5872
Epoch 3 Step 601 Train Loss: 0.5831
Epoch 3 Step 651 Train Loss: 0.6877
Epoch 3 Step 701 Train Loss: 0.6063
Epoch 3 Step 751 Train Loss: 0.6150
Epoch 3 Step 801 Train Loss: 0.6466
Epoch 3 Step 851 Train Loss: 0.5450
Epoch 3 Step 901 Train Loss: 0.5795
Epoch 3 Step 951 Train Loss: 0.5930
Epoch 3 Step 1001 Train Loss: 0.5547
Epoch 3 Step 1051 Train Loss: 0.5951
Epoch 3 Step 1101 Train Loss: 0.6059
Epoch 3 Step 1151 Train Loss: 0.6403
Epoch 3 Step 1201 Train Loss: 0.6260
Epoch 3 Step 1251 Train Loss: 0.6068
Epoch 3 Step 1301 Train Loss: 0.5718
Epoch 3 Step 1351 Train Loss: 0.6179
Epoch 3 Step 1401 Train Loss: 0.6098
Epoch 3 Step 1451 Train Loss: 0.5985
Epoch 3 Step 1501 Train Loss: 0.5983
Epoch 3 Step 1551 Train Loss: 0.6322
Epoch 3 Step 1601 Train Loss: 0.5949
Epoch 3 Step 1651 Train Loss: 0.6226
Epoch 3 Step 1701 Train Loss: 0.6425
Epoch 3 Step 1751 Train Loss: 0.5931
Epoch 3 Step 1801 Train Loss: 0.5951
Epoch 3 Step 1851 Train Loss: 0.5922
Epoch 3 Step 1901 Train Loss: 0.6431
Epoch 3 Step 1951 Train Loss: 0.5458
Epoch 3 Step 2001 Train Loss: 0.6247
Epoch 3 Step 2051 Train Loss: 0.5766
Epoch 3 Step 2101 Train Loss: 0.6569
Epoch 3 Step 2151 Train Loss: 0.5956
Epoch 3 Step 2201 Train Loss: 0.6491
Epoch 3 Step 2251 Train Loss: 0.6746
Epoch 3 Step 2301 Train Loss: 0.5882
Epoch 3 Step 2351 Train Loss: 0.6180
Epoch 3 Step 2401 Train Loss: 0.5850
Epoch 3 Step 2451 Train Loss: 0.6110
Epoch 3 Step 2501 Train Loss: 0.5706
Epoch 3 Step 2551 Train Loss: 0.6239
Epoch 3 Step 2601 Train Loss: 0.5889
Epoch 3 Step 2651 Train Loss: 0.5991
Epoch 3 Step 2701 Train Loss: 0.6175
Epoch 3 Step 2751 Train Loss: 0.5901
Epoch 3 Step 2801 Train Loss: 0.5913
Epoch 3 Step 2851 Train Loss: 0.5932
Epoch 3 Step 2901 Train Loss: 0.6497
Epoch 3 Step 2951 Train Loss: 0.5803
Epoch 3 Step 3001 Train Loss: 0.5869
Epoch 3 Step 3051 Train Loss: 0.6030
Epoch 3 Step 3101 Train Loss: 0.6175
Epoch 3 Step 3151 Train Loss: 0.6429
Epoch 3 Step 3201 Train Loss: 0.5701
Epoch 3: Train Overall MSE: 0.0149 Validation Overall MSE: 0.0167. 
Train Top 20 DE MSE: 0.1128 Validation Top 20 DE MSE: 0.1052. 
Epoch 4 Step 1 Train Loss: 0.6109
Epoch 4 Step 51 Train Loss: 0.6044
Epoch 4 Step 101 Train Loss: 0.5887
Epoch 4 Step 151 Train Loss: 0.5510
Epoch 4 Step 201 Train Loss: 0.5999
Epoch 4 Step 251 Train Loss: 0.6078
Epoch 4 Step 301 Train Loss: 0.5394
Epoch 4 Step 351 Train Loss: 0.6391
Epoch 4 Step 401 Train Loss: 0.5998
Epoch 4 Step 451 Train Loss: 0.6350
Epoch 4 Step 501 Train Loss: 0.6000
Epoch 4 Step 551 Train Loss: 0.6146
Epoch 4 Step 601 Train Loss: 0.6341
Epoch 4 Step 651 Train Loss: 0.6051
Epoch 4 Step 701 Train Loss: 0.5807
Epoch 4 Step 751 Train Loss: 0.6083
Epoch 4 Step 801 Train Loss: 0.6219
Epoch 4 Step 851 Train Loss: 0.6136
Epoch 4 Step 901 Train Loss: 0.6404
Epoch 4 Step 951 Train Loss: 0.5806
Epoch 4 Step 1001 Train Loss: 0.5902
Epoch 4 Step 1051 Train Loss: 0.5707
Epoch 4 Step 1101 Train Loss: 0.5908
Epoch 4 Step 1151 Train Loss: 0.6192
Epoch 4 Step 1201 Train Loss: 0.5987
Epoch 4 Step 1251 Train Loss: 0.5776
Epoch 4 Step 1301 Train Loss: 0.5969
Epoch 4 Step 1351 Train Loss: 0.5619
Epoch 4 Step 1401 Train Loss: 0.6229
Epoch 4 Step 1451 Train Loss: 0.5914
Epoch 4 Step 1501 Train Loss: 0.6341
Epoch 4 Step 1551 Train Loss: 0.5952
Epoch 4 Step 1601 Train Loss: 0.6459
Epoch 4 Step 1651 Train Loss: 0.5974
Epoch 4 Step 1701 Train Loss: 0.6488
Epoch 4 Step 1751 Train Loss: 0.6335
Epoch 4 Step 1801 Train Loss: 0.6093
Epoch 4 Step 1851 Train Loss: 0.6164
Epoch 4 Step 1901 Train Loss: 0.5991
Epoch 4 Step 1951 Train Loss: 0.6200
Epoch 4 Step 2001 Train Loss: 0.6834
Epoch 4 Step 2051 Train Loss: 0.5915
Epoch 4 Step 2101 Train Loss: 0.5813
Epoch 4 Step 2151 Train Loss: 0.6281
Epoch 4 Step 2201 Train Loss: 0.5643
Epoch 4 Step 2251 Train Loss: 0.5187
Epoch 4 Step 2301 Train Loss: 0.5956
Epoch 4 Step 2351 Train Loss: 0.6318
Epoch 4 Step 2401 Train Loss: 0.5819
Epoch 4 Step 2451 Train Loss: 0.6057
Epoch 4 Step 2501 Train Loss: 0.5861
Epoch 4 Step 2551 Train Loss: 0.5911
Epoch 4 Step 2601 Train Loss: 0.5875
Epoch 4 Step 2651 Train Loss: 0.5969
Epoch 4 Step 2701 Train Loss: 0.6049
Epoch 4 Step 2751 Train Loss: 0.6616
Epoch 4 Step 2801 Train Loss: 0.5757
Epoch 4 Step 2851 Train Loss: 0.6017
Epoch 4 Step 2901 Train Loss: 0.5848
Epoch 4 Step 2951 Train Loss: 0.6752
Epoch 4 Step 3001 Train Loss: 0.5988
Epoch 4 Step 3051 Train Loss: 0.5953
Epoch 4 Step 3101 Train Loss: 0.6092
Epoch 4 Step 3151 Train Loss: 0.6051
Epoch 4 Step 3201 Train Loss: 0.5693
Epoch 4: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0146. 
Train Top 20 DE MSE: 0.1221 Validation Top 20 DE MSE: 0.1123. 
Epoch 5 Step 1 Train Loss: 0.6485
Epoch 5 Step 51 Train Loss: 0.5596
Epoch 5 Step 101 Train Loss: 0.6435
Epoch 5 Step 151 Train Loss: 0.6030
Epoch 5 Step 201 Train Loss: 0.5946
Epoch 5 Step 251 Train Loss: 0.6386
Epoch 5 Step 301 Train Loss: 0.5605
Epoch 5 Step 351 Train Loss: 0.5883
Epoch 5 Step 401 Train Loss: 0.6322
Epoch 5 Step 451 Train Loss: 0.6625
Epoch 5 Step 501 Train Loss: 0.6337
Epoch 5 Step 551 Train Loss: 0.6008
Epoch 5 Step 601 Train Loss: 0.6015
Epoch 5 Step 651 Train Loss: 0.6082
Epoch 5 Step 701 Train Loss: 0.5980
Epoch 5 Step 751 Train Loss: 0.6322
Epoch 5 Step 801 Train Loss: 0.6340
Epoch 5 Step 851 Train Loss: 0.5338
Epoch 5 Step 901 Train Loss: 0.5791
Epoch 5 Step 951 Train Loss: 0.5615
Epoch 5 Step 1001 Train Loss: 0.5789
Epoch 5 Step 1051 Train Loss: 0.5894
Epoch 5 Step 1101 Train Loss: 0.5685
Epoch 5 Step 1151 Train Loss: 0.5881
Epoch 5 Step 1201 Train Loss: 0.5796
Epoch 5 Step 1251 Train Loss: 0.5697
Epoch 5 Step 1301 Train Loss: 0.6073
Epoch 5 Step 1351 Train Loss: 0.5466
Epoch 5 Step 1401 Train Loss: 0.5942
Epoch 5 Step 1451 Train Loss: 0.5694
Epoch 5 Step 1501 Train Loss: 0.6230
Epoch 5 Step 1551 Train Loss: 0.5737
Epoch 5 Step 1601 Train Loss: 0.5838
Epoch 5 Step 1651 Train Loss: 0.6171
Epoch 5 Step 1701 Train Loss: 0.5853
Epoch 5 Step 1751 Train Loss: 0.5560
Epoch 5 Step 1801 Train Loss: 0.6163
Epoch 5 Step 1851 Train Loss: 0.5760
Epoch 5 Step 1901 Train Loss: 0.6026
Epoch 5 Step 1951 Train Loss: 0.5740
Epoch 5 Step 2001 Train Loss: 0.5665
Epoch 5 Step 2051 Train Loss: 0.5373
Epoch 5 Step 2101 Train Loss: 0.5646
Epoch 5 Step 2151 Train Loss: 0.6167
Epoch 5 Step 2201 Train Loss: 0.5538
Epoch 5 Step 2251 Train Loss: 0.6214
Epoch 5 Step 2301 Train Loss: 0.5587
Epoch 5 Step 2351 Train Loss: 0.6096
Epoch 5 Step 2401 Train Loss: 0.6571
Epoch 5 Step 2451 Train Loss: 0.6329
Epoch 5 Step 2501 Train Loss: 0.6059
Epoch 5 Step 2551 Train Loss: 0.5656
Epoch 5 Step 2601 Train Loss: 0.5844
Epoch 5 Step 2651 Train Loss: 0.5935
Epoch 5 Step 2701 Train Loss: 0.6240
Epoch 5 Step 2751 Train Loss: 0.6202
Epoch 5 Step 2801 Train Loss: 0.5697
Epoch 5 Step 2851 Train Loss: 0.6182
Epoch 5 Step 2901 Train Loss: 0.6127
Epoch 5 Step 2951 Train Loss: 0.5948
Epoch 5 Step 3001 Train Loss: 0.5683
Epoch 5 Step 3051 Train Loss: 0.6306
Epoch 5 Step 3101 Train Loss: 0.6063
Epoch 5 Step 3151 Train Loss: 0.5992
Epoch 5 Step 3201 Train Loss: 0.5875
Epoch 5: Train Overall MSE: 0.0129 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1221 Validation Top 20 DE MSE: 0.1119. 
Epoch 6 Step 1 Train Loss: 0.6394
Epoch 6 Step 51 Train Loss: 0.5633
Epoch 6 Step 101 Train Loss: 0.5213
Epoch 6 Step 151 Train Loss: 0.6448
Epoch 6 Step 201 Train Loss: 0.6689
Epoch 6 Step 251 Train Loss: 0.6239
Epoch 6 Step 301 Train Loss: 0.5611
Epoch 6 Step 351 Train Loss: 0.6230
Epoch 6 Step 401 Train Loss: 0.6085
Epoch 6 Step 451 Train Loss: 0.5742
Epoch 6 Step 501 Train Loss: 0.6101
Epoch 6 Step 551 Train Loss: 0.6303
Epoch 6 Step 601 Train Loss: 0.6545
Epoch 6 Step 651 Train Loss: 0.5710
Epoch 6 Step 701 Train Loss: 0.5746
Epoch 6 Step 751 Train Loss: 0.6047
Epoch 6 Step 801 Train Loss: 0.6267
Epoch 6 Step 851 Train Loss: 0.6076
Epoch 6 Step 901 Train Loss: 0.5771
Epoch 6 Step 951 Train Loss: 0.5576
Epoch 6 Step 1001 Train Loss: 0.6038
Epoch 6 Step 1051 Train Loss: 0.6265
Epoch 6 Step 1101 Train Loss: 0.6081
Epoch 6 Step 1151 Train Loss: 0.5944
Epoch 6 Step 1201 Train Loss: 0.6190
Epoch 6 Step 1251 Train Loss: 0.5897
Epoch 6 Step 1301 Train Loss: 0.5378
Epoch 6 Step 1351 Train Loss: 0.6209
Epoch 6 Step 1401 Train Loss: 0.6647
Epoch 6 Step 1451 Train Loss: 0.5707
Epoch 6 Step 1501 Train Loss: 0.6368
Epoch 6 Step 1551 Train Loss: 0.5581
Epoch 6 Step 1601 Train Loss: 0.5800
Epoch 6 Step 1651 Train Loss: 0.5250
Epoch 6 Step 1701 Train Loss: 0.5612
Epoch 6 Step 1751 Train Loss: 0.6475
Epoch 6 Step 1801 Train Loss: 0.5608
Epoch 6 Step 1851 Train Loss: 0.5559
Epoch 6 Step 1901 Train Loss: 0.5676
Epoch 6 Step 1951 Train Loss: 0.5990
Epoch 6 Step 2001 Train Loss: 0.6141
Epoch 6 Step 2051 Train Loss: 0.5868
Epoch 6 Step 2101 Train Loss: 0.5418
Epoch 6 Step 2151 Train Loss: 0.5229
Epoch 6 Step 2201 Train Loss: 0.5896
Epoch 6 Step 2251 Train Loss: 0.5943
Epoch 6 Step 2301 Train Loss: 0.6294
Epoch 6 Step 2351 Train Loss: 0.6365
Epoch 6 Step 2401 Train Loss: 0.5866
Epoch 6 Step 2451 Train Loss: 0.6425
Epoch 6 Step 2501 Train Loss: 0.6014
Epoch 6 Step 2551 Train Loss: 0.5768
Epoch 6 Step 2601 Train Loss: 0.5793
Epoch 6 Step 2651 Train Loss: 0.6445
Epoch 6 Step 2701 Train Loss: 0.5642
Epoch 6 Step 2751 Train Loss: 0.6112
Epoch 6 Step 2801 Train Loss: 0.5637
Epoch 6 Step 2851 Train Loss: 0.6000
Epoch 6 Step 2901 Train Loss: 0.5671
Epoch 6 Step 2951 Train Loss: 0.5941
Epoch 6 Step 3001 Train Loss: 0.6296
Epoch 6 Step 3051 Train Loss: 0.5820
Epoch 6 Step 3101 Train Loss: 0.6580
Epoch 6 Step 3151 Train Loss: 0.5865
Epoch 6 Step 3201 Train Loss: 0.6343
Epoch 6: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1195 Validation Top 20 DE MSE: 0.1098. 
Epoch 7 Step 1 Train Loss: 0.5992
Epoch 7 Step 51 Train Loss: 0.5977
Epoch 7 Step 101 Train Loss: 0.5824
Epoch 7 Step 151 Train Loss: 0.6631
Epoch 7 Step 201 Train Loss: 0.6265
Epoch 7 Step 251 Train Loss: 0.5907
Epoch 7 Step 301 Train Loss: 0.5952
Epoch 7 Step 351 Train Loss: 0.5994
Epoch 7 Step 401 Train Loss: 0.5788
Epoch 7 Step 451 Train Loss: 0.5452
Epoch 7 Step 501 Train Loss: 0.5882
Epoch 7 Step 551 Train Loss: 0.5700
Epoch 7 Step 601 Train Loss: 0.5567
Epoch 7 Step 651 Train Loss: 0.5913
Epoch 7 Step 701 Train Loss: 0.6094
Epoch 7 Step 751 Train Loss: 0.5769
Epoch 7 Step 801 Train Loss: 0.5539
Epoch 7 Step 851 Train Loss: 0.5953
Epoch 7 Step 901 Train Loss: 0.6123
Epoch 7 Step 951 Train Loss: 0.6106
Epoch 7 Step 1001 Train Loss: 0.6073
Epoch 7 Step 1051 Train Loss: 0.6087
Epoch 7 Step 1101 Train Loss: 0.6016
Epoch 7 Step 1151 Train Loss: 0.6643
Epoch 7 Step 1201 Train Loss: 0.5932
Epoch 7 Step 1251 Train Loss: 0.5768
Epoch 7 Step 1301 Train Loss: 0.5952
Epoch 7 Step 1351 Train Loss: 0.5683
Epoch 7 Step 1401 Train Loss: 0.6312
Epoch 7 Step 1451 Train Loss: 0.6511
Epoch 7 Step 1501 Train Loss: 0.5984
Epoch 7 Step 1551 Train Loss: 0.5633
Epoch 7 Step 1601 Train Loss: 0.6395
Epoch 7 Step 1651 Train Loss: 0.6637
Epoch 7 Step 1701 Train Loss: 0.6423
Epoch 7 Step 1751 Train Loss: 0.6648
Epoch 7 Step 1801 Train Loss: 0.5604
Epoch 7 Step 1851 Train Loss: 0.5238
Epoch 7 Step 1901 Train Loss: 0.6473
Epoch 7 Step 1951 Train Loss: 0.6149
Epoch 7 Step 2001 Train Loss: 0.6030
Epoch 7 Step 2051 Train Loss: 0.6179
Epoch 7 Step 2101 Train Loss: 0.5876
Epoch 7 Step 2151 Train Loss: 0.6028
Epoch 7 Step 2201 Train Loss: 0.6207
Epoch 7 Step 2251 Train Loss: 0.5945
Epoch 7 Step 2301 Train Loss: 0.5644
Epoch 7 Step 2351 Train Loss: 0.6370
Epoch 7 Step 2401 Train Loss: 0.5899
Epoch 7 Step 2451 Train Loss: 0.6201
Epoch 7 Step 2501 Train Loss: 0.5933
Epoch 7 Step 2551 Train Loss: 0.6467
Epoch 7 Step 2601 Train Loss: 0.5790
Epoch 7 Step 2651 Train Loss: 0.6421
Epoch 7 Step 2701 Train Loss: 0.5906
Epoch 7 Step 2751 Train Loss: 0.5389
Epoch 7 Step 2801 Train Loss: 0.6459
Epoch 7 Step 2851 Train Loss: 0.5930
Epoch 7 Step 2901 Train Loss: 0.5786
Epoch 7 Step 2951 Train Loss: 0.6226
Epoch 7 Step 3001 Train Loss: 0.6227
Epoch 7 Step 3051 Train Loss: 0.6646
Epoch 7 Step 3101 Train Loss: 0.6524
Epoch 7 Step 3151 Train Loss: 0.5976
Epoch 7 Step 3201 Train Loss: 0.5462
Epoch 7: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1190 Validation Top 20 DE MSE: 0.1098. 
Epoch 8 Step 1 Train Loss: 0.6187
Epoch 8 Step 51 Train Loss: 0.5498
Epoch 8 Step 101 Train Loss: 0.5444
Epoch 8 Step 151 Train Loss: 0.5580
Epoch 8 Step 201 Train Loss: 0.5555
Epoch 8 Step 251 Train Loss: 0.5524
Epoch 8 Step 301 Train Loss: 0.5825
Epoch 8 Step 351 Train Loss: 0.5015
Epoch 8 Step 401 Train Loss: 0.5831
Epoch 8 Step 451 Train Loss: 0.5501
Epoch 8 Step 501 Train Loss: 0.6477
Epoch 8 Step 551 Train Loss: 0.5683
Epoch 8 Step 601 Train Loss: 0.6141
Epoch 8 Step 651 Train Loss: 0.6062
Epoch 8 Step 701 Train Loss: 0.6456
Epoch 8 Step 751 Train Loss: 0.5529
Epoch 8 Step 801 Train Loss: 0.5705
Epoch 8 Step 851 Train Loss: 0.5730
Epoch 8 Step 901 Train Loss: 0.5882
Epoch 8 Step 951 Train Loss: 0.6610
Epoch 8 Step 1001 Train Loss: 0.5866
Epoch 8 Step 1051 Train Loss: 0.6422
Epoch 8 Step 1101 Train Loss: 0.5793
Epoch 8 Step 1151 Train Loss: 0.6238
Epoch 8 Step 1201 Train Loss: 0.6181
Epoch 8 Step 1251 Train Loss: 0.5408
Epoch 8 Step 1301 Train Loss: 0.5783
Epoch 8 Step 1351 Train Loss: 0.6453
Epoch 8 Step 1401 Train Loss: 0.6172
Epoch 8 Step 1451 Train Loss: 0.5936
Epoch 8 Step 1501 Train Loss: 0.6599
Epoch 8 Step 1551 Train Loss: 0.6268
Epoch 8 Step 1601 Train Loss: 0.5976
Epoch 8 Step 1651 Train Loss: 0.6350
Epoch 8 Step 1701 Train Loss: 0.5977
Epoch 8 Step 1751 Train Loss: 0.6431
Epoch 8 Step 1801 Train Loss: 0.5896
Epoch 8 Step 1851 Train Loss: 0.5890
Epoch 8 Step 1901 Train Loss: 0.6041
Epoch 8 Step 1951 Train Loss: 0.6162
Epoch 8 Step 2001 Train Loss: 0.5818
Epoch 8 Step 2051 Train Loss: 0.5775
Epoch 8 Step 2101 Train Loss: 0.6087
Epoch 8 Step 2151 Train Loss: 0.5514
Epoch 8 Step 2201 Train Loss: 0.6439
Epoch 8 Step 2251 Train Loss: 0.5992
Epoch 8 Step 2301 Train Loss: 0.5940
Epoch 8 Step 2351 Train Loss: 0.6170
Epoch 8 Step 2401 Train Loss: 0.5637
Epoch 8 Step 2451 Train Loss: 0.6495
Epoch 8 Step 2501 Train Loss: 0.5631
Epoch 8 Step 2551 Train Loss: 0.5522
Epoch 8 Step 2601 Train Loss: 0.5711
Epoch 8 Step 2651 Train Loss: 0.5684
Epoch 8 Step 2701 Train Loss: 0.5970
Epoch 8 Step 2751 Train Loss: 0.6402
Epoch 8 Step 2801 Train Loss: 0.5944
Epoch 8 Step 2851 Train Loss: 0.5511
Epoch 8 Step 2901 Train Loss: 0.6050
Epoch 8 Step 2951 Train Loss: 0.5561
Epoch 8 Step 3001 Train Loss: 0.5952
Epoch 8 Step 3051 Train Loss: 0.6037
Epoch 8 Step 3101 Train Loss: 0.5863
Epoch 8 Step 3151 Train Loss: 0.6362
Epoch 8 Step 3201 Train Loss: 0.6281
Epoch 8: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1216 Validation Top 20 DE MSE: 0.1114. 
Epoch 9 Step 1 Train Loss: 0.6478
Epoch 9 Step 51 Train Loss: 0.5795
Epoch 9 Step 101 Train Loss: 0.6128
Epoch 9 Step 151 Train Loss: 0.5529
Epoch 9 Step 201 Train Loss: 0.6148
Epoch 9 Step 251 Train Loss: 0.6076
Epoch 9 Step 301 Train Loss: 0.6026
Epoch 9 Step 351 Train Loss: 0.5994
Epoch 9 Step 401 Train Loss: 0.6235
Epoch 9 Step 451 Train Loss: 0.5856
Epoch 9 Step 501 Train Loss: 0.5692
Epoch 9 Step 551 Train Loss: 0.5825
Epoch 9 Step 601 Train Loss: 0.6270
Epoch 9 Step 651 Train Loss: 0.6365
Epoch 9 Step 701 Train Loss: 0.6620
Epoch 9 Step 751 Train Loss: 0.5962
Epoch 9 Step 801 Train Loss: 0.6414
Epoch 9 Step 851 Train Loss: 0.6083
Epoch 9 Step 901 Train Loss: 0.5760
Epoch 9 Step 951 Train Loss: 0.6044
Epoch 9 Step 1001 Train Loss: 0.6309
Epoch 9 Step 1051 Train Loss: 0.6322
Epoch 9 Step 1101 Train Loss: 0.5675
Epoch 9 Step 1151 Train Loss: 0.6592
Epoch 9 Step 1201 Train Loss: 0.6157
Epoch 9 Step 1251 Train Loss: 0.5919
Epoch 9 Step 1301 Train Loss: 0.5853
Epoch 9 Step 1351 Train Loss: 0.6252
Epoch 9 Step 1401 Train Loss: 0.5762
Epoch 9 Step 1451 Train Loss: 0.6178
Epoch 9 Step 1501 Train Loss: 0.5752
Epoch 9 Step 1551 Train Loss: 0.6319
Epoch 9 Step 1601 Train Loss: 0.5449
Epoch 9 Step 1651 Train Loss: 0.5850
Epoch 9 Step 1701 Train Loss: 0.6232
Epoch 9 Step 1751 Train Loss: 0.6075
Epoch 9 Step 1801 Train Loss: 0.6148
Epoch 9 Step 1851 Train Loss: 0.6357
Epoch 9 Step 1901 Train Loss: 0.6140
Epoch 9 Step 1951 Train Loss: 0.5851
Epoch 9 Step 2001 Train Loss: 0.6712
Epoch 9 Step 2051 Train Loss: 0.5825
Epoch 9 Step 2101 Train Loss: 0.5830
Epoch 9 Step 2151 Train Loss: 0.6193
Epoch 9 Step 2201 Train Loss: 0.5636
Epoch 9 Step 2251 Train Loss: 0.6056
Epoch 9 Step 2301 Train Loss: 0.5558
Epoch 9 Step 2351 Train Loss: 0.6305
Epoch 9 Step 2401 Train Loss: 0.5758
Epoch 9 Step 2451 Train Loss: 0.5699
Epoch 9 Step 2501 Train Loss: 0.5706
Epoch 9 Step 2551 Train Loss: 0.5525
Epoch 9 Step 2601 Train Loss: 0.5752
Epoch 9 Step 2651 Train Loss: 0.5980
Epoch 9 Step 2701 Train Loss: 0.5649
Epoch 9 Step 2751 Train Loss: 0.5791
Epoch 9 Step 2801 Train Loss: 0.5870
Epoch 9 Step 2851 Train Loss: 0.6549
Epoch 9 Step 2901 Train Loss: 0.5943
Epoch 9 Step 2951 Train Loss: 0.6057
Epoch 9 Step 3001 Train Loss: 0.6129
Epoch 9 Step 3051 Train Loss: 0.6083
Epoch 9 Step 3101 Train Loss: 0.6146
Epoch 9 Step 3151 Train Loss: 0.5709
Epoch 9 Step 3201 Train Loss: 0.5939
Epoch 9: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1206 Validation Top 20 DE MSE: 0.1111. 
Epoch 10 Step 1 Train Loss: 0.6411
Epoch 10 Step 51 Train Loss: 0.6164
Epoch 10 Step 101 Train Loss: 0.6341
Epoch 10 Step 151 Train Loss: 0.5626
Epoch 10 Step 201 Train Loss: 0.6308
Epoch 10 Step 251 Train Loss: 0.5654
Epoch 10 Step 301 Train Loss: 0.5871
Epoch 10 Step 351 Train Loss: 0.5818
Epoch 10 Step 401 Train Loss: 0.5515
Epoch 10 Step 451 Train Loss: 0.5980
Epoch 10 Step 501 Train Loss: 0.6692
Epoch 10 Step 551 Train Loss: 0.5779
Epoch 10 Step 601 Train Loss: 0.5886
Epoch 10 Step 651 Train Loss: 0.5791
Epoch 10 Step 701 Train Loss: 0.5730
Epoch 10 Step 751 Train Loss: 0.6041
Epoch 10 Step 801 Train Loss: 0.5841
Epoch 10 Step 851 Train Loss: 0.6358
Epoch 10 Step 901 Train Loss: 0.5503
Epoch 10 Step 951 Train Loss: 0.5925
Epoch 10 Step 1001 Train Loss: 0.6086
Epoch 10 Step 1051 Train Loss: 0.5352
Epoch 10 Step 1101 Train Loss: 0.5647
Epoch 10 Step 1151 Train Loss: 0.6364
Epoch 10 Step 1201 Train Loss: 0.6148
Epoch 10 Step 1251 Train Loss: 0.6117
Epoch 10 Step 1301 Train Loss: 0.5534
Epoch 10 Step 1351 Train Loss: 0.5176
Epoch 10 Step 1401 Train Loss: 0.5756
Epoch 10 Step 1451 Train Loss: 0.5747
Epoch 10 Step 1501 Train Loss: 0.6032
Epoch 10 Step 1551 Train Loss: 0.6389
Epoch 10 Step 1601 Train Loss: 0.5858
Epoch 10 Step 1651 Train Loss: 0.5309
Epoch 10 Step 1701 Train Loss: 0.5132
Epoch 10 Step 1751 Train Loss: 0.6500
Epoch 10 Step 1801 Train Loss: 0.5936
Epoch 10 Step 1851 Train Loss: 0.5316
Epoch 10 Step 1901 Train Loss: 0.5590
Epoch 10 Step 1951 Train Loss: 0.5860
Epoch 10 Step 2001 Train Loss: 0.5837
Epoch 10 Step 2051 Train Loss: 0.6217
Epoch 10 Step 2101 Train Loss: 0.6243
Epoch 10 Step 2151 Train Loss: 0.5713
Epoch 10 Step 2201 Train Loss: 0.6388
Epoch 10 Step 2251 Train Loss: 0.6160
Epoch 10 Step 2301 Train Loss: 0.6142
Epoch 10 Step 2351 Train Loss: 0.5630
Epoch 10 Step 2401 Train Loss: 0.6006
Epoch 10 Step 2451 Train Loss: 0.6075
Epoch 10 Step 2501 Train Loss: 0.5490
Epoch 10 Step 2551 Train Loss: 0.5598
Epoch 10 Step 2601 Train Loss: 0.6490
Epoch 10 Step 2651 Train Loss: 0.5883
Epoch 10 Step 2701 Train Loss: 0.6253
Epoch 10 Step 2751 Train Loss: 0.6216
Epoch 10 Step 2801 Train Loss: 0.5830
Epoch 10 Step 2851 Train Loss: 0.5940
Epoch 10 Step 2901 Train Loss: 0.6143
Epoch 10 Step 2951 Train Loss: 0.6073
Epoch 10 Step 3001 Train Loss: 0.5686
Epoch 10 Step 3051 Train Loss: 0.6549
Epoch 10 Step 3101 Train Loss: 0.5982
Epoch 10 Step 3151 Train Loss: 0.5712
Epoch 10 Step 3201 Train Loss: 0.6020
Epoch 10: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0144. 
Train Top 20 DE MSE: 0.1205 Validation Top 20 DE MSE: 0.1107. 
Epoch 11 Step 1 Train Loss: 0.5678
Epoch 11 Step 51 Train Loss: 0.5337
Epoch 11 Step 101 Train Loss: 0.6023
Epoch 11 Step 151 Train Loss: 0.5311
Epoch 11 Step 201 Train Loss: 0.6136
Epoch 11 Step 251 Train Loss: 0.5893
Epoch 11 Step 301 Train Loss: 0.6428
Epoch 11 Step 351 Train Loss: 0.5965
Epoch 11 Step 401 Train Loss: 0.5730
Epoch 11 Step 451 Train Loss: 0.6571
Epoch 11 Step 501 Train Loss: 0.6032
Epoch 11 Step 551 Train Loss: 0.5820
Epoch 11 Step 601 Train Loss: 0.5500
Epoch 11 Step 651 Train Loss: 0.5624
Epoch 11 Step 701 Train Loss: 0.6040
Epoch 11 Step 751 Train Loss: 0.5896
Epoch 11 Step 801 Train Loss: 0.5847
Epoch 11 Step 851 Train Loss: 0.6438
Epoch 11 Step 901 Train Loss: 0.7208
Epoch 11 Step 951 Train Loss: 0.5779
Epoch 11 Step 1001 Train Loss: 0.7018
Epoch 11 Step 1051 Train Loss: 0.6092
Epoch 11 Step 1101 Train Loss: 0.6062
Epoch 11 Step 1151 Train Loss: 0.5908
Epoch 11 Step 1201 Train Loss: 0.5622
Epoch 11 Step 1251 Train Loss: 0.5780
Epoch 11 Step 1301 Train Loss: 0.6079
Epoch 11 Step 1351 Train Loss: 0.5572
Epoch 11 Step 1401 Train Loss: 0.5847
Epoch 11 Step 1451 Train Loss: 0.5791
Epoch 11 Step 1501 Train Loss: 0.5945
Epoch 11 Step 1551 Train Loss: 0.5713
Epoch 11 Step 1601 Train Loss: 0.6116
Epoch 11 Step 1651 Train Loss: 0.6409
Epoch 11 Step 1701 Train Loss: 0.5828
Epoch 11 Step 1751 Train Loss: 0.5849
Epoch 11 Step 1801 Train Loss: 0.5906
Epoch 11 Step 1851 Train Loss: 0.6531
Epoch 11 Step 1901 Train Loss: 0.6041
Epoch 11 Step 1951 Train Loss: 0.6025
Epoch 11 Step 2001 Train Loss: 0.6232
Epoch 11 Step 2051 Train Loss: 0.5565
Epoch 11 Step 2101 Train Loss: 0.5853
Epoch 11 Step 2151 Train Loss: 0.5931
Epoch 11 Step 2201 Train Loss: 0.5895
Epoch 11 Step 2251 Train Loss: 0.5761
Epoch 11 Step 2301 Train Loss: 0.5889
Epoch 11 Step 2351 Train Loss: 0.6228
Epoch 11 Step 2401 Train Loss: 0.5793
Epoch 11 Step 2451 Train Loss: 0.6153
Epoch 11 Step 2501 Train Loss: 0.5526
Epoch 11 Step 2551 Train Loss: 0.5653
Epoch 11 Step 2601 Train Loss: 0.6255
Epoch 11 Step 2651 Train Loss: 0.5661
Epoch 11 Step 2701 Train Loss: 0.6159
Epoch 11 Step 2751 Train Loss: 0.5772
Epoch 11 Step 2801 Train Loss: 0.5988
Epoch 11 Step 2851 Train Loss: 0.5787
Epoch 11 Step 2901 Train Loss: 0.6309
Epoch 11 Step 2951 Train Loss: 0.6246
Epoch 11 Step 3001 Train Loss: 0.6205
Epoch 11 Step 3051 Train Loss: 0.6513
Epoch 11 Step 3101 Train Loss: 0.6026
Epoch 11 Step 3151 Train Loss: 0.5750
Epoch 11 Step 3201 Train Loss: 0.5809
Epoch 11: Train Overall MSE: 0.0129 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1229 Validation Top 20 DE MSE: 0.1122. 
Epoch 12 Step 1 Train Loss: 0.5291
Epoch 12 Step 51 Train Loss: 0.6170
Epoch 12 Step 101 Train Loss: 0.5577
Epoch 12 Step 151 Train Loss: 0.6220
Epoch 12 Step 201 Train Loss: 0.6301
Epoch 12 Step 251 Train Loss: 0.6706
Epoch 12 Step 301 Train Loss: 0.6215
Epoch 12 Step 351 Train Loss: 0.6191
Epoch 12 Step 401 Train Loss: 0.5442
Epoch 12 Step 451 Train Loss: 0.5673
Epoch 12 Step 501 Train Loss: 0.6495
Epoch 12 Step 551 Train Loss: 0.5790
Epoch 12 Step 601 Train Loss: 0.5802
Epoch 12 Step 651 Train Loss: 0.5981
Epoch 12 Step 701 Train Loss: 0.6153
Epoch 12 Step 751 Train Loss: 0.5932
Epoch 12 Step 801 Train Loss: 0.5540
Epoch 12 Step 851 Train Loss: 0.6014
Epoch 12 Step 901 Train Loss: 0.6110
Epoch 12 Step 951 Train Loss: 0.6382
Epoch 12 Step 1001 Train Loss: 0.5917
Epoch 12 Step 1051 Train Loss: 0.5943
Epoch 12 Step 1101 Train Loss: 0.5986
Epoch 12 Step 1151 Train Loss: 0.6715
Epoch 12 Step 1201 Train Loss: 0.5837
Epoch 12 Step 1251 Train Loss: 0.5632
Epoch 12 Step 1301 Train Loss: 0.5380
Epoch 12 Step 1351 Train Loss: 0.5825
Epoch 12 Step 1401 Train Loss: 0.5951
Epoch 12 Step 1451 Train Loss: 0.5594
Epoch 12 Step 1501 Train Loss: 0.5986
Epoch 12 Step 1551 Train Loss: 0.6236
Epoch 12 Step 1601 Train Loss: 0.6410
Epoch 12 Step 1651 Train Loss: 0.6246
Epoch 12 Step 1701 Train Loss: 0.5925
Epoch 12 Step 1751 Train Loss: 0.6167
Epoch 12 Step 1801 Train Loss: 0.5918
Epoch 12 Step 1851 Train Loss: 0.6020
Epoch 12 Step 1901 Train Loss: 0.6007
Epoch 12 Step 1951 Train Loss: 0.6334
Epoch 12 Step 2001 Train Loss: 0.6296
Epoch 12 Step 2051 Train Loss: 0.5634
Epoch 12 Step 2101 Train Loss: 0.6215
Epoch 12 Step 2151 Train Loss: 0.6172
Epoch 12 Step 2201 Train Loss: 0.5834
Epoch 12 Step 2251 Train Loss: 0.5685
Epoch 12 Step 2301 Train Loss: 0.6015
Epoch 12 Step 2351 Train Loss: 0.5919
Epoch 12 Step 2401 Train Loss: 0.5294
Epoch 12 Step 2451 Train Loss: 0.5876
Epoch 12 Step 2501 Train Loss: 0.6041
Epoch 12 Step 2551 Train Loss: 0.5780
Epoch 12 Step 2601 Train Loss: 0.6752
Epoch 12 Step 2651 Train Loss: 0.6084
Epoch 12 Step 2701 Train Loss: 0.6429
Epoch 12 Step 2751 Train Loss: 0.5525
Epoch 12 Step 2801 Train Loss: 0.5729
Epoch 12 Step 2851 Train Loss: 0.5929
Epoch 12 Step 2901 Train Loss: 0.5722
Epoch 12 Step 2951 Train Loss: 0.7142
Epoch 12 Step 3001 Train Loss: 0.5595
Epoch 12 Step 3051 Train Loss: 0.6680
Epoch 12 Step 3101 Train Loss: 0.6299
Epoch 12 Step 3151 Train Loss: 0.5763
Epoch 12 Step 3201 Train Loss: 0.6165
Epoch 12: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1200 Validation Top 20 DE MSE: 0.1106. 
Epoch 13 Step 1 Train Loss: 0.6365
Epoch 13 Step 51 Train Loss: 0.5367
Epoch 13 Step 101 Train Loss: 0.6844
Epoch 13 Step 151 Train Loss: 0.5491
Epoch 13 Step 201 Train Loss: 0.5767
Epoch 13 Step 251 Train Loss: 0.6735
Epoch 13 Step 301 Train Loss: 0.5812
Epoch 13 Step 351 Train Loss: 0.6371
Epoch 13 Step 401 Train Loss: 0.6026
Epoch 13 Step 451 Train Loss: 0.5822
Epoch 13 Step 501 Train Loss: 0.6016
Epoch 13 Step 551 Train Loss: 0.6119
Epoch 13 Step 601 Train Loss: 0.6179
Epoch 13 Step 651 Train Loss: 0.5775
Epoch 13 Step 701 Train Loss: 0.6010
Epoch 13 Step 751 Train Loss: 0.6307
Epoch 13 Step 801 Train Loss: 0.5569
Epoch 13 Step 851 Train Loss: 0.5544
Epoch 13 Step 901 Train Loss: 0.5609
Epoch 13 Step 951 Train Loss: 0.6148
Epoch 13 Step 1001 Train Loss: 0.5494
Epoch 13 Step 1051 Train Loss: 0.6434
Epoch 13 Step 1101 Train Loss: 0.5914
Epoch 13 Step 1151 Train Loss: 0.6433
Epoch 13 Step 1201 Train Loss: 0.5823
Epoch 13 Step 1251 Train Loss: 0.5557
Epoch 13 Step 1301 Train Loss: 0.6142
Epoch 13 Step 1351 Train Loss: 0.6107
Epoch 13 Step 1401 Train Loss: 0.5864
Epoch 13 Step 1451 Train Loss: 0.6551
Epoch 13 Step 1501 Train Loss: 0.6242
Epoch 13 Step 1551 Train Loss: 0.5803
Epoch 13 Step 1601 Train Loss: 0.5735
Epoch 13 Step 1651 Train Loss: 0.6133
Epoch 13 Step 1701 Train Loss: 0.5786
Epoch 13 Step 1751 Train Loss: 0.5784
Epoch 13 Step 1801 Train Loss: 0.5877
Epoch 13 Step 1851 Train Loss: 0.5909
Epoch 13 Step 1901 Train Loss: 0.5890
Epoch 13 Step 1951 Train Loss: 0.6542
Epoch 13 Step 2001 Train Loss: 0.5939
Epoch 13 Step 2051 Train Loss: 0.5919
Epoch 13 Step 2101 Train Loss: 0.5751
Epoch 13 Step 2151 Train Loss: 0.5468
Epoch 13 Step 2201 Train Loss: 0.6589
Epoch 13 Step 2251 Train Loss: 0.5706
Epoch 13 Step 2301 Train Loss: 0.5542
Epoch 13 Step 2351 Train Loss: 0.6284
Epoch 13 Step 2401 Train Loss: 0.5871
Epoch 13 Step 2451 Train Loss: 0.5966
Epoch 13 Step 2501 Train Loss: 0.6424
Epoch 13 Step 2551 Train Loss: 0.5605
Epoch 13 Step 2601 Train Loss: 0.6658
Epoch 13 Step 2651 Train Loss: 0.6149
Epoch 13 Step 2701 Train Loss: 0.6096
Epoch 13 Step 2751 Train Loss: 0.5882
Epoch 13 Step 2801 Train Loss: 0.6496
Epoch 13 Step 2851 Train Loss: 0.6078
Epoch 13 Step 2901 Train Loss: 0.6300
Epoch 13 Step 2951 Train Loss: 0.5786
Epoch 13 Step 3001 Train Loss: 0.5791
Epoch 13 Step 3051 Train Loss: 0.6480
Epoch 13 Step 3101 Train Loss: 0.5561
Epoch 13 Step 3151 Train Loss: 0.5633
Epoch 13 Step 3201 Train Loss: 0.5988
Epoch 13: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1212 Validation Top 20 DE MSE: 0.1114. 
Epoch 14 Step 1 Train Loss: 0.5367
Epoch 14 Step 51 Train Loss: 0.6204
Epoch 14 Step 101 Train Loss: 0.6241
Epoch 14 Step 151 Train Loss: 0.5252
Epoch 14 Step 201 Train Loss: 0.6137
Epoch 14 Step 251 Train Loss: 0.5849
Epoch 14 Step 301 Train Loss: 0.6312
Epoch 14 Step 351 Train Loss: 0.6020
Epoch 14 Step 401 Train Loss: 0.5658
Epoch 14 Step 451 Train Loss: 0.6070
Epoch 14 Step 501 Train Loss: 0.5584
Epoch 14 Step 551 Train Loss: 0.6489
Epoch 14 Step 601 Train Loss: 0.5760
Epoch 14 Step 651 Train Loss: 0.6373
Epoch 14 Step 701 Train Loss: 0.5820
Epoch 14 Step 751 Train Loss: 0.5575
Epoch 14 Step 801 Train Loss: 0.5504
Epoch 14 Step 851 Train Loss: 0.5710
Epoch 14 Step 901 Train Loss: 0.6264
Epoch 14 Step 951 Train Loss: 0.5821
Epoch 14 Step 1001 Train Loss: 0.5983
Epoch 14 Step 1051 Train Loss: 0.6097
Epoch 14 Step 1101 Train Loss: 0.6546
Epoch 14 Step 1151 Train Loss: 0.6111
Epoch 14 Step 1201 Train Loss: 0.6159
Epoch 14 Step 1251 Train Loss: 0.6652
Epoch 14 Step 1301 Train Loss: 0.6444
Epoch 14 Step 1351 Train Loss: 0.6436
Epoch 14 Step 1401 Train Loss: 0.5831
Epoch 14 Step 1451 Train Loss: 0.6000
Epoch 14 Step 1501 Train Loss: 0.5994
Epoch 14 Step 1551 Train Loss: 0.6140
Epoch 14 Step 1601 Train Loss: 0.6251
Epoch 14 Step 1651 Train Loss: 0.5882
Epoch 14 Step 1701 Train Loss: 0.6009
Epoch 14 Step 1751 Train Loss: 0.6170
Epoch 14 Step 1801 Train Loss: 0.6669
Epoch 14 Step 1851 Train Loss: 0.5815
Epoch 14 Step 1901 Train Loss: 0.5867
Epoch 14 Step 1951 Train Loss: 0.6038
Epoch 14 Step 2001 Train Loss: 0.5970
Epoch 14 Step 2051 Train Loss: 0.5986
Epoch 14 Step 2101 Train Loss: 0.6067
Epoch 14 Step 2151 Train Loss: 0.5767
Epoch 14 Step 2201 Train Loss: 0.5545
Epoch 14 Step 2251 Train Loss: 0.5976
Epoch 14 Step 2301 Train Loss: 0.6051
Epoch 14 Step 2351 Train Loss: 0.6063
Epoch 14 Step 2401 Train Loss: 0.5434
Epoch 14 Step 2451 Train Loss: 0.5776
Epoch 14 Step 2501 Train Loss: 0.5842
Epoch 14 Step 2551 Train Loss: 0.5894
Epoch 14 Step 2601 Train Loss: 0.6037
Epoch 14 Step 2651 Train Loss: 0.5964
Epoch 14 Step 2701 Train Loss: 0.5374
Epoch 14 Step 2751 Train Loss: 0.6184
Epoch 14 Step 2801 Train Loss: 0.6607
Epoch 14 Step 2851 Train Loss: 0.6003
Epoch 14 Step 2901 Train Loss: 0.5972
Epoch 14 Step 2951 Train Loss: 0.6241
Epoch 14 Step 3001 Train Loss: 0.5726
Epoch 14 Step 3051 Train Loss: 0.5831
Epoch 14 Step 3101 Train Loss: 0.6205
Epoch 14 Step 3151 Train Loss: 0.5564
Epoch 14 Step 3201 Train Loss: 0.6218
Epoch 14: Train Overall MSE: 0.0129 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1223 Validation Top 20 DE MSE: 0.1120. 
Epoch 15 Step 1 Train Loss: 0.6368
Epoch 15 Step 51 Train Loss: 0.5518
Epoch 15 Step 101 Train Loss: 0.5595
Epoch 15 Step 151 Train Loss: 0.6432
Epoch 15 Step 201 Train Loss: 0.5449
Epoch 15 Step 251 Train Loss: 0.5937
Epoch 15 Step 301 Train Loss: 0.6319
Epoch 15 Step 351 Train Loss: 0.5969
Epoch 15 Step 401 Train Loss: 0.6207
Epoch 15 Step 451 Train Loss: 0.5679
Epoch 15 Step 501 Train Loss: 0.6337
Epoch 15 Step 551 Train Loss: 0.6310
Epoch 15 Step 601 Train Loss: 0.6014
Epoch 15 Step 651 Train Loss: 0.5835
Epoch 15 Step 701 Train Loss: 0.5976
Epoch 15 Step 751 Train Loss: 0.5805
Epoch 15 Step 801 Train Loss: 0.5773
Epoch 15 Step 851 Train Loss: 0.6468
Epoch 15 Step 901 Train Loss: 0.5580
Epoch 15 Step 951 Train Loss: 0.5737
Epoch 15 Step 1001 Train Loss: 0.5717
Epoch 15 Step 1051 Train Loss: 0.6759
Epoch 15 Step 1101 Train Loss: 0.6148
Epoch 15 Step 1151 Train Loss: 0.5986
Epoch 15 Step 1201 Train Loss: 0.5628
Epoch 15 Step 1251 Train Loss: 0.6386
Epoch 15 Step 1301 Train Loss: 0.5650
Epoch 15 Step 1351 Train Loss: 0.6295
Epoch 15 Step 1401 Train Loss: 0.5615
Epoch 15 Step 1451 Train Loss: 0.5638
Epoch 15 Step 1501 Train Loss: 0.6282
Epoch 15 Step 1551 Train Loss: 0.5849
Epoch 15 Step 1601 Train Loss: 0.5469
Epoch 15 Step 1651 Train Loss: 0.5809
Epoch 15 Step 1701 Train Loss: 0.6253
Epoch 15 Step 1751 Train Loss: 0.5908
Epoch 15 Step 1801 Train Loss: 0.6306
Epoch 15 Step 1851 Train Loss: 0.5545
Epoch 15 Step 1901 Train Loss: 0.5856
Epoch 15 Step 1951 Train Loss: 0.6033
Epoch 15 Step 2001 Train Loss: 0.5849
Epoch 15 Step 2051 Train Loss: 0.5811
Epoch 15 Step 2101 Train Loss: 0.5858
Epoch 15 Step 2151 Train Loss: 0.5958
Epoch 15 Step 2201 Train Loss: 0.5968
Epoch 15 Step 2251 Train Loss: 0.5713
Epoch 15 Step 2301 Train Loss: 0.5987
Epoch 15 Step 2351 Train Loss: 0.5686
Epoch 15 Step 2401 Train Loss: 0.5787
Epoch 15 Step 2451 Train Loss: 0.5878
Epoch 15 Step 2501 Train Loss: 0.5994
Epoch 15 Step 2551 Train Loss: 0.6311
Epoch 15 Step 2601 Train Loss: 0.5781
Epoch 15 Step 2651 Train Loss: 0.5900
Epoch 15 Step 2701 Train Loss: 0.5898
Epoch 15 Step 2751 Train Loss: 0.6404
Epoch 15 Step 2801 Train Loss: 0.6244
Epoch 15 Step 2851 Train Loss: 0.6034
Epoch 15 Step 2901 Train Loss: 0.6693
Epoch 15 Step 2951 Train Loss: 0.6782
Epoch 15 Step 3001 Train Loss: 0.6806
Epoch 15 Step 3051 Train Loss: 0.5804
Epoch 15 Step 3101 Train Loss: 0.6310
Epoch 15 Step 3151 Train Loss: 0.5506
Epoch 15 Step 3201 Train Loss: 0.6024
Epoch 15: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1198 Validation Top 20 DE MSE: 0.1105. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1194
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.016790647
test_unseen_single_pearson: 0.9748362438141133
test_unseen_single_mse_de: 0.119446374
test_unseen_single_pearson_de: 0.6464037416007199
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.5199499953883544
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.19999999999999998
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6231197771587743
test_unseen_single_mse_top20_de_non_dropout: 0.15017599
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.053 MB uploadedwandb: | 0.001 MB of 0.053 MB uploadedwandb: / 0.013 MB of 0.053 MB uploadedwandb: - 0.015 MB of 0.053 MB uploadedwandb: \ 0.053 MB of 0.053 MB uploadedwandb: | 0.053 MB of 0.053 MB uploadedwandb: / 0.053 MB of 0.053 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                             train_de_pearson ‚ñà‚ñá‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb:                                                    train_mse ‚ñà‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÇ‚ñÑ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                               val_de_pearson ‚ñà‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                                                      val_mse ‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÖ‚ñÖ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.11945
wandb:                                              test_de_pearson 0.6464
wandb:               test_frac_opposite_direction_top20_non_dropout 0.2
wandb:                          test_frac_sigma_below_1_non_dropout 0.62312
wandb:                                                     test_mse 0.01679
wandb:                                test_mse_top20_de_non_dropout 0.15018
wandb:                                                 test_pearson 0.97484
wandb:                                           test_pearson_delta 0.51995
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.2
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.62312
wandb:                                       test_unseen_single_mse 0.01679
wandb:                                    test_unseen_single_mse_de 0.11945
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.15018
wandb:                                   test_unseen_single_pearson 0.97484
wandb:                                test_unseen_single_pearson_de 0.6464
wandb:                             test_unseen_single_pearson_delta 0.51995
wandb:                                                 train_de_mse 0.11979
wandb:                                             train_de_pearson 0.66417
wandb:                                                    train_mse 0.01275
wandb:                                                train_pearson 0.98083
wandb:                                                training_loss 0.62341
wandb:                                                   val_de_mse 0.11053
wandb:                                               val_de_pearson 0.63839
wandb:                                                      val_mse 0.01449
wandb:                                                  val_pearson 0.97824
wandb: 
wandb: üöÄ View run geneformer_Replogle_rpe1_essential_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/09cmhkbp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_150135-09cmhkbp/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:359
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_173331-l8jprrhe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_rpe1_essential_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/l8jprrhe
wandb: WARNING Serializing object of type ndarray that is 23564416 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6361
Epoch 1 Step 51 Train Loss: 0.6659
Epoch 1 Step 101 Train Loss: 0.6091
Epoch 1 Step 151 Train Loss: 0.5918
Epoch 1 Step 201 Train Loss: 0.6039
Epoch 1 Step 251 Train Loss: 0.5543
Epoch 1 Step 301 Train Loss: 0.5850
Epoch 1 Step 351 Train Loss: 0.5514
Epoch 1 Step 401 Train Loss: 0.5787
Epoch 1 Step 451 Train Loss: 0.6282
Epoch 1 Step 501 Train Loss: 0.5608
Epoch 1 Step 551 Train Loss: 0.6420
Epoch 1 Step 601 Train Loss: 0.6031
Epoch 1 Step 651 Train Loss: 0.6016
Epoch 1 Step 701 Train Loss: 0.5486
Epoch 1 Step 751 Train Loss: 0.5478
Epoch 1 Step 801 Train Loss: 0.6494
Epoch 1 Step 851 Train Loss: 0.6795
Epoch 1 Step 901 Train Loss: 0.6245
Epoch 1 Step 951 Train Loss: 0.5997
Epoch 1 Step 1001 Train Loss: 0.6023
Epoch 1 Step 1051 Train Loss: 0.5886
Epoch 1 Step 1101 Train Loss: 0.6121
Epoch 1 Step 1151 Train Loss: 0.5912
Epoch 1 Step 1201 Train Loss: 0.5775
Epoch 1 Step 1251 Train Loss: 0.6304
Epoch 1 Step 1301 Train Loss: 0.5842
Epoch 1 Step 1351 Train Loss: 0.6533
Epoch 1 Step 1401 Train Loss: 0.6098
Epoch 1 Step 1451 Train Loss: 0.6045
Epoch 1 Step 1501 Train Loss: 0.6084
Epoch 1 Step 1551 Train Loss: 0.6615
Epoch 1 Step 1601 Train Loss: 0.5861
Epoch 1 Step 1651 Train Loss: 0.6128
Epoch 1 Step 1701 Train Loss: 0.5831
Epoch 1 Step 1751 Train Loss: 0.5756
Epoch 1 Step 1801 Train Loss: 0.5655
Epoch 1 Step 1851 Train Loss: 0.5685
Epoch 1 Step 1901 Train Loss: 0.6394
Epoch 1 Step 1951 Train Loss: 0.5481
Epoch 1 Step 2001 Train Loss: 0.6063
Epoch 1 Step 2051 Train Loss: 0.5376
Epoch 1 Step 2101 Train Loss: 0.5594
Epoch 1 Step 2151 Train Loss: 0.6056
Epoch 1 Step 2201 Train Loss: 0.6004
Epoch 1 Step 2251 Train Loss: 0.6033
Epoch 1 Step 2301 Train Loss: 0.5573
Epoch 1 Step 2351 Train Loss: 0.6774
Epoch 1 Step 2401 Train Loss: 0.6074
Epoch 1 Step 2451 Train Loss: 0.5969
Epoch 1 Step 2501 Train Loss: 0.5722
Epoch 1 Step 2551 Train Loss: 0.5888
Epoch 1 Step 2601 Train Loss: 0.6135
Epoch 1 Step 2651 Train Loss: 0.5563
Epoch 1 Step 2701 Train Loss: 0.5555
Epoch 1 Step 2751 Train Loss: 0.6027
Epoch 1 Step 2801 Train Loss: 0.6267
Epoch 1 Step 2851 Train Loss: 0.6032
Epoch 1 Step 2901 Train Loss: 0.6303
Epoch 1 Step 2951 Train Loss: 0.5795
Epoch 1 Step 3001 Train Loss: 0.6075
Epoch 1 Step 3051 Train Loss: 0.5661
Epoch 1 Step 3101 Train Loss: 0.6195
Epoch 1 Step 3151 Train Loss: 0.5815
Epoch 1 Step 3201 Train Loss: 0.6148
Epoch 1 Step 3251 Train Loss: 0.5902
Epoch 1: Train Overall MSE: 0.0779 Validation Overall MSE: 0.0888. 
Train Top 20 DE MSE: 0.3260 Validation Top 20 DE MSE: 0.3320. 
Epoch 2 Step 1 Train Loss: 0.5497
Epoch 2 Step 51 Train Loss: 0.6010
Epoch 2 Step 101 Train Loss: 0.6065
Epoch 2 Step 151 Train Loss: 0.5739
Epoch 2 Step 201 Train Loss: 0.6605
Epoch 2 Step 251 Train Loss: 0.6263
Epoch 2 Step 301 Train Loss: 0.5764
Epoch 2 Step 351 Train Loss: 0.5783
Epoch 2 Step 401 Train Loss: 0.6265
Epoch 2 Step 451 Train Loss: 0.5716
Epoch 2 Step 501 Train Loss: 0.5716
Epoch 2 Step 551 Train Loss: 0.5746
Epoch 2 Step 601 Train Loss: 0.6373
Epoch 2 Step 651 Train Loss: 0.5544
Epoch 2 Step 701 Train Loss: 0.6029
Epoch 2 Step 751 Train Loss: 0.5551
Epoch 2 Step 801 Train Loss: 0.5784
Epoch 2 Step 851 Train Loss: 0.5906
Epoch 2 Step 901 Train Loss: 0.5589
Epoch 2 Step 951 Train Loss: 0.5923
Epoch 2 Step 1001 Train Loss: 0.5620
Epoch 2 Step 1051 Train Loss: 0.5964
Epoch 2 Step 1101 Train Loss: 0.6121
Epoch 2 Step 1151 Train Loss: 0.6052
Epoch 2 Step 1201 Train Loss: 0.6177
Epoch 2 Step 1251 Train Loss: 0.5915
Epoch 2 Step 1301 Train Loss: 0.5913
Epoch 2 Step 1351 Train Loss: 0.5906
Epoch 2 Step 1401 Train Loss: 0.5780
Epoch 2 Step 1451 Train Loss: 0.5993
Epoch 2 Step 1501 Train Loss: 0.5270
Epoch 2 Step 1551 Train Loss: 0.5860
Epoch 2 Step 1601 Train Loss: 0.5531
Epoch 2 Step 1651 Train Loss: 0.5818
Epoch 2 Step 1701 Train Loss: 0.6097
Epoch 2 Step 1751 Train Loss: 0.5809
Epoch 2 Step 1801 Train Loss: 0.5995
Epoch 2 Step 1851 Train Loss: 0.5487
Epoch 2 Step 1901 Train Loss: 0.6838
Epoch 2 Step 1951 Train Loss: 0.5813
Epoch 2 Step 2001 Train Loss: 0.6422
Epoch 2 Step 2051 Train Loss: 0.5929
Epoch 2 Step 2101 Train Loss: 0.5804
Epoch 2 Step 2151 Train Loss: 0.5938
Epoch 2 Step 2201 Train Loss: 0.5968
Epoch 2 Step 2251 Train Loss: 0.6404
Epoch 2 Step 2301 Train Loss: 0.6147
Epoch 2 Step 2351 Train Loss: 0.5992
Epoch 2 Step 2401 Train Loss: 0.5669
Epoch 2 Step 2451 Train Loss: 0.5973
Epoch 2 Step 2501 Train Loss: 0.5915
Epoch 2 Step 2551 Train Loss: 0.6025
Epoch 2 Step 2601 Train Loss: 0.6062
Epoch 2 Step 2651 Train Loss: 0.6260
Epoch 2 Step 2701 Train Loss: 0.5893
Epoch 2 Step 2751 Train Loss: 0.6163
Epoch 2 Step 2801 Train Loss: 0.5846
Epoch 2 Step 2851 Train Loss: 0.6478
Epoch 2 Step 2901 Train Loss: 0.6339
Epoch 2 Step 2951 Train Loss: 0.5460
Epoch 2 Step 3001 Train Loss: 0.5857
Epoch 2 Step 3051 Train Loss: 0.6080
Epoch 2 Step 3101 Train Loss: 0.5960
Epoch 2 Step 3151 Train Loss: 0.6334
Epoch 2 Step 3201 Train Loss: 0.5544
Epoch 2 Step 3251 Train Loss: 0.5365
Epoch 2: Train Overall MSE: 0.0140 Validation Overall MSE: 0.0164. 
Train Top 20 DE MSE: 0.1346 Validation Top 20 DE MSE: 0.1546. 
Epoch 3 Step 1 Train Loss: 0.5936
Epoch 3 Step 51 Train Loss: 0.5989
Epoch 3 Step 101 Train Loss: 0.5950
Epoch 3 Step 151 Train Loss: 0.5766
Epoch 3 Step 201 Train Loss: 0.6220
Epoch 3 Step 251 Train Loss: 0.6059
Epoch 3 Step 301 Train Loss: 0.5613
Epoch 3 Step 351 Train Loss: 0.6204
Epoch 3 Step 401 Train Loss: 0.5805
Epoch 3 Step 451 Train Loss: 0.5908
Epoch 3 Step 501 Train Loss: 0.6242
Epoch 3 Step 551 Train Loss: 0.6763
Epoch 3 Step 601 Train Loss: 0.6240
Epoch 3 Step 651 Train Loss: 0.5507
Epoch 3 Step 701 Train Loss: 0.6183
Epoch 3 Step 751 Train Loss: 0.5540
Epoch 3 Step 801 Train Loss: 0.6671
Epoch 3 Step 851 Train Loss: 0.6419
Epoch 3 Step 901 Train Loss: 0.6005
Epoch 3 Step 951 Train Loss: 0.5708
Epoch 3 Step 1001 Train Loss: 0.6244
Epoch 3 Step 1051 Train Loss: 0.6977
Epoch 3 Step 1101 Train Loss: 0.6047
Epoch 3 Step 1151 Train Loss: 0.5992
Epoch 3 Step 1201 Train Loss: 0.6679
Epoch 3 Step 1251 Train Loss: 0.7017
Epoch 3 Step 1301 Train Loss: 0.6768
Epoch 3 Step 1351 Train Loss: 0.5552
Epoch 3 Step 1401 Train Loss: 0.5831
Epoch 3 Step 1451 Train Loss: 0.5364
Epoch 3 Step 1501 Train Loss: 0.5883
Epoch 3 Step 1551 Train Loss: 0.5336
Epoch 3 Step 1601 Train Loss: 0.5691
Epoch 3 Step 1651 Train Loss: 0.5921
Epoch 3 Step 1701 Train Loss: 0.5647
Epoch 3 Step 1751 Train Loss: 0.5874
Epoch 3 Step 1801 Train Loss: 0.6046
Epoch 3 Step 1851 Train Loss: 0.5863
Epoch 3 Step 1901 Train Loss: 0.5796
Epoch 3 Step 1951 Train Loss: 0.5690
Epoch 3 Step 2001 Train Loss: 0.5891
Epoch 3 Step 2051 Train Loss: 0.5949
Epoch 3 Step 2101 Train Loss: 0.5851
Epoch 3 Step 2151 Train Loss: 0.5946
Epoch 3 Step 2201 Train Loss: 0.6105
Epoch 3 Step 2251 Train Loss: 0.5881
Epoch 3 Step 2301 Train Loss: 0.6193
Epoch 3 Step 2351 Train Loss: 0.5989
Epoch 3 Step 2401 Train Loss: 0.5786
Epoch 3 Step 2451 Train Loss: 0.6643
Epoch 3 Step 2501 Train Loss: 0.5507
Epoch 3 Step 2551 Train Loss: 0.5957
Epoch 3 Step 2601 Train Loss: 0.5782
Epoch 3 Step 2651 Train Loss: 0.5222
Epoch 3 Step 2701 Train Loss: 0.5977
Epoch 3 Step 2751 Train Loss: 0.6012
Epoch 3 Step 2801 Train Loss: 0.5636
Epoch 3 Step 2851 Train Loss: 0.6682
Epoch 3 Step 2901 Train Loss: 0.5496
Epoch 3 Step 2951 Train Loss: 0.6794
Epoch 3 Step 3001 Train Loss: 0.5931
Epoch 3 Step 3051 Train Loss: 0.5805
Epoch 3 Step 3101 Train Loss: 0.6642
Epoch 3 Step 3151 Train Loss: 0.5477
Epoch 3 Step 3201 Train Loss: 0.6228
Epoch 3 Step 3251 Train Loss: 0.5643
Epoch 3: Train Overall MSE: 0.0131 Validation Overall MSE: 0.0164. 
Train Top 20 DE MSE: 0.1105 Validation Top 20 DE MSE: 0.1396. 
Epoch 4 Step 1 Train Loss: 0.5516
Epoch 4 Step 51 Train Loss: 0.6366
Epoch 4 Step 101 Train Loss: 0.6240
Epoch 4 Step 151 Train Loss: 0.5799
Epoch 4 Step 201 Train Loss: 0.6490
Epoch 4 Step 251 Train Loss: 0.6047
Epoch 4 Step 301 Train Loss: 0.5901
Epoch 4 Step 351 Train Loss: 0.5663
Epoch 4 Step 401 Train Loss: 0.5516
Epoch 4 Step 451 Train Loss: 0.5679
Epoch 4 Step 501 Train Loss: 0.6348
Epoch 4 Step 551 Train Loss: 0.5861
Epoch 4 Step 601 Train Loss: 0.5854
Epoch 4 Step 651 Train Loss: 0.6610
Epoch 4 Step 701 Train Loss: 0.5676
Epoch 4 Step 751 Train Loss: 0.5839
Epoch 4 Step 801 Train Loss: 0.5761
Epoch 4 Step 851 Train Loss: 0.6053
Epoch 4 Step 901 Train Loss: 0.6073
Epoch 4 Step 951 Train Loss: 0.5952
Epoch 4 Step 1001 Train Loss: 0.6028
Epoch 4 Step 1051 Train Loss: 0.5590
Epoch 4 Step 1101 Train Loss: 0.6226
Epoch 4 Step 1151 Train Loss: 0.5841
Epoch 4 Step 1201 Train Loss: 0.5373
Epoch 4 Step 1251 Train Loss: 0.6180
Epoch 4 Step 1301 Train Loss: 0.6773
Epoch 4 Step 1351 Train Loss: 0.5986
Epoch 4 Step 1401 Train Loss: 0.5962
Epoch 4 Step 1451 Train Loss: 0.6151
Epoch 4 Step 1501 Train Loss: 0.6062
Epoch 4 Step 1551 Train Loss: 0.6086
Epoch 4 Step 1601 Train Loss: 0.6164
Epoch 4 Step 1651 Train Loss: 0.5596
Epoch 4 Step 1701 Train Loss: 0.5495
Epoch 4 Step 1751 Train Loss: 0.5763
Epoch 4 Step 1801 Train Loss: 0.5928
Epoch 4 Step 1851 Train Loss: 0.5663
Epoch 4 Step 1901 Train Loss: 0.5785
Epoch 4 Step 1951 Train Loss: 0.5691
Epoch 4 Step 2001 Train Loss: 0.6098
Epoch 4 Step 2051 Train Loss: 0.5603
Epoch 4 Step 2101 Train Loss: 0.5948
Epoch 4 Step 2151 Train Loss: 0.6199
Epoch 4 Step 2201 Train Loss: 0.6190
Epoch 4 Step 2251 Train Loss: 0.5911
Epoch 4 Step 2301 Train Loss: 0.5615
Epoch 4 Step 2351 Train Loss: 0.6955
Epoch 4 Step 2401 Train Loss: 0.6709
Epoch 4 Step 2451 Train Loss: 0.6001
Epoch 4 Step 2501 Train Loss: 0.5823
Epoch 4 Step 2551 Train Loss: 0.6284
Epoch 4 Step 2601 Train Loss: 0.5594
Epoch 4 Step 2651 Train Loss: 0.6421
Epoch 4 Step 2701 Train Loss: 0.5677
Epoch 4 Step 2751 Train Loss: 0.5917
Epoch 4 Step 2801 Train Loss: 0.6029
Epoch 4 Step 2851 Train Loss: 0.5734
Epoch 4 Step 2901 Train Loss: 0.6618
Epoch 4 Step 2951 Train Loss: 0.5589
Epoch 4 Step 3001 Train Loss: 0.6823
Epoch 4 Step 3051 Train Loss: 0.5641
Epoch 4 Step 3101 Train Loss: 0.6067
Epoch 4 Step 3151 Train Loss: 0.5891
Epoch 4 Step 3201 Train Loss: 0.5826
Epoch 4 Step 3251 Train Loss: 0.5764
Epoch 4: Train Overall MSE: 0.0147 Validation Overall MSE: 0.0175. 
Train Top 20 DE MSE: 0.1464 Validation Top 20 DE MSE: 0.1691. 
Epoch 5 Step 1 Train Loss: 0.6107
Epoch 5 Step 51 Train Loss: 0.5806
Epoch 5 Step 101 Train Loss: 0.5916
Epoch 5 Step 151 Train Loss: 0.6035
Epoch 5 Step 201 Train Loss: 0.6018
Epoch 5 Step 251 Train Loss: 0.6352
Epoch 5 Step 301 Train Loss: 0.6073
Epoch 5 Step 351 Train Loss: 0.5998
Epoch 5 Step 401 Train Loss: 0.5763
Epoch 5 Step 451 Train Loss: 0.6257
Epoch 5 Step 501 Train Loss: 0.6594
Epoch 5 Step 551 Train Loss: 0.5529
Epoch 5 Step 601 Train Loss: 0.5880
Epoch 5 Step 651 Train Loss: 0.6266
Epoch 5 Step 701 Train Loss: 0.5941
Epoch 5 Step 751 Train Loss: 0.6347
Epoch 5 Step 801 Train Loss: 0.6335
Epoch 5 Step 851 Train Loss: 0.5458
Epoch 5 Step 901 Train Loss: 0.6495
Epoch 5 Step 951 Train Loss: 0.5794
Epoch 5 Step 1001 Train Loss: 0.6597
Epoch 5 Step 1051 Train Loss: 0.6154
Epoch 5 Step 1101 Train Loss: 0.5901
Epoch 5 Step 1151 Train Loss: 0.5361
Epoch 5 Step 1201 Train Loss: 0.5787
Epoch 5 Step 1251 Train Loss: 0.5863
Epoch 5 Step 1301 Train Loss: 0.5624
Epoch 5 Step 1351 Train Loss: 0.6319
Epoch 5 Step 1401 Train Loss: 0.5965
Epoch 5 Step 1451 Train Loss: 0.5541
Epoch 5 Step 1501 Train Loss: 0.6735
Epoch 5 Step 1551 Train Loss: 0.5878
Epoch 5 Step 1601 Train Loss: 0.5708
Epoch 5 Step 1651 Train Loss: 0.6055
Epoch 5 Step 1701 Train Loss: 0.6055
Epoch 5 Step 1751 Train Loss: 0.6472
Epoch 5 Step 1801 Train Loss: 0.5755
Epoch 5 Step 1851 Train Loss: 0.6085
Epoch 5 Step 1901 Train Loss: 0.6049
Epoch 5 Step 1951 Train Loss: 0.6073
Epoch 5 Step 2001 Train Loss: 0.5717
Epoch 5 Step 2051 Train Loss: 0.5492
Epoch 5 Step 2101 Train Loss: 0.5770
Epoch 5 Step 2151 Train Loss: 0.5804
Epoch 5 Step 2201 Train Loss: 0.5920
Epoch 5 Step 2251 Train Loss: 0.5453
Epoch 5 Step 2301 Train Loss: 0.5900
Epoch 5 Step 2351 Train Loss: 0.5864
Epoch 5 Step 2401 Train Loss: 0.5925
Epoch 5 Step 2451 Train Loss: 0.6057
Epoch 5 Step 2501 Train Loss: 0.6124
Epoch 5 Step 2551 Train Loss: 0.6473
Epoch 5 Step 2601 Train Loss: 0.6051
Epoch 5 Step 2651 Train Loss: 0.5921
Epoch 5 Step 2701 Train Loss: 0.5519
Epoch 5 Step 2751 Train Loss: 0.5577
Epoch 5 Step 2801 Train Loss: 0.5466
Epoch 5 Step 2851 Train Loss: 0.5820
Epoch 5 Step 2901 Train Loss: 0.5573
Epoch 5 Step 2951 Train Loss: 0.5956
Epoch 5 Step 3001 Train Loss: 0.5977
Epoch 5 Step 3051 Train Loss: 0.5733
Epoch 5 Step 3101 Train Loss: 0.6160
Epoch 5 Step 3151 Train Loss: 0.6218
Epoch 5 Step 3201 Train Loss: 0.5910
Epoch 5 Step 3251 Train Loss: 0.5669
Epoch 5: Train Overall MSE: 0.0123 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1212 Validation Top 20 DE MSE: 0.1488. 
Epoch 6 Step 1 Train Loss: 0.6324
Epoch 6 Step 51 Train Loss: 0.6096
Epoch 6 Step 101 Train Loss: 0.6260
Epoch 6 Step 151 Train Loss: 0.5841
Epoch 6 Step 201 Train Loss: 0.6064
Epoch 6 Step 251 Train Loss: 0.5796
Epoch 6 Step 301 Train Loss: 0.5925
Epoch 6 Step 351 Train Loss: 0.6045
Epoch 6 Step 401 Train Loss: 0.5791
Epoch 6 Step 451 Train Loss: 0.5933
Epoch 6 Step 501 Train Loss: 0.6264
Epoch 6 Step 551 Train Loss: 0.6045
Epoch 6 Step 601 Train Loss: 0.6007
Epoch 6 Step 651 Train Loss: 0.5487
Epoch 6 Step 701 Train Loss: 0.6212
Epoch 6 Step 751 Train Loss: 0.5900
Epoch 6 Step 801 Train Loss: 0.5975
Epoch 6 Step 851 Train Loss: 0.6041
Epoch 6 Step 901 Train Loss: 0.6338
Epoch 6 Step 951 Train Loss: 0.5643
Epoch 6 Step 1001 Train Loss: 0.5923
Epoch 6 Step 1051 Train Loss: 0.5637
Epoch 6 Step 1101 Train Loss: 0.6570
Epoch 6 Step 1151 Train Loss: 0.6551
Epoch 6 Step 1201 Train Loss: 0.5971
Epoch 6 Step 1251 Train Loss: 0.6180
Epoch 6 Step 1301 Train Loss: 0.6268
Epoch 6 Step 1351 Train Loss: 0.6068
Epoch 6 Step 1401 Train Loss: 0.6050
Epoch 6 Step 1451 Train Loss: 0.6126
Epoch 6 Step 1501 Train Loss: 0.5746
Epoch 6 Step 1551 Train Loss: 0.5723
Epoch 6 Step 1601 Train Loss: 0.5983
Epoch 6 Step 1651 Train Loss: 0.5891
Epoch 6 Step 1701 Train Loss: 0.6309
Epoch 6 Step 1751 Train Loss: 0.6501
Epoch 6 Step 1801 Train Loss: 0.6329
Epoch 6 Step 1851 Train Loss: 0.6619
Epoch 6 Step 1901 Train Loss: 0.6356
Epoch 6 Step 1951 Train Loss: 0.6672
Epoch 6 Step 2001 Train Loss: 0.5458
Epoch 6 Step 2051 Train Loss: 0.5830
Epoch 6 Step 2101 Train Loss: 0.6596
Epoch 6 Step 2151 Train Loss: 0.5710
Epoch 6 Step 2201 Train Loss: 0.5655
Epoch 6 Step 2251 Train Loss: 0.6216
Epoch 6 Step 2301 Train Loss: 0.5853
Epoch 6 Step 2351 Train Loss: 0.6174
Epoch 6 Step 2401 Train Loss: 0.5830
Epoch 6 Step 2451 Train Loss: 0.5585
Epoch 6 Step 2501 Train Loss: 0.5987
Epoch 6 Step 2551 Train Loss: 0.5789
Epoch 6 Step 2601 Train Loss: 0.5801
Epoch 6 Step 2651 Train Loss: 0.6273
Epoch 6 Step 2701 Train Loss: 0.6099
Epoch 6 Step 2751 Train Loss: 0.6039
Epoch 6 Step 2801 Train Loss: 0.6781
Epoch 6 Step 2851 Train Loss: 0.6567
Epoch 6 Step 2901 Train Loss: 0.6084
Epoch 6 Step 2951 Train Loss: 0.5701
Epoch 6 Step 3001 Train Loss: 0.6022
Epoch 6 Step 3051 Train Loss: 0.5564
Epoch 6 Step 3101 Train Loss: 0.6611
Epoch 6 Step 3151 Train Loss: 0.6104
Epoch 6 Step 3201 Train Loss: 0.5674
Epoch 6 Step 3251 Train Loss: 0.6335
Epoch 6: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1159 Validation Top 20 DE MSE: 0.1446. 
Epoch 7 Step 1 Train Loss: 0.6068
Epoch 7 Step 51 Train Loss: 0.6106
Epoch 7 Step 101 Train Loss: 0.6136
Epoch 7 Step 151 Train Loss: 0.6205
Epoch 7 Step 201 Train Loss: 0.5647
Epoch 7 Step 251 Train Loss: 0.5758
Epoch 7 Step 301 Train Loss: 0.6398
Epoch 7 Step 351 Train Loss: 0.5973
Epoch 7 Step 401 Train Loss: 0.5792
Epoch 7 Step 451 Train Loss: 0.6520
Epoch 7 Step 501 Train Loss: 0.5996
Epoch 7 Step 551 Train Loss: 0.5626
Epoch 7 Step 601 Train Loss: 0.5780
Epoch 7 Step 651 Train Loss: 0.6201
Epoch 7 Step 701 Train Loss: 0.5711
Epoch 7 Step 751 Train Loss: 0.5984
Epoch 7 Step 801 Train Loss: 0.6018
Epoch 7 Step 851 Train Loss: 0.5695
Epoch 7 Step 901 Train Loss: 0.5822
Epoch 7 Step 951 Train Loss: 0.5507
Epoch 7 Step 1001 Train Loss: 0.5968
Epoch 7 Step 1051 Train Loss: 0.6133
Epoch 7 Step 1101 Train Loss: 0.5770
Epoch 7 Step 1151 Train Loss: 0.5631
Epoch 7 Step 1201 Train Loss: 0.5384
Epoch 7 Step 1251 Train Loss: 0.5301
Epoch 7 Step 1301 Train Loss: 0.5339
Epoch 7 Step 1351 Train Loss: 0.5876
Epoch 7 Step 1401 Train Loss: 0.6049
Epoch 7 Step 1451 Train Loss: 0.5541
Epoch 7 Step 1501 Train Loss: 0.5870
Epoch 7 Step 1551 Train Loss: 0.6001
Epoch 7 Step 1601 Train Loss: 0.5924
Epoch 7 Step 1651 Train Loss: 0.6347
Epoch 7 Step 1701 Train Loss: 0.5718
Epoch 7 Step 1751 Train Loss: 0.5918
Epoch 7 Step 1801 Train Loss: 0.5878
Epoch 7 Step 1851 Train Loss: 0.5461
Epoch 7 Step 1901 Train Loss: 0.5781
Epoch 7 Step 1951 Train Loss: 0.5771
Epoch 7 Step 2001 Train Loss: 0.5910
Epoch 7 Step 2051 Train Loss: 0.5665
Epoch 7 Step 2101 Train Loss: 0.6208
Epoch 7 Step 2151 Train Loss: 0.5531
Epoch 7 Step 2201 Train Loss: 0.5501
Epoch 7 Step 2251 Train Loss: 0.6304
Epoch 7 Step 2301 Train Loss: 0.5497
Epoch 7 Step 2351 Train Loss: 0.5907
Epoch 7 Step 2401 Train Loss: 0.5870
Epoch 7 Step 2451 Train Loss: 0.6176
Epoch 7 Step 2501 Train Loss: 0.5761
Epoch 7 Step 2551 Train Loss: 0.5870
Epoch 7 Step 2601 Train Loss: 0.5709
Epoch 7 Step 2651 Train Loss: 0.5977
Epoch 7 Step 2701 Train Loss: 0.6508
Epoch 7 Step 2751 Train Loss: 0.5776
Epoch 7 Step 2801 Train Loss: 0.5854
Epoch 7 Step 2851 Train Loss: 0.5867
Epoch 7 Step 2901 Train Loss: 0.6329
Epoch 7 Step 2951 Train Loss: 0.6594
Epoch 7 Step 3001 Train Loss: 0.6237
Epoch 7 Step 3051 Train Loss: 0.6348
Epoch 7 Step 3101 Train Loss: 0.5779
Epoch 7 Step 3151 Train Loss: 0.5937
Epoch 7 Step 3201 Train Loss: 0.6056
Epoch 7 Step 3251 Train Loss: 0.6583
Epoch 7: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1202 Validation Top 20 DE MSE: 0.1482. 
Epoch 8 Step 1 Train Loss: 0.5841
Epoch 8 Step 51 Train Loss: 0.5912
Epoch 8 Step 101 Train Loss: 0.6338
Epoch 8 Step 151 Train Loss: 0.5921
Epoch 8 Step 201 Train Loss: 0.5909
Epoch 8 Step 251 Train Loss: 0.5915
Epoch 8 Step 301 Train Loss: 0.5637
Epoch 8 Step 351 Train Loss: 0.6221
Epoch 8 Step 401 Train Loss: 0.6290
Epoch 8 Step 451 Train Loss: 0.5898
Epoch 8 Step 501 Train Loss: 0.5610
Epoch 8 Step 551 Train Loss: 0.5618
Epoch 8 Step 601 Train Loss: 0.6112
Epoch 8 Step 651 Train Loss: 0.5937
Epoch 8 Step 701 Train Loss: 0.6588
Epoch 8 Step 751 Train Loss: 0.6053
Epoch 8 Step 801 Train Loss: 0.5596
Epoch 8 Step 851 Train Loss: 0.5767
Epoch 8 Step 901 Train Loss: 0.6050
Epoch 8 Step 951 Train Loss: 0.5445
Epoch 8 Step 1001 Train Loss: 0.5891
Epoch 8 Step 1051 Train Loss: 0.5800
Epoch 8 Step 1101 Train Loss: 0.6229
Epoch 8 Step 1151 Train Loss: 0.5915
Epoch 8 Step 1201 Train Loss: 0.5371
Epoch 8 Step 1251 Train Loss: 0.5779
Epoch 8 Step 1301 Train Loss: 0.5897
Epoch 8 Step 1351 Train Loss: 0.5722
Epoch 8 Step 1401 Train Loss: 0.5855
Epoch 8 Step 1451 Train Loss: 0.6006
Epoch 8 Step 1501 Train Loss: 0.5367
Epoch 8 Step 1551 Train Loss: 0.6582
Epoch 8 Step 1601 Train Loss: 0.5966
Epoch 8 Step 1651 Train Loss: 0.5964
Epoch 8 Step 1701 Train Loss: 0.6048
Epoch 8 Step 1751 Train Loss: 0.6043
Epoch 8 Step 1801 Train Loss: 0.6234
Epoch 8 Step 1851 Train Loss: 0.6023
Epoch 8 Step 1901 Train Loss: 0.6106
Epoch 8 Step 1951 Train Loss: 0.5678
Epoch 8 Step 2001 Train Loss: 0.6132
Epoch 8 Step 2051 Train Loss: 0.6367
Epoch 8 Step 2101 Train Loss: 0.5816
Epoch 8 Step 2151 Train Loss: 0.5802
Epoch 8 Step 2201 Train Loss: 0.6256
Epoch 8 Step 2251 Train Loss: 0.5683
Epoch 8 Step 2301 Train Loss: 0.5835
Epoch 8 Step 2351 Train Loss: 0.5884
Epoch 8 Step 2401 Train Loss: 0.5725
Epoch 8 Step 2451 Train Loss: 0.5293
Epoch 8 Step 2501 Train Loss: 0.5941
Epoch 8 Step 2551 Train Loss: 0.6212
Epoch 8 Step 2601 Train Loss: 0.5901
Epoch 8 Step 2651 Train Loss: 0.6257
Epoch 8 Step 2701 Train Loss: 0.6283
Epoch 8 Step 2751 Train Loss: 0.5663
Epoch 8 Step 2801 Train Loss: 0.6007
Epoch 8 Step 2851 Train Loss: 0.5849
Epoch 8 Step 2901 Train Loss: 0.6125
Epoch 8 Step 2951 Train Loss: 0.6527
Epoch 8 Step 3001 Train Loss: 0.6003
Epoch 8 Step 3051 Train Loss: 0.5881
Epoch 8 Step 3101 Train Loss: 0.5487
Epoch 8 Step 3151 Train Loss: 0.6063
Epoch 8 Step 3201 Train Loss: 0.6229
Epoch 8 Step 3251 Train Loss: 0.5676
Epoch 8: Train Overall MSE: 0.0121 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1164 Validation Top 20 DE MSE: 0.1454. 
Epoch 9 Step 1 Train Loss: 0.6249
Epoch 9 Step 51 Train Loss: 0.6283
Epoch 9 Step 101 Train Loss: 0.5864
Epoch 9 Step 151 Train Loss: 0.5753
Epoch 9 Step 201 Train Loss: 0.6012
Epoch 9 Step 251 Train Loss: 0.5629
Epoch 9 Step 301 Train Loss: 0.5551
Epoch 9 Step 351 Train Loss: 0.5901
Epoch 9 Step 401 Train Loss: 0.5778
Epoch 9 Step 451 Train Loss: 0.5472
Epoch 9 Step 501 Train Loss: 0.5937
Epoch 9 Step 551 Train Loss: 0.6085
Epoch 9 Step 601 Train Loss: 0.6198
Epoch 9 Step 651 Train Loss: 0.5971
Epoch 9 Step 701 Train Loss: 0.6158
Epoch 9 Step 751 Train Loss: 0.6328
Epoch 9 Step 801 Train Loss: 0.6096
Epoch 9 Step 851 Train Loss: 0.5578
Epoch 9 Step 901 Train Loss: 0.5883
Epoch 9 Step 951 Train Loss: 0.6509
Epoch 9 Step 1001 Train Loss: 0.6104
Epoch 9 Step 1051 Train Loss: 0.5878
Epoch 9 Step 1101 Train Loss: 0.5067
Epoch 9 Step 1151 Train Loss: 0.6389
Epoch 9 Step 1201 Train Loss: 0.6035
Epoch 9 Step 1251 Train Loss: 0.5920
Epoch 9 Step 1301 Train Loss: 0.5961
Epoch 9 Step 1351 Train Loss: 0.6271
Epoch 9 Step 1401 Train Loss: 0.5983
Epoch 9 Step 1451 Train Loss: 0.6250
Epoch 9 Step 1501 Train Loss: 0.5903
Epoch 9 Step 1551 Train Loss: 0.6009
Epoch 9 Step 1601 Train Loss: 0.5980
Epoch 9 Step 1651 Train Loss: 0.5881
Epoch 9 Step 1701 Train Loss: 0.6260
Epoch 9 Step 1751 Train Loss: 0.6179
Epoch 9 Step 1801 Train Loss: 0.6680
Epoch 9 Step 1851 Train Loss: 0.6264
Epoch 9 Step 1901 Train Loss: 0.6407
Epoch 9 Step 1951 Train Loss: 0.6004
Epoch 9 Step 2001 Train Loss: 0.6217
Epoch 9 Step 2051 Train Loss: 0.5555
Epoch 9 Step 2101 Train Loss: 0.6092
Epoch 9 Step 2151 Train Loss: 0.5589
Epoch 9 Step 2201 Train Loss: 0.5581
Epoch 9 Step 2251 Train Loss: 0.5934
Epoch 9 Step 2301 Train Loss: 0.5554
Epoch 9 Step 2351 Train Loss: 0.5379
Epoch 9 Step 2401 Train Loss: 0.5884
Epoch 9 Step 2451 Train Loss: 0.5679
Epoch 9 Step 2501 Train Loss: 0.5513
Epoch 9 Step 2551 Train Loss: 0.5889
Epoch 9 Step 2601 Train Loss: 0.5751
Epoch 9 Step 2651 Train Loss: 0.5984
Epoch 9 Step 2701 Train Loss: 0.5691
Epoch 9 Step 2751 Train Loss: 0.6017
Epoch 9 Step 2801 Train Loss: 0.5576
Epoch 9 Step 2851 Train Loss: 0.5616
Epoch 9 Step 2901 Train Loss: 0.5975
Epoch 9 Step 2951 Train Loss: 0.6197
Epoch 9 Step 3001 Train Loss: 0.5614
Epoch 9 Step 3051 Train Loss: 0.6012
Epoch 9 Step 3101 Train Loss: 0.7155
Epoch 9 Step 3151 Train Loss: 0.5983
Epoch 9 Step 3201 Train Loss: 0.5732
Epoch 9 Step 3251 Train Loss: 0.5586
Epoch 9: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1211 Validation Top 20 DE MSE: 0.1486. 
Epoch 10 Step 1 Train Loss: 0.6353
Epoch 10 Step 51 Train Loss: 0.6257
Epoch 10 Step 101 Train Loss: 0.6458
Epoch 10 Step 151 Train Loss: 0.6038
Epoch 10 Step 201 Train Loss: 0.6037
Epoch 10 Step 251 Train Loss: 0.6666
Epoch 10 Step 301 Train Loss: 0.5770
Epoch 10 Step 351 Train Loss: 0.5798
Epoch 10 Step 401 Train Loss: 0.6151
Epoch 10 Step 451 Train Loss: 0.6301
Epoch 10 Step 501 Train Loss: 0.6096
Epoch 10 Step 551 Train Loss: 0.5774
Epoch 10 Step 601 Train Loss: 0.5689
Epoch 10 Step 651 Train Loss: 0.5449
Epoch 10 Step 701 Train Loss: 0.5916
Epoch 10 Step 751 Train Loss: 0.6096
Epoch 10 Step 801 Train Loss: 0.6437
Epoch 10 Step 851 Train Loss: 0.6147
Epoch 10 Step 901 Train Loss: 0.6197
Epoch 10 Step 951 Train Loss: 0.5933
Epoch 10 Step 1001 Train Loss: 0.5561
Epoch 10 Step 1051 Train Loss: 0.5774
Epoch 10 Step 1101 Train Loss: 0.5734
Epoch 10 Step 1151 Train Loss: 0.6075
Epoch 10 Step 1201 Train Loss: 0.6109
Epoch 10 Step 1251 Train Loss: 0.5790
Epoch 10 Step 1301 Train Loss: 0.5354
Epoch 10 Step 1351 Train Loss: 0.6155
Epoch 10 Step 1401 Train Loss: 0.5905
Epoch 10 Step 1451 Train Loss: 0.6287
Epoch 10 Step 1501 Train Loss: 0.6602
Epoch 10 Step 1551 Train Loss: 0.6042
Epoch 10 Step 1601 Train Loss: 0.5769
Epoch 10 Step 1651 Train Loss: 0.5284
Epoch 10 Step 1701 Train Loss: 0.5778
Epoch 10 Step 1751 Train Loss: 0.5614
Epoch 10 Step 1801 Train Loss: 0.6059
Epoch 10 Step 1851 Train Loss: 0.6190
Epoch 10 Step 1901 Train Loss: 0.6119
Epoch 10 Step 1951 Train Loss: 0.5502
Epoch 10 Step 2001 Train Loss: 0.5401
Epoch 10 Step 2051 Train Loss: 0.5536
Epoch 10 Step 2101 Train Loss: 0.6178
Epoch 10 Step 2151 Train Loss: 0.5416
Epoch 10 Step 2201 Train Loss: 0.5846
Epoch 10 Step 2251 Train Loss: 0.6054
Epoch 10 Step 2301 Train Loss: 0.5772
Epoch 10 Step 2351 Train Loss: 0.6258
Epoch 10 Step 2401 Train Loss: 0.6446
Epoch 10 Step 2451 Train Loss: 0.5600
Epoch 10 Step 2501 Train Loss: 0.6479
Epoch 10 Step 2551 Train Loss: 0.5656
Epoch 10 Step 2601 Train Loss: 0.6136
Epoch 10 Step 2651 Train Loss: 0.5679
Epoch 10 Step 2701 Train Loss: 0.5705
Epoch 10 Step 2751 Train Loss: 0.5899
Epoch 10 Step 2801 Train Loss: 0.6453
Epoch 10 Step 2851 Train Loss: 0.6486
Epoch 10 Step 2901 Train Loss: 0.6419
Epoch 10 Step 2951 Train Loss: 0.5892
Epoch 10 Step 3001 Train Loss: 0.6104
Epoch 10 Step 3051 Train Loss: 0.5794
Epoch 10 Step 3101 Train Loss: 0.6094
Epoch 10 Step 3151 Train Loss: 0.5976
Epoch 10 Step 3201 Train Loss: 0.5675
Epoch 10 Step 3251 Train Loss: 0.5835
Epoch 10: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1214 Validation Top 20 DE MSE: 0.1490. 
Epoch 11 Step 1 Train Loss: 0.5621
Epoch 11 Step 51 Train Loss: 0.5991
Epoch 11 Step 101 Train Loss: 0.6095
Epoch 11 Step 151 Train Loss: 0.5776
Epoch 11 Step 201 Train Loss: 0.5660
Epoch 11 Step 251 Train Loss: 0.6781
Epoch 11 Step 301 Train Loss: 0.5861
Epoch 11 Step 351 Train Loss: 0.5904
Epoch 11 Step 401 Train Loss: 0.5968
Epoch 11 Step 451 Train Loss: 0.5714
Epoch 11 Step 501 Train Loss: 0.6091
Epoch 11 Step 551 Train Loss: 0.5588
Epoch 11 Step 601 Train Loss: 0.6366
Epoch 11 Step 651 Train Loss: 0.5920
Epoch 11 Step 701 Train Loss: 0.5853
Epoch 11 Step 751 Train Loss: 0.5291
Epoch 11 Step 801 Train Loss: 0.6083
Epoch 11 Step 851 Train Loss: 0.5803
Epoch 11 Step 901 Train Loss: 0.7450
Epoch 11 Step 951 Train Loss: 0.6084
Epoch 11 Step 1001 Train Loss: 0.5940
Epoch 11 Step 1051 Train Loss: 0.6334
Epoch 11 Step 1101 Train Loss: 0.5659
Epoch 11 Step 1151 Train Loss: 0.5602
Epoch 11 Step 1201 Train Loss: 0.5579
Epoch 11 Step 1251 Train Loss: 0.5972
Epoch 11 Step 1301 Train Loss: 0.6004
Epoch 11 Step 1351 Train Loss: 0.6012
Epoch 11 Step 1401 Train Loss: 0.5672
Epoch 11 Step 1451 Train Loss: 0.6241
Epoch 11 Step 1501 Train Loss: 0.5937
Epoch 11 Step 1551 Train Loss: 0.5928
Epoch 11 Step 1601 Train Loss: 0.5893
Epoch 11 Step 1651 Train Loss: 0.5575
Epoch 11 Step 1701 Train Loss: 0.6005
Epoch 11 Step 1751 Train Loss: 0.6668
Epoch 11 Step 1801 Train Loss: 0.5916
Epoch 11 Step 1851 Train Loss: 0.5852
Epoch 11 Step 1901 Train Loss: 0.6177
Epoch 11 Step 1951 Train Loss: 0.5966
Epoch 11 Step 2001 Train Loss: 0.6137
Epoch 11 Step 2051 Train Loss: 0.6125
Epoch 11 Step 2101 Train Loss: 0.5572
Epoch 11 Step 2151 Train Loss: 0.6312
Epoch 11 Step 2201 Train Loss: 0.5717
Epoch 11 Step 2251 Train Loss: 0.6504
Epoch 11 Step 2301 Train Loss: 0.6116
Epoch 11 Step 2351 Train Loss: 0.6064
Epoch 11 Step 2401 Train Loss: 0.6728
Epoch 11 Step 2451 Train Loss: 0.6583
Epoch 11 Step 2501 Train Loss: 0.5892
Epoch 11 Step 2551 Train Loss: 0.5956
Epoch 11 Step 2601 Train Loss: 0.6631
Epoch 11 Step 2651 Train Loss: 0.6004
Epoch 11 Step 2701 Train Loss: 0.6391
Epoch 11 Step 2751 Train Loss: 0.5363
Epoch 11 Step 2801 Train Loss: 0.6059
Epoch 11 Step 2851 Train Loss: 0.5564
Epoch 11 Step 2901 Train Loss: 0.5816
Epoch 11 Step 2951 Train Loss: 0.6260
Epoch 11 Step 3001 Train Loss: 0.5507
Epoch 11 Step 3051 Train Loss: 0.5867
Epoch 11 Step 3101 Train Loss: 0.6138
Epoch 11 Step 3151 Train Loss: 0.6090
Epoch 11 Step 3201 Train Loss: 0.5727
Epoch 11 Step 3251 Train Loss: 0.5670
Epoch 11: Train Overall MSE: 0.0121 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1184 Validation Top 20 DE MSE: 0.1471. 
Epoch 12 Step 1 Train Loss: 0.5710
Epoch 12 Step 51 Train Loss: 0.5570
Epoch 12 Step 101 Train Loss: 0.6079
Epoch 12 Step 151 Train Loss: 0.5658
Epoch 12 Step 201 Train Loss: 0.5448
Epoch 12 Step 251 Train Loss: 0.6134
Epoch 12 Step 301 Train Loss: 0.5976
Epoch 12 Step 351 Train Loss: 0.6054
Epoch 12 Step 401 Train Loss: 0.5740
Epoch 12 Step 451 Train Loss: 0.5776
Epoch 12 Step 501 Train Loss: 0.6121
Epoch 12 Step 551 Train Loss: 0.6132
Epoch 12 Step 601 Train Loss: 0.5971
Epoch 12 Step 651 Train Loss: 0.6181
Epoch 12 Step 701 Train Loss: 0.6942
Epoch 12 Step 751 Train Loss: 0.5808
Epoch 12 Step 801 Train Loss: 0.6295
Epoch 12 Step 851 Train Loss: 0.6338
Epoch 12 Step 901 Train Loss: 0.6158
Epoch 12 Step 951 Train Loss: 0.6263
Epoch 12 Step 1001 Train Loss: 0.5574
Epoch 12 Step 1051 Train Loss: 0.5965
Epoch 12 Step 1101 Train Loss: 0.6792
Epoch 12 Step 1151 Train Loss: 0.5556
Epoch 12 Step 1201 Train Loss: 0.5911
Epoch 12 Step 1251 Train Loss: 0.6122
Epoch 12 Step 1301 Train Loss: 0.6357
Epoch 12 Step 1351 Train Loss: 0.5635
Epoch 12 Step 1401 Train Loss: 0.6004
Epoch 12 Step 1451 Train Loss: 0.5827
Epoch 12 Step 1501 Train Loss: 0.6304
Epoch 12 Step 1551 Train Loss: 0.5591
Epoch 12 Step 1601 Train Loss: 0.5661
Epoch 12 Step 1651 Train Loss: 0.6225
Epoch 12 Step 1701 Train Loss: 0.5462
Epoch 12 Step 1751 Train Loss: 0.6211
Epoch 12 Step 1801 Train Loss: 0.6806
Epoch 12 Step 1851 Train Loss: 0.6175
Epoch 12 Step 1901 Train Loss: 0.5919
Epoch 12 Step 1951 Train Loss: 0.6092
Epoch 12 Step 2001 Train Loss: 0.6007
Epoch 12 Step 2051 Train Loss: 0.6040
Epoch 12 Step 2101 Train Loss: 0.6338
Epoch 12 Step 2151 Train Loss: 0.5828
Epoch 12 Step 2201 Train Loss: 0.5969
Epoch 12 Step 2251 Train Loss: 0.6573
Epoch 12 Step 2301 Train Loss: 0.6266
Epoch 12 Step 2351 Train Loss: 0.6076
Epoch 12 Step 2401 Train Loss: 0.5509
Epoch 12 Step 2451 Train Loss: 0.5716
Epoch 12 Step 2501 Train Loss: 0.6135
Epoch 12 Step 2551 Train Loss: 0.5501
Epoch 12 Step 2601 Train Loss: 0.5615
Epoch 12 Step 2651 Train Loss: 0.5558
Epoch 12 Step 2701 Train Loss: 0.6175
Epoch 12 Step 2751 Train Loss: 0.5843
Epoch 12 Step 2801 Train Loss: 0.5955
Epoch 12 Step 2851 Train Loss: 0.6298
Epoch 12 Step 2901 Train Loss: 0.5821
Epoch 12 Step 2951 Train Loss: 0.5750
Epoch 12 Step 3001 Train Loss: 0.5409
Epoch 12 Step 3051 Train Loss: 0.5539
Epoch 12 Step 3101 Train Loss: 0.6291
Epoch 12 Step 3151 Train Loss: 0.5900
Epoch 12 Step 3201 Train Loss: 0.5832
Epoch 12 Step 3251 Train Loss: 0.5740
Epoch 12: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1212 Validation Top 20 DE MSE: 0.1490. 
Epoch 13 Step 1 Train Loss: 0.5664
Epoch 13 Step 51 Train Loss: 0.6082
Epoch 13 Step 101 Train Loss: 0.6007
Epoch 13 Step 151 Train Loss: 0.5931
Epoch 13 Step 201 Train Loss: 0.6341
Epoch 13 Step 251 Train Loss: 0.6156
Epoch 13 Step 301 Train Loss: 0.6633
Epoch 13 Step 351 Train Loss: 0.5975
Epoch 13 Step 401 Train Loss: 0.5700
Epoch 13 Step 451 Train Loss: 0.6099
Epoch 13 Step 501 Train Loss: 0.5784
Epoch 13 Step 551 Train Loss: 0.6178
Epoch 13 Step 601 Train Loss: 0.5346
Epoch 13 Step 651 Train Loss: 0.5607
Epoch 13 Step 701 Train Loss: 0.6202
Epoch 13 Step 751 Train Loss: 0.6304
Epoch 13 Step 801 Train Loss: 0.5942
Epoch 13 Step 851 Train Loss: 0.5372
Epoch 13 Step 901 Train Loss: 0.5267
Epoch 13 Step 951 Train Loss: 0.5682
Epoch 13 Step 1001 Train Loss: 0.5431
Epoch 13 Step 1051 Train Loss: 0.6160
Epoch 13 Step 1101 Train Loss: 0.5982
Epoch 13 Step 1151 Train Loss: 0.5462
Epoch 13 Step 1201 Train Loss: 0.6256
Epoch 13 Step 1251 Train Loss: 0.6094
Epoch 13 Step 1301 Train Loss: 0.6108
Epoch 13 Step 1351 Train Loss: 0.6350
Epoch 13 Step 1401 Train Loss: 0.5545
Epoch 13 Step 1451 Train Loss: 0.5558
Epoch 13 Step 1501 Train Loss: 0.6106
Epoch 13 Step 1551 Train Loss: 0.6524
Epoch 13 Step 1601 Train Loss: 0.6002
Epoch 13 Step 1651 Train Loss: 0.5794
Epoch 13 Step 1701 Train Loss: 0.6139
Epoch 13 Step 1751 Train Loss: 0.5812
Epoch 13 Step 1801 Train Loss: 0.6439
Epoch 13 Step 1851 Train Loss: 0.5904
Epoch 13 Step 1901 Train Loss: 0.5664
Epoch 13 Step 1951 Train Loss: 0.5830
Epoch 13 Step 2001 Train Loss: 0.5799
Epoch 13 Step 2051 Train Loss: 0.5849
Epoch 13 Step 2101 Train Loss: 0.6340
Epoch 13 Step 2151 Train Loss: 0.5735
Epoch 13 Step 2201 Train Loss: 0.5875
Epoch 13 Step 2251 Train Loss: 0.6185
Epoch 13 Step 2301 Train Loss: 0.5977
Epoch 13 Step 2351 Train Loss: 0.6087
Epoch 13 Step 2401 Train Loss: 0.5854
Epoch 13 Step 2451 Train Loss: 0.6262
Epoch 13 Step 2501 Train Loss: 0.5744
Epoch 13 Step 2551 Train Loss: 0.5947
Epoch 13 Step 2601 Train Loss: 0.5798
Epoch 13 Step 2651 Train Loss: 0.6950
Epoch 13 Step 2701 Train Loss: 0.6629
Epoch 13 Step 2751 Train Loss: 0.5608
Epoch 13 Step 2801 Train Loss: 0.6158
Epoch 13 Step 2851 Train Loss: 0.5860
Epoch 13 Step 2901 Train Loss: 0.5590
Epoch 13 Step 2951 Train Loss: 0.5901
Epoch 13 Step 3001 Train Loss: 0.5721
Epoch 13 Step 3051 Train Loss: 0.6474
Epoch 13 Step 3101 Train Loss: 0.6542
Epoch 13 Step 3151 Train Loss: 0.6013
Epoch 13 Step 3201 Train Loss: 0.5647
Epoch 13 Step 3251 Train Loss: 0.5870
Epoch 13: Train Overall MSE: 0.0121 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1192 Validation Top 20 DE MSE: 0.1476. 
Epoch 14 Step 1 Train Loss: 0.5427
Epoch 14 Step 51 Train Loss: 0.5720
Epoch 14 Step 101 Train Loss: 0.5553
Epoch 14 Step 151 Train Loss: 0.6000
Epoch 14 Step 201 Train Loss: 0.6115
Epoch 14 Step 251 Train Loss: 0.5475
Epoch 14 Step 301 Train Loss: 0.5525
Epoch 14 Step 351 Train Loss: 0.6131
Epoch 14 Step 401 Train Loss: 0.5960
Epoch 14 Step 451 Train Loss: 0.6128
Epoch 14 Step 501 Train Loss: 0.6162
Epoch 14 Step 551 Train Loss: 0.5940
Epoch 14 Step 601 Train Loss: 0.5566
Epoch 14 Step 651 Train Loss: 0.6384
Epoch 14 Step 701 Train Loss: 0.6072
Epoch 14 Step 751 Train Loss: 0.5799
Epoch 14 Step 801 Train Loss: 0.5764
Epoch 14 Step 851 Train Loss: 0.5885
Epoch 14 Step 901 Train Loss: 0.5865
Epoch 14 Step 951 Train Loss: 0.6422
Epoch 14 Step 1001 Train Loss: 0.6269
Epoch 14 Step 1051 Train Loss: 0.6374
Epoch 14 Step 1101 Train Loss: 0.5724
Epoch 14 Step 1151 Train Loss: 0.5727
Epoch 14 Step 1201 Train Loss: 0.6597
Epoch 14 Step 1251 Train Loss: 0.6348
Epoch 14 Step 1301 Train Loss: 0.5872
Epoch 14 Step 1351 Train Loss: 0.6121
Epoch 14 Step 1401 Train Loss: 0.5710
Epoch 14 Step 1451 Train Loss: 0.5929
Epoch 14 Step 1501 Train Loss: 0.5543
Epoch 14 Step 1551 Train Loss: 0.5740
Epoch 14 Step 1601 Train Loss: 0.5986
Epoch 14 Step 1651 Train Loss: 0.6120
Epoch 14 Step 1701 Train Loss: 0.6208
Epoch 14 Step 1751 Train Loss: 0.5521
Epoch 14 Step 1801 Train Loss: 0.6564
Epoch 14 Step 1851 Train Loss: 0.5517
Epoch 14 Step 1901 Train Loss: 0.5857
Epoch 14 Step 1951 Train Loss: 0.5503
Epoch 14 Step 2001 Train Loss: 0.5830
Epoch 14 Step 2051 Train Loss: 0.5934
Epoch 14 Step 2101 Train Loss: 0.5962
Epoch 14 Step 2151 Train Loss: 0.5463
Epoch 14 Step 2201 Train Loss: 0.5411
Epoch 14 Step 2251 Train Loss: 0.5539
Epoch 14 Step 2301 Train Loss: 0.6112
Epoch 14 Step 2351 Train Loss: 0.5746
Epoch 14 Step 2401 Train Loss: 0.6211
Epoch 14 Step 2451 Train Loss: 0.5652
Epoch 14 Step 2501 Train Loss: 0.6295
Epoch 14 Step 2551 Train Loss: 0.5734
Epoch 14 Step 2601 Train Loss: 0.5484
Epoch 14 Step 2651 Train Loss: 0.6013
Epoch 14 Step 2701 Train Loss: 0.5477
Epoch 14 Step 2751 Train Loss: 0.6290
Epoch 14 Step 2801 Train Loss: 0.6097
Epoch 14 Step 2851 Train Loss: 0.5683
Epoch 14 Step 2901 Train Loss: 0.5690
Epoch 14 Step 2951 Train Loss: 0.6119
Epoch 14 Step 3001 Train Loss: 0.6253
Epoch 14 Step 3051 Train Loss: 0.6023
Epoch 14 Step 3101 Train Loss: 0.5958
Epoch 14 Step 3151 Train Loss: 0.5607
Epoch 14 Step 3201 Train Loss: 0.5614
Epoch 14 Step 3251 Train Loss: 0.6034
Epoch 14: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1214 Validation Top 20 DE MSE: 0.1491. 
Epoch 15 Step 1 Train Loss: 0.5627
Epoch 15 Step 51 Train Loss: 0.5821
Epoch 15 Step 101 Train Loss: 0.5901
Epoch 15 Step 151 Train Loss: 0.5931
Epoch 15 Step 201 Train Loss: 0.5721
Epoch 15 Step 251 Train Loss: 0.5893
Epoch 15 Step 301 Train Loss: 0.6361
Epoch 15 Step 351 Train Loss: 0.5849
Epoch 15 Step 401 Train Loss: 0.6121
Epoch 15 Step 451 Train Loss: 0.6018
Epoch 15 Step 501 Train Loss: 0.6533
Epoch 15 Step 551 Train Loss: 0.6130
Epoch 15 Step 601 Train Loss: 0.6069
Epoch 15 Step 651 Train Loss: 0.6057
Epoch 15 Step 701 Train Loss: 0.5577
Epoch 15 Step 751 Train Loss: 0.6220
Epoch 15 Step 801 Train Loss: 0.6061
Epoch 15 Step 851 Train Loss: 0.5725
Epoch 15 Step 901 Train Loss: 0.6044
Epoch 15 Step 951 Train Loss: 0.6098
Epoch 15 Step 1001 Train Loss: 0.5658
Epoch 15 Step 1051 Train Loss: 0.5747
Epoch 15 Step 1101 Train Loss: 0.5629
Epoch 15 Step 1151 Train Loss: 0.5936
Epoch 15 Step 1201 Train Loss: 0.5654
Epoch 15 Step 1251 Train Loss: 0.5854
Epoch 15 Step 1301 Train Loss: 0.6112
Epoch 15 Step 1351 Train Loss: 0.5848
Epoch 15 Step 1401 Train Loss: 0.6273
Epoch 15 Step 1451 Train Loss: 0.5699
Epoch 15 Step 1501 Train Loss: 0.5607
Epoch 15 Step 1551 Train Loss: 0.5608
Epoch 15 Step 1601 Train Loss: 0.5518
Epoch 15 Step 1651 Train Loss: 0.6131
Epoch 15 Step 1701 Train Loss: 0.5451
Epoch 15 Step 1751 Train Loss: 0.6039
Epoch 15 Step 1801 Train Loss: 0.5694
Epoch 15 Step 1851 Train Loss: 0.5791
Epoch 15 Step 1901 Train Loss: 0.6251
Epoch 15 Step 1951 Train Loss: 0.5962
Epoch 15 Step 2001 Train Loss: 0.5578
Epoch 15 Step 2051 Train Loss: 0.6365
Epoch 15 Step 2101 Train Loss: 0.5955
Epoch 15 Step 2151 Train Loss: 0.5880
Epoch 15 Step 2201 Train Loss: 0.6192
Epoch 15 Step 2251 Train Loss: 0.6268
Epoch 15 Step 2301 Train Loss: 0.5387
Epoch 15 Step 2351 Train Loss: 0.5616
Epoch 15 Step 2401 Train Loss: 0.5711
Epoch 15 Step 2451 Train Loss: 0.6002
Epoch 15 Step 2501 Train Loss: 0.5793
Epoch 15 Step 2551 Train Loss: 0.5946
Epoch 15 Step 2601 Train Loss: 0.5696
Epoch 15 Step 2651 Train Loss: 0.5878
Epoch 15 Step 2701 Train Loss: 0.6374
Epoch 15 Step 2751 Train Loss: 0.6422
Epoch 15 Step 2801 Train Loss: 0.5453
Epoch 15 Step 2851 Train Loss: 0.6231
Epoch 15 Step 2901 Train Loss: 0.6475
Epoch 15 Step 2951 Train Loss: 0.5560
Epoch 15 Step 3001 Train Loss: 0.5939
Epoch 15 Step 3051 Train Loss: 0.6334
Epoch 15 Step 3101 Train Loss: 0.5631
Epoch 15 Step 3151 Train Loss: 0.5725
Epoch 15 Step 3201 Train Loss: 0.6476
Epoch 15 Step 3251 Train Loss: 0.6051
Epoch 15: Train Overall MSE: 0.0122 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1206 Validation Top 20 DE MSE: 0.1488. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1465
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.01630846
test_unseen_single_pearson: 0.9754780381360922
test_unseen_single_mse_de: 0.14649364
test_unseen_single_pearson_de: 0.6378378503645585
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.5111152032764681
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.1915041782729805
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5675487465181058
test_unseen_single_mse_top20_de_non_dropout: 0.19320495
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.053 MB uploadedwandb: | 0.001 MB of 0.053 MB uploadedwandb: / 0.053 MB of 0.053 MB uploadedwandb: - 0.053 MB of 0.053 MB uploadedwandb: \ 0.053 MB of 0.053 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñÖ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñà
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.14649
wandb:                                              test_de_pearson 0.63784
wandb:               test_frac_opposite_direction_top20_non_dropout 0.1915
wandb:                          test_frac_sigma_below_1_non_dropout 0.56755
wandb:                                                     test_mse 0.01631
wandb:                                test_mse_top20_de_non_dropout 0.1932
wandb:                                                 test_pearson 0.97548
wandb:                                           test_pearson_delta 0.51112
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.1915
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.56755
wandb:                                       test_unseen_single_mse 0.01631
wandb:                                    test_unseen_single_mse_de 0.14649
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.1932
wandb:                                   test_unseen_single_pearson 0.97548
wandb:                                test_unseen_single_pearson_de 0.63784
wandb:                             test_unseen_single_pearson_delta 0.51112
wandb:                                                 train_de_mse 0.12059
wandb:                                             train_de_pearson 0.66549
wandb:                                                    train_mse 0.01216
wandb:                                                train_pearson 0.98174
wandb:                                                training_loss 0.56403
wandb:                                                   val_de_mse 0.14884
wandb:                                               val_de_pearson 0.67881
wandb:                                                      val_mse 0.01542
wandb:                                                  val_pearson 0.97681
wandb: 
wandb: üöÄ View run geneformer_Replogle_rpe1_essential_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/l8jprrhe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_173331-l8jprrhe/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:359
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_200118-w23mytdk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_rpe1_essential_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/w23mytdk
wandb: WARNING Serializing object of type ndarray that is 23564416 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6260
Epoch 1 Step 51 Train Loss: 0.6066
Epoch 1 Step 101 Train Loss: 0.5957
Epoch 1 Step 151 Train Loss: 0.6200
Epoch 1 Step 201 Train Loss: 0.5784
Epoch 1 Step 251 Train Loss: 0.5533
Epoch 1 Step 301 Train Loss: 0.5690
Epoch 1 Step 351 Train Loss: 0.6759
Epoch 1 Step 401 Train Loss: 0.6013
Epoch 1 Step 451 Train Loss: 0.5917
Epoch 1 Step 501 Train Loss: 0.6170
Epoch 1 Step 551 Train Loss: 0.6397
Epoch 1 Step 601 Train Loss: 0.6277
Epoch 1 Step 651 Train Loss: 0.5736
Epoch 1 Step 701 Train Loss: 0.5961
Epoch 1 Step 751 Train Loss: 0.6096
Epoch 1 Step 801 Train Loss: 0.5817
Epoch 1 Step 851 Train Loss: 0.5551
Epoch 1 Step 901 Train Loss: 0.5735
Epoch 1 Step 951 Train Loss: 0.5418
Epoch 1 Step 1001 Train Loss: 0.5956
Epoch 1 Step 1051 Train Loss: 0.6862
Epoch 1 Step 1101 Train Loss: 0.6092
Epoch 1 Step 1151 Train Loss: 0.5972
Epoch 1 Step 1201 Train Loss: 0.5940
Epoch 1 Step 1251 Train Loss: 0.6354
Epoch 1 Step 1301 Train Loss: 0.6865
Epoch 1 Step 1351 Train Loss: 0.5762
Epoch 1 Step 1401 Train Loss: 0.6129
Epoch 1 Step 1451 Train Loss: 0.5823
Epoch 1 Step 1501 Train Loss: 0.5824
Epoch 1 Step 1551 Train Loss: 0.5962
Epoch 1 Step 1601 Train Loss: 0.5794
Epoch 1 Step 1651 Train Loss: 0.5747
Epoch 1 Step 1701 Train Loss: 0.5851
Epoch 1 Step 1751 Train Loss: 0.5929
Epoch 1 Step 1801 Train Loss: 0.5832
Epoch 1 Step 1851 Train Loss: 0.6405
Epoch 1 Step 1901 Train Loss: 0.5941
Epoch 1 Step 1951 Train Loss: 0.6422
Epoch 1 Step 2001 Train Loss: 0.5710
Epoch 1 Step 2051 Train Loss: 0.5458
Epoch 1 Step 2101 Train Loss: 0.5765
Epoch 1 Step 2151 Train Loss: 0.5973
Epoch 1 Step 2201 Train Loss: 0.6299
Epoch 1 Step 2251 Train Loss: 0.5905
Epoch 1 Step 2301 Train Loss: 0.6053
Epoch 1 Step 2351 Train Loss: 0.6703
Epoch 1 Step 2401 Train Loss: 0.5419
Epoch 1 Step 2451 Train Loss: 0.6256
Epoch 1 Step 2501 Train Loss: 0.6161
Epoch 1 Step 2551 Train Loss: 0.6262
Epoch 1 Step 2601 Train Loss: 0.5696
Epoch 1 Step 2651 Train Loss: 0.6194
Epoch 1 Step 2701 Train Loss: 0.6022
Epoch 1 Step 2751 Train Loss: 0.5855
Epoch 1 Step 2801 Train Loss: 0.5914
Epoch 1 Step 2851 Train Loss: 0.6107
Epoch 1 Step 2901 Train Loss: 0.5721
Epoch 1 Step 2951 Train Loss: 0.5940
Epoch 1 Step 3001 Train Loss: 0.5970
Epoch 1 Step 3051 Train Loss: 0.6126
Epoch 1 Step 3101 Train Loss: 0.7158
Epoch 1: Train Overall MSE: 0.0148 Validation Overall MSE: 0.0160. 
Train Top 20 DE MSE: 0.1338 Validation Top 20 DE MSE: 0.1259. 
Epoch 2 Step 1 Train Loss: 0.5745
Epoch 2 Step 51 Train Loss: 0.6458
Epoch 2 Step 101 Train Loss: 0.6528
Epoch 2 Step 151 Train Loss: 0.6076
Epoch 2 Step 201 Train Loss: 0.5991
Epoch 2 Step 251 Train Loss: 0.5274
Epoch 2 Step 301 Train Loss: 0.7051
Epoch 2 Step 351 Train Loss: 0.5660
Epoch 2 Step 401 Train Loss: 0.5670
Epoch 2 Step 451 Train Loss: 0.6475
Epoch 2 Step 501 Train Loss: 0.5852
Epoch 2 Step 551 Train Loss: 0.5633
Epoch 2 Step 601 Train Loss: 0.6345
Epoch 2 Step 651 Train Loss: 0.5676
Epoch 2 Step 701 Train Loss: 0.6436
Epoch 2 Step 751 Train Loss: 0.6043
Epoch 2 Step 801 Train Loss: 0.5994
Epoch 2 Step 851 Train Loss: 0.5557
Epoch 2 Step 901 Train Loss: 0.6178
Epoch 2 Step 951 Train Loss: 0.5684
Epoch 2 Step 1001 Train Loss: 0.6692
Epoch 2 Step 1051 Train Loss: 0.6153
Epoch 2 Step 1101 Train Loss: 0.6015
Epoch 2 Step 1151 Train Loss: 0.6257
Epoch 2 Step 1201 Train Loss: 0.5629
Epoch 2 Step 1251 Train Loss: 0.6333
Epoch 2 Step 1301 Train Loss: 0.6013
Epoch 2 Step 1351 Train Loss: 0.5585
Epoch 2 Step 1401 Train Loss: 0.6199
Epoch 2 Step 1451 Train Loss: 0.5946
Epoch 2 Step 1501 Train Loss: 0.6087
Epoch 2 Step 1551 Train Loss: 0.6141
Epoch 2 Step 1601 Train Loss: 0.6607
Epoch 2 Step 1651 Train Loss: 0.5875
Epoch 2 Step 1701 Train Loss: 0.5732
Epoch 2 Step 1751 Train Loss: 0.6172
Epoch 2 Step 1801 Train Loss: 0.5941
Epoch 2 Step 1851 Train Loss: 0.6610
Epoch 2 Step 1901 Train Loss: 0.5727
Epoch 2 Step 1951 Train Loss: 0.6303
Epoch 2 Step 2001 Train Loss: 0.5818
Epoch 2 Step 2051 Train Loss: 0.5788
Epoch 2 Step 2101 Train Loss: 0.6214
Epoch 2 Step 2151 Train Loss: 0.6092
Epoch 2 Step 2201 Train Loss: 0.6205
Epoch 2 Step 2251 Train Loss: 0.6246
Epoch 2 Step 2301 Train Loss: 0.5742
Epoch 2 Step 2351 Train Loss: 0.5541
Epoch 2 Step 2401 Train Loss: 0.5777
Epoch 2 Step 2451 Train Loss: 0.6012
Epoch 2 Step 2501 Train Loss: 0.5894
Epoch 2 Step 2551 Train Loss: 0.6393
Epoch 2 Step 2601 Train Loss: 0.5841
Epoch 2 Step 2651 Train Loss: 0.5890
Epoch 2 Step 2701 Train Loss: 0.5798
Epoch 2 Step 2751 Train Loss: 0.6017
Epoch 2 Step 2801 Train Loss: 0.6120
Epoch 2 Step 2851 Train Loss: 0.6097
Epoch 2 Step 2901 Train Loss: 0.6399
Epoch 2 Step 2951 Train Loss: 0.6039
Epoch 2 Step 3001 Train Loss: 0.6278
Epoch 2 Step 3051 Train Loss: 0.5859
Epoch 2 Step 3101 Train Loss: 0.5830
Epoch 2: Train Overall MSE: 0.0126 Validation Overall MSE: 0.0152. 
Train Top 20 DE MSE: 0.1227 Validation Top 20 DE MSE: 0.1141. 
Epoch 3 Step 1 Train Loss: 0.6021
Epoch 3 Step 51 Train Loss: 0.6255
Epoch 3 Step 101 Train Loss: 0.6176
Epoch 3 Step 151 Train Loss: 0.5739
Epoch 3 Step 201 Train Loss: 0.5484
Epoch 3 Step 251 Train Loss: 0.6262
Epoch 3 Step 301 Train Loss: 0.5920
Epoch 3 Step 351 Train Loss: 0.5552
Epoch 3 Step 401 Train Loss: 0.6238
Epoch 3 Step 451 Train Loss: 0.5783
Epoch 3 Step 501 Train Loss: 0.5875
Epoch 3 Step 551 Train Loss: 0.5858
Epoch 3 Step 601 Train Loss: 0.6320
Epoch 3 Step 651 Train Loss: 0.5873
Epoch 3 Step 701 Train Loss: 0.5607
Epoch 3 Step 751 Train Loss: 0.5713
Epoch 3 Step 801 Train Loss: 0.6565
Epoch 3 Step 851 Train Loss: 0.5295
Epoch 3 Step 901 Train Loss: 0.6138
Epoch 3 Step 951 Train Loss: 0.5615
Epoch 3 Step 1001 Train Loss: 0.5883
Epoch 3 Step 1051 Train Loss: 0.6290
Epoch 3 Step 1101 Train Loss: 0.5517
Epoch 3 Step 1151 Train Loss: 0.5314
Epoch 3 Step 1201 Train Loss: 0.6284
Epoch 3 Step 1251 Train Loss: 0.6077
Epoch 3 Step 1301 Train Loss: 0.6053
Epoch 3 Step 1351 Train Loss: 0.5634
Epoch 3 Step 1401 Train Loss: 0.6161
Epoch 3 Step 1451 Train Loss: 0.6322
Epoch 3 Step 1501 Train Loss: 0.5944
Epoch 3 Step 1551 Train Loss: 0.5811
Epoch 3 Step 1601 Train Loss: 0.5878
Epoch 3 Step 1651 Train Loss: 0.6633
Epoch 3 Step 1701 Train Loss: 0.6592
Epoch 3 Step 1751 Train Loss: 0.5928
Epoch 3 Step 1801 Train Loss: 0.5800
Epoch 3 Step 1851 Train Loss: 0.6183
Epoch 3 Step 1901 Train Loss: 0.5784
Epoch 3 Step 1951 Train Loss: 0.6067
Epoch 3 Step 2001 Train Loss: 0.5748
Epoch 3 Step 2051 Train Loss: 0.5748
Epoch 3 Step 2101 Train Loss: 0.5687
Epoch 3 Step 2151 Train Loss: 0.6196
Epoch 3 Step 2201 Train Loss: 0.5662
Epoch 3 Step 2251 Train Loss: 0.5982
Epoch 3 Step 2301 Train Loss: 0.5978
Epoch 3 Step 2351 Train Loss: 0.5823
Epoch 3 Step 2401 Train Loss: 0.5544
Epoch 3 Step 2451 Train Loss: 0.5846
Epoch 3 Step 2501 Train Loss: 0.6197
Epoch 3 Step 2551 Train Loss: 0.5236
Epoch 3 Step 2601 Train Loss: 0.6121
Epoch 3 Step 2651 Train Loss: 0.6415
Epoch 3 Step 2701 Train Loss: 0.6130
Epoch 3 Step 2751 Train Loss: 0.5869
Epoch 3 Step 2801 Train Loss: 0.5493
Epoch 3 Step 2851 Train Loss: 0.5718
Epoch 3 Step 2901 Train Loss: 0.5937
Epoch 3 Step 2951 Train Loss: 0.5857
Epoch 3 Step 3001 Train Loss: 0.5827
Epoch 3 Step 3051 Train Loss: 0.5670
Epoch 3 Step 3101 Train Loss: 0.5432
Epoch 3: Train Overall MSE: 0.0121 Validation Overall MSE: 0.0146. 
Train Top 20 DE MSE: 0.1191 Validation Top 20 DE MSE: 0.1131. 
Epoch 4 Step 1 Train Loss: 0.6817
Epoch 4 Step 51 Train Loss: 0.6297
Epoch 4 Step 101 Train Loss: 0.5754
Epoch 4 Step 151 Train Loss: 0.6034
Epoch 4 Step 201 Train Loss: 0.5537
Epoch 4 Step 251 Train Loss: 0.5508
Epoch 4 Step 301 Train Loss: 0.6241
Epoch 4 Step 351 Train Loss: 0.6041
Epoch 4 Step 401 Train Loss: 0.6344
Epoch 4 Step 451 Train Loss: 0.5698
Epoch 4 Step 501 Train Loss: 0.6074
Epoch 4 Step 551 Train Loss: 0.6498
Epoch 4 Step 601 Train Loss: 0.6044
Epoch 4 Step 651 Train Loss: 0.5634
Epoch 4 Step 701 Train Loss: 0.6384
Epoch 4 Step 751 Train Loss: 0.5943
Epoch 4 Step 801 Train Loss: 0.6009
Epoch 4 Step 851 Train Loss: 0.5783
Epoch 4 Step 901 Train Loss: 0.5585
Epoch 4 Step 951 Train Loss: 0.5918
Epoch 4 Step 1001 Train Loss: 0.5739
Epoch 4 Step 1051 Train Loss: 0.6155
Epoch 4 Step 1101 Train Loss: 0.6028
Epoch 4 Step 1151 Train Loss: 0.5822
Epoch 4 Step 1201 Train Loss: 0.5821
Epoch 4 Step 1251 Train Loss: 0.5981
Epoch 4 Step 1301 Train Loss: 0.6016
Epoch 4 Step 1351 Train Loss: 0.5855
Epoch 4 Step 1401 Train Loss: 0.6637
Epoch 4 Step 1451 Train Loss: 0.5752
Epoch 4 Step 1501 Train Loss: 0.5630
Epoch 4 Step 1551 Train Loss: 0.5716
Epoch 4 Step 1601 Train Loss: 0.6022
Epoch 4 Step 1651 Train Loss: 0.6223
Epoch 4 Step 1701 Train Loss: 0.5534
Epoch 4 Step 1751 Train Loss: 0.6221
Epoch 4 Step 1801 Train Loss: 0.5900
Epoch 4 Step 1851 Train Loss: 0.5827
Epoch 4 Step 1901 Train Loss: 0.5708
Epoch 4 Step 1951 Train Loss: 0.6038
Epoch 4 Step 2001 Train Loss: 0.5456
Epoch 4 Step 2051 Train Loss: 0.6094
Epoch 4 Step 2101 Train Loss: 0.6370
Epoch 4 Step 2151 Train Loss: 0.5760
Epoch 4 Step 2201 Train Loss: 0.5459
Epoch 4 Step 2251 Train Loss: 0.6471
Epoch 4 Step 2301 Train Loss: 0.6172
Epoch 4 Step 2351 Train Loss: 0.5773
Epoch 4 Step 2401 Train Loss: 0.6124
Epoch 4 Step 2451 Train Loss: 0.5758
Epoch 4 Step 2501 Train Loss: 0.5929
Epoch 4 Step 2551 Train Loss: 0.5748
Epoch 4 Step 2601 Train Loss: 0.5952
Epoch 4 Step 2651 Train Loss: 0.6009
Epoch 4 Step 2701 Train Loss: 0.5725
Epoch 4 Step 2751 Train Loss: 0.5647
Epoch 4 Step 2801 Train Loss: 0.6631
Epoch 4 Step 2851 Train Loss: 0.5965
Epoch 4 Step 2901 Train Loss: 0.5918
Epoch 4 Step 2951 Train Loss: 0.6423
Epoch 4 Step 3001 Train Loss: 0.6166
Epoch 4 Step 3051 Train Loss: 0.5716
Epoch 4 Step 3101 Train Loss: 0.5894
Epoch 4: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0154. 
Train Top 20 DE MSE: 0.1179 Validation Top 20 DE MSE: 0.1184. 
Epoch 5 Step 1 Train Loss: 0.5864
Epoch 5 Step 51 Train Loss: 0.6337
Epoch 5 Step 101 Train Loss: 0.6359
Epoch 5 Step 151 Train Loss: 0.6017
Epoch 5 Step 201 Train Loss: 0.5608
Epoch 5 Step 251 Train Loss: 0.5455
Epoch 5 Step 301 Train Loss: 0.6305
Epoch 5 Step 351 Train Loss: 0.6140
Epoch 5 Step 401 Train Loss: 0.5844
Epoch 5 Step 451 Train Loss: 0.5787
Epoch 5 Step 501 Train Loss: 0.6790
Epoch 5 Step 551 Train Loss: 0.5827
Epoch 5 Step 601 Train Loss: 0.5922
Epoch 5 Step 651 Train Loss: 0.6023
Epoch 5 Step 701 Train Loss: 0.6033
Epoch 5 Step 751 Train Loss: 0.6103
Epoch 5 Step 801 Train Loss: 0.6056
Epoch 5 Step 851 Train Loss: 0.5894
Epoch 5 Step 901 Train Loss: 0.6045
Epoch 5 Step 951 Train Loss: 0.5661
Epoch 5 Step 1001 Train Loss: 0.5407
Epoch 5 Step 1051 Train Loss: 0.5873
Epoch 5 Step 1101 Train Loss: 0.6442
Epoch 5 Step 1151 Train Loss: 0.6693
Epoch 5 Step 1201 Train Loss: 0.5906
Epoch 5 Step 1251 Train Loss: 0.5823
Epoch 5 Step 1301 Train Loss: 0.5779
Epoch 5 Step 1351 Train Loss: 0.5445
Epoch 5 Step 1401 Train Loss: 0.5625
Epoch 5 Step 1451 Train Loss: 0.5541
Epoch 5 Step 1501 Train Loss: 0.5793
Epoch 5 Step 1551 Train Loss: 0.5934
Epoch 5 Step 1601 Train Loss: 0.5896
Epoch 5 Step 1651 Train Loss: 0.5932
Epoch 5 Step 1701 Train Loss: 0.5928
Epoch 5 Step 1751 Train Loss: 0.5801
Epoch 5 Step 1801 Train Loss: 0.5654
Epoch 5 Step 1851 Train Loss: 0.5569
Epoch 5 Step 1901 Train Loss: 0.5640
Epoch 5 Step 1951 Train Loss: 0.5646
Epoch 5 Step 2001 Train Loss: 0.5630
Epoch 5 Step 2051 Train Loss: 0.6237
Epoch 5 Step 2101 Train Loss: 0.6195
Epoch 5 Step 2151 Train Loss: 0.5928
Epoch 5 Step 2201 Train Loss: 0.6096
Epoch 5 Step 2251 Train Loss: 0.5512
Epoch 5 Step 2301 Train Loss: 0.5833
Epoch 5 Step 2351 Train Loss: 0.5682
Epoch 5 Step 2401 Train Loss: 0.6008
Epoch 5 Step 2451 Train Loss: 0.6154
Epoch 5 Step 2501 Train Loss: 0.6383
Epoch 5 Step 2551 Train Loss: 0.5616
Epoch 5 Step 2601 Train Loss: 0.5441
Epoch 5 Step 2651 Train Loss: 0.6028
Epoch 5 Step 2701 Train Loss: 0.5924
Epoch 5 Step 2751 Train Loss: 0.5684
Epoch 5 Step 2801 Train Loss: 0.6042
Epoch 5 Step 2851 Train Loss: 0.5770
Epoch 5 Step 2901 Train Loss: 0.6460
Epoch 5 Step 2951 Train Loss: 0.5819
Epoch 5 Step 3001 Train Loss: 0.5806
Epoch 5 Step 3051 Train Loss: 0.6274
Epoch 5 Step 3101 Train Loss: 0.5937
Epoch 5: Train Overall MSE: 0.0118 Validation Overall MSE: 0.0149. 
Train Top 20 DE MSE: 0.1192 Validation Top 20 DE MSE: 0.1195. 
Epoch 6 Step 1 Train Loss: 0.5579
Epoch 6 Step 51 Train Loss: 0.6666
Epoch 6 Step 101 Train Loss: 0.5524
Epoch 6 Step 151 Train Loss: 0.5702
Epoch 6 Step 201 Train Loss: 0.5428
Epoch 6 Step 251 Train Loss: 0.6511
Epoch 6 Step 301 Train Loss: 0.6050
Epoch 6 Step 351 Train Loss: 0.6081
Epoch 6 Step 401 Train Loss: 0.5968
Epoch 6 Step 451 Train Loss: 0.5775
Epoch 6 Step 501 Train Loss: 0.6224
Epoch 6 Step 551 Train Loss: 0.6024
Epoch 6 Step 601 Train Loss: 0.6030
Epoch 6 Step 651 Train Loss: 0.6056
Epoch 6 Step 701 Train Loss: 0.5736
Epoch 6 Step 751 Train Loss: 0.5873
Epoch 6 Step 801 Train Loss: 0.5842
Epoch 6 Step 851 Train Loss: 0.5611
Epoch 6 Step 901 Train Loss: 0.5776
Epoch 6 Step 951 Train Loss: 0.5480
Epoch 6 Step 1001 Train Loss: 0.5590
Epoch 6 Step 1051 Train Loss: 0.6425
Epoch 6 Step 1101 Train Loss: 0.6193
Epoch 6 Step 1151 Train Loss: 0.5301
Epoch 6 Step 1201 Train Loss: 0.6135
Epoch 6 Step 1251 Train Loss: 0.5862
Epoch 6 Step 1301 Train Loss: 0.5695
Epoch 6 Step 1351 Train Loss: 0.6206
Epoch 6 Step 1401 Train Loss: 0.6136
Epoch 6 Step 1451 Train Loss: 0.6007
Epoch 6 Step 1501 Train Loss: 0.5818
Epoch 6 Step 1551 Train Loss: 0.5793
Epoch 6 Step 1601 Train Loss: 0.6182
Epoch 6 Step 1651 Train Loss: 0.5900
Epoch 6 Step 1701 Train Loss: 0.6004
Epoch 6 Step 1751 Train Loss: 0.5931
Epoch 6 Step 1801 Train Loss: 0.5874
Epoch 6 Step 1851 Train Loss: 0.5872
Epoch 6 Step 1901 Train Loss: 0.6075
Epoch 6 Step 1951 Train Loss: 0.6440
Epoch 6 Step 2001 Train Loss: 0.6133
Epoch 6 Step 2051 Train Loss: 0.6134
Epoch 6 Step 2101 Train Loss: 0.6337
Epoch 6 Step 2151 Train Loss: 0.6052
Epoch 6 Step 2201 Train Loss: 0.5787
Epoch 6 Step 2251 Train Loss: 0.6241
Epoch 6 Step 2301 Train Loss: 0.6163
Epoch 6 Step 2351 Train Loss: 0.5854
Epoch 6 Step 2401 Train Loss: 0.6240
Epoch 6 Step 2451 Train Loss: 0.5987
Epoch 6 Step 2501 Train Loss: 0.6306
Epoch 6 Step 2551 Train Loss: 0.5704
Epoch 6 Step 2601 Train Loss: 0.5936
Epoch 6 Step 2651 Train Loss: 0.6203
Epoch 6 Step 2701 Train Loss: 0.6056
Epoch 6 Step 2751 Train Loss: 0.6500
Epoch 6 Step 2801 Train Loss: 0.5467
Epoch 6 Step 2851 Train Loss: 0.6378
Epoch 6 Step 2901 Train Loss: 0.5904
Epoch 6 Step 2951 Train Loss: 0.6024
Epoch 6 Step 3001 Train Loss: 0.5611
Epoch 6 Step 3051 Train Loss: 0.5762
Epoch 6 Step 3101 Train Loss: 0.6043
Epoch 6: Train Overall MSE: 0.0114 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1116 Validation Top 20 DE MSE: 0.1135. 
Epoch 7 Step 1 Train Loss: 0.6211
Epoch 7 Step 51 Train Loss: 0.5638
Epoch 7 Step 101 Train Loss: 0.5741
Epoch 7 Step 151 Train Loss: 0.6017
Epoch 7 Step 201 Train Loss: 0.5977
Epoch 7 Step 251 Train Loss: 0.5923
Epoch 7 Step 301 Train Loss: 0.6227
Epoch 7 Step 351 Train Loss: 0.5636
Epoch 7 Step 401 Train Loss: 0.5838
Epoch 7 Step 451 Train Loss: 0.5819
Epoch 7 Step 501 Train Loss: 0.5414
Epoch 7 Step 551 Train Loss: 0.5978
Epoch 7 Step 601 Train Loss: 0.5624
Epoch 7 Step 651 Train Loss: 0.5272
Epoch 7 Step 701 Train Loss: 0.6329
Epoch 7 Step 751 Train Loss: 0.5944
Epoch 7 Step 801 Train Loss: 0.5828
Epoch 7 Step 851 Train Loss: 0.5660
Epoch 7 Step 901 Train Loss: 0.6131
Epoch 7 Step 951 Train Loss: 0.5808
Epoch 7 Step 1001 Train Loss: 0.6207
Epoch 7 Step 1051 Train Loss: 0.5932
Epoch 7 Step 1101 Train Loss: 0.6025
Epoch 7 Step 1151 Train Loss: 0.6252
Epoch 7 Step 1201 Train Loss: 0.5883
Epoch 7 Step 1251 Train Loss: 0.5767
Epoch 7 Step 1301 Train Loss: 0.5888
Epoch 7 Step 1351 Train Loss: 0.5905
Epoch 7 Step 1401 Train Loss: 0.6078
Epoch 7 Step 1451 Train Loss: 0.5703
Epoch 7 Step 1501 Train Loss: 0.5469
Epoch 7 Step 1551 Train Loss: 0.6156
Epoch 7 Step 1601 Train Loss: 0.5893
Epoch 7 Step 1651 Train Loss: 0.5966
Epoch 7 Step 1701 Train Loss: 0.5855
Epoch 7 Step 1751 Train Loss: 0.6097
Epoch 7 Step 1801 Train Loss: 0.5547
Epoch 7 Step 1851 Train Loss: 0.5608
Epoch 7 Step 1901 Train Loss: 0.5639
Epoch 7 Step 1951 Train Loss: 0.6393
Epoch 7 Step 2001 Train Loss: 0.5951
Epoch 7 Step 2051 Train Loss: 0.5849
Epoch 7 Step 2101 Train Loss: 0.5459
Epoch 7 Step 2151 Train Loss: 0.5523
Epoch 7 Step 2201 Train Loss: 0.5505
Epoch 7 Step 2251 Train Loss: 0.5835
Epoch 7 Step 2301 Train Loss: 0.5560
Epoch 7 Step 2351 Train Loss: 0.6335
Epoch 7 Step 2401 Train Loss: 0.5510
Epoch 7 Step 2451 Train Loss: 0.6000
Epoch 7 Step 2501 Train Loss: 0.5763
Epoch 7 Step 2551 Train Loss: 0.6550
Epoch 7 Step 2601 Train Loss: 0.5675
Epoch 7 Step 2651 Train Loss: 0.5682
Epoch 7 Step 2701 Train Loss: 0.6300
Epoch 7 Step 2751 Train Loss: 0.5815
Epoch 7 Step 2801 Train Loss: 0.6240
Epoch 7 Step 2851 Train Loss: 0.5955
Epoch 7 Step 2901 Train Loss: 0.6590
Epoch 7 Step 2951 Train Loss: 0.5825
Epoch 7 Step 3001 Train Loss: 0.6266
Epoch 7 Step 3051 Train Loss: 0.6008
Epoch 7 Step 3101 Train Loss: 0.5997
Epoch 7: Train Overall MSE: 0.0114 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1115 Validation Top 20 DE MSE: 0.1123. 
Epoch 8 Step 1 Train Loss: 0.5830
Epoch 8 Step 51 Train Loss: 0.6056
Epoch 8 Step 101 Train Loss: 0.6741
Epoch 8 Step 151 Train Loss: 0.6567
Epoch 8 Step 201 Train Loss: 0.5395
Epoch 8 Step 251 Train Loss: 0.6216
Epoch 8 Step 301 Train Loss: 0.5711
Epoch 8 Step 351 Train Loss: 0.5881
Epoch 8 Step 401 Train Loss: 0.6632
Epoch 8 Step 451 Train Loss: 0.6101
Epoch 8 Step 501 Train Loss: 0.5398
Epoch 8 Step 551 Train Loss: 0.6208
Epoch 8 Step 601 Train Loss: 0.6159
Epoch 8 Step 651 Train Loss: 0.6886
Epoch 8 Step 701 Train Loss: 0.6261
Epoch 8 Step 751 Train Loss: 0.5745
Epoch 8 Step 801 Train Loss: 0.5739
Epoch 8 Step 851 Train Loss: 0.5841
Epoch 8 Step 901 Train Loss: 0.5633
Epoch 8 Step 951 Train Loss: 0.5452
Epoch 8 Step 1001 Train Loss: 0.5570
Epoch 8 Step 1051 Train Loss: 0.5829
Epoch 8 Step 1101 Train Loss: 0.6023
Epoch 8 Step 1151 Train Loss: 0.6448
Epoch 8 Step 1201 Train Loss: 0.6431
Epoch 8 Step 1251 Train Loss: 0.5687
Epoch 8 Step 1301 Train Loss: 0.5922
Epoch 8 Step 1351 Train Loss: 0.5545
Epoch 8 Step 1401 Train Loss: 0.5412
Epoch 8 Step 1451 Train Loss: 0.5718
Epoch 8 Step 1501 Train Loss: 0.5450
Epoch 8 Step 1551 Train Loss: 0.5747
Epoch 8 Step 1601 Train Loss: 0.5525
Epoch 8 Step 1651 Train Loss: 0.5794
Epoch 8 Step 1701 Train Loss: 0.5397
Epoch 8 Step 1751 Train Loss: 0.6313
Epoch 8 Step 1801 Train Loss: 0.6356
Epoch 8 Step 1851 Train Loss: 0.6132
Epoch 8 Step 1901 Train Loss: 0.6451
Epoch 8 Step 1951 Train Loss: 0.6091
Epoch 8 Step 2001 Train Loss: 0.6326
Epoch 8 Step 2051 Train Loss: 0.5818
Epoch 8 Step 2101 Train Loss: 0.5692
Epoch 8 Step 2151 Train Loss: 0.5877
Epoch 8 Step 2201 Train Loss: 0.5695
Epoch 8 Step 2251 Train Loss: 0.5802
Epoch 8 Step 2301 Train Loss: 0.5367
Epoch 8 Step 2351 Train Loss: 0.6051
Epoch 8 Step 2401 Train Loss: 0.5783
Epoch 8 Step 2451 Train Loss: 0.5807
Epoch 8 Step 2501 Train Loss: 0.5960
Epoch 8 Step 2551 Train Loss: 0.6197
Epoch 8 Step 2601 Train Loss: 0.6003
Epoch 8 Step 2651 Train Loss: 0.6008
Epoch 8 Step 2701 Train Loss: 0.5601
Epoch 8 Step 2751 Train Loss: 0.5449
Epoch 8 Step 2801 Train Loss: 0.5965
Epoch 8 Step 2851 Train Loss: 0.5146
Epoch 8 Step 2901 Train Loss: 0.6119
Epoch 8 Step 2951 Train Loss: 0.5976
Epoch 8 Step 3001 Train Loss: 0.5645
Epoch 8 Step 3051 Train Loss: 0.6141
Epoch 8 Step 3101 Train Loss: 0.6169
Epoch 8: Train Overall MSE: 0.0114 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1112 Validation Top 20 DE MSE: 0.1128. 
Epoch 9 Step 1 Train Loss: 0.5091
Epoch 9 Step 51 Train Loss: 0.5807
Epoch 9 Step 101 Train Loss: 0.5634
Epoch 9 Step 151 Train Loss: 0.5536
Epoch 9 Step 201 Train Loss: 0.6173
Epoch 9 Step 251 Train Loss: 0.5725
Epoch 9 Step 301 Train Loss: 0.5804
Epoch 9 Step 351 Train Loss: 0.6944
Epoch 9 Step 401 Train Loss: 0.5504
Epoch 9 Step 451 Train Loss: 0.5132
Epoch 9 Step 501 Train Loss: 0.5586
Epoch 9 Step 551 Train Loss: 0.5743
Epoch 9 Step 601 Train Loss: 0.6144
Epoch 9 Step 651 Train Loss: 0.5922
Epoch 9 Step 701 Train Loss: 0.5888
Epoch 9 Step 751 Train Loss: 0.5737
Epoch 9 Step 801 Train Loss: 0.5205
Epoch 9 Step 851 Train Loss: 0.5677
Epoch 9 Step 901 Train Loss: 0.5956
Epoch 9 Step 951 Train Loss: 0.5890
Epoch 9 Step 1001 Train Loss: 0.5984
Epoch 9 Step 1051 Train Loss: 0.5685
Epoch 9 Step 1101 Train Loss: 0.5809
Epoch 9 Step 1151 Train Loss: 0.5994
Epoch 9 Step 1201 Train Loss: 0.6284
Epoch 9 Step 1251 Train Loss: 0.5431
Epoch 9 Step 1301 Train Loss: 0.5495
Epoch 9 Step 1351 Train Loss: 0.5897
Epoch 9 Step 1401 Train Loss: 0.6291
Epoch 9 Step 1451 Train Loss: 0.5612
Epoch 9 Step 1501 Train Loss: 0.6142
Epoch 9 Step 1551 Train Loss: 0.5709
Epoch 9 Step 1601 Train Loss: 0.5717
Epoch 9 Step 1651 Train Loss: 0.6253
Epoch 9 Step 1701 Train Loss: 0.5678
Epoch 9 Step 1751 Train Loss: 0.5514
Epoch 9 Step 1801 Train Loss: 0.5621
Epoch 9 Step 1851 Train Loss: 0.5813
Epoch 9 Step 1901 Train Loss: 0.6535
Epoch 9 Step 1951 Train Loss: 0.5907
Epoch 9 Step 2001 Train Loss: 0.6076
Epoch 9 Step 2051 Train Loss: 0.6006
Epoch 9 Step 2101 Train Loss: 0.6053
Epoch 9 Step 2151 Train Loss: 0.6142
Epoch 9 Step 2201 Train Loss: 0.6508
Epoch 9 Step 2251 Train Loss: 0.5792
Epoch 9 Step 2301 Train Loss: 0.5924
Epoch 9 Step 2351 Train Loss: 0.6083
Epoch 9 Step 2401 Train Loss: 0.5942
Epoch 9 Step 2451 Train Loss: 0.5971
Epoch 9 Step 2501 Train Loss: 0.5760
Epoch 9 Step 2551 Train Loss: 0.5453
Epoch 9 Step 2601 Train Loss: 0.5780
Epoch 9 Step 2651 Train Loss: 0.5859
Epoch 9 Step 2701 Train Loss: 0.5892
Epoch 9 Step 2751 Train Loss: 0.5967
Epoch 9 Step 2801 Train Loss: 0.5966
Epoch 9 Step 2851 Train Loss: 0.5397
Epoch 9 Step 2901 Train Loss: 0.6421
Epoch 9 Step 2951 Train Loss: 0.5728
Epoch 9 Step 3001 Train Loss: 0.5934
Epoch 9 Step 3051 Train Loss: 0.6030
Epoch 9 Step 3101 Train Loss: 0.6477
Epoch 9: Train Overall MSE: 0.0114 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1110 Validation Top 20 DE MSE: 0.1131. 
Epoch 10 Step 1 Train Loss: 0.6296
Epoch 10 Step 51 Train Loss: 0.6331
Epoch 10 Step 101 Train Loss: 0.5772
Epoch 10 Step 151 Train Loss: 0.6093
Epoch 10 Step 201 Train Loss: 0.6141
Epoch 10 Step 251 Train Loss: 0.5432
Epoch 10 Step 301 Train Loss: 0.6147
Epoch 10 Step 351 Train Loss: 0.5962
Epoch 10 Step 401 Train Loss: 0.5943
Epoch 10 Step 451 Train Loss: 0.5592
Epoch 10 Step 501 Train Loss: 0.5906
Epoch 10 Step 551 Train Loss: 0.5754
Epoch 10 Step 601 Train Loss: 0.6381
Epoch 10 Step 651 Train Loss: 0.5769
Epoch 10 Step 701 Train Loss: 0.6259
Epoch 10 Step 751 Train Loss: 0.5986
Epoch 10 Step 801 Train Loss: 0.5879
Epoch 10 Step 851 Train Loss: 0.5343
Epoch 10 Step 901 Train Loss: 0.6731
Epoch 10 Step 951 Train Loss: 0.6438
Epoch 10 Step 1001 Train Loss: 0.5966
Epoch 10 Step 1051 Train Loss: 0.6196
Epoch 10 Step 1101 Train Loss: 0.5355
Epoch 10 Step 1151 Train Loss: 0.5975
Epoch 10 Step 1201 Train Loss: 0.6021
Epoch 10 Step 1251 Train Loss: 0.5976
Epoch 10 Step 1301 Train Loss: 0.5868
Epoch 10 Step 1351 Train Loss: 0.5710
Epoch 10 Step 1401 Train Loss: 0.6143
Epoch 10 Step 1451 Train Loss: 0.6480
Epoch 10 Step 1501 Train Loss: 0.5662
Epoch 10 Step 1551 Train Loss: 0.6094
Epoch 10 Step 1601 Train Loss: 0.6171
Epoch 10 Step 1651 Train Loss: 0.5631
Epoch 10 Step 1701 Train Loss: 0.6541
Epoch 10 Step 1751 Train Loss: 0.6116
Epoch 10 Step 1801 Train Loss: 0.5874
Epoch 10 Step 1851 Train Loss: 0.6069
Epoch 10 Step 1901 Train Loss: 0.6231
Epoch 10 Step 1951 Train Loss: 0.6213
Epoch 10 Step 2001 Train Loss: 0.6169
Epoch 10 Step 2051 Train Loss: 0.6329
Epoch 10 Step 2101 Train Loss: 0.6018
Epoch 10 Step 2151 Train Loss: 0.6114
Epoch 10 Step 2201 Train Loss: 0.6096
Epoch 10 Step 2251 Train Loss: 0.5584
Epoch 10 Step 2301 Train Loss: 0.5957
Epoch 10 Step 2351 Train Loss: 0.5944
Epoch 10 Step 2401 Train Loss: 0.5873
Epoch 10 Step 2451 Train Loss: 0.5903
Epoch 10 Step 2501 Train Loss: 0.5746
Epoch 10 Step 2551 Train Loss: 0.6114
Epoch 10 Step 2601 Train Loss: 0.6092
Epoch 10 Step 2651 Train Loss: 0.5563
Epoch 10 Step 2701 Train Loss: 0.6278
Epoch 10 Step 2751 Train Loss: 0.5718
Epoch 10 Step 2801 Train Loss: 0.5745
Epoch 10 Step 2851 Train Loss: 0.6114
Epoch 10 Step 2901 Train Loss: 0.5572
Epoch 10 Step 2951 Train Loss: 0.6130
Epoch 10 Step 3001 Train Loss: 0.5950
Epoch 10 Step 3051 Train Loss: 0.5887
Epoch 10 Step 3101 Train Loss: 0.5349
Epoch 10: Train Overall MSE: 0.0113 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1099 Validation Top 20 DE MSE: 0.1115. 
Epoch 11 Step 1 Train Loss: 0.6293
Epoch 11 Step 51 Train Loss: 0.6171
Epoch 11 Step 101 Train Loss: 0.6033
Epoch 11 Step 151 Train Loss: 0.6477
Epoch 11 Step 201 Train Loss: 0.6280
Epoch 11 Step 251 Train Loss: 0.5654
Epoch 11 Step 301 Train Loss: 0.6158
Epoch 11 Step 351 Train Loss: 0.5776
Epoch 11 Step 401 Train Loss: 0.6067
Epoch 11 Step 451 Train Loss: 0.5880
Epoch 11 Step 501 Train Loss: 0.6455
Epoch 11 Step 551 Train Loss: 0.5759
Epoch 11 Step 601 Train Loss: 0.5674
Epoch 11 Step 651 Train Loss: 0.5641
Epoch 11 Step 701 Train Loss: 0.5882
Epoch 11 Step 751 Train Loss: 0.5393
Epoch 11 Step 801 Train Loss: 0.6469
Epoch 11 Step 851 Train Loss: 0.5872
Epoch 11 Step 901 Train Loss: 0.6078
Epoch 11 Step 951 Train Loss: 0.6146
Epoch 11 Step 1001 Train Loss: 0.6121
Epoch 11 Step 1051 Train Loss: 0.5897
Epoch 11 Step 1101 Train Loss: 0.5992
Epoch 11 Step 1151 Train Loss: 0.5873
Epoch 11 Step 1201 Train Loss: 0.5968
Epoch 11 Step 1251 Train Loss: 0.6553
Epoch 11 Step 1301 Train Loss: 0.6038
Epoch 11 Step 1351 Train Loss: 0.5733
Epoch 11 Step 1401 Train Loss: 0.5978
Epoch 11 Step 1451 Train Loss: 0.6416
Epoch 11 Step 1501 Train Loss: 0.6045
Epoch 11 Step 1551 Train Loss: 0.6256
Epoch 11 Step 1601 Train Loss: 0.5921
Epoch 11 Step 1651 Train Loss: 0.6314
Epoch 11 Step 1701 Train Loss: 0.5784
Epoch 11 Step 1751 Train Loss: 0.5849
Epoch 11 Step 1801 Train Loss: 0.5986
Epoch 11 Step 1851 Train Loss: 0.5290
Epoch 11 Step 1901 Train Loss: 0.6172
Epoch 11 Step 1951 Train Loss: 0.6532
Epoch 11 Step 2001 Train Loss: 0.5716
Epoch 11 Step 2051 Train Loss: 0.5925
Epoch 11 Step 2101 Train Loss: 0.6354
Epoch 11 Step 2151 Train Loss: 0.5666
Epoch 11 Step 2201 Train Loss: 0.5767
Epoch 11 Step 2251 Train Loss: 0.5214
Epoch 11 Step 2301 Train Loss: 0.5792
Epoch 11 Step 2351 Train Loss: 0.5158
Epoch 11 Step 2401 Train Loss: 0.5187
Epoch 11 Step 2451 Train Loss: 0.5715
Epoch 11 Step 2501 Train Loss: 0.6165
Epoch 11 Step 2551 Train Loss: 0.5987
Epoch 11 Step 2601 Train Loss: 0.5918
Epoch 11 Step 2651 Train Loss: 0.5491
Epoch 11 Step 2701 Train Loss: 0.5925
Epoch 11 Step 2751 Train Loss: 0.6283
Epoch 11 Step 2801 Train Loss: 0.5837
Epoch 11 Step 2851 Train Loss: 0.6308
Epoch 11 Step 2901 Train Loss: 0.6090
Epoch 11 Step 2951 Train Loss: 0.6053
Epoch 11 Step 3001 Train Loss: 0.5827
Epoch 11 Step 3051 Train Loss: 0.5566
Epoch 11 Step 3101 Train Loss: 0.5950
Epoch 11: Train Overall MSE: 0.0113 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1083 Validation Top 20 DE MSE: 0.1110. 
Epoch 12 Step 1 Train Loss: 0.6057
Epoch 12 Step 51 Train Loss: 0.6392
Epoch 12 Step 101 Train Loss: 0.6061
Epoch 12 Step 151 Train Loss: 0.5478
Epoch 12 Step 201 Train Loss: 0.5826
Epoch 12 Step 251 Train Loss: 0.5704
Epoch 12 Step 301 Train Loss: 0.5838
Epoch 12 Step 351 Train Loss: 0.5730
Epoch 12 Step 401 Train Loss: 0.5680
Epoch 12 Step 451 Train Loss: 0.6066
Epoch 12 Step 501 Train Loss: 0.5962
Epoch 12 Step 551 Train Loss: 0.6071
Epoch 12 Step 601 Train Loss: 0.5919
Epoch 12 Step 651 Train Loss: 0.5685
Epoch 12 Step 701 Train Loss: 0.6403
Epoch 12 Step 751 Train Loss: 0.5705
Epoch 12 Step 801 Train Loss: 0.6006
Epoch 12 Step 851 Train Loss: 0.6325
Epoch 12 Step 901 Train Loss: 0.6126
Epoch 12 Step 951 Train Loss: 0.5898
Epoch 12 Step 1001 Train Loss: 0.5763
Epoch 12 Step 1051 Train Loss: 0.6730
Epoch 12 Step 1101 Train Loss: 0.6126
Epoch 12 Step 1151 Train Loss: 0.5753
Epoch 12 Step 1201 Train Loss: 0.5905
Epoch 12 Step 1251 Train Loss: 0.6013
Epoch 12 Step 1301 Train Loss: 0.5553
Epoch 12 Step 1351 Train Loss: 0.6320
Epoch 12 Step 1401 Train Loss: 0.5878
Epoch 12 Step 1451 Train Loss: 0.5752
Epoch 12 Step 1501 Train Loss: 0.6114
Epoch 12 Step 1551 Train Loss: 0.5835
Epoch 12 Step 1601 Train Loss: 0.5425
Epoch 12 Step 1651 Train Loss: 0.6504
Epoch 12 Step 1701 Train Loss: 0.6079
Epoch 12 Step 1751 Train Loss: 0.5861
Epoch 12 Step 1801 Train Loss: 0.5547
Epoch 12 Step 1851 Train Loss: 0.6445
Epoch 12 Step 1901 Train Loss: 0.6155
Epoch 12 Step 1951 Train Loss: 0.5855
Epoch 12 Step 2001 Train Loss: 0.6244
Epoch 12 Step 2051 Train Loss: 0.6280
Epoch 12 Step 2101 Train Loss: 0.6233
Epoch 12 Step 2151 Train Loss: 0.5962
Epoch 12 Step 2201 Train Loss: 0.5621
Epoch 12 Step 2251 Train Loss: 0.6063
Epoch 12 Step 2301 Train Loss: 0.5634
Epoch 12 Step 2351 Train Loss: 0.5594
Epoch 12 Step 2401 Train Loss: 0.6288
Epoch 12 Step 2451 Train Loss: 0.5811
Epoch 12 Step 2501 Train Loss: 0.6014
Epoch 12 Step 2551 Train Loss: 0.5794
Epoch 12 Step 2601 Train Loss: 0.5891
Epoch 12 Step 2651 Train Loss: 0.5895
Epoch 12 Step 2701 Train Loss: 0.6025
Epoch 12 Step 2751 Train Loss: 0.5551
Epoch 12 Step 2801 Train Loss: 0.5920
Epoch 12 Step 2851 Train Loss: 0.5633
Epoch 12 Step 2901 Train Loss: 0.6174
Epoch 12 Step 2951 Train Loss: 0.6104
Epoch 12 Step 3001 Train Loss: 0.5516
Epoch 12 Step 3051 Train Loss: 0.6002
Epoch 12 Step 3101 Train Loss: 0.5641
Epoch 12: Train Overall MSE: 0.0114 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1113 Validation Top 20 DE MSE: 0.1125. 
Epoch 13 Step 1 Train Loss: 0.6038
Epoch 13 Step 51 Train Loss: 0.6064
Epoch 13 Step 101 Train Loss: 0.5858
Epoch 13 Step 151 Train Loss: 0.6400
Epoch 13 Step 201 Train Loss: 0.6168
Epoch 13 Step 251 Train Loss: 0.6165
Epoch 13 Step 301 Train Loss: 0.6780
Epoch 13 Step 351 Train Loss: 0.5919
Epoch 13 Step 401 Train Loss: 0.6175
Epoch 13 Step 451 Train Loss: 0.5997
Epoch 13 Step 501 Train Loss: 0.5699
Epoch 13 Step 551 Train Loss: 0.6414
Epoch 13 Step 601 Train Loss: 0.5850
Epoch 13 Step 651 Train Loss: 0.6478
Epoch 13 Step 701 Train Loss: 0.5383
Epoch 13 Step 751 Train Loss: 0.5683
Epoch 13 Step 801 Train Loss: 0.7046
Epoch 13 Step 851 Train Loss: 0.5961
Epoch 13 Step 901 Train Loss: 0.5609
Epoch 13 Step 951 Train Loss: 0.5367
Epoch 13 Step 1001 Train Loss: 0.5679
Epoch 13 Step 1051 Train Loss: 0.5426
Epoch 13 Step 1101 Train Loss: 0.5898
Epoch 13 Step 1151 Train Loss: 0.5891
Epoch 13 Step 1201 Train Loss: 0.6134
Epoch 13 Step 1251 Train Loss: 0.5795
Epoch 13 Step 1301 Train Loss: 0.5849
Epoch 13 Step 1351 Train Loss: 0.6178
Epoch 13 Step 1401 Train Loss: 0.5802
Epoch 13 Step 1451 Train Loss: 0.6729
Epoch 13 Step 1501 Train Loss: 0.6119
Epoch 13 Step 1551 Train Loss: 0.6140
Epoch 13 Step 1601 Train Loss: 0.5640
Epoch 13 Step 1651 Train Loss: 0.5962
Epoch 13 Step 1701 Train Loss: 0.6367
Epoch 13 Step 1751 Train Loss: 0.6218
Epoch 13 Step 1801 Train Loss: 0.5497
Epoch 13 Step 1851 Train Loss: 0.5871
Epoch 13 Step 1901 Train Loss: 0.5883
Epoch 13 Step 1951 Train Loss: 0.5921
Epoch 13 Step 2001 Train Loss: 0.6104
Epoch 13 Step 2051 Train Loss: 0.5276
Epoch 13 Step 2101 Train Loss: 0.5911
Epoch 13 Step 2151 Train Loss: 0.6602
Epoch 13 Step 2201 Train Loss: 0.5991
Epoch 13 Step 2251 Train Loss: 0.5929
Epoch 13 Step 2301 Train Loss: 0.5345
Epoch 13 Step 2351 Train Loss: 0.5662
Epoch 13 Step 2401 Train Loss: 0.5518
Epoch 13 Step 2451 Train Loss: 0.5989
Epoch 13 Step 2501 Train Loss: 0.6082
Epoch 13 Step 2551 Train Loss: 0.6436
Epoch 13 Step 2601 Train Loss: 0.6063
Epoch 13 Step 2651 Train Loss: 0.6155
Epoch 13 Step 2701 Train Loss: 0.6229
Epoch 13 Step 2751 Train Loss: 0.6009
Epoch 13 Step 2801 Train Loss: 0.6008
Epoch 13 Step 2851 Train Loss: 0.6022
Epoch 13 Step 2901 Train Loss: 0.5496
Epoch 13 Step 2951 Train Loss: 0.6208
Epoch 13 Step 3001 Train Loss: 0.5960
Epoch 13 Step 3051 Train Loss: 0.5788
Epoch 13 Step 3101 Train Loss: 0.6373
Epoch 13: Train Overall MSE: 0.0115 Validation Overall MSE: 0.0147. 
Train Top 20 DE MSE: 0.1130 Validation Top 20 DE MSE: 0.1153. 
Epoch 14 Step 1 Train Loss: 0.6234
Epoch 14 Step 51 Train Loss: 0.5952
Epoch 14 Step 101 Train Loss: 0.6264
Epoch 14 Step 151 Train Loss: 0.5539
Epoch 14 Step 201 Train Loss: 0.6131
Epoch 14 Step 251 Train Loss: 0.5919
Epoch 14 Step 301 Train Loss: 0.5478
Epoch 14 Step 351 Train Loss: 0.6301
Epoch 14 Step 401 Train Loss: 0.6404
Epoch 14 Step 451 Train Loss: 0.6053
Epoch 14 Step 501 Train Loss: 0.5902
Epoch 14 Step 551 Train Loss: 0.5581
Epoch 14 Step 601 Train Loss: 0.5906
Epoch 14 Step 651 Train Loss: 0.5953
Epoch 14 Step 701 Train Loss: 0.5947
Epoch 14 Step 751 Train Loss: 0.6420
Epoch 14 Step 801 Train Loss: 0.5658
Epoch 14 Step 851 Train Loss: 0.6009
Epoch 14 Step 901 Train Loss: 0.6314
Epoch 14 Step 951 Train Loss: 0.5836
Epoch 14 Step 1001 Train Loss: 0.6091
Epoch 14 Step 1051 Train Loss: 0.6149
Epoch 14 Step 1101 Train Loss: 0.5818
Epoch 14 Step 1151 Train Loss: 0.6490
Epoch 14 Step 1201 Train Loss: 0.5582
Epoch 14 Step 1251 Train Loss: 0.5799
Epoch 14 Step 1301 Train Loss: 0.6043
Epoch 14 Step 1351 Train Loss: 0.5649
Epoch 14 Step 1401 Train Loss: 0.5945
Epoch 14 Step 1451 Train Loss: 0.6168
Epoch 14 Step 1501 Train Loss: 0.6023
Epoch 14 Step 1551 Train Loss: 0.5466
Epoch 14 Step 1601 Train Loss: 0.5683
Epoch 14 Step 1651 Train Loss: 0.6241
Epoch 14 Step 1701 Train Loss: 0.6161
Epoch 14 Step 1751 Train Loss: 0.5704
Epoch 14 Step 1801 Train Loss: 0.5537
Epoch 14 Step 1851 Train Loss: 0.6340
Epoch 14 Step 1901 Train Loss: 0.5608
Epoch 14 Step 1951 Train Loss: 0.6055
Epoch 14 Step 2001 Train Loss: 0.5650
Epoch 14 Step 2051 Train Loss: 0.6029
Epoch 14 Step 2101 Train Loss: 0.6216
Epoch 14 Step 2151 Train Loss: 0.5331
Epoch 14 Step 2201 Train Loss: 0.5889
Epoch 14 Step 2251 Train Loss: 0.5889
Epoch 14 Step 2301 Train Loss: 0.5790
Epoch 14 Step 2351 Train Loss: 0.5066
Epoch 14 Step 2401 Train Loss: 0.5683
Epoch 14 Step 2451 Train Loss: 0.5397
Epoch 14 Step 2501 Train Loss: 0.5979
Epoch 14 Step 2551 Train Loss: 0.5690
Epoch 14 Step 2601 Train Loss: 0.5839
Epoch 14 Step 2651 Train Loss: 0.6041
Epoch 14 Step 2701 Train Loss: 0.5764
Epoch 14 Step 2751 Train Loss: 0.6146
Epoch 14 Step 2801 Train Loss: 0.6571
Epoch 14 Step 2851 Train Loss: 0.5798
Epoch 14 Step 2901 Train Loss: 0.5968
Epoch 14 Step 2951 Train Loss: 0.5453
Epoch 14 Step 3001 Train Loss: 0.5880
Epoch 14 Step 3051 Train Loss: 0.5419
Epoch 14 Step 3101 Train Loss: 0.5913
Epoch 14: Train Overall MSE: 0.0113 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1106 Validation Top 20 DE MSE: 0.1121. 
Epoch 15 Step 1 Train Loss: 0.5849
Epoch 15 Step 51 Train Loss: 0.6689
Epoch 15 Step 101 Train Loss: 0.6259
Epoch 15 Step 151 Train Loss: 0.5545
Epoch 15 Step 201 Train Loss: 0.5380
Epoch 15 Step 251 Train Loss: 0.6194
Epoch 15 Step 301 Train Loss: 0.5664
Epoch 15 Step 351 Train Loss: 0.5901
Epoch 15 Step 401 Train Loss: 0.6154
Epoch 15 Step 451 Train Loss: 0.6425
Epoch 15 Step 501 Train Loss: 0.5929
Epoch 15 Step 551 Train Loss: 0.6139
Epoch 15 Step 601 Train Loss: 0.5615
Epoch 15 Step 651 Train Loss: 0.6535
Epoch 15 Step 701 Train Loss: 0.6172
Epoch 15 Step 751 Train Loss: 0.5910
Epoch 15 Step 801 Train Loss: 0.5749
Epoch 15 Step 851 Train Loss: 0.5775
Epoch 15 Step 901 Train Loss: 0.5415
Epoch 15 Step 951 Train Loss: 0.6120
Epoch 15 Step 1001 Train Loss: 0.6182
Epoch 15 Step 1051 Train Loss: 0.5396
Epoch 15 Step 1101 Train Loss: 0.5963
Epoch 15 Step 1151 Train Loss: 0.5766
Epoch 15 Step 1201 Train Loss: 0.5491
Epoch 15 Step 1251 Train Loss: 0.5868
Epoch 15 Step 1301 Train Loss: 0.6403
Epoch 15 Step 1351 Train Loss: 0.5925
Epoch 15 Step 1401 Train Loss: 0.6236
Epoch 15 Step 1451 Train Loss: 0.6137
Epoch 15 Step 1501 Train Loss: 0.5541
Epoch 15 Step 1551 Train Loss: 0.5726
Epoch 15 Step 1601 Train Loss: 0.6031
Epoch 15 Step 1651 Train Loss: 0.5976
Epoch 15 Step 1701 Train Loss: 0.6506
Epoch 15 Step 1751 Train Loss: 0.5921
Epoch 15 Step 1801 Train Loss: 0.5695
Epoch 15 Step 1851 Train Loss: 0.6325
Epoch 15 Step 1901 Train Loss: 0.5460
Epoch 15 Step 1951 Train Loss: 0.6053
Epoch 15 Step 2001 Train Loss: 0.5484
Epoch 15 Step 2051 Train Loss: 0.6125
Epoch 15 Step 2101 Train Loss: 0.5656
Epoch 15 Step 2151 Train Loss: 0.5378
Epoch 15 Step 2201 Train Loss: 0.5552
Epoch 15 Step 2251 Train Loss: 0.5859
Epoch 15 Step 2301 Train Loss: 0.5453
Epoch 15 Step 2351 Train Loss: 0.5999
Epoch 15 Step 2401 Train Loss: 0.5714
Epoch 15 Step 2451 Train Loss: 0.5644
Epoch 15 Step 2501 Train Loss: 0.6751
Epoch 15 Step 2551 Train Loss: 0.5765
Epoch 15 Step 2601 Train Loss: 0.5951
Epoch 15 Step 2651 Train Loss: 0.5864
Epoch 15 Step 2701 Train Loss: 0.5790
Epoch 15 Step 2751 Train Loss: 0.5642
Epoch 15 Step 2801 Train Loss: 0.5883
Epoch 15 Step 2851 Train Loss: 0.6264
Epoch 15 Step 2901 Train Loss: 0.5468
Epoch 15 Step 2951 Train Loss: 0.5842
Epoch 15 Step 3001 Train Loss: 0.5915
Epoch 15 Step 3051 Train Loss: 0.5921
Epoch 15 Step 3101 Train Loss: 0.5891
Epoch 15: Train Overall MSE: 0.0114 Validation Overall MSE: 0.0146. 
Train Top 20 DE MSE: 0.1101 Validation Top 20 DE MSE: 0.1134. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1197
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0145838875
test_unseen_single_pearson: 0.9782040261141777
test_unseen_single_mse_de: 0.11965666
test_unseen_single_pearson_de: 0.6418048479902189
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.47360510846988163
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.21740947075208913
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5243732590529248
test_unseen_single_mse_top20_de_non_dropout: 0.17141643
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.052 MB uploadedwandb: | 0.001 MB of 0.052 MB uploadedwandb: / 0.001 MB of 0.052 MB uploadedwandb: - 0.042 MB of 0.052 MB uploadedwandb: \ 0.052 MB of 0.052 MB uploadedwandb: | 0.052 MB of 0.052 MB uploadedwandb: / 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                             train_de_pearson ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñá‚ñà‚ñÖ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñá‚ñÅ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.11966
wandb:                                              test_de_pearson 0.6418
wandb:               test_frac_opposite_direction_top20_non_dropout 0.21741
wandb:                          test_frac_sigma_below_1_non_dropout 0.52437
wandb:                                                     test_mse 0.01458
wandb:                                test_mse_top20_de_non_dropout 0.17142
wandb:                                                 test_pearson 0.9782
wandb:                                           test_pearson_delta 0.47361
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.21741
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.52437
wandb:                                       test_unseen_single_mse 0.01458
wandb:                                    test_unseen_single_mse_de 0.11966
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.17142
wandb:                                   test_unseen_single_pearson 0.9782
wandb:                                test_unseen_single_pearson_de 0.6418
wandb:                             test_unseen_single_pearson_delta 0.47361
wandb:                                                 train_de_mse 0.11009
wandb:                                             train_de_pearson 0.67451
wandb:                                                    train_mse 0.01139
wandb:                                                train_pearson 0.98289
wandb:                                                training_loss 0.60666
wandb:                                                   val_de_mse 0.11341
wandb:                                               val_de_pearson 0.6404
wandb:                                                      val_mse 0.01461
wandb:                                                  val_pearson 0.97809
wandb: 
wandb: üöÄ View run geneformer_Replogle_rpe1_essential_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/w23mytdk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_200118-w23mytdk/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:359
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240922_222640-6nidvc19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_rpe1_essential_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/6nidvc19
wandb: WARNING Serializing object of type ndarray that is 23564416 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5949
Epoch 1 Step 51 Train Loss: 0.6321
Epoch 1 Step 101 Train Loss: 0.5571
Epoch 1 Step 151 Train Loss: 0.5615
Epoch 1 Step 201 Train Loss: 0.6682
Epoch 1 Step 251 Train Loss: 0.5769
Epoch 1 Step 301 Train Loss: 0.6104
Epoch 1 Step 351 Train Loss: 0.5867
Epoch 1 Step 401 Train Loss: 0.6196
Epoch 1 Step 451 Train Loss: 0.5979
Epoch 1 Step 501 Train Loss: 0.5168
Epoch 1 Step 551 Train Loss: 0.5908
Epoch 1 Step 601 Train Loss: 0.6007
Epoch 1 Step 651 Train Loss: 0.6317
Epoch 1 Step 701 Train Loss: 0.5734
Epoch 1 Step 751 Train Loss: 0.5971
Epoch 1 Step 801 Train Loss: 0.5958
Epoch 1 Step 851 Train Loss: 0.6029
Epoch 1 Step 901 Train Loss: 0.5934
Epoch 1 Step 951 Train Loss: 0.6186
Epoch 1 Step 1001 Train Loss: 0.6183
Epoch 1 Step 1051 Train Loss: 0.6483
Epoch 1 Step 1101 Train Loss: 0.6043
Epoch 1 Step 1151 Train Loss: 0.6119
Epoch 1 Step 1201 Train Loss: 0.5801
Epoch 1 Step 1251 Train Loss: 0.6051
Epoch 1 Step 1301 Train Loss: 0.5820
Epoch 1 Step 1351 Train Loss: 0.5888
Epoch 1 Step 1401 Train Loss: 0.6128
Epoch 1 Step 1451 Train Loss: 0.5998
Epoch 1 Step 1501 Train Loss: 0.6925
Epoch 1 Step 1551 Train Loss: 0.5658
Epoch 1 Step 1601 Train Loss: 0.6667
Epoch 1 Step 1651 Train Loss: 0.5835
Epoch 1 Step 1701 Train Loss: 0.5682
Epoch 1 Step 1751 Train Loss: 0.6189
Epoch 1 Step 1801 Train Loss: 0.6029
Epoch 1 Step 1851 Train Loss: 0.6160
Epoch 1 Step 1901 Train Loss: 0.6001
Epoch 1 Step 1951 Train Loss: 0.6030
Epoch 1 Step 2001 Train Loss: 0.5699
Epoch 1 Step 2051 Train Loss: 0.6058
Epoch 1 Step 2101 Train Loss: 0.6010
Epoch 1 Step 2151 Train Loss: 0.5282
Epoch 1 Step 2201 Train Loss: 0.5763
Epoch 1 Step 2251 Train Loss: 0.6240
Epoch 1 Step 2301 Train Loss: 0.6860
Epoch 1 Step 2351 Train Loss: 0.5913
Epoch 1 Step 2401 Train Loss: 0.5710
Epoch 1 Step 2451 Train Loss: 0.6086
Epoch 1 Step 2501 Train Loss: 0.6340
Epoch 1 Step 2551 Train Loss: 0.6246
Epoch 1 Step 2601 Train Loss: 0.5743
Epoch 1 Step 2651 Train Loss: 0.6305
Epoch 1 Step 2701 Train Loss: 0.6249
Epoch 1 Step 2751 Train Loss: 0.5876
Epoch 1 Step 2801 Train Loss: 0.5692
Epoch 1 Step 2851 Train Loss: 0.5830
Epoch 1 Step 2901 Train Loss: 0.6468
Epoch 1 Step 2951 Train Loss: 0.6222
Epoch 1 Step 3001 Train Loss: 0.6218
Epoch 1 Step 3051 Train Loss: 0.5725
Epoch 1 Step 3101 Train Loss: 0.6101
Epoch 1: Train Overall MSE: 0.0145 Validation Overall MSE: 0.0151. 
Train Top 20 DE MSE: 0.1324 Validation Top 20 DE MSE: 0.1159. 
Epoch 2 Step 1 Train Loss: 0.6124
Epoch 2 Step 51 Train Loss: 0.5713
Epoch 2 Step 101 Train Loss: 0.5961
Epoch 2 Step 151 Train Loss: 0.5927
Epoch 2 Step 201 Train Loss: 0.6169
Epoch 2 Step 251 Train Loss: 0.6497
Epoch 2 Step 301 Train Loss: 0.6071
Epoch 2 Step 351 Train Loss: 0.5915
Epoch 2 Step 401 Train Loss: 0.5389
Epoch 2 Step 451 Train Loss: 0.6330
Epoch 2 Step 501 Train Loss: 0.5521
Epoch 2 Step 551 Train Loss: 0.5920
Epoch 2 Step 601 Train Loss: 0.6132
Epoch 2 Step 651 Train Loss: 0.6405
Epoch 2 Step 701 Train Loss: 0.5614
Epoch 2 Step 751 Train Loss: 0.6554
Epoch 2 Step 801 Train Loss: 0.6159
Epoch 2 Step 851 Train Loss: 0.6003
Epoch 2 Step 901 Train Loss: 0.6703
Epoch 2 Step 951 Train Loss: 0.5944
Epoch 2 Step 1001 Train Loss: 0.6153
Epoch 2 Step 1051 Train Loss: 0.6195
Epoch 2 Step 1101 Train Loss: 0.5997
Epoch 2 Step 1151 Train Loss: 0.5874
Epoch 2 Step 1201 Train Loss: 0.5984
Epoch 2 Step 1251 Train Loss: 0.5629
Epoch 2 Step 1301 Train Loss: 0.6407
Epoch 2 Step 1351 Train Loss: 0.5954
Epoch 2 Step 1401 Train Loss: 0.6183
Epoch 2 Step 1451 Train Loss: 0.6450
Epoch 2 Step 1501 Train Loss: 0.5536
Epoch 2 Step 1551 Train Loss: 0.6822
Epoch 2 Step 1601 Train Loss: 0.5999
Epoch 2 Step 1651 Train Loss: 0.5692
Epoch 2 Step 1701 Train Loss: 0.5701
Epoch 2 Step 1751 Train Loss: 0.6245
Epoch 2 Step 1801 Train Loss: 0.6440
Epoch 2 Step 1851 Train Loss: 0.6220
Epoch 2 Step 1901 Train Loss: 0.5838
Epoch 2 Step 1951 Train Loss: 0.6812
Epoch 2 Step 2001 Train Loss: 0.6157
Epoch 2 Step 2051 Train Loss: 0.5654
Epoch 2 Step 2101 Train Loss: 0.5704
Epoch 2 Step 2151 Train Loss: 0.5852
Epoch 2 Step 2201 Train Loss: 0.5642
Epoch 2 Step 2251 Train Loss: 0.6496
Epoch 2 Step 2301 Train Loss: 0.6113
Epoch 2 Step 2351 Train Loss: 0.6595
Epoch 2 Step 2401 Train Loss: 0.5774
Epoch 2 Step 2451 Train Loss: 0.6277
Epoch 2 Step 2501 Train Loss: 0.5659
Epoch 2 Step 2551 Train Loss: 0.5498
Epoch 2 Step 2601 Train Loss: 0.5765
Epoch 2 Step 2651 Train Loss: 0.5532
Epoch 2 Step 2701 Train Loss: 0.6104
Epoch 2 Step 2751 Train Loss: 0.7037
Epoch 2 Step 2801 Train Loss: 0.5733
Epoch 2 Step 2851 Train Loss: 0.6170
Epoch 2 Step 2901 Train Loss: 0.5604
Epoch 2 Step 2951 Train Loss: 0.6114
Epoch 2 Step 3001 Train Loss: 0.6366
Epoch 2 Step 3051 Train Loss: 0.6475
Epoch 2 Step 3101 Train Loss: 0.5758
Epoch 2: Train Overall MSE: 0.0136 Validation Overall MSE: 0.0148. 
Train Top 20 DE MSE: 0.1190 Validation Top 20 DE MSE: 0.1110. 
Epoch 3 Step 1 Train Loss: 0.5743
Epoch 3 Step 51 Train Loss: 0.5879
Epoch 3 Step 101 Train Loss: 0.6117
Epoch 3 Step 151 Train Loss: 0.6001
Epoch 3 Step 201 Train Loss: 0.5883
Epoch 3 Step 251 Train Loss: 0.5919
Epoch 3 Step 301 Train Loss: 0.5955
Epoch 3 Step 351 Train Loss: 0.6122
Epoch 3 Step 401 Train Loss: 0.5984
Epoch 3 Step 451 Train Loss: 0.6748
Epoch 3 Step 501 Train Loss: 0.5995
Epoch 3 Step 551 Train Loss: 0.5945
Epoch 3 Step 601 Train Loss: 0.6047
Epoch 3 Step 651 Train Loss: 0.5934
Epoch 3 Step 701 Train Loss: 0.7112
Epoch 3 Step 751 Train Loss: 0.6151
Epoch 3 Step 801 Train Loss: 0.6146
Epoch 3 Step 851 Train Loss: 0.6122
Epoch 3 Step 901 Train Loss: 0.5977
Epoch 3 Step 951 Train Loss: 0.6455
Epoch 3 Step 1001 Train Loss: 0.6514
Epoch 3 Step 1051 Train Loss: 0.5656
Epoch 3 Step 1101 Train Loss: 0.5810
Epoch 3 Step 1151 Train Loss: 0.6030
Epoch 3 Step 1201 Train Loss: 0.5885
Epoch 3 Step 1251 Train Loss: 0.5952
Epoch 3 Step 1301 Train Loss: 0.5930
Epoch 3 Step 1351 Train Loss: 0.6211
Epoch 3 Step 1401 Train Loss: 0.6576
Epoch 3 Step 1451 Train Loss: 0.6364
Epoch 3 Step 1501 Train Loss: 0.6321
Epoch 3 Step 1551 Train Loss: 0.6544
Epoch 3 Step 1601 Train Loss: 0.6136
Epoch 3 Step 1651 Train Loss: 0.6132
Epoch 3 Step 1701 Train Loss: 0.5502
Epoch 3 Step 1751 Train Loss: 0.5721
Epoch 3 Step 1801 Train Loss: 0.5551
Epoch 3 Step 1851 Train Loss: 0.5800
Epoch 3 Step 1901 Train Loss: 0.6159
Epoch 3 Step 1951 Train Loss: 0.5572
Epoch 3 Step 2001 Train Loss: 0.6060
Epoch 3 Step 2051 Train Loss: 0.5807
Epoch 3 Step 2101 Train Loss: 0.6004
Epoch 3 Step 2151 Train Loss: 0.5924
Epoch 3 Step 2201 Train Loss: 0.6696
Epoch 3 Step 2251 Train Loss: 0.6270
Epoch 3 Step 2301 Train Loss: 0.5882
Epoch 3 Step 2351 Train Loss: 0.5765
Epoch 3 Step 2401 Train Loss: 0.6299
Epoch 3 Step 2451 Train Loss: 0.5809
Epoch 3 Step 2501 Train Loss: 0.6018
Epoch 3 Step 2551 Train Loss: 0.5589
Epoch 3 Step 2601 Train Loss: 0.5770
Epoch 3 Step 2651 Train Loss: 0.6256
Epoch 3 Step 2701 Train Loss: 0.6299
Epoch 3 Step 2751 Train Loss: 0.5442
Epoch 3 Step 2801 Train Loss: 0.5685
Epoch 3 Step 2851 Train Loss: 0.5452
Epoch 3 Step 2901 Train Loss: 0.6006
Epoch 3 Step 2951 Train Loss: 0.6142
Epoch 3 Step 3001 Train Loss: 0.7020
Epoch 3 Step 3051 Train Loss: 0.5743
Epoch 3 Step 3101 Train Loss: 0.5933
Epoch 3: Train Overall MSE: 0.0140 Validation Overall MSE: 0.0156. 
Train Top 20 DE MSE: 0.1120 Validation Top 20 DE MSE: 0.1070. 
Epoch 4 Step 1 Train Loss: 0.5832
Epoch 4 Step 51 Train Loss: 0.5874
Epoch 4 Step 101 Train Loss: 0.6292
Epoch 4 Step 151 Train Loss: 0.5650
Epoch 4 Step 201 Train Loss: 0.5922
Epoch 4 Step 251 Train Loss: 0.5983
Epoch 4 Step 301 Train Loss: 0.6416
Epoch 4 Step 351 Train Loss: 0.5898
Epoch 4 Step 401 Train Loss: 0.5881
Epoch 4 Step 451 Train Loss: 0.6261
Epoch 4 Step 501 Train Loss: 0.5976
Epoch 4 Step 551 Train Loss: 0.5935
Epoch 4 Step 601 Train Loss: 0.5634
Epoch 4 Step 651 Train Loss: 0.6663
Epoch 4 Step 701 Train Loss: 0.5700
Epoch 4 Step 751 Train Loss: 0.6005
Epoch 4 Step 801 Train Loss: 0.6271
Epoch 4 Step 851 Train Loss: 0.6082
Epoch 4 Step 901 Train Loss: 0.5774
Epoch 4 Step 951 Train Loss: 0.6061
Epoch 4 Step 1001 Train Loss: 0.5890
Epoch 4 Step 1051 Train Loss: 0.6144
Epoch 4 Step 1101 Train Loss: 0.5639
Epoch 4 Step 1151 Train Loss: 0.6258
Epoch 4 Step 1201 Train Loss: 0.6071
Epoch 4 Step 1251 Train Loss: 0.6272
Epoch 4 Step 1301 Train Loss: 0.5975
Epoch 4 Step 1351 Train Loss: 0.6520
Epoch 4 Step 1401 Train Loss: 0.6003
Epoch 4 Step 1451 Train Loss: 0.5887
Epoch 4 Step 1501 Train Loss: 0.5801
Epoch 4 Step 1551 Train Loss: 0.6189
Epoch 4 Step 1601 Train Loss: 0.5809
Epoch 4 Step 1651 Train Loss: 0.6614
Epoch 4 Step 1701 Train Loss: 0.6461
Epoch 4 Step 1751 Train Loss: 0.6321
Epoch 4 Step 1801 Train Loss: 0.6064
Epoch 4 Step 1851 Train Loss: 0.5923
Epoch 4 Step 1901 Train Loss: 0.5974
Epoch 4 Step 1951 Train Loss: 0.6165
Epoch 4 Step 2001 Train Loss: 0.6068
Epoch 4 Step 2051 Train Loss: 0.5803
Epoch 4 Step 2101 Train Loss: 0.5928
Epoch 4 Step 2151 Train Loss: 0.5870
Epoch 4 Step 2201 Train Loss: 0.6119
Epoch 4 Step 2251 Train Loss: 0.5835
Epoch 4 Step 2301 Train Loss: 0.6087
Epoch 4 Step 2351 Train Loss: 0.5815
Epoch 4 Step 2401 Train Loss: 0.5946
Epoch 4 Step 2451 Train Loss: 0.5829
Epoch 4 Step 2501 Train Loss: 0.6008
Epoch 4 Step 2551 Train Loss: 0.6125
Epoch 4 Step 2601 Train Loss: 0.5807
Epoch 4 Step 2651 Train Loss: 0.5709
Epoch 4 Step 2701 Train Loss: 0.5965
Epoch 4 Step 2751 Train Loss: 0.5611
Epoch 4 Step 2801 Train Loss: 0.6100
Epoch 4 Step 2851 Train Loss: 0.6347
Epoch 4 Step 2901 Train Loss: 0.5710
Epoch 4 Step 2951 Train Loss: 0.6507
Epoch 4 Step 3001 Train Loss: 0.6807
Epoch 4 Step 3051 Train Loss: 0.6024
Epoch 4 Step 3101 Train Loss: 0.6486
Epoch 4: Train Overall MSE: 0.0139 Validation Overall MSE: 0.0158. 
Train Top 20 DE MSE: 0.1130 Validation Top 20 DE MSE: 0.1083. 
Epoch 5 Step 1 Train Loss: 0.5572
Epoch 5 Step 51 Train Loss: 0.5742
Epoch 5 Step 101 Train Loss: 0.6599
Epoch 5 Step 151 Train Loss: 0.6549
Epoch 5 Step 201 Train Loss: 0.6106
Epoch 5 Step 251 Train Loss: 0.5695
Epoch 5 Step 301 Train Loss: 0.6683
Epoch 5 Step 351 Train Loss: 0.5698
Epoch 5 Step 401 Train Loss: 0.5826
Epoch 5 Step 451 Train Loss: 0.6338
Epoch 5 Step 501 Train Loss: 0.6289
Epoch 5 Step 551 Train Loss: 0.5986
Epoch 5 Step 601 Train Loss: 0.6245
Epoch 5 Step 651 Train Loss: 0.5519
Epoch 5 Step 701 Train Loss: 0.5918
Epoch 5 Step 751 Train Loss: 0.5668
Epoch 5 Step 801 Train Loss: 0.5895
Epoch 5 Step 851 Train Loss: 0.5871
Epoch 5 Step 901 Train Loss: 0.6201
Epoch 5 Step 951 Train Loss: 0.6035
Epoch 5 Step 1001 Train Loss: 0.6144
Epoch 5 Step 1051 Train Loss: 0.6234
Epoch 5 Step 1101 Train Loss: 0.6147
Epoch 5 Step 1151 Train Loss: 0.5293
Epoch 5 Step 1201 Train Loss: 0.6300
Epoch 5 Step 1251 Train Loss: 0.5756
Epoch 5 Step 1301 Train Loss: 0.5639
Epoch 5 Step 1351 Train Loss: 0.6471
Epoch 5 Step 1401 Train Loss: 0.5724
Epoch 5 Step 1451 Train Loss: 0.5800
Epoch 5 Step 1501 Train Loss: 0.5820
Epoch 5 Step 1551 Train Loss: 0.6326
Epoch 5 Step 1601 Train Loss: 0.5580
Epoch 5 Step 1651 Train Loss: 0.6528
Epoch 5 Step 1701 Train Loss: 0.5556
Epoch 5 Step 1751 Train Loss: 0.5839
Epoch 5 Step 1801 Train Loss: 0.5825
Epoch 5 Step 1851 Train Loss: 0.6297
Epoch 5 Step 1901 Train Loss: 0.5696
Epoch 5 Step 1951 Train Loss: 0.5835
Epoch 5 Step 2001 Train Loss: 0.5413
Epoch 5 Step 2051 Train Loss: 0.6472
Epoch 5 Step 2101 Train Loss: 0.5104
Epoch 5 Step 2151 Train Loss: 0.6378
Epoch 5 Step 2201 Train Loss: 0.5850
Epoch 5 Step 2251 Train Loss: 0.6158
Epoch 5 Step 2301 Train Loss: 0.6157
Epoch 5 Step 2351 Train Loss: 0.6168
Epoch 5 Step 2401 Train Loss: 0.6199
Epoch 5 Step 2451 Train Loss: 0.5566
Epoch 5 Step 2501 Train Loss: 0.5275
Epoch 5 Step 2551 Train Loss: 0.6721
Epoch 5 Step 2601 Train Loss: 0.5829
Epoch 5 Step 2651 Train Loss: 0.5680
Epoch 5 Step 2701 Train Loss: 0.6015
Epoch 5 Step 2751 Train Loss: 0.6198
Epoch 5 Step 2801 Train Loss: 0.6136
Epoch 5 Step 2851 Train Loss: 0.6334
Epoch 5 Step 2901 Train Loss: 0.6048
Epoch 5 Step 2951 Train Loss: 0.6087
Epoch 5 Step 3001 Train Loss: 0.6037
Epoch 5 Step 3051 Train Loss: 0.5427
Epoch 5 Step 3101 Train Loss: 0.6181
Epoch 5: Train Overall MSE: 0.0132 Validation Overall MSE: 0.0146. 
Train Top 20 DE MSE: 0.1173 Validation Top 20 DE MSE: 0.1109. 
Epoch 6 Step 1 Train Loss: 0.6359
Epoch 6 Step 51 Train Loss: 0.6162
Epoch 6 Step 101 Train Loss: 0.5855
Epoch 6 Step 151 Train Loss: 0.5902
Epoch 6 Step 201 Train Loss: 0.6142
Epoch 6 Step 251 Train Loss: 0.5811
Epoch 6 Step 301 Train Loss: 0.6342
Epoch 6 Step 351 Train Loss: 0.5911
Epoch 6 Step 401 Train Loss: 0.6229
Epoch 6 Step 451 Train Loss: 0.5363
Epoch 6 Step 501 Train Loss: 0.5665
Epoch 6 Step 551 Train Loss: 0.6240
Epoch 6 Step 601 Train Loss: 0.6052
Epoch 6 Step 651 Train Loss: 0.6306
Epoch 6 Step 701 Train Loss: 0.6383
Epoch 6 Step 751 Train Loss: 0.5309
Epoch 6 Step 801 Train Loss: 0.5341
Epoch 6 Step 851 Train Loss: 0.5823
Epoch 6 Step 901 Train Loss: 0.5919
Epoch 6 Step 951 Train Loss: 0.6115
Epoch 6 Step 1001 Train Loss: 0.6664
Epoch 6 Step 1051 Train Loss: 0.5936
Epoch 6 Step 1101 Train Loss: 0.5660
Epoch 6 Step 1151 Train Loss: 0.5824
Epoch 6 Step 1201 Train Loss: 0.5910
Epoch 6 Step 1251 Train Loss: 0.5679
Epoch 6 Step 1301 Train Loss: 0.6185
Epoch 6 Step 1351 Train Loss: 0.5859
Epoch 6 Step 1401 Train Loss: 0.5744
Epoch 6 Step 1451 Train Loss: 0.6012
Epoch 6 Step 1501 Train Loss: 0.5644
Epoch 6 Step 1551 Train Loss: 0.5953
Epoch 6 Step 1601 Train Loss: 0.6150
Epoch 6 Step 1651 Train Loss: 0.5569
Epoch 6 Step 1701 Train Loss: 0.5600
Epoch 6 Step 1751 Train Loss: 0.6355
Epoch 6 Step 1801 Train Loss: 0.6370
Epoch 6 Step 1851 Train Loss: 0.6267
Epoch 6 Step 1901 Train Loss: 0.6304
Epoch 6 Step 1951 Train Loss: 0.5795
Epoch 6 Step 2001 Train Loss: 0.6059
Epoch 6 Step 2051 Train Loss: 0.6155
Epoch 6 Step 2101 Train Loss: 0.5737
Epoch 6 Step 2151 Train Loss: 0.5736
Epoch 6 Step 2201 Train Loss: 0.5887
Epoch 6 Step 2251 Train Loss: 0.6352
Epoch 6 Step 2301 Train Loss: 0.5862
Epoch 6 Step 2351 Train Loss: 0.5814
Epoch 6 Step 2401 Train Loss: 0.5743
Epoch 6 Step 2451 Train Loss: 0.5579
Epoch 6 Step 2501 Train Loss: 0.5768
Epoch 6 Step 2551 Train Loss: 0.5981
Epoch 6 Step 2601 Train Loss: 0.5868
Epoch 6 Step 2651 Train Loss: 0.6065
Epoch 6 Step 2701 Train Loss: 0.5593
Epoch 6 Step 2751 Train Loss: 0.6558
Epoch 6 Step 2801 Train Loss: 0.6087
Epoch 6 Step 2851 Train Loss: 0.5976
Epoch 6 Step 2901 Train Loss: 0.6164
Epoch 6 Step 2951 Train Loss: 0.5783
Epoch 6 Step 3001 Train Loss: 0.5800
Epoch 6 Step 3051 Train Loss: 0.6086
Epoch 6 Step 3101 Train Loss: 0.5942
Epoch 6: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1177 Validation Top 20 DE MSE: 0.1105. 
Epoch 7 Step 1 Train Loss: 0.6203
Epoch 7 Step 51 Train Loss: 0.5939
Epoch 7 Step 101 Train Loss: 0.5960
Epoch 7 Step 151 Train Loss: 0.5832
Epoch 7 Step 201 Train Loss: 0.6227
Epoch 7 Step 251 Train Loss: 0.5885
Epoch 7 Step 301 Train Loss: 0.6090
Epoch 7 Step 351 Train Loss: 0.5738
Epoch 7 Step 401 Train Loss: 0.6119
Epoch 7 Step 451 Train Loss: 0.5976
Epoch 7 Step 501 Train Loss: 0.5346
Epoch 7 Step 551 Train Loss: 0.5901
Epoch 7 Step 601 Train Loss: 0.5465
Epoch 7 Step 651 Train Loss: 0.6284
Epoch 7 Step 701 Train Loss: 0.5519
Epoch 7 Step 751 Train Loss: 0.5289
Epoch 7 Step 801 Train Loss: 0.5897
Epoch 7 Step 851 Train Loss: 0.5843
Epoch 7 Step 901 Train Loss: 0.6188
Epoch 7 Step 951 Train Loss: 0.6359
Epoch 7 Step 1001 Train Loss: 0.5618
Epoch 7 Step 1051 Train Loss: 0.6090
Epoch 7 Step 1101 Train Loss: 0.6425
Epoch 7 Step 1151 Train Loss: 0.6741
Epoch 7 Step 1201 Train Loss: 0.6155
Epoch 7 Step 1251 Train Loss: 0.6393
Epoch 7 Step 1301 Train Loss: 0.6332
Epoch 7 Step 1351 Train Loss: 0.5870
Epoch 7 Step 1401 Train Loss: 0.5778
Epoch 7 Step 1451 Train Loss: 0.5548
Epoch 7 Step 1501 Train Loss: 0.6162
Epoch 7 Step 1551 Train Loss: 0.5992
Epoch 7 Step 1601 Train Loss: 0.5794
Epoch 7 Step 1651 Train Loss: 0.6206
Epoch 7 Step 1701 Train Loss: 0.6117
Epoch 7 Step 1751 Train Loss: 0.6044
Epoch 7 Step 1801 Train Loss: 0.5853
Epoch 7 Step 1851 Train Loss: 0.5865
Epoch 7 Step 1901 Train Loss: 0.5863
Epoch 7 Step 1951 Train Loss: 0.6200
Epoch 7 Step 2001 Train Loss: 0.5688
Epoch 7 Step 2051 Train Loss: 0.6203
Epoch 7 Step 2101 Train Loss: 0.6207
Epoch 7 Step 2151 Train Loss: 0.5863
Epoch 7 Step 2201 Train Loss: 0.6290
Epoch 7 Step 2251 Train Loss: 0.6058
Epoch 7 Step 2301 Train Loss: 0.5774
Epoch 7 Step 2351 Train Loss: 0.5718
Epoch 7 Step 2401 Train Loss: 0.5338
Epoch 7 Step 2451 Train Loss: 0.5916
Epoch 7 Step 2501 Train Loss: 0.5637
Epoch 7 Step 2551 Train Loss: 0.5771
Epoch 7 Step 2601 Train Loss: 0.6121
Epoch 7 Step 2651 Train Loss: 0.5447
Epoch 7 Step 2701 Train Loss: 0.5847
Epoch 7 Step 2751 Train Loss: 0.5765
Epoch 7 Step 2801 Train Loss: 0.5646
Epoch 7 Step 2851 Train Loss: 0.5639
Epoch 7 Step 2901 Train Loss: 0.6444
Epoch 7 Step 2951 Train Loss: 0.6605
Epoch 7 Step 3001 Train Loss: 0.5765
Epoch 7 Step 3051 Train Loss: 0.5548
Epoch 7 Step 3101 Train Loss: 0.5888
Epoch 7: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1170 Validation Top 20 DE MSE: 0.1102. 
Epoch 8 Step 1 Train Loss: 0.5577
Epoch 8 Step 51 Train Loss: 0.5857
Epoch 8 Step 101 Train Loss: 0.5793
Epoch 8 Step 151 Train Loss: 0.6119
Epoch 8 Step 201 Train Loss: 0.6426
Epoch 8 Step 251 Train Loss: 0.6123
Epoch 8 Step 301 Train Loss: 0.5985
Epoch 8 Step 351 Train Loss: 0.5830
Epoch 8 Step 401 Train Loss: 0.5615
Epoch 8 Step 451 Train Loss: 0.5716
Epoch 8 Step 501 Train Loss: 0.5974
Epoch 8 Step 551 Train Loss: 0.5636
Epoch 8 Step 601 Train Loss: 0.5843
Epoch 8 Step 651 Train Loss: 0.6137
Epoch 8 Step 701 Train Loss: 0.6031
Epoch 8 Step 751 Train Loss: 0.5650
Epoch 8 Step 801 Train Loss: 0.5838
Epoch 8 Step 851 Train Loss: 0.5800
Epoch 8 Step 901 Train Loss: 0.5913
Epoch 8 Step 951 Train Loss: 0.5894
Epoch 8 Step 1001 Train Loss: 0.6312
Epoch 8 Step 1051 Train Loss: 0.6444
Epoch 8 Step 1101 Train Loss: 0.6281
Epoch 8 Step 1151 Train Loss: 0.6543
Epoch 8 Step 1201 Train Loss: 0.5159
Epoch 8 Step 1251 Train Loss: 0.5637
Epoch 8 Step 1301 Train Loss: 0.6095
Epoch 8 Step 1351 Train Loss: 0.5450
Epoch 8 Step 1401 Train Loss: 0.5771
Epoch 8 Step 1451 Train Loss: 0.5829
Epoch 8 Step 1501 Train Loss: 0.5905
Epoch 8 Step 1551 Train Loss: 0.6444
Epoch 8 Step 1601 Train Loss: 0.6020
Epoch 8 Step 1651 Train Loss: 0.6570
Epoch 8 Step 1701 Train Loss: 0.5935
Epoch 8 Step 1751 Train Loss: 0.5890
Epoch 8 Step 1801 Train Loss: 0.5785
Epoch 8 Step 1851 Train Loss: 0.6051
Epoch 8 Step 1901 Train Loss: 0.5653
Epoch 8 Step 1951 Train Loss: 0.6070
Epoch 8 Step 2001 Train Loss: 0.5621
Epoch 8 Step 2051 Train Loss: 0.6413
Epoch 8 Step 2101 Train Loss: 0.6040
Epoch 8 Step 2151 Train Loss: 0.6326
Epoch 8 Step 2201 Train Loss: 0.5899
Epoch 8 Step 2251 Train Loss: 0.5639
Epoch 8 Step 2301 Train Loss: 0.5950
Epoch 8 Step 2351 Train Loss: 0.5719
Epoch 8 Step 2401 Train Loss: 0.5920
Epoch 8 Step 2451 Train Loss: 0.5666
Epoch 8 Step 2501 Train Loss: 0.5849
Epoch 8 Step 2551 Train Loss: 0.6103
Epoch 8 Step 2601 Train Loss: 0.5605
Epoch 8 Step 2651 Train Loss: 0.6204
Epoch 8 Step 2701 Train Loss: 0.5541
Epoch 8 Step 2751 Train Loss: 0.6476
Epoch 8 Step 2801 Train Loss: 0.5534
Epoch 8 Step 2851 Train Loss: 0.5536
Epoch 8 Step 2901 Train Loss: 0.6187
Epoch 8 Step 2951 Train Loss: 0.6169
Epoch 8 Step 3001 Train Loss: 0.5862
Epoch 8 Step 3051 Train Loss: 0.6066
Epoch 8 Step 3101 Train Loss: 0.5946
Epoch 8: Train Overall MSE: 0.0131 Validation Overall MSE: 0.0147. 
Train Top 20 DE MSE: 0.1128 Validation Top 20 DE MSE: 0.1071. 
Epoch 9 Step 1 Train Loss: 0.5703
Epoch 9 Step 51 Train Loss: 0.5881
Epoch 9 Step 101 Train Loss: 0.5989
Epoch 9 Step 151 Train Loss: 0.5944
Epoch 9 Step 201 Train Loss: 0.6126
Epoch 9 Step 251 Train Loss: 0.5366
Epoch 9 Step 301 Train Loss: 0.5688
Epoch 9 Step 351 Train Loss: 0.6000
Epoch 9 Step 401 Train Loss: 0.6167
Epoch 9 Step 451 Train Loss: 0.5942
Epoch 9 Step 501 Train Loss: 0.6030
Epoch 9 Step 551 Train Loss: 0.5964
Epoch 9 Step 601 Train Loss: 0.5844
Epoch 9 Step 651 Train Loss: 0.5966
Epoch 9 Step 701 Train Loss: 0.6431
Epoch 9 Step 751 Train Loss: 0.6345
Epoch 9 Step 801 Train Loss: 0.5879
Epoch 9 Step 851 Train Loss: 0.6603
Epoch 9 Step 901 Train Loss: 0.6068
Epoch 9 Step 951 Train Loss: 0.6387
Epoch 9 Step 1001 Train Loss: 0.6130
Epoch 9 Step 1051 Train Loss: 0.5618
Epoch 9 Step 1101 Train Loss: 0.5880
Epoch 9 Step 1151 Train Loss: 0.5480
Epoch 9 Step 1201 Train Loss: 0.6476
Epoch 9 Step 1251 Train Loss: 0.5969
Epoch 9 Step 1301 Train Loss: 0.5766
Epoch 9 Step 1351 Train Loss: 0.5713
Epoch 9 Step 1401 Train Loss: 0.6338
Epoch 9 Step 1451 Train Loss: 0.5887
Epoch 9 Step 1501 Train Loss: 0.6182
Epoch 9 Step 1551 Train Loss: 0.5905
Epoch 9 Step 1601 Train Loss: 0.5741
Epoch 9 Step 1651 Train Loss: 0.5766
Epoch 9 Step 1701 Train Loss: 0.6178
Epoch 9 Step 1751 Train Loss: 0.5753
Epoch 9 Step 1801 Train Loss: 0.6250
Epoch 9 Step 1851 Train Loss: 0.6043
Epoch 9 Step 1901 Train Loss: 0.6696
Epoch 9 Step 1951 Train Loss: 0.6471
Epoch 9 Step 2001 Train Loss: 0.5488
Epoch 9 Step 2051 Train Loss: 0.5567
Epoch 9 Step 2101 Train Loss: 0.5493
Epoch 9 Step 2151 Train Loss: 0.5815
Epoch 9 Step 2201 Train Loss: 0.6056
Epoch 9 Step 2251 Train Loss: 0.5937
Epoch 9 Step 2301 Train Loss: 0.6258
Epoch 9 Step 2351 Train Loss: 0.5885
Epoch 9 Step 2401 Train Loss: 0.6095
Epoch 9 Step 2451 Train Loss: 0.6121
Epoch 9 Step 2501 Train Loss: 0.6041
Epoch 9 Step 2551 Train Loss: 0.6027
Epoch 9 Step 2601 Train Loss: 0.6275
Epoch 9 Step 2651 Train Loss: 0.5600
Epoch 9 Step 2701 Train Loss: 0.5912
Epoch 9 Step 2751 Train Loss: 0.5840
Epoch 9 Step 2801 Train Loss: 0.5753
Epoch 9 Step 2851 Train Loss: 0.6232
Epoch 9 Step 2901 Train Loss: 0.6139
Epoch 9 Step 2951 Train Loss: 0.6182
Epoch 9 Step 3001 Train Loss: 0.6130
Epoch 9 Step 3051 Train Loss: 0.5602
Epoch 9 Step 3101 Train Loss: 0.5925
Epoch 9: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1167 Validation Top 20 DE MSE: 0.1096. 
Epoch 10 Step 1 Train Loss: 0.6313
Epoch 10 Step 51 Train Loss: 0.5888
Epoch 10 Step 101 Train Loss: 0.5370
Epoch 10 Step 151 Train Loss: 0.6118
Epoch 10 Step 201 Train Loss: 0.6286
Epoch 10 Step 251 Train Loss: 0.5690
Epoch 10 Step 301 Train Loss: 0.6019
Epoch 10 Step 351 Train Loss: 0.5943
Epoch 10 Step 401 Train Loss: 0.6558
Epoch 10 Step 451 Train Loss: 0.6159
Epoch 10 Step 501 Train Loss: 0.6610
Epoch 10 Step 551 Train Loss: 0.6664
Epoch 10 Step 601 Train Loss: 0.5631
Epoch 10 Step 651 Train Loss: 0.6131
Epoch 10 Step 701 Train Loss: 0.5848
Epoch 10 Step 751 Train Loss: 0.5728
Epoch 10 Step 801 Train Loss: 0.5924
Epoch 10 Step 851 Train Loss: 0.6061
Epoch 10 Step 901 Train Loss: 0.6100
Epoch 10 Step 951 Train Loss: 0.6007
Epoch 10 Step 1001 Train Loss: 0.5609
Epoch 10 Step 1051 Train Loss: 0.5867
Epoch 10 Step 1101 Train Loss: 0.6516
Epoch 10 Step 1151 Train Loss: 0.5761
Epoch 10 Step 1201 Train Loss: 0.5695
Epoch 10 Step 1251 Train Loss: 0.6330
Epoch 10 Step 1301 Train Loss: 0.6057
Epoch 10 Step 1351 Train Loss: 0.5474
Epoch 10 Step 1401 Train Loss: 0.5795
Epoch 10 Step 1451 Train Loss: 0.5577
Epoch 10 Step 1501 Train Loss: 0.5982
Epoch 10 Step 1551 Train Loss: 0.6475
Epoch 10 Step 1601 Train Loss: 0.6216
Epoch 10 Step 1651 Train Loss: 0.6103
Epoch 10 Step 1701 Train Loss: 0.5798
Epoch 10 Step 1751 Train Loss: 0.5605
Epoch 10 Step 1801 Train Loss: 0.5749
Epoch 10 Step 1851 Train Loss: 0.6438
Epoch 10 Step 1901 Train Loss: 0.5513
Epoch 10 Step 1951 Train Loss: 0.5850
Epoch 10 Step 2001 Train Loss: 0.6099
Epoch 10 Step 2051 Train Loss: 0.6152
Epoch 10 Step 2101 Train Loss: 0.5780
Epoch 10 Step 2151 Train Loss: 0.5689
Epoch 10 Step 2201 Train Loss: 0.6170
Epoch 10 Step 2251 Train Loss: 0.5639
Epoch 10 Step 2301 Train Loss: 0.5624
Epoch 10 Step 2351 Train Loss: 0.5981
Epoch 10 Step 2401 Train Loss: 0.6131
Epoch 10 Step 2451 Train Loss: 0.5822
Epoch 10 Step 2501 Train Loss: 0.5909
Epoch 10 Step 2551 Train Loss: 0.5967
Epoch 10 Step 2601 Train Loss: 0.6049
Epoch 10 Step 2651 Train Loss: 0.6220
Epoch 10 Step 2701 Train Loss: 0.5729
Epoch 10 Step 2751 Train Loss: 0.5550
Epoch 10 Step 2801 Train Loss: 0.6350
Epoch 10 Step 2851 Train Loss: 0.5948
Epoch 10 Step 2901 Train Loss: 0.6012
Epoch 10 Step 2951 Train Loss: 0.6489
Epoch 10 Step 3001 Train Loss: 0.5688
Epoch 10 Step 3051 Train Loss: 0.6342
Epoch 10 Step 3101 Train Loss: 0.6196
Epoch 10: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1147 Validation Top 20 DE MSE: 0.1084. 
Epoch 11 Step 1 Train Loss: 0.5993
Epoch 11 Step 51 Train Loss: 0.6384
Epoch 11 Step 101 Train Loss: 0.6284
Epoch 11 Step 151 Train Loss: 0.6009
Epoch 11 Step 201 Train Loss: 0.6403
Epoch 11 Step 251 Train Loss: 0.6637
Epoch 11 Step 301 Train Loss: 0.6026
Epoch 11 Step 351 Train Loss: 0.6039
Epoch 11 Step 401 Train Loss: 0.5692
Epoch 11 Step 451 Train Loss: 0.6017
Epoch 11 Step 501 Train Loss: 0.5960
Epoch 11 Step 551 Train Loss: 0.5497
Epoch 11 Step 601 Train Loss: 0.5631
Epoch 11 Step 651 Train Loss: 0.6006
Epoch 11 Step 701 Train Loss: 0.5981
Epoch 11 Step 751 Train Loss: 0.5857
Epoch 11 Step 801 Train Loss: 0.5769
Epoch 11 Step 851 Train Loss: 0.6052
Epoch 11 Step 901 Train Loss: 0.5760
Epoch 11 Step 951 Train Loss: 0.5869
Epoch 11 Step 1001 Train Loss: 0.6228
Epoch 11 Step 1051 Train Loss: 0.5934
Epoch 11 Step 1101 Train Loss: 0.5755
Epoch 11 Step 1151 Train Loss: 0.5739
Epoch 11 Step 1201 Train Loss: 0.6431
Epoch 11 Step 1251 Train Loss: 0.6191
Epoch 11 Step 1301 Train Loss: 0.5605
Epoch 11 Step 1351 Train Loss: 0.5966
Epoch 11 Step 1401 Train Loss: 0.6074
Epoch 11 Step 1451 Train Loss: 0.5962
Epoch 11 Step 1501 Train Loss: 0.6401
Epoch 11 Step 1551 Train Loss: 0.5996
Epoch 11 Step 1601 Train Loss: 0.5597
Epoch 11 Step 1651 Train Loss: 0.5565
Epoch 11 Step 1701 Train Loss: 0.5849
Epoch 11 Step 1751 Train Loss: 0.6630
Epoch 11 Step 1801 Train Loss: 0.6336
Epoch 11 Step 1851 Train Loss: 0.5690
Epoch 11 Step 1901 Train Loss: 0.6487
Epoch 11 Step 1951 Train Loss: 0.6218
Epoch 11 Step 2001 Train Loss: 0.6127
Epoch 11 Step 2051 Train Loss: 0.5746
Epoch 11 Step 2101 Train Loss: 0.6278
Epoch 11 Step 2151 Train Loss: 0.5359
Epoch 11 Step 2201 Train Loss: 0.6531
Epoch 11 Step 2251 Train Loss: 0.6372
Epoch 11 Step 2301 Train Loss: 0.6159
Epoch 11 Step 2351 Train Loss: 0.6078
Epoch 11 Step 2401 Train Loss: 0.5607
Epoch 11 Step 2451 Train Loss: 0.5813
Epoch 11 Step 2501 Train Loss: 0.6396
Epoch 11 Step 2551 Train Loss: 0.6109
Epoch 11 Step 2601 Train Loss: 0.5901
Epoch 11 Step 2651 Train Loss: 0.5916
Epoch 11 Step 2701 Train Loss: 0.6108
Epoch 11 Step 2751 Train Loss: 0.5729
Epoch 11 Step 2801 Train Loss: 0.5896
Epoch 11 Step 2851 Train Loss: 0.6228
Epoch 11 Step 2901 Train Loss: 0.6433
Epoch 11 Step 2951 Train Loss: 0.6278
Epoch 11 Step 3001 Train Loss: 0.5971
Epoch 11 Step 3051 Train Loss: 0.6267
Epoch 11 Step 3101 Train Loss: 0.6087
Epoch 11: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0146. 
Train Top 20 DE MSE: 0.1144 Validation Top 20 DE MSE: 0.1081. 
Epoch 12 Step 1 Train Loss: 0.6532
Epoch 12 Step 51 Train Loss: 0.5845
Epoch 12 Step 101 Train Loss: 0.5638
Epoch 12 Step 151 Train Loss: 0.5855
Epoch 12 Step 201 Train Loss: 0.6726
Epoch 12 Step 251 Train Loss: 0.6204
Epoch 12 Step 301 Train Loss: 0.5937
Epoch 12 Step 351 Train Loss: 0.6263
Epoch 12 Step 401 Train Loss: 0.5317
Epoch 12 Step 451 Train Loss: 0.5992
Epoch 12 Step 501 Train Loss: 0.5703
Epoch 12 Step 551 Train Loss: 0.5713
Epoch 12 Step 601 Train Loss: 0.5704
Epoch 12 Step 651 Train Loss: 0.6100
Epoch 12 Step 701 Train Loss: 0.6458
Epoch 12 Step 751 Train Loss: 0.6016
Epoch 12 Step 801 Train Loss: 0.6128
Epoch 12 Step 851 Train Loss: 0.5798
Epoch 12 Step 901 Train Loss: 0.6322
Epoch 12 Step 951 Train Loss: 0.5987
Epoch 12 Step 1001 Train Loss: 0.5977
Epoch 12 Step 1051 Train Loss: 0.5789
Epoch 12 Step 1101 Train Loss: 0.5903
Epoch 12 Step 1151 Train Loss: 0.6229
Epoch 12 Step 1201 Train Loss: 0.6293
Epoch 12 Step 1251 Train Loss: 0.6423
Epoch 12 Step 1301 Train Loss: 0.6222
Epoch 12 Step 1351 Train Loss: 0.5507
Epoch 12 Step 1401 Train Loss: 0.6340
Epoch 12 Step 1451 Train Loss: 0.6175
Epoch 12 Step 1501 Train Loss: 0.5833
Epoch 12 Step 1551 Train Loss: 0.5425
Epoch 12 Step 1601 Train Loss: 0.5489
Epoch 12 Step 1651 Train Loss: 0.5699
Epoch 12 Step 1701 Train Loss: 0.5613
Epoch 12 Step 1751 Train Loss: 0.5515
Epoch 12 Step 1801 Train Loss: 0.6138
Epoch 12 Step 1851 Train Loss: 0.5931
Epoch 12 Step 1901 Train Loss: 0.6638
Epoch 12 Step 1951 Train Loss: 0.5907
Epoch 12 Step 2001 Train Loss: 0.5583
Epoch 12 Step 2051 Train Loss: 0.6447
Epoch 12 Step 2101 Train Loss: 0.6244
Epoch 12 Step 2151 Train Loss: 0.6028
Epoch 12 Step 2201 Train Loss: 0.5747
Epoch 12 Step 2251 Train Loss: 0.5651
Epoch 12 Step 2301 Train Loss: 0.5986
Epoch 12 Step 2351 Train Loss: 0.5747
Epoch 12 Step 2401 Train Loss: 0.6254
Epoch 12 Step 2451 Train Loss: 0.6159
Epoch 12 Step 2501 Train Loss: 0.5764
Epoch 12 Step 2551 Train Loss: 0.6994
Epoch 12 Step 2601 Train Loss: 0.6101
Epoch 12 Step 2651 Train Loss: 0.6128
Epoch 12 Step 2701 Train Loss: 0.6205
Epoch 12 Step 2751 Train Loss: 0.6182
Epoch 12 Step 2801 Train Loss: 0.6203
Epoch 12 Step 2851 Train Loss: 0.5959
Epoch 12 Step 2901 Train Loss: 0.5643
Epoch 12 Step 2951 Train Loss: 0.6086
Epoch 12 Step 3001 Train Loss: 0.5411
Epoch 12 Step 3051 Train Loss: 0.5482
Epoch 12 Step 3101 Train Loss: 0.5562
Epoch 12: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1148 Validation Top 20 DE MSE: 0.1085. 
Epoch 13 Step 1 Train Loss: 0.6018
Epoch 13 Step 51 Train Loss: 0.6368
Epoch 13 Step 101 Train Loss: 0.5864
Epoch 13 Step 151 Train Loss: 0.5619
Epoch 13 Step 201 Train Loss: 0.5989
Epoch 13 Step 251 Train Loss: 0.6149
Epoch 13 Step 301 Train Loss: 0.5995
Epoch 13 Step 351 Train Loss: 0.6211
Epoch 13 Step 401 Train Loss: 0.6675
Epoch 13 Step 451 Train Loss: 0.6564
Epoch 13 Step 501 Train Loss: 0.6064
Epoch 13 Step 551 Train Loss: 0.5925
Epoch 13 Step 601 Train Loss: 0.5809
Epoch 13 Step 651 Train Loss: 0.6104
Epoch 13 Step 701 Train Loss: 0.6255
Epoch 13 Step 751 Train Loss: 0.6064
Epoch 13 Step 801 Train Loss: 0.6180
Epoch 13 Step 851 Train Loss: 0.6369
Epoch 13 Step 901 Train Loss: 0.5498
Epoch 13 Step 951 Train Loss: 0.6498
Epoch 13 Step 1001 Train Loss: 0.6100
Epoch 13 Step 1051 Train Loss: 0.5852
Epoch 13 Step 1101 Train Loss: 0.5761
Epoch 13 Step 1151 Train Loss: 0.5672
Epoch 13 Step 1201 Train Loss: 0.5875
Epoch 13 Step 1251 Train Loss: 0.6066
Epoch 13 Step 1301 Train Loss: 0.6203
Epoch 13 Step 1351 Train Loss: 0.6702
Epoch 13 Step 1401 Train Loss: 0.6300
Epoch 13 Step 1451 Train Loss: 0.5916
Epoch 13 Step 1501 Train Loss: 0.6274
Epoch 13 Step 1551 Train Loss: 0.6239
Epoch 13 Step 1601 Train Loss: 0.6042
Epoch 13 Step 1651 Train Loss: 0.5763
Epoch 13 Step 1701 Train Loss: 0.6068
Epoch 13 Step 1751 Train Loss: 0.6076
Epoch 13 Step 1801 Train Loss: 0.5753
Epoch 13 Step 1851 Train Loss: 0.6257
Epoch 13 Step 1901 Train Loss: 0.5881
Epoch 13 Step 1951 Train Loss: 0.6495
Epoch 13 Step 2001 Train Loss: 0.6127
Epoch 13 Step 2051 Train Loss: 0.5955
Epoch 13 Step 2101 Train Loss: 0.5362
Epoch 13 Step 2151 Train Loss: 0.5877
Epoch 13 Step 2201 Train Loss: 0.6444
Epoch 13 Step 2251 Train Loss: 0.5715
Epoch 13 Step 2301 Train Loss: 0.6000
Epoch 13 Step 2351 Train Loss: 0.5766
Epoch 13 Step 2401 Train Loss: 0.6233
Epoch 13 Step 2451 Train Loss: 0.6497
Epoch 13 Step 2501 Train Loss: 0.6511
Epoch 13 Step 2551 Train Loss: 0.6174
Epoch 13 Step 2601 Train Loss: 0.6008
Epoch 13 Step 2651 Train Loss: 0.5807
Epoch 13 Step 2701 Train Loss: 0.5847
Epoch 13 Step 2751 Train Loss: 0.5685
Epoch 13 Step 2801 Train Loss: 0.5464
Epoch 13 Step 2851 Train Loss: 0.6086
Epoch 13 Step 2901 Train Loss: 0.5802
Epoch 13 Step 2951 Train Loss: 0.6797
Epoch 13 Step 3001 Train Loss: 0.6035
Epoch 13 Step 3051 Train Loss: 0.5888
Epoch 13 Step 3101 Train Loss: 0.6186
Epoch 13: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1188 Validation Top 20 DE MSE: 0.1112. 
Epoch 14 Step 1 Train Loss: 0.5661
Epoch 14 Step 51 Train Loss: 0.5820
Epoch 14 Step 101 Train Loss: 0.5575
Epoch 14 Step 151 Train Loss: 0.6248
Epoch 14 Step 201 Train Loss: 0.5706
Epoch 14 Step 251 Train Loss: 0.5961
Epoch 14 Step 301 Train Loss: 0.5584
Epoch 14 Step 351 Train Loss: 0.5446
Epoch 14 Step 401 Train Loss: 0.6270
Epoch 14 Step 451 Train Loss: 0.5732
Epoch 14 Step 501 Train Loss: 0.6049
Epoch 14 Step 551 Train Loss: 0.5999
Epoch 14 Step 601 Train Loss: 0.6006
Epoch 14 Step 651 Train Loss: 0.5895
Epoch 14 Step 701 Train Loss: 0.6058
Epoch 14 Step 751 Train Loss: 0.6720
Epoch 14 Step 801 Train Loss: 0.5991
Epoch 14 Step 851 Train Loss: 0.5817
Epoch 14 Step 901 Train Loss: 0.5785
Epoch 14 Step 951 Train Loss: 0.6171
Epoch 14 Step 1001 Train Loss: 0.6894
Epoch 14 Step 1051 Train Loss: 0.5980
Epoch 14 Step 1101 Train Loss: 0.6301
Epoch 14 Step 1151 Train Loss: 0.5676
Epoch 14 Step 1201 Train Loss: 0.6255
Epoch 14 Step 1251 Train Loss: 0.5399
Epoch 14 Step 1301 Train Loss: 0.6007
Epoch 14 Step 1351 Train Loss: 0.6157
Epoch 14 Step 1401 Train Loss: 0.6136
Epoch 14 Step 1451 Train Loss: 0.5725
Epoch 14 Step 1501 Train Loss: 0.5657
Epoch 14 Step 1551 Train Loss: 0.5934
Epoch 14 Step 1601 Train Loss: 0.6309
Epoch 14 Step 1651 Train Loss: 0.6173
Epoch 14 Step 1701 Train Loss: 0.6577
Epoch 14 Step 1751 Train Loss: 0.5766
Epoch 14 Step 1801 Train Loss: 0.6272
Epoch 14 Step 1851 Train Loss: 0.6576
Epoch 14 Step 1901 Train Loss: 0.5930
Epoch 14 Step 1951 Train Loss: 0.6521
Epoch 14 Step 2001 Train Loss: 0.6145
Epoch 14 Step 2051 Train Loss: 0.6138
Epoch 14 Step 2101 Train Loss: 0.5893
Epoch 14 Step 2151 Train Loss: 0.6038
Epoch 14 Step 2201 Train Loss: 0.6138
Epoch 14 Step 2251 Train Loss: 0.5814
Epoch 14 Step 2301 Train Loss: 0.5727
Epoch 14 Step 2351 Train Loss: 0.6190
Epoch 14 Step 2401 Train Loss: 0.6278
Epoch 14 Step 2451 Train Loss: 0.5930
Epoch 14 Step 2501 Train Loss: 0.5977
Epoch 14 Step 2551 Train Loss: 0.5879
Epoch 14 Step 2601 Train Loss: 0.5368
Epoch 14 Step 2651 Train Loss: 0.5990
Epoch 14 Step 2701 Train Loss: 0.5614
Epoch 14 Step 2751 Train Loss: 0.6044
Epoch 14 Step 2801 Train Loss: 0.6262
Epoch 14 Step 2851 Train Loss: 0.5848
Epoch 14 Step 2901 Train Loss: 0.6184
Epoch 14 Step 2951 Train Loss: 0.5789
Epoch 14 Step 3001 Train Loss: 0.6341
Epoch 14 Step 3051 Train Loss: 0.6774
Epoch 14 Step 3101 Train Loss: 0.5557
Epoch 14: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1146 Validation Top 20 DE MSE: 0.1083. 
Epoch 15 Step 1 Train Loss: 0.5770
Epoch 15 Step 51 Train Loss: 0.5670
Epoch 15 Step 101 Train Loss: 0.6540
Epoch 15 Step 151 Train Loss: 0.6117
Epoch 15 Step 201 Train Loss: 0.5941
Epoch 15 Step 251 Train Loss: 0.6429
Epoch 15 Step 301 Train Loss: 0.6056
Epoch 15 Step 351 Train Loss: 0.6070
Epoch 15 Step 401 Train Loss: 0.5761
Epoch 15 Step 451 Train Loss: 0.6301
Epoch 15 Step 501 Train Loss: 0.5867
Epoch 15 Step 551 Train Loss: 0.6037
Epoch 15 Step 601 Train Loss: 0.6115
Epoch 15 Step 651 Train Loss: 0.6024
Epoch 15 Step 701 Train Loss: 0.5757
Epoch 15 Step 751 Train Loss: 0.5787
Epoch 15 Step 801 Train Loss: 0.5599
Epoch 15 Step 851 Train Loss: 0.5860
Epoch 15 Step 901 Train Loss: 0.5574
Epoch 15 Step 951 Train Loss: 0.6002
Epoch 15 Step 1001 Train Loss: 0.5944
Epoch 15 Step 1051 Train Loss: 0.5649
Epoch 15 Step 1101 Train Loss: 0.6436
Epoch 15 Step 1151 Train Loss: 0.5995
Epoch 15 Step 1201 Train Loss: 0.5807
Epoch 15 Step 1251 Train Loss: 0.5719
Epoch 15 Step 1301 Train Loss: 0.5700
Epoch 15 Step 1351 Train Loss: 0.5916
Epoch 15 Step 1401 Train Loss: 0.5879
Epoch 15 Step 1451 Train Loss: 0.6029
Epoch 15 Step 1501 Train Loss: 0.6143
Epoch 15 Step 1551 Train Loss: 0.6378
Epoch 15 Step 1601 Train Loss: 0.5730
Epoch 15 Step 1651 Train Loss: 0.5420
Epoch 15 Step 1701 Train Loss: 0.6349
Epoch 15 Step 1751 Train Loss: 0.5936
Epoch 15 Step 1801 Train Loss: 0.6224
Epoch 15 Step 1851 Train Loss: 0.5908
Epoch 15 Step 1901 Train Loss: 0.6427
Epoch 15 Step 1951 Train Loss: 0.5990
Epoch 15 Step 2001 Train Loss: 0.6136
Epoch 15 Step 2051 Train Loss: 0.6185
Epoch 15 Step 2101 Train Loss: 0.6111
Epoch 15 Step 2151 Train Loss: 0.6325
Epoch 15 Step 2201 Train Loss: 0.5862
Epoch 15 Step 2251 Train Loss: 0.5872
Epoch 15 Step 2301 Train Loss: 0.6203
Epoch 15 Step 2351 Train Loss: 0.6039
Epoch 15 Step 2401 Train Loss: 0.5634
Epoch 15 Step 2451 Train Loss: 0.6006
Epoch 15 Step 2501 Train Loss: 0.5570
Epoch 15 Step 2551 Train Loss: 0.6470
Epoch 15 Step 2601 Train Loss: 0.6250
Epoch 15 Step 2651 Train Loss: 0.6260
Epoch 15 Step 2701 Train Loss: 0.6217
Epoch 15 Step 2751 Train Loss: 0.6236
Epoch 15 Step 2801 Train Loss: 0.6873
Epoch 15 Step 2851 Train Loss: 0.5924
Epoch 15 Step 2901 Train Loss: 0.6033
Epoch 15 Step 2951 Train Loss: 0.5272
Epoch 15 Step 3001 Train Loss: 0.5896
Epoch 15 Step 3051 Train Loss: 0.6067
Epoch 15 Step 3101 Train Loss: 0.5466
Epoch 15: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0145. 
Train Top 20 DE MSE: 0.1148 Validation Top 20 DE MSE: 0.1086. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1208
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.014801558
test_unseen_single_pearson: 0.9778621719327781
test_unseen_single_mse_de: 0.12078836
test_unseen_single_pearson_de: 0.6927413360668031
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.5017199775564123
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.21406685236768805
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6005571030640668
test_unseen_single_mse_top20_de_non_dropout: 0.15826574
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.048 MB uploadedwandb: | 0.003 MB of 0.052 MB uploadedwandb: / 0.052 MB of 0.052 MB uploadedwandb: - 0.052 MB of 0.052 MB uploadedwandb: \ 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:                                             train_de_pearson ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ
wandb:                                                      val_mse ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.12079
wandb:                                              test_de_pearson 0.69274
wandb:               test_frac_opposite_direction_top20_non_dropout 0.21407
wandb:                          test_frac_sigma_below_1_non_dropout 0.60056
wandb:                                                     test_mse 0.0148
wandb:                                test_mse_top20_de_non_dropout 0.15827
wandb:                                                 test_pearson 0.97786
wandb:                                           test_pearson_delta 0.50172
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.21407
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.60056
wandb:                                       test_unseen_single_mse 0.0148
wandb:                                    test_unseen_single_mse_de 0.12079
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.15827
wandb:                                   test_unseen_single_pearson 0.97786
wandb:                                test_unseen_single_pearson_de 0.69274
wandb:                             test_unseen_single_pearson_delta 0.50172
wandb:                                                 train_de_mse 0.11475
wandb:                                             train_de_pearson 0.64653
wandb:                                                    train_mse 0.01298
wandb:                                                train_pearson 0.98045
wandb:                                                training_loss 0.54143
wandb:                                                   val_de_mse 0.10858
wandb:                                               val_de_pearson 0.67868
wandb:                                                      val_mse 0.01453
wandb:                                                  val_pearson 0.9782
wandb: 
wandb: üöÄ View run geneformer_Replogle_rpe1_essential_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/6nidvc19
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240922_222640-6nidvc19/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:359
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/geneformer/wandb/run-20240923_005448-ipqigpzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run geneformer_Replogle_rpe1_essential_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/ipqigpzz
wandb: WARNING Serializing object of type ndarray that is 23564416 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.6056
Epoch 1 Step 51 Train Loss: 0.6141
Epoch 1 Step 101 Train Loss: 0.5917
Epoch 1 Step 151 Train Loss: 0.6013
Epoch 1 Step 201 Train Loss: 0.6059
Epoch 1 Step 251 Train Loss: 0.6271
Epoch 1 Step 301 Train Loss: 0.6003
Epoch 1 Step 351 Train Loss: 0.6297
Epoch 1 Step 401 Train Loss: 0.6375
Epoch 1 Step 451 Train Loss: 0.5883
Epoch 1 Step 501 Train Loss: 0.5713
Epoch 1 Step 551 Train Loss: 0.6023
Epoch 1 Step 601 Train Loss: 0.6109
Epoch 1 Step 651 Train Loss: 0.5700
Epoch 1 Step 701 Train Loss: 0.6195
Epoch 1 Step 751 Train Loss: 0.5626
Epoch 1 Step 801 Train Loss: 0.6468
Epoch 1 Step 851 Train Loss: 0.6286
Epoch 1 Step 901 Train Loss: 0.5985
Epoch 1 Step 951 Train Loss: 0.5836
Epoch 1 Step 1001 Train Loss: 0.5998
Epoch 1 Step 1051 Train Loss: 0.6006
Epoch 1 Step 1101 Train Loss: 0.5888
Epoch 1 Step 1151 Train Loss: 0.6335
Epoch 1 Step 1201 Train Loss: 0.5652
Epoch 1 Step 1251 Train Loss: 0.5833
Epoch 1 Step 1301 Train Loss: 0.5662
Epoch 1 Step 1351 Train Loss: 0.6183
Epoch 1 Step 1401 Train Loss: 0.5990
Epoch 1 Step 1451 Train Loss: 0.6260
Epoch 1 Step 1501 Train Loss: 0.6108
Epoch 1 Step 1551 Train Loss: 0.5937
Epoch 1 Step 1601 Train Loss: 0.5672
Epoch 1 Step 1651 Train Loss: 0.5752
Epoch 1 Step 1701 Train Loss: 0.5898
Epoch 1 Step 1751 Train Loss: 0.5980
Epoch 1 Step 1801 Train Loss: 0.6137
Epoch 1 Step 1851 Train Loss: 0.6295
Epoch 1 Step 1901 Train Loss: 0.5780
Epoch 1 Step 1951 Train Loss: 0.5617
Epoch 1 Step 2001 Train Loss: 0.6467
Epoch 1 Step 2051 Train Loss: 0.5476
Epoch 1 Step 2101 Train Loss: 0.5758
Epoch 1 Step 2151 Train Loss: 0.6248
Epoch 1 Step 2201 Train Loss: 0.6778
Epoch 1 Step 2251 Train Loss: 0.5990
Epoch 1 Step 2301 Train Loss: 0.6027
Epoch 1 Step 2351 Train Loss: 0.5673
Epoch 1 Step 2401 Train Loss: 0.5740
Epoch 1 Step 2451 Train Loss: 0.5858
Epoch 1 Step 2501 Train Loss: 0.5808
Epoch 1 Step 2551 Train Loss: 0.5821
Epoch 1 Step 2601 Train Loss: 0.5678
Epoch 1 Step 2651 Train Loss: 0.6387
Epoch 1 Step 2701 Train Loss: 0.6227
Epoch 1 Step 2751 Train Loss: 0.6065
Epoch 1 Step 2801 Train Loss: 0.6039
Epoch 1 Step 2851 Train Loss: 0.6052
Epoch 1 Step 2901 Train Loss: 0.5208
Epoch 1 Step 2951 Train Loss: 0.5894
Epoch 1 Step 3001 Train Loss: 0.5811
Epoch 1 Step 3051 Train Loss: 0.5352
Epoch 1 Step 3101 Train Loss: 0.5413
Epoch 1 Step 3151 Train Loss: 0.5865
Epoch 1: Train Overall MSE: 0.0148 Validation Overall MSE: 0.0146. 
Train Top 20 DE MSE: 0.1406 Validation Top 20 DE MSE: 0.1510. 
Epoch 2 Step 1 Train Loss: 0.5590
Epoch 2 Step 51 Train Loss: 0.5820
Epoch 2 Step 101 Train Loss: 0.5870
Epoch 2 Step 151 Train Loss: 0.6129
Epoch 2 Step 201 Train Loss: 0.5861
Epoch 2 Step 251 Train Loss: 0.6045
Epoch 2 Step 301 Train Loss: 0.5649
Epoch 2 Step 351 Train Loss: 0.5864
Epoch 2 Step 401 Train Loss: 0.5549
Epoch 2 Step 451 Train Loss: 0.5589
Epoch 2 Step 501 Train Loss: 0.6376
Epoch 2 Step 551 Train Loss: 0.5665
Epoch 2 Step 601 Train Loss: 0.6125
Epoch 2 Step 651 Train Loss: 0.5625
Epoch 2 Step 701 Train Loss: 0.6139
Epoch 2 Step 751 Train Loss: 0.6033
Epoch 2 Step 801 Train Loss: 0.5311
Epoch 2 Step 851 Train Loss: 0.6162
Epoch 2 Step 901 Train Loss: 0.5934
Epoch 2 Step 951 Train Loss: 0.5805
Epoch 2 Step 1001 Train Loss: 0.6015
Epoch 2 Step 1051 Train Loss: 0.5510
Epoch 2 Step 1101 Train Loss: 0.6157
Epoch 2 Step 1151 Train Loss: 0.5993
Epoch 2 Step 1201 Train Loss: 0.6066
Epoch 2 Step 1251 Train Loss: 0.5413
Epoch 2 Step 1301 Train Loss: 0.5377
Epoch 2 Step 1351 Train Loss: 0.5474
Epoch 2 Step 1401 Train Loss: 0.6594
Epoch 2 Step 1451 Train Loss: 0.5839
Epoch 2 Step 1501 Train Loss: 0.5800
Epoch 2 Step 1551 Train Loss: 0.6591
Epoch 2 Step 1601 Train Loss: 0.5742
Epoch 2 Step 1651 Train Loss: 0.5592
Epoch 2 Step 1701 Train Loss: 0.5751
Epoch 2 Step 1751 Train Loss: 0.6107
Epoch 2 Step 1801 Train Loss: 0.6364
Epoch 2 Step 1851 Train Loss: 0.6407
Epoch 2 Step 1901 Train Loss: 0.6246
Epoch 2 Step 1951 Train Loss: 0.6173
Epoch 2 Step 2001 Train Loss: 0.6004
Epoch 2 Step 2051 Train Loss: 0.5979
Epoch 2 Step 2101 Train Loss: 0.6141
Epoch 2 Step 2151 Train Loss: 0.5828
Epoch 2 Step 2201 Train Loss: 0.6579
Epoch 2 Step 2251 Train Loss: 0.6064
Epoch 2 Step 2301 Train Loss: 0.6105
Epoch 2 Step 2351 Train Loss: 0.6399
Epoch 2 Step 2401 Train Loss: 0.5461
Epoch 2 Step 2451 Train Loss: 0.5979
Epoch 2 Step 2501 Train Loss: 0.6020
Epoch 2 Step 2551 Train Loss: 0.7120
Epoch 2 Step 2601 Train Loss: 0.6136
Epoch 2 Step 2651 Train Loss: 0.6295
Epoch 2 Step 2701 Train Loss: 0.6048
Epoch 2 Step 2751 Train Loss: 0.6005
Epoch 2 Step 2801 Train Loss: 0.5711
Epoch 2 Step 2851 Train Loss: 0.6497
Epoch 2 Step 2901 Train Loss: 0.6039
Epoch 2 Step 2951 Train Loss: 0.5962
Epoch 2 Step 3001 Train Loss: 0.5613
Epoch 2 Step 3051 Train Loss: 0.6143
Epoch 2 Step 3101 Train Loss: 0.6362
Epoch 2 Step 3151 Train Loss: 0.6138
Epoch 2: Train Overall MSE: 0.0136 Validation Overall MSE: 0.0141. 
Train Top 20 DE MSE: 0.1215 Validation Top 20 DE MSE: 0.1413. 
Epoch 3 Step 1 Train Loss: 0.6641
Epoch 3 Step 51 Train Loss: 0.6271
Epoch 3 Step 101 Train Loss: 0.5927
Epoch 3 Step 151 Train Loss: 0.5511
Epoch 3 Step 201 Train Loss: 0.5912
Epoch 3 Step 251 Train Loss: 0.5868
Epoch 3 Step 301 Train Loss: 0.5963
Epoch 3 Step 351 Train Loss: 0.5986
Epoch 3 Step 401 Train Loss: 0.6049
Epoch 3 Step 451 Train Loss: 0.5665
Epoch 3 Step 501 Train Loss: 0.6180
Epoch 3 Step 551 Train Loss: 0.5920
Epoch 3 Step 601 Train Loss: 0.6039
Epoch 3 Step 651 Train Loss: 0.5865
Epoch 3 Step 701 Train Loss: 0.5722
Epoch 3 Step 751 Train Loss: 0.6281
Epoch 3 Step 801 Train Loss: 0.5796
Epoch 3 Step 851 Train Loss: 0.5788
Epoch 3 Step 901 Train Loss: 0.6011
Epoch 3 Step 951 Train Loss: 0.5803
Epoch 3 Step 1001 Train Loss: 0.6174
Epoch 3 Step 1051 Train Loss: 0.6275
Epoch 3 Step 1101 Train Loss: 0.6063
Epoch 3 Step 1151 Train Loss: 0.6057
Epoch 3 Step 1201 Train Loss: 0.5708
Epoch 3 Step 1251 Train Loss: 0.6037
Epoch 3 Step 1301 Train Loss: 0.5857
Epoch 3 Step 1351 Train Loss: 0.5881
Epoch 3 Step 1401 Train Loss: 0.5864
Epoch 3 Step 1451 Train Loss: 0.6008
Epoch 3 Step 1501 Train Loss: 0.5940
Epoch 3 Step 1551 Train Loss: 0.5580
Epoch 3 Step 1601 Train Loss: 0.6361
Epoch 3 Step 1651 Train Loss: 0.5764
Epoch 3 Step 1701 Train Loss: 0.5764
Epoch 3 Step 1751 Train Loss: 0.5552
Epoch 3 Step 1801 Train Loss: 0.6155
Epoch 3 Step 1851 Train Loss: 0.6468
Epoch 3 Step 1901 Train Loss: 0.6294
Epoch 3 Step 1951 Train Loss: 0.6318
Epoch 3 Step 2001 Train Loss: 0.6512
Epoch 3 Step 2051 Train Loss: 0.6315
Epoch 3 Step 2101 Train Loss: 0.6080
Epoch 3 Step 2151 Train Loss: 0.5757
Epoch 3 Step 2201 Train Loss: 0.6093
Epoch 3 Step 2251 Train Loss: 0.6047
Epoch 3 Step 2301 Train Loss: 0.6031
Epoch 3 Step 2351 Train Loss: 0.5991
Epoch 3 Step 2401 Train Loss: 0.5581
Epoch 3 Step 2451 Train Loss: 0.5975
Epoch 3 Step 2501 Train Loss: 0.6070
Epoch 3 Step 2551 Train Loss: 0.5672
Epoch 3 Step 2601 Train Loss: 0.6004
Epoch 3 Step 2651 Train Loss: 0.5664
Epoch 3 Step 2701 Train Loss: 0.5675
Epoch 3 Step 2751 Train Loss: 0.5742
Epoch 3 Step 2801 Train Loss: 0.5737
Epoch 3 Step 2851 Train Loss: 0.6301
Epoch 3 Step 2901 Train Loss: 0.6013
Epoch 3 Step 2951 Train Loss: 0.6496
Epoch 3 Step 3001 Train Loss: 0.5817
Epoch 3 Step 3051 Train Loss: 0.5152
Epoch 3 Step 3101 Train Loss: 0.6005
Epoch 3 Step 3151 Train Loss: 0.5655
Epoch 3: Train Overall MSE: 0.0132 Validation Overall MSE: 0.0137. 
Train Top 20 DE MSE: 0.1230 Validation Top 20 DE MSE: 0.1435. 
Epoch 4 Step 1 Train Loss: 0.5693
Epoch 4 Step 51 Train Loss: 0.5884
Epoch 4 Step 101 Train Loss: 0.5818
Epoch 4 Step 151 Train Loss: 0.5905
Epoch 4 Step 201 Train Loss: 0.6238
Epoch 4 Step 251 Train Loss: 0.5725
Epoch 4 Step 301 Train Loss: 0.6278
Epoch 4 Step 351 Train Loss: 0.6073
Epoch 4 Step 401 Train Loss: 0.5946
Epoch 4 Step 451 Train Loss: 0.5857
Epoch 4 Step 501 Train Loss: 0.5961
Epoch 4 Step 551 Train Loss: 0.6128
Epoch 4 Step 601 Train Loss: 0.5805
Epoch 4 Step 651 Train Loss: 0.5874
Epoch 4 Step 701 Train Loss: 0.6029
Epoch 4 Step 751 Train Loss: 0.5564
Epoch 4 Step 801 Train Loss: 0.5724
Epoch 4 Step 851 Train Loss: 0.6893
Epoch 4 Step 901 Train Loss: 0.6128
Epoch 4 Step 951 Train Loss: 0.5923
Epoch 4 Step 1001 Train Loss: 0.5633
Epoch 4 Step 1051 Train Loss: 0.6036
Epoch 4 Step 1101 Train Loss: 0.5532
Epoch 4 Step 1151 Train Loss: 0.5792
Epoch 4 Step 1201 Train Loss: 0.6043
Epoch 4 Step 1251 Train Loss: 0.6320
Epoch 4 Step 1301 Train Loss: 0.5746
Epoch 4 Step 1351 Train Loss: 0.5265
Epoch 4 Step 1401 Train Loss: 0.6226
Epoch 4 Step 1451 Train Loss: 0.6134
Epoch 4 Step 1501 Train Loss: 0.5934
Epoch 4 Step 1551 Train Loss: 0.6010
Epoch 4 Step 1601 Train Loss: 0.5790
Epoch 4 Step 1651 Train Loss: 0.6381
Epoch 4 Step 1701 Train Loss: 0.5836
Epoch 4 Step 1751 Train Loss: 0.6249
Epoch 4 Step 1801 Train Loss: 0.6069
Epoch 4 Step 1851 Train Loss: 0.5513
Epoch 4 Step 1901 Train Loss: 0.5693
Epoch 4 Step 1951 Train Loss: 0.5740
Epoch 4 Step 2001 Train Loss: 0.5796
Epoch 4 Step 2051 Train Loss: 0.5723
Epoch 4 Step 2101 Train Loss: 0.6052
Epoch 4 Step 2151 Train Loss: 0.6199
Epoch 4 Step 2201 Train Loss: 0.6155
Epoch 4 Step 2251 Train Loss: 0.6458
Epoch 4 Step 2301 Train Loss: 0.5870
Epoch 4 Step 2351 Train Loss: 0.6115
Epoch 4 Step 2401 Train Loss: 0.6346
Epoch 4 Step 2451 Train Loss: 0.6002
Epoch 4 Step 2501 Train Loss: 0.6104
Epoch 4 Step 2551 Train Loss: 0.6023
Epoch 4 Step 2601 Train Loss: 0.5716
Epoch 4 Step 2651 Train Loss: 0.6424
Epoch 4 Step 2701 Train Loss: 0.6157
Epoch 4 Step 2751 Train Loss: 0.5386
Epoch 4 Step 2801 Train Loss: 0.5650
Epoch 4 Step 2851 Train Loss: 0.5923
Epoch 4 Step 2901 Train Loss: 0.5803
Epoch 4 Step 2951 Train Loss: 0.5576
Epoch 4 Step 3001 Train Loss: 0.5416
Epoch 4 Step 3051 Train Loss: 0.6466
Epoch 4 Step 3101 Train Loss: 0.6245
Epoch 4 Step 3151 Train Loss: 0.5511
Epoch 4: Train Overall MSE: 0.0130 Validation Overall MSE: 0.0137. 
Train Top 20 DE MSE: 0.1188 Validation Top 20 DE MSE: 0.1400. 
Epoch 5 Step 1 Train Loss: 0.5822
Epoch 5 Step 51 Train Loss: 0.6055
Epoch 5 Step 101 Train Loss: 0.6142
Epoch 5 Step 151 Train Loss: 0.6131
Epoch 5 Step 201 Train Loss: 0.5698
Epoch 5 Step 251 Train Loss: 0.5844
Epoch 5 Step 301 Train Loss: 0.5977
Epoch 5 Step 351 Train Loss: 0.6191
Epoch 5 Step 401 Train Loss: 0.6419
Epoch 5 Step 451 Train Loss: 0.6130
Epoch 5 Step 501 Train Loss: 0.6239
Epoch 5 Step 551 Train Loss: 0.6055
Epoch 5 Step 601 Train Loss: 0.6425
Epoch 5 Step 651 Train Loss: 0.5706
Epoch 5 Step 701 Train Loss: 0.6417
Epoch 5 Step 751 Train Loss: 0.6038
Epoch 5 Step 801 Train Loss: 0.5864
Epoch 5 Step 851 Train Loss: 0.6276
Epoch 5 Step 901 Train Loss: 0.5605
Epoch 5 Step 951 Train Loss: 0.5939
Epoch 5 Step 1001 Train Loss: 0.6371
Epoch 5 Step 1051 Train Loss: 0.5454
Epoch 5 Step 1101 Train Loss: 0.6286
Epoch 5 Step 1151 Train Loss: 0.5690
Epoch 5 Step 1201 Train Loss: 0.5867
Epoch 5 Step 1251 Train Loss: 0.5786
Epoch 5 Step 1301 Train Loss: 0.6280
Epoch 5 Step 1351 Train Loss: 0.5852
Epoch 5 Step 1401 Train Loss: 0.5535
Epoch 5 Step 1451 Train Loss: 0.5844
Epoch 5 Step 1501 Train Loss: 0.6350
Epoch 5 Step 1551 Train Loss: 0.5780
Epoch 5 Step 1601 Train Loss: 0.6513
Epoch 5 Step 1651 Train Loss: 0.5784
Epoch 5 Step 1701 Train Loss: 0.6030
Epoch 5 Step 1751 Train Loss: 0.5711
Epoch 5 Step 1801 Train Loss: 0.5772
Epoch 5 Step 1851 Train Loss: 0.5759
Epoch 5 Step 1901 Train Loss: 0.5794
Epoch 5 Step 1951 Train Loss: 0.5912
Epoch 5 Step 2001 Train Loss: 0.5816
Epoch 5 Step 2051 Train Loss: 0.5682
Epoch 5 Step 2101 Train Loss: 0.5787
Epoch 5 Step 2151 Train Loss: 0.5672
Epoch 5 Step 2201 Train Loss: 0.5904
Epoch 5 Step 2251 Train Loss: 0.6313
Epoch 5 Step 2301 Train Loss: 0.6230
Epoch 5 Step 2351 Train Loss: 0.5543
Epoch 5 Step 2401 Train Loss: 0.5496
Epoch 5 Step 2451 Train Loss: 0.5907
Epoch 5 Step 2501 Train Loss: 0.5896
Epoch 5 Step 2551 Train Loss: 0.6169
Epoch 5 Step 2601 Train Loss: 0.5594
Epoch 5 Step 2651 Train Loss: 0.5912
Epoch 5 Step 2701 Train Loss: 0.6153
Epoch 5 Step 2751 Train Loss: 0.6296
Epoch 5 Step 2801 Train Loss: 0.5701
Epoch 5 Step 2851 Train Loss: 0.6054
Epoch 5 Step 2901 Train Loss: 0.5697
Epoch 5 Step 2951 Train Loss: 0.6383
Epoch 5 Step 3001 Train Loss: 0.6273
Epoch 5 Step 3051 Train Loss: 0.6138
Epoch 5 Step 3101 Train Loss: 0.6100
Epoch 5 Step 3151 Train Loss: 0.5763
Epoch 5: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0136. 
Train Top 20 DE MSE: 0.1180 Validation Top 20 DE MSE: 0.1382. 
Epoch 6 Step 1 Train Loss: 0.5938
Epoch 6 Step 51 Train Loss: 0.5949
Epoch 6 Step 101 Train Loss: 0.5986
Epoch 6 Step 151 Train Loss: 0.5568
Epoch 6 Step 201 Train Loss: 0.5478
Epoch 6 Step 251 Train Loss: 0.6030
Epoch 6 Step 301 Train Loss: 0.6019
Epoch 6 Step 351 Train Loss: 0.5727
Epoch 6 Step 401 Train Loss: 0.5722
Epoch 6 Step 451 Train Loss: 0.5699
Epoch 6 Step 501 Train Loss: 0.5844
Epoch 6 Step 551 Train Loss: 0.5611
Epoch 6 Step 601 Train Loss: 0.6141
Epoch 6 Step 651 Train Loss: 0.5416
Epoch 6 Step 701 Train Loss: 0.6481
Epoch 6 Step 751 Train Loss: 0.5759
Epoch 6 Step 801 Train Loss: 0.5964
Epoch 6 Step 851 Train Loss: 0.5960
Epoch 6 Step 901 Train Loss: 0.5861
Epoch 6 Step 951 Train Loss: 0.6030
Epoch 6 Step 1001 Train Loss: 0.5929
Epoch 6 Step 1051 Train Loss: 0.6131
Epoch 6 Step 1101 Train Loss: 0.6222
Epoch 6 Step 1151 Train Loss: 0.5447
Epoch 6 Step 1201 Train Loss: 0.5709
Epoch 6 Step 1251 Train Loss: 0.5577
Epoch 6 Step 1301 Train Loss: 0.5788
Epoch 6 Step 1351 Train Loss: 0.6136
Epoch 6 Step 1401 Train Loss: 0.6185
Epoch 6 Step 1451 Train Loss: 0.5716
Epoch 6 Step 1501 Train Loss: 0.5802
Epoch 6 Step 1551 Train Loss: 0.6073
Epoch 6 Step 1601 Train Loss: 0.5906
Epoch 6 Step 1651 Train Loss: 0.6434
Epoch 6 Step 1701 Train Loss: 0.6452
Epoch 6 Step 1751 Train Loss: 0.6318
Epoch 6 Step 1801 Train Loss: 0.5621
Epoch 6 Step 1851 Train Loss: 0.5971
Epoch 6 Step 1901 Train Loss: 0.6231
Epoch 6 Step 1951 Train Loss: 0.6170
Epoch 6 Step 2001 Train Loss: 0.6362
Epoch 6 Step 2051 Train Loss: 0.6165
Epoch 6 Step 2101 Train Loss: 0.6217
Epoch 6 Step 2151 Train Loss: 0.5627
Epoch 6 Step 2201 Train Loss: 0.5658
Epoch 6 Step 2251 Train Loss: 0.5884
Epoch 6 Step 2301 Train Loss: 0.6441
Epoch 6 Step 2351 Train Loss: 0.6115
Epoch 6 Step 2401 Train Loss: 0.5981
Epoch 6 Step 2451 Train Loss: 0.5524
Epoch 6 Step 2501 Train Loss: 0.5620
Epoch 6 Step 2551 Train Loss: 0.6347
Epoch 6 Step 2601 Train Loss: 0.6453
Epoch 6 Step 2651 Train Loss: 0.6158
Epoch 6 Step 2701 Train Loss: 0.5535
Epoch 6 Step 2751 Train Loss: 0.5903
Epoch 6 Step 2801 Train Loss: 0.5789
Epoch 6 Step 2851 Train Loss: 0.5592
Epoch 6 Step 2901 Train Loss: 0.6273
Epoch 6 Step 2951 Train Loss: 0.5968
Epoch 6 Step 3001 Train Loss: 0.5887
Epoch 6 Step 3051 Train Loss: 0.6016
Epoch 6 Step 3101 Train Loss: 0.5736
Epoch 6 Step 3151 Train Loss: 0.6327
Epoch 6: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0135. 
Train Top 20 DE MSE: 0.1186 Validation Top 20 DE MSE: 0.1407. 
Epoch 7 Step 1 Train Loss: 0.6142
Epoch 7 Step 51 Train Loss: 0.6123
Epoch 7 Step 101 Train Loss: 0.6117
Epoch 7 Step 151 Train Loss: 0.6159
Epoch 7 Step 201 Train Loss: 0.5610
Epoch 7 Step 251 Train Loss: 0.6308
Epoch 7 Step 301 Train Loss: 0.6582
Epoch 7 Step 351 Train Loss: 0.5808
Epoch 7 Step 401 Train Loss: 0.5966
Epoch 7 Step 451 Train Loss: 0.5943
Epoch 7 Step 501 Train Loss: 0.6561
Epoch 7 Step 551 Train Loss: 0.5918
Epoch 7 Step 601 Train Loss: 0.5750
Epoch 7 Step 651 Train Loss: 0.5916
Epoch 7 Step 701 Train Loss: 0.6063
Epoch 7 Step 751 Train Loss: 0.6665
Epoch 7 Step 801 Train Loss: 0.5796
Epoch 7 Step 851 Train Loss: 0.5938
Epoch 7 Step 901 Train Loss: 0.5555
Epoch 7 Step 951 Train Loss: 0.5948
Epoch 7 Step 1001 Train Loss: 0.6016
Epoch 7 Step 1051 Train Loss: 0.6492
Epoch 7 Step 1101 Train Loss: 0.5605
Epoch 7 Step 1151 Train Loss: 0.6010
Epoch 7 Step 1201 Train Loss: 0.6007
Epoch 7 Step 1251 Train Loss: 0.6028
Epoch 7 Step 1301 Train Loss: 0.5993
Epoch 7 Step 1351 Train Loss: 0.5932
Epoch 7 Step 1401 Train Loss: 0.5910
Epoch 7 Step 1451 Train Loss: 0.5647
Epoch 7 Step 1501 Train Loss: 0.5312
Epoch 7 Step 1551 Train Loss: 0.6354
Epoch 7 Step 1601 Train Loss: 0.6164
Epoch 7 Step 1651 Train Loss: 0.6357
Epoch 7 Step 1701 Train Loss: 0.6050
Epoch 7 Step 1751 Train Loss: 0.6042
Epoch 7 Step 1801 Train Loss: 0.6203
Epoch 7 Step 1851 Train Loss: 0.6057
Epoch 7 Step 1901 Train Loss: 0.6255
Epoch 7 Step 1951 Train Loss: 0.6118
Epoch 7 Step 2001 Train Loss: 0.5582
Epoch 7 Step 2051 Train Loss: 0.5866
Epoch 7 Step 2101 Train Loss: 0.5751
Epoch 7 Step 2151 Train Loss: 0.5624
Epoch 7 Step 2201 Train Loss: 0.5877
Epoch 7 Step 2251 Train Loss: 0.6168
Epoch 7 Step 2301 Train Loss: 0.6078
Epoch 7 Step 2351 Train Loss: 0.6155
Epoch 7 Step 2401 Train Loss: 0.5350
Epoch 7 Step 2451 Train Loss: 0.5719
Epoch 7 Step 2501 Train Loss: 0.6314
Epoch 7 Step 2551 Train Loss: 0.5508
Epoch 7 Step 2601 Train Loss: 0.5988
Epoch 7 Step 2651 Train Loss: 0.5476
Epoch 7 Step 2701 Train Loss: 0.5790
Epoch 7 Step 2751 Train Loss: 0.6976
Epoch 7 Step 2801 Train Loss: 0.6358
Epoch 7 Step 2851 Train Loss: 0.6322
Epoch 7 Step 2901 Train Loss: 0.6146
Epoch 7 Step 2951 Train Loss: 0.5902
Epoch 7 Step 3001 Train Loss: 0.5567
Epoch 7 Step 3051 Train Loss: 0.6109
Epoch 7 Step 3101 Train Loss: 0.6351
Epoch 7 Step 3151 Train Loss: 0.5998
Epoch 7: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0136. 
Train Top 20 DE MSE: 0.1178 Validation Top 20 DE MSE: 0.1391. 
Epoch 8 Step 1 Train Loss: 0.6362
Epoch 8 Step 51 Train Loss: 0.5327
Epoch 8 Step 101 Train Loss: 0.5380
Epoch 8 Step 151 Train Loss: 0.6114
Epoch 8 Step 201 Train Loss: 0.6321
Epoch 8 Step 251 Train Loss: 0.5942
Epoch 8 Step 301 Train Loss: 0.5988
Epoch 8 Step 351 Train Loss: 0.5890
Epoch 8 Step 401 Train Loss: 0.6088
Epoch 8 Step 451 Train Loss: 0.5760
Epoch 8 Step 501 Train Loss: 0.6450
Epoch 8 Step 551 Train Loss: 0.6208
Epoch 8 Step 601 Train Loss: 0.6067
Epoch 8 Step 651 Train Loss: 0.6251
Epoch 8 Step 701 Train Loss: 0.6544
Epoch 8 Step 751 Train Loss: 0.5897
Epoch 8 Step 801 Train Loss: 0.5767
Epoch 8 Step 851 Train Loss: 0.6204
Epoch 8 Step 901 Train Loss: 0.5917
Epoch 8 Step 951 Train Loss: 0.6244
Epoch 8 Step 1001 Train Loss: 0.6434
Epoch 8 Step 1051 Train Loss: 0.6388
Epoch 8 Step 1101 Train Loss: 0.6596
Epoch 8 Step 1151 Train Loss: 0.5674
Epoch 8 Step 1201 Train Loss: 0.6225
Epoch 8 Step 1251 Train Loss: 0.6076
Epoch 8 Step 1301 Train Loss: 0.5985
Epoch 8 Step 1351 Train Loss: 0.5975
Epoch 8 Step 1401 Train Loss: 0.6163
Epoch 8 Step 1451 Train Loss: 0.6024
Epoch 8 Step 1501 Train Loss: 0.6153
Epoch 8 Step 1551 Train Loss: 0.5739
Epoch 8 Step 1601 Train Loss: 0.6588
Epoch 8 Step 1651 Train Loss: 0.5832
Epoch 8 Step 1701 Train Loss: 0.5901
Epoch 8 Step 1751 Train Loss: 0.5843
Epoch 8 Step 1801 Train Loss: 0.5836
Epoch 8 Step 1851 Train Loss: 0.6843
Epoch 8 Step 1901 Train Loss: 0.5584
Epoch 8 Step 1951 Train Loss: 0.5922
Epoch 8 Step 2001 Train Loss: 0.6850
Epoch 8 Step 2051 Train Loss: 0.6634
Epoch 8 Step 2101 Train Loss: 0.6278
Epoch 8 Step 2151 Train Loss: 0.6347
Epoch 8 Step 2201 Train Loss: 0.6332
Epoch 8 Step 2251 Train Loss: 0.5981
Epoch 8 Step 2301 Train Loss: 0.5758
Epoch 8 Step 2351 Train Loss: 0.5603
Epoch 8 Step 2401 Train Loss: 0.5524
Epoch 8 Step 2451 Train Loss: 0.5828
Epoch 8 Step 2501 Train Loss: 0.6568
Epoch 8 Step 2551 Train Loss: 0.5665
Epoch 8 Step 2601 Train Loss: 0.5646
Epoch 8 Step 2651 Train Loss: 0.5946
Epoch 8 Step 2701 Train Loss: 0.6139
Epoch 8 Step 2751 Train Loss: 0.6062
Epoch 8 Step 2801 Train Loss: 0.5908
Epoch 8 Step 2851 Train Loss: 0.6497
Epoch 8 Step 2901 Train Loss: 0.5670
Epoch 8 Step 2951 Train Loss: 0.5378
Epoch 8 Step 3001 Train Loss: 0.5931
Epoch 8 Step 3051 Train Loss: 0.6040
Epoch 8 Step 3101 Train Loss: 0.5589
Epoch 8 Step 3151 Train Loss: 0.5740
Epoch 8: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0135. 
Train Top 20 DE MSE: 0.1180 Validation Top 20 DE MSE: 0.1387. 
Epoch 9 Step 1 Train Loss: 0.5903
Epoch 9 Step 51 Train Loss: 0.5777
Epoch 9 Step 101 Train Loss: 0.5800
Epoch 9 Step 151 Train Loss: 0.6324
Epoch 9 Step 201 Train Loss: 0.5565
Epoch 9 Step 251 Train Loss: 0.5614
Epoch 9 Step 301 Train Loss: 0.6071
Epoch 9 Step 351 Train Loss: 0.6016
Epoch 9 Step 401 Train Loss: 0.6707
Epoch 9 Step 451 Train Loss: 0.6227
Epoch 9 Step 501 Train Loss: 0.6124
Epoch 9 Step 551 Train Loss: 0.5813
Epoch 9 Step 601 Train Loss: 0.6395
Epoch 9 Step 651 Train Loss: 0.5181
Epoch 9 Step 701 Train Loss: 0.6630
Epoch 9 Step 751 Train Loss: 0.6474
Epoch 9 Step 801 Train Loss: 0.5809
Epoch 9 Step 851 Train Loss: 0.6042
Epoch 9 Step 901 Train Loss: 0.5741
Epoch 9 Step 951 Train Loss: 0.6024
Epoch 9 Step 1001 Train Loss: 0.5979
Epoch 9 Step 1051 Train Loss: 0.5256
Epoch 9 Step 1101 Train Loss: 0.5997
Epoch 9 Step 1151 Train Loss: 0.6134
Epoch 9 Step 1201 Train Loss: 0.6018
Epoch 9 Step 1251 Train Loss: 0.5527
Epoch 9 Step 1301 Train Loss: 0.6081
Epoch 9 Step 1351 Train Loss: 0.5868
Epoch 9 Step 1401 Train Loss: 0.6614
Epoch 9 Step 1451 Train Loss: 0.5874
Epoch 9 Step 1501 Train Loss: 0.5996
Epoch 9 Step 1551 Train Loss: 0.5851
Epoch 9 Step 1601 Train Loss: 0.5686
Epoch 9 Step 1651 Train Loss: 0.5834
Epoch 9 Step 1701 Train Loss: 0.6186
Epoch 9 Step 1751 Train Loss: 0.5581
Epoch 9 Step 1801 Train Loss: 0.6029
Epoch 9 Step 1851 Train Loss: 0.5620
Epoch 9 Step 1901 Train Loss: 0.6307
Epoch 9 Step 1951 Train Loss: 0.5812
Epoch 9 Step 2001 Train Loss: 0.5728
Epoch 9 Step 2051 Train Loss: 0.5532
Epoch 9 Step 2101 Train Loss: 0.5615
Epoch 9 Step 2151 Train Loss: 0.6734
Epoch 9 Step 2201 Train Loss: 0.6266
Epoch 9 Step 2251 Train Loss: 0.6075
Epoch 9 Step 2301 Train Loss: 0.6215
Epoch 9 Step 2351 Train Loss: 0.6106
Epoch 9 Step 2401 Train Loss: 0.5921
Epoch 9 Step 2451 Train Loss: 0.6533
Epoch 9 Step 2501 Train Loss: 0.5842
Epoch 9 Step 2551 Train Loss: 0.6390
Epoch 9 Step 2601 Train Loss: 0.5759
Epoch 9 Step 2651 Train Loss: 0.6083
Epoch 9 Step 2701 Train Loss: 0.5837
Epoch 9 Step 2751 Train Loss: 0.6103
Epoch 9 Step 2801 Train Loss: 0.5874
Epoch 9 Step 2851 Train Loss: 0.5588
Epoch 9 Step 2901 Train Loss: 0.6257
Epoch 9 Step 2951 Train Loss: 0.6034
Epoch 9 Step 3001 Train Loss: 0.5517
Epoch 9 Step 3051 Train Loss: 0.5930
Epoch 9 Step 3101 Train Loss: 0.5590
Epoch 9 Step 3151 Train Loss: 0.6099
Epoch 9: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0137. 
Train Top 20 DE MSE: 0.1151 Validation Top 20 DE MSE: 0.1364. 
Epoch 10 Step 1 Train Loss: 0.6120
Epoch 10 Step 51 Train Loss: 0.5850
Epoch 10 Step 101 Train Loss: 0.6616
Epoch 10 Step 151 Train Loss: 0.6097
Epoch 10 Step 201 Train Loss: 0.5732
Epoch 10 Step 251 Train Loss: 0.5946
Epoch 10 Step 301 Train Loss: 0.6578
Epoch 10 Step 351 Train Loss: 0.5502
Epoch 10 Step 401 Train Loss: 0.5888
Epoch 10 Step 451 Train Loss: 0.5777
Epoch 10 Step 501 Train Loss: 0.5888
Epoch 10 Step 551 Train Loss: 0.6287
Epoch 10 Step 601 Train Loss: 0.5823
Epoch 10 Step 651 Train Loss: 0.6181
Epoch 10 Step 701 Train Loss: 0.6073
Epoch 10 Step 751 Train Loss: 0.6339
Epoch 10 Step 801 Train Loss: 0.5895
Epoch 10 Step 851 Train Loss: 0.6350
Epoch 10 Step 901 Train Loss: 0.5602
Epoch 10 Step 951 Train Loss: 0.5482
Epoch 10 Step 1001 Train Loss: 0.5539
Epoch 10 Step 1051 Train Loss: 0.5698
Epoch 10 Step 1101 Train Loss: 0.6059
Epoch 10 Step 1151 Train Loss: 0.5617
Epoch 10 Step 1201 Train Loss: 0.6084
Epoch 10 Step 1251 Train Loss: 0.5845
Epoch 10 Step 1301 Train Loss: 0.5978
Epoch 10 Step 1351 Train Loss: 0.6012
Epoch 10 Step 1401 Train Loss: 0.5912
Epoch 10 Step 1451 Train Loss: 0.6014
Epoch 10 Step 1501 Train Loss: 0.6650
Epoch 10 Step 1551 Train Loss: 0.6532
Epoch 10 Step 1601 Train Loss: 0.5681
Epoch 10 Step 1651 Train Loss: 0.5414
Epoch 10 Step 1701 Train Loss: 0.6385
Epoch 10 Step 1751 Train Loss: 0.5695
Epoch 10 Step 1801 Train Loss: 0.5877
Epoch 10 Step 1851 Train Loss: 0.6077
Epoch 10 Step 1901 Train Loss: 0.5911
Epoch 10 Step 1951 Train Loss: 0.5415
Epoch 10 Step 2001 Train Loss: 0.6039
Epoch 10 Step 2051 Train Loss: 0.5192
Epoch 10 Step 2101 Train Loss: 0.5956
Epoch 10 Step 2151 Train Loss: 0.6518
Epoch 10 Step 2201 Train Loss: 0.6039
Epoch 10 Step 2251 Train Loss: 0.5756
Epoch 10 Step 2301 Train Loss: 0.5764
Epoch 10 Step 2351 Train Loss: 0.6221
Epoch 10 Step 2401 Train Loss: 0.6036
Epoch 10 Step 2451 Train Loss: 0.6172
Epoch 10 Step 2501 Train Loss: 0.6084
Epoch 10 Step 2551 Train Loss: 0.6616
Epoch 10 Step 2601 Train Loss: 0.7107
Epoch 10 Step 2651 Train Loss: 0.6035
Epoch 10 Step 2701 Train Loss: 0.6578
Epoch 10 Step 2751 Train Loss: 0.6190
Epoch 10 Step 2801 Train Loss: 0.6534
Epoch 10 Step 2851 Train Loss: 0.5526
Epoch 10 Step 2901 Train Loss: 0.5921
Epoch 10 Step 2951 Train Loss: 0.6101
Epoch 10 Step 3001 Train Loss: 0.6029
Epoch 10 Step 3051 Train Loss: 0.6282
Epoch 10 Step 3101 Train Loss: 0.6060
Epoch 10 Step 3151 Train Loss: 0.6178
Epoch 10: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0136. 
Train Top 20 DE MSE: 0.1164 Validation Top 20 DE MSE: 0.1381. 
Epoch 11 Step 1 Train Loss: 0.5326
Epoch 11 Step 51 Train Loss: 0.5556
Epoch 11 Step 101 Train Loss: 0.5373
Epoch 11 Step 151 Train Loss: 0.5596
Epoch 11 Step 201 Train Loss: 0.5778
Epoch 11 Step 251 Train Loss: 0.6027
Epoch 11 Step 301 Train Loss: 0.5620
Epoch 11 Step 351 Train Loss: 0.6001
Epoch 11 Step 401 Train Loss: 0.5974
Epoch 11 Step 451 Train Loss: 0.6467
Epoch 11 Step 501 Train Loss: 0.5331
Epoch 11 Step 551 Train Loss: 0.5945
Epoch 11 Step 601 Train Loss: 0.6151
Epoch 11 Step 651 Train Loss: 0.5760
Epoch 11 Step 701 Train Loss: 0.5064
Epoch 11 Step 751 Train Loss: 0.6165
Epoch 11 Step 801 Train Loss: 0.5691
Epoch 11 Step 851 Train Loss: 0.6177
Epoch 11 Step 901 Train Loss: 0.6104
Epoch 11 Step 951 Train Loss: 0.5925
Epoch 11 Step 1001 Train Loss: 0.5615
Epoch 11 Step 1051 Train Loss: 0.6131
Epoch 11 Step 1101 Train Loss: 0.6180
Epoch 11 Step 1151 Train Loss: 0.5774
Epoch 11 Step 1201 Train Loss: 0.5896
Epoch 11 Step 1251 Train Loss: 0.5723
Epoch 11 Step 1301 Train Loss: 0.6056
Epoch 11 Step 1351 Train Loss: 0.6286
Epoch 11 Step 1401 Train Loss: 0.5315
Epoch 11 Step 1451 Train Loss: 0.5858
Epoch 11 Step 1501 Train Loss: 0.6109
Epoch 11 Step 1551 Train Loss: 0.5905
Epoch 11 Step 1601 Train Loss: 0.5664
Epoch 11 Step 1651 Train Loss: 0.5641
Epoch 11 Step 1701 Train Loss: 0.5915
Epoch 11 Step 1751 Train Loss: 0.6056
Epoch 11 Step 1801 Train Loss: 0.6476
Epoch 11 Step 1851 Train Loss: 0.5839
Epoch 11 Step 1901 Train Loss: 0.5961
Epoch 11 Step 1951 Train Loss: 0.5444
Epoch 11 Step 2001 Train Loss: 0.6301
Epoch 11 Step 2051 Train Loss: 0.6975
Epoch 11 Step 2101 Train Loss: 0.5935
Epoch 11 Step 2151 Train Loss: 0.5851
Epoch 11 Step 2201 Train Loss: 0.6140
Epoch 11 Step 2251 Train Loss: 0.5729
Epoch 11 Step 2301 Train Loss: 0.5751
Epoch 11 Step 2351 Train Loss: 0.5250
Epoch 11 Step 2401 Train Loss: 0.5798
Epoch 11 Step 2451 Train Loss: 0.6111
Epoch 11 Step 2501 Train Loss: 0.6424
Epoch 11 Step 2551 Train Loss: 0.5883
Epoch 11 Step 2601 Train Loss: 0.6140
Epoch 11 Step 2651 Train Loss: 0.6261
Epoch 11 Step 2701 Train Loss: 0.5607
Epoch 11 Step 2751 Train Loss: 0.5788
Epoch 11 Step 2801 Train Loss: 0.5861
Epoch 11 Step 2851 Train Loss: 0.5930
Epoch 11 Step 2901 Train Loss: 0.6134
Epoch 11 Step 2951 Train Loss: 0.5286
Epoch 11 Step 3001 Train Loss: 0.6191
Epoch 11 Step 3051 Train Loss: 0.6033
Epoch 11 Step 3101 Train Loss: 0.5823
Epoch 11 Step 3151 Train Loss: 0.6345
Epoch 11: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0135. 
Train Top 20 DE MSE: 0.1199 Validation Top 20 DE MSE: 0.1413. 
Epoch 12 Step 1 Train Loss: 0.5575
Epoch 12 Step 51 Train Loss: 0.5903
Epoch 12 Step 101 Train Loss: 0.5880
Epoch 12 Step 151 Train Loss: 0.5889
Epoch 12 Step 201 Train Loss: 0.5709
Epoch 12 Step 251 Train Loss: 0.6057
Epoch 12 Step 301 Train Loss: 0.6178
Epoch 12 Step 351 Train Loss: 0.5738
Epoch 12 Step 401 Train Loss: 0.5495
Epoch 12 Step 451 Train Loss: 0.5856
Epoch 12 Step 501 Train Loss: 0.6284
Epoch 12 Step 551 Train Loss: 0.6262
Epoch 12 Step 601 Train Loss: 0.5963
Epoch 12 Step 651 Train Loss: 0.6021
Epoch 12 Step 701 Train Loss: 0.5697
Epoch 12 Step 751 Train Loss: 0.6623
Epoch 12 Step 801 Train Loss: 0.6436
Epoch 12 Step 851 Train Loss: 0.6071
Epoch 12 Step 901 Train Loss: 0.5875
Epoch 12 Step 951 Train Loss: 0.5451
Epoch 12 Step 1001 Train Loss: 0.5512
Epoch 12 Step 1051 Train Loss: 0.5760
Epoch 12 Step 1101 Train Loss: 0.6433
Epoch 12 Step 1151 Train Loss: 0.5914
Epoch 12 Step 1201 Train Loss: 0.6090
Epoch 12 Step 1251 Train Loss: 0.6094
Epoch 12 Step 1301 Train Loss: 0.6318
Epoch 12 Step 1351 Train Loss: 0.5631
Epoch 12 Step 1401 Train Loss: 0.6048
Epoch 12 Step 1451 Train Loss: 0.5913
Epoch 12 Step 1501 Train Loss: 0.5797
Epoch 12 Step 1551 Train Loss: 0.6411
Epoch 12 Step 1601 Train Loss: 0.6215
Epoch 12 Step 1651 Train Loss: 0.6190
Epoch 12 Step 1701 Train Loss: 0.5681
Epoch 12 Step 1751 Train Loss: 0.5758
Epoch 12 Step 1801 Train Loss: 0.6267
Epoch 12 Step 1851 Train Loss: 0.6468
Epoch 12 Step 1901 Train Loss: 0.6051
Epoch 12 Step 1951 Train Loss: 0.6346
Epoch 12 Step 2001 Train Loss: 0.6665
Epoch 12 Step 2051 Train Loss: 0.5816
Epoch 12 Step 2101 Train Loss: 0.5908
Epoch 12 Step 2151 Train Loss: 0.6090
Epoch 12 Step 2201 Train Loss: 0.6609
Epoch 12 Step 2251 Train Loss: 0.5907
Epoch 12 Step 2301 Train Loss: 0.6130
Epoch 12 Step 2351 Train Loss: 0.5500
Epoch 12 Step 2401 Train Loss: 0.6349
Epoch 12 Step 2451 Train Loss: 0.6377
Epoch 12 Step 2501 Train Loss: 0.6644
Epoch 12 Step 2551 Train Loss: 0.6067
Epoch 12 Step 2601 Train Loss: 0.5804
Epoch 12 Step 2651 Train Loss: 0.5582
Epoch 12 Step 2701 Train Loss: 0.6021
Epoch 12 Step 2751 Train Loss: 0.5927
Epoch 12 Step 2801 Train Loss: 0.5837
Epoch 12 Step 2851 Train Loss: 0.5626
Epoch 12 Step 2901 Train Loss: 0.6628
Epoch 12 Step 2951 Train Loss: 0.5708
Epoch 12 Step 3001 Train Loss: 0.6019
Epoch 12 Step 3051 Train Loss: 0.5725
Epoch 12 Step 3101 Train Loss: 0.6327
Epoch 12 Step 3151 Train Loss: 0.6455
Epoch 12: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0138. 
Train Top 20 DE MSE: 0.1129 Validation Top 20 DE MSE: 0.1360. 
Epoch 13 Step 1 Train Loss: 0.5866
Epoch 13 Step 51 Train Loss: 0.5584
Epoch 13 Step 101 Train Loss: 0.5902
Epoch 13 Step 151 Train Loss: 0.5876
Epoch 13 Step 201 Train Loss: 0.6327
Epoch 13 Step 251 Train Loss: 0.5861
Epoch 13 Step 301 Train Loss: 0.5223
Epoch 13 Step 351 Train Loss: 0.6310
Epoch 13 Step 401 Train Loss: 0.5954
Epoch 13 Step 451 Train Loss: 0.5540
Epoch 13 Step 501 Train Loss: 0.5722
Epoch 13 Step 551 Train Loss: 0.6018
Epoch 13 Step 601 Train Loss: 0.5434
Epoch 13 Step 651 Train Loss: 0.5953
Epoch 13 Step 701 Train Loss: 0.6539
Epoch 13 Step 751 Train Loss: 0.6215
Epoch 13 Step 801 Train Loss: 0.6541
Epoch 13 Step 851 Train Loss: 0.6690
Epoch 13 Step 901 Train Loss: 0.5715
Epoch 13 Step 951 Train Loss: 0.6115
Epoch 13 Step 1001 Train Loss: 0.6062
Epoch 13 Step 1051 Train Loss: 0.6158
Epoch 13 Step 1101 Train Loss: 0.6173
Epoch 13 Step 1151 Train Loss: 0.5840
Epoch 13 Step 1201 Train Loss: 0.6111
Epoch 13 Step 1251 Train Loss: 0.6521
Epoch 13 Step 1301 Train Loss: 0.5927
Epoch 13 Step 1351 Train Loss: 0.6098
Epoch 13 Step 1401 Train Loss: 0.6055
Epoch 13 Step 1451 Train Loss: 0.5545
Epoch 13 Step 1501 Train Loss: 0.5850
Epoch 13 Step 1551 Train Loss: 0.6139
Epoch 13 Step 1601 Train Loss: 0.6374
Epoch 13 Step 1651 Train Loss: 0.6332
Epoch 13 Step 1701 Train Loss: 0.5576
Epoch 13 Step 1751 Train Loss: 0.5212
Epoch 13 Step 1801 Train Loss: 0.6469
Epoch 13 Step 1851 Train Loss: 0.5994
Epoch 13 Step 1901 Train Loss: 0.6398
Epoch 13 Step 1951 Train Loss: 0.6026
Epoch 13 Step 2001 Train Loss: 0.5482
Epoch 13 Step 2051 Train Loss: 0.5823
Epoch 13 Step 2101 Train Loss: 0.5934
Epoch 13 Step 2151 Train Loss: 0.5238
Epoch 13 Step 2201 Train Loss: 0.5606
Epoch 13 Step 2251 Train Loss: 0.5834
Epoch 13 Step 2301 Train Loss: 0.5340
Epoch 13 Step 2351 Train Loss: 0.6120
Epoch 13 Step 2401 Train Loss: 0.6590
Epoch 13 Step 2451 Train Loss: 0.5935
Epoch 13 Step 2501 Train Loss: 0.6022
Epoch 13 Step 2551 Train Loss: 0.7019
Epoch 13 Step 2601 Train Loss: 0.5757
Epoch 13 Step 2651 Train Loss: 0.6080
Epoch 13 Step 2701 Train Loss: 0.5766
Epoch 13 Step 2751 Train Loss: 0.5664
Epoch 13 Step 2801 Train Loss: 0.6072
Epoch 13 Step 2851 Train Loss: 0.5687
Epoch 13 Step 2901 Train Loss: 0.5768
Epoch 13 Step 2951 Train Loss: 0.6482
Epoch 13 Step 3001 Train Loss: 0.5838
Epoch 13 Step 3051 Train Loss: 0.6007
Epoch 13 Step 3101 Train Loss: 0.6117
Epoch 13 Step 3151 Train Loss: 0.6079
Epoch 13: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0135. 
Train Top 20 DE MSE: 0.1175 Validation Top 20 DE MSE: 0.1386. 
Epoch 14 Step 1 Train Loss: 0.5679
Epoch 14 Step 51 Train Loss: 0.5702
Epoch 14 Step 101 Train Loss: 0.5773
Epoch 14 Step 151 Train Loss: 0.5847
Epoch 14 Step 201 Train Loss: 0.6516
Epoch 14 Step 251 Train Loss: 0.5605
Epoch 14 Step 301 Train Loss: 0.5838
Epoch 14 Step 351 Train Loss: 0.5856
Epoch 14 Step 401 Train Loss: 0.6024
Epoch 14 Step 451 Train Loss: 0.6241
Epoch 14 Step 501 Train Loss: 0.6098
Epoch 14 Step 551 Train Loss: 0.6202
Epoch 14 Step 601 Train Loss: 0.6208
Epoch 14 Step 651 Train Loss: 0.6128
Epoch 14 Step 701 Train Loss: 0.5802
Epoch 14 Step 751 Train Loss: 0.6095
Epoch 14 Step 801 Train Loss: 0.6123
Epoch 14 Step 851 Train Loss: 0.5856
Epoch 14 Step 901 Train Loss: 0.6292
Epoch 14 Step 951 Train Loss: 0.5678
Epoch 14 Step 1001 Train Loss: 0.6043
Epoch 14 Step 1051 Train Loss: 0.6247
Epoch 14 Step 1101 Train Loss: 0.5365
Epoch 14 Step 1151 Train Loss: 0.5618
Epoch 14 Step 1201 Train Loss: 0.6489
Epoch 14 Step 1251 Train Loss: 0.5719
Epoch 14 Step 1301 Train Loss: 0.5749
Epoch 14 Step 1351 Train Loss: 0.5921
Epoch 14 Step 1401 Train Loss: 0.6428
Epoch 14 Step 1451 Train Loss: 0.5171
Epoch 14 Step 1501 Train Loss: 0.5571
Epoch 14 Step 1551 Train Loss: 0.6501
Epoch 14 Step 1601 Train Loss: 0.5620
Epoch 14 Step 1651 Train Loss: 0.5883
Epoch 14 Step 1701 Train Loss: 0.5615
Epoch 14 Step 1751 Train Loss: 0.5907
Epoch 14 Step 1801 Train Loss: 0.6204
Epoch 14 Step 1851 Train Loss: 0.5825
Epoch 14 Step 1901 Train Loss: 0.5777
Epoch 14 Step 1951 Train Loss: 0.6372
Epoch 14 Step 2001 Train Loss: 0.5973
Epoch 14 Step 2051 Train Loss: 0.6261
Epoch 14 Step 2101 Train Loss: 0.6018
Epoch 14 Step 2151 Train Loss: 0.6492
Epoch 14 Step 2201 Train Loss: 0.6171
Epoch 14 Step 2251 Train Loss: 0.5796
Epoch 14 Step 2301 Train Loss: 0.5926
Epoch 14 Step 2351 Train Loss: 0.6238
Epoch 14 Step 2401 Train Loss: 0.6225
Epoch 14 Step 2451 Train Loss: 0.6135
Epoch 14 Step 2501 Train Loss: 0.6035
Epoch 14 Step 2551 Train Loss: 0.6226
Epoch 14 Step 2601 Train Loss: 0.5727
Epoch 14 Step 2651 Train Loss: 0.5864
Epoch 14 Step 2701 Train Loss: 0.5834
Epoch 14 Step 2751 Train Loss: 0.5992
Epoch 14 Step 2801 Train Loss: 0.6341
Epoch 14 Step 2851 Train Loss: 0.5767
Epoch 14 Step 2901 Train Loss: 0.5888
Epoch 14 Step 2951 Train Loss: 0.6166
Epoch 14 Step 3001 Train Loss: 0.6592
Epoch 14 Step 3051 Train Loss: 0.6302
Epoch 14 Step 3101 Train Loss: 0.5784
Epoch 14 Step 3151 Train Loss: 0.5643
Epoch 14: Train Overall MSE: 0.0128 Validation Overall MSE: 0.0137. 
Train Top 20 DE MSE: 0.1151 Validation Top 20 DE MSE: 0.1363. 
Epoch 15 Step 1 Train Loss: 0.6123
Epoch 15 Step 51 Train Loss: 0.5755
Epoch 15 Step 101 Train Loss: 0.6327
Epoch 15 Step 151 Train Loss: 0.5523
Epoch 15 Step 201 Train Loss: 0.5990
Epoch 15 Step 251 Train Loss: 0.5876
Epoch 15 Step 301 Train Loss: 0.6151
Epoch 15 Step 351 Train Loss: 0.6039
Epoch 15 Step 401 Train Loss: 0.6629
Epoch 15 Step 451 Train Loss: 0.5612
Epoch 15 Step 501 Train Loss: 0.5950
Epoch 15 Step 551 Train Loss: 0.6261
Epoch 15 Step 601 Train Loss: 0.5936
Epoch 15 Step 651 Train Loss: 0.5919
Epoch 15 Step 701 Train Loss: 0.6114
Epoch 15 Step 751 Train Loss: 0.6043
Epoch 15 Step 801 Train Loss: 0.5702
Epoch 15 Step 851 Train Loss: 0.5698
Epoch 15 Step 901 Train Loss: 0.6013
Epoch 15 Step 951 Train Loss: 0.5565
Epoch 15 Step 1001 Train Loss: 0.6405
Epoch 15 Step 1051 Train Loss: 0.5941
Epoch 15 Step 1101 Train Loss: 0.5663
Epoch 15 Step 1151 Train Loss: 0.6562
Epoch 15 Step 1201 Train Loss: 0.5971
Epoch 15 Step 1251 Train Loss: 0.5838
Epoch 15 Step 1301 Train Loss: 0.6308
Epoch 15 Step 1351 Train Loss: 0.5909
Epoch 15 Step 1401 Train Loss: 0.5810
Epoch 15 Step 1451 Train Loss: 0.5548
Epoch 15 Step 1501 Train Loss: 0.6436
Epoch 15 Step 1551 Train Loss: 0.7002
Epoch 15 Step 1601 Train Loss: 0.5790
Epoch 15 Step 1651 Train Loss: 0.5563
Epoch 15 Step 1701 Train Loss: 0.5952
Epoch 15 Step 1751 Train Loss: 0.5905
Epoch 15 Step 1801 Train Loss: 0.6006
Epoch 15 Step 1851 Train Loss: 0.6313
Epoch 15 Step 1901 Train Loss: 0.5907
Epoch 15 Step 1951 Train Loss: 0.6000
Epoch 15 Step 2001 Train Loss: 0.6251
Epoch 15 Step 2051 Train Loss: 0.5896
Epoch 15 Step 2101 Train Loss: 0.5785
Epoch 15 Step 2151 Train Loss: 0.5648
Epoch 15 Step 2201 Train Loss: 0.6101
Epoch 15 Step 2251 Train Loss: 0.6725
Epoch 15 Step 2301 Train Loss: 0.5966
Epoch 15 Step 2351 Train Loss: 0.6304
Epoch 15 Step 2401 Train Loss: 0.6001
Epoch 15 Step 2451 Train Loss: 0.6499
Epoch 15 Step 2501 Train Loss: 0.5892
Epoch 15 Step 2551 Train Loss: 0.5891
Epoch 15 Step 2601 Train Loss: 0.6154
Epoch 15 Step 2651 Train Loss: 0.6028
Epoch 15 Step 2701 Train Loss: 0.5705
Epoch 15 Step 2751 Train Loss: 0.6142
Epoch 15 Step 2801 Train Loss: 0.6206
Epoch 15 Step 2851 Train Loss: 0.5879
Epoch 15 Step 2901 Train Loss: 0.6516
Epoch 15 Step 2951 Train Loss: 0.6083
Epoch 15 Step 3001 Train Loss: 0.6572
Epoch 15 Step 3051 Train Loss: 0.5750
Epoch 15 Step 3101 Train Loss: 0.6229
Epoch 15 Step 3151 Train Loss: 0.5747
Epoch 15: Train Overall MSE: 0.0127 Validation Overall MSE: 0.0137. 
Train Top 20 DE MSE: 0.1155 Validation Top 20 DE MSE: 0.1373. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1191
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0149502875
test_unseen_single_pearson: 0.9775018785149
test_unseen_single_mse_de: 0.11912031
test_unseen_single_pearson_de: 0.6388436077648499
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.498681662226718
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.19693593314763227
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5512534818941505
test_unseen_single_mse_top20_de_non_dropout: 0.16908991
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.052 MB uploadedwandb: | 0.050 MB of 0.052 MB uploadedwandb: / 0.050 MB of 0.052 MB uploadedwandb: - 0.052 MB of 0.052 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:                                             train_de_pearson ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÉ
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:                                               val_de_pearson ‚ñà‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÉ
wandb:                                                      val_mse ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñÖ‚ñà‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.11912
wandb:                                              test_de_pearson 0.63884
wandb:               test_frac_opposite_direction_top20_non_dropout 0.19694
wandb:                          test_frac_sigma_below_1_non_dropout 0.55125
wandb:                                                     test_mse 0.01495
wandb:                                test_mse_top20_de_non_dropout 0.16909
wandb:                                                 test_pearson 0.9775
wandb:                                           test_pearson_delta 0.49868
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.19694
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.55125
wandb:                                       test_unseen_single_mse 0.01495
wandb:                                    test_unseen_single_mse_de 0.11912
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.16909
wandb:                                   test_unseen_single_pearson 0.9775
wandb:                                test_unseen_single_pearson_de 0.63884
wandb:                             test_unseen_single_pearson_delta 0.49868
wandb:                                                 train_de_mse 0.11549
wandb:                                             train_de_pearson 0.66551
wandb:                                                    train_mse 0.01271
wandb:                                                train_pearson 0.98089
wandb:                                                training_loss 0.58602
wandb:                                                   val_de_mse 0.13728
wandb:                                               val_de_pearson 0.69083
wandb:                                                      val_mse 0.01365
wandb:                                                  val_pearson 0.97964
wandb: 
wandb: üöÄ View run geneformer_Replogle_rpe1_essential_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/ipqigpzz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240923_005448-ipqigpzz/logs
