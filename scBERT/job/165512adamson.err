Loading compilers/gcc/12.2.0
  ERROR: Module cannot be loaded due to a conflict.
    HINT: Might try "module unload compilers/gcc" first.
cmake-3.27.0 loaded successful
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_170231-6kw383jl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406675_1_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/6kw383jl
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
  0%|                                                                                       | 0/3895 [00:00<?, ?it/s]  0%|                                                                             | 1/3895 [00:01<1:18:02,  1.20s/it]  1%|‚ñä                                                                             | 40/3895 [00:01<01:31, 42.11it/s]  2%|‚ñà‚ñé                                                                            | 63/3895 [00:01<01:09, 55.36it/s]  2%|‚ñà‚ñå                                                                            | 80/3895 [00:01<01:00, 62.99it/s]  2%|‚ñà‚ñâ                                                                            | 94/3895 [00:01<00:54, 69.15it/s]  3%|‚ñà‚ñà                                                                           | 106/3895 [00:02<00:52, 71.65it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 117/3895 [00:02<00:50, 74.85it/s]  3%|‚ñà‚ñà‚ñå                                                                          | 127/3895 [00:02<00:48, 77.93it/s]  4%|‚ñà‚ñà‚ñã                                                                          | 137/3895 [00:02<00:46, 80.24it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 147/3895 [00:02<00:45, 82.90it/s]  4%|‚ñà‚ñà‚ñà                                                                          | 157/3895 [00:02<00:43, 85.12it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 167/3895 [00:02<00:43, 85.93it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 178/3895 [00:02<00:42, 87.32it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 188/3895 [00:02<00:41, 88.29it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 198/3895 [00:03<00:40, 90.80it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 208/3895 [00:03<00:41, 87.89it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 219/3895 [00:03<00:40, 91.73it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 229/3895 [00:03<00:40, 90.64it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 239/3895 [00:03<00:41, 88.13it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 249/3895 [00:03<00:41, 88.53it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 259/3895 [00:03<00:40, 90.87it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 269/3895 [00:03<00:41, 87.75it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 278/3895 [00:03<00:41, 88.07it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 288/3895 [00:04<00:41, 86.53it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 298/3895 [00:04<00:40, 89.12it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 307/3895 [00:04<00:40, 88.54it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 317/3895 [00:04<00:40, 89.09it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 327/3895 [00:04<00:38, 91.70it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 337/3895 [00:04<00:41, 85.97it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 347/3895 [00:04<00:39, 89.17it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 358/3895 [00:04<00:39, 89.61it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 368/3895 [00:04<00:38, 92.38it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 378/3895 [00:05<00:38, 91.36it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 388/3895 [00:05<00:38, 90.73it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 398/3895 [00:05<00:38, 90.00it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 408/3895 [00:05<00:39, 87.41it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 417/3895 [00:05<00:39, 87.91it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 427/3895 [00:05<00:39, 87.33it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 437/3895 [00:05<00:38, 90.48it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 447/3895 [00:05<00:38, 89.58it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 457/3895 [00:05<00:38, 90.38it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 467/3895 [00:06<00:37, 90.26it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 477/3895 [00:06<00:37, 90.25it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 487/3895 [00:06<00:38, 87.41it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 497/3895 [00:06<00:38, 88.90it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 507/3895 [00:06<00:36, 91.58it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 517/3895 [00:06<00:36, 91.99it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 527/3895 [00:06<00:37, 90.92it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 537/3895 [00:06<00:37, 90.09it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 547/3895 [00:06<00:38, 87.18it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 557/3895 [00:07<00:36, 90.63it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 567/3895 [00:07<00:36, 90.44it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 577/3895 [00:07<00:36, 90.55it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 587/3895 [00:07<00:36, 89.91it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 597/3895 [00:07<00:36, 90.07it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 607/3895 [00:07<00:36, 89.17it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 616/3895 [00:07<00:37, 86.95it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 625/3895 [00:07<00:37, 86.97it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 635/3895 [00:07<00:35, 90.63it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 645/3895 [00:08<00:37, 87.33it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 656/3895 [00:08<00:35, 91.60it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 666/3895 [00:08<00:36, 88.58it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 675/3895 [00:08<00:36, 88.73it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 684/3895 [00:08<00:36, 88.66it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 694/3895 [00:08<00:34, 91.59it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 704/3895 [00:08<00:34, 91.24it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 714/3895 [00:08<00:36, 88.19it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 723/3895 [00:08<00:36, 85.83it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 734/3895 [00:09<00:35, 88.81it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 745/3895 [00:09<00:35, 89.17it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 756/3895 [00:09<00:33, 93.36it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 766/3895 [00:09<00:34, 91.88it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 776/3895 [00:09<00:35, 88.54it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 786/3895 [00:09<00:34, 91.36it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 796/3895 [00:09<00:33, 91.72it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 806/3895 [00:09<00:34, 90.83it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 816/3895 [00:09<00:33, 90.84it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                            | 826/3895 [00:10<00:34, 88.30it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 835/3895 [00:10<00:34, 88.55it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                            | 846/3895 [00:10<00:33, 89.73it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                            | 856/3895 [00:10<00:34, 87.46it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 865/3895 [00:10<00:34, 87.02it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 874/3895 [00:10<00:37, 81.41it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 883/3895 [00:10<00:37, 81.07it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 892/3895 [00:10<00:36, 83.00it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 901/3895 [00:11<00:37, 79.55it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 910/3895 [00:11<00:36, 81.87it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 919/3895 [00:11<00:36, 80.99it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 928/3895 [00:11<00:37, 78.44it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 936/3895 [00:11<00:37, 78.43it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 945/3895 [00:11<00:36, 80.13it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 954/3895 [00:11<00:37, 77.80it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 962/3895 [00:11<00:38, 75.72it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 970/3895 [00:11<00:38, 75.79it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 978/3895 [00:12<00:39, 73.56it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 987/3895 [00:12<00:38, 76.11it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 995/3895 [00:12<00:37, 76.35it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 1003/3895 [00:12<00:39, 74.13it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 1012/3895 [00:12<00:37, 76.92it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 1020/3895 [00:12<00:37, 76.93it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 1028/3895 [00:12<00:38, 74.36it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1036/3895 [00:12<00:37, 75.24it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 1044/3895 [00:12<00:37, 76.14it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 1053/3895 [00:12<00:36, 78.86it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 1061/3895 [00:13<00:36, 76.99it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 1070/3895 [00:13<00:35, 79.89it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                       | 1079/3895 [00:13<00:35, 78.74it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 1088/3895 [00:13<00:36, 77.75it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 1097/3895 [00:13<00:34, 80.03it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 1106/3895 [00:13<00:34, 80.76it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 1115/3895 [00:13<00:34, 80.80it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 1124/3895 [00:13<00:34, 80.20it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1133/3895 [00:13<00:34, 80.53it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1142/3895 [00:14<00:34, 79.49it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1150/3895 [00:14<00:36, 74.97it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1160/3895 [00:14<00:33, 81.57it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1169/3895 [00:14<00:33, 80.71it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                     | 1178/3895 [00:14<00:34, 78.34it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1186/3895 [00:14<00:34, 78.58it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1195/3895 [00:14<00:33, 81.12it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1204/3895 [00:14<00:34, 78.28it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1212/3895 [00:14<00:34, 78.33it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1221/3895 [00:15<00:33, 80.97it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1230/3895 [00:15<00:32, 81.19it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1239/3895 [00:15<00:35, 75.13it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1250/3895 [00:15<00:32, 81.95it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1259/3895 [00:15<00:32, 81.24it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1268/3895 [00:15<00:32, 80.48it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1277/3895 [00:15<00:33, 78.10it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1286/3895 [00:15<00:33, 78.32it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1294/3895 [00:16<00:33, 78.61it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1303/3895 [00:16<00:32, 79.21it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1312/3895 [00:16<00:31, 82.06it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1321/3895 [00:16<00:32, 78.47it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1330/3895 [00:16<00:32, 78.92it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1339/3895 [00:16<00:31, 81.91it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1348/3895 [00:16<00:31, 81.47it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1357/3895 [00:16<00:31, 81.24it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1366/3895 [00:16<00:32, 78.38it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1375/3895 [00:17<00:31, 79.00it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1384/3895 [00:17<00:31, 79.76it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 1394/3895 [00:17<00:30, 82.51it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 1403/3895 [00:17<00:30, 82.15it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1412/3895 [00:17<00:30, 81.81it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1421/3895 [00:17<00:30, 81.33it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1430/3895 [00:17<00:31, 78.88it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1440/3895 [00:17<00:30, 79.49it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1449/3895 [00:17<00:29, 82.21it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1458/3895 [00:18<00:30, 79.30it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1468/3895 [00:18<00:29, 82.06it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1477/3895 [00:18<00:30, 79.19it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 1486/3895 [00:18<00:29, 81.82it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1495/3895 [00:18<00:29, 81.22it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1504/3895 [00:18<00:30, 78.26it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1513/3895 [00:18<00:29, 81.19it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                              | 1522/3895 [00:18<00:30, 78.27it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 1532/3895 [00:18<00:29, 79.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1540/3895 [00:19<00:29, 79.16it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1550/3895 [00:19<00:29, 79.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1560/3895 [00:19<00:29, 79.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1570/3895 [00:19<00:28, 81.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1579/3895 [00:19<00:29, 79.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 1589/3895 [00:19<00:27, 82.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1598/3895 [00:19<00:27, 82.81it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1607/3895 [00:19<00:29, 78.38it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1616/3895 [00:20<00:28, 79.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1627/3895 [00:20<00:27, 82.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1636/3895 [00:20<00:26, 84.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 1646/3895 [00:20<00:25, 86.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 1656/3895 [00:20<00:24, 90.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                           | 1667/3895 [00:20<00:24, 91.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 1679/3895 [00:20<00:22, 96.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 1690/3895 [00:20<00:22, 98.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 1700/3895 [00:20<00:22, 98.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 1711/3895 [00:21<00:22, 99.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1721/3895 [00:21<00:22, 95.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 1733/3895 [00:21<00:21, 100.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 1744/3895 [00:21<00:21, 98.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 1754/3895 [00:21<00:21, 97.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 1764/3895 [00:21<00:21, 98.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1774/3895 [00:21<00:21, 97.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 1784/3895 [00:21<00:21, 96.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 1794/3895 [00:21<00:21, 96.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1804/3895 [00:21<00:21, 95.90it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 1814/3895 [00:22<00:21, 96.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 1824/3895 [00:22<00:22, 92.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 1835/3895 [00:22<00:21, 95.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1845/3895 [00:22<00:21, 96.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 1856/3895 [00:22<00:20, 97.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 1867/3895 [00:22<00:21, 96.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 1878/3895 [00:22<00:20, 97.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1889/3895 [00:22<00:20, 97.01it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 1900/3895 [00:22<00:20, 97.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 1911/3895 [00:23<00:20, 97.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1921/3895 [00:23<00:20, 96.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1931/3895 [00:23<00:20, 96.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 1941/3895 [00:23<00:20, 95.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1951/3895 [00:23<00:20, 95.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1961/3895 [00:23<00:20, 96.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 1971/3895 [00:23<00:20, 93.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 1982/3895 [00:23<00:19, 96.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 1992/3895 [00:23<00:19, 95.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 2003/3895 [00:24<00:19, 97.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 2013/3895 [00:24<00:19, 95.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 2023/3895 [00:24<00:19, 95.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 2033/3895 [00:24<00:19, 96.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 2043/3895 [00:24<00:19, 95.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 2053/3895 [00:24<00:19, 94.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 2064/3895 [00:24<00:18, 97.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 2074/3895 [00:24<00:19, 93.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 2084/3895 [00:24<00:19, 94.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 2094/3895 [00:24<00:19, 94.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2104/3895 [00:25<00:19, 93.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 2114/3895 [00:25<00:18, 94.03it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 2124/3895 [00:25<00:18, 94.34it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 2134/3895 [00:25<00:19, 91.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 2145/3895 [00:25<00:18, 95.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 2155/3895 [00:25<00:18, 94.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 2165/3895 [00:25<00:18, 93.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 2176/3895 [00:25<00:18, 94.10it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 2187/3895 [00:25<00:17, 95.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 2197/3895 [00:26<00:17, 95.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 2207/3895 [00:26<00:17, 96.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2217/3895 [00:26<00:17, 96.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 2227/3895 [00:26<00:17, 97.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2237/3895 [00:26<00:16, 97.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 2247/3895 [00:26<00:16, 98.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 2257/3895 [00:26<00:16, 98.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 2267/3895 [00:26<00:16, 98.30it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2278/3895 [00:26<00:16, 95.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2289/3895 [00:27<00:16, 98.80it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 2299/3895 [00:27<00:16, 98.75it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 2310/3895 [00:27<00:15, 101.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2321/3895 [00:27<00:15, 101.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2332/3895 [00:27<00:15, 100.02it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2343/3895 [00:27<00:16, 96.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2353/3895 [00:27<00:15, 97.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2363/3895 [00:27<00:15, 96.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2373/3895 [00:27<00:16, 93.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2383/3895 [00:28<00:16, 91.50it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2393/3895 [00:28<00:17, 84.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2402/3895 [00:28<00:17, 85.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2411/3895 [00:28<00:18, 80.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2420/3895 [00:28<00:18, 79.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2429/3895 [00:28<00:18, 80.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2438/3895 [00:28<00:17, 82.03it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2448/3895 [00:28<00:17, 82.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2458/3895 [00:28<00:16, 86.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 2467/3895 [00:29<00:16, 86.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 2476/3895 [00:29<00:16, 86.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 2486/3895 [00:29<00:16, 87.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 2496/3895 [00:29<00:15, 88.25it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 2505/3895 [00:29<00:15, 87.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 2516/3895 [00:29<00:14, 93.12it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 2526/3895 [00:29<00:14, 94.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2537/3895 [00:29<00:13, 98.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 2547/3895 [00:29<00:14, 95.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 2557/3895 [00:29<00:13, 96.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 2567/3895 [00:30<00:13, 96.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 2577/3895 [00:30<00:13, 96.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 2588/3895 [00:30<00:13, 95.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 2599/3895 [00:30<00:13, 98.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 2610/3895 [00:30<00:12, 99.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2620/3895 [00:30<00:12, 99.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2631/3895 [00:30<00:12, 100.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2642/3895 [00:30<00:12, 99.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2652/3895 [00:30<00:12, 98.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2663/3895 [00:31<00:12, 99.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2674/3895 [00:31<00:12, 99.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2685/3895 [00:31<00:12, 99.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2696/3895 [00:31<00:12, 99.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2706/3895 [00:31<00:12, 96.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 2718/3895 [00:31<00:11, 99.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2729/3895 [00:31<00:11, 100.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2740/3895 [00:31<00:11, 101.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2751/3895 [00:31<00:11, 101.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2762/3895 [00:32<00:11, 101.43it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2773/3895 [00:32<00:11, 101.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 2784/3895 [00:32<00:11, 99.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2796/3895 [00:32<00:11, 99.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2808/3895 [00:32<00:10, 102.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 2819/3895 [00:32<00:10, 102.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2830/3895 [00:32<00:10, 102.33it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2841/3895 [00:32<00:10, 104.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2852/3895 [00:32<00:10, 100.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2863/3895 [00:33<00:10, 102.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2874/3895 [00:33<00:10, 96.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2885/3895 [00:33<00:10, 99.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2896/3895 [00:33<00:09, 102.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2907/3895 [00:33<00:09, 99.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2918/3895 [00:33<00:09, 99.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2929/3895 [00:33<00:09, 98.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2941/3895 [00:33<00:09, 100.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2952/3895 [00:33<00:09, 100.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2963/3895 [00:34<00:09, 99.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2974/3895 [00:34<00:09, 100.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2985/3895 [00:34<00:09, 99.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2996/3895 [00:34<00:09, 99.68it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 3007/3895 [00:34<00:08, 100.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3018/3895 [00:34<00:08, 102.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3029/3895 [00:34<00:08, 99.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3040/3895 [00:34<00:08, 102.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3051/3895 [00:34<00:08, 99.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3061/3895 [00:35<00:08, 99.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3071/3895 [00:35<00:08, 98.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3082/3895 [00:35<00:08, 99.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3092/3895 [00:35<00:08, 99.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3102/3895 [00:35<00:07, 99.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3112/3895 [00:35<00:07, 98.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3123/3895 [00:35<00:07, 99.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3135/3895 [00:35<00:07, 99.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3145/3895 [00:35<00:07, 98.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3156/3895 [00:35<00:07, 99.54it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3167/3895 [00:36<00:07, 96.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3179/3895 [00:36<00:07, 100.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3190/3895 [00:36<00:07, 100.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3201/3895 [00:36<00:06, 99.85it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3213/3895 [00:36<00:06, 99.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3223/3895 [00:36<00:06, 99.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3233/3895 [00:36<00:06, 99.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3243/3895 [00:36<00:06, 99.37it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3253/3895 [00:36<00:06, 99.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3264/3895 [00:37<00:06, 101.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3275/3895 [00:37<00:06, 98.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3285/3895 [00:37<00:06, 98.28it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 3295/3895 [00:37<00:06, 97.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3305/3895 [00:37<00:05, 98.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 3315/3895 [00:37<00:05, 98.15it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3326/3895 [00:37<00:05, 98.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 3337/3895 [00:37<00:05, 98.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3348/3895 [00:37<00:05, 100.72it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3359/3895 [00:38<00:05, 94.65it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3371/3895 [00:38<00:05, 98.38it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3381/3895 [00:38<00:05, 96.01it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3392/3895 [00:38<00:05, 99.59it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 3403/3895 [00:38<00:04, 102.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 3414/3895 [00:38<00:04, 98.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 3424/3895 [00:38<00:04, 98.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 3434/3895 [00:38<00:04, 95.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 3444/3895 [00:38<00:04, 93.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 3454/3895 [00:39<00:04, 91.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 3464/3895 [00:39<00:05, 84.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 3473/3895 [00:39<00:05, 83.62it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 3482/3895 [00:39<00:04, 82.64it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 3491/3895 [00:39<00:04, 81.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 3501/3895 [00:39<00:04, 84.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 3510/3895 [00:39<00:04, 80.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 3519/3895 [00:39<00:04, 80.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 3528/3895 [00:39<00:04, 79.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 3537/3895 [00:40<00:04, 77.24it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 3547/3895 [00:40<00:04, 80.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 3556/3895 [00:40<00:04, 80.09it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3565/3895 [00:40<00:04, 82.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 3574/3895 [00:40<00:03, 81.93it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 3584/3895 [00:40<00:03, 82.67it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 3595/3895 [00:40<00:03, 87.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3606/3895 [00:40<00:03, 91.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3616/3895 [00:41<00:03, 83.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 3625/3895 [00:41<00:03, 81.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3634/3895 [00:41<00:03, 80.81it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3643/3895 [00:41<00:03, 83.07it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3652/3895 [00:41<00:02, 82.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3661/3895 [00:41<00:02, 81.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3670/3895 [00:41<00:02, 77.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3679/3895 [00:41<00:02, 80.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3688/3895 [00:41<00:02, 77.12it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3697/3895 [00:42<00:02, 77.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3706/3895 [00:42<00:02, 80.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3715/3895 [00:42<00:02, 83.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3725/3895 [00:42<00:01, 86.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3734/3895 [00:42<00:01, 87.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3743/3895 [00:42<00:01, 86.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3754/3895 [00:42<00:01, 91.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3764/3895 [00:42<00:01, 91.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3774/3895 [00:42<00:01, 92.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3785/3895 [00:42<00:01, 93.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3796/3895 [00:43<00:01, 94.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3807/3895 [00:43<00:00, 96.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3817/3895 [00:43<00:00, 91.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3827/3895 [00:43<00:00, 92.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3839/3895 [00:43<00:00, 92.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3850/3895 [00:43<00:00, 96.97it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3860/3895 [00:43<00:00, 95.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3871/3895 [00:43<00:00, 95.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3881/3895 [00:44<00:00, 94.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3892/3895 [00:44<00:00, 94.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3895/3895 [00:44<00:00, 88.23it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.2492
Epoch 1 Step 51 Train Loss: 0.2479
Epoch 1 Step 101 Train Loss: 0.2638
Epoch 1: Train Overall MSE: 0.0887 Validation Overall MSE: 0.0942. 
Train Top 20 DE MSE: 0.1557 Validation Top 20 DE MSE: 0.2622. 
Epoch 2 Step 1 Train Loss: 0.2520
Epoch 2 Step 51 Train Loss: 0.2419
Epoch 2 Step 101 Train Loss: 0.2487
Epoch 2: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0026. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0468. 
Epoch 3 Step 1 Train Loss: 0.2457
Epoch 3 Step 51 Train Loss: 0.2376
Epoch 3 Step 101 Train Loss: 0.2468
Epoch 3: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0240 Validation Top 20 DE MSE: 0.0519. 
Epoch 4 Step 1 Train Loss: 0.2662
Epoch 4 Step 51 Train Loss: 0.2379
Epoch 4 Step 101 Train Loss: 0.2914
Epoch 4: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0047 Validation Top 20 DE MSE: 0.0596. 
Epoch 5 Step 1 Train Loss: 0.2463
Epoch 5 Step 51 Train Loss: 0.2489
Epoch 5 Step 101 Train Loss: 0.2610
Epoch 5: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0572. 
Epoch 6 Step 1 Train Loss: 0.2547
Epoch 6 Step 51 Train Loss: 0.2508
Epoch 6 Step 101 Train Loss: 0.2484
Epoch 6: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0594. 
Epoch 7 Step 1 Train Loss: 0.2669
Epoch 7 Step 51 Train Loss: 0.2568
Epoch 7 Step 101 Train Loss: 0.2555
Epoch 7: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0028 Validation Top 20 DE MSE: 0.0596. 
Epoch 8 Step 1 Train Loss: 0.2520
Epoch 8 Step 51 Train Loss: 0.2741
Epoch 8 Step 101 Train Loss: 0.2500
Epoch 8: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0042 Validation Top 20 DE MSE: 0.0661. 
Epoch 9 Step 1 Train Loss: 0.2550
Epoch 9 Step 51 Train Loss: 0.2386
Epoch 9 Step 101 Train Loss: 0.2547
Epoch 9: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0030 Validation Top 20 DE MSE: 0.0653. 
Epoch 10 Step 1 Train Loss: 0.2655
Epoch 10 Step 51 Train Loss: 0.2504
Epoch 10 Step 101 Train Loss: 0.2455
Epoch 10: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0034 Validation Top 20 DE MSE: 0.0570. 
Epoch 11 Step 1 Train Loss: 0.2681
Epoch 11 Step 51 Train Loss: 0.2509
Epoch 11 Step 101 Train Loss: 0.2560
Epoch 11: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0032 Validation Top 20 DE MSE: 0.0617. 
Epoch 12 Step 1 Train Loss: 0.2493
Epoch 12 Step 51 Train Loss: 0.2632
Epoch 12 Step 101 Train Loss: 0.2635
Epoch 12: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0027 Validation Top 20 DE MSE: 0.0557. 
Epoch 13 Step 1 Train Loss: 0.2593
Epoch 13 Step 51 Train Loss: 0.2636
Epoch 13 Step 101 Train Loss: 0.2562
Epoch 13: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0031 Validation Top 20 DE MSE: 0.0649. 
Epoch 14 Step 1 Train Loss: 0.2652
Epoch 14 Step 51 Train Loss: 0.2586
Epoch 14 Step 101 Train Loss: 0.2818
Epoch 14: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0026 Validation Top 20 DE MSE: 0.0632. 
Epoch 15 Step 1 Train Loss: 0.2712
Epoch 15 Step 51 Train Loss: 0.2636
Epoch 15 Step 101 Train Loss: 0.2433
Epoch 15: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0033 Validation Top 20 DE MSE: 0.0544. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1482
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0028773444
test_unseen_single_pearson: 0.9916540130529694
test_unseen_single_mse_de: 0.14816427
test_unseen_single_pearson_de: 0.9429500718203425
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.07355903616487135
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.5
test_unseen_single_frac_sigma_below_1_non_dropout: 0.85
test_unseen_single_mse_top20_de_non_dropout: 0.14816427
Done!
wandb: - 0.001 MB of 0.020 MB uploadedwandb: \ 0.003 MB of 0.020 MB uploadedwandb: | 0.010 MB of 0.020 MB uploadedwandb: / 0.010 MB of 0.020 MB uploadedwandb: - 0.010 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.020 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÜ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.14816
wandb:                                              test_de_pearson 0.94295
wandb:               test_frac_opposite_direction_top20_non_dropout 0.5
wandb:                          test_frac_sigma_below_1_non_dropout 0.85
wandb:                                                     test_mse 0.00288
wandb:                                test_mse_top20_de_non_dropout 0.14816
wandb:                                                 test_pearson 0.99165
wandb:                                           test_pearson_delta 0.07356
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.5
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.85
wandb:                                       test_unseen_single_mse 0.00288
wandb:                                    test_unseen_single_mse_de 0.14816
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.14816
wandb:                                   test_unseen_single_pearson 0.99165
wandb:                                test_unseen_single_pearson_de 0.94295
wandb:                             test_unseen_single_pearson_delta 0.07356
wandb:                                                 train_de_mse 0.00325
wandb:                                             train_de_pearson 0.99911
wandb:                                                    train_mse 0.00051
wandb:                                                train_pearson 0.99852
wandb:                                                training_loss 0.24546
wandb:                                                   val_de_mse 0.05443
wandb:                                               val_de_pearson 0.97784
wandb:                                                      val_mse 0.00097
wandb:                                                  val_pearson 0.99714
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406675_1_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/6kw383jl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_170231-6kw383jl/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_170632-knvfjr5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406675_1_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/knvfjr5r
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2514
Epoch 1 Step 51 Train Loss: 0.2596
Epoch 1 Step 101 Train Loss: 0.2303
Epoch 1: Train Overall MSE: 0.0210 Validation Overall MSE: 0.0199. 
Train Top 20 DE MSE: 0.0514 Validation Top 20 DE MSE: 0.0406. 
Epoch 2 Step 1 Train Loss: 0.2521
Epoch 2 Step 51 Train Loss: 0.2509
Epoch 2 Step 101 Train Loss: 0.2532
Epoch 2: Train Overall MSE: 0.0131 Validation Overall MSE: 0.0079. 
Train Top 20 DE MSE: 0.0975 Validation Top 20 DE MSE: 0.0331. 
Epoch 3 Step 1 Train Loss: 0.2793
Epoch 3 Step 51 Train Loss: 0.2492
Epoch 3 Step 101 Train Loss: 0.2605
Epoch 3: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0199 Validation Top 20 DE MSE: 0.0091. 
Epoch 4 Step 1 Train Loss: 0.2400
Epoch 4 Step 51 Train Loss: 0.2572
Epoch 4 Step 101 Train Loss: 0.2679
Epoch 4: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0078. 
Epoch 5 Step 1 Train Loss: 0.2602
Epoch 5 Step 51 Train Loss: 0.2554
Epoch 5 Step 101 Train Loss: 0.2413
Epoch 5: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0007. 
Train Top 20 DE MSE: 0.0076 Validation Top 20 DE MSE: 0.0079. 
Epoch 6 Step 1 Train Loss: 0.2565
Epoch 6 Step 51 Train Loss: 0.2692
Epoch 6 Step 101 Train Loss: 0.2541
Epoch 6: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0007. 
Train Top 20 DE MSE: 0.0065 Validation Top 20 DE MSE: 0.0074. 
Epoch 7 Step 1 Train Loss: 0.2567
Epoch 7 Step 51 Train Loss: 0.2496
Epoch 7 Step 101 Train Loss: 0.2590
Epoch 7: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0007. 
Train Top 20 DE MSE: 0.0066 Validation Top 20 DE MSE: 0.0075. 
Epoch 8 Step 1 Train Loss: 0.2465
Epoch 8 Step 51 Train Loss: 0.2515
Epoch 8 Step 101 Train Loss: 0.2689
Epoch 8: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 9 Step 1 Train Loss: 0.2481
Epoch 9 Step 51 Train Loss: 0.2736
Epoch 9 Step 101 Train Loss: 0.2522
Epoch 9: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0008. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0086. 
Epoch 10 Step 1 Train Loss: 0.2383
Epoch 10 Step 51 Train Loss: 0.2500
Epoch 10 Step 101 Train Loss: 0.2489
Epoch 10: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0008. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0084. 
Epoch 11 Step 1 Train Loss: 0.2437
Epoch 11 Step 51 Train Loss: 0.2515
Epoch 11 Step 101 Train Loss: 0.2497
Epoch 11: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0054 Validation Top 20 DE MSE: 0.0091. 
Epoch 12 Step 1 Train Loss: 0.2451
Epoch 12 Step 51 Train Loss: 0.2562
Epoch 12 Step 101 Train Loss: 0.2602
Epoch 12: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0008. 
Train Top 20 DE MSE: 0.0053 Validation Top 20 DE MSE: 0.0086. 
Epoch 13 Step 1 Train Loss: 0.2465
Epoch 13 Step 51 Train Loss: 0.2352
Epoch 13 Step 101 Train Loss: 0.2485
Epoch 13: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0050 Validation Top 20 DE MSE: 0.0090. 
Epoch 14 Step 1 Train Loss: 0.2497
Epoch 14 Step 51 Train Loss: 0.2551
Epoch 14 Step 101 Train Loss: 0.2488
Epoch 14: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0008. 
Train Top 20 DE MSE: 0.0054 Validation Top 20 DE MSE: 0.0087. 
Epoch 15 Step 1 Train Loss: 0.2546
Epoch 15 Step 51 Train Loss: 0.2507
Epoch 15 Step 101 Train Loss: 0.2611
Epoch 15: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0052 Validation Top 20 DE MSE: 0.0091. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1534
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0017314744
test_unseen_single_pearson: 0.9949301197520992
test_unseen_single_mse_de: 0.15335006
test_unseen_single_pearson_de: 0.9372725832966117
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.09730487492085016
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.42500000000000004
test_unseen_single_frac_sigma_below_1_non_dropout: 0.825
test_unseen_single_mse_top20_de_non_dropout: 0.15335006
Done!
wandb: - 0.003 MB of 0.019 MB uploadedwandb: \ 0.012 MB of 0.019 MB uploadedwandb: | 0.019 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÖ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.15335
wandb:                                              test_de_pearson 0.93727
wandb:               test_frac_opposite_direction_top20_non_dropout 0.425
wandb:                          test_frac_sigma_below_1_non_dropout 0.825
wandb:                                                     test_mse 0.00173
wandb:                                test_mse_top20_de_non_dropout 0.15335
wandb:                                                 test_pearson 0.99493
wandb:                                           test_pearson_delta 0.0973
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.425
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.825
wandb:                                       test_unseen_single_mse 0.00173
wandb:                                    test_unseen_single_mse_de 0.15335
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.15335
wandb:                                   test_unseen_single_pearson 0.99493
wandb:                                test_unseen_single_pearson_de 0.93727
wandb:                             test_unseen_single_pearson_delta 0.0973
wandb:                                                 train_de_mse 0.0052
wandb:                                             train_de_pearson 0.99859
wandb:                                                    train_mse 0.00048
wandb:                                                train_pearson 0.99862
wandb:                                                training_loss 0.26957
wandb:                                                   val_de_mse 0.00909
wandb:                                               val_de_pearson 0.99797
wandb:                                                      val_mse 0.00085
wandb:                                                  val_pearson 0.99751
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406675_1_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/knvfjr5r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_170632-knvfjr5r/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_170908-lh3u42nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406675_1_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/lh3u42nw
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2544
Epoch 1 Step 51 Train Loss: 0.2678
Epoch 1 Step 101 Train Loss: 0.2586
Epoch 1: Train Overall MSE: 0.7369 Validation Overall MSE: 0.7698. 
Train Top 20 DE MSE: 2.0589 Validation Top 20 DE MSE: 1.8779. 
Epoch 2 Step 1 Train Loss: 0.2592
Epoch 2 Step 51 Train Loss: 0.2537
Epoch 2 Step 101 Train Loss: 0.2861
Epoch 2: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0404 Validation Top 20 DE MSE: 0.0530. 
Epoch 3 Step 1 Train Loss: 0.2434
Epoch 3 Step 51 Train Loss: 0.2440
Epoch 3 Step 101 Train Loss: 0.2563
Epoch 3: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0130 Validation Top 20 DE MSE: 0.0541. 
Epoch 4 Step 1 Train Loss: 0.2701
Epoch 4 Step 51 Train Loss: 0.2543
Epoch 4 Step 101 Train Loss: 0.2666
Epoch 4: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0185 Validation Top 20 DE MSE: 0.0536. 
Epoch 5 Step 1 Train Loss: 0.2401
Epoch 5 Step 51 Train Loss: 0.2476
Epoch 5 Step 101 Train Loss: 0.2527
Epoch 5: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0427 Validation Top 20 DE MSE: 0.0578. 
Epoch 6 Step 1 Train Loss: 0.2531
Epoch 6 Step 51 Train Loss: 0.2586
Epoch 6 Step 101 Train Loss: 0.2447
Epoch 6: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0140 Validation Top 20 DE MSE: 0.0501. 
Epoch 7 Step 1 Train Loss: 0.2496
Epoch 7 Step 51 Train Loss: 0.2619
Epoch 7 Step 101 Train Loss: 0.2638
Epoch 7: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0079 Validation Top 20 DE MSE: 0.0525. 
Epoch 8 Step 1 Train Loss: 0.2696
Epoch 8 Step 51 Train Loss: 0.2588
Epoch 8 Step 101 Train Loss: 0.2449
Epoch 8: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0088 Validation Top 20 DE MSE: 0.0513. 
Epoch 9 Step 1 Train Loss: 0.2710
Epoch 9 Step 51 Train Loss: 0.2696
Epoch 9 Step 101 Train Loss: 0.2514
Epoch 9: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0078 Validation Top 20 DE MSE: 0.0507. 
Epoch 10 Step 1 Train Loss: 0.2561
Epoch 10 Step 51 Train Loss: 0.2530
Epoch 10 Step 101 Train Loss: 0.2568
Epoch 10: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0083 Validation Top 20 DE MSE: 0.0527. 
Epoch 11 Step 1 Train Loss: 0.2691
Epoch 11 Step 51 Train Loss: 0.2445
Epoch 11 Step 101 Train Loss: 0.2820
Epoch 11: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0077 Validation Top 20 DE MSE: 0.0524. 
Epoch 12 Step 1 Train Loss: 0.2501
Epoch 12 Step 51 Train Loss: 0.2447
Epoch 12 Step 101 Train Loss: 0.2796
Epoch 12: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0516. 
Epoch 13 Step 1 Train Loss: 0.2756
Epoch 13 Step 51 Train Loss: 0.2460
Epoch 13 Step 101 Train Loss: 0.2601
Epoch 13: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0075 Validation Top 20 DE MSE: 0.0519. 
Epoch 14 Step 1 Train Loss: 0.2659
Epoch 14 Step 51 Train Loss: 0.2571
Epoch 14 Step 101 Train Loss: 0.2625
Epoch 14: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0085 Validation Top 20 DE MSE: 0.0515. 
Epoch 15 Step 1 Train Loss: 0.2636
Epoch 15 Step 51 Train Loss: 0.2568
Epoch 15 Step 101 Train Loss: 0.2546
Epoch 15: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0067 Validation Top 20 DE MSE: 0.0532. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0484
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0010706587
test_unseen_single_pearson: 0.9968807232659544
test_unseen_single_mse_de: 0.04840546
test_unseen_single_pearson_de: 0.9855968101794392
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.2107603041415729
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.25
test_unseen_single_frac_sigma_below_1_non_dropout: 0.875
test_unseen_single_mse_top20_de_non_dropout: 0.0484387
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.003 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb: \ 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñÜ‚ñá‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñá‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.04841
wandb:                                              test_de_pearson 0.9856
wandb:               test_frac_opposite_direction_top20_non_dropout 0.25
wandb:                          test_frac_sigma_below_1_non_dropout 0.875
wandb:                                                     test_mse 0.00107
wandb:                                test_mse_top20_de_non_dropout 0.04844
wandb:                                                 test_pearson 0.99688
wandb:                                           test_pearson_delta 0.21076
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.25
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.875
wandb:                                       test_unseen_single_mse 0.00107
wandb:                                    test_unseen_single_mse_de 0.04841
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.04844
wandb:                                   test_unseen_single_pearson 0.99688
wandb:                                test_unseen_single_pearson_de 0.9856
wandb:                             test_unseen_single_pearson_delta 0.21076
wandb:                                                 train_de_mse 0.00668
wandb:                                             train_de_pearson 0.99802
wandb:                                                    train_mse 0.00058
wandb:                                                train_pearson 0.99835
wandb:                                                training_loss 0.25693
wandb:                                                   val_de_mse 0.05322
wandb:                                               val_de_pearson 0.97876
wandb:                                                      val_mse 0.00117
wandb:                                                  val_pearson 0.99659
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406675_1_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/lh3u42nw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_170908-lh3u42nw/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_171154-hteywwre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406675_1_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/hteywwre
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2537
Epoch 1 Step 51 Train Loss: 0.2439
Epoch 1 Step 101 Train Loss: 0.2751
Epoch 1: Train Overall MSE: 0.1233 Validation Overall MSE: 0.1337. 
Train Top 20 DE MSE: 0.5326 Validation Top 20 DE MSE: 1.0119. 
Epoch 2 Step 1 Train Loss: 0.2646
Epoch 2 Step 51 Train Loss: 0.2743
Epoch 2 Step 101 Train Loss: 0.3033
Epoch 2: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0269 Validation Top 20 DE MSE: 0.0474. 
Epoch 3 Step 1 Train Loss: 0.3032
Epoch 3 Step 51 Train Loss: 0.2606
Epoch 3 Step 101 Train Loss: 0.2339
Epoch 3: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0133 Validation Top 20 DE MSE: 0.0627. 
Epoch 4 Step 1 Train Loss: 0.2642
Epoch 4 Step 51 Train Loss: 0.2649
Epoch 4 Step 101 Train Loss: 0.2433
Epoch 4: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0641. 
Epoch 5 Step 1 Train Loss: 0.2516
Epoch 5 Step 51 Train Loss: 0.2759
Epoch 5 Step 101 Train Loss: 0.2572
Epoch 5: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0586. 
Epoch 6 Step 1 Train Loss: 0.2482
Epoch 6 Step 51 Train Loss: 0.2549
Epoch 6 Step 101 Train Loss: 0.2519
Epoch 6: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0050 Validation Top 20 DE MSE: 0.0675. 
Epoch 7 Step 1 Train Loss: 0.2506
Epoch 7 Step 51 Train Loss: 0.2564
Epoch 7 Step 101 Train Loss: 0.2696
Epoch 7: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0060 Validation Top 20 DE MSE: 0.0664. 
Epoch 8 Step 1 Train Loss: 0.2584
Epoch 8 Step 51 Train Loss: 0.2640
Epoch 8 Step 101 Train Loss: 0.2686
Epoch 8: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0053 Validation Top 20 DE MSE: 0.0628. 
Epoch 9 Step 1 Train Loss: 0.2742
Epoch 9 Step 51 Train Loss: 0.2574
Epoch 9 Step 101 Train Loss: 0.2647
Epoch 9: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0047 Validation Top 20 DE MSE: 0.0642. 
Epoch 10 Step 1 Train Loss: 0.2492
Epoch 10 Step 51 Train Loss: 0.2504
Epoch 10 Step 101 Train Loss: 0.2465
Epoch 10: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0041 Validation Top 20 DE MSE: 0.0658. 
Epoch 11 Step 1 Train Loss: 0.2711
Epoch 11 Step 51 Train Loss: 0.2802
Epoch 11 Step 101 Train Loss: 0.2471
Epoch 11: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0044 Validation Top 20 DE MSE: 0.0669. 
Epoch 12 Step 1 Train Loss: 0.2780
Epoch 12 Step 51 Train Loss: 0.2421
Epoch 12 Step 101 Train Loss: 0.2592
Epoch 12: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0045 Validation Top 20 DE MSE: 0.0606. 
Epoch 13 Step 1 Train Loss: 0.2518
Epoch 13 Step 51 Train Loss: 0.2676
Epoch 13 Step 101 Train Loss: 0.2526
Epoch 13: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0042 Validation Top 20 DE MSE: 0.0643. 
Epoch 14 Step 1 Train Loss: 0.2526
Epoch 14 Step 51 Train Loss: 0.2759
Epoch 14 Step 101 Train Loss: 0.2471
Epoch 14: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0043 Validation Top 20 DE MSE: 0.0613. 
Epoch 15 Step 1 Train Loss: 0.2655
Epoch 15 Step 51 Train Loss: 0.2489
Epoch 15 Step 101 Train Loss: 0.2611
Epoch 15: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0045 Validation Top 20 DE MSE: 0.0613. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1035
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.002906185
test_unseen_single_pearson: 0.9915856329644269
test_unseen_single_mse_de: 0.10348154
test_unseen_single_pearson_de: 0.9532284452617745
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.13730299718974354
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.22499999999999998
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8
test_unseen_single_mse_top20_de_non_dropout: 0.10360873
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.001 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.10348
wandb:                                              test_de_pearson 0.95323
wandb:               test_frac_opposite_direction_top20_non_dropout 0.225
wandb:                          test_frac_sigma_below_1_non_dropout 0.8
wandb:                                                     test_mse 0.00291
wandb:                                test_mse_top20_de_non_dropout 0.10361
wandb:                                                 test_pearson 0.99159
wandb:                                           test_pearson_delta 0.1373
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.225
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.8
wandb:                                       test_unseen_single_mse 0.00291
wandb:                                    test_unseen_single_mse_de 0.10348
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.10361
wandb:                                   test_unseen_single_pearson 0.99159
wandb:                                test_unseen_single_pearson_de 0.95323
wandb:                             test_unseen_single_pearson_delta 0.1373
wandb:                                                 train_de_mse 0.00449
wandb:                                             train_de_pearson 0.9986
wandb:                                                    train_mse 0.00054
wandb:                                                train_pearson 0.99843
wandb:                                                training_loss 0.26544
wandb:                                                   val_de_mse 0.0613
wandb:                                               val_de_pearson 0.99126
wandb:                                                      val_mse 0.00102
wandb:                                                  val_pearson 0.99702
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406675_1_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/hteywwre
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_171154-hteywwre/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_171422-9tmh42sz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406675_1_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/9tmh42sz
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2564
Epoch 1 Step 51 Train Loss: 0.2453
Epoch 1 Step 101 Train Loss: 0.2795
Epoch 1: Train Overall MSE: 0.1859 Validation Overall MSE: 0.1935. 
Train Top 20 DE MSE: 1.5133 Validation Top 20 DE MSE: 1.5250. 
Epoch 2 Step 1 Train Loss: 0.2444
Epoch 2 Step 51 Train Loss: 0.2719
Epoch 2 Step 101 Train Loss: 0.2536
Epoch 2: Train Overall MSE: 0.0295 Validation Overall MSE: 0.0288. 
Train Top 20 DE MSE: 0.1195 Validation Top 20 DE MSE: 0.1579. 
Epoch 3 Step 1 Train Loss: 0.2746
Epoch 3 Step 51 Train Loss: 0.2714
Epoch 3 Step 101 Train Loss: 0.2691
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0212 Validation Top 20 DE MSE: 0.0520. 
Epoch 4 Step 1 Train Loss: 0.2561
Epoch 4 Step 51 Train Loss: 0.2577
Epoch 4 Step 101 Train Loss: 0.2690
Epoch 4: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0553. 
Epoch 5 Step 1 Train Loss: 0.2582
Epoch 5 Step 51 Train Loss: 0.2562
Epoch 5 Step 101 Train Loss: 0.2551
Epoch 5: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0060 Validation Top 20 DE MSE: 0.0646. 
Epoch 6 Step 1 Train Loss: 0.2531
Epoch 6 Step 51 Train Loss: 0.2502
Epoch 6 Step 101 Train Loss: 0.2549
Epoch 6: Train Overall MSE: 0.0005 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0038 Validation Top 20 DE MSE: 0.0655. 
Epoch 7 Step 1 Train Loss: 0.2492
Epoch 7 Step 51 Train Loss: 0.2513
Epoch 7 Step 101 Train Loss: 0.2745
Epoch 7: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0044 Validation Top 20 DE MSE: 0.0561. 
Epoch 8 Step 1 Train Loss: 0.2597
Epoch 8 Step 51 Train Loss: 0.2350
Epoch 8 Step 101 Train Loss: 0.2572
Epoch 8: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0042 Validation Top 20 DE MSE: 0.0590. 
Epoch 9 Step 1 Train Loss: 0.2573
Epoch 9 Step 51 Train Loss: 0.2593
Epoch 9 Step 101 Train Loss: 0.2588
Epoch 9: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0042 Validation Top 20 DE MSE: 0.0581. 
Epoch 10 Step 1 Train Loss: 0.2473
Epoch 10 Step 51 Train Loss: 0.2591
Epoch 10 Step 101 Train Loss: 0.2594
Epoch 10: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0044 Validation Top 20 DE MSE: 0.0620. 
Epoch 11 Step 1 Train Loss: 0.2672
Epoch 11 Step 51 Train Loss: 0.2639
Epoch 11 Step 101 Train Loss: 0.2603
Epoch 11: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0036 Validation Top 20 DE MSE: 0.0675. 
Epoch 12 Step 1 Train Loss: 0.2719
Epoch 12 Step 51 Train Loss: 0.2692
Epoch 12 Step 101 Train Loss: 0.2502
Epoch 12: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0038 Validation Top 20 DE MSE: 0.0605. 
Epoch 13 Step 1 Train Loss: 0.2435
Epoch 13 Step 51 Train Loss: 0.2639
Epoch 13 Step 101 Train Loss: 0.2523
Epoch 13: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0043 Validation Top 20 DE MSE: 0.0565. 
Epoch 14 Step 1 Train Loss: 0.2604
Epoch 14 Step 51 Train Loss: 0.2389
Epoch 14 Step 101 Train Loss: 0.2449
Epoch 14: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0046 Validation Top 20 DE MSE: 0.0582. 
Epoch 15 Step 1 Train Loss: 0.2818
Epoch 15 Step 51 Train Loss: 0.2639
Epoch 15 Step 101 Train Loss: 0.2391
Epoch 15: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0044 Validation Top 20 DE MSE: 0.0519. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1257
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0014869045
test_unseen_single_pearson: 0.9956628744013645
test_unseen_single_mse_de: 0.12574731
test_unseen_single_pearson_de: 0.9512380500229082
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.15663844228390583
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.42500000000000004
test_unseen_single_frac_sigma_below_1_non_dropout: 0.85
test_unseen_single_mse_top20_de_non_dropout: 0.12574732
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.008 MB of 0.019 MB uploadedwandb: / 0.008 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.12575
wandb:                                              test_de_pearson 0.95124
wandb:               test_frac_opposite_direction_top20_non_dropout 0.425
wandb:                          test_frac_sigma_below_1_non_dropout 0.85
wandb:                                                     test_mse 0.00149
wandb:                                test_mse_top20_de_non_dropout 0.12575
wandb:                                                 test_pearson 0.99566
wandb:                                           test_pearson_delta 0.15664
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.425
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.85
wandb:                                       test_unseen_single_mse 0.00149
wandb:                                    test_unseen_single_mse_de 0.12575
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.12575
wandb:                                   test_unseen_single_pearson 0.99566
wandb:                                test_unseen_single_pearson_de 0.95124
wandb:                             test_unseen_single_pearson_delta 0.15664
wandb:                                                 train_de_mse 0.00444
wandb:                                             train_de_pearson 0.99867
wandb:                                                    train_mse 0.00056
wandb:                                                train_pearson 0.99837
wandb:                                                training_loss 0.25324
wandb:                                                   val_de_mse 0.0519
wandb:                                               val_de_pearson 0.97868
wandb:                                                      val_mse 0.00097
wandb:                                                  val_pearson 0.99714
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406675_1_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/9tmh42sz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_171422-9tmh42sz/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:2
combo_seen2:1
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_171753-vcab61jp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406677_2_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/vcab61jp
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
  0%|                                                                                       | 0/3722 [00:00<?, ?it/s]  0%|‚ñè                                                                              | 8/3722 [00:00<00:57, 64.79it/s]  0%|‚ñç                                                                             | 18/3722 [00:00<00:46, 78.88it/s]  1%|‚ñå                                                                             | 27/3722 [00:00<00:44, 83.52it/s]  1%|‚ñä                                                                             | 36/3722 [00:00<00:43, 84.30it/s]  1%|‚ñâ                                                                             | 45/3722 [00:00<00:45, 80.47it/s]  1%|‚ñà‚ñè                                                                            | 54/3722 [00:00<00:45, 81.04it/s]  2%|‚ñà‚ñé                                                                            | 63/3722 [00:00<00:45, 79.89it/s]  2%|‚ñà‚ñå                                                                            | 72/3722 [00:00<00:45, 80.66it/s]  2%|‚ñà‚ñã                                                                            | 81/3722 [00:01<00:44, 82.30it/s]  2%|‚ñà‚ñâ                                                                            | 90/3722 [00:01<00:43, 83.36it/s]  3%|‚ñà‚ñà                                                                            | 99/3722 [00:01<00:43, 83.15it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 108/3722 [00:01<00:43, 83.70it/s]  3%|‚ñà‚ñà‚ñç                                                                          | 117/3722 [00:01<00:42, 84.27it/s]  3%|‚ñà‚ñà‚ñå                                                                          | 126/3722 [00:01<00:42, 84.44it/s]  4%|‚ñà‚ñà‚ñä                                                                          | 135/3722 [00:01<00:42, 84.54it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 144/3722 [00:01<00:42, 84.53it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 153/3722 [00:01<00:42, 84.90it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 162/3722 [00:01<00:43, 81.29it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 171/3722 [00:02<00:42, 83.65it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 180/3722 [00:02<00:42, 84.05it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 189/3722 [00:02<00:41, 84.90it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 198/3722 [00:02<00:41, 85.21it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 207/3722 [00:02<00:42, 83.03it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 217/3722 [00:02<00:40, 86.24it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 226/3722 [00:02<00:40, 85.70it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                        | 235/3722 [00:02<00:45, 77.21it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 243/3722 [00:03<00:50, 68.47it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 251/3722 [00:03<00:53, 64.32it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 258/3722 [00:03<00:55, 61.90it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 265/3722 [00:03<00:57, 60.11it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 272/3722 [00:03<00:58, 58.84it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 278/3722 [00:03<00:59, 57.68it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 284/3722 [00:03<01:00, 56.76it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 290/3722 [00:03<01:01, 56.12it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 296/3722 [00:03<01:01, 55.70it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 302/3722 [00:04<01:01, 55.39it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 308/3722 [00:04<01:01, 55.67it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 314/3722 [00:04<01:00, 56.77it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 321/3722 [00:04<00:56, 60.11it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 330/3722 [00:04<00:49, 68.12it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 338/3722 [00:04<00:47, 71.03it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 346/3722 [00:04<00:46, 72.72it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 354/3722 [00:04<00:45, 73.43it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 363/3722 [00:04<00:44, 76.33it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 371/3722 [00:05<00:46, 72.15it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 379/3722 [00:05<00:51, 64.63it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 386/3722 [00:05<00:54, 61.74it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 393/3722 [00:05<00:55, 59.78it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 400/3722 [00:05<00:57, 58.09it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 406/3722 [00:05<00:58, 56.70it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 412/3722 [00:05<00:59, 56.04it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 418/3722 [00:05<00:59, 55.55it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 424/3722 [00:06<01:00, 54.92it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 430/3722 [00:06<01:00, 54.81it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 436/3722 [00:06<00:59, 55.27it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 442/3722 [00:06<00:59, 55.44it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 448/3722 [00:06<00:59, 55.30it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 454/3722 [00:06<00:59, 55.05it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 460/3722 [00:06<00:59, 54.37it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 466/3722 [00:06<01:00, 53.80it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 472/3722 [00:06<01:01, 53.08it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 478/3722 [00:07<01:00, 53.70it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 484/3722 [00:07<00:59, 54.44it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 490/3722 [00:07<00:59, 54.55it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 496/3722 [00:07<00:59, 53.90it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 502/3722 [00:07<00:59, 54.35it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 508/3722 [00:07<00:59, 54.41it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 514/3722 [00:07<00:58, 54.63it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 520/3722 [00:07<00:58, 54.79it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 526/3722 [00:08<02:15, 23.60it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 531/3722 [00:08<03:05, 17.21it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 540/3722 [00:09<02:15, 23.56it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 544/3722 [00:09<02:14, 23.54it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 550/3722 [00:09<01:56, 27.15it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 580/3722 [00:09<00:44, 71.17it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 591/3722 [00:09<00:47, 66.18it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 601/3722 [00:09<00:49, 63.14it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 610/3722 [00:10<00:50, 61.76it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 618/3722 [00:10<00:51, 60.54it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 625/3722 [00:10<00:51, 60.00it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 632/3722 [00:10<00:50, 60.59it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 639/3722 [00:10<00:50, 60.93it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 646/3722 [00:10<00:51, 60.31it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 653/3722 [00:10<00:53, 57.01it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 660/3722 [00:10<00:51, 59.50it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 667/3722 [00:10<00:51, 59.89it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 674/3722 [00:11<00:54, 55.66it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 682/3722 [00:11<00:51, 59.36it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 689/3722 [00:11<00:52, 58.21it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 695/3722 [00:11<00:51, 58.41it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 701/3722 [00:11<00:53, 56.76it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 708/3722 [00:11<00:50, 59.58it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 715/3722 [00:11<00:50, 59.46it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 722/3722 [00:11<00:49, 60.13it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 729/3722 [00:12<00:48, 61.10it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 736/3722 [00:12<00:48, 61.27it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 743/3722 [00:12<00:47, 62.23it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 750/3722 [00:12<00:48, 61.79it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 757/3722 [00:12<00:47, 62.28it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 764/3722 [00:12<00:47, 62.69it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 771/3722 [00:12<00:46, 63.03it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 778/3722 [00:12<00:46, 62.80it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 785/3722 [00:12<00:46, 63.24it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 793/3722 [00:13<00:44, 65.48it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 800/3722 [00:13<00:45, 64.25it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                            | 807/3722 [00:13<00:45, 64.46it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 814/3722 [00:13<00:44, 65.78it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                            | 821/3722 [00:13<00:44, 65.13it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 828/3722 [00:13<00:45, 64.01it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 835/3722 [00:13<00:44, 64.79it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 842/3722 [00:13<00:48, 59.69it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 849/3722 [00:13<00:46, 61.63it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 856/3722 [00:14<00:45, 63.01it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 863/3722 [00:14<00:44, 64.42it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 870/3722 [00:14<00:43, 64.96it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 877/3722 [00:14<00:43, 65.27it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 884/3722 [00:14<00:43, 65.15it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                          | 891/3722 [00:14<00:44, 64.22it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 898/3722 [00:14<00:46, 61.28it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 907/3722 [00:14<00:42, 65.67it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 917/3722 [00:14<00:38, 72.66it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 927/3722 [00:15<00:36, 77.40it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 937/3722 [00:15<00:33, 83.27it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 946/3722 [00:15<00:33, 82.62it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 955/3722 [00:15<00:33, 83.83it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                         | 965/3722 [00:15<00:31, 88.15it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                        | 974/3722 [00:15<00:31, 88.39it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 983/3722 [00:15<00:30, 88.39it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 992/3722 [00:15<00:31, 86.59it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 1002/3722 [00:15<00:31, 86.85it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 1012/3722 [00:15<00:30, 88.75it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                       | 1021/3722 [00:16<00:31, 86.06it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                       | 1030/3722 [00:16<00:31, 86.35it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 1040/3722 [00:16<00:31, 85.29it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 1051/3722 [00:16<00:29, 91.48it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 1061/3722 [00:16<00:30, 88.30it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 1071/3722 [00:16<00:30, 85.69it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1082/3722 [00:16<00:28, 91.44it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1092/3722 [00:16<00:29, 89.23it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1101/3722 [00:17<00:29, 88.83it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1110/3722 [00:17<00:29, 88.94it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1120/3722 [00:17<00:29, 89.33it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1130/3722 [00:17<00:28, 91.80it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1140/3722 [00:17<00:28, 90.42it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1150/3722 [00:17<00:29, 87.63it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1159/3722 [00:17<00:29, 87.18it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1169/3722 [00:17<00:29, 87.16it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1178/3722 [00:17<00:29, 87.11it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1188/3722 [00:18<00:30, 83.50it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1198/3722 [00:18<00:29, 85.77it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1207/3722 [00:18<00:29, 85.37it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1216/3722 [00:18<00:29, 85.08it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1225/3722 [00:18<00:29, 84.50it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1235/3722 [00:18<00:29, 85.22it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1244/3722 [00:18<00:28, 86.16it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1254/3722 [00:18<00:27, 89.24it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1263/3722 [00:18<00:28, 86.05it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1273/3722 [00:18<00:28, 86.00it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1283/3722 [00:19<00:28, 86.88it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1293/3722 [00:19<00:26, 90.18it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1303/3722 [00:19<00:27, 89.39it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1312/3722 [00:19<00:27, 88.71it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 1321/3722 [00:19<00:29, 82.23it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 1330/3722 [00:19<00:29, 82.33it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1339/3722 [00:19<00:29, 80.24it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1348/3722 [00:19<00:30, 78.76it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1358/3722 [00:19<00:28, 83.44it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1367/3722 [00:20<00:28, 81.32it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1376/3722 [00:20<00:28, 82.38it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1385/3722 [00:20<00:27, 83.51it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1394/3722 [00:20<00:27, 83.30it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1404/3722 [00:20<00:27, 84.18it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1414/3722 [00:20<00:26, 87.24it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1423/3722 [00:20<00:26, 87.48it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1432/3722 [00:20<00:26, 87.99it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 1441/3722 [00:20<00:26, 87.35it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1450/3722 [00:21<00:27, 83.10it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1459/3722 [00:21<00:29, 77.74it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 1468/3722 [00:21<00:28, 79.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1477/3722 [00:21<00:29, 75.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                             | 1486/3722 [00:21<00:28, 78.49it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 1494/3722 [00:21<00:28, 77.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1502/3722 [00:21<00:28, 76.78it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1510/3722 [00:21<00:29, 76.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1518/3722 [00:21<00:29, 75.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1526/3722 [00:22<00:29, 75.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1534/3722 [00:22<00:29, 73.04it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1543/3722 [00:22<00:28, 76.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1551/3722 [00:22<00:28, 76.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                            | 1559/3722 [00:22<00:29, 73.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1567/3722 [00:22<00:29, 73.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 1576/3722 [00:22<00:28, 74.18it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 1584/3722 [00:22<00:28, 74.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                           | 1593/3722 [00:22<00:27, 78.18it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 1601/3722 [00:23<00:27, 77.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 1609/3722 [00:23<00:28, 74.16it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 1618/3722 [00:23<00:26, 78.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 1626/3722 [00:23<00:27, 77.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 1634/3722 [00:23<00:27, 75.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1642/3722 [00:23<00:28, 73.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 1650/3722 [00:23<00:30, 68.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1657/3722 [00:23<00:30, 68.22it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 1664/3722 [00:23<00:30, 68.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 1671/3722 [00:24<00:30, 67.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 1678/3722 [00:24<00:30, 66.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 1685/3722 [00:24<00:31, 65.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1694/3722 [00:24<00:29, 69.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 1702/3722 [00:24<00:28, 70.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 1711/3722 [00:24<00:26, 75.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 1720/3722 [00:24<00:25, 78.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 1730/3722 [00:24<00:23, 83.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 1740/3722 [00:24<00:23, 85.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 1749/3722 [00:25<00:22, 86.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 1758/3722 [00:25<00:22, 86.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1767/3722 [00:25<00:23, 84.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 1776/3722 [00:25<00:22, 85.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 1786/3722 [00:25<00:21, 89.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 1795/3722 [00:25<00:22, 86.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1804/3722 [00:25<00:21, 87.22it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 1815/3722 [00:25<00:21, 90.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 1825/3722 [00:25<00:21, 90.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1835/3722 [00:26<00:20, 90.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1845/3722 [00:26<00:20, 90.27it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 1855/3722 [00:26<00:21, 88.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1866/3722 [00:26<00:20, 91.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1876/3722 [00:26<00:21, 87.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 1885/3722 [00:26<00:20, 87.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 1895/3722 [00:26<00:20, 89.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 1904/3722 [00:26<00:21, 82.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 1913/3722 [00:26<00:23, 76.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 1921/3722 [00:27<00:25, 70.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 1929/3722 [00:27<00:25, 69.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 1937/3722 [00:27<00:25, 69.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 1945/3722 [00:27<00:25, 68.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 1952/3722 [00:27<00:25, 69.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 1959/3722 [00:27<00:26, 66.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1968/3722 [00:27<00:24, 72.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1978/3722 [00:27<00:22, 78.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 1987/3722 [00:28<00:22, 76.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1998/3722 [00:28<00:21, 81.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 2007/3722 [00:28<00:20, 82.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 2017/3722 [00:28<00:20, 84.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 2027/3722 [00:28<00:20, 84.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 2038/3722 [00:28<00:19, 85.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 2048/3722 [00:28<00:19, 87.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 2057/3722 [00:28<00:19, 83.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 2067/3722 [00:28<00:19, 84.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 2076/3722 [00:29<00:19, 85.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 2085/3722 [00:29<00:19, 85.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 2095/3722 [00:29<00:18, 87.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 2104/3722 [00:29<00:18, 87.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 2113/3722 [00:29<00:18, 86.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2122/3722 [00:29<00:18, 85.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 2131/3722 [00:29<00:19, 83.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2140/3722 [00:29<00:18, 84.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 2149/3722 [00:29<00:18, 85.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 2159/3722 [00:30<00:18, 86.56it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2168/3722 [00:30<00:18, 84.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2177/3722 [00:30<00:19, 79.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2186/3722 [00:30<00:21, 72.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 2194/3722 [00:30<00:20, 74.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 2202/3722 [00:30<00:20, 73.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 2210/3722 [00:30<00:20, 72.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2218/3722 [00:30<00:20, 71.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 2226/3722 [00:30<00:20, 72.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2235/3722 [00:31<00:19, 76.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 2244/3722 [00:31<00:19, 76.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2255/3722 [00:31<00:18, 79.59it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2266/3722 [00:31<00:17, 84.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2275/3722 [00:31<00:17, 84.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2284/3722 [00:31<00:17, 82.12it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2293/3722 [00:31<00:17, 82.96it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2302/3722 [00:31<00:16, 84.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2312/3722 [00:31<00:16, 83.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2322/3722 [00:32<00:16, 87.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2331/3722 [00:32<00:15, 87.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2341/3722 [00:32<00:15, 88.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2350/3722 [00:32<00:15, 88.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 2359/3722 [00:32<00:16, 83.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 2370/3722 [00:32<00:15, 88.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 2379/3722 [00:32<00:15, 88.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 2388/3722 [00:32<00:15, 84.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 2398/3722 [00:32<00:15, 87.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 2407/3722 [00:33<00:14, 87.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 2416/3722 [00:33<00:14, 87.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2425/3722 [00:33<00:14, 87.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 2434/3722 [00:33<00:14, 87.39it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 2443/3722 [00:33<00:15, 84.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 2453/3722 [00:33<00:14, 89.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 2462/3722 [00:33<00:14, 86.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 2471/3722 [00:33<00:14, 86.47it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 2481/3722 [00:33<00:14, 87.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 2491/3722 [00:33<00:13, 90.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2501/3722 [00:34<00:13, 88.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2510/3722 [00:34<00:13, 88.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 2519/3722 [00:34<00:14, 84.73it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 2529/3722 [00:34<00:13, 87.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2538/3722 [00:34<00:14, 84.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2548/3722 [00:34<00:13, 84.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2558/3722 [00:34<00:13, 87.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2567/3722 [00:34<00:13, 87.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2576/3722 [00:34<00:13, 84.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2585/3722 [00:35<00:13, 84.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2595/3722 [00:35<00:12, 87.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2604/3722 [00:35<00:12, 86.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2613/3722 [00:35<00:12, 87.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2622/3722 [00:35<00:12, 86.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2631/3722 [00:35<00:13, 82.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2640/3722 [00:35<00:13, 79.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2648/3722 [00:35<00:14, 73.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2656/3722 [00:35<00:14, 74.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2664/3722 [00:36<00:14, 72.45it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2672/3722 [00:36<00:14, 72.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2681/3722 [00:36<00:13, 77.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2689/3722 [00:36<00:14, 73.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 2697/3722 [00:36<00:14, 72.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2705/3722 [00:36<00:14, 70.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2713/3722 [00:36<00:14, 71.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2722/3722 [00:36<00:13, 75.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2730/3722 [00:37<00:13, 71.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2738/3722 [00:37<00:14, 67.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 2747/3722 [00:37<00:13, 71.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 2755/3722 [00:37<00:13, 73.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2763/3722 [00:37<00:13, 71.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 2772/3722 [00:37<00:12, 73.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2781/3722 [00:37<00:12, 76.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2789/3722 [00:37<00:12, 74.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2798/3722 [00:37<00:11, 77.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 2807/3722 [00:38<00:11, 78.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2818/3722 [00:38<00:10, 84.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2827/3722 [00:38<00:10, 86.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2836/3722 [00:38<00:10, 84.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2845/3722 [00:38<00:10, 85.07it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 2855/3722 [00:38<00:10, 85.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2865/3722 [00:38<00:09, 89.31it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2874/3722 [00:38<00:09, 85.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2883/3722 [00:38<00:09, 85.84it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 2893/3722 [00:39<00:09, 86.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2903/3722 [00:39<00:09, 88.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2913/3722 [00:39<00:09, 86.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2923/3722 [00:39<00:08, 89.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2932/3722 [00:39<00:09, 85.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2941/3722 [00:39<00:09, 83.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2950/3722 [00:39<00:09, 84.89it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2959/3722 [00:39<00:08, 85.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 2968/3722 [00:39<00:08, 85.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2978/3722 [00:39<00:08, 89.46it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2987/3722 [00:40<00:08, 83.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 2998/3722 [00:40<00:08, 90.14it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3008/3722 [00:40<00:08, 86.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3017/3722 [00:40<00:08, 87.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3026/3722 [00:40<00:07, 87.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3037/3722 [00:40<00:07, 88.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3047/3722 [00:40<00:07, 91.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3057/3722 [00:40<00:07, 90.68it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3067/3722 [00:41<00:07, 88.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3076/3722 [00:41<00:07, 88.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3085/3722 [00:41<00:07, 87.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3096/3722 [00:41<00:06, 91.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3106/3722 [00:41<00:06, 90.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3116/3722 [00:41<00:06, 88.12it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3126/3722 [00:41<00:06, 87.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3135/3722 [00:41<00:06, 87.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3144/3722 [00:41<00:06, 87.62it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3153/3722 [00:41<00:06, 87.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3163/3722 [00:42<00:06, 89.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3172/3722 [00:42<00:06, 88.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3182/3722 [00:42<00:06, 88.84it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3193/3722 [00:42<00:05, 90.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 3203/3722 [00:42<00:05, 92.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3213/3722 [00:42<00:05, 92.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3223/3722 [00:42<00:05, 91.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 3233/3722 [00:42<00:05, 88.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3243/3722 [00:42<00:05, 89.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 3253/3722 [00:43<00:05, 91.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 3263/3722 [00:43<00:05, 91.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 3273/3722 [00:43<00:04, 90.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 3283/3722 [00:43<00:05, 86.27it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 3292/3722 [00:43<00:05, 85.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 3301/3722 [00:43<00:05, 78.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 3309/3722 [00:43<00:05, 77.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 3318/3722 [00:43<00:05, 80.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 3328/3722 [00:43<00:04, 82.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 3338/3722 [00:44<00:04, 87.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 3347/3722 [00:44<00:04, 87.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 3357/3722 [00:44<00:04, 88.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 3366/3722 [00:44<00:04, 86.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 3376/3722 [00:44<00:03, 90.20it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 3386/3722 [00:44<00:03, 90.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 3396/3722 [00:44<00:03, 87.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3405/3722 [00:44<00:03, 88.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3416/3722 [00:44<00:03, 88.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 3426/3722 [00:45<00:03, 88.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 3435/3722 [00:45<00:03, 88.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3444/3722 [00:45<00:03, 87.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3453/3722 [00:45<00:03, 87.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 3463/3722 [00:45<00:02, 87.95it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3472/3722 [00:45<00:02, 88.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3482/3722 [00:45<00:02, 87.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3493/3722 [00:45<00:02, 89.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3503/3722 [00:45<00:02, 92.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3513/3722 [00:46<00:02, 92.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3523/3722 [00:46<00:02, 91.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3533/3722 [00:46<00:02, 90.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3543/3722 [00:46<00:01, 91.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3553/3722 [00:46<00:01, 89.88it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3562/3722 [00:46<00:01, 87.27it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3571/3722 [00:46<00:01, 87.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3581/3722 [00:46<00:01, 90.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3591/3722 [00:46<00:01, 91.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3601/3722 [00:47<00:01, 89.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3611/3722 [00:47<00:01, 86.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3622/3722 [00:47<00:01, 89.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3632/3722 [00:47<00:01, 87.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3641/3722 [00:47<00:00, 87.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3650/3722 [00:47<00:00, 88.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3659/3722 [00:47<00:00, 88.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3669/3722 [00:47<00:00, 88.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3678/3722 [00:47<00:00, 88.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3687/3722 [00:48<00:00, 88.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3696/3722 [00:48<00:00, 88.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3705/3722 [00:48<00:00, 87.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3714/3722 [00:48<00:00, 88.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3722/3722 [00:48<00:00, 76.88it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.2541
Epoch 1 Step 51 Train Loss: 0.2370
Epoch 1 Step 101 Train Loss: 0.3253
Epoch 1 Step 151 Train Loss: 0.3042
Epoch 1: Train Overall MSE: 331.8027 Validation Overall MSE: 343.1342. 
Train Top 20 DE MSE: 571.1351 Validation Top 20 DE MSE: 697.3704. 
Epoch 2 Step 1 Train Loss: 0.2725
Epoch 2 Step 51 Train Loss: 0.2531
Epoch 2 Step 101 Train Loss: 0.2368
Epoch 2 Step 151 Train Loss: 0.2550
Epoch 2: Train Overall MSE: 2032.3947 Validation Overall MSE: 1519.4980. 
Train Top 20 DE MSE: 7987.5825 Validation Top 20 DE MSE: 2645.1567. 
Epoch 3 Step 1 Train Loss: 0.3043
Epoch 3 Step 51 Train Loss: 0.2881
Epoch 3 Step 101 Train Loss: 0.2453
Epoch 3 Step 151 Train Loss: 0.2416
Epoch 3: Train Overall MSE: 865.7930 Validation Overall MSE: 577.4330. 
Train Top 20 DE MSE: 2281.9070 Validation Top 20 DE MSE: 1206.8290. 
Epoch 4 Step 1 Train Loss: 0.2397
Epoch 4 Step 51 Train Loss: 0.2954
Epoch 4 Step 101 Train Loss: 0.2118
Epoch 4 Step 151 Train Loss: 0.2393
Epoch 4: Train Overall MSE: 67.3561 Validation Overall MSE: 58.5644. 
Train Top 20 DE MSE: 56.1500 Validation Top 20 DE MSE: 103.7697. 
Epoch 5 Step 1 Train Loss: 0.2507
Epoch 5 Step 51 Train Loss: 0.2305
Epoch 5 Step 101 Train Loss: 0.2260
Epoch 5 Step 151 Train Loss: 0.3472
Epoch 5: Train Overall MSE: 319.2112 Validation Overall MSE: 257.4313. 
Train Top 20 DE MSE: 499.1883 Validation Top 20 DE MSE: 533.6545. 
Epoch 6 Step 1 Train Loss: 0.2474
Epoch 6 Step 51 Train Loss: 0.2685
Epoch 6 Step 101 Train Loss: 0.3073
Epoch 6 Step 151 Train Loss: 0.4137
Epoch 6: Train Overall MSE: 19.4020 Validation Overall MSE: 6.6341. 
Train Top 20 DE MSE: 15.3551 Validation Top 20 DE MSE: 15.0640. 
Epoch 7 Step 1 Train Loss: 0.2635
Epoch 7 Step 51 Train Loss: 0.2527
Epoch 7 Step 101 Train Loss: 0.2586
Epoch 7 Step 151 Train Loss: 0.2661
Epoch 7: Train Overall MSE: 6.1235 Validation Overall MSE: 0.8519. 
Train Top 20 DE MSE: 2.8450 Validation Top 20 DE MSE: 2.3287. 
Epoch 8 Step 1 Train Loss: 0.3189
Epoch 8 Step 51 Train Loss: 0.2734
Epoch 8 Step 101 Train Loss: 0.2499
Epoch 8 Step 151 Train Loss: 0.2147
Epoch 8: Train Overall MSE: 197.3266 Validation Overall MSE: 24.6079. 
Train Top 20 DE MSE: 78.4391 Validation Top 20 DE MSE: 53.1292. 
Epoch 9 Step 1 Train Loss: 0.2844
Epoch 9 Step 51 Train Loss: 0.3067
Epoch 9 Step 101 Train Loss: 0.2250
Epoch 9 Step 151 Train Loss: 0.2998
Epoch 9: Train Overall MSE: 8.7425 Validation Overall MSE: 0.8275. 
Train Top 20 DE MSE: 2.8089 Validation Top 20 DE MSE: 2.3140. 
Epoch 10 Step 1 Train Loss: 0.2933
Epoch 10 Step 51 Train Loss: 0.3846
Epoch 10 Step 101 Train Loss: 0.4225
Epoch 10 Step 151 Train Loss: 0.2393
Epoch 10: Train Overall MSE: 1134.7284 Validation Overall MSE: 152.5145. 
Train Top 20 DE MSE: 510.9190 Validation Top 20 DE MSE: 311.4045. 
Epoch 11 Step 1 Train Loss: 0.2965
Epoch 11 Step 51 Train Loss: 0.2655
Epoch 11 Step 101 Train Loss: 0.2605
Epoch 11 Step 151 Train Loss: 0.2945
Epoch 11: Train Overall MSE: 39.8321 Validation Overall MSE: 4.4659. 
Train Top 20 DE MSE: 12.7217 Validation Top 20 DE MSE: 10.9176. 
Epoch 12 Step 1 Train Loss: 0.2254
Epoch 12 Step 51 Train Loss: 0.2281
Epoch 12 Step 101 Train Loss: 0.2703
Epoch 12 Step 151 Train Loss: 0.2369
Epoch 12: Train Overall MSE: 14.5259 Validation Overall MSE: 1.3296. 
Train Top 20 DE MSE: 4.5444 Validation Top 20 DE MSE: 3.5556. 
Epoch 13 Step 1 Train Loss: 0.3027
Epoch 13 Step 51 Train Loss: 0.2428
Epoch 13 Step 101 Train Loss: 0.2209
Epoch 13 Step 151 Train Loss: 0.2584
Epoch 13: Train Overall MSE: 20.9210 Validation Overall MSE: 1.9550. 
Train Top 20 DE MSE: 6.3765 Validation Top 20 DE MSE: 5.0047. 
Epoch 14 Step 1 Train Loss: 0.2214
Epoch 14 Step 51 Train Loss: 0.3675
Epoch 14 Step 101 Train Loss: 0.2607
Epoch 14 Step 151 Train Loss: 0.2496
Epoch 14: Train Overall MSE: 1136.2401 Validation Overall MSE: 153.6113. 
Train Top 20 DE MSE: 545.6718 Validation Top 20 DE MSE: 306.1200. 
Epoch 15 Step 1 Train Loss: 0.3222
Epoch 15 Step 51 Train Loss: 0.2389
Epoch 15 Step 101 Train Loss: 0.2982
Epoch 15 Step 151 Train Loss: 0.2146
Epoch 15: Train Overall MSE: 6.7962 Validation Overall MSE: 0.4719. 
Train Top 20 DE MSE: 2.1426 Validation Top 20 DE MSE: 1.4024. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 8.1831
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: 0.29184255
test_combo_seen1_pearson: 0.7969616303696415
test_combo_seen1_mse_de: 0.9901181
test_combo_seen1_pearson_de: 0.6951109727880431
test_combo_seen2_mse: 0.29084793
test_combo_seen2_pearson: 0.7324784495198924
test_combo_seen2_mse_de: 0.78563744
test_combo_seen2_pearson_de: 0.8264658005520642
test_unseen_single_mse: 6.512702
test_unseen_single_pearson: 0.19190520918086973
test_unseen_single_mse_de: 19.074823
test_unseen_single_pearson_de: 0.1693655345621291
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: 0.4090811050170166
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.2
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.625
test_combo_seen1_mse_top20_de_non_dropout: 0.99011815
test_combo_seen2_pearson_delta: 0.1940398632797643
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.15
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.6
test_combo_seen2_mse_top20_de_non_dropout: 0.7856375
test_unseen_single_pearson_delta: 0.015975313205518232
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.55
test_unseen_single_frac_sigma_below_1_non_dropout: 0.2
test_unseen_single_mse_top20_de_non_dropout: 20.028511
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.005 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb: | 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ
wandb:                                                   val_de_mse ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñà
wandb:                                                      val_mse ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñÇ‚ñá‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÅ‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.2
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.625
wandb:                                         test_combo_seen1_mse 0.29184
wandb:                                      test_combo_seen1_mse_de 0.99012
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.99012
wandb:                                     test_combo_seen1_pearson 0.79696
wandb:                                  test_combo_seen1_pearson_de 0.69511
wandb:                               test_combo_seen1_pearson_delta 0.40908
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.15
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.6
wandb:                                         test_combo_seen2_mse 0.29085
wandb:                                      test_combo_seen2_mse_de 0.78564
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.78564
wandb:                                     test_combo_seen2_pearson 0.73248
wandb:                                  test_combo_seen2_pearson_de 0.82647
wandb:                               test_combo_seen2_pearson_delta 0.19404
wandb:                                                  test_de_mse 8.1831
wandb:                                              test_de_pearson 0.51108
wandb:               test_frac_opposite_direction_top20_non_dropout 0.33
wandb:                          test_frac_sigma_below_1_non_dropout 0.45
wandb:                                                     test_mse 2.77999
wandb:                                test_mse_top20_de_non_dropout 8.56458
wandb:                                                 test_pearson 0.54204
wandb:                                           test_pearson_delta 0.20883
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.55
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.2
wandb:                                       test_unseen_single_mse 6.5127
wandb:                                    test_unseen_single_mse_de 19.07482
wandb:                  test_unseen_single_mse_top20_de_non_dropout 20.02851
wandb:                                   test_unseen_single_pearson 0.19191
wandb:                                test_unseen_single_pearson_de 0.16937
wandb:                             test_unseen_single_pearson_delta 0.01598
wandb:                                                 train_de_mse 2.1426
wandb:                                             train_de_pearson 0.49796
wandb:                                                    train_mse 6.79622
wandb:                                                train_pearson 0.72505
wandb:                                                training_loss 0.35368
wandb:                                                   val_de_mse 1.4024
wandb:                                               val_de_pearson 0.4036
wandb:                                                      val_mse 0.47195
wandb:                                                  val_pearson 0.64204
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406677_2_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/vcab61jp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_171753-vcab61jp/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:2
combo_seen2:1
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_172447-puwmddyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406677_2_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/puwmddyg
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2563
Epoch 1 Step 51 Train Loss: 0.4393
Epoch 1 Step 101 Train Loss: 0.2443
Epoch 1 Step 151 Train Loss: 0.2396
Epoch 1: Train Overall MSE: 7312.8809 Validation Overall MSE: 5254.8389. 
Train Top 20 DE MSE: 8443.0391 Validation Top 20 DE MSE: 26952.7812. 
Epoch 2 Step 1 Train Loss: 0.2073
Epoch 2 Step 51 Train Loss: 0.6586
Epoch 2 Step 101 Train Loss: 0.2172
Epoch 2 Step 151 Train Loss: 0.3070
Epoch 2: Train Overall MSE: 1676.0333 Validation Overall MSE: 777.8342. 
Train Top 20 DE MSE: 2557.2542 Validation Top 20 DE MSE: 4424.2769. 
Epoch 3 Step 1 Train Loss: 0.2603
Epoch 3 Step 51 Train Loss: 0.2392
Epoch 3 Step 101 Train Loss: 0.2411
Epoch 3 Step 151 Train Loss: 0.2230
Epoch 3: Train Overall MSE: 88.9497 Validation Overall MSE: 68.8579. 
Train Top 20 DE MSE: 251.2212 Validation Top 20 DE MSE: 311.0061. 
Epoch 4 Step 1 Train Loss: 0.2208
Epoch 4 Step 51 Train Loss: 0.3395
Epoch 4 Step 101 Train Loss: 0.2205
Epoch 4 Step 151 Train Loss: 0.2391
Epoch 4: Train Overall MSE: 62.3349 Validation Overall MSE: 48.2252. 
Train Top 20 DE MSE: 238.9815 Validation Top 20 DE MSE: 280.0938. 
Epoch 5 Step 1 Train Loss: 0.2732
Epoch 5 Step 51 Train Loss: 0.3209
Epoch 5 Step 101 Train Loss: 0.2541
Epoch 5 Step 151 Train Loss: 0.2904
Epoch 5: Train Overall MSE: 19.0152 Validation Overall MSE: 12.5686. 
Train Top 20 DE MSE: 31.3363 Validation Top 20 DE MSE: 58.3243. 
Epoch 6 Step 1 Train Loss: 0.2348
Epoch 6 Step 51 Train Loss: 0.2531
Epoch 6 Step 101 Train Loss: 0.3329
Epoch 6 Step 151 Train Loss: 0.2273
Epoch 6: Train Overall MSE: 748.7583 Validation Overall MSE: 189.0056. 
Train Top 20 DE MSE: 707.9042 Validation Top 20 DE MSE: 883.3467. 
Epoch 7 Step 1 Train Loss: 0.2914
Epoch 7 Step 51 Train Loss: 0.2495
Epoch 7 Step 101 Train Loss: 0.3151
Epoch 7 Step 151 Train Loss: 0.2351
Epoch 7: Train Overall MSE: 5.1661 Validation Overall MSE: 1.8218. 
Train Top 20 DE MSE: 4.3757 Validation Top 20 DE MSE: 10.4208. 
Epoch 8 Step 1 Train Loss: 0.2406
Epoch 8 Step 51 Train Loss: 0.3452
Epoch 8 Step 101 Train Loss: 0.2449
Epoch 8 Step 151 Train Loss: 0.2323
Epoch 8: Train Overall MSE: 70.3540 Validation Overall MSE: 19.7448. 
Train Top 20 DE MSE: 52.2438 Validation Top 20 DE MSE: 96.7317. 
Epoch 9 Step 1 Train Loss: 0.2619
Epoch 9 Step 51 Train Loss: 0.2947
Epoch 9 Step 101 Train Loss: 0.2955
Epoch 9 Step 151 Train Loss: 0.3353
Epoch 9: Train Overall MSE: 1052.2416 Validation Overall MSE: 236.6384. 
Train Top 20 DE MSE: 841.5193 Validation Top 20 DE MSE: 1157.8457. 
Epoch 10 Step 1 Train Loss: 0.2666
Epoch 10 Step 51 Train Loss: 0.2278
Epoch 10 Step 101 Train Loss: 0.2408
Epoch 10 Step 151 Train Loss: 0.2317
Epoch 10: Train Overall MSE: 261.8602 Validation Overall MSE: 62.7727. 
Train Top 20 DE MSE: 208.3826 Validation Top 20 DE MSE: 309.3548. 
Epoch 11 Step 1 Train Loss: 0.2394
Epoch 11 Step 51 Train Loss: 0.2393
Epoch 11 Step 101 Train Loss: 0.2219
Epoch 11 Step 151 Train Loss: 0.2949
Epoch 11: Train Overall MSE: 5.2307 Validation Overall MSE: 1.3306. 
Train Top 20 DE MSE: 3.6351 Validation Top 20 DE MSE: 7.8395. 
Epoch 12 Step 1 Train Loss: 0.2775
Epoch 12 Step 51 Train Loss: 0.2979
Epoch 12 Step 101 Train Loss: 0.3010
Epoch 12 Step 151 Train Loss: 0.2631
Epoch 12: Train Overall MSE: 450.3768 Validation Overall MSE: 106.3098. 
Train Top 20 DE MSE: 354.4615 Validation Top 20 DE MSE: 517.8603. 
Epoch 13 Step 1 Train Loss: 0.2912
Epoch 13 Step 51 Train Loss: 0.3483
Epoch 13 Step 101 Train Loss: 0.2598
Epoch 13 Step 151 Train Loss: 0.2537
Epoch 13: Train Overall MSE: 11.1997 Validation Overall MSE: 2.7618. 
Train Top 20 DE MSE: 8.1739 Validation Top 20 DE MSE: 15.1320. 
Epoch 14 Step 1 Train Loss: 0.2657
Epoch 14 Step 51 Train Loss: 0.2958
Epoch 14 Step 101 Train Loss: 0.2830
Epoch 14 Step 151 Train Loss: 0.3434
Epoch 14: Train Overall MSE: 61.0084 Validation Overall MSE: 14.8312. 
Train Top 20 DE MSE: 46.3717 Validation Top 20 DE MSE: 74.7889. 
Epoch 15 Step 1 Train Loss: 0.3029
Epoch 15 Step 51 Train Loss: 0.3463
Epoch 15 Step 101 Train Loss: 0.2194
Epoch 15 Step 151 Train Loss: 0.2245
Epoch 15: Train Overall MSE: 176.1349 Validation Overall MSE: 42.5752. 
Train Top 20 DE MSE: 137.8157 Validation Top 20 DE MSE: 208.0760. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 19.3690
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: 0.66885155
test_combo_seen1_pearson: 0.7167263354253226
test_combo_seen1_mse_de: 5.4448805
test_combo_seen1_pearson_de: 0.4298361513769054
test_combo_seen2_mse: 0.08993824
test_combo_seen2_pearson: 0.8996926347738784
test_combo_seen2_mse_de: 1.673569
test_combo_seen2_pearson_de: 0.6407597476752986
test_unseen_single_mse: 7.7486916
test_unseen_single_pearson: 0.1924476545321385
test_unseen_single_mse_de: 42.14083
test_unseen_single_pearson_de: 0.14086721974820304
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: 0.013254036829486338
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.525
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.4
test_combo_seen1_mse_top20_de_non_dropout: 5.44488
test_combo_seen2_pearson_delta: -0.37797871299265473
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.9
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.09999999999999998
test_combo_seen2_mse_top20_de_non_dropout: 1.673569
test_unseen_single_pearson_delta: -0.07125744569163901
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.7
test_unseen_single_frac_sigma_below_1_non_dropout: 0.09999999999999998
test_unseen_single_mse_top20_de_non_dropout: 39.652885
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.020 MB uploadedwandb: | 0.005 MB of 0.020 MB uploadedwandb: / 0.005 MB of 0.020 MB uploadedwandb: - 0.020 MB of 0.020 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÇ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÖ‚ñÇ‚ñÇ
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÜ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.525
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.4
wandb:                                         test_combo_seen1_mse 0.66885
wandb:                                      test_combo_seen1_mse_de 5.44488
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 5.44488
wandb:                                     test_combo_seen1_pearson 0.71673
wandb:                                  test_combo_seen1_pearson_de 0.42984
wandb:                               test_combo_seen1_pearson_delta 0.01325
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.9
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.1
wandb:                                         test_combo_seen2_mse 0.08994
wandb:                                      test_combo_seen2_mse_de 1.67357
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 1.67357
wandb:                                     test_combo_seen2_pearson 0.89969
wandb:                                  test_combo_seen2_pearson_de 0.64076
wandb:                               test_combo_seen2_pearson_delta -0.37798
wandb:                                                  test_de_mse 19.369
wandb:                                              test_de_pearson 0.35643
wandb:               test_frac_opposite_direction_top20_non_dropout 0.67
wandb:                          test_frac_sigma_below_1_non_dropout 0.22
wandb:                                                     test_mse 3.38501
wandb:                                test_mse_top20_de_non_dropout 18.37382
wandb:                                                 test_pearson 0.54361
wandb:                                           test_pearson_delta -0.0988
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.7
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.1
wandb:                                       test_unseen_single_mse 7.74869
wandb:                                    test_unseen_single_mse_de 42.14083
wandb:                  test_unseen_single_mse_top20_de_non_dropout 39.65289
wandb:                                   test_unseen_single_pearson 0.19245
wandb:                                test_unseen_single_pearson_de 0.14087
wandb:                             test_unseen_single_pearson_delta -0.07126
wandb:                                                 train_de_mse 137.81572
wandb:                                             train_de_pearson 0.49897
wandb:                                                    train_mse 176.1349
wandb:                                                train_pearson 0.69723
wandb:                                                training_loss 0.30128
wandb:                                                   val_de_mse 208.07602
wandb:                                               val_de_pearson -0.61489
wandb:                                                      val_mse 42.57517
wandb:                                                  val_pearson 0.04649
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406677_2_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/puwmddyg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_172447-puwmddyg/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:1
combo_seen1:2
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_173011-5ayqcsxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406677_2_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/5ayqcsxf
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3077
Epoch 1 Step 51 Train Loss: 0.2441
Epoch 1 Step 101 Train Loss: 0.2920
Epoch 1 Step 151 Train Loss: 0.2468
Epoch 1: Train Overall MSE: 16851.2480 Validation Overall MSE: 30108.0352. 
Train Top 20 DE MSE: 57264.7188 Validation Top 20 DE MSE: 39636.5469. 
Epoch 2 Step 1 Train Loss: 0.2805
Epoch 2 Step 51 Train Loss: 0.2689
Epoch 2 Step 101 Train Loss: 0.2383
Epoch 2 Step 151 Train Loss: 0.3225
Epoch 2: Train Overall MSE: 966.4391 Validation Overall MSE: 1770.9351. 
Train Top 20 DE MSE: 2799.8018 Validation Top 20 DE MSE: 3283.8091. 
Epoch 3 Step 1 Train Loss: 0.2631
Epoch 3 Step 51 Train Loss: 0.2745
Epoch 3 Step 101 Train Loss: 0.2533
Epoch 3 Step 151 Train Loss: 0.3480
Epoch 3: Train Overall MSE: 224.8177 Validation Overall MSE: 410.2308. 
Train Top 20 DE MSE: 740.5629 Validation Top 20 DE MSE: 939.4310. 
Epoch 4 Step 1 Train Loss: 0.3154
Epoch 4 Step 51 Train Loss: 0.2781
Epoch 4 Step 101 Train Loss: 0.2709
Epoch 4 Step 151 Train Loss: 0.3241
Epoch 4: Train Overall MSE: 711.1811 Validation Overall MSE: 1366.9471. 
Train Top 20 DE MSE: 2637.6780 Validation Top 20 DE MSE: 2755.4832. 
Epoch 5 Step 1 Train Loss: 0.2891
Epoch 5 Step 51 Train Loss: 0.2544
Epoch 5 Step 101 Train Loss: 0.2559
Epoch 5 Step 151 Train Loss: 0.2662
Epoch 5: Train Overall MSE: 2194.8586 Validation Overall MSE: 4216.0200. 
Train Top 20 DE MSE: 7713.3462 Validation Top 20 DE MSE: 9250.7520. 
Epoch 6 Step 1 Train Loss: 0.3116
Epoch 6 Step 51 Train Loss: 0.2761
Epoch 6 Step 101 Train Loss: 0.2322
Epoch 6 Step 151 Train Loss: 0.2690
Epoch 6: Train Overall MSE: 59842.8281 Validation Overall MSE: 117477.6094. 
Train Top 20 DE MSE: 227651.3125 Validation Top 20 DE MSE: 259436.9531. 
Epoch 7 Step 1 Train Loss: 0.3099
Epoch 7 Step 51 Train Loss: 0.2798
Epoch 7 Step 101 Train Loss: 0.2510
Epoch 7 Step 151 Train Loss: 0.2793
Epoch 7: Train Overall MSE: 77.3527 Validation Overall MSE: 148.4672. 
Train Top 20 DE MSE: 278.2505 Validation Top 20 DE MSE: 340.3984. 
Epoch 8 Step 1 Train Loss: 0.2632
Epoch 8 Step 51 Train Loss: 0.2369
Epoch 8 Step 101 Train Loss: 0.2355
Epoch 8 Step 151 Train Loss: 0.3365
Epoch 8: Train Overall MSE: 58758.1406 Validation Overall MSE: 115405.5000. 
Train Top 20 DE MSE: 235142.2969 Validation Top 20 DE MSE: 242195.6719. 
Epoch 9 Step 1 Train Loss: 0.2971
Epoch 9 Step 51 Train Loss: 0.2740
Epoch 9 Step 101 Train Loss: 0.2586
Epoch 9 Step 151 Train Loss: 0.2659
Epoch 9: Train Overall MSE: 90.8628 Validation Overall MSE: 176.6308. 
Train Top 20 DE MSE: 330.7498 Validation Top 20 DE MSE: 408.8286. 
Epoch 10 Step 1 Train Loss: 0.3379
Epoch 10 Step 51 Train Loss: 0.2486
Epoch 10 Step 101 Train Loss: 0.3183
Epoch 10 Step 151 Train Loss: 0.2546
Epoch 10: Train Overall MSE: 9460.5352 Validation Overall MSE: 18558.3184. 
Train Top 20 DE MSE: 36584.7031 Validation Top 20 DE MSE: 40832.3945. 
Epoch 11 Step 1 Train Loss: 0.2405
Epoch 11 Step 51 Train Loss: 0.2495
Epoch 11 Step 101 Train Loss: 0.2992
Epoch 11 Step 151 Train Loss: 0.2697
Epoch 11: Train Overall MSE: 39466.7773 Validation Overall MSE: 77516.7734. 
Train Top 20 DE MSE: 155943.7188 Validation Top 20 DE MSE: 166844.3750. 
Epoch 12 Step 1 Train Loss: 0.3083
Epoch 12 Step 51 Train Loss: 0.2956
Epoch 12 Step 101 Train Loss: 0.2826
Epoch 12 Step 151 Train Loss: 0.1990
Epoch 12: Train Overall MSE: 737.3284 Validation Overall MSE: 1440.0006. 
Train Top 20 DE MSE: 2761.8958 Validation Top 20 DE MSE: 3250.6582. 
Epoch 13 Step 1 Train Loss: 0.2258
Epoch 13 Step 51 Train Loss: 0.2558
Epoch 13 Step 101 Train Loss: 0.2608
Epoch 13 Step 151 Train Loss: 0.2564
Epoch 13: Train Overall MSE: 4414.3760 Validation Overall MSE: 8646.5371. 
Train Top 20 DE MSE: 17370.2383 Validation Top 20 DE MSE: 18643.8770. 
Epoch 14 Step 1 Train Loss: 0.2389
Epoch 14 Step 51 Train Loss: 0.2439
Epoch 14 Step 101 Train Loss: 0.2683
Epoch 14 Step 151 Train Loss: 0.2199
Epoch 14: Train Overall MSE: 1538.4093 Validation Overall MSE: 3007.4919. 
Train Top 20 DE MSE: 5864.9883 Validation Top 20 DE MSE: 6710.2031. 
Epoch 15 Step 1 Train Loss: 0.3093
Epoch 15 Step 51 Train Loss: 0.2644
Epoch 15 Step 101 Train Loss: 0.2795
Epoch 15 Step 151 Train Loss: 0.2531
Epoch 15: Train Overall MSE: 37.6248 Validation Overall MSE: 72.9836. 
Train Top 20 DE MSE: 141.9012 Validation Top 20 DE MSE: 167.9247. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 18.9029
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: 5.4649467
test_combo_seen0_pearson: 0.288081578095987
test_combo_seen0_mse_de: 9.8876
test_combo_seen0_pearson_de: -0.3648796554603378
test_combo_seen1_mse: 0.6340249
test_combo_seen1_pearson: 0.737378371527009
test_combo_seen1_mse_de: 7.9785676
test_combo_seen1_pearson_de: 0.17171012490208493
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 15.4456415
test_unseen_single_pearson: 0.20819031885446773
test_unseen_single_mse_de: 34.335
test_unseen_single_pearson_de: -0.3684541323993624
test_combo_seen0_pearson_delta: 0.04138731449594133
test_combo_seen0_frac_opposite_direction_top20_non_dropout: 0.75
test_combo_seen0_frac_sigma_below_1_non_dropout: 0.25
test_combo_seen0_mse_top20_de_non_dropout: 9.8876
test_combo_seen1_pearson_delta: 0.18165373895676837
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.5
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.475
test_combo_seen1_mse_top20_de_non_dropout: 7.978568
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: -0.010497581163972335
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.7
test_unseen_single_frac_sigma_below_1_non_dropout: 0.07500000000000001
test_unseen_single_mse_top20_de_non_dropout: 34.335
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.002 MB of 0.020 MB uploadedwandb: | 0.002 MB of 0.020 MB uploadedwandb: / 0.020 MB of 0.020 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen0_mse ‚ñÅ
wandb:                                      test_combo_seen0_mse_de ‚ñÅ
wandb:                    test_combo_seen0_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen0_pearson ‚ñÅ
wandb:                                  test_combo_seen0_pearson_de ‚ñÅ
wandb:                               test_combo_seen0_pearson_delta ‚ñÅ
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñà‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ
wandb:                                                   val_de_mse ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                      val_mse ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout 0.75
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout 0.25
wandb:                                         test_combo_seen0_mse 5.46495
wandb:                                      test_combo_seen0_mse_de 9.8876
wandb:                    test_combo_seen0_mse_top20_de_non_dropout 9.8876
wandb:                                     test_combo_seen0_pearson 0.28808
wandb:                                  test_combo_seen0_pearson_de -0.36488
wandb:                               test_combo_seen0_pearson_delta 0.04139
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.5
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.475
wandb:                                         test_combo_seen1_mse 0.63402
wandb:                                      test_combo_seen1_mse_de 7.97857
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 7.97857
wandb:                                     test_combo_seen1_pearson 0.73738
wandb:                                  test_combo_seen1_pearson_de 0.17171
wandb:                               test_combo_seen1_pearson_delta 0.18165
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 18.90295
wandb:                                              test_de_pearson -0.15167
wandb:               test_frac_opposite_direction_top20_non_dropout 0.63
wandb:                          test_frac_sigma_below_1_non_dropout 0.27
wandb:                                                     test_mse 7.52486
wandb:                                test_mse_top20_de_non_dropout 18.90295
wandb:                                                 test_pearson 0.43584
wandb:                                           test_pearson_delta 0.07674
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.7
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.075
wandb:                                       test_unseen_single_mse 15.44564
wandb:                                    test_unseen_single_mse_de 34.335
wandb:                  test_unseen_single_mse_top20_de_non_dropout 34.335
wandb:                                   test_unseen_single_pearson 0.20819
wandb:                                test_unseen_single_pearson_de -0.36845
wandb:                             test_unseen_single_pearson_delta -0.0105
wandb:                                                 train_de_mse 141.90117
wandb:                                             train_de_pearson 0.49862
wandb:                                                    train_mse 37.62478
wandb:                                                train_pearson 0.71263
wandb:                                                training_loss 0.27128
wandb:                                                   val_de_mse 167.92474
wandb:                                               val_de_pearson 0.0
wandb:                                                      val_mse 72.9836
wandb:                                                  val_pearson 0.08421
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406677_2_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/5ayqcsxf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_173011-5ayqcsxf/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:2
combo_seen2:1
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_173422-z97v1dko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406677_2_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/z97v1dko
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3544
Epoch 1 Step 51 Train Loss: 0.3813
Epoch 1 Step 101 Train Loss: 0.3558
Epoch 1 Step 151 Train Loss: 0.3694
Epoch 1 Step 201 Train Loss: 0.3418
Epoch 1: Train Overall MSE: 64.6658 Validation Overall MSE: 65.2814. 
Train Top 20 DE MSE: 385.6200 Validation Top 20 DE MSE: 45.8714. 
Epoch 2 Step 1 Train Loss: 0.4356
Epoch 2 Step 51 Train Loss: 0.3490
Epoch 2 Step 101 Train Loss: 0.4151
Epoch 2 Step 151 Train Loss: 0.3787
Epoch 2 Step 201 Train Loss: 0.4135
Epoch 2: Train Overall MSE: 0.2859 Validation Overall MSE: 0.3272. 
Train Top 20 DE MSE: 2.3239 Validation Top 20 DE MSE: 0.8668. 
Epoch 3 Step 1 Train Loss: 0.3451
Epoch 3 Step 51 Train Loss: 0.3270
Epoch 3 Step 101 Train Loss: 0.3605
Epoch 3 Step 151 Train Loss: 0.3499
Epoch 3 Step 201 Train Loss: 0.3927
Epoch 3: Train Overall MSE: 0.2055 Validation Overall MSE: 0.2691. 
Train Top 20 DE MSE: 3.0922 Validation Top 20 DE MSE: 0.8380. 
Epoch 4 Step 1 Train Loss: 0.4666
Epoch 4 Step 51 Train Loss: 0.3679
Epoch 4 Step 101 Train Loss: 0.3110
Epoch 4 Step 151 Train Loss: 0.3699
Epoch 4 Step 201 Train Loss: 0.3857
Epoch 4: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0374. 
Train Top 20 DE MSE: 0.0483 Validation Top 20 DE MSE: 0.3037. 
Epoch 5 Step 1 Train Loss: 0.3230
Epoch 5 Step 51 Train Loss: 0.3944
Epoch 5 Step 101 Train Loss: 0.3637
Epoch 5 Step 151 Train Loss: 0.3563
Epoch 5 Step 201 Train Loss: 0.3676
Epoch 5: Train Overall MSE: 0.0076 Validation Overall MSE: 0.0453. 
Train Top 20 DE MSE: 0.1186 Validation Top 20 DE MSE: 0.3198. 
Epoch 6 Step 1 Train Loss: 0.4374
Epoch 6 Step 51 Train Loss: 0.3939
Epoch 6 Step 101 Train Loss: 0.3499
Epoch 6 Step 151 Train Loss: 0.3474
Epoch 6 Step 201 Train Loss: 0.3865
Epoch 6: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0365. 
Train Top 20 DE MSE: 0.0613 Validation Top 20 DE MSE: 0.2895. 
Epoch 7 Step 1 Train Loss: 0.3800
Epoch 7 Step 51 Train Loss: 0.2966
Epoch 7 Step 101 Train Loss: 0.3464
Epoch 7 Step 151 Train Loss: 0.3938
Epoch 7 Step 201 Train Loss: 0.3059
Epoch 7: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0403. 
Train Top 20 DE MSE: 0.0750 Validation Top 20 DE MSE: 0.3183. 
Epoch 8 Step 1 Train Loss: 0.3942
Epoch 8 Step 51 Train Loss: 0.3405
Epoch 8 Step 101 Train Loss: 0.3301
Epoch 8 Step 151 Train Loss: 0.3997
Epoch 8 Step 201 Train Loss: 0.3309
Epoch 8: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0352. 
Train Top 20 DE MSE: 0.0307 Validation Top 20 DE MSE: 0.2697. 
Epoch 9 Step 1 Train Loss: 0.3529
Epoch 9 Step 51 Train Loss: 0.3308
Epoch 9 Step 101 Train Loss: 0.3342
Epoch 9 Step 151 Train Loss: 0.3207
Epoch 9 Step 201 Train Loss: 0.3211
Epoch 9: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0357. 
Train Top 20 DE MSE: 0.0349 Validation Top 20 DE MSE: 0.2802. 
Epoch 10 Step 1 Train Loss: 0.3087
Epoch 10 Step 51 Train Loss: 0.3178
Epoch 10 Step 101 Train Loss: 0.3657
Epoch 10 Step 151 Train Loss: 0.3793
Epoch 10 Step 201 Train Loss: 0.3435
Epoch 10: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0355. 
Train Top 20 DE MSE: 0.0189 Validation Top 20 DE MSE: 0.2759. 
Epoch 11 Step 1 Train Loss: 0.3471
Epoch 11 Step 51 Train Loss: 0.4081
Epoch 11 Step 101 Train Loss: 0.3752
Epoch 11 Step 151 Train Loss: 0.3407
Epoch 11 Step 201 Train Loss: 0.3633
Epoch 11: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0354. 
Train Top 20 DE MSE: 0.0223 Validation Top 20 DE MSE: 0.2756. 
Epoch 12 Step 1 Train Loss: 0.4044
Epoch 12 Step 51 Train Loss: 0.3398
Epoch 12 Step 101 Train Loss: 0.3820
Epoch 12 Step 151 Train Loss: 0.3604
Epoch 12 Step 201 Train Loss: 0.3070
Epoch 12: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0355. 
Train Top 20 DE MSE: 0.0181 Validation Top 20 DE MSE: 0.2762. 
Epoch 13 Step 1 Train Loss: 0.3112
Epoch 13 Step 51 Train Loss: 0.3133
Epoch 13 Step 101 Train Loss: 0.4130
Epoch 13 Step 151 Train Loss: 0.3006
Epoch 13 Step 201 Train Loss: 0.3335
Epoch 13: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0364. 
Train Top 20 DE MSE: 0.0216 Validation Top 20 DE MSE: 0.2894. 
Epoch 14 Step 1 Train Loss: 0.3351
Epoch 14 Step 51 Train Loss: 0.3049
Epoch 14 Step 101 Train Loss: 0.3178
Epoch 14 Step 151 Train Loss: 0.3484
Epoch 14 Step 201 Train Loss: 0.3367
Epoch 14: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0355. 
Train Top 20 DE MSE: 0.0197 Validation Top 20 DE MSE: 0.2763. 
Epoch 15 Step 1 Train Loss: 0.3248
Epoch 15 Step 51 Train Loss: 0.3148
Epoch 15 Step 101 Train Loss: 0.3728
Epoch 15 Step 151 Train Loss: 0.3704
Epoch 15 Step 201 Train Loss: 0.3931
Epoch 15: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0360. 
Train Top 20 DE MSE: 0.0219 Validation Top 20 DE MSE: 0.2842. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1249
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: 0.0029924735
test_combo_seen1_pearson: 0.9961762688916591
test_combo_seen1_mse_de: 0.1515598
test_combo_seen1_pearson_de: 0.986690632665628
test_combo_seen2_mse: 0.0020878897
test_combo_seen2_pearson: 0.9972858261963837
test_combo_seen2_mse_de: 0.17768802
test_combo_seen2_pearson_de: 0.9791285540601021
test_unseen_single_mse: 0.01970137
test_unseen_single_pearson: 0.9758325005556596
test_unseen_single_mse_de: 0.07173255
test_unseen_single_pearson_de: 0.49692556573937774
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: 0.4103895575908168
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.05
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.925
test_combo_seen1_mse_top20_de_non_dropout: 0.15155981
test_combo_seen2_pearson_delta: 0.7921917244817115
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.0
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.8
test_combo_seen2_mse_top20_de_non_dropout: 0.17768803
test_unseen_single_pearson_delta: 0.1342615054633169
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.475
test_unseen_single_frac_sigma_below_1_non_dropout: 0.525
test_unseen_single_mse_top20_de_non_dropout: 0.18909563
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.001 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñà‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñà‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.05
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.925
wandb:                                         test_combo_seen1_mse 0.00299
wandb:                                      test_combo_seen1_mse_de 0.15156
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.15156
wandb:                                     test_combo_seen1_pearson 0.99618
wandb:                                  test_combo_seen1_pearson_de 0.98669
wandb:                               test_combo_seen1_pearson_delta 0.41039
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.0
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.8
wandb:                                         test_combo_seen2_mse 0.00209
wandb:                                      test_combo_seen2_mse_de 0.17769
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.17769
wandb:                                     test_combo_seen2_pearson 0.99729
wandb:                                  test_combo_seen2_pearson_de 0.97913
wandb:                               test_combo_seen2_pearson_delta 0.79219
wandb:                                                  test_de_mse 0.12485
wandb:                                              test_de_pearson 0.78927
wandb:               test_frac_opposite_direction_top20_non_dropout 0.21
wandb:                          test_frac_sigma_below_1_non_dropout 0.74
wandb:                                                     test_mse 0.0095
wandb:                                test_mse_top20_de_non_dropout 0.1718
wandb:                                                 test_pearson 0.98826
wandb:                                           test_pearson_delta 0.3763
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.475
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.525
wandb:                                       test_unseen_single_mse 0.0197
wandb:                                    test_unseen_single_mse_de 0.07173
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.1891
wandb:                                   test_unseen_single_pearson 0.97583
wandb:                                test_unseen_single_pearson_de 0.49693
wandb:                             test_unseen_single_pearson_delta 0.13426
wandb:                                                 train_de_mse 0.02189
wandb:                                             train_de_pearson 0.99726
wandb:                                                    train_mse 0.0008
wandb:                                                train_pearson 0.99898
wandb:                                                training_loss 0.34102
wandb:                                                   val_de_mse 0.28417
wandb:                                               val_de_pearson 0.0
wandb:                                                      val_mse 0.03598
wandb:                                                  val_pearson 0.95467
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406677_2_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/z97v1dko
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_173422-z97v1dko/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:2
combo_seen2:1
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_174030-w5tukpzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406677_2_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/w5tukpzs
wandb: WARNING Serializing object of type ndarray that is 8001728 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4129
Epoch 1 Step 51 Train Loss: 0.3594
Epoch 1 Step 101 Train Loss: 0.4394
Epoch 1 Step 151 Train Loss: 0.3502
Epoch 1 Step 201 Train Loss: 0.3636
Epoch 1: Train Overall MSE: 0.4336 Validation Overall MSE: 0.4975. 
Train Top 20 DE MSE: 4.5404 Validation Top 20 DE MSE: 0.7301. 
Epoch 2 Step 1 Train Loss: 0.3600
Epoch 2 Step 51 Train Loss: 0.3914
Epoch 2 Step 101 Train Loss: 0.3400
Epoch 2 Step 151 Train Loss: 0.4847
Epoch 2 Step 201 Train Loss: 0.3534
Epoch 2: Train Overall MSE: 1.9547 Validation Overall MSE: 2.1113. 
Train Top 20 DE MSE: 33.0879 Validation Top 20 DE MSE: 2.7921. 
Epoch 3 Step 1 Train Loss: 0.3224
Epoch 3 Step 51 Train Loss: 0.3442
Epoch 3 Step 101 Train Loss: 0.3571
Epoch 3 Step 151 Train Loss: 0.3394
Epoch 3 Step 201 Train Loss: 0.3226
Epoch 3: Train Overall MSE: 0.0259 Validation Overall MSE: 0.0660. 
Train Top 20 DE MSE: 0.0986 Validation Top 20 DE MSE: 0.0753. 
Epoch 4 Step 1 Train Loss: 0.3479
Epoch 4 Step 51 Train Loss: 0.3604
Epoch 4 Step 101 Train Loss: 0.3243
Epoch 4 Step 151 Train Loss: 0.3895
Epoch 4 Step 201 Train Loss: 0.3393
Epoch 4: Train Overall MSE: 0.0240 Validation Overall MSE: 0.0651. 
Train Top 20 DE MSE: 0.2307 Validation Top 20 DE MSE: 0.0703. 
Epoch 5 Step 1 Train Loss: 0.3465
Epoch 5 Step 51 Train Loss: 0.3626
Epoch 5 Step 101 Train Loss: 0.2929
Epoch 5 Step 151 Train Loss: 0.3313
Epoch 5 Step 201 Train Loss: 0.3309
Epoch 5: Train Overall MSE: 0.0038 Validation Overall MSE: 0.0345. 
Train Top 20 DE MSE: 0.1225 Validation Top 20 DE MSE: 0.1323. 
Epoch 6 Step 1 Train Loss: 0.3123
Epoch 6 Step 51 Train Loss: 0.3592
Epoch 6 Step 101 Train Loss: 0.3588
Epoch 6 Step 151 Train Loss: 0.3088
Epoch 6 Step 201 Train Loss: 0.3499
Epoch 6: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0368. 
Train Top 20 DE MSE: 0.1011 Validation Top 20 DE MSE: 0.0877. 
Epoch 7 Step 1 Train Loss: 0.3036
Epoch 7 Step 51 Train Loss: 0.3669
Epoch 7 Step 101 Train Loss: 0.3557
Epoch 7 Step 151 Train Loss: 0.3331
Epoch 7 Step 201 Train Loss: 0.3583
Epoch 7: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0322. 
Train Top 20 DE MSE: 0.0578 Validation Top 20 DE MSE: 0.1233. 
Epoch 8 Step 1 Train Loss: 0.3486
Epoch 8 Step 51 Train Loss: 0.3383
Epoch 8 Step 101 Train Loss: 0.3193
Epoch 8 Step 151 Train Loss: 0.4081
Epoch 8 Step 201 Train Loss: 0.4732
Epoch 8: Train Overall MSE: 0.0008 Validation Overall MSE: 0.0311. 
Train Top 20 DE MSE: 0.0311 Validation Top 20 DE MSE: 0.1182. 
Epoch 9 Step 1 Train Loss: 0.3564
Epoch 9 Step 51 Train Loss: 0.3599
Epoch 9 Step 101 Train Loss: 0.3405
Epoch 9 Step 151 Train Loss: 0.3483
Epoch 9 Step 201 Train Loss: 0.3071
Epoch 9: Train Overall MSE: 0.0006 Validation Overall MSE: 0.0305. 
Train Top 20 DE MSE: 0.0270 Validation Top 20 DE MSE: 0.1125. 
Epoch 10 Step 1 Train Loss: 0.4168
Epoch 10 Step 51 Train Loss: 0.3220
Epoch 10 Step 101 Train Loss: 0.3748
Epoch 10 Step 151 Train Loss: 0.3284
Epoch 10 Step 201 Train Loss: 0.3167
Epoch 10: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0303. 
Train Top 20 DE MSE: 0.0219 Validation Top 20 DE MSE: 0.1151. 
Epoch 11 Step 1 Train Loss: 0.3432
Epoch 11 Step 51 Train Loss: 0.3165
Epoch 11 Step 101 Train Loss: 0.3687
Epoch 11 Step 151 Train Loss: 0.3557
Epoch 11 Step 201 Train Loss: 0.3424
Epoch 11: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0302. 
Train Top 20 DE MSE: 0.0217 Validation Top 20 DE MSE: 0.1164. 
Epoch 12 Step 1 Train Loss: 0.3700
Epoch 12 Step 51 Train Loss: 0.3699
Epoch 12 Step 101 Train Loss: 0.3730
Epoch 12 Step 151 Train Loss: 0.3317
Epoch 12 Step 201 Train Loss: 0.3255
Epoch 12: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0304. 
Train Top 20 DE MSE: 0.0177 Validation Top 20 DE MSE: 0.1156. 
Epoch 13 Step 1 Train Loss: 0.3200
Epoch 13 Step 51 Train Loss: 0.3338
Epoch 13 Step 101 Train Loss: 0.3336
Epoch 13 Step 151 Train Loss: 0.3581
Epoch 13 Step 201 Train Loss: 0.3372
Epoch 13: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0302. 
Train Top 20 DE MSE: 0.0233 Validation Top 20 DE MSE: 0.1161. 
Epoch 14 Step 1 Train Loss: 0.3319
Epoch 14 Step 51 Train Loss: 0.3522
Epoch 14 Step 101 Train Loss: 0.3332
Epoch 14 Step 151 Train Loss: 0.3288
Epoch 14 Step 201 Train Loss: 0.3553
Epoch 14: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0304. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.1148. 
Epoch 15 Step 1 Train Loss: 0.3239
Epoch 15 Step 51 Train Loss: 0.2949
Epoch 15 Step 101 Train Loss: 0.3279
Epoch 15 Step 151 Train Loss: 0.2839
Epoch 15 Step 201 Train Loss: 0.3470
Epoch 15: Train Overall MSE: 0.0007 Validation Overall MSE: 0.0304. 
Train Top 20 DE MSE: 0.0189 Validation Top 20 DE MSE: 0.1170. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.2127
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: 0.024203317
test_combo_seen1_pearson: 0.9704041267469794
test_combo_seen1_mse_de: 0.26469514
test_combo_seen1_pearson_de: 0.980534626643943
test_combo_seen2_mse: 0.017446946
test_combo_seen2_pearson: 0.9784958598851099
test_combo_seen2_mse_de: 0.2482559
test_combo_seen2_pearson_de: 0.9773825655611696
test_unseen_single_mse: 0.037637826
test_unseen_single_pearson: 0.9535689391606779
test_unseen_single_mse_de: 0.14300857
test_unseen_single_pearson_de: 0.4918004718738629
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: 0.35053083377332994
test_combo_seen1_frac_opposite_direction_top20_non_dropout: 0.075
test_combo_seen1_frac_sigma_below_1_non_dropout: 0.675
test_combo_seen1_mse_top20_de_non_dropout: 0.26469517
test_combo_seen2_pearson_delta: 0.6833516857977207
test_combo_seen2_frac_opposite_direction_top20_non_dropout: 0.0
test_combo_seen2_frac_sigma_below_1_non_dropout: 0.7
test_combo_seen2_mse_top20_de_non_dropout: 0.2482559
test_unseen_single_pearson_delta: 0.1543567779692281
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.35
test_unseen_single_frac_sigma_below_1_non_dropout: 0.525
test_unseen_single_mse_top20_de_non_dropout: 0.16181622
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.021 MB uploadedwandb: | 0.005 MB of 0.021 MB uploadedwandb: / 0.014 MB of 0.021 MB uploadedwandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.021 MB of 0.021 MB uploadedwandb: | 0.021 MB of 0.021 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen1_mse ‚ñÅ
wandb:                                      test_combo_seen1_mse_de ‚ñÅ
wandb:                    test_combo_seen1_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen1_pearson ‚ñÅ
wandb:                                  test_combo_seen1_pearson_de ‚ñÅ
wandb:                               test_combo_seen1_pearson_delta ‚ñÅ
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                         test_combo_seen2_mse ‚ñÅ
wandb:                                      test_combo_seen2_mse_de ‚ñÅ
wandb:                    test_combo_seen2_mse_top20_de_non_dropout ‚ñÅ
wandb:                                     test_combo_seen2_pearson ‚ñÅ
wandb:                                  test_combo_seen2_pearson_de ‚ñÅ
wandb:                               test_combo_seen2_pearson_delta ‚ñÅ
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÑ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                      val_mse ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÑ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout 0.075
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout 0.675
wandb:                                         test_combo_seen1_mse 0.0242
wandb:                                      test_combo_seen1_mse_de 0.2647
wandb:                    test_combo_seen1_mse_top20_de_non_dropout 0.2647
wandb:                                     test_combo_seen1_pearson 0.9704
wandb:                                  test_combo_seen1_pearson_de 0.98053
wandb:                               test_combo_seen1_pearson_delta 0.35053
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout 0.0
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout 0.7
wandb:                                         test_combo_seen2_mse 0.01745
wandb:                                      test_combo_seen2_mse_de 0.24826
wandb:                    test_combo_seen2_mse_top20_de_non_dropout 0.24826
wandb:                                     test_combo_seen2_pearson 0.9785
wandb:                                  test_combo_seen2_pearson_de 0.97738
wandb:                               test_combo_seen2_pearson_delta 0.68335
wandb:                                                  test_de_mse 0.21273
wandb:                                              test_de_pearson 0.78441
wandb:               test_frac_opposite_direction_top20_non_dropout 0.17
wandb:                          test_frac_sigma_below_1_non_dropout 0.62
wandb:                                                     test_mse 0.02823
wandb:                                test_mse_top20_de_non_dropout 0.22026
wandb:                                                 test_pearson 0.96529
wandb:                                           test_pearson_delta 0.33863
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.35
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.525
wandb:                                       test_unseen_single_mse 0.03764
wandb:                                    test_unseen_single_mse_de 0.14301
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.16182
wandb:                                   test_unseen_single_pearson 0.95357
wandb:                                test_unseen_single_pearson_de 0.4918
wandb:                             test_unseen_single_pearson_delta 0.15436
wandb:                                                 train_de_mse 0.01893
wandb:                                             train_de_pearson 0.99737
wandb:                                                    train_mse 0.00072
wandb:                                                train_pearson 0.99907
wandb:                                                training_loss 0.36457
wandb:                                                   val_de_mse 0.11697
wandb:                                               val_de_pearson 0.0
wandb:                                                      val_mse 0.03036
wandb:                                                  val_pearson 0.96199
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406677_2_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/w5tukpzs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_174030-w5tukpzs/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:22
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_174702-qhl6jhfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406681_3_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/qhl6jhfl
wandb: WARNING Serializing object of type ndarray that is 8100928 bytes
  0%|                                                                                       | 0/3555 [00:00<?, ?it/s]  0%|‚ñè                                                                              | 7/3555 [00:00<00:56, 62.41it/s]  0%|‚ñé                                                                             | 15/3555 [00:00<00:52, 67.11it/s]  1%|‚ñå                                                                             | 23/3555 [00:00<00:51, 68.87it/s]  1%|‚ñã                                                                             | 31/3555 [00:00<00:49, 71.28it/s]  1%|‚ñä                                                                             | 39/3555 [00:00<00:48, 73.06it/s]  1%|‚ñà                                                                             | 48/3555 [00:00<00:45, 77.10it/s]  2%|‚ñà‚ñè                                                                            | 56/3555 [00:00<00:45, 77.12it/s]  2%|‚ñà‚ñç                                                                            | 64/3555 [00:00<00:44, 77.61it/s]  2%|‚ñà‚ñå                                                                            | 72/3555 [00:00<00:44, 77.85it/s]  2%|‚ñà‚ñä                                                                            | 80/3555 [00:01<00:44, 77.76it/s]  2%|‚ñà‚ñâ                                                                            | 88/3555 [00:01<00:44, 78.17it/s]  3%|‚ñà‚ñà                                                                            | 96/3555 [00:01<00:44, 78.13it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 104/3555 [00:01<00:45, 75.20it/s]  3%|‚ñà‚ñà‚ñç                                                                          | 113/3555 [00:01<00:43, 79.26it/s]  3%|‚ñà‚ñà‚ñå                                                                          | 121/3555 [00:01<00:43, 78.86it/s]  4%|‚ñà‚ñà‚ñä                                                                          | 129/3555 [00:01<00:43, 78.91it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 137/3555 [00:01<00:43, 79.09it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 145/3555 [00:01<00:43, 78.39it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 153/3555 [00:01<00:43, 78.10it/s]  5%|‚ñà‚ñà‚ñà‚ñç                                                                         | 161/3555 [00:02<00:45, 75.03it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 169/3555 [00:02<00:44, 76.02it/s]  5%|‚ñà‚ñà‚ñà‚ñä                                                                         | 178/3555 [00:02<00:42, 79.25it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 186/3555 [00:02<00:42, 79.08it/s]  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                        | 194/3555 [00:02<00:42, 79.06it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 202/3555 [00:02<00:42, 78.88it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 210/3555 [00:02<00:42, 78.96it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 218/3555 [00:02<00:42, 78.78it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 226/3555 [00:02<00:42, 78.18it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 234/3555 [00:03<00:42, 78.37it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 242/3555 [00:03<00:42, 78.50it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 250/3555 [00:03<00:42, 78.48it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 258/3555 [00:03<00:41, 78.51it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 266/3555 [00:03<00:42, 78.30it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 274/3555 [00:03<00:41, 78.69it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 282/3555 [00:03<00:41, 78.77it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 290/3555 [00:03<00:41, 78.80it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 298/3555 [00:03<00:42, 75.86it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 307/3555 [00:03<00:40, 79.76it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 316/3555 [00:04<00:42, 76.78it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 325/3555 [00:04<00:42, 76.85it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 333/3555 [00:04<00:42, 76.69it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 342/3555 [00:04<00:40, 79.11it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 350/3555 [00:04<00:41, 77.76it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 358/3555 [00:04<00:40, 77.98it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 366/3555 [00:04<00:44, 71.39it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 374/3555 [00:04<00:46, 68.14it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 383/3555 [00:04<00:43, 73.75it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 391/3555 [00:05<00:44, 71.49it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 399/3555 [00:05<00:47, 66.87it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 408/3555 [00:05<00:43, 72.62it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 416/3555 [00:05<00:43, 72.22it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 426/3555 [00:05<00:40, 77.44it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 434/3555 [00:05<00:40, 77.85it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 442/3555 [00:05<00:41, 74.47it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 452/3555 [00:05<00:38, 80.95it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 461/3555 [00:06<00:39, 79.06it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 469/3555 [00:06<00:41, 74.96it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 479/3555 [00:06<00:38, 80.47it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 488/3555 [00:06<00:38, 80.13it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 497/3555 [00:06<00:37, 81.23it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 506/3555 [00:06<00:38, 80.04it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 515/3555 [00:06<00:38, 79.69it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 524/3555 [00:06<00:39, 77.69it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 533/3555 [00:06<00:37, 80.20it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 542/3555 [00:07<00:38, 78.07it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 551/3555 [00:07<00:37, 81.00it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 560/3555 [00:07<00:37, 79.66it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 569/3555 [00:07<00:38, 77.53it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 578/3555 [00:07<00:37, 80.11it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 587/3555 [00:07<00:37, 79.33it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 595/3555 [00:07<00:38, 77.81it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 604/3555 [00:07<00:36, 80.68it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 613/3555 [00:07<00:37, 77.57it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 622/3555 [00:08<00:36, 79.32it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 630/3555 [00:08<00:37, 78.80it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 638/3555 [00:08<00:37, 78.48it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 648/3555 [00:08<00:36, 79.31it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 656/3555 [00:08<00:36, 78.90it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 665/3555 [00:08<00:35, 81.60it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 674/3555 [00:08<00:35, 82.31it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 683/3555 [00:08<00:35, 80.77it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 692/3555 [00:08<00:36, 77.47it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 701/3555 [00:09<00:36, 78.56it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 710/3555 [00:09<00:35, 81.03it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 719/3555 [00:09<00:36, 78.65it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 729/3555 [00:09<00:35, 79.38it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 738/3555 [00:09<00:35, 78.93it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 747/3555 [00:09<00:34, 80.60it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                            | 756/3555 [00:09<00:35, 79.76it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 765/3555 [00:09<00:34, 81.72it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 774/3555 [00:09<00:35, 78.28it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                            | 783/3555 [00:10<00:35, 78.62it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 792/3555 [00:10<00:35, 78.92it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 802/3555 [00:10<00:33, 82.13it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 811/3555 [00:10<00:33, 81.32it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 820/3555 [00:10<00:34, 78.48it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 830/3555 [00:10<00:34, 79.04it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 839/3555 [00:10<00:33, 81.69it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 848/3555 [00:10<00:33, 81.69it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 857/3555 [00:10<00:34, 78.62it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 866/3555 [00:11<00:33, 81.28it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 875/3555 [00:11<00:34, 77.09it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 885/3555 [00:11<00:33, 80.13it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 894/3555 [00:11<00:33, 80.09it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 904/3555 [00:11<00:33, 79.99it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 913/3555 [00:11<00:32, 82.11it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                         | 922/3555 [00:11<00:33, 79.70it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                        | 931/3555 [00:11<00:32, 81.70it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 940/3555 [00:12<00:33, 77.47it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 950/3555 [00:12<00:33, 78.62it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 959/3555 [00:12<00:32, 78.69it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 968/3555 [00:12<00:31, 81.32it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 977/3555 [00:12<00:31, 81.42it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 986/3555 [00:12<00:31, 80.43it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 995/3555 [00:12<00:32, 78.19it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 1005/3555 [00:12<00:31, 81.67it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 1014/3555 [00:12<00:32, 77.80it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 1024/3555 [00:13<00:31, 79.66it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1033/3555 [00:13<00:30, 82.22it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1042/3555 [00:13<00:31, 80.87it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1051/3555 [00:13<00:31, 78.47it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1060/3555 [00:13<00:32, 77.92it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1068/3555 [00:13<00:31, 78.20it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1078/3555 [00:13<00:30, 81.64it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1087/3555 [00:13<00:30, 80.53it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1096/3555 [00:13<00:31, 77.70it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 1105/3555 [00:14<00:31, 78.42it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1113/3555 [00:14<00:31, 78.49it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 1121/3555 [00:14<00:32, 74.66it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1132/3555 [00:14<00:28, 84.24it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1141/3555 [00:14<00:29, 82.50it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1150/3555 [00:14<00:29, 81.19it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1159/3555 [00:14<00:28, 83.20it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1168/3555 [00:14<00:30, 79.36it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1178/3555 [00:15<00:29, 80.00it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1187/3555 [00:15<00:29, 81.64it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1196/3555 [00:15<00:29, 79.15it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1206/3555 [00:15<00:28, 82.45it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1215/3555 [00:15<00:28, 81.02it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1224/3555 [00:15<00:29, 79.36it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1233/3555 [00:15<00:29, 78.96it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1242/3555 [00:15<00:29, 78.55it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1251/3555 [00:15<00:29, 79.13it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 1260/3555 [00:16<00:28, 81.47it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 1269/3555 [00:16<00:29, 78.42it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1277/3555 [00:16<00:29, 76.76it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1287/3555 [00:16<00:28, 79.50it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1295/3555 [00:16<00:28, 78.29it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1305/3555 [00:16<00:27, 81.97it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1314/3555 [00:16<00:26, 83.88it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1323/3555 [00:16<00:27, 81.25it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1332/3555 [00:16<00:27, 80.87it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1341/3555 [00:17<00:26, 82.80it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1350/3555 [00:17<00:26, 84.00it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1359/3555 [00:17<00:26, 81.89it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1368/3555 [00:17<00:27, 78.74it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 1378/3555 [00:17<00:27, 79.58it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                              | 1387/3555 [00:17<00:26, 81.72it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1396/3555 [00:17<00:26, 82.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1405/3555 [00:17<00:27, 77.98it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1413/3555 [00:17<00:29, 73.57it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1423/3555 [00:18<00:27, 76.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 1432/3555 [00:18<00:27, 78.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1440/3555 [00:18<00:27, 77.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1448/3555 [00:18<00:27, 76.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1457/3555 [00:18<00:26, 79.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1465/3555 [00:18<00:26, 79.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 1473/3555 [00:18<00:26, 77.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1482/3555 [00:18<00:26, 77.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1491/3555 [00:18<00:25, 80.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 1500/3555 [00:19<00:25, 80.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 1509/3555 [00:19<00:25, 79.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 1517/3555 [00:19<00:26, 76.80it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 1527/3555 [00:19<00:25, 78.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 1536/3555 [00:19<00:25, 77.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 1546/3555 [00:19<00:24, 81.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 1555/3555 [00:19<00:25, 78.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 1563/3555 [00:19<00:25, 78.45it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1572/3555 [00:19<00:24, 79.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1581/3555 [00:20<00:24, 79.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 1589/3555 [00:20<00:24, 79.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 1598/3555 [00:20<00:25, 77.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 1609/3555 [00:20<00:23, 83.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1618/3555 [00:20<00:24, 80.49it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 1627/3555 [00:20<00:23, 82.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 1636/3555 [00:20<00:23, 81.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1646/3555 [00:20<00:22, 84.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 1655/3555 [00:20<00:23, 81.34it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 1664/3555 [00:21<00:23, 81.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 1673/3555 [00:21<00:22, 82.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 1682/3555 [00:21<00:22, 81.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 1692/3555 [00:21<00:22, 84.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 1701/3555 [00:21<00:22, 82.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 1711/3555 [00:21<00:21, 84.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1720/3555 [00:21<00:21, 84.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 1729/3555 [00:21<00:21, 84.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 1738/3555 [00:21<00:22, 80.46it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 1748/3555 [00:22<00:22, 82.10it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 1758/3555 [00:22<00:21, 81.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 1768/3555 [00:22<00:21, 84.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 1777/3555 [00:22<00:21, 81.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 1786/3555 [00:22<00:21, 83.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1795/3555 [00:22<00:21, 80.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 1804/3555 [00:22<00:22, 78.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 1813/3555 [00:22<00:21, 80.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 1823/3555 [00:23<00:21, 78.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 1834/3555 [00:23<00:21, 81.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 1843/3555 [00:23<00:20, 81.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 1852/3555 [00:23<00:21, 78.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 1862/3555 [00:23<00:20, 83.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 1871/3555 [00:23<00:20, 83.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1880/3555 [00:23<00:20, 83.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1889/3555 [00:23<00:20, 80.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 1898/3555 [00:23<00:20, 80.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1908/3555 [00:24<00:19, 83.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 1917/3555 [00:24<00:20, 80.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 1927/3555 [00:24<00:20, 81.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 1936/3555 [00:24<00:19, 82.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 1945/3555 [00:24<00:19, 83.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 1954/3555 [00:24<00:19, 82.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 1963/3555 [00:24<00:19, 81.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 1972/3555 [00:24<00:19, 79.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 1981/3555 [00:24<00:19, 82.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 1990/3555 [00:25<00:19, 81.17it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 1999/3555 [00:25<00:18, 82.10it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 2008/3555 [00:25<00:18, 81.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 2017/3555 [00:25<00:19, 78.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2027/3555 [00:25<00:19, 79.87it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 2036/3555 [00:25<00:19, 79.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2046/3555 [00:25<00:18, 81.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 2056/3555 [00:25<00:17, 84.05it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 2065/3555 [00:25<00:18, 81.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2074/3555 [00:26<00:17, 82.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 2083/3555 [00:26<00:18, 81.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2092/3555 [00:26<00:17, 81.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 2101/3555 [00:26<00:19, 75.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 2111/3555 [00:26<00:17, 81.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2120/3555 [00:26<00:17, 82.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2129/3555 [00:26<00:17, 81.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2138/3555 [00:26<00:17, 80.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2147/3555 [00:27<00:17, 78.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2155/3555 [00:27<00:17, 79.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2164/3555 [00:27<00:17, 80.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2174/3555 [00:27<00:17, 81.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2183/3555 [00:27<00:17, 79.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2192/3555 [00:27<00:18, 75.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2200/3555 [00:27<00:17, 76.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2209/3555 [00:27<00:18, 73.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2218/3555 [00:27<00:17, 76.66it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2227/3555 [00:28<00:17, 77.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2235/3555 [00:28<00:16, 77.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2245/3555 [00:28<00:16, 81.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 2254/3555 [00:28<00:15, 82.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 2263/3555 [00:28<00:16, 78.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 2272/3555 [00:28<00:16, 79.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 2282/3555 [00:28<00:15, 80.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 2291/3555 [00:28<00:15, 80.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 2300/3555 [00:28<00:15, 79.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 2309/3555 [00:29<00:15, 82.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2318/3555 [00:29<00:14, 83.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 2327/3555 [00:29<00:15, 81.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 2337/3555 [00:29<00:14, 81.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 2347/3555 [00:29<00:14, 82.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 2357/3555 [00:29<00:13, 85.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 2366/3555 [00:29<00:14, 83.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 2375/3555 [00:29<00:13, 84.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 2384/3555 [00:29<00:14, 82.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 2393/3555 [00:30<00:13, 84.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2403/3555 [00:30<00:13, 85.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2412/3555 [00:30<00:13, 84.02it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2421/3555 [00:30<00:13, 85.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 2431/3555 [00:30<00:12, 86.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2440/3555 [00:30<00:13, 82.91it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2450/3555 [00:30<00:12, 86.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 2459/3555 [00:30<00:12, 85.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 2468/3555 [00:30<00:13, 83.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2478/3555 [00:31<00:12, 86.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2487/3555 [00:31<00:12, 85.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 2496/3555 [00:31<00:12, 84.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 2506/3555 [00:31<00:12, 86.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 2515/3555 [00:31<00:12, 80.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 2526/3555 [00:31<00:11, 88.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2535/3555 [00:31<00:12, 82.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2545/3555 [00:31<00:11, 85.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 2554/3555 [00:31<00:11, 84.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 2563/3555 [00:32<00:11, 84.09it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2572/3555 [00:32<00:11, 82.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2583/3555 [00:32<00:11, 87.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2592/3555 [00:32<00:11, 86.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 2601/3555 [00:32<00:11, 84.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 2610/3555 [00:32<00:11, 85.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2619/3555 [00:32<00:11, 84.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2629/3555 [00:32<00:10, 88.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2638/3555 [00:32<00:11, 81.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2649/3555 [00:33<00:10, 86.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 2659/3555 [00:33<00:10, 87.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 2668/3555 [00:33<00:10, 87.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2677/3555 [00:33<00:09, 87.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2686/3555 [00:33<00:10, 84.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 2695/3555 [00:33<00:10, 83.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 2705/3555 [00:33<00:09, 86.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 2714/3555 [00:33<00:10, 82.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2723/3555 [00:33<00:09, 83.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2733/3555 [00:34<00:09, 85.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2742/3555 [00:34<00:09, 83.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 2753/3555 [00:34<00:09, 85.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 2762/3555 [00:34<00:09, 84.84it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 2771/3555 [00:34<00:09, 86.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2781/3555 [00:34<00:08, 88.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2790/3555 [00:34<00:08, 87.70it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2799/3555 [00:34<00:09, 83.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2810/3555 [00:34<00:08, 88.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2819/3555 [00:35<00:08, 86.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2828/3555 [00:35<00:09, 78.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2836/3555 [00:35<00:10, 71.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2844/3555 [00:35<00:10, 71.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2852/3555 [00:35<00:10, 66.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2859/3555 [00:35<00:11, 60.94it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2867/3555 [00:35<00:10, 65.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 2874/3555 [00:35<00:10, 64.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 2883/3555 [00:36<00:09, 70.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2892/3555 [00:36<00:08, 74.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 2900/3555 [00:36<00:09, 72.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 2909/3555 [00:36<00:08, 75.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2919/3555 [00:36<00:08, 77.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2928/3555 [00:36<00:07, 78.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2938/3555 [00:36<00:07, 82.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2947/3555 [00:36<00:07, 80.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 2956/3555 [00:36<00:07, 83.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2965/3555 [00:37<00:07, 81.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 2974/3555 [00:37<00:06, 83.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 2983/3555 [00:37<00:07, 79.46it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2993/3555 [00:37<00:06, 82.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 3002/3555 [00:37<00:06, 81.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3012/3555 [00:37<00:06, 84.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 3021/3555 [00:37<00:06, 85.21it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 3030/3555 [00:37<00:06, 84.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 3039/3555 [00:37<00:06, 83.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 3048/3555 [00:38<00:06, 78.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 3058/3555 [00:38<00:06, 81.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 3068/3555 [00:38<00:05, 83.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 3077/3555 [00:38<00:05, 82.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 3087/3555 [00:38<00:05, 82.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 3096/3555 [00:38<00:05, 83.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 3106/3555 [00:38<00:05, 85.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 3115/3555 [00:38<00:05, 83.27it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 3124/3555 [00:38<00:05, 81.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 3133/3555 [00:39<00:05, 83.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 3142/3555 [00:39<00:05, 79.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 3153/3555 [00:39<00:04, 83.11it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 3162/3555 [00:39<00:04, 84.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 3171/3555 [00:39<00:04, 83.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 3180/3555 [00:39<00:04, 81.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 3189/3555 [00:39<00:04, 79.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 3197/3555 [00:39<00:04, 77.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 3208/3555 [00:39<00:04, 83.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 3218/3555 [00:40<00:03, 85.11it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 3227/3555 [00:40<00:03, 84.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 3236/3555 [00:40<00:03, 83.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 3245/3555 [00:40<00:03, 84.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3254/3555 [00:40<00:03, 81.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3263/3555 [00:40<00:03, 82.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 3272/3555 [00:40<00:03, 72.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 3280/3555 [00:40<00:03, 72.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3288/3555 [00:41<00:04, 65.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 3296/3555 [00:41<00:03, 68.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3303/3555 [00:41<00:03, 64.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 3310/3555 [00:41<00:04, 59.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3318/3555 [00:41<00:03, 62.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3325/3555 [00:41<00:03, 63.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3332/3555 [00:41<00:04, 53.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3342/3555 [00:41<00:03, 63.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3349/3555 [00:42<00:03, 63.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3358/3555 [00:42<00:02, 68.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3368/3555 [00:42<00:02, 74.79it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3376/3555 [00:42<00:02, 70.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3386/3555 [00:42<00:02, 73.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3396/3555 [00:42<00:02, 76.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3404/3555 [00:42<00:01, 76.27it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3412/3555 [00:42<00:01, 76.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3420/3555 [00:42<00:01, 77.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3429/3555 [00:43<00:01, 77.93it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3437/3555 [00:43<00:01, 74.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3446/3555 [00:43<00:01, 77.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3455/3555 [00:43<00:01, 77.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3463/3555 [00:43<00:01, 76.26it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3472/3555 [00:43<00:01, 75.07it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3481/3555 [00:43<00:00, 75.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3490/3555 [00:43<00:00, 78.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3498/3555 [00:44<00:00, 74.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3507/3555 [00:44<00:00, 76.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3515/3555 [00:44<00:00, 75.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3523/3555 [00:44<00:00, 72.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3531/3555 [00:44<00:00, 71.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3539/3555 [00:44<00:00, 71.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3547/3555 [00:44<00:00, 71.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3555/3555 [00:44<00:00, 70.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3555/3555 [00:44<00:00, 79.35it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.5256
Epoch 1 Step 51 Train Loss: 0.5309
Epoch 1 Step 101 Train Loss: 0.5150
Epoch 1 Step 151 Train Loss: 0.5346
Epoch 1 Step 201 Train Loss: 0.5022
Epoch 1 Step 251 Train Loss: 0.5426
Epoch 1 Step 301 Train Loss: 0.5780
Epoch 1 Step 351 Train Loss: 0.6472
Epoch 1 Step 401 Train Loss: 0.4915
Epoch 1 Step 451 Train Loss: 0.4747
Epoch 1 Step 501 Train Loss: 0.5598
Epoch 1 Step 551 Train Loss: 0.5111
Epoch 1 Step 601 Train Loss: 0.5706
Epoch 1 Step 651 Train Loss: 0.5181
Epoch 1 Step 701 Train Loss: 0.5398
Epoch 1 Step 751 Train Loss: 0.5704
Epoch 1 Step 801 Train Loss: 0.5479
Epoch 1 Step 851 Train Loss: 0.5155
Epoch 1 Step 901 Train Loss: 0.4960
Epoch 1 Step 951 Train Loss: 0.5112
Epoch 1 Step 1001 Train Loss: 0.4518
Epoch 1 Step 1051 Train Loss: 0.4814
Epoch 1 Step 1101 Train Loss: 0.5575
Epoch 1 Step 1151 Train Loss: 0.5321
Epoch 1 Step 1201 Train Loss: 0.4202
Epoch 1 Step 1251 Train Loss: 0.4815
Epoch 1 Step 1301 Train Loss: 0.5857
Epoch 1 Step 1351 Train Loss: 0.4520
Epoch 1: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.1362 Validation Top 20 DE MSE: 0.2163. 
Epoch 2 Step 1 Train Loss: 0.4875
Epoch 2 Step 51 Train Loss: 0.5756
Epoch 2 Step 101 Train Loss: 0.4575
Epoch 2 Step 151 Train Loss: 0.5468
Epoch 2 Step 201 Train Loss: 0.4585
Epoch 2 Step 251 Train Loss: 0.4794
Epoch 2 Step 301 Train Loss: 0.5254
Epoch 2 Step 351 Train Loss: 0.5502
Epoch 2 Step 401 Train Loss: 0.5095
Epoch 2 Step 451 Train Loss: 0.5384
Epoch 2 Step 501 Train Loss: 0.4830
Epoch 2 Step 551 Train Loss: 0.5964
Epoch 2 Step 601 Train Loss: 0.4992
Epoch 2 Step 651 Train Loss: 0.4339
Epoch 2 Step 701 Train Loss: 0.4576
Epoch 2 Step 751 Train Loss: 0.5116
Epoch 2 Step 801 Train Loss: 0.4379
Epoch 2 Step 851 Train Loss: 0.4954
Epoch 2 Step 901 Train Loss: 0.5422
Epoch 2 Step 951 Train Loss: 0.5245
Epoch 2 Step 1001 Train Loss: 0.5742
Epoch 2 Step 1051 Train Loss: 0.5938
Epoch 2 Step 1101 Train Loss: 0.6749
Epoch 2 Step 1151 Train Loss: 0.5270
Epoch 2 Step 1201 Train Loss: 0.5819
Epoch 2 Step 1251 Train Loss: 0.5811
Epoch 2 Step 1301 Train Loss: 0.5307
Epoch 2 Step 1351 Train Loss: 0.4689
Epoch 2: Train Overall MSE: 0.0044 Validation Overall MSE: 0.0038. 
Train Top 20 DE MSE: 0.1065 Validation Top 20 DE MSE: 0.0677. 
Epoch 3 Step 1 Train Loss: 0.4769
Epoch 3 Step 51 Train Loss: 0.5495
Epoch 3 Step 101 Train Loss: 0.4929
Epoch 3 Step 151 Train Loss: 0.4995
Epoch 3 Step 201 Train Loss: 0.5043
Epoch 3 Step 251 Train Loss: 0.4779
Epoch 3 Step 301 Train Loss: 0.5527
Epoch 3 Step 351 Train Loss: 0.5322
Epoch 3 Step 401 Train Loss: 0.5341
Epoch 3 Step 451 Train Loss: 0.5094
Epoch 3 Step 501 Train Loss: 0.4607
Epoch 3 Step 551 Train Loss: 0.4670
Epoch 3 Step 601 Train Loss: 0.4808
Epoch 3 Step 651 Train Loss: 0.4609
Epoch 3 Step 701 Train Loss: 0.5952
Epoch 3 Step 751 Train Loss: 0.5078
Epoch 3 Step 801 Train Loss: 0.4681
Epoch 3 Step 851 Train Loss: 0.5870
Epoch 3 Step 901 Train Loss: 0.4681
Epoch 3 Step 951 Train Loss: 0.4443
Epoch 3 Step 1001 Train Loss: 0.4917
Epoch 3 Step 1051 Train Loss: 0.5007
Epoch 3 Step 1101 Train Loss: 0.4824
Epoch 3 Step 1151 Train Loss: 0.5907
Epoch 3 Step 1201 Train Loss: 0.4702
Epoch 3 Step 1251 Train Loss: 0.5231
Epoch 3 Step 1301 Train Loss: 0.4902
Epoch 3 Step 1351 Train Loss: 0.5128
Epoch 3: Train Overall MSE: 0.0036 Validation Overall MSE: 0.0061. 
Train Top 20 DE MSE: 0.1794 Validation Top 20 DE MSE: 0.3684. 
Epoch 4 Step 1 Train Loss: 0.5073
Epoch 4 Step 51 Train Loss: 0.5330
Epoch 4 Step 101 Train Loss: 0.5625
Epoch 4 Step 151 Train Loss: 0.5127
Epoch 4 Step 201 Train Loss: 0.4823
Epoch 4 Step 251 Train Loss: 0.4877
Epoch 4 Step 301 Train Loss: 0.5629
Epoch 4 Step 351 Train Loss: 0.4908
Epoch 4 Step 401 Train Loss: 0.4588
Epoch 4 Step 451 Train Loss: 0.4715
Epoch 4 Step 501 Train Loss: 0.6493
Epoch 4 Step 551 Train Loss: 0.5158
Epoch 4 Step 601 Train Loss: 0.4786
Epoch 4 Step 651 Train Loss: 0.6012
Epoch 4 Step 701 Train Loss: 0.5500
Epoch 4 Step 751 Train Loss: 0.5509
Epoch 4 Step 801 Train Loss: 0.4879
Epoch 4 Step 851 Train Loss: 0.5209
Epoch 4 Step 901 Train Loss: 0.5064
Epoch 4 Step 951 Train Loss: 0.5200
Epoch 4 Step 1001 Train Loss: 0.4950
Epoch 4 Step 1051 Train Loss: 0.5682
Epoch 4 Step 1101 Train Loss: 0.5571
Epoch 4 Step 1151 Train Loss: 0.4851
Epoch 4 Step 1201 Train Loss: 0.4629
Epoch 4 Step 1251 Train Loss: 0.5061
Epoch 4 Step 1301 Train Loss: 0.4748
Epoch 4 Step 1351 Train Loss: 0.5135
Epoch 4: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0880 Validation Top 20 DE MSE: 0.1722. 
Epoch 5 Step 1 Train Loss: 0.4895
Epoch 5 Step 51 Train Loss: 0.5104
Epoch 5 Step 101 Train Loss: 0.6141
Epoch 5 Step 151 Train Loss: 0.4915
Epoch 5 Step 201 Train Loss: 0.5008
Epoch 5 Step 251 Train Loss: 0.5954
Epoch 5 Step 301 Train Loss: 0.5344
Epoch 5 Step 351 Train Loss: 0.5026
Epoch 5 Step 401 Train Loss: 0.4561
Epoch 5 Step 451 Train Loss: 0.5029
Epoch 5 Step 501 Train Loss: 0.5063
Epoch 5 Step 551 Train Loss: 0.4739
Epoch 5 Step 601 Train Loss: 0.7028
Epoch 5 Step 651 Train Loss: 0.5142
Epoch 5 Step 701 Train Loss: 0.5361
Epoch 5 Step 751 Train Loss: 0.5027
Epoch 5 Step 801 Train Loss: 0.5167
Epoch 5 Step 851 Train Loss: 0.4346
Epoch 5 Step 901 Train Loss: 0.5011
Epoch 5 Step 951 Train Loss: 0.5621
Epoch 5 Step 1001 Train Loss: 0.4902
Epoch 5 Step 1051 Train Loss: 0.5151
Epoch 5 Step 1101 Train Loss: 0.4576
Epoch 5 Step 1151 Train Loss: 0.4613
Epoch 5 Step 1201 Train Loss: 0.4535
Epoch 5 Step 1251 Train Loss: 0.4597
Epoch 5 Step 1301 Train Loss: 0.4928
Epoch 5 Step 1351 Train Loss: 0.4802
Epoch 5: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0787 Validation Top 20 DE MSE: 0.1360. 
Epoch 6 Step 1 Train Loss: 0.6311
Epoch 6 Step 51 Train Loss: 0.5128
Epoch 6 Step 101 Train Loss: 0.4968
Epoch 6 Step 151 Train Loss: 0.5408
Epoch 6 Step 201 Train Loss: 0.5068
Epoch 6 Step 251 Train Loss: 0.5335
Epoch 6 Step 301 Train Loss: 0.4537
Epoch 6 Step 351 Train Loss: 0.4528
Epoch 6 Step 401 Train Loss: 0.5067
Epoch 6 Step 451 Train Loss: 0.5364
Epoch 6 Step 501 Train Loss: 0.4724
Epoch 6 Step 551 Train Loss: 0.4689
Epoch 6 Step 601 Train Loss: 0.5745
Epoch 6 Step 651 Train Loss: 0.4942
Epoch 6 Step 701 Train Loss: 0.5276
Epoch 6 Step 751 Train Loss: 0.4753
Epoch 6 Step 801 Train Loss: 0.5501
Epoch 6 Step 851 Train Loss: 0.5365
Epoch 6 Step 901 Train Loss: 0.5431
Epoch 6 Step 951 Train Loss: 0.5280
Epoch 6 Step 1001 Train Loss: 0.5078
Epoch 6 Step 1051 Train Loss: 0.5595
Epoch 6 Step 1101 Train Loss: 0.5323
Epoch 6 Step 1151 Train Loss: 0.5615
Epoch 6 Step 1201 Train Loss: 0.4863
Epoch 6 Step 1251 Train Loss: 0.4826
Epoch 6 Step 1301 Train Loss: 0.5288
Epoch 6 Step 1351 Train Loss: 0.5298
Epoch 6: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0885 Validation Top 20 DE MSE: 0.1659. 
Epoch 7 Step 1 Train Loss: 0.4833
Epoch 7 Step 51 Train Loss: 0.5555
Epoch 7 Step 101 Train Loss: 0.4839
Epoch 7 Step 151 Train Loss: 0.5829
Epoch 7 Step 201 Train Loss: 0.4794
Epoch 7 Step 251 Train Loss: 0.4926
Epoch 7 Step 301 Train Loss: 0.4586
Epoch 7 Step 351 Train Loss: 0.6495
Epoch 7 Step 401 Train Loss: 0.5170
Epoch 7 Step 451 Train Loss: 0.5647
Epoch 7 Step 501 Train Loss: 0.4811
Epoch 7 Step 551 Train Loss: 0.5088
Epoch 7 Step 601 Train Loss: 0.4749
Epoch 7 Step 651 Train Loss: 0.5616
Epoch 7 Step 701 Train Loss: 0.5779
Epoch 7 Step 751 Train Loss: 0.5449
Epoch 7 Step 801 Train Loss: 0.5187
Epoch 7 Step 851 Train Loss: 0.5108
Epoch 7 Step 901 Train Loss: 0.4935
Epoch 7 Step 951 Train Loss: 0.6714
Epoch 7 Step 1001 Train Loss: 0.5193
Epoch 7 Step 1051 Train Loss: 0.4956
Epoch 7 Step 1101 Train Loss: 0.4654
Epoch 7 Step 1151 Train Loss: 0.6102
Epoch 7 Step 1201 Train Loss: 0.5246
Epoch 7 Step 1251 Train Loss: 0.4554
Epoch 7 Step 1301 Train Loss: 0.4546
Epoch 7 Step 1351 Train Loss: 0.4811
Epoch 7: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0755 Validation Top 20 DE MSE: 0.1343. 
Epoch 8 Step 1 Train Loss: 0.5249
Epoch 8 Step 51 Train Loss: 0.4989
Epoch 8 Step 101 Train Loss: 0.5014
Epoch 8 Step 151 Train Loss: 0.6131
Epoch 8 Step 201 Train Loss: 0.4688
Epoch 8 Step 251 Train Loss: 0.5117
Epoch 8 Step 301 Train Loss: 0.5789
Epoch 8 Step 351 Train Loss: 0.5419
Epoch 8 Step 401 Train Loss: 0.5266
Epoch 8 Step 451 Train Loss: 0.5412
Epoch 8 Step 501 Train Loss: 0.5066
Epoch 8 Step 551 Train Loss: 0.4780
Epoch 8 Step 601 Train Loss: 0.5611
Epoch 8 Step 651 Train Loss: 0.5095
Epoch 8 Step 701 Train Loss: 0.5534
Epoch 8 Step 751 Train Loss: 0.5177
Epoch 8 Step 801 Train Loss: 0.4931
Epoch 8 Step 851 Train Loss: 0.4566
Epoch 8 Step 901 Train Loss: 0.4950
Epoch 8 Step 951 Train Loss: 0.5371
Epoch 8 Step 1001 Train Loss: 0.5499
Epoch 8 Step 1051 Train Loss: 0.5238
Epoch 8 Step 1101 Train Loss: 0.4829
Epoch 8 Step 1151 Train Loss: 0.5676
Epoch 8 Step 1201 Train Loss: 0.4890
Epoch 8 Step 1251 Train Loss: 0.4757
Epoch 8 Step 1301 Train Loss: 0.4719
Epoch 8 Step 1351 Train Loss: 0.5247
Epoch 8: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0790 Validation Top 20 DE MSE: 0.1435. 
Epoch 9 Step 1 Train Loss: 0.5180
Epoch 9 Step 51 Train Loss: 0.5053
Epoch 9 Step 101 Train Loss: 0.4683
Epoch 9 Step 151 Train Loss: 0.4765
Epoch 9 Step 201 Train Loss: 0.5460
Epoch 9 Step 251 Train Loss: 0.4898
Epoch 9 Step 301 Train Loss: 0.5692
Epoch 9 Step 351 Train Loss: 0.5658
Epoch 9 Step 401 Train Loss: 0.4939
Epoch 9 Step 451 Train Loss: 0.4895
Epoch 9 Step 501 Train Loss: 0.5682
Epoch 9 Step 551 Train Loss: 0.6455
Epoch 9 Step 601 Train Loss: 0.5480
Epoch 9 Step 651 Train Loss: 0.6296
Epoch 9 Step 701 Train Loss: 0.4821
Epoch 9 Step 751 Train Loss: 0.5701
Epoch 9 Step 801 Train Loss: 0.5191
Epoch 9 Step 851 Train Loss: 0.4966
Epoch 9 Step 901 Train Loss: 0.5392
Epoch 9 Step 951 Train Loss: 0.5024
Epoch 9 Step 1001 Train Loss: 0.4563
Epoch 9 Step 1051 Train Loss: 0.5746
Epoch 9 Step 1101 Train Loss: 0.5442
Epoch 9 Step 1151 Train Loss: 0.5154
Epoch 9 Step 1201 Train Loss: 0.5016
Epoch 9 Step 1251 Train Loss: 0.6275
Epoch 9 Step 1301 Train Loss: 0.4567
Epoch 9 Step 1351 Train Loss: 0.4970
Epoch 9: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0793 Validation Top 20 DE MSE: 0.1363. 
Epoch 10 Step 1 Train Loss: 0.5181
Epoch 10 Step 51 Train Loss: 0.5594
Epoch 10 Step 101 Train Loss: 0.4880
Epoch 10 Step 151 Train Loss: 0.5177
Epoch 10 Step 201 Train Loss: 0.5074
Epoch 10 Step 251 Train Loss: 0.4632
Epoch 10 Step 301 Train Loss: 0.6154
Epoch 10 Step 351 Train Loss: 0.4624
Epoch 10 Step 401 Train Loss: 0.4963
Epoch 10 Step 451 Train Loss: 0.4500
Epoch 10 Step 501 Train Loss: 0.4642
Epoch 10 Step 551 Train Loss: 0.4657
Epoch 10 Step 601 Train Loss: 0.5563
Epoch 10 Step 651 Train Loss: 0.5144
Epoch 10 Step 701 Train Loss: 0.4909
Epoch 10 Step 751 Train Loss: 0.4587
Epoch 10 Step 801 Train Loss: 0.5162
Epoch 10 Step 851 Train Loss: 0.4982
Epoch 10 Step 901 Train Loss: 0.5233
Epoch 10 Step 951 Train Loss: 0.5496
Epoch 10 Step 1001 Train Loss: 0.4937
Epoch 10 Step 1051 Train Loss: 0.5078
Epoch 10 Step 1101 Train Loss: 0.5550
Epoch 10 Step 1151 Train Loss: 0.4732
Epoch 10 Step 1201 Train Loss: 0.5174
Epoch 10 Step 1251 Train Loss: 0.5315
Epoch 10 Step 1301 Train Loss: 0.5251
Epoch 10 Step 1351 Train Loss: 0.4932
Epoch 10: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0776 Validation Top 20 DE MSE: 0.1379. 
Epoch 11 Step 1 Train Loss: 0.5634
Epoch 11 Step 51 Train Loss: 0.5785
Epoch 11 Step 101 Train Loss: 0.5020
Epoch 11 Step 151 Train Loss: 0.5437
Epoch 11 Step 201 Train Loss: 0.5325
Epoch 11 Step 251 Train Loss: 0.5545
Epoch 11 Step 301 Train Loss: 0.4790
Epoch 11 Step 351 Train Loss: 0.5350
Epoch 11 Step 401 Train Loss: 0.5272
Epoch 11 Step 451 Train Loss: 0.5195
Epoch 11 Step 501 Train Loss: 0.4981
Epoch 11 Step 551 Train Loss: 0.4543
Epoch 11 Step 601 Train Loss: 0.6808
Epoch 11 Step 651 Train Loss: 0.5525
Epoch 11 Step 701 Train Loss: 0.5463
Epoch 11 Step 751 Train Loss: 0.4926
Epoch 11 Step 801 Train Loss: 0.5461
Epoch 11 Step 851 Train Loss: 0.6026
Epoch 11 Step 901 Train Loss: 0.5764
Epoch 11 Step 951 Train Loss: 0.4928
Epoch 11 Step 1001 Train Loss: 0.6088
Epoch 11 Step 1051 Train Loss: 0.5521
Epoch 11 Step 1101 Train Loss: 0.4948
Epoch 11 Step 1151 Train Loss: 0.4596
Epoch 11 Step 1201 Train Loss: 0.5629
Epoch 11 Step 1251 Train Loss: 0.4873
Epoch 11 Step 1301 Train Loss: 0.4489
Epoch 11 Step 1351 Train Loss: 0.4955
Epoch 11: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0778 Validation Top 20 DE MSE: 0.1332. 
Epoch 12 Step 1 Train Loss: 0.5141
Epoch 12 Step 51 Train Loss: 0.6015
Epoch 12 Step 101 Train Loss: 0.6011
Epoch 12 Step 151 Train Loss: 0.4930
Epoch 12 Step 201 Train Loss: 0.4773
Epoch 12 Step 251 Train Loss: 0.5256
Epoch 12 Step 301 Train Loss: 0.5885
Epoch 12 Step 351 Train Loss: 0.5477
Epoch 12 Step 401 Train Loss: 0.4875
Epoch 12 Step 451 Train Loss: 0.5199
Epoch 12 Step 501 Train Loss: 0.4951
Epoch 12 Step 551 Train Loss: 0.5127
Epoch 12 Step 601 Train Loss: 0.5580
Epoch 12 Step 651 Train Loss: 0.5241
Epoch 12 Step 701 Train Loss: 0.4549
Epoch 12 Step 751 Train Loss: 0.5158
Epoch 12 Step 801 Train Loss: 0.4787
Epoch 12 Step 851 Train Loss: 0.4550
Epoch 12 Step 901 Train Loss: 0.5257
Epoch 12 Step 951 Train Loss: 0.5888
Epoch 12 Step 1001 Train Loss: 0.6456
Epoch 12 Step 1051 Train Loss: 0.5206
Epoch 12 Step 1101 Train Loss: 0.5899
Epoch 12 Step 1151 Train Loss: 0.5720
Epoch 12 Step 1201 Train Loss: 0.5282
Epoch 12 Step 1251 Train Loss: 0.4960
Epoch 12 Step 1301 Train Loss: 0.5195
Epoch 12 Step 1351 Train Loss: 0.5845
Epoch 12: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0772 Validation Top 20 DE MSE: 0.1305. 
Epoch 13 Step 1 Train Loss: 0.5077
Epoch 13 Step 51 Train Loss: 0.5886
Epoch 13 Step 101 Train Loss: 0.5927
Epoch 13 Step 151 Train Loss: 0.5575
Epoch 13 Step 201 Train Loss: 0.4558
Epoch 13 Step 251 Train Loss: 0.5336
Epoch 13 Step 301 Train Loss: 0.5321
Epoch 13 Step 351 Train Loss: 0.4989
Epoch 13 Step 401 Train Loss: 0.6110
Epoch 13 Step 451 Train Loss: 0.6170
Epoch 13 Step 501 Train Loss: 0.5571
Epoch 13 Step 551 Train Loss: 0.4746
Epoch 13 Step 601 Train Loss: 0.5208
Epoch 13 Step 651 Train Loss: 0.5573
Epoch 13 Step 701 Train Loss: 0.5396
Epoch 13 Step 751 Train Loss: 0.5286
Epoch 13 Step 801 Train Loss: 0.5361
Epoch 13 Step 851 Train Loss: 0.5598
Epoch 13 Step 901 Train Loss: 0.5338
Epoch 13 Step 951 Train Loss: 0.5418
Epoch 13 Step 1001 Train Loss: 0.5471
Epoch 13 Step 1051 Train Loss: 0.4768
Epoch 13 Step 1101 Train Loss: 0.4797
Epoch 13 Step 1151 Train Loss: 0.4719
Epoch 13 Step 1201 Train Loss: 0.4098
Epoch 13 Step 1251 Train Loss: 0.4797
Epoch 13 Step 1301 Train Loss: 0.4895
Epoch 13 Step 1351 Train Loss: 0.4875
Epoch 13: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0813 Validation Top 20 DE MSE: 0.1488. 
Epoch 14 Step 1 Train Loss: 0.4884
Epoch 14 Step 51 Train Loss: 0.5668
Epoch 14 Step 101 Train Loss: 0.5736
Epoch 14 Step 151 Train Loss: 0.4853
Epoch 14 Step 201 Train Loss: 0.4942
Epoch 14 Step 251 Train Loss: 0.4959
Epoch 14 Step 301 Train Loss: 0.4735
Epoch 14 Step 351 Train Loss: 0.5541
Epoch 14 Step 401 Train Loss: 0.5659
Epoch 14 Step 451 Train Loss: 0.4991
Epoch 14 Step 501 Train Loss: 0.5138
Epoch 14 Step 551 Train Loss: 0.5471
Epoch 14 Step 601 Train Loss: 0.5048
Epoch 14 Step 651 Train Loss: 0.4830
Epoch 14 Step 701 Train Loss: 0.6216
Epoch 14 Step 751 Train Loss: 0.5552
Epoch 14 Step 801 Train Loss: 0.5827
Epoch 14 Step 851 Train Loss: 0.5021
Epoch 14 Step 901 Train Loss: 0.7494
Epoch 14 Step 951 Train Loss: 0.5274
Epoch 14 Step 1001 Train Loss: 0.5330
Epoch 14 Step 1051 Train Loss: 0.5057
Epoch 14 Step 1101 Train Loss: 0.4733
Epoch 14 Step 1151 Train Loss: 0.6033
Epoch 14 Step 1201 Train Loss: 0.6642
Epoch 14 Step 1251 Train Loss: 0.5972
Epoch 14 Step 1301 Train Loss: 0.4790
Epoch 14 Step 1351 Train Loss: 0.6121
Epoch 14: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0763 Validation Top 20 DE MSE: 0.1350. 
Epoch 15 Step 1 Train Loss: 0.5008
Epoch 15 Step 51 Train Loss: 0.5437
Epoch 15 Step 101 Train Loss: 0.4300
Epoch 15 Step 151 Train Loss: 0.5356
Epoch 15 Step 201 Train Loss: 0.5117
Epoch 15 Step 251 Train Loss: 0.5148
Epoch 15 Step 301 Train Loss: 0.5824
Epoch 15 Step 351 Train Loss: 0.4938
Epoch 15 Step 401 Train Loss: 0.6288
Epoch 15 Step 451 Train Loss: 0.5487
Epoch 15 Step 501 Train Loss: 0.5200
Epoch 15 Step 551 Train Loss: 0.5875
Epoch 15 Step 601 Train Loss: 0.5715
Epoch 15 Step 651 Train Loss: 0.5983
Epoch 15 Step 701 Train Loss: 0.5349
Epoch 15 Step 751 Train Loss: 0.4767
Epoch 15 Step 801 Train Loss: 0.5172
Epoch 15 Step 851 Train Loss: 0.5410
Epoch 15 Step 901 Train Loss: 0.5905
Epoch 15 Step 951 Train Loss: 0.5001
Epoch 15 Step 1001 Train Loss: 0.4821
Epoch 15 Step 1051 Train Loss: 0.4792
Epoch 15 Step 1101 Train Loss: 0.5053
Epoch 15 Step 1151 Train Loss: 0.5840
Epoch 15 Step 1201 Train Loss: 0.4889
Epoch 15 Step 1251 Train Loss: 0.5374
Epoch 15 Step 1301 Train Loss: 0.5434
Epoch 15 Step 1351 Train Loss: 0.5975
Epoch 15: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0761 Validation Top 20 DE MSE: 0.1363. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0998
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0052884608
test_unseen_single_pearson: 0.9901839316772779
test_unseen_single_mse_de: 0.09980328
test_unseen_single_pearson_de: 0.800154186113286
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.31564198309649244
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.28409090909090906
test_unseen_single_frac_sigma_below_1_non_dropout: 0.85
test_unseen_single_mse_top20_de_non_dropout: 0.10937644
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.033 MB uploadedwandb: | 0.001 MB of 0.033 MB uploadedwandb: / 0.027 MB of 0.033 MB uploadedwandb: - 0.027 MB of 0.033 MB uploadedwandb: \ 0.033 MB of 0.033 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÖ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÉ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÇ
wandb:                                                   val_de_mse ‚ñÑ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:                                               val_de_pearson ‚ñÑ‚ñà‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                                                      val_mse ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÖ‚ñÜ‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.0998
wandb:                                              test_de_pearson 0.80015
wandb:               test_frac_opposite_direction_top20_non_dropout 0.28409
wandb:                          test_frac_sigma_below_1_non_dropout 0.85
wandb:                                                     test_mse 0.00529
wandb:                                test_mse_top20_de_non_dropout 0.10938
wandb:                                                 test_pearson 0.99018
wandb:                                           test_pearson_delta 0.31564
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.28409
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.85
wandb:                                       test_unseen_single_mse 0.00529
wandb:                                    test_unseen_single_mse_de 0.0998
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.10938
wandb:                                   test_unseen_single_pearson 0.99018
wandb:                                test_unseen_single_pearson_de 0.80015
wandb:                             test_unseen_single_pearson_delta 0.31564
wandb:                                                 train_de_mse 0.07607
wandb:                                             train_de_pearson 0.93813
wandb:                                                    train_mse 0.00158
wandb:                                                train_pearson 0.99703
wandb:                                                training_loss 0.5601
wandb:                                                   val_de_mse 0.13628
wandb:                                               val_de_pearson 0.96959
wandb:                                                      val_mse 0.00282
wandb:                                                  val_pearson 0.99457
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406681_3_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/qhl6jhfl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_174702-qhl6jhfl/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:22
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_182759-nfxn3bg0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406681_3_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/nfxn3bg0
wandb: WARNING Serializing object of type ndarray that is 8100928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4946
Epoch 1 Step 51 Train Loss: 0.6530
Epoch 1 Step 101 Train Loss: 0.4826
Epoch 1 Step 151 Train Loss: 0.5028
Epoch 1 Step 201 Train Loss: 0.5103
Epoch 1 Step 251 Train Loss: 0.4835
Epoch 1 Step 301 Train Loss: 0.5763
Epoch 1 Step 351 Train Loss: 0.5704
Epoch 1 Step 401 Train Loss: 0.4827
Epoch 1 Step 451 Train Loss: 0.5192
Epoch 1 Step 501 Train Loss: 0.6075
Epoch 1 Step 551 Train Loss: 0.5513
Epoch 1 Step 601 Train Loss: 0.5659
Epoch 1 Step 651 Train Loss: 0.5260
Epoch 1 Step 701 Train Loss: 0.5687
Epoch 1 Step 751 Train Loss: 0.6144
Epoch 1 Step 801 Train Loss: 0.4824
Epoch 1 Step 851 Train Loss: 0.4577
Epoch 1 Step 901 Train Loss: 0.4980
Epoch 1 Step 951 Train Loss: 0.5492
Epoch 1 Step 1001 Train Loss: 0.5428
Epoch 1 Step 1051 Train Loss: 0.5555
Epoch 1 Step 1101 Train Loss: 0.4952
Epoch 1 Step 1151 Train Loss: 0.4617
Epoch 1 Step 1201 Train Loss: 0.4640
Epoch 1 Step 1251 Train Loss: 0.4305
Epoch 1 Step 1301 Train Loss: 0.4834
Epoch 1: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0931 Validation Top 20 DE MSE: 0.1532. 
Epoch 2 Step 1 Train Loss: 0.5173
Epoch 2 Step 51 Train Loss: 0.4560
Epoch 2 Step 101 Train Loss: 0.4474
Epoch 2 Step 151 Train Loss: 0.5198
Epoch 2 Step 201 Train Loss: 0.5684
Epoch 2 Step 251 Train Loss: 0.4878
Epoch 2 Step 301 Train Loss: 0.5582
Epoch 2 Step 351 Train Loss: 0.4497
Epoch 2 Step 401 Train Loss: 0.4579
Epoch 2 Step 451 Train Loss: 0.4607
Epoch 2 Step 501 Train Loss: 0.4243
Epoch 2 Step 551 Train Loss: 0.4869
Epoch 2 Step 601 Train Loss: 0.4884
Epoch 2 Step 651 Train Loss: 0.5120
Epoch 2 Step 701 Train Loss: 0.4612
Epoch 2 Step 751 Train Loss: 0.5601
Epoch 2 Step 801 Train Loss: 0.4830
Epoch 2 Step 851 Train Loss: 0.4760
Epoch 2 Step 901 Train Loss: 0.4773
Epoch 2 Step 951 Train Loss: 0.4641
Epoch 2 Step 1001 Train Loss: 0.5106
Epoch 2 Step 1051 Train Loss: 0.4461
Epoch 2 Step 1101 Train Loss: 0.5339
Epoch 2 Step 1151 Train Loss: 0.5266
Epoch 2 Step 1201 Train Loss: 0.5445
Epoch 2 Step 1251 Train Loss: 0.5038
Epoch 2 Step 1301 Train Loss: 0.4425
Epoch 2: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0752 Validation Top 20 DE MSE: 0.1412. 
Epoch 3 Step 1 Train Loss: 0.4476
Epoch 3 Step 51 Train Loss: 0.5594
Epoch 3 Step 101 Train Loss: 0.5549
Epoch 3 Step 151 Train Loss: 0.4635
Epoch 3 Step 201 Train Loss: 0.5270
Epoch 3 Step 251 Train Loss: 0.5186
Epoch 3 Step 301 Train Loss: 0.4797
Epoch 3 Step 351 Train Loss: 0.4715
Epoch 3 Step 401 Train Loss: 0.4985
Epoch 3 Step 451 Train Loss: 0.5468
Epoch 3 Step 501 Train Loss: 0.4947
Epoch 3 Step 551 Train Loss: 0.4687
Epoch 3 Step 601 Train Loss: 0.5186
Epoch 3 Step 651 Train Loss: 0.4807
Epoch 3 Step 701 Train Loss: 0.4777
Epoch 3 Step 751 Train Loss: 0.5094
Epoch 3 Step 801 Train Loss: 0.4963
Epoch 3 Step 851 Train Loss: 0.5218
Epoch 3 Step 901 Train Loss: 0.4931
Epoch 3 Step 951 Train Loss: 0.5223
Epoch 3 Step 1001 Train Loss: 0.4568
Epoch 3 Step 1051 Train Loss: 0.5038
Epoch 3 Step 1101 Train Loss: 0.4466
Epoch 3 Step 1151 Train Loss: 0.5563
Epoch 3 Step 1201 Train Loss: 0.4625
Epoch 3 Step 1251 Train Loss: 0.6196
Epoch 3 Step 1301 Train Loss: 0.5253
Epoch 3: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0715 Validation Top 20 DE MSE: 0.1575. 
Epoch 4 Step 1 Train Loss: 0.5123
Epoch 4 Step 51 Train Loss: 0.4950
Epoch 4 Step 101 Train Loss: 0.4429
Epoch 4 Step 151 Train Loss: 0.4605
Epoch 4 Step 201 Train Loss: 0.5111
Epoch 4 Step 251 Train Loss: 0.5000
Epoch 4 Step 301 Train Loss: 0.4916
Epoch 4 Step 351 Train Loss: 0.5078
Epoch 4 Step 401 Train Loss: 0.4647
Epoch 4 Step 451 Train Loss: 0.6948
Epoch 4 Step 501 Train Loss: 0.5082
Epoch 4 Step 551 Train Loss: 0.5243
Epoch 4 Step 601 Train Loss: 0.4964
Epoch 4 Step 651 Train Loss: 0.4457
Epoch 4 Step 701 Train Loss: 0.5241
Epoch 4 Step 751 Train Loss: 0.5188
Epoch 4 Step 801 Train Loss: 0.5278
Epoch 4 Step 851 Train Loss: 0.4477
Epoch 4 Step 901 Train Loss: 0.4890
Epoch 4 Step 951 Train Loss: 0.5560
Epoch 4 Step 1001 Train Loss: 0.5192
Epoch 4 Step 1051 Train Loss: 0.4870
Epoch 4 Step 1101 Train Loss: 0.4845
Epoch 4 Step 1151 Train Loss: 0.5730
Epoch 4 Step 1201 Train Loss: 0.5670
Epoch 4 Step 1251 Train Loss: 0.6077
Epoch 4 Step 1301 Train Loss: 0.5380
Epoch 4: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0856 Validation Top 20 DE MSE: 0.1695. 
Epoch 5 Step 1 Train Loss: 0.5294
Epoch 5 Step 51 Train Loss: 0.5110
Epoch 5 Step 101 Train Loss: 0.5630
Epoch 5 Step 151 Train Loss: 0.4683
Epoch 5 Step 201 Train Loss: 0.5206
Epoch 5 Step 251 Train Loss: 0.5079
Epoch 5 Step 301 Train Loss: 0.4593
Epoch 5 Step 351 Train Loss: 0.4444
Epoch 5 Step 401 Train Loss: 0.5055
Epoch 5 Step 451 Train Loss: 0.5939
Epoch 5 Step 501 Train Loss: 0.5066
Epoch 5 Step 551 Train Loss: 0.5754
Epoch 5 Step 601 Train Loss: 0.4808
Epoch 5 Step 651 Train Loss: 0.5880
Epoch 5 Step 701 Train Loss: 0.5307
Epoch 5 Step 751 Train Loss: 0.4729
Epoch 5 Step 801 Train Loss: 0.4651
Epoch 5 Step 851 Train Loss: 0.5381
Epoch 5 Step 901 Train Loss: 0.5403
Epoch 5 Step 951 Train Loss: 0.5173
Epoch 5 Step 1001 Train Loss: 0.5111
Epoch 5 Step 1051 Train Loss: 0.5184
Epoch 5 Step 1101 Train Loss: 0.5198
Epoch 5 Step 1151 Train Loss: 0.5047
Epoch 5 Step 1201 Train Loss: 0.5923
Epoch 5 Step 1251 Train Loss: 0.5240
Epoch 5 Step 1301 Train Loss: 0.4922
Epoch 5: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0734 Validation Top 20 DE MSE: 0.1618. 
Epoch 6 Step 1 Train Loss: 0.5875
Epoch 6 Step 51 Train Loss: 0.5465
Epoch 6 Step 101 Train Loss: 0.5776
Epoch 6 Step 151 Train Loss: 0.6619
Epoch 6 Step 201 Train Loss: 0.5213
Epoch 6 Step 251 Train Loss: 0.6157
Epoch 6 Step 301 Train Loss: 0.5603
Epoch 6 Step 351 Train Loss: 0.4945
Epoch 6 Step 401 Train Loss: 0.6180
Epoch 6 Step 451 Train Loss: 0.6351
Epoch 6 Step 501 Train Loss: 0.4782
Epoch 6 Step 551 Train Loss: 0.4391
Epoch 6 Step 601 Train Loss: 0.5678
Epoch 6 Step 651 Train Loss: 0.5700
Epoch 6 Step 701 Train Loss: 0.6064
Epoch 6 Step 751 Train Loss: 0.4956
Epoch 6 Step 801 Train Loss: 0.4858
Epoch 6 Step 851 Train Loss: 0.4885
Epoch 6 Step 901 Train Loss: 0.5641
Epoch 6 Step 951 Train Loss: 0.5684
Epoch 6 Step 1001 Train Loss: 0.5958
Epoch 6 Step 1051 Train Loss: 0.5504
Epoch 6 Step 1101 Train Loss: 0.5429
Epoch 6 Step 1151 Train Loss: 0.5014
Epoch 6 Step 1201 Train Loss: 0.5537
Epoch 6 Step 1251 Train Loss: 0.5537
Epoch 6 Step 1301 Train Loss: 0.5280
Epoch 6: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0740 Validation Top 20 DE MSE: 0.1599. 
Epoch 7 Step 1 Train Loss: 0.5465
Epoch 7 Step 51 Train Loss: 0.5730
Epoch 7 Step 101 Train Loss: 0.4941
Epoch 7 Step 151 Train Loss: 0.4661
Epoch 7 Step 201 Train Loss: 0.5282
Epoch 7 Step 251 Train Loss: 0.5307
Epoch 7 Step 301 Train Loss: 0.5681
Epoch 7 Step 351 Train Loss: 0.5102
Epoch 7 Step 401 Train Loss: 0.5062
Epoch 7 Step 451 Train Loss: 0.5158
Epoch 7 Step 501 Train Loss: 0.5468
Epoch 7 Step 551 Train Loss: 0.5176
Epoch 7 Step 601 Train Loss: 0.4575
Epoch 7 Step 651 Train Loss: 0.6094
Epoch 7 Step 701 Train Loss: 0.5029
Epoch 7 Step 751 Train Loss: 0.4467
Epoch 7 Step 801 Train Loss: 0.5743
Epoch 7 Step 851 Train Loss: 0.4793
Epoch 7 Step 901 Train Loss: 0.5061
Epoch 7 Step 951 Train Loss: 0.6335
Epoch 7 Step 1001 Train Loss: 0.5339
Epoch 7 Step 1051 Train Loss: 0.5279
Epoch 7 Step 1101 Train Loss: 0.4544
Epoch 7 Step 1151 Train Loss: 0.4913
Epoch 7 Step 1201 Train Loss: 0.5120
Epoch 7 Step 1251 Train Loss: 0.5330
Epoch 7 Step 1301 Train Loss: 0.5185
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0680 Validation Top 20 DE MSE: 0.1563. 
Epoch 8 Step 1 Train Loss: 0.6778
Epoch 8 Step 51 Train Loss: 0.5398
Epoch 8 Step 101 Train Loss: 0.4900
Epoch 8 Step 151 Train Loss: 0.5754
Epoch 8 Step 201 Train Loss: 0.5534
Epoch 8 Step 251 Train Loss: 0.6260
Epoch 8 Step 301 Train Loss: 0.5635
Epoch 8 Step 351 Train Loss: 0.5244
Epoch 8 Step 401 Train Loss: 0.4741
Epoch 8 Step 451 Train Loss: 0.5239
Epoch 8 Step 501 Train Loss: 0.5428
Epoch 8 Step 551 Train Loss: 0.5109
Epoch 8 Step 601 Train Loss: 0.4836
Epoch 8 Step 651 Train Loss: 0.4602
Epoch 8 Step 701 Train Loss: 0.4971
Epoch 8 Step 751 Train Loss: 0.5395
Epoch 8 Step 801 Train Loss: 0.4919
Epoch 8 Step 851 Train Loss: 0.5093
Epoch 8 Step 901 Train Loss: 0.5034
Epoch 8 Step 951 Train Loss: 0.5020
Epoch 8 Step 1001 Train Loss: 0.5986
Epoch 8 Step 1051 Train Loss: 0.5051
Epoch 8 Step 1101 Train Loss: 0.4773
Epoch 8 Step 1151 Train Loss: 0.4920
Epoch 8 Step 1201 Train Loss: 0.5630
Epoch 8 Step 1251 Train Loss: 0.4909
Epoch 8 Step 1301 Train Loss: 0.5317
Epoch 8: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0720 Validation Top 20 DE MSE: 0.1574. 
Epoch 9 Step 1 Train Loss: 0.4812
Epoch 9 Step 51 Train Loss: 0.4775
Epoch 9 Step 101 Train Loss: 0.5391
Epoch 9 Step 151 Train Loss: 0.5015
Epoch 9 Step 201 Train Loss: 0.5371
Epoch 9 Step 251 Train Loss: 0.5564
Epoch 9 Step 301 Train Loss: 0.5133
Epoch 9 Step 351 Train Loss: 0.5532
Epoch 9 Step 401 Train Loss: 0.5055
Epoch 9 Step 451 Train Loss: 0.5465
Epoch 9 Step 501 Train Loss: 0.4798
Epoch 9 Step 551 Train Loss: 0.5771
Epoch 9 Step 601 Train Loss: 0.4468
Epoch 9 Step 651 Train Loss: 0.6177
Epoch 9 Step 701 Train Loss: 0.4988
Epoch 9 Step 751 Train Loss: 0.4668
Epoch 9 Step 801 Train Loss: 0.5079
Epoch 9 Step 851 Train Loss: 0.5627
Epoch 9 Step 901 Train Loss: 0.5268
Epoch 9 Step 951 Train Loss: 0.4972
Epoch 9 Step 1001 Train Loss: 0.5120
Epoch 9 Step 1051 Train Loss: 0.4785
Epoch 9 Step 1101 Train Loss: 0.5205
Epoch 9 Step 1151 Train Loss: 0.4900
Epoch 9 Step 1201 Train Loss: 0.4873
Epoch 9 Step 1251 Train Loss: 0.4789
Epoch 9 Step 1301 Train Loss: 0.5808
Epoch 9: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0699 Validation Top 20 DE MSE: 0.1553. 
Epoch 10 Step 1 Train Loss: 0.4631
Epoch 10 Step 51 Train Loss: 0.4502
Epoch 10 Step 101 Train Loss: 0.5292
Epoch 10 Step 151 Train Loss: 0.5040
Epoch 10 Step 201 Train Loss: 0.5238
Epoch 10 Step 251 Train Loss: 0.5070
Epoch 10 Step 301 Train Loss: 0.5545
Epoch 10 Step 351 Train Loss: 0.5615
Epoch 10 Step 401 Train Loss: 0.5028
Epoch 10 Step 451 Train Loss: 0.5588
Epoch 10 Step 501 Train Loss: 0.5593
Epoch 10 Step 551 Train Loss: 0.4397
Epoch 10 Step 601 Train Loss: 0.5423
Epoch 10 Step 651 Train Loss: 0.5143
Epoch 10 Step 701 Train Loss: 0.5888
Epoch 10 Step 751 Train Loss: 0.5316
Epoch 10 Step 801 Train Loss: 0.4934
Epoch 10 Step 851 Train Loss: 0.5255
Epoch 10 Step 901 Train Loss: 0.6530
Epoch 10 Step 951 Train Loss: 0.4770
Epoch 10 Step 1001 Train Loss: 0.5658
Epoch 10 Step 1051 Train Loss: 0.4969
Epoch 10 Step 1101 Train Loss: 0.6531
Epoch 10 Step 1151 Train Loss: 0.5112
Epoch 10 Step 1201 Train Loss: 0.5007
Epoch 10 Step 1251 Train Loss: 0.4711
Epoch 10 Step 1301 Train Loss: 0.5091
Epoch 10: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0736 Validation Top 20 DE MSE: 0.1601. 
Epoch 11 Step 1 Train Loss: 0.5247
Epoch 11 Step 51 Train Loss: 0.4840
Epoch 11 Step 101 Train Loss: 0.5558
Epoch 11 Step 151 Train Loss: 0.5782
Epoch 11 Step 201 Train Loss: 0.5197
Epoch 11 Step 251 Train Loss: 0.5748
Epoch 11 Step 301 Train Loss: 0.6170
Epoch 11 Step 351 Train Loss: 0.5730
Epoch 11 Step 401 Train Loss: 0.5671
Epoch 11 Step 451 Train Loss: 0.5198
Epoch 11 Step 501 Train Loss: 0.4165
Epoch 11 Step 551 Train Loss: 0.5136
Epoch 11 Step 601 Train Loss: 0.5642
Epoch 11 Step 651 Train Loss: 0.4421
Epoch 11 Step 701 Train Loss: 0.5285
Epoch 11 Step 751 Train Loss: 0.5448
Epoch 11 Step 801 Train Loss: 0.5489
Epoch 11 Step 851 Train Loss: 0.4922
Epoch 11 Step 901 Train Loss: 0.5369
Epoch 11 Step 951 Train Loss: 0.6004
Epoch 11 Step 1001 Train Loss: 0.5120
Epoch 11 Step 1051 Train Loss: 0.5664
Epoch 11 Step 1101 Train Loss: 0.5034
Epoch 11 Step 1151 Train Loss: 0.5444
Epoch 11 Step 1201 Train Loss: 0.5666
Epoch 11 Step 1251 Train Loss: 0.5450
Epoch 11 Step 1301 Train Loss: 0.5253
Epoch 11: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0701 Validation Top 20 DE MSE: 0.1556. 
Epoch 12 Step 1 Train Loss: 0.5410
Epoch 12 Step 51 Train Loss: 0.5852
Epoch 12 Step 101 Train Loss: 0.4867
Epoch 12 Step 151 Train Loss: 0.5546
Epoch 12 Step 201 Train Loss: 0.5067
Epoch 12 Step 251 Train Loss: 0.5120
Epoch 12 Step 301 Train Loss: 0.5702
Epoch 12 Step 351 Train Loss: 0.4965
Epoch 12 Step 401 Train Loss: 0.5267
Epoch 12 Step 451 Train Loss: 0.5600
Epoch 12 Step 501 Train Loss: 0.4941
Epoch 12 Step 551 Train Loss: 0.5082
Epoch 12 Step 601 Train Loss: 0.5725
Epoch 12 Step 651 Train Loss: 0.5428
Epoch 12 Step 701 Train Loss: 0.4872
Epoch 12 Step 751 Train Loss: 0.6239
Epoch 12 Step 801 Train Loss: 0.5935
Epoch 12 Step 851 Train Loss: 0.5554
Epoch 12 Step 901 Train Loss: 0.5330
Epoch 12 Step 951 Train Loss: 0.6283
Epoch 12 Step 1001 Train Loss: 0.5481
Epoch 12 Step 1051 Train Loss: 0.5247
Epoch 12 Step 1101 Train Loss: 0.4818
Epoch 12 Step 1151 Train Loss: 0.5915
Epoch 12 Step 1201 Train Loss: 0.4877
Epoch 12 Step 1251 Train Loss: 0.5290
Epoch 12 Step 1301 Train Loss: 0.4847
Epoch 12: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0679 Validation Top 20 DE MSE: 0.1536. 
Epoch 13 Step 1 Train Loss: 0.5132
Epoch 13 Step 51 Train Loss: 0.5931
Epoch 13 Step 101 Train Loss: 0.5158
Epoch 13 Step 151 Train Loss: 0.4775
Epoch 13 Step 201 Train Loss: 0.5301
Epoch 13 Step 251 Train Loss: 0.5030
Epoch 13 Step 301 Train Loss: 0.4678
Epoch 13 Step 351 Train Loss: 0.4924
Epoch 13 Step 401 Train Loss: 0.5314
Epoch 13 Step 451 Train Loss: 0.5266
Epoch 13 Step 501 Train Loss: 0.4843
Epoch 13 Step 551 Train Loss: 0.5015
Epoch 13 Step 601 Train Loss: 0.5839
Epoch 13 Step 651 Train Loss: 0.5314
Epoch 13 Step 701 Train Loss: 0.4736
Epoch 13 Step 751 Train Loss: 0.6471
Epoch 13 Step 801 Train Loss: 0.5277
Epoch 13 Step 851 Train Loss: 0.5332
Epoch 13 Step 901 Train Loss: 0.4780
Epoch 13 Step 951 Train Loss: 0.5546
Epoch 13 Step 1001 Train Loss: 0.5809
Epoch 13 Step 1051 Train Loss: 0.4967
Epoch 13 Step 1101 Train Loss: 0.5247
Epoch 13 Step 1151 Train Loss: 0.5679
Epoch 13 Step 1201 Train Loss: 0.4990
Epoch 13 Step 1251 Train Loss: 0.5409
Epoch 13 Step 1301 Train Loss: 0.5330
Epoch 13: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0734 Validation Top 20 DE MSE: 0.1602. 
Epoch 14 Step 1 Train Loss: 0.4852
Epoch 14 Step 51 Train Loss: 0.4911
Epoch 14 Step 101 Train Loss: 0.5223
Epoch 14 Step 151 Train Loss: 0.5978
Epoch 14 Step 201 Train Loss: 0.6198
Epoch 14 Step 251 Train Loss: 0.5003
Epoch 14 Step 301 Train Loss: 0.5276
Epoch 14 Step 351 Train Loss: 0.4526
Epoch 14 Step 401 Train Loss: 0.5698
Epoch 14 Step 451 Train Loss: 0.4947
Epoch 14 Step 501 Train Loss: 0.4728
Epoch 14 Step 551 Train Loss: 0.5858
Epoch 14 Step 601 Train Loss: 0.4804
Epoch 14 Step 651 Train Loss: 0.5205
Epoch 14 Step 701 Train Loss: 0.5567
Epoch 14 Step 751 Train Loss: 0.5313
Epoch 14 Step 801 Train Loss: 0.4989
Epoch 14 Step 851 Train Loss: 0.4940
Epoch 14 Step 901 Train Loss: 0.5862
Epoch 14 Step 951 Train Loss: 0.4623
Epoch 14 Step 1001 Train Loss: 0.4794
Epoch 14 Step 1051 Train Loss: 0.5043
Epoch 14 Step 1101 Train Loss: 0.5781
Epoch 14 Step 1151 Train Loss: 0.6637
Epoch 14 Step 1201 Train Loss: 0.4719
Epoch 14 Step 1251 Train Loss: 0.5023
Epoch 14 Step 1301 Train Loss: 0.5167
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0696 Validation Top 20 DE MSE: 0.1576. 
Epoch 15 Step 1 Train Loss: 0.5929
Epoch 15 Step 51 Train Loss: 0.5085
Epoch 15 Step 101 Train Loss: 0.5015
Epoch 15 Step 151 Train Loss: 0.4836
Epoch 15 Step 201 Train Loss: 0.5442
Epoch 15 Step 251 Train Loss: 0.5030
Epoch 15 Step 301 Train Loss: 0.6049
Epoch 15 Step 351 Train Loss: 0.5295
Epoch 15 Step 401 Train Loss: 0.5207
Epoch 15 Step 451 Train Loss: 0.5143
Epoch 15 Step 501 Train Loss: 0.5283
Epoch 15 Step 551 Train Loss: 0.4876
Epoch 15 Step 601 Train Loss: 0.4456
Epoch 15 Step 651 Train Loss: 0.4807
Epoch 15 Step 701 Train Loss: 0.5189
Epoch 15 Step 751 Train Loss: 0.5076
Epoch 15 Step 801 Train Loss: 0.5084
Epoch 15 Step 851 Train Loss: 0.5069
Epoch 15 Step 901 Train Loss: 0.5575
Epoch 15 Step 951 Train Loss: 0.5586
Epoch 15 Step 1001 Train Loss: 0.5437
Epoch 15 Step 1051 Train Loss: 0.5449
Epoch 15 Step 1101 Train Loss: 0.5180
Epoch 15 Step 1151 Train Loss: 0.5418
Epoch 15 Step 1201 Train Loss: 0.5270
Epoch 15 Step 1251 Train Loss: 0.5587
Epoch 15 Step 1301 Train Loss: 0.4909
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0699 Validation Top 20 DE MSE: 0.1544. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1381
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.003556051
test_unseen_single_pearson: 0.9932265912504704
test_unseen_single_mse_de: 0.13806516
test_unseen_single_pearson_de: 0.8562558659318976
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3309654713728842
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.27499999999999997
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8704545454545454
test_unseen_single_mse_top20_de_non_dropout: 0.14148813
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.032 MB uploadedwandb: | 0.001 MB of 0.032 MB uploadedwandb: / 0.025 MB of 0.032 MB uploadedwandb: - 0.025 MB of 0.032 MB uploadedwandb: \ 0.032 MB of 0.032 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñá‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá
wandb:                                                    train_mse ‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÑ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ
wandb:                                                   val_de_mse ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ
wandb:                                               val_de_pearson ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ
wandb:                                                      val_mse ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÜ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.13807
wandb:                                              test_de_pearson 0.85626
wandb:               test_frac_opposite_direction_top20_non_dropout 0.275
wandb:                          test_frac_sigma_below_1_non_dropout 0.87045
wandb:                                                     test_mse 0.00356
wandb:                                test_mse_top20_de_non_dropout 0.14149
wandb:                                                 test_pearson 0.99323
wandb:                                           test_pearson_delta 0.33097
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.275
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.87045
wandb:                                       test_unseen_single_mse 0.00356
wandb:                                    test_unseen_single_mse_de 0.13807
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.14149
wandb:                                   test_unseen_single_pearson 0.99323
wandb:                                test_unseen_single_pearson_de 0.85626
wandb:                             test_unseen_single_pearson_delta 0.33097
wandb:                                                 train_de_mse 0.0699
wandb:                                             train_de_pearson 0.91071
wandb:                                                    train_mse 0.00174
wandb:                                                train_pearson 0.99678
wandb:                                                training_loss 0.5278
wandb:                                                   val_de_mse 0.15439
wandb:                                               val_de_pearson 0.96607
wandb:                                                      val_mse 0.00207
wandb:                                                  val_pearson 0.99609
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406681_3_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/nfxn3bg0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_182759-nfxn3bg0/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:22
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_190723-ahc1vrq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406681_3_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/ahc1vrq9
wandb: WARNING Serializing object of type ndarray that is 8100928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5000
Epoch 1 Step 51 Train Loss: 0.5712
Epoch 1 Step 101 Train Loss: 0.5921
Epoch 1 Step 151 Train Loss: 0.5659
Epoch 1 Step 201 Train Loss: 0.5080
Epoch 1 Step 251 Train Loss: 0.5112
Epoch 1 Step 301 Train Loss: 0.4588
Epoch 1 Step 351 Train Loss: 0.5178
Epoch 1 Step 401 Train Loss: 0.5339
Epoch 1 Step 451 Train Loss: 0.5284
Epoch 1 Step 501 Train Loss: 0.5327
Epoch 1 Step 551 Train Loss: 0.5162
Epoch 1 Step 601 Train Loss: 0.5262
Epoch 1 Step 651 Train Loss: 0.5070
Epoch 1 Step 701 Train Loss: 0.5270
Epoch 1 Step 751 Train Loss: 0.5448
Epoch 1 Step 801 Train Loss: 0.5920
Epoch 1 Step 851 Train Loss: 0.4837
Epoch 1 Step 901 Train Loss: 0.5316
Epoch 1 Step 951 Train Loss: 0.5445
Epoch 1 Step 1001 Train Loss: 0.5171
Epoch 1 Step 1051 Train Loss: 0.5268
Epoch 1 Step 1101 Train Loss: 0.5526
Epoch 1 Step 1151 Train Loss: 0.5057
Epoch 1 Step 1201 Train Loss: 0.5455
Epoch 1: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0890 Validation Top 20 DE MSE: 0.0990. 
Epoch 2 Step 1 Train Loss: 0.4904
Epoch 2 Step 51 Train Loss: 0.5002
Epoch 2 Step 101 Train Loss: 0.5424
Epoch 2 Step 151 Train Loss: 0.5772
Epoch 2 Step 201 Train Loss: 0.4993
Epoch 2 Step 251 Train Loss: 0.5139
Epoch 2 Step 301 Train Loss: 0.4334
Epoch 2 Step 351 Train Loss: 0.4708
Epoch 2 Step 401 Train Loss: 0.4971
Epoch 2 Step 451 Train Loss: 0.5229
Epoch 2 Step 501 Train Loss: 0.6063
Epoch 2 Step 551 Train Loss: 0.4444
Epoch 2 Step 601 Train Loss: 0.4829
Epoch 2 Step 651 Train Loss: 0.5125
Epoch 2 Step 701 Train Loss: 0.4569
Epoch 2 Step 751 Train Loss: 0.4779
Epoch 2 Step 801 Train Loss: 0.4886
Epoch 2 Step 851 Train Loss: 0.4879
Epoch 2 Step 901 Train Loss: 0.5152
Epoch 2 Step 951 Train Loss: 0.5324
Epoch 2 Step 1001 Train Loss: 0.4880
Epoch 2 Step 1051 Train Loss: 0.4345
Epoch 2 Step 1101 Train Loss: 0.5426
Epoch 2 Step 1151 Train Loss: 0.5421
Epoch 2 Step 1201 Train Loss: 0.5061
Epoch 2: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0842 Validation Top 20 DE MSE: 0.1176. 
Epoch 3 Step 1 Train Loss: 0.4757
Epoch 3 Step 51 Train Loss: 0.4691
Epoch 3 Step 101 Train Loss: 0.4788
Epoch 3 Step 151 Train Loss: 0.4805
Epoch 3 Step 201 Train Loss: 0.4983
Epoch 3 Step 251 Train Loss: 0.5832
Epoch 3 Step 301 Train Loss: 0.5018
Epoch 3 Step 351 Train Loss: 0.5013
Epoch 3 Step 401 Train Loss: 0.4484
Epoch 3 Step 451 Train Loss: 0.4587
Epoch 3 Step 501 Train Loss: 0.5114
Epoch 3 Step 551 Train Loss: 0.5624
Epoch 3 Step 601 Train Loss: 0.5117
Epoch 3 Step 651 Train Loss: 0.5438
Epoch 3 Step 701 Train Loss: 0.4745
Epoch 3 Step 751 Train Loss: 0.4773
Epoch 3 Step 801 Train Loss: 0.5276
Epoch 3 Step 851 Train Loss: 0.4803
Epoch 3 Step 901 Train Loss: 0.6270
Epoch 3 Step 951 Train Loss: 0.5329
Epoch 3 Step 1001 Train Loss: 0.5157
Epoch 3 Step 1051 Train Loss: 0.4606
Epoch 3 Step 1101 Train Loss: 0.5123
Epoch 3 Step 1151 Train Loss: 0.4902
Epoch 3 Step 1201 Train Loss: 0.4531
Epoch 3: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0765 Validation Top 20 DE MSE: 0.1023. 
Epoch 4 Step 1 Train Loss: 0.4702
Epoch 4 Step 51 Train Loss: 0.6687
Epoch 4 Step 101 Train Loss: 0.4582
Epoch 4 Step 151 Train Loss: 0.5243
Epoch 4 Step 201 Train Loss: 0.5554
Epoch 4 Step 251 Train Loss: 0.4896
Epoch 4 Step 301 Train Loss: 0.6111
Epoch 4 Step 351 Train Loss: 0.5453
Epoch 4 Step 401 Train Loss: 0.5298
Epoch 4 Step 451 Train Loss: 0.5800
Epoch 4 Step 501 Train Loss: 0.5322
Epoch 4 Step 551 Train Loss: 0.4294
Epoch 4 Step 601 Train Loss: 0.5026
Epoch 4 Step 651 Train Loss: 0.5192
Epoch 4 Step 701 Train Loss: 0.5205
Epoch 4 Step 751 Train Loss: 0.4395
Epoch 4 Step 801 Train Loss: 0.5122
Epoch 4 Step 851 Train Loss: 0.5373
Epoch 4 Step 901 Train Loss: 0.5627
Epoch 4 Step 951 Train Loss: 0.6043
Epoch 4 Step 1001 Train Loss: 0.4574
Epoch 4 Step 1051 Train Loss: 0.4310
Epoch 4 Step 1101 Train Loss: 0.5015
Epoch 4 Step 1151 Train Loss: 0.4797
Epoch 4 Step 1201 Train Loss: 0.5935
Epoch 4: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0698 Validation Top 20 DE MSE: 0.1046. 
Epoch 5 Step 1 Train Loss: 0.4911
Epoch 5 Step 51 Train Loss: 0.4636
Epoch 5 Step 101 Train Loss: 0.5922
Epoch 5 Step 151 Train Loss: 0.5635
Epoch 5 Step 201 Train Loss: 0.5472
Epoch 5 Step 251 Train Loss: 0.5184
Epoch 5 Step 301 Train Loss: 0.4603
Epoch 5 Step 351 Train Loss: 0.5367
Epoch 5 Step 401 Train Loss: 0.4892
Epoch 5 Step 451 Train Loss: 0.4999
Epoch 5 Step 501 Train Loss: 0.5452
Epoch 5 Step 551 Train Loss: 0.4385
Epoch 5 Step 601 Train Loss: 0.4879
Epoch 5 Step 651 Train Loss: 0.4721
Epoch 5 Step 701 Train Loss: 0.5361
Epoch 5 Step 751 Train Loss: 0.5177
Epoch 5 Step 801 Train Loss: 0.5230
Epoch 5 Step 851 Train Loss: 0.4641
Epoch 5 Step 901 Train Loss: 0.4631
Epoch 5 Step 951 Train Loss: 0.5533
Epoch 5 Step 1001 Train Loss: 0.5241
Epoch 5 Step 1051 Train Loss: 0.6202
Epoch 5 Step 1101 Train Loss: 0.4863
Epoch 5 Step 1151 Train Loss: 0.5216
Epoch 5 Step 1201 Train Loss: 0.4812
Epoch 5: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0637 Validation Top 20 DE MSE: 0.0997. 
Epoch 6 Step 1 Train Loss: 0.6262
Epoch 6 Step 51 Train Loss: 0.6434
Epoch 6 Step 101 Train Loss: 0.5193
Epoch 6 Step 151 Train Loss: 0.5535
Epoch 6 Step 201 Train Loss: 0.5889
Epoch 6 Step 251 Train Loss: 0.5569
Epoch 6 Step 301 Train Loss: 0.5468
Epoch 6 Step 351 Train Loss: 0.4765
Epoch 6 Step 401 Train Loss: 0.5176
Epoch 6 Step 451 Train Loss: 0.4719
Epoch 6 Step 501 Train Loss: 0.5265
Epoch 6 Step 551 Train Loss: 0.5721
Epoch 6 Step 601 Train Loss: 0.5653
Epoch 6 Step 651 Train Loss: 0.5167
Epoch 6 Step 701 Train Loss: 0.4807
Epoch 6 Step 751 Train Loss: 0.5012
Epoch 6 Step 801 Train Loss: 0.5138
Epoch 6 Step 851 Train Loss: 0.5078
Epoch 6 Step 901 Train Loss: 0.5799
Epoch 6 Step 951 Train Loss: 0.4325
Epoch 6 Step 1001 Train Loss: 0.4739
Epoch 6 Step 1051 Train Loss: 0.6331
Epoch 6 Step 1101 Train Loss: 0.5057
Epoch 6 Step 1151 Train Loss: 0.5517
Epoch 6 Step 1201 Train Loss: 0.5070
Epoch 6: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0671 Validation Top 20 DE MSE: 0.1070. 
Epoch 7 Step 1 Train Loss: 0.4725
Epoch 7 Step 51 Train Loss: 0.4907
Epoch 7 Step 101 Train Loss: 0.5425
Epoch 7 Step 151 Train Loss: 0.5143
Epoch 7 Step 201 Train Loss: 0.5546
Epoch 7 Step 251 Train Loss: 0.4592
Epoch 7 Step 301 Train Loss: 0.5247
Epoch 7 Step 351 Train Loss: 0.5399
Epoch 7 Step 401 Train Loss: 0.5186
Epoch 7 Step 451 Train Loss: 0.5542
Epoch 7 Step 501 Train Loss: 0.5699
Epoch 7 Step 551 Train Loss: 0.5344
Epoch 7 Step 601 Train Loss: 0.4337
Epoch 7 Step 651 Train Loss: 0.5264
Epoch 7 Step 701 Train Loss: 0.6383
Epoch 7 Step 751 Train Loss: 0.4561
Epoch 7 Step 801 Train Loss: 0.5943
Epoch 7 Step 851 Train Loss: 0.5013
Epoch 7 Step 901 Train Loss: 0.5771
Epoch 7 Step 951 Train Loss: 0.5243
Epoch 7 Step 1001 Train Loss: 0.5194
Epoch 7 Step 1051 Train Loss: 0.4979
Epoch 7 Step 1101 Train Loss: 0.4973
Epoch 7 Step 1151 Train Loss: 0.4776
Epoch 7 Step 1201 Train Loss: 0.5419
Epoch 7: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0627 Validation Top 20 DE MSE: 0.0986. 
Epoch 8 Step 1 Train Loss: 0.5671
Epoch 8 Step 51 Train Loss: 0.5314
Epoch 8 Step 101 Train Loss: 0.5328
Epoch 8 Step 151 Train Loss: 0.5086
Epoch 8 Step 201 Train Loss: 0.4901
Epoch 8 Step 251 Train Loss: 0.5199
Epoch 8 Step 301 Train Loss: 0.4848
Epoch 8 Step 351 Train Loss: 0.4866
Epoch 8 Step 401 Train Loss: 0.5076
Epoch 8 Step 451 Train Loss: 0.5803
Epoch 8 Step 501 Train Loss: 0.5210
Epoch 8 Step 551 Train Loss: 0.4866
Epoch 8 Step 601 Train Loss: 0.5415
Epoch 8 Step 651 Train Loss: 0.4805
Epoch 8 Step 701 Train Loss: 0.5306
Epoch 8 Step 751 Train Loss: 0.5032
Epoch 8 Step 801 Train Loss: 0.5680
Epoch 8 Step 851 Train Loss: 0.4769
Epoch 8 Step 901 Train Loss: 0.5164
Epoch 8 Step 951 Train Loss: 0.5348
Epoch 8 Step 1001 Train Loss: 0.4368
Epoch 8 Step 1051 Train Loss: 0.5059
Epoch 8 Step 1101 Train Loss: 0.5872
Epoch 8 Step 1151 Train Loss: 0.5808
Epoch 8 Step 1201 Train Loss: 0.5278
Epoch 8: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0615 Validation Top 20 DE MSE: 0.0995. 
Epoch 9 Step 1 Train Loss: 0.5177
Epoch 9 Step 51 Train Loss: 0.5528
Epoch 9 Step 101 Train Loss: 0.6306
Epoch 9 Step 151 Train Loss: 0.5166
Epoch 9 Step 201 Train Loss: 0.5421
Epoch 9 Step 251 Train Loss: 0.5348
Epoch 9 Step 301 Train Loss: 0.5009
Epoch 9 Step 351 Train Loss: 0.4911
Epoch 9 Step 401 Train Loss: 0.5244
Epoch 9 Step 451 Train Loss: 0.4746
Epoch 9 Step 501 Train Loss: 0.5326
Epoch 9 Step 551 Train Loss: 0.5402
Epoch 9 Step 601 Train Loss: 0.6190
Epoch 9 Step 651 Train Loss: 0.5446
Epoch 9 Step 701 Train Loss: 0.5298
Epoch 9 Step 751 Train Loss: 0.5056
Epoch 9 Step 801 Train Loss: 0.5229
Epoch 9 Step 851 Train Loss: 0.5777
Epoch 9 Step 901 Train Loss: 0.4773
Epoch 9 Step 951 Train Loss: 0.5417
Epoch 9 Step 1001 Train Loss: 0.5273
Epoch 9 Step 1051 Train Loss: 0.5818
Epoch 9 Step 1101 Train Loss: 0.4497
Epoch 9 Step 1151 Train Loss: 0.6480
Epoch 9 Step 1201 Train Loss: 0.4751
Epoch 9: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0629 Validation Top 20 DE MSE: 0.1016. 
Epoch 10 Step 1 Train Loss: 0.5185
Epoch 10 Step 51 Train Loss: 0.4873
Epoch 10 Step 101 Train Loss: 0.5243
Epoch 10 Step 151 Train Loss: 0.5589
Epoch 10 Step 201 Train Loss: 0.5461
Epoch 10 Step 251 Train Loss: 0.4631
Epoch 10 Step 301 Train Loss: 0.5572
Epoch 10 Step 351 Train Loss: 0.4659
Epoch 10 Step 401 Train Loss: 0.4838
Epoch 10 Step 451 Train Loss: 0.5083
Epoch 10 Step 501 Train Loss: 0.5039
Epoch 10 Step 551 Train Loss: 0.6694
Epoch 10 Step 601 Train Loss: 0.4701
Epoch 10 Step 651 Train Loss: 0.5201
Epoch 10 Step 701 Train Loss: 0.5542
Epoch 10 Step 751 Train Loss: 0.5226
Epoch 10 Step 801 Train Loss: 0.5470
Epoch 10 Step 851 Train Loss: 0.4848
Epoch 10 Step 901 Train Loss: 0.4825
Epoch 10 Step 951 Train Loss: 0.5251
Epoch 10 Step 1001 Train Loss: 0.4660
Epoch 10 Step 1051 Train Loss: 0.5064
Epoch 10 Step 1101 Train Loss: 0.6190
Epoch 10 Step 1151 Train Loss: 0.5334
Epoch 10 Step 1201 Train Loss: 0.5368
Epoch 10: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0659 Validation Top 20 DE MSE: 0.1092. 
Epoch 11 Step 1 Train Loss: 0.5137
Epoch 11 Step 51 Train Loss: 0.6149
Epoch 11 Step 101 Train Loss: 0.6352
Epoch 11 Step 151 Train Loss: 0.4970
Epoch 11 Step 201 Train Loss: 0.5224
Epoch 11 Step 251 Train Loss: 0.5592
Epoch 11 Step 301 Train Loss: 0.6191
Epoch 11 Step 351 Train Loss: 0.5919
Epoch 11 Step 401 Train Loss: 0.4595
Epoch 11 Step 451 Train Loss: 0.5303
Epoch 11 Step 501 Train Loss: 0.5351
Epoch 11 Step 551 Train Loss: 0.5210
Epoch 11 Step 601 Train Loss: 0.4841
Epoch 11 Step 651 Train Loss: 0.5163
Epoch 11 Step 701 Train Loss: 0.6010
Epoch 11 Step 751 Train Loss: 0.5447
Epoch 11 Step 801 Train Loss: 0.4576
Epoch 11 Step 851 Train Loss: 0.5034
Epoch 11 Step 901 Train Loss: 0.5316
Epoch 11 Step 951 Train Loss: 0.5434
Epoch 11 Step 1001 Train Loss: 0.5320
Epoch 11 Step 1051 Train Loss: 0.5599
Epoch 11 Step 1101 Train Loss: 0.5172
Epoch 11 Step 1151 Train Loss: 0.4811
Epoch 11 Step 1201 Train Loss: 0.5717
Epoch 11: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0615 Validation Top 20 DE MSE: 0.0987. 
Epoch 12 Step 1 Train Loss: 0.5981
Epoch 12 Step 51 Train Loss: 0.4812
Epoch 12 Step 101 Train Loss: 0.5053
Epoch 12 Step 151 Train Loss: 0.5070
Epoch 12 Step 201 Train Loss: 0.6230
Epoch 12 Step 251 Train Loss: 0.4866
Epoch 12 Step 301 Train Loss: 0.5926
Epoch 12 Step 351 Train Loss: 0.5323
Epoch 12 Step 401 Train Loss: 0.5143
Epoch 12 Step 451 Train Loss: 0.4808
Epoch 12 Step 501 Train Loss: 0.5581
Epoch 12 Step 551 Train Loss: 0.5307
Epoch 12 Step 601 Train Loss: 0.4703
Epoch 12 Step 651 Train Loss: 0.5376
Epoch 12 Step 701 Train Loss: 0.4476
Epoch 12 Step 751 Train Loss: 0.5755
Epoch 12 Step 801 Train Loss: 0.4814
Epoch 12 Step 851 Train Loss: 0.5069
Epoch 12 Step 901 Train Loss: 0.5134
Epoch 12 Step 951 Train Loss: 0.5739
Epoch 12 Step 1001 Train Loss: 0.5590
Epoch 12 Step 1051 Train Loss: 0.5411
Epoch 12 Step 1101 Train Loss: 0.5124
Epoch 12 Step 1151 Train Loss: 0.6514
Epoch 12 Step 1201 Train Loss: 0.5009
Epoch 12: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0675 Validation Top 20 DE MSE: 0.1091. 
Epoch 13 Step 1 Train Loss: 0.4880
Epoch 13 Step 51 Train Loss: 0.5728
Epoch 13 Step 101 Train Loss: 0.4406
Epoch 13 Step 151 Train Loss: 0.4683
Epoch 13 Step 201 Train Loss: 0.6124
Epoch 13 Step 251 Train Loss: 0.4652
Epoch 13 Step 301 Train Loss: 0.5023
Epoch 13 Step 351 Train Loss: 0.5618
Epoch 13 Step 401 Train Loss: 0.5006
Epoch 13 Step 451 Train Loss: 0.5307
Epoch 13 Step 501 Train Loss: 0.4738
Epoch 13 Step 551 Train Loss: 0.4552
Epoch 13 Step 601 Train Loss: 0.5192
Epoch 13 Step 651 Train Loss: 0.5221
Epoch 13 Step 701 Train Loss: 0.5347
Epoch 13 Step 751 Train Loss: 0.6233
Epoch 13 Step 801 Train Loss: 0.6559
Epoch 13 Step 851 Train Loss: 0.5619
Epoch 13 Step 901 Train Loss: 0.5286
Epoch 13 Step 951 Train Loss: 0.5711
Epoch 13 Step 1001 Train Loss: 0.5870
Epoch 13 Step 1051 Train Loss: 0.5781
Epoch 13 Step 1101 Train Loss: 0.6105
Epoch 13 Step 1151 Train Loss: 0.5752
Epoch 13 Step 1201 Train Loss: 0.5154
Epoch 13: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0580 Validation Top 20 DE MSE: 0.0956. 
Epoch 14 Step 1 Train Loss: 0.5262
Epoch 14 Step 51 Train Loss: 0.5385
Epoch 14 Step 101 Train Loss: 0.4745
Epoch 14 Step 151 Train Loss: 0.4632
Epoch 14 Step 201 Train Loss: 0.5153
Epoch 14 Step 251 Train Loss: 0.5795
Epoch 14 Step 301 Train Loss: 0.4358
Epoch 14 Step 351 Train Loss: 0.5811
Epoch 14 Step 401 Train Loss: 0.4760
Epoch 14 Step 451 Train Loss: 0.4774
Epoch 14 Step 501 Train Loss: 0.5156
Epoch 14 Step 551 Train Loss: 0.5128
Epoch 14 Step 601 Train Loss: 0.4902
Epoch 14 Step 651 Train Loss: 0.5618
Epoch 14 Step 701 Train Loss: 0.5945
Epoch 14 Step 751 Train Loss: 0.5834
Epoch 14 Step 801 Train Loss: 0.4843
Epoch 14 Step 851 Train Loss: 0.4554
Epoch 14 Step 901 Train Loss: 0.4945
Epoch 14 Step 951 Train Loss: 0.5023
Epoch 14 Step 1001 Train Loss: 0.5257
Epoch 14 Step 1051 Train Loss: 0.6017
Epoch 14 Step 1101 Train Loss: 0.5663
Epoch 14 Step 1151 Train Loss: 0.5114
Epoch 14 Step 1201 Train Loss: 0.5670
Epoch 14: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0641 Validation Top 20 DE MSE: 0.1005. 
Epoch 15 Step 1 Train Loss: 0.5242
Epoch 15 Step 51 Train Loss: 0.5251
Epoch 15 Step 101 Train Loss: 0.4571
Epoch 15 Step 151 Train Loss: 0.4600
Epoch 15 Step 201 Train Loss: 0.5212
Epoch 15 Step 251 Train Loss: 0.5993
Epoch 15 Step 301 Train Loss: 0.5233
Epoch 15 Step 351 Train Loss: 0.4901
Epoch 15 Step 401 Train Loss: 0.5177
Epoch 15 Step 451 Train Loss: 0.4831
Epoch 15 Step 501 Train Loss: 0.5801
Epoch 15 Step 551 Train Loss: 0.5107
Epoch 15 Step 601 Train Loss: 0.5144
Epoch 15 Step 651 Train Loss: 0.5206
Epoch 15 Step 701 Train Loss: 0.5308
Epoch 15 Step 751 Train Loss: 0.7152
Epoch 15 Step 801 Train Loss: 0.4619
Epoch 15 Step 851 Train Loss: 0.4665
Epoch 15 Step 901 Train Loss: 0.5717
Epoch 15 Step 951 Train Loss: 0.5308
Epoch 15 Step 1001 Train Loss: 0.5855
Epoch 15 Step 1051 Train Loss: 0.5005
Epoch 15 Step 1101 Train Loss: 0.6478
Epoch 15 Step 1151 Train Loss: 0.5571
Epoch 15 Step 1201 Train Loss: 0.4652
Epoch 15: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0639 Validation Top 20 DE MSE: 0.1035. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1433
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0026559038
test_unseen_single_pearson: 0.9949601476962395
test_unseen_single_mse_de: 0.14325003
test_unseen_single_pearson_de: 0.9184437617556934
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.43592857047487166
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.26590909090909093
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8840909090909089
test_unseen_single_mse_top20_de_non_dropout: 0.14629452
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.031 MB uploadedwandb: | 0.003 MB of 0.031 MB uploadedwandb: / 0.027 MB of 0.031 MB uploadedwandb: - 0.027 MB of 0.031 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñÇ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÑ
wandb:                                               val_de_pearson ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñà‚ñá‚ñÜ
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.14325
wandb:                                              test_de_pearson 0.91844
wandb:               test_frac_opposite_direction_top20_non_dropout 0.26591
wandb:                          test_frac_sigma_below_1_non_dropout 0.88409
wandb:                                                     test_mse 0.00266
wandb:                                test_mse_top20_de_non_dropout 0.14629
wandb:                                                 test_pearson 0.99496
wandb:                                           test_pearson_delta 0.43593
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.26591
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.88409
wandb:                                       test_unseen_single_mse 0.00266
wandb:                                    test_unseen_single_mse_de 0.14325
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.14629
wandb:                                   test_unseen_single_pearson 0.99496
wandb:                                test_unseen_single_pearson_de 0.91844
wandb:                             test_unseen_single_pearson_delta 0.43593
wandb:                                                 train_de_mse 0.0639
wandb:                                             train_de_pearson 0.89227
wandb:                                                    train_mse 0.00182
wandb:                                                train_pearson 0.9966
wandb:                                                training_loss 0.49235
wandb:                                                   val_de_mse 0.10351
wandb:                                               val_de_pearson 0.96672
wandb:                                                      val_mse 0.00163
wandb:                                                  val_pearson 0.99689
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406681_3_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/ahc1vrq9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_190723-ahc1vrq9/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:22
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_194548-oj7w08li
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406681_3_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/oj7w08li
wandb: WARNING Serializing object of type ndarray that is 8100928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.5630
Epoch 1 Step 51 Train Loss: 0.5147
Epoch 1 Step 101 Train Loss: 0.5317
Epoch 1 Step 151 Train Loss: 0.5026
Epoch 1 Step 201 Train Loss: 0.5193
Epoch 1 Step 251 Train Loss: 0.6010
Epoch 1 Step 301 Train Loss: 0.6367
Epoch 1 Step 351 Train Loss: 0.5630
Epoch 1 Step 401 Train Loss: 0.4792
Epoch 1 Step 451 Train Loss: 0.4858
Epoch 1 Step 501 Train Loss: 0.5270
Epoch 1 Step 551 Train Loss: 0.5881
Epoch 1 Step 601 Train Loss: 0.4667
Epoch 1 Step 651 Train Loss: 0.6273
Epoch 1 Step 701 Train Loss: 0.5210
Epoch 1 Step 751 Train Loss: 0.5250
Epoch 1 Step 801 Train Loss: 0.4814
Epoch 1 Step 851 Train Loss: 0.4760
Epoch 1 Step 901 Train Loss: 0.4925
Epoch 1 Step 951 Train Loss: 0.5161
Epoch 1 Step 1001 Train Loss: 0.5164
Epoch 1 Step 1051 Train Loss: 0.5320
Epoch 1 Step 1101 Train Loss: 0.4929
Epoch 1 Step 1151 Train Loss: 0.4974
Epoch 1 Step 1201 Train Loss: 0.4788
Epoch 1: Train Overall MSE: 0.0232 Validation Overall MSE: 0.0205. 
Train Top 20 DE MSE: 0.2419 Validation Top 20 DE MSE: 0.1220. 
Epoch 2 Step 1 Train Loss: 0.5268
Epoch 2 Step 51 Train Loss: 0.4580
Epoch 2 Step 101 Train Loss: 0.4766
Epoch 2 Step 151 Train Loss: 0.4946
Epoch 2 Step 201 Train Loss: 0.4545
Epoch 2 Step 251 Train Loss: 0.5274
Epoch 2 Step 301 Train Loss: 0.5005
Epoch 2 Step 351 Train Loss: 0.5674
Epoch 2 Step 401 Train Loss: 0.4202
Epoch 2 Step 451 Train Loss: 0.5528
Epoch 2 Step 501 Train Loss: 0.4689
Epoch 2 Step 551 Train Loss: 0.4753
Epoch 2 Step 601 Train Loss: 0.5762
Epoch 2 Step 651 Train Loss: 0.5548
Epoch 2 Step 701 Train Loss: 0.5163
Epoch 2 Step 751 Train Loss: 0.5152
Epoch 2 Step 801 Train Loss: 0.4699
Epoch 2 Step 851 Train Loss: 0.4570
Epoch 2 Step 901 Train Loss: 0.4806
Epoch 2 Step 951 Train Loss: 0.5650
Epoch 2 Step 1001 Train Loss: 0.4953
Epoch 2 Step 1051 Train Loss: 0.4784
Epoch 2 Step 1101 Train Loss: 0.5174
Epoch 2 Step 1151 Train Loss: 0.4951
Epoch 2 Step 1201 Train Loss: 0.4892
Epoch 2: Train Overall MSE: 0.0037 Validation Overall MSE: 0.0051. 
Train Top 20 DE MSE: 0.1919 Validation Top 20 DE MSE: 0.1994. 
Epoch 3 Step 1 Train Loss: 0.5078
Epoch 3 Step 51 Train Loss: 0.5180
Epoch 3 Step 101 Train Loss: 0.5019
Epoch 3 Step 151 Train Loss: 0.5220
Epoch 3 Step 201 Train Loss: 0.5417
Epoch 3 Step 251 Train Loss: 0.5324
Epoch 3 Step 301 Train Loss: 0.5122
Epoch 3 Step 351 Train Loss: 0.5524
Epoch 3 Step 401 Train Loss: 0.5794
Epoch 3 Step 451 Train Loss: 0.4956
Epoch 3 Step 501 Train Loss: 0.4650
Epoch 3 Step 551 Train Loss: 0.4840
Epoch 3 Step 601 Train Loss: 0.5373
Epoch 3 Step 651 Train Loss: 0.4820
Epoch 3 Step 701 Train Loss: 0.4314
Epoch 3 Step 751 Train Loss: 0.5723
Epoch 3 Step 801 Train Loss: 0.4945
Epoch 3 Step 851 Train Loss: 0.5265
Epoch 3 Step 901 Train Loss: 0.5703
Epoch 3 Step 951 Train Loss: 0.4539
Epoch 3 Step 1001 Train Loss: 0.5018
Epoch 3 Step 1051 Train Loss: 0.5062
Epoch 3 Step 1101 Train Loss: 0.4282
Epoch 3 Step 1151 Train Loss: 0.5726
Epoch 3 Step 1201 Train Loss: 0.5434
Epoch 3: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0703 Validation Top 20 DE MSE: 0.0984. 
Epoch 4 Step 1 Train Loss: 0.5392
Epoch 4 Step 51 Train Loss: 0.4818
Epoch 4 Step 101 Train Loss: 0.4724
Epoch 4 Step 151 Train Loss: 0.5145
Epoch 4 Step 201 Train Loss: 0.5403
Epoch 4 Step 251 Train Loss: 0.4918
Epoch 4 Step 301 Train Loss: 0.5951
Epoch 4 Step 351 Train Loss: 0.5328
Epoch 4 Step 401 Train Loss: 0.5700
Epoch 4 Step 451 Train Loss: 0.5713
Epoch 4 Step 501 Train Loss: 0.4501
Epoch 4 Step 551 Train Loss: 0.5438
Epoch 4 Step 601 Train Loss: 0.5089
Epoch 4 Step 651 Train Loss: 0.5150
Epoch 4 Step 701 Train Loss: 0.4974
Epoch 4 Step 751 Train Loss: 0.4622
Epoch 4 Step 801 Train Loss: 0.5296
Epoch 4 Step 851 Train Loss: 0.4200
Epoch 4 Step 901 Train Loss: 0.4838
Epoch 4 Step 951 Train Loss: 0.5436
Epoch 4 Step 1001 Train Loss: 0.5335
Epoch 4 Step 1051 Train Loss: 0.5315
Epoch 4 Step 1101 Train Loss: 0.4884
Epoch 4 Step 1151 Train Loss: 0.4918
Epoch 4 Step 1201 Train Loss: 0.5052
Epoch 4: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0030. 
Train Top 20 DE MSE: 0.0605 Validation Top 20 DE MSE: 0.0896. 
Epoch 5 Step 1 Train Loss: 0.5466
Epoch 5 Step 51 Train Loss: 0.5800
Epoch 5 Step 101 Train Loss: 0.5639
Epoch 5 Step 151 Train Loss: 0.5978
Epoch 5 Step 201 Train Loss: 0.4995
Epoch 5 Step 251 Train Loss: 0.5344
Epoch 5 Step 301 Train Loss: 0.5238
Epoch 5 Step 351 Train Loss: 0.5085
Epoch 5 Step 401 Train Loss: 0.5300
Epoch 5 Step 451 Train Loss: 0.5615
Epoch 5 Step 501 Train Loss: 0.4983
Epoch 5 Step 551 Train Loss: 0.5499
Epoch 5 Step 601 Train Loss: 0.4967
Epoch 5 Step 651 Train Loss: 0.5532
Epoch 5 Step 701 Train Loss: 0.5439
Epoch 5 Step 751 Train Loss: 0.4814
Epoch 5 Step 801 Train Loss: 0.5843
Epoch 5 Step 851 Train Loss: 0.5871
Epoch 5 Step 901 Train Loss: 0.5557
Epoch 5 Step 951 Train Loss: 0.4818
Epoch 5 Step 1001 Train Loss: 0.4788
Epoch 5 Step 1051 Train Loss: 0.4869
Epoch 5 Step 1101 Train Loss: 0.4957
Epoch 5 Step 1151 Train Loss: 0.4740
Epoch 5 Step 1201 Train Loss: 0.5771
Epoch 5: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0034. 
Train Top 20 DE MSE: 0.0753 Validation Top 20 DE MSE: 0.1099. 
Epoch 6 Step 1 Train Loss: 0.5403
Epoch 6 Step 51 Train Loss: 0.4864
Epoch 6 Step 101 Train Loss: 0.4914
Epoch 6 Step 151 Train Loss: 0.4980
Epoch 6 Step 201 Train Loss: 0.5354
Epoch 6 Step 251 Train Loss: 0.5419
Epoch 6 Step 301 Train Loss: 0.5049
Epoch 6 Step 351 Train Loss: 0.5512
Epoch 6 Step 401 Train Loss: 0.4564
Epoch 6 Step 451 Train Loss: 0.4778
Epoch 6 Step 501 Train Loss: 0.4928
Epoch 6 Step 551 Train Loss: 0.5888
Epoch 6 Step 601 Train Loss: 0.4964
Epoch 6 Step 651 Train Loss: 0.5872
Epoch 6 Step 701 Train Loss: 0.5544
Epoch 6 Step 751 Train Loss: 0.5359
Epoch 6 Step 801 Train Loss: 0.4779
Epoch 6 Step 851 Train Loss: 0.5883
Epoch 6 Step 901 Train Loss: 0.5190
Epoch 6 Step 951 Train Loss: 0.5051
Epoch 6 Step 1001 Train Loss: 0.4918
Epoch 6 Step 1051 Train Loss: 0.5000
Epoch 6 Step 1101 Train Loss: 0.4935
Epoch 6 Step 1151 Train Loss: 0.5174
Epoch 6 Step 1201 Train Loss: 0.4911
Epoch 6: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0696 Validation Top 20 DE MSE: 0.1037. 
Epoch 7 Step 1 Train Loss: 0.4940
Epoch 7 Step 51 Train Loss: 0.5803
Epoch 7 Step 101 Train Loss: 0.5208
Epoch 7 Step 151 Train Loss: 0.5384
Epoch 7 Step 201 Train Loss: 0.5318
Epoch 7 Step 251 Train Loss: 0.4713
Epoch 7 Step 301 Train Loss: 0.5137
Epoch 7 Step 351 Train Loss: 0.4703
Epoch 7 Step 401 Train Loss: 0.5684
Epoch 7 Step 451 Train Loss: 0.5135
Epoch 7 Step 501 Train Loss: 0.5629
Epoch 7 Step 551 Train Loss: 0.5081
Epoch 7 Step 601 Train Loss: 0.6297
Epoch 7 Step 651 Train Loss: 0.5234
Epoch 7 Step 701 Train Loss: 0.4746
Epoch 7 Step 751 Train Loss: 0.6352
Epoch 7 Step 801 Train Loss: 0.5221
Epoch 7 Step 851 Train Loss: 0.4917
Epoch 7 Step 901 Train Loss: 0.6680
Epoch 7 Step 951 Train Loss: 0.5048
Epoch 7 Step 1001 Train Loss: 0.4951
Epoch 7 Step 1051 Train Loss: 0.4977
Epoch 7 Step 1101 Train Loss: 0.5700
Epoch 7 Step 1151 Train Loss: 0.6187
Epoch 7 Step 1201 Train Loss: 0.5044
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0677 Validation Top 20 DE MSE: 0.1035. 
Epoch 8 Step 1 Train Loss: 0.5499
Epoch 8 Step 51 Train Loss: 0.4687
Epoch 8 Step 101 Train Loss: 0.5543
Epoch 8 Step 151 Train Loss: 0.4933
Epoch 8 Step 201 Train Loss: 0.5108
Epoch 8 Step 251 Train Loss: 0.5152
Epoch 8 Step 301 Train Loss: 0.5160
Epoch 8 Step 351 Train Loss: 0.5135
Epoch 8 Step 401 Train Loss: 0.4862
Epoch 8 Step 451 Train Loss: 0.5709
Epoch 8 Step 501 Train Loss: 0.5126
Epoch 8 Step 551 Train Loss: 0.4664
Epoch 8 Step 601 Train Loss: 0.4659
Epoch 8 Step 651 Train Loss: 0.5250
Epoch 8 Step 701 Train Loss: 0.5208
Epoch 8 Step 751 Train Loss: 0.5674
Epoch 8 Step 801 Train Loss: 0.5949
Epoch 8 Step 851 Train Loss: 0.4249
Epoch 8 Step 901 Train Loss: 0.5172
Epoch 8 Step 951 Train Loss: 0.5193
Epoch 8 Step 1001 Train Loss: 0.5155
Epoch 8 Step 1051 Train Loss: 0.5118
Epoch 8 Step 1101 Train Loss: 0.5057
Epoch 8 Step 1151 Train Loss: 0.4797
Epoch 8 Step 1201 Train Loss: 0.5892
Epoch 8: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0718 Validation Top 20 DE MSE: 0.1075. 
Epoch 9 Step 1 Train Loss: 0.4794
Epoch 9 Step 51 Train Loss: 0.4930
Epoch 9 Step 101 Train Loss: 0.5993
Epoch 9 Step 151 Train Loss: 0.4548
Epoch 9 Step 201 Train Loss: 0.6040
Epoch 9 Step 251 Train Loss: 0.4885
Epoch 9 Step 301 Train Loss: 0.4260
Epoch 9 Step 351 Train Loss: 0.6449
Epoch 9 Step 401 Train Loss: 0.5099
Epoch 9 Step 451 Train Loss: 0.4675
Epoch 9 Step 501 Train Loss: 0.5019
Epoch 9 Step 551 Train Loss: 0.5743
Epoch 9 Step 601 Train Loss: 0.5021
Epoch 9 Step 651 Train Loss: 0.4686
Epoch 9 Step 701 Train Loss: 0.4904
Epoch 9 Step 751 Train Loss: 0.6211
Epoch 9 Step 801 Train Loss: 0.4859
Epoch 9 Step 851 Train Loss: 0.5493
Epoch 9 Step 901 Train Loss: 0.6167
Epoch 9 Step 951 Train Loss: 0.5309
Epoch 9 Step 1001 Train Loss: 0.5359
Epoch 9 Step 1051 Train Loss: 0.5794
Epoch 9 Step 1101 Train Loss: 0.4990
Epoch 9 Step 1151 Train Loss: 0.4471
Epoch 9 Step 1201 Train Loss: 0.4720
Epoch 9: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0669 Validation Top 20 DE MSE: 0.1026. 
Epoch 10 Step 1 Train Loss: 0.5108
Epoch 10 Step 51 Train Loss: 0.4605
Epoch 10 Step 101 Train Loss: 0.5653
Epoch 10 Step 151 Train Loss: 0.4916
Epoch 10 Step 201 Train Loss: 0.5208
Epoch 10 Step 251 Train Loss: 0.4552
Epoch 10 Step 301 Train Loss: 0.5554
Epoch 10 Step 351 Train Loss: 0.5446
Epoch 10 Step 401 Train Loss: 0.5641
Epoch 10 Step 451 Train Loss: 0.5549
Epoch 10 Step 501 Train Loss: 0.5762
Epoch 10 Step 551 Train Loss: 0.5069
Epoch 10 Step 601 Train Loss: 0.5227
Epoch 10 Step 651 Train Loss: 0.4987
Epoch 10 Step 701 Train Loss: 0.5897
Epoch 10 Step 751 Train Loss: 0.5424
Epoch 10 Step 801 Train Loss: 0.5232
Epoch 10 Step 851 Train Loss: 0.5452
Epoch 10 Step 901 Train Loss: 0.5604
Epoch 10 Step 951 Train Loss: 0.6302
Epoch 10 Step 1001 Train Loss: 0.4798
Epoch 10 Step 1051 Train Loss: 0.5530
Epoch 10 Step 1101 Train Loss: 0.5793
Epoch 10 Step 1151 Train Loss: 0.5335
Epoch 10 Step 1201 Train Loss: 0.5334
Epoch 10: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0668 Validation Top 20 DE MSE: 0.1017. 
Epoch 11 Step 1 Train Loss: 0.6115
Epoch 11 Step 51 Train Loss: 0.6022
Epoch 11 Step 101 Train Loss: 0.4942
Epoch 11 Step 151 Train Loss: 0.5611
Epoch 11 Step 201 Train Loss: 0.5703
Epoch 11 Step 251 Train Loss: 0.5576
Epoch 11 Step 301 Train Loss: 0.5067
Epoch 11 Step 351 Train Loss: 0.5336
Epoch 11 Step 401 Train Loss: 0.6784
Epoch 11 Step 451 Train Loss: 0.5170
Epoch 11 Step 501 Train Loss: 0.5616
Epoch 11 Step 551 Train Loss: 0.4531
Epoch 11 Step 601 Train Loss: 0.5019
Epoch 11 Step 651 Train Loss: 0.4959
Epoch 11 Step 701 Train Loss: 0.6868
Epoch 11 Step 751 Train Loss: 0.5514
Epoch 11 Step 801 Train Loss: 0.5888
Epoch 11 Step 851 Train Loss: 0.4697
Epoch 11 Step 901 Train Loss: 0.5252
Epoch 11 Step 951 Train Loss: 0.4728
Epoch 11 Step 1001 Train Loss: 0.5458
Epoch 11 Step 1051 Train Loss: 0.5456
Epoch 11 Step 1101 Train Loss: 0.5242
Epoch 11 Step 1151 Train Loss: 0.5511
Epoch 11 Step 1201 Train Loss: 0.5392
Epoch 11: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0680 Validation Top 20 DE MSE: 0.1034. 
Epoch 12 Step 1 Train Loss: 0.5496
Epoch 12 Step 51 Train Loss: 0.4624
Epoch 12 Step 101 Train Loss: 0.5495
Epoch 12 Step 151 Train Loss: 0.4937
Epoch 12 Step 201 Train Loss: 0.5266
Epoch 12 Step 251 Train Loss: 0.5482
Epoch 12 Step 301 Train Loss: 0.5575
Epoch 12 Step 351 Train Loss: 0.5519
Epoch 12 Step 401 Train Loss: 0.4791
Epoch 12 Step 451 Train Loss: 0.6114
Epoch 12 Step 501 Train Loss: 0.5502
Epoch 12 Step 551 Train Loss: 0.5185
Epoch 12 Step 601 Train Loss: 0.5422
Epoch 12 Step 651 Train Loss: 0.5343
Epoch 12 Step 701 Train Loss: 0.5621
Epoch 12 Step 751 Train Loss: 0.5397
Epoch 12 Step 801 Train Loss: 0.5853
Epoch 12 Step 851 Train Loss: 0.4793
Epoch 12 Step 901 Train Loss: 0.5168
Epoch 12 Step 951 Train Loss: 0.5456
Epoch 12 Step 1001 Train Loss: 0.5622
Epoch 12 Step 1051 Train Loss: 0.5230
Epoch 12 Step 1101 Train Loss: 0.5370
Epoch 12 Step 1151 Train Loss: 0.5673
Epoch 12 Step 1201 Train Loss: 0.5438
Epoch 12: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0658 Validation Top 20 DE MSE: 0.1016. 
Epoch 13 Step 1 Train Loss: 0.5239
Epoch 13 Step 51 Train Loss: 0.4708
Epoch 13 Step 101 Train Loss: 0.5315
Epoch 13 Step 151 Train Loss: 0.5413
Epoch 13 Step 201 Train Loss: 0.5596
Epoch 13 Step 251 Train Loss: 0.6217
Epoch 13 Step 301 Train Loss: 0.5428
Epoch 13 Step 351 Train Loss: 0.5214
Epoch 13 Step 401 Train Loss: 0.5893
Epoch 13 Step 451 Train Loss: 0.5256
Epoch 13 Step 501 Train Loss: 0.4866
Epoch 13 Step 551 Train Loss: 0.4435
Epoch 13 Step 601 Train Loss: 0.4686
Epoch 13 Step 651 Train Loss: 0.4711
Epoch 13 Step 701 Train Loss: 0.4676
Epoch 13 Step 751 Train Loss: 0.5654
Epoch 13 Step 801 Train Loss: 0.6057
Epoch 13 Step 851 Train Loss: 0.5714
Epoch 13 Step 901 Train Loss: 0.5723
Epoch 13 Step 951 Train Loss: 0.5961
Epoch 13 Step 1001 Train Loss: 0.5502
Epoch 13 Step 1051 Train Loss: 0.5757
Epoch 13 Step 1101 Train Loss: 0.4740
Epoch 13 Step 1151 Train Loss: 0.5339
Epoch 13 Step 1201 Train Loss: 0.5388
Epoch 13: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0033. 
Train Top 20 DE MSE: 0.0723 Validation Top 20 DE MSE: 0.1065. 
Epoch 14 Step 1 Train Loss: 0.5286
Epoch 14 Step 51 Train Loss: 0.5755
Epoch 14 Step 101 Train Loss: 0.5336
Epoch 14 Step 151 Train Loss: 0.5271
Epoch 14 Step 201 Train Loss: 0.5526
Epoch 14 Step 251 Train Loss: 0.5758
Epoch 14 Step 301 Train Loss: 0.6472
Epoch 14 Step 351 Train Loss: 0.5411
Epoch 14 Step 401 Train Loss: 0.5437
Epoch 14 Step 451 Train Loss: 0.5454
Epoch 14 Step 501 Train Loss: 0.5509
Epoch 14 Step 551 Train Loss: 0.5240
Epoch 14 Step 601 Train Loss: 0.5718
Epoch 14 Step 651 Train Loss: 0.5123
Epoch 14 Step 701 Train Loss: 0.5108
Epoch 14 Step 751 Train Loss: 0.5298
Epoch 14 Step 801 Train Loss: 0.4737
Epoch 14 Step 851 Train Loss: 0.4774
Epoch 14 Step 901 Train Loss: 0.5174
Epoch 14 Step 951 Train Loss: 0.4961
Epoch 14 Step 1001 Train Loss: 0.5194
Epoch 14 Step 1051 Train Loss: 0.4507
Epoch 14 Step 1101 Train Loss: 0.4844
Epoch 14 Step 1151 Train Loss: 0.5656
Epoch 14 Step 1201 Train Loss: 0.4828
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0682 Validation Top 20 DE MSE: 0.1039. 
Epoch 15 Step 1 Train Loss: 0.5529
Epoch 15 Step 51 Train Loss: 0.5355
Epoch 15 Step 101 Train Loss: 0.5325
Epoch 15 Step 151 Train Loss: 0.5780
Epoch 15 Step 201 Train Loss: 0.4928
Epoch 15 Step 251 Train Loss: 0.5547
Epoch 15 Step 301 Train Loss: 0.5687
Epoch 15 Step 351 Train Loss: 0.4599
Epoch 15 Step 401 Train Loss: 0.5068
Epoch 15 Step 451 Train Loss: 0.5185
Epoch 15 Step 501 Train Loss: 0.5400
Epoch 15 Step 551 Train Loss: 0.5186
Epoch 15 Step 601 Train Loss: 0.5224
Epoch 15 Step 651 Train Loss: 0.4866
Epoch 15 Step 701 Train Loss: 0.5338
Epoch 15 Step 751 Train Loss: 0.5327
Epoch 15 Step 801 Train Loss: 0.4586
Epoch 15 Step 851 Train Loss: 0.4872
Epoch 15 Step 901 Train Loss: 0.4637
Epoch 15 Step 951 Train Loss: 0.5359
Epoch 15 Step 1001 Train Loss: 0.5669
Epoch 15 Step 1051 Train Loss: 0.5191
Epoch 15 Step 1101 Train Loss: 0.5324
Epoch 15 Step 1151 Train Loss: 0.5808
Epoch 15 Step 1201 Train Loss: 0.4662
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0646 Validation Top 20 DE MSE: 0.0983. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1058
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0019599225
test_unseen_single_pearson: 0.996274270452556
test_unseen_single_mse_de: 0.10579967
test_unseen_single_pearson_de: 0.9172061787785363
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3742852056977157
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.2863636363636364
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9295454545454543
test_unseen_single_mse_top20_de_non_dropout: 0.108774826
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.031 MB uploadedwandb: | 0.001 MB of 0.031 MB uploadedwandb: / 0.031 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb:                                                   val_de_mse ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.1058
wandb:                                              test_de_pearson 0.91721
wandb:               test_frac_opposite_direction_top20_non_dropout 0.28636
wandb:                          test_frac_sigma_below_1_non_dropout 0.92955
wandb:                                                     test_mse 0.00196
wandb:                                test_mse_top20_de_non_dropout 0.10877
wandb:                                                 test_pearson 0.99627
wandb:                                           test_pearson_delta 0.37429
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.28636
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.92955
wandb:                                       test_unseen_single_mse 0.00196
wandb:                                    test_unseen_single_mse_de 0.1058
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.10877
wandb:                                   test_unseen_single_pearson 0.99627
wandb:                                test_unseen_single_pearson_de 0.91721
wandb:                             test_unseen_single_pearson_delta 0.37429
wandb:                                                 train_de_mse 0.06461
wandb:                                             train_de_pearson 0.9138
wandb:                                                    train_mse 0.00172
wandb:                                                train_pearson 0.99679
wandb:                                                training_loss 0.45352
wandb:                                                   val_de_mse 0.09831
wandb:                                               val_de_pearson 0.81052
wandb:                                                      val_mse 0.00317
wandb:                                                  val_pearson 0.99381
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406681_3_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/oj7w08li
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_194548-oj7w08li/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:22
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241028_202435-dgxi83d6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_AdamsonWeissman2016_GSM2406681_3_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/dgxi83d6
wandb: WARNING Serializing object of type ndarray that is 8100928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.4781
Epoch 1 Step 51 Train Loss: 0.4799
Epoch 1 Step 101 Train Loss: 0.5385
Epoch 1 Step 151 Train Loss: 0.5814
Epoch 1 Step 201 Train Loss: 0.5601
Epoch 1 Step 251 Train Loss: 0.6724
Epoch 1 Step 301 Train Loss: 0.5739
Epoch 1 Step 351 Train Loss: 0.6007
Epoch 1 Step 401 Train Loss: 0.5267
Epoch 1 Step 451 Train Loss: 0.5554
Epoch 1 Step 501 Train Loss: 0.5252
Epoch 1 Step 551 Train Loss: 0.5190
Epoch 1 Step 601 Train Loss: 0.5426
Epoch 1 Step 651 Train Loss: 0.5899
Epoch 1 Step 701 Train Loss: 0.5716
Epoch 1 Step 751 Train Loss: 0.6201
Epoch 1 Step 801 Train Loss: 0.4760
Epoch 1 Step 851 Train Loss: 0.5350
Epoch 1 Step 901 Train Loss: 0.5019
Epoch 1 Step 951 Train Loss: 0.5311
Epoch 1 Step 1001 Train Loss: 0.6002
Epoch 1 Step 1051 Train Loss: 0.4130
Epoch 1 Step 1101 Train Loss: 0.4990
Epoch 1 Step 1151 Train Loss: 0.5221
Epoch 1 Step 1201 Train Loss: 0.5975
Epoch 1 Step 1251 Train Loss: 0.4621
Epoch 1 Step 1301 Train Loss: 0.4848
Epoch 1: Train Overall MSE: 0.0097 Validation Overall MSE: 0.0102. 
Train Top 20 DE MSE: 0.1090 Validation Top 20 DE MSE: 0.2006. 
Epoch 2 Step 1 Train Loss: 0.5370
Epoch 2 Step 51 Train Loss: 0.4425
Epoch 2 Step 101 Train Loss: 0.5485
Epoch 2 Step 151 Train Loss: 0.4604
Epoch 2 Step 201 Train Loss: 0.5117
Epoch 2 Step 251 Train Loss: 0.5391
Epoch 2 Step 301 Train Loss: 0.4617
Epoch 2 Step 351 Train Loss: 0.5057
Epoch 2 Step 401 Train Loss: 0.5481
Epoch 2 Step 451 Train Loss: 0.4533
Epoch 2 Step 501 Train Loss: 0.4733
Epoch 2 Step 551 Train Loss: 0.5208
Epoch 2 Step 601 Train Loss: 0.6281
Epoch 2 Step 651 Train Loss: 0.5516
Epoch 2 Step 701 Train Loss: 0.4695
Epoch 2 Step 751 Train Loss: 0.4454
Epoch 2 Step 801 Train Loss: 0.4930
Epoch 2 Step 851 Train Loss: 0.4562
Epoch 2 Step 901 Train Loss: 0.4754
Epoch 2 Step 951 Train Loss: 0.5555
Epoch 2 Step 1001 Train Loss: 0.4854
Epoch 2 Step 1051 Train Loss: 0.5240
Epoch 2 Step 1101 Train Loss: 0.4602
Epoch 2 Step 1151 Train Loss: 0.5508
Epoch 2 Step 1201 Train Loss: 0.5055
Epoch 2 Step 1251 Train Loss: 0.5360
Epoch 2 Step 1301 Train Loss: 0.5779
Epoch 2: Train Overall MSE: 0.0024 Validation Overall MSE: 0.0032. 
Train Top 20 DE MSE: 0.0789 Validation Top 20 DE MSE: 0.1629. 
Epoch 3 Step 1 Train Loss: 0.4763
Epoch 3 Step 51 Train Loss: 0.5737
Epoch 3 Step 101 Train Loss: 0.5095
Epoch 3 Step 151 Train Loss: 0.4715
Epoch 3 Step 201 Train Loss: 0.4937
Epoch 3 Step 251 Train Loss: 0.5110
Epoch 3 Step 301 Train Loss: 0.5662
Epoch 3 Step 351 Train Loss: 0.4864
Epoch 3 Step 401 Train Loss: 0.5017
Epoch 3 Step 451 Train Loss: 0.4489
Epoch 3 Step 501 Train Loss: 0.4589
Epoch 3 Step 551 Train Loss: 0.5188
Epoch 3 Step 601 Train Loss: 0.6557
Epoch 3 Step 651 Train Loss: 0.4772
Epoch 3 Step 701 Train Loss: 0.5146
Epoch 3 Step 751 Train Loss: 0.5140
Epoch 3 Step 801 Train Loss: 0.5072
Epoch 3 Step 851 Train Loss: 0.4716
Epoch 3 Step 901 Train Loss: 0.4199
Epoch 3 Step 951 Train Loss: 0.5323
Epoch 3 Step 1001 Train Loss: 0.5524
Epoch 3 Step 1051 Train Loss: 0.5075
Epoch 3 Step 1101 Train Loss: 0.5482
Epoch 3 Step 1151 Train Loss: 0.6262
Epoch 3 Step 1201 Train Loss: 0.4796
Epoch 3 Step 1251 Train Loss: 0.4928
Epoch 3 Step 1301 Train Loss: 0.5112
Epoch 3: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0828 Validation Top 20 DE MSE: 0.1749. 
Epoch 4 Step 1 Train Loss: 0.5164
Epoch 4 Step 51 Train Loss: 0.4442
Epoch 4 Step 101 Train Loss: 0.5119
Epoch 4 Step 151 Train Loss: 0.4624
Epoch 4 Step 201 Train Loss: 0.5076
Epoch 4 Step 251 Train Loss: 0.5688
Epoch 4 Step 301 Train Loss: 0.5282
Epoch 4 Step 351 Train Loss: 0.4955
Epoch 4 Step 401 Train Loss: 0.5693
Epoch 4 Step 451 Train Loss: 0.5906
Epoch 4 Step 501 Train Loss: 0.5195
Epoch 4 Step 551 Train Loss: 0.5345
Epoch 4 Step 601 Train Loss: 0.5341
Epoch 4 Step 651 Train Loss: 0.5375
Epoch 4 Step 701 Train Loss: 0.5525
Epoch 4 Step 751 Train Loss: 0.5380
Epoch 4 Step 801 Train Loss: 0.4799
Epoch 4 Step 851 Train Loss: 0.6248
Epoch 4 Step 901 Train Loss: 0.4629
Epoch 4 Step 951 Train Loss: 0.5078
Epoch 4 Step 1001 Train Loss: 0.5217
Epoch 4 Step 1051 Train Loss: 0.5175
Epoch 4 Step 1101 Train Loss: 0.4860
Epoch 4 Step 1151 Train Loss: 0.5561
Epoch 4 Step 1201 Train Loss: 0.5358
Epoch 4 Step 1251 Train Loss: 0.5020
Epoch 4 Step 1301 Train Loss: 0.5063
Epoch 4: Train Overall MSE: 0.0029 Validation Overall MSE: 0.0039. 
Train Top 20 DE MSE: 0.0800 Validation Top 20 DE MSE: 0.1772. 
Epoch 5 Step 1 Train Loss: 0.4906
Epoch 5 Step 51 Train Loss: 0.4960
Epoch 5 Step 101 Train Loss: 0.5649
Epoch 5 Step 151 Train Loss: 0.5114
Epoch 5 Step 201 Train Loss: 0.4496
Epoch 5 Step 251 Train Loss: 0.5088
Epoch 5 Step 301 Train Loss: 0.4890
Epoch 5 Step 351 Train Loss: 0.5143
Epoch 5 Step 401 Train Loss: 0.4935
Epoch 5 Step 451 Train Loss: 0.5226
Epoch 5 Step 501 Train Loss: 0.5363
Epoch 5 Step 551 Train Loss: 0.4990
Epoch 5 Step 601 Train Loss: 0.5298
Epoch 5 Step 651 Train Loss: 0.4793
Epoch 5 Step 701 Train Loss: 0.6296
Epoch 5 Step 751 Train Loss: 0.5476
Epoch 5 Step 801 Train Loss: 0.5163
Epoch 5 Step 851 Train Loss: 0.6402
Epoch 5 Step 901 Train Loss: 0.4844
Epoch 5 Step 951 Train Loss: 0.5726
Epoch 5 Step 1001 Train Loss: 0.4994
Epoch 5 Step 1051 Train Loss: 0.6370
Epoch 5 Step 1101 Train Loss: 0.4804
Epoch 5 Step 1151 Train Loss: 0.5202
Epoch 5 Step 1201 Train Loss: 0.4688
Epoch 5 Step 1251 Train Loss: 0.5012
Epoch 5 Step 1301 Train Loss: 0.5155
Epoch 5: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0663 Validation Top 20 DE MSE: 0.1611. 
Epoch 6 Step 1 Train Loss: 0.5507
Epoch 6 Step 51 Train Loss: 0.5464
Epoch 6 Step 101 Train Loss: 0.5572
Epoch 6 Step 151 Train Loss: 0.5847
Epoch 6 Step 201 Train Loss: 0.5057
Epoch 6 Step 251 Train Loss: 0.5851
Epoch 6 Step 301 Train Loss: 0.4845
Epoch 6 Step 351 Train Loss: 0.4638
Epoch 6 Step 401 Train Loss: 0.4746
Epoch 6 Step 451 Train Loss: 0.6090
Epoch 6 Step 501 Train Loss: 0.5274
Epoch 6 Step 551 Train Loss: 0.4955
Epoch 6 Step 601 Train Loss: 0.5351
Epoch 6 Step 651 Train Loss: 0.4723
Epoch 6 Step 701 Train Loss: 0.5103
Epoch 6 Step 751 Train Loss: 0.5290
Epoch 6 Step 801 Train Loss: 0.5237
Epoch 6 Step 851 Train Loss: 0.4454
Epoch 6 Step 901 Train Loss: 0.5122
Epoch 6 Step 951 Train Loss: 0.4394
Epoch 6 Step 1001 Train Loss: 0.4642
Epoch 6 Step 1051 Train Loss: 0.4969
Epoch 6 Step 1101 Train Loss: 0.6813
Epoch 6 Step 1151 Train Loss: 0.5031
Epoch 6 Step 1201 Train Loss: 0.5748
Epoch 6 Step 1251 Train Loss: 0.6469
Epoch 6 Step 1301 Train Loss: 0.4866
Epoch 6: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0688 Validation Top 20 DE MSE: 0.1689. 
Epoch 7 Step 1 Train Loss: 0.4724
Epoch 7 Step 51 Train Loss: 0.5909
Epoch 7 Step 101 Train Loss: 0.5331
Epoch 7 Step 151 Train Loss: 0.5344
Epoch 7 Step 201 Train Loss: 0.5671
Epoch 7 Step 251 Train Loss: 0.5132
Epoch 7 Step 301 Train Loss: 0.5110
Epoch 7 Step 351 Train Loss: 0.4608
Epoch 7 Step 401 Train Loss: 0.6189
Epoch 7 Step 451 Train Loss: 0.4541
Epoch 7 Step 501 Train Loss: 0.5493
Epoch 7 Step 551 Train Loss: 0.6068
Epoch 7 Step 601 Train Loss: 0.4667
Epoch 7 Step 651 Train Loss: 0.5362
Epoch 7 Step 701 Train Loss: 0.5043
Epoch 7 Step 751 Train Loss: 0.5305
Epoch 7 Step 801 Train Loss: 0.5074
Epoch 7 Step 851 Train Loss: 0.5681
Epoch 7 Step 901 Train Loss: 0.7137
Epoch 7 Step 951 Train Loss: 0.5591
Epoch 7 Step 1001 Train Loss: 0.5049
Epoch 7 Step 1051 Train Loss: 0.5268
Epoch 7 Step 1101 Train Loss: 0.5556
Epoch 7 Step 1151 Train Loss: 0.5023
Epoch 7 Step 1201 Train Loss: 0.4804
Epoch 7 Step 1251 Train Loss: 0.6452
Epoch 7 Step 1301 Train Loss: 0.4971
Epoch 7: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0684 Validation Top 20 DE MSE: 0.1648. 
Epoch 8 Step 1 Train Loss: 0.5419
Epoch 8 Step 51 Train Loss: 0.4889
Epoch 8 Step 101 Train Loss: 0.6168
Epoch 8 Step 151 Train Loss: 0.6628
Epoch 8 Step 201 Train Loss: 0.5412
Epoch 8 Step 251 Train Loss: 0.5317
Epoch 8 Step 301 Train Loss: 0.5069
Epoch 8 Step 351 Train Loss: 0.5430
Epoch 8 Step 401 Train Loss: 0.4922
Epoch 8 Step 451 Train Loss: 0.5203
Epoch 8 Step 501 Train Loss: 0.4590
Epoch 8 Step 551 Train Loss: 0.5409
Epoch 8 Step 601 Train Loss: 0.4446
Epoch 8 Step 651 Train Loss: 0.4284
Epoch 8 Step 701 Train Loss: 0.5087
Epoch 8 Step 751 Train Loss: 0.4884
Epoch 8 Step 801 Train Loss: 0.5201
Epoch 8 Step 851 Train Loss: 0.4913
Epoch 8 Step 901 Train Loss: 0.6019
Epoch 8 Step 951 Train Loss: 0.5278
Epoch 8 Step 1001 Train Loss: 0.5205
Epoch 8 Step 1051 Train Loss: 0.5705
Epoch 8 Step 1101 Train Loss: 0.4900
Epoch 8 Step 1151 Train Loss: 0.5628
Epoch 8 Step 1201 Train Loss: 0.5917
Epoch 8 Step 1251 Train Loss: 0.5641
Epoch 8 Step 1301 Train Loss: 0.6265
Epoch 8: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0666 Validation Top 20 DE MSE: 0.1636. 
Epoch 9 Step 1 Train Loss: 0.4846
Epoch 9 Step 51 Train Loss: 0.5552
Epoch 9 Step 101 Train Loss: 0.4629
Epoch 9 Step 151 Train Loss: 0.4988
Epoch 9 Step 201 Train Loss: 0.5595
Epoch 9 Step 251 Train Loss: 0.4897
Epoch 9 Step 301 Train Loss: 0.4947
Epoch 9 Step 351 Train Loss: 0.5817
Epoch 9 Step 401 Train Loss: 0.5030
Epoch 9 Step 451 Train Loss: 0.5146
Epoch 9 Step 501 Train Loss: 0.4903
Epoch 9 Step 551 Train Loss: 0.4787
Epoch 9 Step 601 Train Loss: 0.6173
Epoch 9 Step 651 Train Loss: 0.4916
Epoch 9 Step 701 Train Loss: 0.5284
Epoch 9 Step 751 Train Loss: 0.5441
Epoch 9 Step 801 Train Loss: 0.4945
Epoch 9 Step 851 Train Loss: 0.5313
Epoch 9 Step 901 Train Loss: 0.5319
Epoch 9 Step 951 Train Loss: 0.4560
Epoch 9 Step 1001 Train Loss: 0.5120
Epoch 9 Step 1051 Train Loss: 0.5348
Epoch 9 Step 1101 Train Loss: 0.5736
Epoch 9 Step 1151 Train Loss: 0.4276
Epoch 9 Step 1201 Train Loss: 0.5030
Epoch 9 Step 1251 Train Loss: 0.5644
Epoch 9 Step 1301 Train Loss: 0.6440
Epoch 9: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0673 Validation Top 20 DE MSE: 0.1641. 
Epoch 10 Step 1 Train Loss: 0.5648
Epoch 10 Step 51 Train Loss: 0.4950
Epoch 10 Step 101 Train Loss: 0.5517
Epoch 10 Step 151 Train Loss: 0.4974
Epoch 10 Step 201 Train Loss: 0.5898
Epoch 10 Step 251 Train Loss: 0.5234
Epoch 10 Step 301 Train Loss: 0.4982
Epoch 10 Step 351 Train Loss: 0.5180
Epoch 10 Step 401 Train Loss: 0.4956
Epoch 10 Step 451 Train Loss: 0.5914
Epoch 10 Step 501 Train Loss: 0.4358
Epoch 10 Step 551 Train Loss: 0.5097
Epoch 10 Step 601 Train Loss: 0.5319
Epoch 10 Step 651 Train Loss: 0.5834
Epoch 10 Step 701 Train Loss: 0.5549
Epoch 10 Step 751 Train Loss: 0.5276
Epoch 10 Step 801 Train Loss: 0.5015
Epoch 10 Step 851 Train Loss: 0.5491
Epoch 10 Step 901 Train Loss: 0.5295
Epoch 10 Step 951 Train Loss: 0.6148
Epoch 10 Step 1001 Train Loss: 0.5333
Epoch 10 Step 1051 Train Loss: 0.6572
Epoch 10 Step 1101 Train Loss: 0.5154
Epoch 10 Step 1151 Train Loss: 0.5297
Epoch 10 Step 1201 Train Loss: 0.6148
Epoch 10 Step 1251 Train Loss: 0.5397
Epoch 10 Step 1301 Train Loss: 0.4818
Epoch 10: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0666 Validation Top 20 DE MSE: 0.1636. 
Epoch 11 Step 1 Train Loss: 0.5980
Epoch 11 Step 51 Train Loss: 0.5541
Epoch 11 Step 101 Train Loss: 0.5393
Epoch 11 Step 151 Train Loss: 0.5000
Epoch 11 Step 201 Train Loss: 0.5649
Epoch 11 Step 251 Train Loss: 0.5346
Epoch 11 Step 301 Train Loss: 0.4539
Epoch 11 Step 351 Train Loss: 0.5883
Epoch 11 Step 401 Train Loss: 0.4907
Epoch 11 Step 451 Train Loss: 0.5942
Epoch 11 Step 501 Train Loss: 0.5234
Epoch 11 Step 551 Train Loss: 0.4632
Epoch 11 Step 601 Train Loss: 0.5964
Epoch 11 Step 651 Train Loss: 0.5501
Epoch 11 Step 701 Train Loss: 0.5674
Epoch 11 Step 751 Train Loss: 0.5766
Epoch 11 Step 801 Train Loss: 0.4945
Epoch 11 Step 851 Train Loss: 0.5720
Epoch 11 Step 901 Train Loss: 0.5343
Epoch 11 Step 951 Train Loss: 0.5428
Epoch 11 Step 1001 Train Loss: 0.5198
Epoch 11 Step 1051 Train Loss: 0.4672
Epoch 11 Step 1101 Train Loss: 0.4998
Epoch 11 Step 1151 Train Loss: 0.4860
Epoch 11 Step 1201 Train Loss: 0.5276
Epoch 11 Step 1251 Train Loss: 0.5822
Epoch 11 Step 1301 Train Loss: 0.6024
Epoch 11: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0670 Validation Top 20 DE MSE: 0.1642. 
Epoch 12 Step 1 Train Loss: 0.4793
Epoch 12 Step 51 Train Loss: 0.5987
Epoch 12 Step 101 Train Loss: 0.5142
Epoch 12 Step 151 Train Loss: 0.4721
Epoch 12 Step 201 Train Loss: 0.5104
Epoch 12 Step 251 Train Loss: 0.5153
Epoch 12 Step 301 Train Loss: 0.4249
Epoch 12 Step 351 Train Loss: 0.5420
Epoch 12 Step 401 Train Loss: 0.5350
Epoch 12 Step 451 Train Loss: 0.4934
Epoch 12 Step 501 Train Loss: 0.5614
Epoch 12 Step 551 Train Loss: 0.4887
Epoch 12 Step 601 Train Loss: 0.5289
Epoch 12 Step 651 Train Loss: 0.4845
Epoch 12 Step 701 Train Loss: 0.4835
Epoch 12 Step 751 Train Loss: 0.4812
Epoch 12 Step 801 Train Loss: 0.4913
Epoch 12 Step 851 Train Loss: 0.5227
Epoch 12 Step 901 Train Loss: 0.4668
Epoch 12 Step 951 Train Loss: 0.5842
Epoch 12 Step 1001 Train Loss: 0.5471
Epoch 12 Step 1051 Train Loss: 0.5122
Epoch 12 Step 1101 Train Loss: 0.4661
Epoch 12 Step 1151 Train Loss: 0.5582
Epoch 12 Step 1201 Train Loss: 0.5861
Epoch 12 Step 1251 Train Loss: 0.4840
Epoch 12 Step 1301 Train Loss: 0.4904
Epoch 12: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0691 Validation Top 20 DE MSE: 0.1665. 
Epoch 13 Step 1 Train Loss: 0.4746
Epoch 13 Step 51 Train Loss: 0.5654
Epoch 13 Step 101 Train Loss: 0.4746
Epoch 13 Step 151 Train Loss: 0.5154
Epoch 13 Step 201 Train Loss: 0.5471
Epoch 13 Step 251 Train Loss: 0.5546
Epoch 13 Step 301 Train Loss: 0.5535
Epoch 13 Step 351 Train Loss: 0.4883
Epoch 13 Step 401 Train Loss: 0.5264
Epoch 13 Step 451 Train Loss: 0.5479
Epoch 13 Step 501 Train Loss: 0.4968
Epoch 13 Step 551 Train Loss: 0.4765
Epoch 13 Step 601 Train Loss: 0.6081
Epoch 13 Step 651 Train Loss: 0.5007
Epoch 13 Step 701 Train Loss: 0.5077
Epoch 13 Step 751 Train Loss: 0.5127
Epoch 13 Step 801 Train Loss: 0.5601
Epoch 13 Step 851 Train Loss: 0.5187
Epoch 13 Step 901 Train Loss: 0.5451
Epoch 13 Step 951 Train Loss: 0.4823
Epoch 13 Step 1001 Train Loss: 0.4559
Epoch 13 Step 1051 Train Loss: 0.4503
Epoch 13 Step 1101 Train Loss: 0.4686
Epoch 13 Step 1151 Train Loss: 0.5394
Epoch 13 Step 1201 Train Loss: 0.4297
Epoch 13 Step 1251 Train Loss: 0.5041
Epoch 13 Step 1301 Train Loss: 0.5606
Epoch 13: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0700 Validation Top 20 DE MSE: 0.1669. 
Epoch 14 Step 1 Train Loss: 0.4992
Epoch 14 Step 51 Train Loss: 0.5067
Epoch 14 Step 101 Train Loss: 0.5187
Epoch 14 Step 151 Train Loss: 0.5156
Epoch 14 Step 201 Train Loss: 0.4856
Epoch 14 Step 251 Train Loss: 0.5001
Epoch 14 Step 301 Train Loss: 0.5202
Epoch 14 Step 351 Train Loss: 0.5152
Epoch 14 Step 401 Train Loss: 0.5057
Epoch 14 Step 451 Train Loss: 0.4981
Epoch 14 Step 501 Train Loss: 0.5303
Epoch 14 Step 551 Train Loss: 0.4664
Epoch 14 Step 601 Train Loss: 0.4713
Epoch 14 Step 651 Train Loss: 0.5815
Epoch 14 Step 701 Train Loss: 0.4634
Epoch 14 Step 751 Train Loss: 0.4741
Epoch 14 Step 801 Train Loss: 0.4847
Epoch 14 Step 851 Train Loss: 0.5150
Epoch 14 Step 901 Train Loss: 0.5905
Epoch 14 Step 951 Train Loss: 0.4732
Epoch 14 Step 1001 Train Loss: 0.4857
Epoch 14 Step 1051 Train Loss: 0.4621
Epoch 14 Step 1101 Train Loss: 0.6081
Epoch 14 Step 1151 Train Loss: 0.5620
Epoch 14 Step 1201 Train Loss: 0.6381
Epoch 14 Step 1251 Train Loss: 0.5466
Epoch 14 Step 1301 Train Loss: 0.5249
Epoch 14: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0673 Validation Top 20 DE MSE: 0.1643. 
Epoch 15 Step 1 Train Loss: 0.5070
Epoch 15 Step 51 Train Loss: 0.4717
Epoch 15 Step 101 Train Loss: 0.4863
Epoch 15 Step 151 Train Loss: 0.5528
Epoch 15 Step 201 Train Loss: 0.6085
Epoch 15 Step 251 Train Loss: 0.5565
Epoch 15 Step 301 Train Loss: 0.4753
Epoch 15 Step 351 Train Loss: 0.4864
Epoch 15 Step 401 Train Loss: 0.4819
Epoch 15 Step 451 Train Loss: 0.6247
Epoch 15 Step 501 Train Loss: 0.4993
Epoch 15 Step 551 Train Loss: 0.5633
Epoch 15 Step 601 Train Loss: 0.5265
Epoch 15 Step 651 Train Loss: 0.4853
Epoch 15 Step 701 Train Loss: 0.5145
Epoch 15 Step 751 Train Loss: 0.4534
Epoch 15 Step 801 Train Loss: 0.4946
Epoch 15 Step 851 Train Loss: 0.5510
Epoch 15 Step 901 Train Loss: 0.5890
Epoch 15 Step 951 Train Loss: 0.5028
Epoch 15 Step 1001 Train Loss: 0.4573
Epoch 15 Step 1051 Train Loss: 0.4476
Epoch 15 Step 1101 Train Loss: 0.4823
Epoch 15 Step 1151 Train Loss: 0.5619
Epoch 15 Step 1201 Train Loss: 0.5114
Epoch 15 Step 1251 Train Loss: 0.4945
Epoch 15 Step 1301 Train Loss: 0.5283
Epoch 15: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0669 Validation Top 20 DE MSE: 0.1640. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1479
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0023555332
test_unseen_single_pearson: 0.9955165363783404
test_unseen_single_mse_de: 0.1478587
test_unseen_single_pearson_de: 0.9614237072676001
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.34724434577436214
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.24318181818181817
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9136363636363634
test_unseen_single_mse_top20_de_non_dropout: 0.14906377
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.032 MB uploadedwandb: | 0.021 MB of 0.032 MB uploadedwandb: / 0.028 MB of 0.032 MB uploadedwandb: - 0.028 MB of 0.032 MB uploadedwandb: \ 0.032 MB of 0.032 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.14786
wandb:                                              test_de_pearson 0.96142
wandb:               test_frac_opposite_direction_top20_non_dropout 0.24318
wandb:                          test_frac_sigma_below_1_non_dropout 0.91364
wandb:                                                     test_mse 0.00236
wandb:                                test_mse_top20_de_non_dropout 0.14906
wandb:                                                 test_pearson 0.99552
wandb:                                           test_pearson_delta 0.34724
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.24318
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.91364
wandb:                                       test_unseen_single_mse 0.00236
wandb:                                    test_unseen_single_mse_de 0.14786
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.14906
wandb:                                   test_unseen_single_pearson 0.99552
wandb:                                test_unseen_single_pearson_de 0.96142
wandb:                             test_unseen_single_pearson_delta 0.34724
wandb:                                                 train_de_mse 0.06688
wandb:                                             train_de_pearson 0.87575
wandb:                                                    train_mse 0.00184
wandb:                                                train_pearson 0.99655
wandb:                                                training_loss 0.58833
wandb:                                                   val_de_mse 0.16399
wandb:                                               val_de_pearson 0.96363
wandb:                                                      val_mse 0.00278
wandb:                                                  val_pearson 0.99465
wandb: 
wandb: üöÄ View run scbert_AdamsonWeissman2016_GSM2406681_3_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/dgxi83d6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241028_202435-dgxi83d6/logs
