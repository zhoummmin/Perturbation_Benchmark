Loading compilers/gcc/12.2.0
  ERROR: Module cannot be loaded due to a conflict.
    HINT: Might try "module unload compilers/gcc" first.
cmake-3.27.0 loaded successful
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:51
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_081036-alv5jfkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_XuCao2023_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/alv5jfkp
wandb: WARNING Serializing object of type ndarray that is 8275328 bytes
  0%|                                                                                       | 0/2098 [00:00<?, ?it/s]  0%|‚ñé                                                                              | 9/2098 [00:00<00:34, 61.08it/s]  1%|‚ñä                                                                             | 23/2098 [00:00<00:22, 92.45it/s]  2%|‚ñà‚ñå                                                                           | 44/2098 [00:00<00:14, 138.40it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 60/2098 [00:00<00:14, 143.17it/s]  4%|‚ñà‚ñà‚ñä                                                                          | 75/2098 [00:00<00:14, 135.47it/s]  4%|‚ñà‚ñà‚ñà‚ñç                                                                         | 92/2098 [00:00<00:13, 145.82it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                        | 108/2098 [00:00<00:13, 144.36it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 124/2098 [00:00<00:13, 145.50it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 139/2098 [00:01<00:13, 144.87it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 154/2098 [00:01<00:13, 145.72it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 170/2098 [00:01<00:12, 148.90it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 186/2098 [00:01<00:13, 146.59it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 201/2098 [00:01<00:12, 147.49it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 217/2098 [00:01<00:12, 149.73it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 233/2098 [00:01<00:12, 149.78it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 249/2098 [00:01<00:12, 143.23it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 266/2098 [00:01<00:12, 149.93it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 282/2098 [00:01<00:12, 146.81it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 298/2098 [00:02<00:12, 149.89it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 314/2098 [00:02<00:11, 149.93it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 330/2098 [00:02<00:11, 150.13it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 346/2098 [00:02<00:12, 145.84it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 362/2098 [00:02<00:11, 146.40it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 379/2098 [00:02<00:11, 148.02it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 395/2098 [00:02<00:11, 151.04it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 411/2098 [00:02<00:11, 151.24it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 427/2098 [00:02<00:11, 147.42it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 442/2098 [00:03<00:11, 146.79it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 457/2098 [00:03<00:11, 144.95it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 472/2098 [00:03<00:11, 145.87it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 488/2098 [00:03<00:10, 149.65it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 503/2098 [00:03<00:10, 148.76it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 518/2098 [00:03<00:10, 148.61it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 533/2098 [00:03<00:10, 148.46it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 548/2098 [00:03<00:10, 141.49it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 564/2098 [00:03<00:10, 146.55it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 579/2098 [00:03<00:10, 146.59it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 596/2098 [00:04<00:09, 150.83it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 612/2098 [00:04<00:10, 147.86it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 628/2098 [00:04<00:09, 148.12it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 643/2098 [00:04<00:09, 147.95it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 659/2098 [00:04<00:09, 150.29it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 675/2098 [00:04<00:09, 149.96it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 691/2098 [00:04<00:09, 150.33it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 707/2098 [00:04<00:09, 150.74it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 723/2098 [00:04<00:09, 150.02it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 739/2098 [00:05<00:09, 143.07it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 756/2098 [00:05<00:09, 149.11it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 771/2098 [00:05<00:08, 149.20it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 786/2098 [00:05<00:08, 148.76it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 801/2098 [00:05<00:08, 148.22it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 816/2098 [00:05<00:08, 147.96it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 831/2098 [00:05<00:08, 147.94it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 846/2098 [00:05<00:08, 147.96it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 861/2098 [00:05<00:08, 147.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 876/2098 [00:05<00:08, 147.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 891/2098 [00:06<00:08, 147.33it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 906/2098 [00:06<00:08, 147.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 921/2098 [00:06<00:07, 148.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 936/2098 [00:06<00:07, 147.44it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 951/2098 [00:06<00:07, 146.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 966/2098 [00:06<00:07, 147.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 981/2098 [00:06<00:07, 147.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 996/2098 [00:06<00:07, 148.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 1011/2098 [00:06<00:07, 141.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1026/2098 [00:07<00:07, 143.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 1041/2098 [00:07<00:07, 142.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 1056/2098 [00:07<00:07, 139.37it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 1070/2098 [00:07<00:07, 132.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 1084/2098 [00:07<00:07, 127.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1097/2098 [00:07<00:08, 125.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 1110/2098 [00:07<00:08, 123.29it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 1123/2098 [00:07<00:08, 119.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 1136/2098 [00:07<00:08, 117.29it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 1149/2098 [00:08<00:08, 115.62it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 1162/2098 [00:08<00:07, 117.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 1174/2098 [00:08<00:07, 118.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 1186/2098 [00:08<00:07, 117.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 1198/2098 [00:08<00:07, 117.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 1210/2098 [00:08<00:07, 114.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1222/2098 [00:08<00:07, 115.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1235/2098 [00:08<00:07, 115.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 1248/2098 [00:08<00:07, 117.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1260/2098 [00:08<00:07, 117.34it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 1273/2098 [00:09<00:06, 118.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 1285/2098 [00:09<00:06, 118.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 1297/2098 [00:09<00:06, 115.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 1310/2098 [00:09<00:06, 115.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 1322/2098 [00:09<00:06, 116.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1334/2098 [00:09<00:06, 115.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1346/2098 [00:09<00:06, 114.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1359/2098 [00:09<00:06, 117.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1371/2098 [00:09<00:06, 114.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1384/2098 [00:10<00:06, 118.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1396/2098 [00:10<00:05, 118.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1408/2098 [00:10<00:05, 118.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 1420/2098 [00:10<00:05, 116.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1432/2098 [00:10<00:05, 115.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 1444/2098 [00:10<00:05, 115.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 1456/2098 [00:10<00:06, 105.57it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 1470/2098 [00:10<00:05, 114.29it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 1482/2098 [00:10<00:05, 115.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 1494/2098 [00:11<00:05, 113.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 1506/2098 [00:11<00:05, 115.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 1519/2098 [00:11<00:04, 118.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 1531/2098 [00:11<00:04, 115.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 1543/2098 [00:11<00:04, 114.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 1556/2098 [00:11<00:04, 117.39it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 1568/2098 [00:11<00:05, 102.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 1582/2098 [00:11<00:04, 111.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 1594/2098 [00:11<00:04, 112.66it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 1606/2098 [00:12<00:04, 110.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 1619/2098 [00:12<00:04, 112.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 1632/2098 [00:12<00:04, 115.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 1644/2098 [00:12<00:04, 112.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 1656/2098 [00:12<00:03, 114.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 1668/2098 [00:12<00:04, 106.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 1681/2098 [00:12<00:04, 88.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 1700/2098 [00:12<00:03, 111.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 1713/2098 [00:13<00:03, 112.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 1726/2098 [00:13<00:03, 114.00it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 1738/2098 [00:13<00:03, 114.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 1751/2098 [00:13<00:03, 114.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1763/2098 [00:13<00:02, 115.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 1775/2098 [00:13<00:03, 95.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 1790/2098 [00:13<00:02, 106.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 1804/2098 [00:13<00:02, 111.79it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 1819/2098 [00:13<00:02, 120.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 1833/2098 [00:14<00:02, 119.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 1846/2098 [00:14<00:02, 122.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 1861/2098 [00:14<00:01, 127.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 1875/2098 [00:14<00:01, 130.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 1889/2098 [00:14<00:01, 130.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 1903/2098 [00:14<00:01, 124.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 1917/2098 [00:14<00:01, 128.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 1930/2098 [00:14<00:01, 126.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 1944/2098 [00:14<00:01, 129.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 1959/2098 [00:15<00:01, 133.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1973/2098 [00:15<00:00, 134.14it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/2098 [00:15<00:00, 133.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2001/2098 [00:15<00:00, 134.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2015/2098 [00:15<00:00, 133.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2029/2098 [00:15<00:00, 134.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2043/2098 [00:15<00:00, 132.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2057/2098 [00:15<00:00, 133.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2071/2098 [00:15<00:00, 133.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2085/2098 [00:15<00:00, 133.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2098/2098 [00:16<00:00, 130.76it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.2414
Epoch 1 Step 51 Train Loss: 0.2681
Epoch 1 Step 101 Train Loss: 0.2533
Epoch 1 Step 151 Train Loss: 0.2617
Epoch 1 Step 201 Train Loss: 0.2581
Epoch 1 Step 251 Train Loss: 0.2668
Epoch 1 Step 301 Train Loss: 0.2400
Epoch 1 Step 351 Train Loss: 0.2299
Epoch 1 Step 401 Train Loss: 0.2671
Epoch 1 Step 451 Train Loss: 0.2570
Epoch 1 Step 501 Train Loss: 0.2659
Epoch 1 Step 551 Train Loss: 0.2652
Epoch 1 Step 601 Train Loss: 0.2495
Epoch 1 Step 651 Train Loss: 0.2329
Epoch 1 Step 701 Train Loss: 0.2644
Epoch 1 Step 751 Train Loss: 0.2448
Epoch 1 Step 801 Train Loss: 0.2323
Epoch 1 Step 851 Train Loss: 0.2198
Epoch 1 Step 901 Train Loss: 0.2007
Epoch 1 Step 951 Train Loss: 0.2310
Epoch 1 Step 1001 Train Loss: 0.2169
Epoch 1 Step 1051 Train Loss: 0.2313
Epoch 1 Step 1101 Train Loss: 0.2162
Epoch 1 Step 1151 Train Loss: 0.2379
Epoch 1 Step 1201 Train Loss: 0.2352
Epoch 1 Step 1251 Train Loss: 0.2230
Epoch 1 Step 1301 Train Loss: 0.2233
Epoch 1 Step 1351 Train Loss: 0.2153
Epoch 1 Step 1401 Train Loss: 0.2193
Epoch 1 Step 1451 Train Loss: 0.2256
Epoch 1 Step 1501 Train Loss: 0.2158
Epoch 1 Step 1551 Train Loss: 0.2003
Epoch 1 Step 1601 Train Loss: 0.2457
Epoch 1 Step 1651 Train Loss: 0.2187
Epoch 1 Step 1701 Train Loss: 0.2285
Epoch 1 Step 1751 Train Loss: 0.2286
Epoch 1 Step 1801 Train Loss: 0.2251
Epoch 1 Step 1851 Train Loss: 0.2210
Epoch 1: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0084. 
Epoch 2 Step 1 Train Loss: 0.2245
Epoch 2 Step 51 Train Loss: 0.2330
Epoch 2 Step 101 Train Loss: 0.2382
Epoch 2 Step 151 Train Loss: 0.2445
Epoch 2 Step 201 Train Loss: 0.2310
Epoch 2 Step 251 Train Loss: 0.2275
Epoch 2 Step 301 Train Loss: 0.2262
Epoch 2 Step 351 Train Loss: 0.2441
Epoch 2 Step 401 Train Loss: 0.2370
Epoch 2 Step 451 Train Loss: 0.2385
Epoch 2 Step 501 Train Loss: 0.2577
Epoch 2 Step 551 Train Loss: 0.2309
Epoch 2 Step 601 Train Loss: 0.2231
Epoch 2 Step 651 Train Loss: 0.2229
Epoch 2 Step 701 Train Loss: 0.2592
Epoch 2 Step 751 Train Loss: 0.2501
Epoch 2 Step 801 Train Loss: 0.2328
Epoch 2 Step 851 Train Loss: 0.2161
Epoch 2 Step 901 Train Loss: 0.2208
Epoch 2 Step 951 Train Loss: 0.2155
Epoch 2 Step 1001 Train Loss: 0.2237
Epoch 2 Step 1051 Train Loss: 0.2318
Epoch 2 Step 1101 Train Loss: 0.2106
Epoch 2 Step 1151 Train Loss: 0.2059
Epoch 2 Step 1201 Train Loss: 0.2244
Epoch 2 Step 1251 Train Loss: 0.2344
Epoch 2 Step 1301 Train Loss: 0.1982
Epoch 2 Step 1351 Train Loss: 0.2292
Epoch 2 Step 1401 Train Loss: 0.2414
Epoch 2 Step 1451 Train Loss: 0.2376
Epoch 2 Step 1501 Train Loss: 0.2308
Epoch 2 Step 1551 Train Loss: 0.2285
Epoch 2 Step 1601 Train Loss: 0.2349
Epoch 2 Step 1651 Train Loss: 0.2313
Epoch 2 Step 1701 Train Loss: 0.2279
Epoch 2 Step 1751 Train Loss: 0.2139
Epoch 2 Step 1801 Train Loss: 0.2198
Epoch 2 Step 1851 Train Loss: 0.2183
Epoch 2: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 3 Step 1 Train Loss: 0.2408
Epoch 3 Step 51 Train Loss: 0.2289
Epoch 3 Step 101 Train Loss: 0.2322
Epoch 3 Step 151 Train Loss: 0.2260
Epoch 3 Step 201 Train Loss: 0.2301
Epoch 3 Step 251 Train Loss: 0.2228
Epoch 3 Step 301 Train Loss: 0.2389
Epoch 3 Step 351 Train Loss: 0.2383
Epoch 3 Step 401 Train Loss: 0.2193
Epoch 3 Step 451 Train Loss: 0.2272
Epoch 3 Step 501 Train Loss: 0.2327
Epoch 3 Step 551 Train Loss: 0.2293
Epoch 3 Step 601 Train Loss: 0.2313
Epoch 3 Step 651 Train Loss: 0.2309
Epoch 3 Step 701 Train Loss: 0.2365
Epoch 3 Step 751 Train Loss: 0.2358
Epoch 3 Step 801 Train Loss: 0.2275
Epoch 3 Step 851 Train Loss: 0.2297
Epoch 3 Step 901 Train Loss: 0.2240
Epoch 3 Step 951 Train Loss: 0.2184
Epoch 3 Step 1001 Train Loss: 0.2203
Epoch 3 Step 1051 Train Loss: 0.2178
Epoch 3 Step 1101 Train Loss: 0.2198
Epoch 3 Step 1151 Train Loss: 0.2438
Epoch 3 Step 1201 Train Loss: 0.2485
Epoch 3 Step 1251 Train Loss: 0.2332
Epoch 3 Step 1301 Train Loss: 0.2161
Epoch 3 Step 1351 Train Loss: 0.2458
Epoch 3 Step 1401 Train Loss: 0.2224
Epoch 3 Step 1451 Train Loss: 0.2368
Epoch 3 Step 1501 Train Loss: 0.2472
Epoch 3 Step 1551 Train Loss: 0.2151
Epoch 3 Step 1601 Train Loss: 0.2115
Epoch 3 Step 1651 Train Loss: 0.2461
Epoch 3 Step 1701 Train Loss: 0.2701
Epoch 3 Step 1751 Train Loss: 0.2339
Epoch 3 Step 1801 Train Loss: 0.2273
Epoch 3 Step 1851 Train Loss: 0.2266
Epoch 3: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 4 Step 1 Train Loss: 0.2314
Epoch 4 Step 51 Train Loss: 0.2151
Epoch 4 Step 101 Train Loss: 0.2451
Epoch 4 Step 151 Train Loss: 0.2325
Epoch 4 Step 201 Train Loss: 0.2418
Epoch 4 Step 251 Train Loss: 0.2296
Epoch 4 Step 301 Train Loss: 0.2494
Epoch 4 Step 351 Train Loss: 0.2441
Epoch 4 Step 401 Train Loss: 0.2286
Epoch 4 Step 451 Train Loss: 0.2187
Epoch 4 Step 501 Train Loss: 0.2231
Epoch 4 Step 551 Train Loss: 0.2333
Epoch 4 Step 601 Train Loss: 0.2372
Epoch 4 Step 651 Train Loss: 0.2333
Epoch 4 Step 701 Train Loss: 0.2313
Epoch 4 Step 751 Train Loss: 0.2343
Epoch 4 Step 801 Train Loss: 0.2355
Epoch 4 Step 851 Train Loss: 0.2580
Epoch 4 Step 901 Train Loss: 0.2324
Epoch 4 Step 951 Train Loss: 0.2288
Epoch 4 Step 1001 Train Loss: 0.2204
Epoch 4 Step 1051 Train Loss: 0.2203
Epoch 4 Step 1101 Train Loss: 0.2351
Epoch 4 Step 1151 Train Loss: 0.2487
Epoch 4 Step 1201 Train Loss: 0.2473
Epoch 4 Step 1251 Train Loss: 0.2428
Epoch 4 Step 1301 Train Loss: 0.2365
Epoch 4 Step 1351 Train Loss: 0.2426
Epoch 4 Step 1401 Train Loss: 0.2576
Epoch 4 Step 1451 Train Loss: 0.2394
Epoch 4 Step 1501 Train Loss: 0.2445
Epoch 4 Step 1551 Train Loss: 0.2409
Epoch 4 Step 1601 Train Loss: 0.2340
Epoch 4 Step 1651 Train Loss: 0.2163
Epoch 4 Step 1701 Train Loss: 0.2677
Epoch 4 Step 1751 Train Loss: 0.2379
Epoch 4 Step 1801 Train Loss: 0.2171
Epoch 4 Step 1851 Train Loss: 0.2618
Epoch 4: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 5 Step 1 Train Loss: 0.2110
Epoch 5 Step 51 Train Loss: 0.2326
Epoch 5 Step 101 Train Loss: 0.2516
Epoch 5 Step 151 Train Loss: 0.2286
Epoch 5 Step 201 Train Loss: 0.2376
Epoch 5 Step 251 Train Loss: 0.2351
Epoch 5 Step 301 Train Loss: 0.2287
Epoch 5 Step 351 Train Loss: 0.2388
Epoch 5 Step 401 Train Loss: 0.2558
Epoch 5 Step 451 Train Loss: 0.2311
Epoch 5 Step 501 Train Loss: 0.2307
Epoch 5 Step 551 Train Loss: 0.2195
Epoch 5 Step 601 Train Loss: 0.2476
Epoch 5 Step 651 Train Loss: 0.2387
Epoch 5 Step 701 Train Loss: 0.2241
Epoch 5 Step 751 Train Loss: 0.2129
Epoch 5 Step 801 Train Loss: 0.2536
Epoch 5 Step 851 Train Loss: 0.2339
Epoch 5 Step 901 Train Loss: 0.2333
Epoch 5 Step 951 Train Loss: 0.2294
Epoch 5 Step 1001 Train Loss: 0.2350
Epoch 5 Step 1051 Train Loss: 0.2344
Epoch 5 Step 1101 Train Loss: 0.2485
Epoch 5 Step 1151 Train Loss: 0.2498
Epoch 5 Step 1201 Train Loss: 0.2144
Epoch 5 Step 1251 Train Loss: 0.2677
Epoch 5 Step 1301 Train Loss: 0.2400
Epoch 5 Step 1351 Train Loss: 0.2263
Epoch 5 Step 1401 Train Loss: 0.2516
Epoch 5 Step 1451 Train Loss: 0.2345
Epoch 5 Step 1501 Train Loss: 0.2354
Epoch 5 Step 1551 Train Loss: 0.2296
Epoch 5 Step 1601 Train Loss: 0.2202
Epoch 5 Step 1651 Train Loss: 0.2243
Epoch 5 Step 1701 Train Loss: 0.2309
Epoch 5 Step 1751 Train Loss: 0.2148
Epoch 5 Step 1801 Train Loss: 0.2443
Epoch 5 Step 1851 Train Loss: 0.2315
Epoch 5: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 6 Step 1 Train Loss: 0.2525
Epoch 6 Step 51 Train Loss: 0.2423
Epoch 6 Step 101 Train Loss: 0.2499
Epoch 6 Step 151 Train Loss: 0.2369
Epoch 6 Step 201 Train Loss: 0.2349
Epoch 6 Step 251 Train Loss: 0.2374
Epoch 6 Step 301 Train Loss: 0.2157
Epoch 6 Step 351 Train Loss: 0.2402
Epoch 6 Step 401 Train Loss: 0.2393
Epoch 6 Step 451 Train Loss: 0.2532
Epoch 6 Step 501 Train Loss: 0.2534
Epoch 6 Step 551 Train Loss: 0.2551
Epoch 6 Step 601 Train Loss: 0.2677
Epoch 6 Step 651 Train Loss: 0.2325
Epoch 6 Step 701 Train Loss: 0.2371
Epoch 6 Step 751 Train Loss: 0.2223
Epoch 6 Step 801 Train Loss: 0.2459
Epoch 6 Step 851 Train Loss: 0.2392
Epoch 6 Step 901 Train Loss: 0.2484
Epoch 6 Step 951 Train Loss: 0.2334
Epoch 6 Step 1001 Train Loss: 0.2451
Epoch 6 Step 1051 Train Loss: 0.2289
Epoch 6 Step 1101 Train Loss: 0.2311
Epoch 6 Step 1151 Train Loss: 0.2478
Epoch 6 Step 1201 Train Loss: 0.2305
Epoch 6 Step 1251 Train Loss: 0.2367
Epoch 6 Step 1301 Train Loss: 0.2179
Epoch 6 Step 1351 Train Loss: 0.2295
Epoch 6 Step 1401 Train Loss: 0.2371
Epoch 6 Step 1451 Train Loss: 0.2401
Epoch 6 Step 1501 Train Loss: 0.2212
Epoch 6 Step 1551 Train Loss: 0.2669
Epoch 6 Step 1601 Train Loss: 0.2338
Epoch 6 Step 1651 Train Loss: 0.2410
Epoch 6 Step 1701 Train Loss: 0.2189
Epoch 6 Step 1751 Train Loss: 0.2469
Epoch 6 Step 1801 Train Loss: 0.2245
Epoch 6 Step 1851 Train Loss: 0.2319
Epoch 6: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 7 Step 1 Train Loss: 0.2546
Epoch 7 Step 51 Train Loss: 0.2310
Epoch 7 Step 101 Train Loss: 0.2226
Epoch 7 Step 151 Train Loss: 0.2452
Epoch 7 Step 201 Train Loss: 0.2629
Epoch 7 Step 251 Train Loss: 0.2227
Epoch 7 Step 301 Train Loss: 0.2331
Epoch 7 Step 351 Train Loss: 0.2403
Epoch 7 Step 401 Train Loss: 0.2363
Epoch 7 Step 451 Train Loss: 0.2550
Epoch 7 Step 501 Train Loss: 0.2418
Epoch 7 Step 551 Train Loss: 0.2501
Epoch 7 Step 601 Train Loss: 0.2372
Epoch 7 Step 651 Train Loss: 0.2385
Epoch 7 Step 701 Train Loss: 0.2468
Epoch 7 Step 751 Train Loss: 0.2424
Epoch 7 Step 801 Train Loss: 0.2319
Epoch 7 Step 851 Train Loss: 0.2504
Epoch 7 Step 901 Train Loss: 0.2652
Epoch 7 Step 951 Train Loss: 0.2348
Epoch 7 Step 1001 Train Loss: 0.2188
Epoch 7 Step 1051 Train Loss: 0.2301
Epoch 7 Step 1101 Train Loss: 0.2548
Epoch 7 Step 1151 Train Loss: 0.2431
Epoch 7 Step 1201 Train Loss: 0.2473
Epoch 7 Step 1251 Train Loss: 0.3245
Epoch 7 Step 1301 Train Loss: 0.2412
Epoch 7 Step 1351 Train Loss: 0.2520
Epoch 7 Step 1401 Train Loss: 0.2438
Epoch 7 Step 1451 Train Loss: 0.2374
Epoch 7 Step 1501 Train Loss: 0.2498
Epoch 7 Step 1551 Train Loss: 0.2317
Epoch 7 Step 1601 Train Loss: 0.2386
Epoch 7 Step 1651 Train Loss: 0.2407
Epoch 7 Step 1701 Train Loss: 0.2251
Epoch 7 Step 1751 Train Loss: 0.2541
Epoch 7 Step 1801 Train Loss: 0.2473
Epoch 7 Step 1851 Train Loss: 0.2360
Epoch 7: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 8 Step 1 Train Loss: 0.2262
Epoch 8 Step 51 Train Loss: 0.2452
Epoch 8 Step 101 Train Loss: 0.2275
Epoch 8 Step 151 Train Loss: 0.2342
Epoch 8 Step 201 Train Loss: 0.2509
Epoch 8 Step 251 Train Loss: 0.2585
Epoch 8 Step 301 Train Loss: 0.2659
Epoch 8 Step 351 Train Loss: 0.2413
Epoch 8 Step 401 Train Loss: 0.2333
Epoch 8 Step 451 Train Loss: 0.2187
Epoch 8 Step 501 Train Loss: 0.2345
Epoch 8 Step 551 Train Loss: 0.2454
Epoch 8 Step 601 Train Loss: 0.2456
Epoch 8 Step 651 Train Loss: 0.2192
Epoch 8 Step 701 Train Loss: 0.2288
Epoch 8 Step 751 Train Loss: 0.2368
Epoch 8 Step 801 Train Loss: 0.2375
Epoch 8 Step 851 Train Loss: 0.2282
Epoch 8 Step 901 Train Loss: 0.2273
Epoch 8 Step 951 Train Loss: 0.2237
Epoch 8 Step 1001 Train Loss: 0.2494
Epoch 8 Step 1051 Train Loss: 0.2450
Epoch 8 Step 1101 Train Loss: 0.2496
Epoch 8 Step 1151 Train Loss: 0.2425
Epoch 8 Step 1201 Train Loss: 0.2404
Epoch 8 Step 1251 Train Loss: 0.2479
Epoch 8 Step 1301 Train Loss: 0.2305
Epoch 8 Step 1351 Train Loss: 0.2736
Epoch 8 Step 1401 Train Loss: 0.2366
Epoch 8 Step 1451 Train Loss: 0.2260
Epoch 8 Step 1501 Train Loss: 0.2519
Epoch 8 Step 1551 Train Loss: 0.2273
Epoch 8 Step 1601 Train Loss: 0.2329
Epoch 8 Step 1651 Train Loss: 0.2249
Epoch 8 Step 1701 Train Loss: 0.2633
Epoch 8 Step 1751 Train Loss: 0.2429
Epoch 8 Step 1801 Train Loss: 0.2595
Epoch 8 Step 1851 Train Loss: 0.2708
Epoch 8: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 9 Step 1 Train Loss: 0.2251
Epoch 9 Step 51 Train Loss: 0.2373
Epoch 9 Step 101 Train Loss: 0.2323
Epoch 9 Step 151 Train Loss: 0.2474
Epoch 9 Step 201 Train Loss: 0.2621
Epoch 9 Step 251 Train Loss: 0.2220
Epoch 9 Step 301 Train Loss: 0.2568
Epoch 9 Step 351 Train Loss: 0.2492
Epoch 9 Step 401 Train Loss: 0.2550
Epoch 9 Step 451 Train Loss: 0.2519
Epoch 9 Step 501 Train Loss: 0.2359
Epoch 9 Step 551 Train Loss: 0.2493
Epoch 9 Step 601 Train Loss: 0.2352
Epoch 9 Step 651 Train Loss: 0.2410
Epoch 9 Step 701 Train Loss: 0.2356
Epoch 9 Step 751 Train Loss: 0.2184
Epoch 9 Step 801 Train Loss: 0.2411
Epoch 9 Step 851 Train Loss: 0.2367
Epoch 9 Step 901 Train Loss: 0.2450
Epoch 9 Step 951 Train Loss: 0.2480
Epoch 9 Step 1001 Train Loss: 0.2343
Epoch 9 Step 1051 Train Loss: 0.2344
Epoch 9 Step 1101 Train Loss: 0.2361
Epoch 9 Step 1151 Train Loss: 0.2817
Epoch 9 Step 1201 Train Loss: 0.2749
Epoch 9 Step 1251 Train Loss: 0.2315
Epoch 9 Step 1301 Train Loss: 0.2455
Epoch 9 Step 1351 Train Loss: 0.2483
Epoch 9 Step 1401 Train Loss: 0.2644
Epoch 9 Step 1451 Train Loss: 0.2888
Epoch 9 Step 1501 Train Loss: 0.2385
Epoch 9 Step 1551 Train Loss: 0.2557
Epoch 9 Step 1601 Train Loss: 0.2460
Epoch 9 Step 1651 Train Loss: 0.2594
Epoch 9 Step 1701 Train Loss: 0.2472
Epoch 9 Step 1751 Train Loss: 0.2455
Epoch 9 Step 1801 Train Loss: 0.2605
Epoch 9 Step 1851 Train Loss: 0.2423
Epoch 9: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 10 Step 1 Train Loss: 0.2399
Epoch 10 Step 51 Train Loss: 0.2465
Epoch 10 Step 101 Train Loss: 0.2420
Epoch 10 Step 151 Train Loss: 0.2311
Epoch 10 Step 201 Train Loss: 0.2651
Epoch 10 Step 251 Train Loss: 0.2689
Epoch 10 Step 301 Train Loss: 0.2246
Epoch 10 Step 351 Train Loss: 0.2555
Epoch 10 Step 401 Train Loss: 0.2212
Epoch 10 Step 451 Train Loss: 0.2618
Epoch 10 Step 501 Train Loss: 0.2304
Epoch 10 Step 551 Train Loss: 0.2292
Epoch 10 Step 601 Train Loss: 0.2400
Epoch 10 Step 651 Train Loss: 0.2528
Epoch 10 Step 701 Train Loss: 0.2391
Epoch 10 Step 751 Train Loss: 0.2418
Epoch 10 Step 801 Train Loss: 0.2357
Epoch 10 Step 851 Train Loss: 0.2450
Epoch 10 Step 901 Train Loss: 0.2927
Epoch 10 Step 951 Train Loss: 0.2547
Epoch 10 Step 1001 Train Loss: 0.2581
Epoch 10 Step 1051 Train Loss: 0.2455
Epoch 10 Step 1101 Train Loss: 0.2387
Epoch 10 Step 1151 Train Loss: 0.2451
Epoch 10 Step 1201 Train Loss: 0.2395
Epoch 10 Step 1251 Train Loss: 0.2561
Epoch 10 Step 1301 Train Loss: 0.2311
Epoch 10 Step 1351 Train Loss: 0.2260
Epoch 10 Step 1401 Train Loss: 0.2442
Epoch 10 Step 1451 Train Loss: 0.2294
Epoch 10 Step 1501 Train Loss: 0.2317
Epoch 10 Step 1551 Train Loss: 0.2456
Epoch 10 Step 1601 Train Loss: 0.2425
Epoch 10 Step 1651 Train Loss: 0.2314
Epoch 10 Step 1701 Train Loss: 0.2618
Epoch 10 Step 1751 Train Loss: 0.2418
Epoch 10 Step 1801 Train Loss: 0.2553
Epoch 10 Step 1851 Train Loss: 0.2445
Epoch 10: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 11 Step 1 Train Loss: 0.2385
Epoch 11 Step 51 Train Loss: 0.2372
Epoch 11 Step 101 Train Loss: 0.2509
Epoch 11 Step 151 Train Loss: 0.2351
Epoch 11 Step 201 Train Loss: 0.2348
Epoch 11 Step 251 Train Loss: 0.2421
Epoch 11 Step 301 Train Loss: 0.2104
Epoch 11 Step 351 Train Loss: 0.2421
Epoch 11 Step 401 Train Loss: 0.2473
Epoch 11 Step 451 Train Loss: 0.2508
Epoch 11 Step 501 Train Loss: 0.2346
Epoch 11 Step 551 Train Loss: 0.2476
Epoch 11 Step 601 Train Loss: 0.2442
Epoch 11 Step 651 Train Loss: 0.2658
Epoch 11 Step 701 Train Loss: 0.2393
Epoch 11 Step 751 Train Loss: 0.2361
Epoch 11 Step 801 Train Loss: 0.2363
Epoch 11 Step 851 Train Loss: 0.2394
Epoch 11 Step 901 Train Loss: 0.2517
Epoch 11 Step 951 Train Loss: 0.2296
Epoch 11 Step 1001 Train Loss: 0.2417
Epoch 11 Step 1051 Train Loss: 0.2396
Epoch 11 Step 1101 Train Loss: 0.2541
Epoch 11 Step 1151 Train Loss: 0.2491
Epoch 11 Step 1201 Train Loss: 0.2563
Epoch 11 Step 1251 Train Loss: 0.2233
Epoch 11 Step 1301 Train Loss: 0.2172
Epoch 11 Step 1351 Train Loss: 0.2388
Epoch 11 Step 1401 Train Loss: 0.2399
Epoch 11 Step 1451 Train Loss: 0.2490
Epoch 11 Step 1501 Train Loss: 0.2304
Epoch 11 Step 1551 Train Loss: 0.2277
Epoch 11 Step 1601 Train Loss: 0.2333
Epoch 11 Step 1651 Train Loss: 0.2340
Epoch 11 Step 1701 Train Loss: 0.2246
Epoch 11 Step 1751 Train Loss: 0.2510
Epoch 11 Step 1801 Train Loss: 0.2278
Epoch 11 Step 1851 Train Loss: 0.2456
Epoch 11: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 12 Step 1 Train Loss: 0.2368
Epoch 12 Step 51 Train Loss: 0.2421
Epoch 12 Step 101 Train Loss: 0.2448
Epoch 12 Step 151 Train Loss: 0.2532
Epoch 12 Step 201 Train Loss: 0.2600
Epoch 12 Step 251 Train Loss: 0.2684
Epoch 12 Step 301 Train Loss: 0.2494
Epoch 12 Step 351 Train Loss: 0.2700
Epoch 12 Step 401 Train Loss: 0.2504
Epoch 12 Step 451 Train Loss: 0.2602
Epoch 12 Step 501 Train Loss: 0.2601
Epoch 12 Step 551 Train Loss: 0.2410
Epoch 12 Step 601 Train Loss: 0.2650
Epoch 12 Step 651 Train Loss: 0.2328
Epoch 12 Step 701 Train Loss: 0.2523
Epoch 12 Step 751 Train Loss: 0.2378
Epoch 12 Step 801 Train Loss: 0.2436
Epoch 12 Step 851 Train Loss: 0.2316
Epoch 12 Step 901 Train Loss: 0.2477
Epoch 12 Step 951 Train Loss: 0.2511
Epoch 12 Step 1001 Train Loss: 0.2273
Epoch 12 Step 1051 Train Loss: 0.2363
Epoch 12 Step 1101 Train Loss: 0.2480
Epoch 12 Step 1151 Train Loss: 0.2285
Epoch 12 Step 1201 Train Loss: 0.2408
Epoch 12 Step 1251 Train Loss: 0.2440
Epoch 12 Step 1301 Train Loss: 0.2302
Epoch 12 Step 1351 Train Loss: 0.2417
Epoch 12 Step 1401 Train Loss: 0.2327
Epoch 12 Step 1451 Train Loss: 0.2353
Epoch 12 Step 1501 Train Loss: 0.2595
Epoch 12 Step 1551 Train Loss: 0.2396
Epoch 12 Step 1601 Train Loss: 0.2271
Epoch 12 Step 1651 Train Loss: 0.2269
Epoch 12 Step 1701 Train Loss: 0.2433
Epoch 12 Step 1751 Train Loss: 0.2317
Epoch 12 Step 1801 Train Loss: 0.2251
Epoch 12 Step 1851 Train Loss: 0.2493
Epoch 12: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 13 Step 1 Train Loss: 0.2545
Epoch 13 Step 51 Train Loss: 0.2333
Epoch 13 Step 101 Train Loss: 0.2335
Epoch 13 Step 151 Train Loss: 0.2469
Epoch 13 Step 201 Train Loss: 0.2291
Epoch 13 Step 251 Train Loss: 0.2331
Epoch 13 Step 301 Train Loss: 0.2426
Epoch 13 Step 351 Train Loss: 0.2280
Epoch 13 Step 401 Train Loss: 0.2425
Epoch 13 Step 451 Train Loss: 0.2255
Epoch 13 Step 501 Train Loss: 0.2460
Epoch 13 Step 551 Train Loss: 0.2283
Epoch 13 Step 601 Train Loss: 0.2561
Epoch 13 Step 651 Train Loss: 0.2427
Epoch 13 Step 701 Train Loss: 0.2504
Epoch 13 Step 751 Train Loss: 0.2401
Epoch 13 Step 801 Train Loss: 0.2352
Epoch 13 Step 851 Train Loss: 0.2515
Epoch 13 Step 901 Train Loss: 0.2448
Epoch 13 Step 951 Train Loss: 0.2204
Epoch 13 Step 1001 Train Loss: 0.2440
Epoch 13 Step 1051 Train Loss: 0.2309
Epoch 13 Step 1101 Train Loss: 0.2526
Epoch 13 Step 1151 Train Loss: 0.2346
Epoch 13 Step 1201 Train Loss: 0.2387
Epoch 13 Step 1251 Train Loss: 0.2430
Epoch 13 Step 1301 Train Loss: 0.2285
Epoch 13 Step 1351 Train Loss: 0.2414
Epoch 13 Step 1401 Train Loss: 0.2349
Epoch 13 Step 1451 Train Loss: 0.2385
Epoch 13 Step 1501 Train Loss: 0.2208
Epoch 13 Step 1551 Train Loss: 0.2446
Epoch 13 Step 1601 Train Loss: 0.2316
Epoch 13 Step 1651 Train Loss: 0.2115
Epoch 13 Step 1701 Train Loss: 0.2419
Epoch 13 Step 1751 Train Loss: 0.2399
Epoch 13 Step 1801 Train Loss: 0.2500
Epoch 13 Step 1851 Train Loss: 0.2414
Epoch 13: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 14 Step 1 Train Loss: 0.2320
Epoch 14 Step 51 Train Loss: 0.2539
Epoch 14 Step 101 Train Loss: 0.2437
Epoch 14 Step 151 Train Loss: 0.2467
Epoch 14 Step 201 Train Loss: 0.2254
Epoch 14 Step 251 Train Loss: 0.2445
Epoch 14 Step 301 Train Loss: 0.2599
Epoch 14 Step 351 Train Loss: 0.2353
Epoch 14 Step 401 Train Loss: 0.2257
Epoch 14 Step 451 Train Loss: 0.2451
Epoch 14 Step 501 Train Loss: 0.2287
Epoch 14 Step 551 Train Loss: 0.2557
Epoch 14 Step 601 Train Loss: 0.2322
Epoch 14 Step 651 Train Loss: 0.2322
Epoch 14 Step 701 Train Loss: 0.2413
Epoch 14 Step 751 Train Loss: 0.2497
Epoch 14 Step 801 Train Loss: 0.2607
Epoch 14 Step 851 Train Loss: 0.2370
Epoch 14 Step 901 Train Loss: 0.2198
Epoch 14 Step 951 Train Loss: 0.2421
Epoch 14 Step 1001 Train Loss: 0.2575
Epoch 14 Step 1051 Train Loss: 0.2496
Epoch 14 Step 1101 Train Loss: 0.2573
Epoch 14 Step 1151 Train Loss: 0.2479
Epoch 14 Step 1201 Train Loss: 0.2439
Epoch 14 Step 1251 Train Loss: 0.2244
Epoch 14 Step 1301 Train Loss: 0.2498
Epoch 14 Step 1351 Train Loss: 0.2574
Epoch 14 Step 1401 Train Loss: 0.2441
Epoch 14 Step 1451 Train Loss: 0.2279
Epoch 14 Step 1501 Train Loss: 0.2455
Epoch 14 Step 1551 Train Loss: 0.2613
Epoch 14 Step 1601 Train Loss: 0.2571
Epoch 14 Step 1651 Train Loss: 0.2482
Epoch 14 Step 1701 Train Loss: 0.2380
Epoch 14 Step 1751 Train Loss: 0.2471
Epoch 14 Step 1801 Train Loss: 0.2477
Epoch 14 Step 1851 Train Loss: 0.2311
Epoch 14: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Epoch 15 Step 1 Train Loss: 0.2491
Epoch 15 Step 51 Train Loss: 0.2502
Epoch 15 Step 101 Train Loss: 0.2463
Epoch 15 Step 151 Train Loss: 0.2591
Epoch 15 Step 201 Train Loss: 0.2503
Epoch 15 Step 251 Train Loss: 0.2493
Epoch 15 Step 301 Train Loss: 0.2490
Epoch 15 Step 351 Train Loss: 0.2316
Epoch 15 Step 401 Train Loss: 0.2438
Epoch 15 Step 451 Train Loss: 0.2375
Epoch 15 Step 501 Train Loss: 0.2413
Epoch 15 Step 551 Train Loss: 0.2470
Epoch 15 Step 601 Train Loss: 0.2264
Epoch 15 Step 651 Train Loss: 0.2447
Epoch 15 Step 701 Train Loss: 0.2489
Epoch 15 Step 751 Train Loss: 0.2374
Epoch 15 Step 801 Train Loss: 0.2299
Epoch 15 Step 851 Train Loss: 0.2417
Epoch 15 Step 901 Train Loss: 0.2210
Epoch 15 Step 951 Train Loss: 0.2421
Epoch 15 Step 1001 Train Loss: 0.2361
Epoch 15 Step 1051 Train Loss: 0.2346
Epoch 15 Step 1101 Train Loss: 0.2376
Epoch 15 Step 1151 Train Loss: 0.2664
Epoch 15 Step 1201 Train Loss: 0.2333
Epoch 15 Step 1251 Train Loss: 0.2427
Epoch 15 Step 1301 Train Loss: 0.2501
Epoch 15 Step 1351 Train Loss: 0.2404
Epoch 15 Step 1401 Train Loss: 0.2300
Epoch 15 Step 1451 Train Loss: 0.2528
Epoch 15 Step 1501 Train Loss: 0.2217
Epoch 15 Step 1551 Train Loss: 0.2382
Epoch 15 Step 1601 Train Loss: 0.2477
Epoch 15 Step 1651 Train Loss: 0.2465
Epoch 15 Step 1701 Train Loss: 0.2416
Epoch 15 Step 1751 Train Loss: 0.2514
Epoch 15 Step 1801 Train Loss: 0.2439
Epoch 15 Step 1851 Train Loss: 0.2255
Epoch 15: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0005. 
Train Top 20 DE MSE: 0.0055 Validation Top 20 DE MSE: 0.0083. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0044
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00033281368
test_unseen_single_pearson: 0.9928243984083052
test_unseen_single_mse_de: 0.004438492
test_unseen_single_pearson_de: 0.8028125568160407
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.16071907091874243
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3431372549019608
test_unseen_single_frac_sigma_below_1_non_dropout: 0.931372549019608
test_unseen_single_mse_top20_de_non_dropout: 0.0074429996297817975
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.038 MB uploadedwandb: | 0.027 MB of 0.038 MB uploadedwandb: / 0.027 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñá‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÖ‚ñÑ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                                                      val_mse ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00444
wandb:                                              test_de_pearson 0.80281
wandb:               test_frac_opposite_direction_top20_non_dropout 0.34314
wandb:                          test_frac_sigma_below_1_non_dropout 0.93137
wandb:                                                     test_mse 0.00033
wandb:                                test_mse_top20_de_non_dropout 0.00744
wandb:                                                 test_pearson 0.99282
wandb:                                           test_pearson_delta 0.16072
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.34314
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.93137
wandb:                                       test_unseen_single_mse 0.00033
wandb:                                    test_unseen_single_mse_de 0.00444
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00744
wandb:                                   test_unseen_single_pearson 0.99282
wandb:                                test_unseen_single_pearson_de 0.80281
wandb:                             test_unseen_single_pearson_delta 0.16072
wandb:                                                 train_de_mse 0.00546
wandb:                                             train_de_pearson 0.79166
wandb:                                                    train_mse 0.00033
wandb:                                                train_pearson 0.99282
wandb:                                                training_loss 0.2226
wandb:                                                   val_de_mse 0.00826
wandb:                                               val_de_pearson 0.75109
wandb:                                                      val_mse 0.00055
wandb:                                                  val_pearson 0.98864
wandb: 
wandb: üöÄ View run scbert_XuCao2023_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/alv5jfkp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_081036-alv5jfkp/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:51
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_090504-tbbwo76y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_XuCao2023_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/tbbwo76y
wandb: WARNING Serializing object of type ndarray that is 8275328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2583
Epoch 1 Step 51 Train Loss: 0.2593
Epoch 1 Step 101 Train Loss: 0.2636
Epoch 1 Step 151 Train Loss: 0.2630
Epoch 1 Step 201 Train Loss: 0.2854
Epoch 1 Step 251 Train Loss: 0.2532
Epoch 1 Step 301 Train Loss: 0.2374
Epoch 1 Step 351 Train Loss: 0.2546
Epoch 1 Step 401 Train Loss: 0.2491
Epoch 1 Step 451 Train Loss: 0.2540
Epoch 1 Step 501 Train Loss: 0.2431
Epoch 1 Step 551 Train Loss: 0.2392
Epoch 1 Step 601 Train Loss: 0.2281
Epoch 1 Step 651 Train Loss: 0.2235
Epoch 1 Step 701 Train Loss: 0.2400
Epoch 1 Step 751 Train Loss: 0.2254
Epoch 1 Step 801 Train Loss: 0.2416
Epoch 1 Step 851 Train Loss: 0.2238
Epoch 1 Step 901 Train Loss: 0.2247
Epoch 1 Step 951 Train Loss: 0.2254
Epoch 1 Step 1001 Train Loss: 0.2113
Epoch 1 Step 1051 Train Loss: 0.2254
Epoch 1 Step 1101 Train Loss: 0.2132
Epoch 1 Step 1151 Train Loss: 0.2202
Epoch 1 Step 1201 Train Loss: 0.2122
Epoch 1 Step 1251 Train Loss: 0.1971
Epoch 1 Step 1301 Train Loss: 0.2082
Epoch 1 Step 1351 Train Loss: 0.2297
Epoch 1 Step 1401 Train Loss: 0.2296
Epoch 1 Step 1451 Train Loss: 0.2256
Epoch 1 Step 1501 Train Loss: 0.2207
Epoch 1 Step 1551 Train Loss: 0.2110
Epoch 1 Step 1601 Train Loss: 0.2510
Epoch 1 Step 1651 Train Loss: 0.2151
Epoch 1 Step 1701 Train Loss: 0.2054
Epoch 1 Step 1751 Train Loss: 0.2156
Epoch 1 Step 1801 Train Loss: 0.2412
Epoch 1 Step 1851 Train Loss: 0.2350
Epoch 1 Step 1901 Train Loss: 0.1993
Epoch 1 Step 1951 Train Loss: 0.2224
Epoch 1 Step 2001 Train Loss: 0.2375
Epoch 1: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 2 Step 1 Train Loss: 0.2136
Epoch 2 Step 51 Train Loss: 0.2322
Epoch 2 Step 101 Train Loss: 0.2144
Epoch 2 Step 151 Train Loss: 0.2249
Epoch 2 Step 201 Train Loss: 0.2150
Epoch 2 Step 251 Train Loss: 0.2315
Epoch 2 Step 301 Train Loss: 0.2163
Epoch 2 Step 351 Train Loss: 0.2355
Epoch 2 Step 401 Train Loss: 0.2355
Epoch 2 Step 451 Train Loss: 0.2119
Epoch 2 Step 501 Train Loss: 0.2192
Epoch 2 Step 551 Train Loss: 0.2201
Epoch 2 Step 601 Train Loss: 0.2416
Epoch 2 Step 651 Train Loss: 0.2175
Epoch 2 Step 701 Train Loss: 0.2392
Epoch 2 Step 751 Train Loss: 0.2455
Epoch 2 Step 801 Train Loss: 0.2409
Epoch 2 Step 851 Train Loss: 0.2213
Epoch 2 Step 901 Train Loss: 0.2064
Epoch 2 Step 951 Train Loss: 0.2131
Epoch 2 Step 1001 Train Loss: 0.2155
Epoch 2 Step 1051 Train Loss: 0.2264
Epoch 2 Step 1101 Train Loss: 0.2196
Epoch 2 Step 1151 Train Loss: 0.2141
Epoch 2 Step 1201 Train Loss: 0.2130
Epoch 2 Step 1251 Train Loss: 0.2116
Epoch 2 Step 1301 Train Loss: 0.2276
Epoch 2 Step 1351 Train Loss: 0.2209
Epoch 2 Step 1401 Train Loss: 0.2240
Epoch 2 Step 1451 Train Loss: 0.2357
Epoch 2 Step 1501 Train Loss: 0.2532
Epoch 2 Step 1551 Train Loss: 0.2290
Epoch 2 Step 1601 Train Loss: 0.2293
Epoch 2 Step 1651 Train Loss: 0.2298
Epoch 2 Step 1701 Train Loss: 0.2210
Epoch 2 Step 1751 Train Loss: 0.2177
Epoch 2 Step 1801 Train Loss: 0.2184
Epoch 2 Step 1851 Train Loss: 0.2111
Epoch 2 Step 1901 Train Loss: 0.2445
Epoch 2 Step 1951 Train Loss: 0.2102
Epoch 2 Step 2001 Train Loss: 0.2208
Epoch 2: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 3 Step 1 Train Loss: 0.2140
Epoch 3 Step 51 Train Loss: 0.2219
Epoch 3 Step 101 Train Loss: 0.2109
Epoch 3 Step 151 Train Loss: 0.2410
Epoch 3 Step 201 Train Loss: 0.2293
Epoch 3 Step 251 Train Loss: 0.2306
Epoch 3 Step 301 Train Loss: 0.2443
Epoch 3 Step 351 Train Loss: 0.2196
Epoch 3 Step 401 Train Loss: 0.2314
Epoch 3 Step 451 Train Loss: 0.2560
Epoch 3 Step 501 Train Loss: 0.2223
Epoch 3 Step 551 Train Loss: 0.2425
Epoch 3 Step 601 Train Loss: 0.2230
Epoch 3 Step 651 Train Loss: 0.2440
Epoch 3 Step 701 Train Loss: 0.2184
Epoch 3 Step 751 Train Loss: 0.2393
Epoch 3 Step 801 Train Loss: 0.2147
Epoch 3 Step 851 Train Loss: 0.2188
Epoch 3 Step 901 Train Loss: 0.2197
Epoch 3 Step 951 Train Loss: 0.2408
Epoch 3 Step 1001 Train Loss: 0.2364
Epoch 3 Step 1051 Train Loss: 0.2194
Epoch 3 Step 1101 Train Loss: 0.2548
Epoch 3 Step 1151 Train Loss: 0.2169
Epoch 3 Step 1201 Train Loss: 0.2369
Epoch 3 Step 1251 Train Loss: 0.2277
Epoch 3 Step 1301 Train Loss: 0.2303
Epoch 3 Step 1351 Train Loss: 0.2529
Epoch 3 Step 1401 Train Loss: 0.2228
Epoch 3 Step 1451 Train Loss: 0.2343
Epoch 3 Step 1501 Train Loss: 0.2280
Epoch 3 Step 1551 Train Loss: 0.2261
Epoch 3 Step 1601 Train Loss: 0.2221
Epoch 3 Step 1651 Train Loss: 0.2200
Epoch 3 Step 1701 Train Loss: 0.2415
Epoch 3 Step 1751 Train Loss: 0.2373
Epoch 3 Step 1801 Train Loss: 0.2449
Epoch 3 Step 1851 Train Loss: 0.2176
Epoch 3 Step 1901 Train Loss: 0.2236
Epoch 3 Step 1951 Train Loss: 0.2202
Epoch 3 Step 2001 Train Loss: 0.2398
Epoch 3: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0039. 
Epoch 4 Step 1 Train Loss: 0.2431
Epoch 4 Step 51 Train Loss: 0.2330
Epoch 4 Step 101 Train Loss: 0.2300
Epoch 4 Step 151 Train Loss: 0.2401
Epoch 4 Step 201 Train Loss: 0.2221
Epoch 4 Step 251 Train Loss: 0.2404
Epoch 4 Step 301 Train Loss: 0.2388
Epoch 4 Step 351 Train Loss: 0.2527
Epoch 4 Step 401 Train Loss: 0.2222
Epoch 4 Step 451 Train Loss: 0.2179
Epoch 4 Step 501 Train Loss: 0.2414
Epoch 4 Step 551 Train Loss: 0.2355
Epoch 4 Step 601 Train Loss: 0.2144
Epoch 4 Step 651 Train Loss: 0.2338
Epoch 4 Step 701 Train Loss: 0.2324
Epoch 4 Step 751 Train Loss: 0.2271
Epoch 4 Step 801 Train Loss: 0.2315
Epoch 4 Step 851 Train Loss: 0.2280
Epoch 4 Step 901 Train Loss: 0.2200
Epoch 4 Step 951 Train Loss: 0.2358
Epoch 4 Step 1001 Train Loss: 0.2479
Epoch 4 Step 1051 Train Loss: 0.2436
Epoch 4 Step 1101 Train Loss: 0.2257
Epoch 4 Step 1151 Train Loss: 0.2195
Epoch 4 Step 1201 Train Loss: 0.2268
Epoch 4 Step 1251 Train Loss: 0.2322
Epoch 4 Step 1301 Train Loss: 0.2392
Epoch 4 Step 1351 Train Loss: 0.2260
Epoch 4 Step 1401 Train Loss: 0.2410
Epoch 4 Step 1451 Train Loss: 0.2507
Epoch 4 Step 1501 Train Loss: 0.2742
Epoch 4 Step 1551 Train Loss: 0.2311
Epoch 4 Step 1601 Train Loss: 0.2353
Epoch 4 Step 1651 Train Loss: 0.2266
Epoch 4 Step 1701 Train Loss: 0.2173
Epoch 4 Step 1751 Train Loss: 0.2315
Epoch 4 Step 1801 Train Loss: 0.2372
Epoch 4 Step 1851 Train Loss: 0.2461
Epoch 4 Step 1901 Train Loss: 0.2471
Epoch 4 Step 1951 Train Loss: 0.2550
Epoch 4 Step 2001 Train Loss: 0.2345
Epoch 4: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 5 Step 1 Train Loss: 0.2368
Epoch 5 Step 51 Train Loss: 0.2593
Epoch 5 Step 101 Train Loss: 0.2374
Epoch 5 Step 151 Train Loss: 0.2538
Epoch 5 Step 201 Train Loss: 0.2352
Epoch 5 Step 251 Train Loss: 0.2326
Epoch 5 Step 301 Train Loss: 0.2376
Epoch 5 Step 351 Train Loss: 0.2449
Epoch 5 Step 401 Train Loss: 0.2293
Epoch 5 Step 451 Train Loss: 0.2204
Epoch 5 Step 501 Train Loss: 0.2424
Epoch 5 Step 551 Train Loss: 0.2447
Epoch 5 Step 601 Train Loss: 0.2482
Epoch 5 Step 651 Train Loss: 0.2118
Epoch 5 Step 701 Train Loss: 0.2511
Epoch 5 Step 751 Train Loss: 0.2463
Epoch 5 Step 801 Train Loss: 0.2364
Epoch 5 Step 851 Train Loss: 0.2481
Epoch 5 Step 901 Train Loss: 0.2274
Epoch 5 Step 951 Train Loss: 0.2235
Epoch 5 Step 1001 Train Loss: 0.2250
Epoch 5 Step 1051 Train Loss: 0.2289
Epoch 5 Step 1101 Train Loss: 0.2502
Epoch 5 Step 1151 Train Loss: 0.2333
Epoch 5 Step 1201 Train Loss: 0.2186
Epoch 5 Step 1251 Train Loss: 0.2527
Epoch 5 Step 1301 Train Loss: 0.2345
Epoch 5 Step 1351 Train Loss: 0.2282
Epoch 5 Step 1401 Train Loss: 0.2423
Epoch 5 Step 1451 Train Loss: 0.2463
Epoch 5 Step 1501 Train Loss: 0.2425
Epoch 5 Step 1551 Train Loss: 0.2320
Epoch 5 Step 1601 Train Loss: 0.2419
Epoch 5 Step 1651 Train Loss: 0.2382
Epoch 5 Step 1701 Train Loss: 0.2255
Epoch 5 Step 1751 Train Loss: 0.2386
Epoch 5 Step 1801 Train Loss: 0.2267
Epoch 5 Step 1851 Train Loss: 0.2267
Epoch 5 Step 1901 Train Loss: 0.2161
Epoch 5 Step 1951 Train Loss: 0.2376
Epoch 5 Step 2001 Train Loss: 0.2317
Epoch 5: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 6 Step 1 Train Loss: 0.2443
Epoch 6 Step 51 Train Loss: 0.2171
Epoch 6 Step 101 Train Loss: 0.2415
Epoch 6 Step 151 Train Loss: 0.2364
Epoch 6 Step 201 Train Loss: 0.2188
Epoch 6 Step 251 Train Loss: 0.2120
Epoch 6 Step 301 Train Loss: 0.2512
Epoch 6 Step 351 Train Loss: 0.2353
Epoch 6 Step 401 Train Loss: 0.2314
Epoch 6 Step 451 Train Loss: 0.2509
Epoch 6 Step 501 Train Loss: 0.2437
Epoch 6 Step 551 Train Loss: 0.2374
Epoch 6 Step 601 Train Loss: 0.2448
Epoch 6 Step 651 Train Loss: 0.2381
Epoch 6 Step 701 Train Loss: 0.2602
Epoch 6 Step 751 Train Loss: 0.2296
Epoch 6 Step 801 Train Loss: 0.2369
Epoch 6 Step 851 Train Loss: 0.2499
Epoch 6 Step 901 Train Loss: 0.2367
Epoch 6 Step 951 Train Loss: 0.2251
Epoch 6 Step 1001 Train Loss: 0.2444
Epoch 6 Step 1051 Train Loss: 0.2369
Epoch 6 Step 1101 Train Loss: 0.2448
Epoch 6 Step 1151 Train Loss: 0.2617
Epoch 6 Step 1201 Train Loss: 0.2170
Epoch 6 Step 1251 Train Loss: 0.2263
Epoch 6 Step 1301 Train Loss: 0.2393
Epoch 6 Step 1351 Train Loss: 0.2290
Epoch 6 Step 1401 Train Loss: 0.2329
Epoch 6 Step 1451 Train Loss: 0.2548
Epoch 6 Step 1501 Train Loss: 0.2638
Epoch 6 Step 1551 Train Loss: 0.2281
Epoch 6 Step 1601 Train Loss: 0.2558
Epoch 6 Step 1651 Train Loss: 0.2308
Epoch 6 Step 1701 Train Loss: 0.2291
Epoch 6 Step 1751 Train Loss: 0.2418
Epoch 6 Step 1801 Train Loss: 0.2490
Epoch 6 Step 1851 Train Loss: 0.2383
Epoch 6 Step 1901 Train Loss: 0.2060
Epoch 6 Step 1951 Train Loss: 0.2261
Epoch 6 Step 2001 Train Loss: 0.2273
Epoch 6: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 7 Step 1 Train Loss: 0.2230
Epoch 7 Step 51 Train Loss: 0.2359
Epoch 7 Step 101 Train Loss: 0.2396
Epoch 7 Step 151 Train Loss: 0.2304
Epoch 7 Step 201 Train Loss: 0.2356
Epoch 7 Step 251 Train Loss: 0.2361
Epoch 7 Step 301 Train Loss: 0.2398
Epoch 7 Step 351 Train Loss: 0.2283
Epoch 7 Step 401 Train Loss: 0.2358
Epoch 7 Step 451 Train Loss: 0.2425
Epoch 7 Step 501 Train Loss: 0.2388
Epoch 7 Step 551 Train Loss: 0.2634
Epoch 7 Step 601 Train Loss: 0.2169
Epoch 7 Step 651 Train Loss: 0.2590
Epoch 7 Step 701 Train Loss: 0.2509
Epoch 7 Step 751 Train Loss: 0.2344
Epoch 7 Step 801 Train Loss: 0.2212
Epoch 7 Step 851 Train Loss: 0.2283
Epoch 7 Step 901 Train Loss: 0.2520
Epoch 7 Step 951 Train Loss: 0.2520
Epoch 7 Step 1001 Train Loss: 0.2290
Epoch 7 Step 1051 Train Loss: 0.2355
Epoch 7 Step 1101 Train Loss: 0.2221
Epoch 7 Step 1151 Train Loss: 0.2321
Epoch 7 Step 1201 Train Loss: 0.2399
Epoch 7 Step 1251 Train Loss: 0.2212
Epoch 7 Step 1301 Train Loss: 0.2287
Epoch 7 Step 1351 Train Loss: 0.2616
Epoch 7 Step 1401 Train Loss: 0.2522
Epoch 7 Step 1451 Train Loss: 0.2383
Epoch 7 Step 1501 Train Loss: 0.2632
Epoch 7 Step 1551 Train Loss: 0.2381
Epoch 7 Step 1601 Train Loss: 0.2578
Epoch 7 Step 1651 Train Loss: 0.2442
Epoch 7 Step 1701 Train Loss: 0.2538
Epoch 7 Step 1751 Train Loss: 0.2316
Epoch 7 Step 1801 Train Loss: 0.2399
Epoch 7 Step 1851 Train Loss: 0.2307
Epoch 7 Step 1901 Train Loss: 0.2403
Epoch 7 Step 1951 Train Loss: 0.2512
Epoch 7 Step 2001 Train Loss: 0.2248
Epoch 7: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 8 Step 1 Train Loss: 0.2380
Epoch 8 Step 51 Train Loss: 0.2294
Epoch 8 Step 101 Train Loss: 0.2483
Epoch 8 Step 151 Train Loss: 0.2372
Epoch 8 Step 201 Train Loss: 0.2196
Epoch 8 Step 251 Train Loss: 0.2388
Epoch 8 Step 301 Train Loss: 0.2423
Epoch 8 Step 351 Train Loss: 0.2319
Epoch 8 Step 401 Train Loss: 0.2401
Epoch 8 Step 451 Train Loss: 0.2197
Epoch 8 Step 501 Train Loss: 0.2192
Epoch 8 Step 551 Train Loss: 0.2307
Epoch 8 Step 601 Train Loss: 0.2352
Epoch 8 Step 651 Train Loss: 0.2361
Epoch 8 Step 701 Train Loss: 0.2416
Epoch 8 Step 751 Train Loss: 0.2301
Epoch 8 Step 801 Train Loss: 0.2394
Epoch 8 Step 851 Train Loss: 0.2359
Epoch 8 Step 901 Train Loss: 0.2263
Epoch 8 Step 951 Train Loss: 0.2336
Epoch 8 Step 1001 Train Loss: 0.2402
Epoch 8 Step 1051 Train Loss: 0.2590
Epoch 8 Step 1101 Train Loss: 0.2266
Epoch 8 Step 1151 Train Loss: 0.2268
Epoch 8 Step 1201 Train Loss: 0.2505
Epoch 8 Step 1251 Train Loss: 0.2553
Epoch 8 Step 1301 Train Loss: 0.2473
Epoch 8 Step 1351 Train Loss: 0.2701
Epoch 8 Step 1401 Train Loss: 0.2432
Epoch 8 Step 1451 Train Loss: 0.2327
Epoch 8 Step 1501 Train Loss: 0.2349
Epoch 8 Step 1551 Train Loss: 0.2370
Epoch 8 Step 1601 Train Loss: 0.2295
Epoch 8 Step 1651 Train Loss: 0.2214
Epoch 8 Step 1701 Train Loss: 0.2431
Epoch 8 Step 1751 Train Loss: 0.2361
Epoch 8 Step 1801 Train Loss: 0.2392
Epoch 8 Step 1851 Train Loss: 0.2414
Epoch 8 Step 1901 Train Loss: 0.2534
Epoch 8 Step 1951 Train Loss: 0.2497
Epoch 8 Step 2001 Train Loss: 0.2396
Epoch 8: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 9 Step 1 Train Loss: 0.2317
Epoch 9 Step 51 Train Loss: 0.2478
Epoch 9 Step 101 Train Loss: 0.2422
Epoch 9 Step 151 Train Loss: 0.2517
Epoch 9 Step 201 Train Loss: 0.2431
Epoch 9 Step 251 Train Loss: 0.2434
Epoch 9 Step 301 Train Loss: 0.2349
Epoch 9 Step 351 Train Loss: 0.2278
Epoch 9 Step 401 Train Loss: 0.2386
Epoch 9 Step 451 Train Loss: 0.2347
Epoch 9 Step 501 Train Loss: 0.2526
Epoch 9 Step 551 Train Loss: 0.2250
Epoch 9 Step 601 Train Loss: 0.2532
Epoch 9 Step 651 Train Loss: 0.2358
Epoch 9 Step 701 Train Loss: 0.2568
Epoch 9 Step 751 Train Loss: 0.2501
Epoch 9 Step 801 Train Loss: 0.2180
Epoch 9 Step 851 Train Loss: 0.2267
Epoch 9 Step 901 Train Loss: 0.2598
Epoch 9 Step 951 Train Loss: 0.2298
Epoch 9 Step 1001 Train Loss: 0.2433
Epoch 9 Step 1051 Train Loss: 0.2544
Epoch 9 Step 1101 Train Loss: 0.2346
Epoch 9 Step 1151 Train Loss: 0.2347
Epoch 9 Step 1201 Train Loss: 0.2260
Epoch 9 Step 1251 Train Loss: 0.2355
Epoch 9 Step 1301 Train Loss: 0.2405
Epoch 9 Step 1351 Train Loss: 0.2418
Epoch 9 Step 1401 Train Loss: 0.2188
Epoch 9 Step 1451 Train Loss: 0.2308
Epoch 9 Step 1501 Train Loss: 0.2377
Epoch 9 Step 1551 Train Loss: 0.2409
Epoch 9 Step 1601 Train Loss: 0.2336
Epoch 9 Step 1651 Train Loss: 0.2301
Epoch 9 Step 1701 Train Loss: 0.2549
Epoch 9 Step 1751 Train Loss: 0.2297
Epoch 9 Step 1801 Train Loss: 0.2362
Epoch 9 Step 1851 Train Loss: 0.2244
Epoch 9 Step 1901 Train Loss: 0.2280
Epoch 9 Step 1951 Train Loss: 0.2451
Epoch 9 Step 2001 Train Loss: 0.2414
Epoch 9: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 10 Step 1 Train Loss: 0.2498
Epoch 10 Step 51 Train Loss: 0.2406
Epoch 10 Step 101 Train Loss: 0.2332
Epoch 10 Step 151 Train Loss: 0.2393
Epoch 10 Step 201 Train Loss: 0.2332
Epoch 10 Step 251 Train Loss: 0.2445
Epoch 10 Step 301 Train Loss: 0.2301
Epoch 10 Step 351 Train Loss: 0.2487
Epoch 10 Step 401 Train Loss: 0.2456
Epoch 10 Step 451 Train Loss: 0.2436
Epoch 10 Step 501 Train Loss: 0.2446
Epoch 10 Step 551 Train Loss: 0.2254
Epoch 10 Step 601 Train Loss: 0.2365
Epoch 10 Step 651 Train Loss: 0.2412
Epoch 10 Step 701 Train Loss: 0.2536
Epoch 10 Step 751 Train Loss: 0.2393
Epoch 10 Step 801 Train Loss: 0.2566
Epoch 10 Step 851 Train Loss: 0.2479
Epoch 10 Step 901 Train Loss: 0.2470
Epoch 10 Step 951 Train Loss: 0.2285
Epoch 10 Step 1001 Train Loss: 0.2291
Epoch 10 Step 1051 Train Loss: 0.2291
Epoch 10 Step 1101 Train Loss: 0.2344
Epoch 10 Step 1151 Train Loss: 0.2208
Epoch 10 Step 1201 Train Loss: 0.2238
Epoch 10 Step 1251 Train Loss: 0.2312
Epoch 10 Step 1301 Train Loss: 0.2482
Epoch 10 Step 1351 Train Loss: 0.2483
Epoch 10 Step 1401 Train Loss: 0.2281
Epoch 10 Step 1451 Train Loss: 0.2340
Epoch 10 Step 1501 Train Loss: 0.2512
Epoch 10 Step 1551 Train Loss: 0.2528
Epoch 10 Step 1601 Train Loss: 0.2212
Epoch 10 Step 1651 Train Loss: 0.2432
Epoch 10 Step 1701 Train Loss: 0.2374
Epoch 10 Step 1751 Train Loss: 0.2418
Epoch 10 Step 1801 Train Loss: 0.2508
Epoch 10 Step 1851 Train Loss: 0.2308
Epoch 10 Step 1901 Train Loss: 0.2341
Epoch 10 Step 1951 Train Loss: 0.2359
Epoch 10 Step 2001 Train Loss: 0.2359
Epoch 10: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 11 Step 1 Train Loss: 0.2426
Epoch 11 Step 51 Train Loss: 0.2255
Epoch 11 Step 101 Train Loss: 0.2266
Epoch 11 Step 151 Train Loss: 0.2382
Epoch 11 Step 201 Train Loss: 0.2420
Epoch 11 Step 251 Train Loss: 0.2258
Epoch 11 Step 301 Train Loss: 0.2454
Epoch 11 Step 351 Train Loss: 0.2463
Epoch 11 Step 401 Train Loss: 0.2385
Epoch 11 Step 451 Train Loss: 0.2570
Epoch 11 Step 501 Train Loss: 0.2318
Epoch 11 Step 551 Train Loss: 0.2357
Epoch 11 Step 601 Train Loss: 0.2571
Epoch 11 Step 651 Train Loss: 0.2391
Epoch 11 Step 701 Train Loss: 0.2371
Epoch 11 Step 751 Train Loss: 0.2472
Epoch 11 Step 801 Train Loss: 0.2382
Epoch 11 Step 851 Train Loss: 0.2322
Epoch 11 Step 901 Train Loss: 0.2482
Epoch 11 Step 951 Train Loss: 0.2395
Epoch 11 Step 1001 Train Loss: 0.2480
Epoch 11 Step 1051 Train Loss: 0.2239
Epoch 11 Step 1101 Train Loss: 0.2335
Epoch 11 Step 1151 Train Loss: 0.2446
Epoch 11 Step 1201 Train Loss: 0.2255
Epoch 11 Step 1251 Train Loss: 0.2342
Epoch 11 Step 1301 Train Loss: 0.2535
Epoch 11 Step 1351 Train Loss: 0.2379
Epoch 11 Step 1401 Train Loss: 0.2401
Epoch 11 Step 1451 Train Loss: 0.2425
Epoch 11 Step 1501 Train Loss: 0.2389
Epoch 11 Step 1551 Train Loss: 0.2452
Epoch 11 Step 1601 Train Loss: 0.2513
Epoch 11 Step 1651 Train Loss: 0.2331
Epoch 11 Step 1701 Train Loss: 0.2223
Epoch 11 Step 1751 Train Loss: 0.2363
Epoch 11 Step 1801 Train Loss: 0.2293
Epoch 11 Step 1851 Train Loss: 0.2502
Epoch 11 Step 1901 Train Loss: 0.2357
Epoch 11 Step 1951 Train Loss: 0.2442
Epoch 11 Step 2001 Train Loss: 0.2263
Epoch 11: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 12 Step 1 Train Loss: 0.2447
Epoch 12 Step 51 Train Loss: 0.2607
Epoch 12 Step 101 Train Loss: 0.2501
Epoch 12 Step 151 Train Loss: 0.2466
Epoch 12 Step 201 Train Loss: 0.2485
Epoch 12 Step 251 Train Loss: 0.2389
Epoch 12 Step 301 Train Loss: 0.2408
Epoch 12 Step 351 Train Loss: 0.2267
Epoch 12 Step 401 Train Loss: 0.2292
Epoch 12 Step 451 Train Loss: 0.2662
Epoch 12 Step 501 Train Loss: 0.2303
Epoch 12 Step 551 Train Loss: 0.2431
Epoch 12 Step 601 Train Loss: 0.2321
Epoch 12 Step 651 Train Loss: 0.2389
Epoch 12 Step 701 Train Loss: 0.2306
Epoch 12 Step 751 Train Loss: 0.2332
Epoch 12 Step 801 Train Loss: 0.2254
Epoch 12 Step 851 Train Loss: 0.2520
Epoch 12 Step 901 Train Loss: 0.2589
Epoch 12 Step 951 Train Loss: 0.2304
Epoch 12 Step 1001 Train Loss: 0.2399
Epoch 12 Step 1051 Train Loss: 0.2420
Epoch 12 Step 1101 Train Loss: 0.2641
Epoch 12 Step 1151 Train Loss: 0.2462
Epoch 12 Step 1201 Train Loss: 0.2486
Epoch 12 Step 1251 Train Loss: 0.2237
Epoch 12 Step 1301 Train Loss: 0.2326
Epoch 12 Step 1351 Train Loss: 0.2449
Epoch 12 Step 1401 Train Loss: 0.2399
Epoch 12 Step 1451 Train Loss: 0.2415
Epoch 12 Step 1501 Train Loss: 0.2419
Epoch 12 Step 1551 Train Loss: 0.2558
Epoch 12 Step 1601 Train Loss: 0.2421
Epoch 12 Step 1651 Train Loss: 0.2221
Epoch 12 Step 1701 Train Loss: 0.2397
Epoch 12 Step 1751 Train Loss: 0.2341
Epoch 12 Step 1801 Train Loss: 0.2325
Epoch 12 Step 1851 Train Loss: 0.2589
Epoch 12 Step 1901 Train Loss: 0.2308
Epoch 12 Step 1951 Train Loss: 0.2405
Epoch 12 Step 2001 Train Loss: 0.2360
Epoch 12: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 13 Step 1 Train Loss: 0.2494
Epoch 13 Step 51 Train Loss: 0.2282
Epoch 13 Step 101 Train Loss: 0.2228
Epoch 13 Step 151 Train Loss: 0.2357
Epoch 13 Step 201 Train Loss: 0.2446
Epoch 13 Step 251 Train Loss: 0.2275
Epoch 13 Step 301 Train Loss: 0.2367
Epoch 13 Step 351 Train Loss: 0.2503
Epoch 13 Step 401 Train Loss: 0.2640
Epoch 13 Step 451 Train Loss: 0.2561
Epoch 13 Step 501 Train Loss: 0.2346
Epoch 13 Step 551 Train Loss: 0.2287
Epoch 13 Step 601 Train Loss: 0.2370
Epoch 13 Step 651 Train Loss: 0.2298
Epoch 13 Step 701 Train Loss: 0.2160
Epoch 13 Step 751 Train Loss: 0.2647
Epoch 13 Step 801 Train Loss: 0.2309
Epoch 13 Step 851 Train Loss: 0.2581
Epoch 13 Step 901 Train Loss: 0.2587
Epoch 13 Step 951 Train Loss: 0.2195
Epoch 13 Step 1001 Train Loss: 0.2390
Epoch 13 Step 1051 Train Loss: 0.2219
Epoch 13 Step 1101 Train Loss: 0.2339
Epoch 13 Step 1151 Train Loss: 0.2419
Epoch 13 Step 1201 Train Loss: 0.2246
Epoch 13 Step 1251 Train Loss: 0.2115
Epoch 13 Step 1301 Train Loss: 0.2361
Epoch 13 Step 1351 Train Loss: 0.2276
Epoch 13 Step 1401 Train Loss: 0.2367
Epoch 13 Step 1451 Train Loss: 0.2342
Epoch 13 Step 1501 Train Loss: 0.2361
Epoch 13 Step 1551 Train Loss: 0.2451
Epoch 13 Step 1601 Train Loss: 0.2361
Epoch 13 Step 1651 Train Loss: 0.2345
Epoch 13 Step 1701 Train Loss: 0.2494
Epoch 13 Step 1751 Train Loss: 0.2198
Epoch 13 Step 1801 Train Loss: 0.2644
Epoch 13 Step 1851 Train Loss: 0.2206
Epoch 13 Step 1901 Train Loss: 0.2397
Epoch 13 Step 1951 Train Loss: 0.2487
Epoch 13 Step 2001 Train Loss: 0.2421
Epoch 13: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 14 Step 1 Train Loss: 0.2261
Epoch 14 Step 51 Train Loss: 0.2461
Epoch 14 Step 101 Train Loss: 0.2518
Epoch 14 Step 151 Train Loss: 0.2266
Epoch 14 Step 201 Train Loss: 0.2533
Epoch 14 Step 251 Train Loss: 0.2367
Epoch 14 Step 301 Train Loss: 0.2332
Epoch 14 Step 351 Train Loss: 0.2238
Epoch 14 Step 401 Train Loss: 0.2329
Epoch 14 Step 451 Train Loss: 0.2262
Epoch 14 Step 501 Train Loss: 0.2270
Epoch 14 Step 551 Train Loss: 0.2282
Epoch 14 Step 601 Train Loss: 0.2081
Epoch 14 Step 651 Train Loss: 0.2414
Epoch 14 Step 701 Train Loss: 0.2312
Epoch 14 Step 751 Train Loss: 0.2393
Epoch 14 Step 801 Train Loss: 0.2164
Epoch 14 Step 851 Train Loss: 0.2261
Epoch 14 Step 901 Train Loss: 0.2658
Epoch 14 Step 951 Train Loss: 0.2306
Epoch 14 Step 1001 Train Loss: 0.2420
Epoch 14 Step 1051 Train Loss: 0.2665
Epoch 14 Step 1101 Train Loss: 0.2482
Epoch 14 Step 1151 Train Loss: 0.2324
Epoch 14 Step 1201 Train Loss: 0.2286
Epoch 14 Step 1251 Train Loss: 0.2316
Epoch 14 Step 1301 Train Loss: 0.2459
Epoch 14 Step 1351 Train Loss: 0.2207
Epoch 14 Step 1401 Train Loss: 0.2316
Epoch 14 Step 1451 Train Loss: 0.2332
Epoch 14 Step 1501 Train Loss: 0.2345
Epoch 14 Step 1551 Train Loss: 0.2428
Epoch 14 Step 1601 Train Loss: 0.2386
Epoch 14 Step 1651 Train Loss: 0.2313
Epoch 14 Step 1701 Train Loss: 0.2626
Epoch 14 Step 1751 Train Loss: 0.2427
Epoch 14 Step 1801 Train Loss: 0.2339
Epoch 14 Step 1851 Train Loss: 0.2594
Epoch 14 Step 1901 Train Loss: 0.2311
Epoch 14 Step 1951 Train Loss: 0.2374
Epoch 14 Step 2001 Train Loss: 0.2361
Epoch 14: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Epoch 15 Step 1 Train Loss: 0.2397
Epoch 15 Step 51 Train Loss: 0.2396
Epoch 15 Step 101 Train Loss: 0.2481
Epoch 15 Step 151 Train Loss: 0.2325
Epoch 15 Step 201 Train Loss: 0.2208
Epoch 15 Step 251 Train Loss: 0.2595
Epoch 15 Step 301 Train Loss: 0.2451
Epoch 15 Step 351 Train Loss: 0.2404
Epoch 15 Step 401 Train Loss: 0.2566
Epoch 15 Step 451 Train Loss: 0.2313
Epoch 15 Step 501 Train Loss: 0.2305
Epoch 15 Step 551 Train Loss: 0.2496
Epoch 15 Step 601 Train Loss: 0.2283
Epoch 15 Step 651 Train Loss: 0.2480
Epoch 15 Step 701 Train Loss: 0.2348
Epoch 15 Step 751 Train Loss: 0.2523
Epoch 15 Step 801 Train Loss: 0.2433
Epoch 15 Step 851 Train Loss: 0.2543
Epoch 15 Step 901 Train Loss: 0.2487
Epoch 15 Step 951 Train Loss: 0.2265
Epoch 15 Step 1001 Train Loss: 0.2645
Epoch 15 Step 1051 Train Loss: 0.2208
Epoch 15 Step 1101 Train Loss: 0.2425
Epoch 15 Step 1151 Train Loss: 0.2675
Epoch 15 Step 1201 Train Loss: 0.2358
Epoch 15 Step 1251 Train Loss: 0.2411
Epoch 15 Step 1301 Train Loss: 0.2354
Epoch 15 Step 1351 Train Loss: 0.2303
Epoch 15 Step 1401 Train Loss: 0.2357
Epoch 15 Step 1451 Train Loss: 0.2282
Epoch 15 Step 1501 Train Loss: 0.2344
Epoch 15 Step 1551 Train Loss: 0.2183
Epoch 15 Step 1601 Train Loss: 0.2353
Epoch 15 Step 1651 Train Loss: 0.2341
Epoch 15 Step 1701 Train Loss: 0.2312
Epoch 15 Step 1751 Train Loss: 0.2489
Epoch 15 Step 1801 Train Loss: 0.2162
Epoch 15 Step 1851 Train Loss: 0.2554
Epoch 15 Step 1901 Train Loss: 0.2212
Epoch 15 Step 1951 Train Loss: 0.2457
Epoch 15 Step 2001 Train Loss: 0.2255
Epoch 15: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0006. 
Train Top 20 DE MSE: 0.0061 Validation Top 20 DE MSE: 0.0038. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0040
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00037717356
test_unseen_single_pearson: 0.9919990044816361
test_unseen_single_mse_de: 0.004033598
test_unseen_single_pearson_de: 0.7995198153089685
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.14591779645721795
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.35294117647058826
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9107843137254903
test_unseen_single_mse_top20_de_non_dropout: 0.008596118572273465
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.039 MB uploadedwandb: | 0.009 MB of 0.039 MB uploadedwandb: / 0.009 MB of 0.039 MB uploadedwandb: - 0.039 MB of 0.039 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                             train_de_pearson ‚ñà‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                                                    train_mse ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñá‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÜ
wandb:                                                   val_de_mse ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                               val_de_pearson ‚ñÅ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00403
wandb:                                              test_de_pearson 0.79952
wandb:               test_frac_opposite_direction_top20_non_dropout 0.35294
wandb:                          test_frac_sigma_below_1_non_dropout 0.91078
wandb:                                                     test_mse 0.00038
wandb:                                test_mse_top20_de_non_dropout 0.0086
wandb:                                                 test_pearson 0.992
wandb:                                           test_pearson_delta 0.14592
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.35294
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.91078
wandb:                                       test_unseen_single_mse 0.00038
wandb:                                    test_unseen_single_mse_de 0.00403
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.0086
wandb:                                   test_unseen_single_pearson 0.992
wandb:                                test_unseen_single_pearson_de 0.79952
wandb:                             test_unseen_single_pearson_delta 0.14592
wandb:                                                 train_de_mse 0.0061
wandb:                                             train_de_pearson 0.79516
wandb:                                                    train_mse 0.00032
wandb:                                                train_pearson 0.99306
wandb:                                                training_loss 0.24244
wandb:                                                   val_de_mse 0.00379
wandb:                                               val_de_pearson 0.70176
wandb:                                                      val_mse 0.00056
wandb:                                                  val_pearson 0.98822
wandb: 
wandb: üöÄ View run scbert_XuCao2023_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/tbbwo76y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_090504-tbbwo76y/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:51
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_100104-s2u5v61r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_XuCao2023_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/s2u5v61r
wandb: WARNING Serializing object of type ndarray that is 8275328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2545
Epoch 1 Step 51 Train Loss: 0.2468
Epoch 1 Step 101 Train Loss: 0.2543
Epoch 1 Step 151 Train Loss: 0.2447
Epoch 1 Step 201 Train Loss: 0.2455
Epoch 1 Step 251 Train Loss: 0.2458
Epoch 1 Step 301 Train Loss: 0.2338
Epoch 1 Step 351 Train Loss: 0.2536
Epoch 1 Step 401 Train Loss: 0.2376
Epoch 1 Step 451 Train Loss: 0.2320
Epoch 1 Step 501 Train Loss: 0.2429
Epoch 1 Step 551 Train Loss: 0.2312
Epoch 1 Step 601 Train Loss: 0.2707
Epoch 1 Step 651 Train Loss: 0.2355
Epoch 1 Step 701 Train Loss: 0.2253
Epoch 1 Step 751 Train Loss: 0.2630
Epoch 1 Step 801 Train Loss: 0.2654
Epoch 1 Step 851 Train Loss: 0.2386
Epoch 1 Step 901 Train Loss: 0.2168
Epoch 1 Step 951 Train Loss: 0.2404
Epoch 1 Step 1001 Train Loss: 0.2223
Epoch 1 Step 1051 Train Loss: 0.2197
Epoch 1 Step 1101 Train Loss: 0.2477
Epoch 1 Step 1151 Train Loss: 0.2108
Epoch 1 Step 1201 Train Loss: 0.2235
Epoch 1 Step 1251 Train Loss: 0.2253
Epoch 1 Step 1301 Train Loss: 0.2339
Epoch 1 Step 1351 Train Loss: 0.2265
Epoch 1 Step 1401 Train Loss: 0.2304
Epoch 1 Step 1451 Train Loss: 0.2248
Epoch 1 Step 1501 Train Loss: 0.1947
Epoch 1 Step 1551 Train Loss: 0.2022
Epoch 1 Step 1601 Train Loss: 0.2118
Epoch 1 Step 1651 Train Loss: 0.2300
Epoch 1 Step 1701 Train Loss: 0.2350
Epoch 1 Step 1751 Train Loss: 0.2334
Epoch 1 Step 1801 Train Loss: 0.2187
Epoch 1 Step 1851 Train Loss: 0.2518
Epoch 1 Step 1901 Train Loss: 0.2321
Epoch 1: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0049 Validation Top 20 DE MSE: 0.0153. 
Epoch 2 Step 1 Train Loss: 0.2371
Epoch 2 Step 51 Train Loss: 0.2422
Epoch 2 Step 101 Train Loss: 0.2124
Epoch 2 Step 151 Train Loss: 0.2242
Epoch 2 Step 201 Train Loss: 0.2321
Epoch 2 Step 251 Train Loss: 0.2221
Epoch 2 Step 301 Train Loss: 0.2216
Epoch 2 Step 351 Train Loss: 0.2267
Epoch 2 Step 401 Train Loss: 0.2264
Epoch 2 Step 451 Train Loss: 0.2234
Epoch 2 Step 501 Train Loss: 0.2197
Epoch 2 Step 551 Train Loss: 0.2275
Epoch 2 Step 601 Train Loss: 0.2307
Epoch 2 Step 651 Train Loss: 0.2465
Epoch 2 Step 701 Train Loss: 0.2344
Epoch 2 Step 751 Train Loss: 0.2472
Epoch 2 Step 801 Train Loss: 0.2176
Epoch 2 Step 851 Train Loss: 0.2139
Epoch 2 Step 901 Train Loss: 0.2409
Epoch 2 Step 951 Train Loss: 0.2431
Epoch 2 Step 1001 Train Loss: 0.2398
Epoch 2 Step 1051 Train Loss: 0.2257
Epoch 2 Step 1101 Train Loss: 0.2276
Epoch 2 Step 1151 Train Loss: 0.2322
Epoch 2 Step 1201 Train Loss: 0.2283
Epoch 2 Step 1251 Train Loss: 0.2233
Epoch 2 Step 1301 Train Loss: 0.2066
Epoch 2 Step 1351 Train Loss: 0.2172
Epoch 2 Step 1401 Train Loss: 0.2378
Epoch 2 Step 1451 Train Loss: 0.2189
Epoch 2 Step 1501 Train Loss: 0.2338
Epoch 2 Step 1551 Train Loss: 0.2280
Epoch 2 Step 1601 Train Loss: 0.1981
Epoch 2 Step 1651 Train Loss: 0.2214
Epoch 2 Step 1701 Train Loss: 0.2364
Epoch 2 Step 1751 Train Loss: 0.2144
Epoch 2 Step 1801 Train Loss: 0.2380
Epoch 2 Step 1851 Train Loss: 0.2351
Epoch 2 Step 1901 Train Loss: 0.2273
Epoch 2: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 3 Step 1 Train Loss: 0.2389
Epoch 3 Step 51 Train Loss: 0.2412
Epoch 3 Step 101 Train Loss: 0.2145
Epoch 3 Step 151 Train Loss: 0.2561
Epoch 3 Step 201 Train Loss: 0.2215
Epoch 3 Step 251 Train Loss: 0.2633
Epoch 3 Step 301 Train Loss: 0.2521
Epoch 3 Step 351 Train Loss: 0.2462
Epoch 3 Step 401 Train Loss: 0.2336
Epoch 3 Step 451 Train Loss: 0.2312
Epoch 3 Step 501 Train Loss: 0.2302
Epoch 3 Step 551 Train Loss: 0.2375
Epoch 3 Step 601 Train Loss: 0.2225
Epoch 3 Step 651 Train Loss: 0.2239
Epoch 3 Step 701 Train Loss: 0.2245
Epoch 3 Step 751 Train Loss: 0.2147
Epoch 3 Step 801 Train Loss: 0.2410
Epoch 3 Step 851 Train Loss: 0.2411
Epoch 3 Step 901 Train Loss: 0.2172
Epoch 3 Step 951 Train Loss: 0.2457
Epoch 3 Step 1001 Train Loss: 0.2385
Epoch 3 Step 1051 Train Loss: 0.2214
Epoch 3 Step 1101 Train Loss: 0.2268
Epoch 3 Step 1151 Train Loss: 0.2151
Epoch 3 Step 1201 Train Loss: 0.2274
Epoch 3 Step 1251 Train Loss: 0.2328
Epoch 3 Step 1301 Train Loss: 0.2319
Epoch 3 Step 1351 Train Loss: 0.2445
Epoch 3 Step 1401 Train Loss: 0.2159
Epoch 3 Step 1451 Train Loss: 0.2091
Epoch 3 Step 1501 Train Loss: 0.2297
Epoch 3 Step 1551 Train Loss: 0.2354
Epoch 3 Step 1601 Train Loss: 0.2132
Epoch 3 Step 1651 Train Loss: 0.2394
Epoch 3 Step 1701 Train Loss: 0.2348
Epoch 3 Step 1751 Train Loss: 0.2218
Epoch 3 Step 1801 Train Loss: 0.2421
Epoch 3 Step 1851 Train Loss: 0.2211
Epoch 3 Step 1901 Train Loss: 0.2352
Epoch 3: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 4 Step 1 Train Loss: 0.2359
Epoch 4 Step 51 Train Loss: 0.2324
Epoch 4 Step 101 Train Loss: 0.2206
Epoch 4 Step 151 Train Loss: 0.2506
Epoch 4 Step 201 Train Loss: 0.2230
Epoch 4 Step 251 Train Loss: 0.2502
Epoch 4 Step 301 Train Loss: 0.2414
Epoch 4 Step 351 Train Loss: 0.2089
Epoch 4 Step 401 Train Loss: 0.2232
Epoch 4 Step 451 Train Loss: 0.2193
Epoch 4 Step 501 Train Loss: 0.2198
Epoch 4 Step 551 Train Loss: 0.2215
Epoch 4 Step 601 Train Loss: 0.2284
Epoch 4 Step 651 Train Loss: 0.2311
Epoch 4 Step 701 Train Loss: 0.2544
Epoch 4 Step 751 Train Loss: 0.2276
Epoch 4 Step 801 Train Loss: 0.2126
Epoch 4 Step 851 Train Loss: 0.2420
Epoch 4 Step 901 Train Loss: 0.2386
Epoch 4 Step 951 Train Loss: 0.2427
Epoch 4 Step 1001 Train Loss: 0.2548
Epoch 4 Step 1051 Train Loss: 0.2139
Epoch 4 Step 1101 Train Loss: 0.2455
Epoch 4 Step 1151 Train Loss: 0.2479
Epoch 4 Step 1201 Train Loss: 0.2128
Epoch 4 Step 1251 Train Loss: 0.2332
Epoch 4 Step 1301 Train Loss: 0.2284
Epoch 4 Step 1351 Train Loss: 0.2404
Epoch 4 Step 1401 Train Loss: 0.2384
Epoch 4 Step 1451 Train Loss: 0.2376
Epoch 4 Step 1501 Train Loss: 0.2312
Epoch 4 Step 1551 Train Loss: 0.2274
Epoch 4 Step 1601 Train Loss: 0.2284
Epoch 4 Step 1651 Train Loss: 0.2439
Epoch 4 Step 1701 Train Loss: 0.2215
Epoch 4 Step 1751 Train Loss: 0.2219
Epoch 4 Step 1801 Train Loss: 0.2245
Epoch 4 Step 1851 Train Loss: 0.2388
Epoch 4 Step 1901 Train Loss: 0.2266
Epoch 4: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 5 Step 1 Train Loss: 0.2496
Epoch 5 Step 51 Train Loss: 0.2471
Epoch 5 Step 101 Train Loss: 0.2602
Epoch 5 Step 151 Train Loss: 0.2333
Epoch 5 Step 201 Train Loss: 0.2459
Epoch 5 Step 251 Train Loss: 0.2345
Epoch 5 Step 301 Train Loss: 0.2452
Epoch 5 Step 351 Train Loss: 0.2284
Epoch 5 Step 401 Train Loss: 0.2443
Epoch 5 Step 451 Train Loss: 0.2465
Epoch 5 Step 501 Train Loss: 0.2459
Epoch 5 Step 551 Train Loss: 0.2288
Epoch 5 Step 601 Train Loss: 0.2186
Epoch 5 Step 651 Train Loss: 0.2434
Epoch 5 Step 701 Train Loss: 0.2295
Epoch 5 Step 751 Train Loss: 0.2243
Epoch 5 Step 801 Train Loss: 0.2456
Epoch 5 Step 851 Train Loss: 0.2552
Epoch 5 Step 901 Train Loss: 0.2254
Epoch 5 Step 951 Train Loss: 0.2369
Epoch 5 Step 1001 Train Loss: 0.2280
Epoch 5 Step 1051 Train Loss: 0.2095
Epoch 5 Step 1101 Train Loss: 0.2371
Epoch 5 Step 1151 Train Loss: 0.2407
Epoch 5 Step 1201 Train Loss: 0.2324
Epoch 5 Step 1251 Train Loss: 0.2212
Epoch 5 Step 1301 Train Loss: 0.2481
Epoch 5 Step 1351 Train Loss: 0.2486
Epoch 5 Step 1401 Train Loss: 0.2411
Epoch 5 Step 1451 Train Loss: 0.2275
Epoch 5 Step 1501 Train Loss: 0.2437
Epoch 5 Step 1551 Train Loss: 0.2254
Epoch 5 Step 1601 Train Loss: 0.2444
Epoch 5 Step 1651 Train Loss: 0.2418
Epoch 5 Step 1701 Train Loss: 0.2752
Epoch 5 Step 1751 Train Loss: 0.2464
Epoch 5 Step 1801 Train Loss: 0.2299
Epoch 5 Step 1851 Train Loss: 0.2282
Epoch 5 Step 1901 Train Loss: 0.2183
Epoch 5: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 6 Step 1 Train Loss: 0.2413
Epoch 6 Step 51 Train Loss: 0.2404
Epoch 6 Step 101 Train Loss: 0.2306
Epoch 6 Step 151 Train Loss: 0.2350
Epoch 6 Step 201 Train Loss: 0.2433
Epoch 6 Step 251 Train Loss: 0.2389
Epoch 6 Step 301 Train Loss: 0.2388
Epoch 6 Step 351 Train Loss: 0.2191
Epoch 6 Step 401 Train Loss: 0.2632
Epoch 6 Step 451 Train Loss: 0.2451
Epoch 6 Step 501 Train Loss: 0.2411
Epoch 6 Step 551 Train Loss: 0.2336
Epoch 6 Step 601 Train Loss: 0.2362
Epoch 6 Step 651 Train Loss: 0.2344
Epoch 6 Step 701 Train Loss: 0.2602
Epoch 6 Step 751 Train Loss: 0.2253
Epoch 6 Step 801 Train Loss: 0.2321
Epoch 6 Step 851 Train Loss: 0.2528
Epoch 6 Step 901 Train Loss: 0.2329
Epoch 6 Step 951 Train Loss: 0.2344
Epoch 6 Step 1001 Train Loss: 0.2613
Epoch 6 Step 1051 Train Loss: 0.2347
Epoch 6 Step 1101 Train Loss: 0.2343
Epoch 6 Step 1151 Train Loss: 0.2354
Epoch 6 Step 1201 Train Loss: 0.2347
Epoch 6 Step 1251 Train Loss: 0.2412
Epoch 6 Step 1301 Train Loss: 0.2526
Epoch 6 Step 1351 Train Loss: 0.2488
Epoch 6 Step 1401 Train Loss: 0.2390
Epoch 6 Step 1451 Train Loss: 0.2369
Epoch 6 Step 1501 Train Loss: 0.2373
Epoch 6 Step 1551 Train Loss: 0.2591
Epoch 6 Step 1601 Train Loss: 0.2309
Epoch 6 Step 1651 Train Loss: 0.2410
Epoch 6 Step 1701 Train Loss: 0.2683
Epoch 6 Step 1751 Train Loss: 0.2523
Epoch 6 Step 1801 Train Loss: 0.2340
Epoch 6 Step 1851 Train Loss: 0.2344
Epoch 6 Step 1901 Train Loss: 0.2415
Epoch 6: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 7 Step 1 Train Loss: 0.2432
Epoch 7 Step 51 Train Loss: 0.2328
Epoch 7 Step 101 Train Loss: 0.2473
Epoch 7 Step 151 Train Loss: 0.2235
Epoch 7 Step 201 Train Loss: 0.2189
Epoch 7 Step 251 Train Loss: 0.2370
Epoch 7 Step 301 Train Loss: 0.2533
Epoch 7 Step 351 Train Loss: 0.2545
Epoch 7 Step 401 Train Loss: 0.2461
Epoch 7 Step 451 Train Loss: 0.2410
Epoch 7 Step 501 Train Loss: 0.2443
Epoch 7 Step 551 Train Loss: 0.2455
Epoch 7 Step 601 Train Loss: 0.2416
Epoch 7 Step 651 Train Loss: 0.2268
Epoch 7 Step 701 Train Loss: 0.2290
Epoch 7 Step 751 Train Loss: 0.2383
Epoch 7 Step 801 Train Loss: 0.2396
Epoch 7 Step 851 Train Loss: 0.2352
Epoch 7 Step 901 Train Loss: 0.2306
Epoch 7 Step 951 Train Loss: 0.2283
Epoch 7 Step 1001 Train Loss: 0.2334
Epoch 7 Step 1051 Train Loss: 0.2275
Epoch 7 Step 1101 Train Loss: 0.2279
Epoch 7 Step 1151 Train Loss: 0.2468
Epoch 7 Step 1201 Train Loss: 0.2353
Epoch 7 Step 1251 Train Loss: 0.2278
Epoch 7 Step 1301 Train Loss: 0.2357
Epoch 7 Step 1351 Train Loss: 0.2435
Epoch 7 Step 1401 Train Loss: 0.2217
Epoch 7 Step 1451 Train Loss: 0.2406
Epoch 7 Step 1501 Train Loss: 0.2414
Epoch 7 Step 1551 Train Loss: 0.2295
Epoch 7 Step 1601 Train Loss: 0.2397
Epoch 7 Step 1651 Train Loss: 0.2426
Epoch 7 Step 1701 Train Loss: 0.2188
Epoch 7 Step 1751 Train Loss: 0.2147
Epoch 7 Step 1801 Train Loss: 0.2259
Epoch 7 Step 1851 Train Loss: 0.2517
Epoch 7 Step 1901 Train Loss: 0.2335
Epoch 7: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 8 Step 1 Train Loss: 0.2309
Epoch 8 Step 51 Train Loss: 0.2315
Epoch 8 Step 101 Train Loss: 0.2286
Epoch 8 Step 151 Train Loss: 0.2399
Epoch 8 Step 201 Train Loss: 0.2424
Epoch 8 Step 251 Train Loss: 0.2192
Epoch 8 Step 301 Train Loss: 0.2444
Epoch 8 Step 351 Train Loss: 0.2255
Epoch 8 Step 401 Train Loss: 0.2336
Epoch 8 Step 451 Train Loss: 0.2355
Epoch 8 Step 501 Train Loss: 0.2301
Epoch 8 Step 551 Train Loss: 0.2479
Epoch 8 Step 601 Train Loss: 0.2427
Epoch 8 Step 651 Train Loss: 0.2490
Epoch 8 Step 701 Train Loss: 0.2502
Epoch 8 Step 751 Train Loss: 0.2407
Epoch 8 Step 801 Train Loss: 0.2385
Epoch 8 Step 851 Train Loss: 0.2295
Epoch 8 Step 901 Train Loss: 0.2116
Epoch 8 Step 951 Train Loss: 0.2476
Epoch 8 Step 1001 Train Loss: 0.2468
Epoch 8 Step 1051 Train Loss: 0.2590
Epoch 8 Step 1101 Train Loss: 0.2529
Epoch 8 Step 1151 Train Loss: 0.2331
Epoch 8 Step 1201 Train Loss: 0.2324
Epoch 8 Step 1251 Train Loss: 0.2310
Epoch 8 Step 1301 Train Loss: 0.2394
Epoch 8 Step 1351 Train Loss: 0.2551
Epoch 8 Step 1401 Train Loss: 0.2224
Epoch 8 Step 1451 Train Loss: 0.2492
Epoch 8 Step 1501 Train Loss: 0.2342
Epoch 8 Step 1551 Train Loss: 0.2337
Epoch 8 Step 1601 Train Loss: 0.2522
Epoch 8 Step 1651 Train Loss: 0.2321
Epoch 8 Step 1701 Train Loss: 0.2342
Epoch 8 Step 1751 Train Loss: 0.2509
Epoch 8 Step 1801 Train Loss: 0.2309
Epoch 8 Step 1851 Train Loss: 0.2548
Epoch 8 Step 1901 Train Loss: 0.2400
Epoch 8: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 9 Step 1 Train Loss: 0.2387
Epoch 9 Step 51 Train Loss: 0.2556
Epoch 9 Step 101 Train Loss: 0.2323
Epoch 9 Step 151 Train Loss: 0.2448
Epoch 9 Step 201 Train Loss: 0.2390
Epoch 9 Step 251 Train Loss: 0.2292
Epoch 9 Step 301 Train Loss: 0.2292
Epoch 9 Step 351 Train Loss: 0.2453
Epoch 9 Step 401 Train Loss: 0.2555
Epoch 9 Step 451 Train Loss: 0.2274
Epoch 9 Step 501 Train Loss: 0.2407
Epoch 9 Step 551 Train Loss: 0.2545
Epoch 9 Step 601 Train Loss: 0.2397
Epoch 9 Step 651 Train Loss: 0.2364
Epoch 9 Step 701 Train Loss: 0.2288
Epoch 9 Step 751 Train Loss: 0.2334
Epoch 9 Step 801 Train Loss: 0.2292
Epoch 9 Step 851 Train Loss: 0.2566
Epoch 9 Step 901 Train Loss: 0.2365
Epoch 9 Step 951 Train Loss: 0.2378
Epoch 9 Step 1001 Train Loss: 0.2408
Epoch 9 Step 1051 Train Loss: 0.2370
Epoch 9 Step 1101 Train Loss: 0.2685
Epoch 9 Step 1151 Train Loss: 0.2487
Epoch 9 Step 1201 Train Loss: 0.2396
Epoch 9 Step 1251 Train Loss: 0.2561
Epoch 9 Step 1301 Train Loss: 0.2404
Epoch 9 Step 1351 Train Loss: 0.2440
Epoch 9 Step 1401 Train Loss: 0.2459
Epoch 9 Step 1451 Train Loss: 0.2315
Epoch 9 Step 1501 Train Loss: 0.2314
Epoch 9 Step 1551 Train Loss: 0.2337
Epoch 9 Step 1601 Train Loss: 0.2655
Epoch 9 Step 1651 Train Loss: 0.2447
Epoch 9 Step 1701 Train Loss: 0.2349
Epoch 9 Step 1751 Train Loss: 0.2568
Epoch 9 Step 1801 Train Loss: 0.2359
Epoch 9 Step 1851 Train Loss: 0.2557
Epoch 9 Step 1901 Train Loss: 0.2553
Epoch 9: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 10 Step 1 Train Loss: 0.2393
Epoch 10 Step 51 Train Loss: 0.2322
Epoch 10 Step 101 Train Loss: 0.2310
Epoch 10 Step 151 Train Loss: 0.2460
Epoch 10 Step 201 Train Loss: 0.2341
Epoch 10 Step 251 Train Loss: 0.2244
Epoch 10 Step 301 Train Loss: 0.2467
Epoch 10 Step 351 Train Loss: 0.2404
Epoch 10 Step 401 Train Loss: 0.2212
Epoch 10 Step 451 Train Loss: 0.2457
Epoch 10 Step 501 Train Loss: 0.2379
Epoch 10 Step 551 Train Loss: 0.2416
Epoch 10 Step 601 Train Loss: 0.2442
Epoch 10 Step 651 Train Loss: 0.2413
Epoch 10 Step 701 Train Loss: 0.2595
Epoch 10 Step 751 Train Loss: 0.2562
Epoch 10 Step 801 Train Loss: 0.2263
Epoch 10 Step 851 Train Loss: 0.2456
Epoch 10 Step 901 Train Loss: 0.2342
Epoch 10 Step 951 Train Loss: 0.2451
Epoch 10 Step 1001 Train Loss: 0.2469
Epoch 10 Step 1051 Train Loss: 0.2496
Epoch 10 Step 1101 Train Loss: 0.2181
Epoch 10 Step 1151 Train Loss: 0.2290
Epoch 10 Step 1201 Train Loss: 0.2353
Epoch 10 Step 1251 Train Loss: 0.2583
Epoch 10 Step 1301 Train Loss: 0.2513
Epoch 10 Step 1351 Train Loss: 0.2316
Epoch 10 Step 1401 Train Loss: 0.2397
Epoch 10 Step 1451 Train Loss: 0.2420
Epoch 10 Step 1501 Train Loss: 0.2130
Epoch 10 Step 1551 Train Loss: 0.2186
Epoch 10 Step 1601 Train Loss: 0.2379
Epoch 10 Step 1651 Train Loss: 0.2306
Epoch 10 Step 1701 Train Loss: 0.2266
Epoch 10 Step 1751 Train Loss: 0.2271
Epoch 10 Step 1801 Train Loss: 0.2281
Epoch 10 Step 1851 Train Loss: 0.2305
Epoch 10 Step 1901 Train Loss: 0.2298
Epoch 10: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 11 Step 1 Train Loss: 0.2474
Epoch 11 Step 51 Train Loss: 0.2644
Epoch 11 Step 101 Train Loss: 0.2487
Epoch 11 Step 151 Train Loss: 0.2303
Epoch 11 Step 201 Train Loss: 0.2400
Epoch 11 Step 251 Train Loss: 0.2435
Epoch 11 Step 301 Train Loss: 0.2455
Epoch 11 Step 351 Train Loss: 0.2390
Epoch 11 Step 401 Train Loss: 0.2371
Epoch 11 Step 451 Train Loss: 0.2528
Epoch 11 Step 501 Train Loss: 0.2290
Epoch 11 Step 551 Train Loss: 0.2540
Epoch 11 Step 601 Train Loss: 0.2491
Epoch 11 Step 651 Train Loss: 0.2325
Epoch 11 Step 701 Train Loss: 0.2273
Epoch 11 Step 751 Train Loss: 0.2320
Epoch 11 Step 801 Train Loss: 0.2304
Epoch 11 Step 851 Train Loss: 0.2451
Epoch 11 Step 901 Train Loss: 0.2456
Epoch 11 Step 951 Train Loss: 0.2384
Epoch 11 Step 1001 Train Loss: 0.2364
Epoch 11 Step 1051 Train Loss: 0.2282
Epoch 11 Step 1101 Train Loss: 0.2173
Epoch 11 Step 1151 Train Loss: 0.2630
Epoch 11 Step 1201 Train Loss: 0.2656
Epoch 11 Step 1251 Train Loss: 0.2190
Epoch 11 Step 1301 Train Loss: 0.2374
Epoch 11 Step 1351 Train Loss: 0.2470
Epoch 11 Step 1401 Train Loss: 0.2173
Epoch 11 Step 1451 Train Loss: 0.2308
Epoch 11 Step 1501 Train Loss: 0.2419
Epoch 11 Step 1551 Train Loss: 0.2379
Epoch 11 Step 1601 Train Loss: 0.2269
Epoch 11 Step 1651 Train Loss: 0.2179
Epoch 11 Step 1701 Train Loss: 0.2354
Epoch 11 Step 1751 Train Loss: 0.2375
Epoch 11 Step 1801 Train Loss: 0.2510
Epoch 11 Step 1851 Train Loss: 0.2376
Epoch 11 Step 1901 Train Loss: 0.2444
Epoch 11: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 12 Step 1 Train Loss: 0.2410
Epoch 12 Step 51 Train Loss: 0.2373
Epoch 12 Step 101 Train Loss: 0.2338
Epoch 12 Step 151 Train Loss: 0.2335
Epoch 12 Step 201 Train Loss: 0.2544
Epoch 12 Step 251 Train Loss: 0.2323
Epoch 12 Step 301 Train Loss: 0.2316
Epoch 12 Step 351 Train Loss: 0.2419
Epoch 12 Step 401 Train Loss: 0.2218
Epoch 12 Step 451 Train Loss: 0.2445
Epoch 12 Step 501 Train Loss: 0.2495
Epoch 12 Step 551 Train Loss: 0.2397
Epoch 12 Step 601 Train Loss: 0.2397
Epoch 12 Step 651 Train Loss: 0.2405
Epoch 12 Step 701 Train Loss: 0.2326
Epoch 12 Step 751 Train Loss: 0.2346
Epoch 12 Step 801 Train Loss: 0.2381
Epoch 12 Step 851 Train Loss: 0.2219
Epoch 12 Step 901 Train Loss: 0.2633
Epoch 12 Step 951 Train Loss: 0.2366
Epoch 12 Step 1001 Train Loss: 0.2401
Epoch 12 Step 1051 Train Loss: 0.2575
Epoch 12 Step 1101 Train Loss: 0.2305
Epoch 12 Step 1151 Train Loss: 0.2417
Epoch 12 Step 1201 Train Loss: 0.2290
Epoch 12 Step 1251 Train Loss: 0.2230
Epoch 12 Step 1301 Train Loss: 0.2410
Epoch 12 Step 1351 Train Loss: 0.2352
Epoch 12 Step 1401 Train Loss: 0.2380
Epoch 12 Step 1451 Train Loss: 0.2439
Epoch 12 Step 1501 Train Loss: 0.2593
Epoch 12 Step 1551 Train Loss: 0.2190
Epoch 12 Step 1601 Train Loss: 0.2620
Epoch 12 Step 1651 Train Loss: 0.2446
Epoch 12 Step 1701 Train Loss: 0.2402
Epoch 12 Step 1751 Train Loss: 0.2480
Epoch 12 Step 1801 Train Loss: 0.2501
Epoch 12 Step 1851 Train Loss: 0.2461
Epoch 12 Step 1901 Train Loss: 0.2381
Epoch 12: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 13 Step 1 Train Loss: 0.2391
Epoch 13 Step 51 Train Loss: 0.2669
Epoch 13 Step 101 Train Loss: 0.2364
Epoch 13 Step 151 Train Loss: 0.2337
Epoch 13 Step 201 Train Loss: 0.2509
Epoch 13 Step 251 Train Loss: 0.2410
Epoch 13 Step 301 Train Loss: 0.2428
Epoch 13 Step 351 Train Loss: 0.2385
Epoch 13 Step 401 Train Loss: 0.2564
Epoch 13 Step 451 Train Loss: 0.2356
Epoch 13 Step 501 Train Loss: 0.2428
Epoch 13 Step 551 Train Loss: 0.2284
Epoch 13 Step 601 Train Loss: 0.2423
Epoch 13 Step 651 Train Loss: 0.2531
Epoch 13 Step 701 Train Loss: 0.2324
Epoch 13 Step 751 Train Loss: 0.2531
Epoch 13 Step 801 Train Loss: 0.2539
Epoch 13 Step 851 Train Loss: 0.2250
Epoch 13 Step 901 Train Loss: 0.2550
Epoch 13 Step 951 Train Loss: 0.2323
Epoch 13 Step 1001 Train Loss: 0.2318
Epoch 13 Step 1051 Train Loss: 0.2389
Epoch 13 Step 1101 Train Loss: 0.2465
Epoch 13 Step 1151 Train Loss: 0.2421
Epoch 13 Step 1201 Train Loss: 0.2372
Epoch 13 Step 1251 Train Loss: 0.2402
Epoch 13 Step 1301 Train Loss: 0.2306
Epoch 13 Step 1351 Train Loss: 0.2546
Epoch 13 Step 1401 Train Loss: 0.2196
Epoch 13 Step 1451 Train Loss: 0.2621
Epoch 13 Step 1501 Train Loss: 0.2460
Epoch 13 Step 1551 Train Loss: 0.2407
Epoch 13 Step 1601 Train Loss: 0.2478
Epoch 13 Step 1651 Train Loss: 0.2285
Epoch 13 Step 1701 Train Loss: 0.2451
Epoch 13 Step 1751 Train Loss: 0.2640
Epoch 13 Step 1801 Train Loss: 0.2477
Epoch 13 Step 1851 Train Loss: 0.2449
Epoch 13 Step 1901 Train Loss: 0.2509
Epoch 13: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 14 Step 1 Train Loss: 0.2105
Epoch 14 Step 51 Train Loss: 0.2307
Epoch 14 Step 101 Train Loss: 0.2454
Epoch 14 Step 151 Train Loss: 0.2384
Epoch 14 Step 201 Train Loss: 0.2428
Epoch 14 Step 251 Train Loss: 0.2285
Epoch 14 Step 301 Train Loss: 0.2662
Epoch 14 Step 351 Train Loss: 0.2334
Epoch 14 Step 401 Train Loss: 0.2265
Epoch 14 Step 451 Train Loss: 0.2256
Epoch 14 Step 501 Train Loss: 0.2472
Epoch 14 Step 551 Train Loss: 0.2188
Epoch 14 Step 601 Train Loss: 0.2640
Epoch 14 Step 651 Train Loss: 0.2366
Epoch 14 Step 701 Train Loss: 0.2298
Epoch 14 Step 751 Train Loss: 0.2431
Epoch 14 Step 801 Train Loss: 0.2330
Epoch 14 Step 851 Train Loss: 0.2451
Epoch 14 Step 901 Train Loss: 0.2343
Epoch 14 Step 951 Train Loss: 0.2362
Epoch 14 Step 1001 Train Loss: 0.2550
Epoch 14 Step 1051 Train Loss: 0.2573
Epoch 14 Step 1101 Train Loss: 0.2702
Epoch 14 Step 1151 Train Loss: 0.2250
Epoch 14 Step 1201 Train Loss: 0.2320
Epoch 14 Step 1251 Train Loss: 0.2461
Epoch 14 Step 1301 Train Loss: 0.2525
Epoch 14 Step 1351 Train Loss: 0.2255
Epoch 14 Step 1401 Train Loss: 0.2410
Epoch 14 Step 1451 Train Loss: 0.2453
Epoch 14 Step 1501 Train Loss: 0.2366
Epoch 14 Step 1551 Train Loss: 0.2471
Epoch 14 Step 1601 Train Loss: 0.2315
Epoch 14 Step 1651 Train Loss: 0.2305
Epoch 14 Step 1701 Train Loss: 0.2512
Epoch 14 Step 1751 Train Loss: 0.2350
Epoch 14 Step 1801 Train Loss: 0.2400
Epoch 14 Step 1851 Train Loss: 0.2378
Epoch 14 Step 1901 Train Loss: 0.2386
Epoch 14: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Epoch 15 Step 1 Train Loss: 0.2171
Epoch 15 Step 51 Train Loss: 0.2265
Epoch 15 Step 101 Train Loss: 0.2332
Epoch 15 Step 151 Train Loss: 0.2349
Epoch 15 Step 201 Train Loss: 0.2389
Epoch 15 Step 251 Train Loss: 0.2626
Epoch 15 Step 301 Train Loss: 0.2622
Epoch 15 Step 351 Train Loss: 0.2423
Epoch 15 Step 401 Train Loss: 0.2412
Epoch 15 Step 451 Train Loss: 0.2419
Epoch 15 Step 501 Train Loss: 0.2534
Epoch 15 Step 551 Train Loss: 0.2533
Epoch 15 Step 601 Train Loss: 0.2433
Epoch 15 Step 651 Train Loss: 0.2273
Epoch 15 Step 701 Train Loss: 0.2343
Epoch 15 Step 751 Train Loss: 0.2411
Epoch 15 Step 801 Train Loss: 0.2392
Epoch 15 Step 851 Train Loss: 0.2562
Epoch 15 Step 901 Train Loss: 0.2472
Epoch 15 Step 951 Train Loss: 0.2424
Epoch 15 Step 1001 Train Loss: 0.2330
Epoch 15 Step 1051 Train Loss: 0.2491
Epoch 15 Step 1101 Train Loss: 0.2246
Epoch 15 Step 1151 Train Loss: 0.2519
Epoch 15 Step 1201 Train Loss: 0.2375
Epoch 15 Step 1251 Train Loss: 0.2314
Epoch 15 Step 1301 Train Loss: 0.2360
Epoch 15 Step 1351 Train Loss: 0.2494
Epoch 15 Step 1401 Train Loss: 0.2481
Epoch 15 Step 1451 Train Loss: 0.2439
Epoch 15 Step 1501 Train Loss: 0.2342
Epoch 15 Step 1551 Train Loss: 0.2458
Epoch 15 Step 1601 Train Loss: 0.2321
Epoch 15 Step 1651 Train Loss: 0.2378
Epoch 15 Step 1701 Train Loss: 0.2553
Epoch 15 Step 1751 Train Loss: 0.2568
Epoch 15 Step 1801 Train Loss: 0.2393
Epoch 15 Step 1851 Train Loss: 0.2628
Epoch 15 Step 1901 Train Loss: 0.2287
Epoch 15: Train Overall MSE: 0.0003 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0048 Validation Top 20 DE MSE: 0.0152. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0040
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00041828302
test_unseen_single_pearson: 0.9910696075250222
test_unseen_single_mse_de: 0.0039911657
test_unseen_single_pearson_de: 0.7188275214781623
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.12944492590506115
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.36764705882352944
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9127450980392158
test_unseen_single_mse_top20_de_non_dropout: 0.009209970907288537
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.038 MB uploadedwandb: | 0.003 MB of 0.038 MB uploadedwandb: / 0.003 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:                                               val_de_pearson ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00399
wandb:                                              test_de_pearson 0.71883
wandb:               test_frac_opposite_direction_top20_non_dropout 0.36765
wandb:                          test_frac_sigma_below_1_non_dropout 0.91275
wandb:                                                     test_mse 0.00042
wandb:                                test_mse_top20_de_non_dropout 0.00921
wandb:                                                 test_pearson 0.99107
wandb:                                           test_pearson_delta 0.12944
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.36765
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.91275
wandb:                                       test_unseen_single_mse 0.00042
wandb:                                    test_unseen_single_mse_de 0.00399
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00921
wandb:                                   test_unseen_single_pearson 0.99107
wandb:                                test_unseen_single_pearson_de 0.71883
wandb:                             test_unseen_single_pearson_delta 0.12944
wandb:                                                 train_de_mse 0.00479
wandb:                                             train_de_pearson 0.80312
wandb:                                                    train_mse 0.00033
wandb:                                                train_pearson 0.99289
wandb:                                                training_loss 0.24193
wandb:                                                   val_de_mse 0.01524
wandb:                                               val_de_pearson 0.92426
wandb:                                                      val_mse 0.0003
wandb:                                                  val_pearson 0.99348
wandb: 
wandb: üöÄ View run scbert_XuCao2023_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/s2u5v61r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_100104-s2u5v61r/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:51
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_105525-18ee4pbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_XuCao2023_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/18ee4pbs
wandb: WARNING Serializing object of type ndarray that is 8275328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2501
Epoch 1 Step 51 Train Loss: 0.2427
Epoch 1 Step 101 Train Loss: 0.2462
Epoch 1 Step 151 Train Loss: 0.2655
Epoch 1 Step 201 Train Loss: 0.2365
Epoch 1 Step 251 Train Loss: 0.2510
Epoch 1 Step 301 Train Loss: 0.2413
Epoch 1 Step 351 Train Loss: 0.2337
Epoch 1 Step 401 Train Loss: 0.2715
Epoch 1 Step 451 Train Loss: 0.2413
Epoch 1 Step 501 Train Loss: 0.2345
Epoch 1 Step 551 Train Loss: 0.2504
Epoch 1 Step 601 Train Loss: 0.2529
Epoch 1 Step 651 Train Loss: 0.2337
Epoch 1 Step 701 Train Loss: 0.2140
Epoch 1 Step 751 Train Loss: 0.2222
Epoch 1 Step 801 Train Loss: 0.2319
Epoch 1 Step 851 Train Loss: 0.2210
Epoch 1 Step 901 Train Loss: 0.2275
Epoch 1 Step 951 Train Loss: 0.2336
Epoch 1 Step 1001 Train Loss: 0.2240
Epoch 1 Step 1051 Train Loss: 0.2119
Epoch 1 Step 1101 Train Loss: 0.2614
Epoch 1 Step 1151 Train Loss: 0.2164
Epoch 1 Step 1201 Train Loss: 0.2115
Epoch 1 Step 1251 Train Loss: 0.2296
Epoch 1 Step 1301 Train Loss: 0.2372
Epoch 1 Step 1351 Train Loss: 0.2309
Epoch 1 Step 1401 Train Loss: 0.2342
Epoch 1 Step 1451 Train Loss: 0.2213
Epoch 1 Step 1501 Train Loss: 0.2162
Epoch 1 Step 1551 Train Loss: 0.1950
Epoch 1 Step 1601 Train Loss: 0.2163
Epoch 1 Step 1651 Train Loss: 0.2300
Epoch 1 Step 1701 Train Loss: 0.2094
Epoch 1 Step 1751 Train Loss: 0.2129
Epoch 1 Step 1801 Train Loss: 0.2440
Epoch 1 Step 1851 Train Loss: 0.2078
Epoch 1 Step 1901 Train Loss: 0.2208
Epoch 1 Step 1951 Train Loss: 0.2182
Epoch 1: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0063 Validation Top 20 DE MSE: 0.0054. 
Epoch 2 Step 1 Train Loss: 0.2285
Epoch 2 Step 51 Train Loss: 0.2137
Epoch 2 Step 101 Train Loss: 0.2084
Epoch 2 Step 151 Train Loss: 0.2451
Epoch 2 Step 201 Train Loss: 0.2320
Epoch 2 Step 251 Train Loss: 0.2347
Epoch 2 Step 301 Train Loss: 0.2272
Epoch 2 Step 351 Train Loss: 0.2204
Epoch 2 Step 401 Train Loss: 0.2260
Epoch 2 Step 451 Train Loss: 0.2092
Epoch 2 Step 501 Train Loss: 0.2253
Epoch 2 Step 551 Train Loss: 0.2288
Epoch 2 Step 601 Train Loss: 0.2289
Epoch 2 Step 651 Train Loss: 0.2149
Epoch 2 Step 701 Train Loss: 0.2334
Epoch 2 Step 751 Train Loss: 0.2163
Epoch 2 Step 801 Train Loss: 0.2182
Epoch 2 Step 851 Train Loss: 0.2107
Epoch 2 Step 901 Train Loss: 0.2232
Epoch 2 Step 951 Train Loss: 0.2289
Epoch 2 Step 1001 Train Loss: 0.2097
Epoch 2 Step 1051 Train Loss: 0.2434
Epoch 2 Step 1101 Train Loss: 0.2048
Epoch 2 Step 1151 Train Loss: 0.2283
Epoch 2 Step 1201 Train Loss: 0.2380
Epoch 2 Step 1251 Train Loss: 0.2301
Epoch 2 Step 1301 Train Loss: 0.2204
Epoch 2 Step 1351 Train Loss: 0.2324
Epoch 2 Step 1401 Train Loss: 0.2444
Epoch 2 Step 1451 Train Loss: 0.2066
Epoch 2 Step 1501 Train Loss: 0.2289
Epoch 2 Step 1551 Train Loss: 0.2279
Epoch 2 Step 1601 Train Loss: 0.2257
Epoch 2 Step 1651 Train Loss: 0.2260
Epoch 2 Step 1701 Train Loss: 0.2172
Epoch 2 Step 1751 Train Loss: 0.2150
Epoch 2 Step 1801 Train Loss: 0.2227
Epoch 2 Step 1851 Train Loss: 0.2262
Epoch 2 Step 1901 Train Loss: 0.2253
Epoch 2 Step 1951 Train Loss: 0.2259
Epoch 2: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0054. 
Epoch 3 Step 1 Train Loss: 0.2368
Epoch 3 Step 51 Train Loss: 0.2204
Epoch 3 Step 101 Train Loss: 0.2159
Epoch 3 Step 151 Train Loss: 0.2312
Epoch 3 Step 201 Train Loss: 0.2327
Epoch 3 Step 251 Train Loss: 0.2198
Epoch 3 Step 301 Train Loss: 0.2313
Epoch 3 Step 351 Train Loss: 0.2239
Epoch 3 Step 401 Train Loss: 0.2257
Epoch 3 Step 451 Train Loss: 0.2197
Epoch 3 Step 501 Train Loss: 0.2160
Epoch 3 Step 551 Train Loss: 0.2215
Epoch 3 Step 601 Train Loss: 0.2174
Epoch 3 Step 651 Train Loss: 0.2341
Epoch 3 Step 701 Train Loss: 0.2161
Epoch 3 Step 751 Train Loss: 0.2371
Epoch 3 Step 801 Train Loss: 0.2247
Epoch 3 Step 851 Train Loss: 0.2110
Epoch 3 Step 901 Train Loss: 0.2142
Epoch 3 Step 951 Train Loss: 0.2386
Epoch 3 Step 1001 Train Loss: 0.2315
Epoch 3 Step 1051 Train Loss: 0.2358
Epoch 3 Step 1101 Train Loss: 0.2327
Epoch 3 Step 1151 Train Loss: 0.2216
Epoch 3 Step 1201 Train Loss: 0.2154
Epoch 3 Step 1251 Train Loss: 0.2346
Epoch 3 Step 1301 Train Loss: 0.2228
Epoch 3 Step 1351 Train Loss: 0.2231
Epoch 3 Step 1401 Train Loss: 0.2332
Epoch 3 Step 1451 Train Loss: 0.2230
Epoch 3 Step 1501 Train Loss: 0.2148
Epoch 3 Step 1551 Train Loss: 0.2437
Epoch 3 Step 1601 Train Loss: 0.2537
Epoch 3 Step 1651 Train Loss: 0.2190
Epoch 3 Step 1701 Train Loss: 0.2627
Epoch 3 Step 1751 Train Loss: 0.2236
Epoch 3 Step 1801 Train Loss: 0.2427
Epoch 3 Step 1851 Train Loss: 0.2301
Epoch 3 Step 1901 Train Loss: 0.2332
Epoch 3 Step 1951 Train Loss: 0.1934
Epoch 3: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0052. 
Epoch 4 Step 1 Train Loss: 0.2361
Epoch 4 Step 51 Train Loss: 0.2266
Epoch 4 Step 101 Train Loss: 0.2459
Epoch 4 Step 151 Train Loss: 0.2352
Epoch 4 Step 201 Train Loss: 0.2224
Epoch 4 Step 251 Train Loss: 0.2474
Epoch 4 Step 301 Train Loss: 0.2251
Epoch 4 Step 351 Train Loss: 0.2395
Epoch 4 Step 401 Train Loss: 0.2411
Epoch 4 Step 451 Train Loss: 0.2449
Epoch 4 Step 501 Train Loss: 0.2373
Epoch 4 Step 551 Train Loss: 0.2371
Epoch 4 Step 601 Train Loss: 0.2184
Epoch 4 Step 651 Train Loss: 0.2275
Epoch 4 Step 701 Train Loss: 0.2022
Epoch 4 Step 751 Train Loss: 0.2311
Epoch 4 Step 801 Train Loss: 0.2286
Epoch 4 Step 851 Train Loss: 0.2286
Epoch 4 Step 901 Train Loss: 0.2480
Epoch 4 Step 951 Train Loss: 0.2432
Epoch 4 Step 1001 Train Loss: 0.2316
Epoch 4 Step 1051 Train Loss: 0.2429
Epoch 4 Step 1101 Train Loss: 0.2343
Epoch 4 Step 1151 Train Loss: 0.2328
Epoch 4 Step 1201 Train Loss: 0.2299
Epoch 4 Step 1251 Train Loss: 0.2500
Epoch 4 Step 1301 Train Loss: 0.2131
Epoch 4 Step 1351 Train Loss: 0.2371
Epoch 4 Step 1401 Train Loss: 0.2320
Epoch 4 Step 1451 Train Loss: 0.2272
Epoch 4 Step 1501 Train Loss: 0.2208
Epoch 4 Step 1551 Train Loss: 0.2329
Epoch 4 Step 1601 Train Loss: 0.2361
Epoch 4 Step 1651 Train Loss: 0.2383
Epoch 4 Step 1701 Train Loss: 0.2397
Epoch 4 Step 1751 Train Loss: 0.2404
Epoch 4 Step 1801 Train Loss: 0.2328
Epoch 4 Step 1851 Train Loss: 0.2221
Epoch 4 Step 1901 Train Loss: 0.2206
Epoch 4 Step 1951 Train Loss: 0.2336
Epoch 4: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 5 Step 1 Train Loss: 0.2310
Epoch 5 Step 51 Train Loss: 0.2363
Epoch 5 Step 101 Train Loss: 0.2397
Epoch 5 Step 151 Train Loss: 0.2295
Epoch 5 Step 201 Train Loss: 0.2323
Epoch 5 Step 251 Train Loss: 0.2393
Epoch 5 Step 301 Train Loss: 0.2263
Epoch 5 Step 351 Train Loss: 0.2193
Epoch 5 Step 401 Train Loss: 0.2346
Epoch 5 Step 451 Train Loss: 0.2364
Epoch 5 Step 501 Train Loss: 0.2463
Epoch 5 Step 551 Train Loss: 0.2324
Epoch 5 Step 601 Train Loss: 0.2322
Epoch 5 Step 651 Train Loss: 0.2253
Epoch 5 Step 701 Train Loss: 0.2398
Epoch 5 Step 751 Train Loss: 0.2318
Epoch 5 Step 801 Train Loss: 0.2254
Epoch 5 Step 851 Train Loss: 0.2252
Epoch 5 Step 901 Train Loss: 0.2267
Epoch 5 Step 951 Train Loss: 0.2250
Epoch 5 Step 1001 Train Loss: 0.2237
Epoch 5 Step 1051 Train Loss: 0.2441
Epoch 5 Step 1101 Train Loss: 0.2316
Epoch 5 Step 1151 Train Loss: 0.2369
Epoch 5 Step 1201 Train Loss: 0.2307
Epoch 5 Step 1251 Train Loss: 0.2337
Epoch 5 Step 1301 Train Loss: 0.2330
Epoch 5 Step 1351 Train Loss: 0.2397
Epoch 5 Step 1401 Train Loss: 0.2348
Epoch 5 Step 1451 Train Loss: 0.2343
Epoch 5 Step 1501 Train Loss: 0.2176
Epoch 5 Step 1551 Train Loss: 0.2427
Epoch 5 Step 1601 Train Loss: 0.2308
Epoch 5 Step 1651 Train Loss: 0.2333
Epoch 5 Step 1701 Train Loss: 0.2428
Epoch 5 Step 1751 Train Loss: 0.2434
Epoch 5 Step 1801 Train Loss: 0.2618
Epoch 5 Step 1851 Train Loss: 0.2327
Epoch 5 Step 1901 Train Loss: 0.2456
Epoch 5 Step 1951 Train Loss: 0.2459
Epoch 5: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 6 Step 1 Train Loss: 0.2572
Epoch 6 Step 51 Train Loss: 0.2478
Epoch 6 Step 101 Train Loss: 0.2282
Epoch 6 Step 151 Train Loss: 0.2124
Epoch 6 Step 201 Train Loss: 0.2606
Epoch 6 Step 251 Train Loss: 0.2396
Epoch 6 Step 301 Train Loss: 0.2349
Epoch 6 Step 351 Train Loss: 0.2232
Epoch 6 Step 401 Train Loss: 0.2412
Epoch 6 Step 451 Train Loss: 0.2417
Epoch 6 Step 501 Train Loss: 0.2372
Epoch 6 Step 551 Train Loss: 0.2280
Epoch 6 Step 601 Train Loss: 0.2287
Epoch 6 Step 651 Train Loss: 0.2379
Epoch 6 Step 701 Train Loss: 0.2336
Epoch 6 Step 751 Train Loss: 0.2259
Epoch 6 Step 801 Train Loss: 0.2319
Epoch 6 Step 851 Train Loss: 0.2331
Epoch 6 Step 901 Train Loss: 0.2351
Epoch 6 Step 951 Train Loss: 0.2477
Epoch 6 Step 1001 Train Loss: 0.2539
Epoch 6 Step 1051 Train Loss: 0.2294
Epoch 6 Step 1101 Train Loss: 0.2531
Epoch 6 Step 1151 Train Loss: 0.2340
Epoch 6 Step 1201 Train Loss: 0.2316
Epoch 6 Step 1251 Train Loss: 0.2415
Epoch 6 Step 1301 Train Loss: 0.2271
Epoch 6 Step 1351 Train Loss: 0.2560
Epoch 6 Step 1401 Train Loss: 0.2505
Epoch 6 Step 1451 Train Loss: 0.2436
Epoch 6 Step 1501 Train Loss: 0.2396
Epoch 6 Step 1551 Train Loss: 0.2252
Epoch 6 Step 1601 Train Loss: 0.2403
Epoch 6 Step 1651 Train Loss: 0.2472
Epoch 6 Step 1701 Train Loss: 0.2761
Epoch 6 Step 1751 Train Loss: 0.2232
Epoch 6 Step 1801 Train Loss: 0.2632
Epoch 6 Step 1851 Train Loss: 0.2491
Epoch 6 Step 1901 Train Loss: 0.2531
Epoch 6 Step 1951 Train Loss: 0.2555
Epoch 6: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 7 Step 1 Train Loss: 0.2335
Epoch 7 Step 51 Train Loss: 0.2240
Epoch 7 Step 101 Train Loss: 0.2453
Epoch 7 Step 151 Train Loss: 0.2320
Epoch 7 Step 201 Train Loss: 0.2273
Epoch 7 Step 251 Train Loss: 0.2299
Epoch 7 Step 301 Train Loss: 0.2340
Epoch 7 Step 351 Train Loss: 0.2293
Epoch 7 Step 401 Train Loss: 0.2544
Epoch 7 Step 451 Train Loss: 0.2329
Epoch 7 Step 501 Train Loss: 0.2526
Epoch 7 Step 551 Train Loss: 0.2064
Epoch 7 Step 601 Train Loss: 0.2365
Epoch 7 Step 651 Train Loss: 0.2357
Epoch 7 Step 701 Train Loss: 0.2277
Epoch 7 Step 751 Train Loss: 0.2413
Epoch 7 Step 801 Train Loss: 0.2299
Epoch 7 Step 851 Train Loss: 0.2419
Epoch 7 Step 901 Train Loss: 0.2445
Epoch 7 Step 951 Train Loss: 0.2691
Epoch 7 Step 1001 Train Loss: 0.2335
Epoch 7 Step 1051 Train Loss: 0.2591
Epoch 7 Step 1101 Train Loss: 0.2322
Epoch 7 Step 1151 Train Loss: 0.2329
Epoch 7 Step 1201 Train Loss: 0.2329
Epoch 7 Step 1251 Train Loss: 0.2408
Epoch 7 Step 1301 Train Loss: 0.2583
Epoch 7 Step 1351 Train Loss: 0.2421
Epoch 7 Step 1401 Train Loss: 0.2344
Epoch 7 Step 1451 Train Loss: 0.2386
Epoch 7 Step 1501 Train Loss: 0.2479
Epoch 7 Step 1551 Train Loss: 0.2394
Epoch 7 Step 1601 Train Loss: 0.2282
Epoch 7 Step 1651 Train Loss: 0.2214
Epoch 7 Step 1701 Train Loss: 0.2197
Epoch 7 Step 1751 Train Loss: 0.2361
Epoch 7 Step 1801 Train Loss: 0.2360
Epoch 7 Step 1851 Train Loss: 0.2425
Epoch 7 Step 1901 Train Loss: 0.2274
Epoch 7 Step 1951 Train Loss: 0.2377
Epoch 7: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 8 Step 1 Train Loss: 0.2707
Epoch 8 Step 51 Train Loss: 0.2419
Epoch 8 Step 101 Train Loss: 0.2212
Epoch 8 Step 151 Train Loss: 0.2528
Epoch 8 Step 201 Train Loss: 0.2346
Epoch 8 Step 251 Train Loss: 0.2412
Epoch 8 Step 301 Train Loss: 0.2413
Epoch 8 Step 351 Train Loss: 0.2283
Epoch 8 Step 401 Train Loss: 0.2345
Epoch 8 Step 451 Train Loss: 0.2254
Epoch 8 Step 501 Train Loss: 0.2271
Epoch 8 Step 551 Train Loss: 0.2323
Epoch 8 Step 601 Train Loss: 0.2183
Epoch 8 Step 651 Train Loss: 0.2483
Epoch 8 Step 701 Train Loss: 0.2481
Epoch 8 Step 751 Train Loss: 0.2359
Epoch 8 Step 801 Train Loss: 0.2431
Epoch 8 Step 851 Train Loss: 0.2427
Epoch 8 Step 901 Train Loss: 0.2295
Epoch 8 Step 951 Train Loss: 0.2224
Epoch 8 Step 1001 Train Loss: 0.2331
Epoch 8 Step 1051 Train Loss: 0.2356
Epoch 8 Step 1101 Train Loss: 0.2474
Epoch 8 Step 1151 Train Loss: 0.2386
Epoch 8 Step 1201 Train Loss: 0.2197
Epoch 8 Step 1251 Train Loss: 0.2306
Epoch 8 Step 1301 Train Loss: 0.2326
Epoch 8 Step 1351 Train Loss: 0.2572
Epoch 8 Step 1401 Train Loss: 0.2400
Epoch 8 Step 1451 Train Loss: 0.2362
Epoch 8 Step 1501 Train Loss: 0.2604
Epoch 8 Step 1551 Train Loss: 0.2563
Epoch 8 Step 1601 Train Loss: 0.2446
Epoch 8 Step 1651 Train Loss: 0.2364
Epoch 8 Step 1701 Train Loss: 0.2353
Epoch 8 Step 1751 Train Loss: 0.2371
Epoch 8 Step 1801 Train Loss: 0.2378
Epoch 8 Step 1851 Train Loss: 0.2279
Epoch 8 Step 1901 Train Loss: 0.2399
Epoch 8 Step 1951 Train Loss: 0.2506
Epoch 8: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 9 Step 1 Train Loss: 0.2434
Epoch 9 Step 51 Train Loss: 0.2351
Epoch 9 Step 101 Train Loss: 0.2439
Epoch 9 Step 151 Train Loss: 0.2359
Epoch 9 Step 201 Train Loss: 0.2251
Epoch 9 Step 251 Train Loss: 0.2388
Epoch 9 Step 301 Train Loss: 0.2261
Epoch 9 Step 351 Train Loss: 0.2362
Epoch 9 Step 401 Train Loss: 0.2268
Epoch 9 Step 451 Train Loss: 0.2299
Epoch 9 Step 501 Train Loss: 0.2274
Epoch 9 Step 551 Train Loss: 0.2535
Epoch 9 Step 601 Train Loss: 0.2376
Epoch 9 Step 651 Train Loss: 0.2592
Epoch 9 Step 701 Train Loss: 0.2316
Epoch 9 Step 751 Train Loss: 0.2312
Epoch 9 Step 801 Train Loss: 0.2311
Epoch 9 Step 851 Train Loss: 0.2372
Epoch 9 Step 901 Train Loss: 0.2503
Epoch 9 Step 951 Train Loss: 0.2413
Epoch 9 Step 1001 Train Loss: 0.2532
Epoch 9 Step 1051 Train Loss: 0.2426
Epoch 9 Step 1101 Train Loss: 0.2413
Epoch 9 Step 1151 Train Loss: 0.2347
Epoch 9 Step 1201 Train Loss: 0.2188
Epoch 9 Step 1251 Train Loss: 0.2686
Epoch 9 Step 1301 Train Loss: 0.2306
Epoch 9 Step 1351 Train Loss: 0.2261
Epoch 9 Step 1401 Train Loss: 0.2353
Epoch 9 Step 1451 Train Loss: 0.2438
Epoch 9 Step 1501 Train Loss: 0.2356
Epoch 9 Step 1551 Train Loss: 0.2389
Epoch 9 Step 1601 Train Loss: 0.2247
Epoch 9 Step 1651 Train Loss: 0.2431
Epoch 9 Step 1701 Train Loss: 0.2263
Epoch 9 Step 1751 Train Loss: 0.2397
Epoch 9 Step 1801 Train Loss: 0.2265
Epoch 9 Step 1851 Train Loss: 0.2439
Epoch 9 Step 1901 Train Loss: 0.2459
Epoch 9 Step 1951 Train Loss: 0.2485
Epoch 9: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 10 Step 1 Train Loss: 0.2287
Epoch 10 Step 51 Train Loss: 0.2400
Epoch 10 Step 101 Train Loss: 0.2531
Epoch 10 Step 151 Train Loss: 0.2315
Epoch 10 Step 201 Train Loss: 0.2352
Epoch 10 Step 251 Train Loss: 0.2358
Epoch 10 Step 301 Train Loss: 0.2450
Epoch 10 Step 351 Train Loss: 0.2473
Epoch 10 Step 401 Train Loss: 0.2504
Epoch 10 Step 451 Train Loss: 0.2519
Epoch 10 Step 501 Train Loss: 0.2559
Epoch 10 Step 551 Train Loss: 0.2274
Epoch 10 Step 601 Train Loss: 0.2156
Epoch 10 Step 651 Train Loss: 0.2206
Epoch 10 Step 701 Train Loss: 0.2289
Epoch 10 Step 751 Train Loss: 0.2246
Epoch 10 Step 801 Train Loss: 0.2294
Epoch 10 Step 851 Train Loss: 0.2318
Epoch 10 Step 901 Train Loss: 0.2127
Epoch 10 Step 951 Train Loss: 0.2492
Epoch 10 Step 1001 Train Loss: 0.2476
Epoch 10 Step 1051 Train Loss: 0.2316
Epoch 10 Step 1101 Train Loss: 0.2416
Epoch 10 Step 1151 Train Loss: 0.2479
Epoch 10 Step 1201 Train Loss: 0.2362
Epoch 10 Step 1251 Train Loss: 0.2464
Epoch 10 Step 1301 Train Loss: 0.2196
Epoch 10 Step 1351 Train Loss: 0.2375
Epoch 10 Step 1401 Train Loss: 0.2293
Epoch 10 Step 1451 Train Loss: 0.2357
Epoch 10 Step 1501 Train Loss: 0.2279
Epoch 10 Step 1551 Train Loss: 0.2268
Epoch 10 Step 1601 Train Loss: 0.2334
Epoch 10 Step 1651 Train Loss: 0.2507
Epoch 10 Step 1701 Train Loss: 0.2521
Epoch 10 Step 1751 Train Loss: 0.2348
Epoch 10 Step 1801 Train Loss: 0.2354
Epoch 10 Step 1851 Train Loss: 0.2374
Epoch 10 Step 1901 Train Loss: 0.2225
Epoch 10 Step 1951 Train Loss: 0.2301
Epoch 10: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 11 Step 1 Train Loss: 0.2232
Epoch 11 Step 51 Train Loss: 0.2292
Epoch 11 Step 101 Train Loss: 0.2348
Epoch 11 Step 151 Train Loss: 0.2403
Epoch 11 Step 201 Train Loss: 0.2454
Epoch 11 Step 251 Train Loss: 0.2235
Epoch 11 Step 301 Train Loss: 0.2195
Epoch 11 Step 351 Train Loss: 0.2335
Epoch 11 Step 401 Train Loss: 0.2475
Epoch 11 Step 451 Train Loss: 0.2262
Epoch 11 Step 501 Train Loss: 0.2466
Epoch 11 Step 551 Train Loss: 0.2384
Epoch 11 Step 601 Train Loss: 0.2338
Epoch 11 Step 651 Train Loss: 0.2358
Epoch 11 Step 701 Train Loss: 0.2374
Epoch 11 Step 751 Train Loss: 0.2564
Epoch 11 Step 801 Train Loss: 0.2522
Epoch 11 Step 851 Train Loss: 0.2698
Epoch 11 Step 901 Train Loss: 0.2437
Epoch 11 Step 951 Train Loss: 0.2588
Epoch 11 Step 1001 Train Loss: 0.2446
Epoch 11 Step 1051 Train Loss: 0.2151
Epoch 11 Step 1101 Train Loss: 0.2368
Epoch 11 Step 1151 Train Loss: 0.2676
Epoch 11 Step 1201 Train Loss: 0.2410
Epoch 11 Step 1251 Train Loss: 0.2287
Epoch 11 Step 1301 Train Loss: 0.2344
Epoch 11 Step 1351 Train Loss: 0.2370
Epoch 11 Step 1401 Train Loss: 0.2535
Epoch 11 Step 1451 Train Loss: 0.2186
Epoch 11 Step 1501 Train Loss: 0.2299
Epoch 11 Step 1551 Train Loss: 0.2518
Epoch 11 Step 1601 Train Loss: 0.2458
Epoch 11 Step 1651 Train Loss: 0.2301
Epoch 11 Step 1701 Train Loss: 0.2343
Epoch 11 Step 1751 Train Loss: 0.2334
Epoch 11 Step 1801 Train Loss: 0.2522
Epoch 11 Step 1851 Train Loss: 0.2281
Epoch 11 Step 1901 Train Loss: 0.2326
Epoch 11 Step 1951 Train Loss: 0.2172
Epoch 11: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 12 Step 1 Train Loss: 0.2456
Epoch 12 Step 51 Train Loss: 0.2354
Epoch 12 Step 101 Train Loss: 0.2336
Epoch 12 Step 151 Train Loss: 0.2414
Epoch 12 Step 201 Train Loss: 0.2347
Epoch 12 Step 251 Train Loss: 0.2678
Epoch 12 Step 301 Train Loss: 0.2365
Epoch 12 Step 351 Train Loss: 0.2490
Epoch 12 Step 401 Train Loss: 0.2514
Epoch 12 Step 451 Train Loss: 0.2473
Epoch 12 Step 501 Train Loss: 0.2503
Epoch 12 Step 551 Train Loss: 0.2468
Epoch 12 Step 601 Train Loss: 0.2476
Epoch 12 Step 651 Train Loss: 0.2167
Epoch 12 Step 701 Train Loss: 0.2428
Epoch 12 Step 751 Train Loss: 0.2438
Epoch 12 Step 801 Train Loss: 0.2538
Epoch 12 Step 851 Train Loss: 0.2385
Epoch 12 Step 901 Train Loss: 0.2196
Epoch 12 Step 951 Train Loss: 0.2384
Epoch 12 Step 1001 Train Loss: 0.2437
Epoch 12 Step 1051 Train Loss: 0.2587
Epoch 12 Step 1101 Train Loss: 0.2453
Epoch 12 Step 1151 Train Loss: 0.2299
Epoch 12 Step 1201 Train Loss: 0.2512
Epoch 12 Step 1251 Train Loss: 0.2214
Epoch 12 Step 1301 Train Loss: 0.2193
Epoch 12 Step 1351 Train Loss: 0.2210
Epoch 12 Step 1401 Train Loss: 0.2290
Epoch 12 Step 1451 Train Loss: 0.2569
Epoch 12 Step 1501 Train Loss: 0.2346
Epoch 12 Step 1551 Train Loss: 0.2366
Epoch 12 Step 1601 Train Loss: 0.2246
Epoch 12 Step 1651 Train Loss: 0.2171
Epoch 12 Step 1701 Train Loss: 0.2311
Epoch 12 Step 1751 Train Loss: 0.2212
Epoch 12 Step 1801 Train Loss: 0.2509
Epoch 12 Step 1851 Train Loss: 0.2317
Epoch 12 Step 1901 Train Loss: 0.2409
Epoch 12 Step 1951 Train Loss: 0.2149
Epoch 12: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 13 Step 1 Train Loss: 0.2152
Epoch 13 Step 51 Train Loss: 0.2355
Epoch 13 Step 101 Train Loss: 0.2467
Epoch 13 Step 151 Train Loss: 0.2367
Epoch 13 Step 201 Train Loss: 0.2284
Epoch 13 Step 251 Train Loss: 0.2327
Epoch 13 Step 301 Train Loss: 0.2280
Epoch 13 Step 351 Train Loss: 0.2509
Epoch 13 Step 401 Train Loss: 0.2347
Epoch 13 Step 451 Train Loss: 0.2407
Epoch 13 Step 501 Train Loss: 0.2535
Epoch 13 Step 551 Train Loss: 0.2427
Epoch 13 Step 601 Train Loss: 0.2418
Epoch 13 Step 651 Train Loss: 0.2482
Epoch 13 Step 701 Train Loss: 0.2436
Epoch 13 Step 751 Train Loss: 0.2455
Epoch 13 Step 801 Train Loss: 0.2286
Epoch 13 Step 851 Train Loss: 0.2406
Epoch 13 Step 901 Train Loss: 0.2408
Epoch 13 Step 951 Train Loss: 0.2455
Epoch 13 Step 1001 Train Loss: 0.2283
Epoch 13 Step 1051 Train Loss: 0.2597
Epoch 13 Step 1101 Train Loss: 0.2258
Epoch 13 Step 1151 Train Loss: 0.2344
Epoch 13 Step 1201 Train Loss: 0.2128
Epoch 13 Step 1251 Train Loss: 0.2449
Epoch 13 Step 1301 Train Loss: 0.2360
Epoch 13 Step 1351 Train Loss: 0.2213
Epoch 13 Step 1401 Train Loss: 0.2440
Epoch 13 Step 1451 Train Loss: 0.2535
Epoch 13 Step 1501 Train Loss: 0.2357
Epoch 13 Step 1551 Train Loss: 0.2208
Epoch 13 Step 1601 Train Loss: 0.2662
Epoch 13 Step 1651 Train Loss: 0.2384
Epoch 13 Step 1701 Train Loss: 0.2451
Epoch 13 Step 1751 Train Loss: 0.2426
Epoch 13 Step 1801 Train Loss: 0.2374
Epoch 13 Step 1851 Train Loss: 0.2421
Epoch 13 Step 1901 Train Loss: 0.2600
Epoch 13 Step 1951 Train Loss: 0.2527
Epoch 13: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 14 Step 1 Train Loss: 0.2400
Epoch 14 Step 51 Train Loss: 0.2394
Epoch 14 Step 101 Train Loss: 0.2478
Epoch 14 Step 151 Train Loss: 0.2416
Epoch 14 Step 201 Train Loss: 0.2286
Epoch 14 Step 251 Train Loss: 0.2524
Epoch 14 Step 301 Train Loss: 0.2450
Epoch 14 Step 351 Train Loss: 0.2443
Epoch 14 Step 401 Train Loss: 0.2217
Epoch 14 Step 451 Train Loss: 0.2154
Epoch 14 Step 501 Train Loss: 0.2458
Epoch 14 Step 551 Train Loss: 0.2519
Epoch 14 Step 601 Train Loss: 0.2517
Epoch 14 Step 651 Train Loss: 0.2273
Epoch 14 Step 701 Train Loss: 0.2564
Epoch 14 Step 751 Train Loss: 0.2198
Epoch 14 Step 801 Train Loss: 0.2470
Epoch 14 Step 851 Train Loss: 0.2439
Epoch 14 Step 901 Train Loss: 0.2301
Epoch 14 Step 951 Train Loss: 0.2459
Epoch 14 Step 1001 Train Loss: 0.2315
Epoch 14 Step 1051 Train Loss: 0.2462
Epoch 14 Step 1101 Train Loss: 0.2279
Epoch 14 Step 1151 Train Loss: 0.2319
Epoch 14 Step 1201 Train Loss: 0.2542
Epoch 14 Step 1251 Train Loss: 0.2055
Epoch 14 Step 1301 Train Loss: 0.2388
Epoch 14 Step 1351 Train Loss: 0.2133
Epoch 14 Step 1401 Train Loss: 0.2527
Epoch 14 Step 1451 Train Loss: 0.2539
Epoch 14 Step 1501 Train Loss: 0.2569
Epoch 14 Step 1551 Train Loss: 0.2498
Epoch 14 Step 1601 Train Loss: 0.2502
Epoch 14 Step 1651 Train Loss: 0.2402
Epoch 14 Step 1701 Train Loss: 0.2330
Epoch 14 Step 1751 Train Loss: 0.2312
Epoch 14 Step 1801 Train Loss: 0.2335
Epoch 14 Step 1851 Train Loss: 0.2308
Epoch 14 Step 1901 Train Loss: 0.2478
Epoch 14 Step 1951 Train Loss: 0.2473
Epoch 14: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Epoch 15 Step 1 Train Loss: 0.2369
Epoch 15 Step 51 Train Loss: 0.2373
Epoch 15 Step 101 Train Loss: 0.2379
Epoch 15 Step 151 Train Loss: 0.2503
Epoch 15 Step 201 Train Loss: 0.2235
Epoch 15 Step 251 Train Loss: 0.2431
Epoch 15 Step 301 Train Loss: 0.2267
Epoch 15 Step 351 Train Loss: 0.2368
Epoch 15 Step 401 Train Loss: 0.2582
Epoch 15 Step 451 Train Loss: 0.2377
Epoch 15 Step 501 Train Loss: 0.2388
Epoch 15 Step 551 Train Loss: 0.2236
Epoch 15 Step 601 Train Loss: 0.2243
Epoch 15 Step 651 Train Loss: 0.2258
Epoch 15 Step 701 Train Loss: 0.2382
Epoch 15 Step 751 Train Loss: 0.2428
Epoch 15 Step 801 Train Loss: 0.2360
Epoch 15 Step 851 Train Loss: 0.2404
Epoch 15 Step 901 Train Loss: 0.2452
Epoch 15 Step 951 Train Loss: 0.2248
Epoch 15 Step 1001 Train Loss: 0.2485
Epoch 15 Step 1051 Train Loss: 0.2282
Epoch 15 Step 1101 Train Loss: 0.2235
Epoch 15 Step 1151 Train Loss: 0.2195
Epoch 15 Step 1201 Train Loss: 0.2297
Epoch 15 Step 1251 Train Loss: 0.2577
Epoch 15 Step 1301 Train Loss: 0.2491
Epoch 15 Step 1351 Train Loss: 0.2482
Epoch 15 Step 1401 Train Loss: 0.2360
Epoch 15 Step 1451 Train Loss: 0.2482
Epoch 15 Step 1501 Train Loss: 0.2339
Epoch 15 Step 1551 Train Loss: 0.2141
Epoch 15 Step 1601 Train Loss: 0.2528
Epoch 15 Step 1651 Train Loss: 0.2229
Epoch 15 Step 1701 Train Loss: 0.2392
Epoch 15 Step 1751 Train Loss: 0.2371
Epoch 15 Step 1801 Train Loss: 0.2526
Epoch 15 Step 1851 Train Loss: 0.2356
Epoch 15 Step 1901 Train Loss: 0.2547
Epoch 15 Step 1951 Train Loss: 0.2165
Epoch 15: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0004. 
Train Top 20 DE MSE: 0.0062 Validation Top 20 DE MSE: 0.0053. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0033
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00033966088
test_unseen_single_pearson: 0.9926343305816057
test_unseen_single_mse_de: 0.0033408124
test_unseen_single_pearson_de: 0.7479110826798031
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.13960006661523341
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.36372549019607836
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9294117647058823
test_unseen_single_mse_top20_de_non_dropout: 0.007478356279269985
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.039 MB uploadedwandb: / 0.001 MB of 0.039 MB uploadedwandb: - 0.013 MB of 0.039 MB uploadedwandb: \ 0.013 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                               val_de_pearson ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00334
wandb:                                              test_de_pearson 0.74791
wandb:               test_frac_opposite_direction_top20_non_dropout 0.36373
wandb:                          test_frac_sigma_below_1_non_dropout 0.92941
wandb:                                                     test_mse 0.00034
wandb:                                test_mse_top20_de_non_dropout 0.00748
wandb:                                                 test_pearson 0.99263
wandb:                                           test_pearson_delta 0.1396
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.36373
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.92941
wandb:                                       test_unseen_single_mse 0.00034
wandb:                                    test_unseen_single_mse_de 0.00334
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00748
wandb:                                   test_unseen_single_pearson 0.99263
wandb:                                test_unseen_single_pearson_de 0.74791
wandb:                             test_unseen_single_pearson_delta 0.1396
wandb:                                                 train_de_mse 0.00621
wandb:                                             train_de_pearson 0.80308
wandb:                                                    train_mse 0.00035
wandb:                                                train_pearson 0.99251
wandb:                                                training_loss 0.24713
wandb:                                                   val_de_mse 0.00529
wandb:                                               val_de_pearson 0.80977
wandb:                                                      val_mse 0.00039
wandb:                                                  val_pearson 0.99153
wandb: 
wandb: üöÄ View run scbert_XuCao2023_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/18ee4pbs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_105525-18ee4pbs/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:51
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_115057-i0boqxke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_XuCao2023_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/i0boqxke
wandb: WARNING Serializing object of type ndarray that is 8275328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.2493
Epoch 1 Step 51 Train Loss: 0.2579
Epoch 1 Step 101 Train Loss: 0.2944
Epoch 1 Step 151 Train Loss: 0.2573
Epoch 1 Step 201 Train Loss: 0.2903
Epoch 1 Step 251 Train Loss: 0.2252
Epoch 1 Step 301 Train Loss: 0.2478
Epoch 1 Step 351 Train Loss: 0.2320
Epoch 1 Step 401 Train Loss: 0.2596
Epoch 1 Step 451 Train Loss: 0.2324
Epoch 1 Step 501 Train Loss: 0.2466
Epoch 1 Step 551 Train Loss: 0.2272
Epoch 1 Step 601 Train Loss: 0.2233
Epoch 1 Step 651 Train Loss: 0.2709
Epoch 1 Step 701 Train Loss: 0.2313
Epoch 1 Step 751 Train Loss: 0.2318
Epoch 1 Step 801 Train Loss: 0.2532
Epoch 1 Step 851 Train Loss: 0.2497
Epoch 1 Step 901 Train Loss: 0.2499
Epoch 1 Step 951 Train Loss: 0.2428
Epoch 1 Step 1001 Train Loss: 0.2261
Epoch 1 Step 1051 Train Loss: 0.2553
Epoch 1 Step 1101 Train Loss: 0.2376
Epoch 1 Step 1151 Train Loss: 0.2235
Epoch 1 Step 1201 Train Loss: 0.2431
Epoch 1 Step 1251 Train Loss: 0.2345
Epoch 1 Step 1301 Train Loss: 0.2248
Epoch 1 Step 1351 Train Loss: 0.2159
Epoch 1 Step 1401 Train Loss: 0.2303
Epoch 1 Step 1451 Train Loss: 0.2186
Epoch 1 Step 1501 Train Loss: 0.2154
Epoch 1 Step 1551 Train Loss: 0.2221
Epoch 1 Step 1601 Train Loss: 0.2249
Epoch 1 Step 1651 Train Loss: 0.2178
Epoch 1 Step 1701 Train Loss: 0.2303
Epoch 1 Step 1751 Train Loss: 0.2158
Epoch 1 Step 1801 Train Loss: 0.2218
Epoch 1: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0057 Validation Top 20 DE MSE: 0.0066. 
Epoch 2 Step 1 Train Loss: 0.2433
Epoch 2 Step 51 Train Loss: 0.2508
Epoch 2 Step 101 Train Loss: 0.2278
Epoch 2 Step 151 Train Loss: 0.2441
Epoch 2 Step 201 Train Loss: 0.2432
Epoch 2 Step 251 Train Loss: 0.2400
Epoch 2 Step 301 Train Loss: 0.2242
Epoch 2 Step 351 Train Loss: 0.2127
Epoch 2 Step 401 Train Loss: 0.2376
Epoch 2 Step 451 Train Loss: 0.2172
Epoch 2 Step 501 Train Loss: 0.2355
Epoch 2 Step 551 Train Loss: 0.2161
Epoch 2 Step 601 Train Loss: 0.2334
Epoch 2 Step 651 Train Loss: 0.2406
Epoch 2 Step 701 Train Loss: 0.2254
Epoch 2 Step 751 Train Loss: 0.2352
Epoch 2 Step 801 Train Loss: 0.2121
Epoch 2 Step 851 Train Loss: 0.2206
Epoch 2 Step 901 Train Loss: 0.2231
Epoch 2 Step 951 Train Loss: 0.2021
Epoch 2 Step 1001 Train Loss: 0.2052
Epoch 2 Step 1051 Train Loss: 0.2115
Epoch 2 Step 1101 Train Loss: 0.2372
Epoch 2 Step 1151 Train Loss: 0.2308
Epoch 2 Step 1201 Train Loss: 0.2164
Epoch 2 Step 1251 Train Loss: 0.2307
Epoch 2 Step 1301 Train Loss: 0.2015
Epoch 2 Step 1351 Train Loss: 0.2363
Epoch 2 Step 1401 Train Loss: 0.2203
Epoch 2 Step 1451 Train Loss: 0.2171
Epoch 2 Step 1501 Train Loss: 0.2317
Epoch 2 Step 1551 Train Loss: 0.2422
Epoch 2 Step 1601 Train Loss: 0.2151
Epoch 2 Step 1651 Train Loss: 0.2457
Epoch 2 Step 1701 Train Loss: 0.2281
Epoch 2 Step 1751 Train Loss: 0.2319
Epoch 2 Step 1801 Train Loss: 0.2331
Epoch 2: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 3 Step 1 Train Loss: 0.2506
Epoch 3 Step 51 Train Loss: 0.2242
Epoch 3 Step 101 Train Loss: 0.2286
Epoch 3 Step 151 Train Loss: 0.2293
Epoch 3 Step 201 Train Loss: 0.2475
Epoch 3 Step 251 Train Loss: 0.2453
Epoch 3 Step 301 Train Loss: 0.2180
Epoch 3 Step 351 Train Loss: 0.2379
Epoch 3 Step 401 Train Loss: 0.2192
Epoch 3 Step 451 Train Loss: 0.2123
Epoch 3 Step 501 Train Loss: 0.2367
Epoch 3 Step 551 Train Loss: 0.2632
Epoch 3 Step 601 Train Loss: 0.2261
Epoch 3 Step 651 Train Loss: 0.2313
Epoch 3 Step 701 Train Loss: 0.2332
Epoch 3 Step 751 Train Loss: 0.2221
Epoch 3 Step 801 Train Loss: 0.2264
Epoch 3 Step 851 Train Loss: 0.2308
Epoch 3 Step 901 Train Loss: 0.2667
Epoch 3 Step 951 Train Loss: 0.2451
Epoch 3 Step 1001 Train Loss: 0.2406
Epoch 3 Step 1051 Train Loss: 0.2001
Epoch 3 Step 1101 Train Loss: 0.2502
Epoch 3 Step 1151 Train Loss: 0.2385
Epoch 3 Step 1201 Train Loss: 0.2211
Epoch 3 Step 1251 Train Loss: 0.2129
Epoch 3 Step 1301 Train Loss: 0.2573
Epoch 3 Step 1351 Train Loss: 0.2279
Epoch 3 Step 1401 Train Loss: 0.2343
Epoch 3 Step 1451 Train Loss: 0.2131
Epoch 3 Step 1501 Train Loss: 0.2604
Epoch 3 Step 1551 Train Loss: 0.2280
Epoch 3 Step 1601 Train Loss: 0.2282
Epoch 3 Step 1651 Train Loss: 0.2312
Epoch 3 Step 1701 Train Loss: 0.2391
Epoch 3 Step 1751 Train Loss: 0.2407
Epoch 3 Step 1801 Train Loss: 0.2539
Epoch 3: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 4 Step 1 Train Loss: 0.2425
Epoch 4 Step 51 Train Loss: 0.2433
Epoch 4 Step 101 Train Loss: 0.2539
Epoch 4 Step 151 Train Loss: 0.2349
Epoch 4 Step 201 Train Loss: 0.2410
Epoch 4 Step 251 Train Loss: 0.2399
Epoch 4 Step 301 Train Loss: 0.2415
Epoch 4 Step 351 Train Loss: 0.2277
Epoch 4 Step 401 Train Loss: 0.2192
Epoch 4 Step 451 Train Loss: 0.2365
Epoch 4 Step 501 Train Loss: 0.2320
Epoch 4 Step 551 Train Loss: 0.2285
Epoch 4 Step 601 Train Loss: 0.2213
Epoch 4 Step 651 Train Loss: 0.2546
Epoch 4 Step 701 Train Loss: 0.2293
Epoch 4 Step 751 Train Loss: 0.2158
Epoch 4 Step 801 Train Loss: 0.2246
Epoch 4 Step 851 Train Loss: 0.2363
Epoch 4 Step 901 Train Loss: 0.2220
Epoch 4 Step 951 Train Loss: 0.2366
Epoch 4 Step 1001 Train Loss: 0.2483
Epoch 4 Step 1051 Train Loss: 0.2337
Epoch 4 Step 1101 Train Loss: 0.2624
Epoch 4 Step 1151 Train Loss: 0.2431
Epoch 4 Step 1201 Train Loss: 0.2309
Epoch 4 Step 1251 Train Loss: 0.2209
Epoch 4 Step 1301 Train Loss: 0.2506
Epoch 4 Step 1351 Train Loss: 0.2275
Epoch 4 Step 1401 Train Loss: 0.2462
Epoch 4 Step 1451 Train Loss: 0.2296
Epoch 4 Step 1501 Train Loss: 0.2471
Epoch 4 Step 1551 Train Loss: 0.2267
Epoch 4 Step 1601 Train Loss: 0.2465
Epoch 4 Step 1651 Train Loss: 0.2305
Epoch 4 Step 1701 Train Loss: 0.2144
Epoch 4 Step 1751 Train Loss: 0.2417
Epoch 4 Step 1801 Train Loss: 0.2382
Epoch 4: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 5 Step 1 Train Loss: 0.2304
Epoch 5 Step 51 Train Loss: 0.2395
Epoch 5 Step 101 Train Loss: 0.2259
Epoch 5 Step 151 Train Loss: 0.2603
Epoch 5 Step 201 Train Loss: 0.2299
Epoch 5 Step 251 Train Loss: 0.2469
Epoch 5 Step 301 Train Loss: 0.2750
Epoch 5 Step 351 Train Loss: 0.2482
Epoch 5 Step 401 Train Loss: 0.2428
Epoch 5 Step 451 Train Loss: 0.2453
Epoch 5 Step 501 Train Loss: 0.2507
Epoch 5 Step 551 Train Loss: 0.2419
Epoch 5 Step 601 Train Loss: 0.2458
Epoch 5 Step 651 Train Loss: 0.2430
Epoch 5 Step 701 Train Loss: 0.2482
Epoch 5 Step 751 Train Loss: 0.2555
Epoch 5 Step 801 Train Loss: 0.2504
Epoch 5 Step 851 Train Loss: 0.2355
Epoch 5 Step 901 Train Loss: 0.2605
Epoch 5 Step 951 Train Loss: 0.2198
Epoch 5 Step 1001 Train Loss: 0.2349
Epoch 5 Step 1051 Train Loss: 0.2308
Epoch 5 Step 1101 Train Loss: 0.2561
Epoch 5 Step 1151 Train Loss: 0.2325
Epoch 5 Step 1201 Train Loss: 0.2267
Epoch 5 Step 1251 Train Loss: 0.2524
Epoch 5 Step 1301 Train Loss: 0.2294
Epoch 5 Step 1351 Train Loss: 0.2371
Epoch 5 Step 1401 Train Loss: 0.2248
Epoch 5 Step 1451 Train Loss: 0.2363
Epoch 5 Step 1501 Train Loss: 0.2381
Epoch 5 Step 1551 Train Loss: 0.2354
Epoch 5 Step 1601 Train Loss: 0.2363
Epoch 5 Step 1651 Train Loss: 0.2243
Epoch 5 Step 1701 Train Loss: 0.2349
Epoch 5 Step 1751 Train Loss: 0.2482
Epoch 5 Step 1801 Train Loss: 0.2421
Epoch 5: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 6 Step 1 Train Loss: 0.2548
Epoch 6 Step 51 Train Loss: 0.2383
Epoch 6 Step 101 Train Loss: 0.2251
Epoch 6 Step 151 Train Loss: 0.2619
Epoch 6 Step 201 Train Loss: 0.2489
Epoch 6 Step 251 Train Loss: 0.2238
Epoch 6 Step 301 Train Loss: 0.2361
Epoch 6 Step 351 Train Loss: 0.2493
Epoch 6 Step 401 Train Loss: 0.2369
Epoch 6 Step 451 Train Loss: 0.2497
Epoch 6 Step 501 Train Loss: 0.2407
Epoch 6 Step 551 Train Loss: 0.2423
Epoch 6 Step 601 Train Loss: 0.2811
Epoch 6 Step 651 Train Loss: 0.2484
Epoch 6 Step 701 Train Loss: 0.2363
Epoch 6 Step 751 Train Loss: 0.2427
Epoch 6 Step 801 Train Loss: 0.2291
Epoch 6 Step 851 Train Loss: 0.2311
Epoch 6 Step 901 Train Loss: 0.2383
Epoch 6 Step 951 Train Loss: 0.2489
Epoch 6 Step 1001 Train Loss: 0.2161
Epoch 6 Step 1051 Train Loss: 0.2414
Epoch 6 Step 1101 Train Loss: 0.2402
Epoch 6 Step 1151 Train Loss: 0.2283
Epoch 6 Step 1201 Train Loss: 0.2522
Epoch 6 Step 1251 Train Loss: 0.2200
Epoch 6 Step 1301 Train Loss: 0.2480
Epoch 6 Step 1351 Train Loss: 0.2520
Epoch 6 Step 1401 Train Loss: 0.2177
Epoch 6 Step 1451 Train Loss: 0.2526
Epoch 6 Step 1501 Train Loss: 0.2494
Epoch 6 Step 1551 Train Loss: 0.2290
Epoch 6 Step 1601 Train Loss: 0.2564
Epoch 6 Step 1651 Train Loss: 0.2490
Epoch 6 Step 1701 Train Loss: 0.2219
Epoch 6 Step 1751 Train Loss: 0.2386
Epoch 6 Step 1801 Train Loss: 0.2309
Epoch 6: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 7 Step 1 Train Loss: 0.2389
Epoch 7 Step 51 Train Loss: 0.2646
Epoch 7 Step 101 Train Loss: 0.2317
Epoch 7 Step 151 Train Loss: 0.2370
Epoch 7 Step 201 Train Loss: 0.2436
Epoch 7 Step 251 Train Loss: 0.2586
Epoch 7 Step 301 Train Loss: 0.2460
Epoch 7 Step 351 Train Loss: 0.2541
Epoch 7 Step 401 Train Loss: 0.2384
Epoch 7 Step 451 Train Loss: 0.2201
Epoch 7 Step 501 Train Loss: 0.2392
Epoch 7 Step 551 Train Loss: 0.2471
Epoch 7 Step 601 Train Loss: 0.2406
Epoch 7 Step 651 Train Loss: 0.2602
Epoch 7 Step 701 Train Loss: 0.2430
Epoch 7 Step 751 Train Loss: 0.2518
Epoch 7 Step 801 Train Loss: 0.2392
Epoch 7 Step 851 Train Loss: 0.2593
Epoch 7 Step 901 Train Loss: 0.2328
Epoch 7 Step 951 Train Loss: 0.2400
Epoch 7 Step 1001 Train Loss: 0.2451
Epoch 7 Step 1051 Train Loss: 0.2642
Epoch 7 Step 1101 Train Loss: 0.2307
Epoch 7 Step 1151 Train Loss: 0.2476
Epoch 7 Step 1201 Train Loss: 0.2397
Epoch 7 Step 1251 Train Loss: 0.2440
Epoch 7 Step 1301 Train Loss: 0.2313
Epoch 7 Step 1351 Train Loss: 0.2221
Epoch 7 Step 1401 Train Loss: 0.2542
Epoch 7 Step 1451 Train Loss: 0.2345
Epoch 7 Step 1501 Train Loss: 0.2301
Epoch 7 Step 1551 Train Loss: 0.2394
Epoch 7 Step 1601 Train Loss: 0.2108
Epoch 7 Step 1651 Train Loss: 0.2281
Epoch 7 Step 1701 Train Loss: 0.2288
Epoch 7 Step 1751 Train Loss: 0.2386
Epoch 7 Step 1801 Train Loss: 0.2657
Epoch 7: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 8 Step 1 Train Loss: 0.2353
Epoch 8 Step 51 Train Loss: 0.2457
Epoch 8 Step 101 Train Loss: 0.2402
Epoch 8 Step 151 Train Loss: 0.2439
Epoch 8 Step 201 Train Loss: 0.2442
Epoch 8 Step 251 Train Loss: 0.2377
Epoch 8 Step 301 Train Loss: 0.2512
Epoch 8 Step 351 Train Loss: 0.2415
Epoch 8 Step 401 Train Loss: 0.2318
Epoch 8 Step 451 Train Loss: 0.2580
Epoch 8 Step 501 Train Loss: 0.2483
Epoch 8 Step 551 Train Loss: 0.2476
Epoch 8 Step 601 Train Loss: 0.2309
Epoch 8 Step 651 Train Loss: 0.2270
Epoch 8 Step 701 Train Loss: 0.2684
Epoch 8 Step 751 Train Loss: 0.2486
Epoch 8 Step 801 Train Loss: 0.2399
Epoch 8 Step 851 Train Loss: 0.2340
Epoch 8 Step 901 Train Loss: 0.2396
Epoch 8 Step 951 Train Loss: 0.2268
Epoch 8 Step 1001 Train Loss: 0.2291
Epoch 8 Step 1051 Train Loss: 0.2347
Epoch 8 Step 1101 Train Loss: 0.2186
Epoch 8 Step 1151 Train Loss: 0.2417
Epoch 8 Step 1201 Train Loss: 0.2363
Epoch 8 Step 1251 Train Loss: 0.2670
Epoch 8 Step 1301 Train Loss: 0.2370
Epoch 8 Step 1351 Train Loss: 0.2686
Epoch 8 Step 1401 Train Loss: 0.2391
Epoch 8 Step 1451 Train Loss: 0.2225
Epoch 8 Step 1501 Train Loss: 0.2517
Epoch 8 Step 1551 Train Loss: 0.2388
Epoch 8 Step 1601 Train Loss: 0.2225
Epoch 8 Step 1651 Train Loss: 0.2295
Epoch 8 Step 1701 Train Loss: 0.2298
Epoch 8 Step 1751 Train Loss: 0.2266
Epoch 8 Step 1801 Train Loss: 0.2414
Epoch 8: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 9 Step 1 Train Loss: 0.2477
Epoch 9 Step 51 Train Loss: 0.2479
Epoch 9 Step 101 Train Loss: 0.2213
Epoch 9 Step 151 Train Loss: 0.2196
Epoch 9 Step 201 Train Loss: 0.2401
Epoch 9 Step 251 Train Loss: 0.2314
Epoch 9 Step 301 Train Loss: 0.2257
Epoch 9 Step 351 Train Loss: 0.2402
Epoch 9 Step 401 Train Loss: 0.2276
Epoch 9 Step 451 Train Loss: 0.2300
Epoch 9 Step 501 Train Loss: 0.2351
Epoch 9 Step 551 Train Loss: 0.2409
Epoch 9 Step 601 Train Loss: 0.2367
Epoch 9 Step 651 Train Loss: 0.2399
Epoch 9 Step 701 Train Loss: 0.2614
Epoch 9 Step 751 Train Loss: 0.2283
Epoch 9 Step 801 Train Loss: 0.2497
Epoch 9 Step 851 Train Loss: 0.2321
Epoch 9 Step 901 Train Loss: 0.2529
Epoch 9 Step 951 Train Loss: 0.2448
Epoch 9 Step 1001 Train Loss: 0.2416
Epoch 9 Step 1051 Train Loss: 0.2319
Epoch 9 Step 1101 Train Loss: 0.2258
Epoch 9 Step 1151 Train Loss: 0.2399
Epoch 9 Step 1201 Train Loss: 0.2473
Epoch 9 Step 1251 Train Loss: 0.2568
Epoch 9 Step 1301 Train Loss: 0.2356
Epoch 9 Step 1351 Train Loss: 0.2573
Epoch 9 Step 1401 Train Loss: 0.2484
Epoch 9 Step 1451 Train Loss: 0.2389
Epoch 9 Step 1501 Train Loss: 0.2194
Epoch 9 Step 1551 Train Loss: 0.2591
Epoch 9 Step 1601 Train Loss: 0.2397
Epoch 9 Step 1651 Train Loss: 0.2197
Epoch 9 Step 1701 Train Loss: 0.2438
Epoch 9 Step 1751 Train Loss: 0.2351
Epoch 9 Step 1801 Train Loss: 0.2346
Epoch 9: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 10 Step 1 Train Loss: 0.2399
Epoch 10 Step 51 Train Loss: 0.2293
Epoch 10 Step 101 Train Loss: 0.2566
Epoch 10 Step 151 Train Loss: 0.2156
Epoch 10 Step 201 Train Loss: 0.2630
Epoch 10 Step 251 Train Loss: 0.2342
Epoch 10 Step 301 Train Loss: 0.2240
Epoch 10 Step 351 Train Loss: 0.2362
Epoch 10 Step 401 Train Loss: 0.2372
Epoch 10 Step 451 Train Loss: 0.2317
Epoch 10 Step 501 Train Loss: 0.2386
Epoch 10 Step 551 Train Loss: 0.2476
Epoch 10 Step 601 Train Loss: 0.2531
Epoch 10 Step 651 Train Loss: 0.2328
Epoch 10 Step 701 Train Loss: 0.2374
Epoch 10 Step 751 Train Loss: 0.2405
Epoch 10 Step 801 Train Loss: 0.2896
Epoch 10 Step 851 Train Loss: 0.2479
Epoch 10 Step 901 Train Loss: 0.2344
Epoch 10 Step 951 Train Loss: 0.2377
Epoch 10 Step 1001 Train Loss: 0.2345
Epoch 10 Step 1051 Train Loss: 0.2307
Epoch 10 Step 1101 Train Loss: 0.2356
Epoch 10 Step 1151 Train Loss: 0.2563
Epoch 10 Step 1201 Train Loss: 0.2272
Epoch 10 Step 1251 Train Loss: 0.2457
Epoch 10 Step 1301 Train Loss: 0.2488
Epoch 10 Step 1351 Train Loss: 0.2433
Epoch 10 Step 1401 Train Loss: 0.2371
Epoch 10 Step 1451 Train Loss: 0.2397
Epoch 10 Step 1501 Train Loss: 0.2430
Epoch 10 Step 1551 Train Loss: 0.2372
Epoch 10 Step 1601 Train Loss: 0.2548
Epoch 10 Step 1651 Train Loss: 0.2206
Epoch 10 Step 1701 Train Loss: 0.2075
Epoch 10 Step 1751 Train Loss: 0.2384
Epoch 10 Step 1801 Train Loss: 0.2218
Epoch 10: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 11 Step 1 Train Loss: 0.2636
Epoch 11 Step 51 Train Loss: 0.2567
Epoch 11 Step 101 Train Loss: 0.2292
Epoch 11 Step 151 Train Loss: 0.2413
Epoch 11 Step 201 Train Loss: 0.2440
Epoch 11 Step 251 Train Loss: 0.2401
Epoch 11 Step 301 Train Loss: 0.2439
Epoch 11 Step 351 Train Loss: 0.2218
Epoch 11 Step 401 Train Loss: 0.2191
Epoch 11 Step 451 Train Loss: 0.2396
Epoch 11 Step 501 Train Loss: 0.2562
Epoch 11 Step 551 Train Loss: 0.2564
Epoch 11 Step 601 Train Loss: 0.2360
Epoch 11 Step 651 Train Loss: 0.2448
Epoch 11 Step 701 Train Loss: 0.2284
Epoch 11 Step 751 Train Loss: 0.2407
Epoch 11 Step 801 Train Loss: 0.2993
Epoch 11 Step 851 Train Loss: 0.2625
Epoch 11 Step 901 Train Loss: 0.2463
Epoch 11 Step 951 Train Loss: 0.2459
Epoch 11 Step 1001 Train Loss: 0.2430
Epoch 11 Step 1051 Train Loss: 0.2268
Epoch 11 Step 1101 Train Loss: 0.2592
Epoch 11 Step 1151 Train Loss: 0.2450
Epoch 11 Step 1201 Train Loss: 0.2431
Epoch 11 Step 1251 Train Loss: 0.2857
Epoch 11 Step 1301 Train Loss: 0.2253
Epoch 11 Step 1351 Train Loss: 0.2432
Epoch 11 Step 1401 Train Loss: 0.2582
Epoch 11 Step 1451 Train Loss: 0.2327
Epoch 11 Step 1501 Train Loss: 0.2265
Epoch 11 Step 1551 Train Loss: 0.2586
Epoch 11 Step 1601 Train Loss: 0.2503
Epoch 11 Step 1651 Train Loss: 0.2302
Epoch 11 Step 1701 Train Loss: 0.2618
Epoch 11 Step 1751 Train Loss: 0.2461
Epoch 11 Step 1801 Train Loss: 0.2508
Epoch 11: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 12 Step 1 Train Loss: 0.2445
Epoch 12 Step 51 Train Loss: 0.2559
Epoch 12 Step 101 Train Loss: 0.2527
Epoch 12 Step 151 Train Loss: 0.2722
Epoch 12 Step 201 Train Loss: 0.2563
Epoch 12 Step 251 Train Loss: 0.2462
Epoch 12 Step 301 Train Loss: 0.2532
Epoch 12 Step 351 Train Loss: 0.2271
Epoch 12 Step 401 Train Loss: 0.2531
Epoch 12 Step 451 Train Loss: 0.2388
Epoch 12 Step 501 Train Loss: 0.2496
Epoch 12 Step 551 Train Loss: 0.2530
Epoch 12 Step 601 Train Loss: 0.2324
Epoch 12 Step 651 Train Loss: 0.2495
Epoch 12 Step 701 Train Loss: 0.2382
Epoch 12 Step 751 Train Loss: 0.2452
Epoch 12 Step 801 Train Loss: 0.2552
Epoch 12 Step 851 Train Loss: 0.2330
Epoch 12 Step 901 Train Loss: 0.2304
Epoch 12 Step 951 Train Loss: 0.2274
Epoch 12 Step 1001 Train Loss: 0.2431
Epoch 12 Step 1051 Train Loss: 0.2310
Epoch 12 Step 1101 Train Loss: 0.2677
Epoch 12 Step 1151 Train Loss: 0.2460
Epoch 12 Step 1201 Train Loss: 0.2330
Epoch 12 Step 1251 Train Loss: 0.2437
Epoch 12 Step 1301 Train Loss: 0.2602
Epoch 12 Step 1351 Train Loss: 0.2261
Epoch 12 Step 1401 Train Loss: 0.2479
Epoch 12 Step 1451 Train Loss: 0.2487
Epoch 12 Step 1501 Train Loss: 0.2450
Epoch 12 Step 1551 Train Loss: 0.2400
Epoch 12 Step 1601 Train Loss: 0.2269
Epoch 12 Step 1651 Train Loss: 0.2440
Epoch 12 Step 1701 Train Loss: 0.2730
Epoch 12 Step 1751 Train Loss: 0.2448
Epoch 12 Step 1801 Train Loss: 0.2401
Epoch 12: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 13 Step 1 Train Loss: 0.2560
Epoch 13 Step 51 Train Loss: 0.2509
Epoch 13 Step 101 Train Loss: 0.2599
Epoch 13 Step 151 Train Loss: 0.2576
Epoch 13 Step 201 Train Loss: 0.2363
Epoch 13 Step 251 Train Loss: 0.2302
Epoch 13 Step 301 Train Loss: 0.2355
Epoch 13 Step 351 Train Loss: 0.2290
Epoch 13 Step 401 Train Loss: 0.2394
Epoch 13 Step 451 Train Loss: 0.2235
Epoch 13 Step 501 Train Loss: 0.2451
Epoch 13 Step 551 Train Loss: 0.2422
Epoch 13 Step 601 Train Loss: 0.2516
Epoch 13 Step 651 Train Loss: 0.2599
Epoch 13 Step 701 Train Loss: 0.2510
Epoch 13 Step 751 Train Loss: 0.2248
Epoch 13 Step 801 Train Loss: 0.2412
Epoch 13 Step 851 Train Loss: 0.2271
Epoch 13 Step 901 Train Loss: 0.2430
Epoch 13 Step 951 Train Loss: 0.2308
Epoch 13 Step 1001 Train Loss: 0.2550
Epoch 13 Step 1051 Train Loss: 0.2390
Epoch 13 Step 1101 Train Loss: 0.2330
Epoch 13 Step 1151 Train Loss: 0.2372
Epoch 13 Step 1201 Train Loss: 0.2221
Epoch 13 Step 1251 Train Loss: 0.2262
Epoch 13 Step 1301 Train Loss: 0.2569
Epoch 13 Step 1351 Train Loss: 0.2515
Epoch 13 Step 1401 Train Loss: 0.2481
Epoch 13 Step 1451 Train Loss: 0.2245
Epoch 13 Step 1501 Train Loss: 0.2337
Epoch 13 Step 1551 Train Loss: 0.2670
Epoch 13 Step 1601 Train Loss: 0.2401
Epoch 13 Step 1651 Train Loss: 0.2770
Epoch 13 Step 1701 Train Loss: 0.2538
Epoch 13 Step 1751 Train Loss: 0.2530
Epoch 13 Step 1801 Train Loss: 0.2363
Epoch 13: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 14 Step 1 Train Loss: 0.2179
Epoch 14 Step 51 Train Loss: 0.2766
Epoch 14 Step 101 Train Loss: 0.2620
Epoch 14 Step 151 Train Loss: 0.2506
Epoch 14 Step 201 Train Loss: 0.2267
Epoch 14 Step 251 Train Loss: 0.2411
Epoch 14 Step 301 Train Loss: 0.2316
Epoch 14 Step 351 Train Loss: 0.2423
Epoch 14 Step 401 Train Loss: 0.2395
Epoch 14 Step 451 Train Loss: 0.2460
Epoch 14 Step 501 Train Loss: 0.2462
Epoch 14 Step 551 Train Loss: 0.2567
Epoch 14 Step 601 Train Loss: 0.2468
Epoch 14 Step 651 Train Loss: 0.2381
Epoch 14 Step 701 Train Loss: 0.2343
Epoch 14 Step 751 Train Loss: 0.2286
Epoch 14 Step 801 Train Loss: 0.2539
Epoch 14 Step 851 Train Loss: 0.2275
Epoch 14 Step 901 Train Loss: 0.2444
Epoch 14 Step 951 Train Loss: 0.2374
Epoch 14 Step 1001 Train Loss: 0.2372
Epoch 14 Step 1051 Train Loss: 0.2396
Epoch 14 Step 1101 Train Loss: 0.2683
Epoch 14 Step 1151 Train Loss: 0.2297
Epoch 14 Step 1201 Train Loss: 0.2377
Epoch 14 Step 1251 Train Loss: 0.2379
Epoch 14 Step 1301 Train Loss: 0.2600
Epoch 14 Step 1351 Train Loss: 0.2286
Epoch 14 Step 1401 Train Loss: 0.2342
Epoch 14 Step 1451 Train Loss: 0.2354
Epoch 14 Step 1501 Train Loss: 0.2797
Epoch 14 Step 1551 Train Loss: 0.2468
Epoch 14 Step 1601 Train Loss: 0.2552
Epoch 14 Step 1651 Train Loss: 0.2556
Epoch 14 Step 1701 Train Loss: 0.2331
Epoch 14 Step 1751 Train Loss: 0.2323
Epoch 14 Step 1801 Train Loss: 0.2498
Epoch 14: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Epoch 15 Step 1 Train Loss: 0.2501
Epoch 15 Step 51 Train Loss: 0.2493
Epoch 15 Step 101 Train Loss: 0.2430
Epoch 15 Step 151 Train Loss: 0.2337
Epoch 15 Step 201 Train Loss: 0.2417
Epoch 15 Step 251 Train Loss: 0.2434
Epoch 15 Step 301 Train Loss: 0.2425
Epoch 15 Step 351 Train Loss: 0.2436
Epoch 15 Step 401 Train Loss: 0.2381
Epoch 15 Step 451 Train Loss: 0.2330
Epoch 15 Step 501 Train Loss: 0.2288
Epoch 15 Step 551 Train Loss: 0.2475
Epoch 15 Step 601 Train Loss: 0.2304
Epoch 15 Step 651 Train Loss: 0.2415
Epoch 15 Step 701 Train Loss: 0.2545
Epoch 15 Step 751 Train Loss: 0.2466
Epoch 15 Step 801 Train Loss: 0.2445
Epoch 15 Step 851 Train Loss: 0.2443
Epoch 15 Step 901 Train Loss: 0.2492
Epoch 15 Step 951 Train Loss: 0.2257
Epoch 15 Step 1001 Train Loss: 0.2744
Epoch 15 Step 1051 Train Loss: 0.2246
Epoch 15 Step 1101 Train Loss: 0.2613
Epoch 15 Step 1151 Train Loss: 0.2290
Epoch 15 Step 1201 Train Loss: 0.2426
Epoch 15 Step 1251 Train Loss: 0.2407
Epoch 15 Step 1301 Train Loss: 0.2561
Epoch 15 Step 1351 Train Loss: 0.2629
Epoch 15 Step 1401 Train Loss: 0.2443
Epoch 15 Step 1451 Train Loss: 0.2329
Epoch 15 Step 1501 Train Loss: 0.2258
Epoch 15 Step 1551 Train Loss: 0.2333
Epoch 15 Step 1601 Train Loss: 0.2451
Epoch 15 Step 1651 Train Loss: 0.2508
Epoch 15 Step 1701 Train Loss: 0.2344
Epoch 15 Step 1751 Train Loss: 0.2356
Epoch 15 Step 1801 Train Loss: 0.2407
Epoch 15: Train Overall MSE: 0.0004 Validation Overall MSE: 0.0003. 
Train Top 20 DE MSE: 0.0058 Validation Top 20 DE MSE: 0.0065. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0040
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.00030547183
test_unseen_single_pearson: 0.9934126287150846
test_unseen_single_mse_de: 0.0039537726
test_unseen_single_pearson_de: 0.8095909044641687
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.1536244048699964
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3656862745098039
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9264705882352939
test_unseen_single_mse_top20_de_non_dropout: 0.006667226554638481
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.031 MB uploadedwandb: | 0.026 MB of 0.031 MB uploadedwandb: / 0.026 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ
wandb:                                             train_de_pearson ‚ñÅ‚ñÇ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÜ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:                                               val_de_pearson ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00395
wandb:                                              test_de_pearson 0.80959
wandb:               test_frac_opposite_direction_top20_non_dropout 0.36569
wandb:                          test_frac_sigma_below_1_non_dropout 0.92647
wandb:                                                     test_mse 0.00031
wandb:                                test_mse_top20_de_non_dropout 0.00667
wandb:                                                 test_pearson 0.99341
wandb:                                           test_pearson_delta 0.15362
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.36569
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.92647
wandb:                                       test_unseen_single_mse 0.00031
wandb:                                    test_unseen_single_mse_de 0.00395
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00667
wandb:                                   test_unseen_single_pearson 0.99341
wandb:                                test_unseen_single_pearson_de 0.80959
wandb:                             test_unseen_single_pearson_delta 0.15362
wandb:                                                 train_de_mse 0.00577
wandb:                                             train_de_pearson 0.7798
wandb:                                                    train_mse 0.00038
wandb:                                                train_pearson 0.99192
wandb:                                                training_loss 0.22079
wandb:                                                   val_de_mse 0.00649
wandb:                                               val_de_pearson 0.83164
wandb:                                                      val_mse 0.00029
wandb:                                                  val_pearson 0.99377
wandb: 
wandb: üöÄ View run scbert_XuCao2023_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/i0boqxke
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_115057-i0boqxke/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_124354-w6ceez1w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_ShifrutMarson2018_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/w6ceez1w
wandb: WARNING Serializing object of type ndarray that is 8012928 bytes
  0%|                                                                                       | 0/3286 [00:00<?, ?it/s]  0%|‚ñè                                                                              | 8/3286 [00:00<00:50, 64.91it/s]  0%|‚ñç                                                                             | 16/3286 [00:00<00:45, 72.10it/s]  1%|‚ñå                                                                             | 24/3286 [00:00<00:43, 75.04it/s]  1%|‚ñä                                                                             | 35/3286 [00:00<00:36, 88.26it/s]  1%|‚ñà                                                                             | 45/3286 [00:00<00:36, 89.29it/s]  2%|‚ñà‚ñé                                                                            | 55/3286 [00:00<00:35, 89.88it/s]  2%|‚ñà‚ñå                                                                            | 65/3286 [00:00<00:35, 89.50it/s]  2%|‚ñà‚ñä                                                                            | 75/3286 [00:00<00:35, 89.73it/s]  3%|‚ñà‚ñà                                                                            | 85/3286 [00:00<00:35, 90.29it/s]  3%|‚ñà‚ñà‚ñé                                                                           | 95/3286 [00:01<00:35, 88.89it/s]  3%|‚ñà‚ñà‚ñç                                                                          | 104/3286 [00:01<00:35, 88.85it/s]  3%|‚ñà‚ñà‚ñã                                                                          | 114/3286 [00:01<00:35, 89.33it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 123/3286 [00:01<00:35, 89.36it/s]  4%|‚ñà‚ñà‚ñà                                                                          | 133/3286 [00:01<00:36, 87.37it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 144/3286 [00:01<00:34, 91.00it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 154/3286 [00:01<00:34, 90.89it/s]  5%|‚ñà‚ñà‚ñà‚ñä                                                                         | 164/3286 [00:01<00:34, 90.02it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 174/3286 [00:01<00:35, 88.77it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 184/3286 [00:02<00:35, 86.82it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 195/3286 [00:02<00:34, 90.40it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                        | 205/3286 [00:02<00:34, 90.40it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 215/3286 [00:02<00:34, 90.15it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 225/3286 [00:02<00:33, 90.56it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 235/3286 [00:02<00:33, 90.78it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 245/3286 [00:02<00:34, 89.43it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 254/3286 [00:02<00:34, 86.77it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 265/3286 [00:03<00:34, 87.98it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 275/3286 [00:03<00:33, 91.12it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 285/3286 [00:03<00:32, 91.20it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 295/3286 [00:03<00:34, 87.89it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 305/3286 [00:03<00:33, 88.64it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 314/3286 [00:03<00:33, 88.58it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 324/3286 [00:03<00:32, 90.67it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 334/3286 [00:03<00:33, 87.76it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 344/3286 [00:03<00:32, 90.75it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 354/3286 [00:03<00:32, 90.69it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 364/3286 [00:04<00:32, 90.75it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 374/3286 [00:04<00:32, 90.65it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 384/3286 [00:04<00:31, 90.91it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 394/3286 [00:04<00:33, 87.26it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 404/3286 [00:04<00:31, 90.16it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 414/3286 [00:04<00:31, 90.07it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 424/3286 [00:04<00:32, 87.37it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 435/3286 [00:04<00:32, 88.94it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 446/3286 [00:05<00:30, 91.71it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 456/3286 [00:05<00:30, 91.90it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 466/3286 [00:05<00:31, 88.20it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 476/3286 [00:05<00:31, 90.55it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 486/3286 [00:05<00:31, 90.18it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 496/3286 [00:05<00:31, 87.43it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 507/3286 [00:05<00:30, 90.99it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                 | 517/3286 [00:05<00:30, 90.99it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 527/3286 [00:05<00:30, 90.66it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 537/3286 [00:06<00:31, 88.03it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 547/3286 [00:06<00:30, 90.36it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 557/3286 [00:06<00:31, 87.83it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 567/3286 [00:06<00:30, 90.54it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 577/3286 [00:06<00:29, 90.69it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 587/3286 [00:06<00:30, 88.28it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 597/3286 [00:06<00:30, 88.90it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 608/3286 [00:06<00:28, 92.39it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 618/3286 [00:06<00:30, 88.68it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 628/3286 [00:07<00:29, 91.12it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 638/3286 [00:07<00:29, 91.20it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 648/3286 [00:07<00:30, 87.76it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 659/3286 [00:07<00:28, 91.14it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 669/3286 [00:07<00:28, 90.98it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 679/3286 [00:07<00:28, 90.87it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 689/3286 [00:07<00:28, 90.51it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 699/3286 [00:07<00:28, 89.30it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                            | 709/3286 [00:07<00:28, 89.88it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                            | 718/3286 [00:08<00:28, 89.67it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 728/3286 [00:08<00:29, 87.82it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 739/3286 [00:08<00:28, 90.94it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 749/3286 [00:08<00:27, 90.75it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 759/3286 [00:08<00:27, 90.48it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 769/3286 [00:08<00:28, 89.59it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 778/3286 [00:08<00:28, 89.02it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                          | 788/3286 [00:08<00:27, 89.80it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 797/3286 [00:08<00:28, 87.18it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 808/3286 [00:09<00:27, 90.89it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 818/3286 [00:09<00:27, 90.90it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 828/3286 [00:09<00:27, 90.71it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 838/3286 [00:09<00:27, 90.37it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 848/3286 [00:09<00:28, 86.59it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 858/3286 [00:09<00:27, 87.99it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 868/3286 [00:09<00:26, 91.14it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 878/3286 [00:09<00:26, 90.89it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 888/3286 [00:09<00:26, 90.91it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 898/3286 [00:10<00:26, 90.08it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 908/3286 [00:10<00:26, 90.24it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 918/3286 [00:10<00:27, 87.08it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 928/3286 [00:10<00:26, 90.28it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 938/3286 [00:10<00:26, 87.31it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 947/3286 [00:10<00:28, 81.25it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 956/3286 [00:10<00:29, 80.33it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 965/3286 [00:10<00:28, 81.69it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 974/3286 [00:10<00:28, 80.49it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 983/3286 [00:11<00:29, 79.02it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 991/3286 [00:11<00:29, 78.66it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 999/3286 [00:11<00:29, 77.87it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1007/3286 [00:11<00:29, 77.43it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1015/3286 [00:11<00:29, 77.19it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1023/3286 [00:11<00:30, 74.19it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1031/3286 [00:11<00:30, 75.09it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1040/3286 [00:11<00:29, 76.21it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1049/3286 [00:11<00:28, 79.27it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1057/3286 [00:12<00:28, 78.47it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1065/3286 [00:12<00:28, 78.52it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1073/3286 [00:12<00:28, 78.19it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1081/3286 [00:12<00:29, 75.06it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1090/3286 [00:12<00:27, 78.72it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1098/3286 [00:12<00:27, 78.78it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1106/3286 [00:12<00:27, 78.82it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1114/3286 [00:12<00:27, 78.85it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1122/3286 [00:12<00:27, 78.86it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1130/3286 [00:12<00:27, 78.70it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1138/3286 [00:13<00:27, 78.52it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1146/3286 [00:13<00:27, 78.53it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1154/3286 [00:13<00:27, 78.38it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 1162/3286 [00:13<00:27, 78.05it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1170/3286 [00:13<00:27, 75.66it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1179/3286 [00:13<00:26, 79.45it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 1187/3286 [00:13<00:26, 79.03it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1195/3286 [00:13<00:26, 78.40it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 1203/3286 [00:13<00:26, 78.24it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1212/3286 [00:14<00:25, 79.78it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1221/3286 [00:14<00:26, 78.85it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1231/3286 [00:14<00:24, 84.01it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1240/3286 [00:14<00:24, 85.05it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 1249/3286 [00:14<00:23, 85.96it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1258/3286 [00:14<00:36, 55.97it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1269/3286 [00:14<00:30, 65.95it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1277/3286 [00:14<00:29, 69.03it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1287/3286 [00:15<00:27, 74.02it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 1296/3286 [00:15<00:26, 75.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1306/3286 [00:15<00:24, 81.18it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1315/3286 [00:15<00:23, 83.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1325/3286 [00:15<00:22, 85.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1334/3286 [00:15<00:22, 86.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 1343/3286 [00:15<00:22, 86.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1353/3286 [00:15<00:21, 88.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1362/3286 [00:15<00:21, 88.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1371/3286 [00:16<00:22, 86.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1381/3286 [00:16<00:21, 87.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 1392/3286 [00:16<00:20, 91.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 1402/3286 [00:16<00:20, 91.87it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 1412/3286 [00:16<00:21, 88.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 1422/3286 [00:16<00:20, 90.31it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 1432/3286 [00:16<00:19, 92.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 1442/3286 [00:16<00:20, 89.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 1453/3286 [00:16<00:20, 90.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 1463/3286 [00:17<00:19, 91.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 1474/3286 [00:17<00:19, 92.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 1485/3286 [00:17<00:19, 94.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 1495/3286 [00:17<00:18, 95.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 1505/3286 [00:17<00:22, 78.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 1514/3286 [00:17<00:22, 78.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 1523/3286 [00:17<00:23, 75.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 1533/3286 [00:17<00:22, 79.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 1543/3286 [00:17<00:20, 83.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 1552/3286 [00:18<00:20, 83.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1561/3286 [00:18<00:20, 85.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 1572/3286 [00:18<00:19, 89.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 1582/3286 [00:18<00:19, 89.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 1591/3286 [00:18<00:19, 86.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 1601/3286 [00:18<00:20, 83.50it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 1610/3286 [00:18<00:20, 82.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 1619/3286 [00:18<00:20, 81.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 1628/3286 [00:19<00:21, 78.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 1637/3286 [00:19<00:20, 79.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 1645/3286 [00:19<00:21, 77.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 1655/3286 [00:19<00:19, 83.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 1664/3286 [00:19<00:19, 82.35it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 1673/3286 [00:19<00:19, 82.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 1682/3286 [00:19<00:19, 81.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 1691/3286 [00:19<00:20, 78.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 1701/3286 [00:19<00:19, 81.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 1710/3286 [00:20<00:19, 81.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 1719/3286 [00:20<00:19, 81.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 1728/3286 [00:20<00:19, 81.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1737/3286 [00:20<00:19, 80.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 1746/3286 [00:20<00:19, 81.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 1755/3286 [00:20<00:18, 81.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 1764/3286 [00:20<00:18, 81.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 1773/3286 [00:20<00:18, 81.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 1782/3286 [00:20<00:18, 81.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 1791/3286 [00:21<00:18, 81.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 1800/3286 [00:21<00:18, 81.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 1809/3286 [00:21<00:18, 81.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 1818/3286 [00:21<00:18, 78.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 1827/3286 [00:21<00:17, 81.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 1836/3286 [00:21<00:17, 81.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 1845/3286 [00:21<00:18, 79.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 1854/3286 [00:21<00:17, 82.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 1863/3286 [00:21<00:17, 81.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 1872/3286 [00:22<00:17, 79.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 1883/3286 [00:22<00:16, 85.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 1893/3286 [00:22<00:15, 88.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 1902/3286 [00:22<00:16, 82.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 1912/3286 [00:22<00:16, 82.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 1922/3286 [00:22<00:15, 86.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 1933/3286 [00:22<00:14, 91.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 1943/3286 [00:22<00:14, 92.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 1953/3286 [00:22<00:14, 93.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 1963/3286 [00:23<00:14, 91.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 1973/3286 [00:23<00:14, 92.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 1984/3286 [00:23<00:13, 95.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 1994/3286 [00:23<00:13, 95.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2004/3286 [00:23<00:13, 94.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 2014/3286 [00:23<00:13, 91.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2024/3286 [00:23<00:13, 90.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2035/3286 [00:23<00:13, 93.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 2045/3286 [00:23<00:13, 91.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2056/3286 [00:24<00:12, 94.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2066/3286 [00:24<00:13, 92.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 2077/3286 [00:24<00:12, 93.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 2087/3286 [00:24<00:12, 93.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 2098/3286 [00:24<00:12, 94.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 2108/3286 [00:24<00:12, 95.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 2118/3286 [00:24<00:12, 92.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 2128/3286 [00:24<00:14, 82.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 2143/3286 [00:24<00:11, 98.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 2154/3286 [00:25<00:11, 96.85it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 2164/3286 [00:25<00:11, 95.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 2174/3286 [00:25<00:11, 95.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 2185/3286 [00:25<00:11, 97.56it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 2196/3286 [00:25<00:11, 95.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2206/3286 [00:25<00:11, 94.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2217/3286 [00:25<00:11, 96.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 2228/3286 [00:25<00:10, 98.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 2238/3286 [00:25<00:11, 94.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 2249/3286 [00:26<00:10, 97.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 2259/3286 [00:26<00:11, 93.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 2269/3286 [00:26<00:10, 94.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 2280/3286 [00:26<00:10, 93.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 2290/3286 [00:26<00:10, 94.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 2301/3286 [00:26<00:10, 95.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 2312/3286 [00:26<00:10, 94.45it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 2323/3286 [00:26<00:10, 95.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 2333/3286 [00:26<00:10, 94.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 2343/3286 [00:27<00:10, 90.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 2355/3286 [00:27<00:09, 96.31it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 2365/3286 [00:27<00:09, 96.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 2376/3286 [00:27<00:09, 96.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 2387/3286 [00:27<00:09, 98.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 2397/3286 [00:27<00:09, 95.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2408/3286 [00:27<00:09, 92.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 2420/3286 [00:27<00:08, 96.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 2430/3286 [00:27<00:08, 96.19it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 2440/3286 [00:28<00:08, 95.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 2450/3286 [00:28<00:08, 96.39it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 2461/3286 [00:28<00:08, 98.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 2472/3286 [00:28<00:08, 96.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 2483/3286 [00:28<00:08, 99.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 2493/3286 [00:28<00:08, 96.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 2503/3286 [00:28<00:08, 96.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 2514/3286 [00:28<00:07, 97.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 2525/3286 [00:28<00:07, 97.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 2536/3286 [00:29<00:07, 99.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 2546/3286 [00:29<00:07, 98.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2557/3286 [00:29<00:07, 100.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 2568/3286 [00:29<00:07, 97.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2578/3286 [00:29<00:07, 88.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2588/3286 [00:29<00:08, 79.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 2597/3286 [00:29<00:09, 72.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2606/3286 [00:29<00:08, 76.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2614/3286 [00:30<00:08, 75.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2624/3286 [00:30<00:08, 79.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2633/3286 [00:30<00:08, 79.63it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 2642/3286 [00:30<00:08, 78.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2653/3286 [00:30<00:07, 84.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2663/3286 [00:30<00:07, 84.86it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2674/3286 [00:30<00:06, 87.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2684/3286 [00:30<00:06, 90.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 2694/3286 [00:30<00:06, 89.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2704/3286 [00:31<00:06, 91.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2714/3286 [00:31<00:06, 87.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2726/3286 [00:31<00:05, 94.12it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2736/3286 [00:31<00:05, 92.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 2746/3286 [00:31<00:05, 94.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2756/3286 [00:31<00:05, 92.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2766/3286 [00:31<00:05, 91.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 2776/3286 [00:31<00:05, 93.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 2786/3286 [00:32<00:18, 27.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 2793/3286 [00:33<00:17, 28.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2811/3286 [00:33<00:15, 29.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 2821/3286 [00:33<00:13, 35.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 2833/3286 [00:33<00:11, 39.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 2929/3286 [00:34<00:02, 156.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 2960/3286 [00:34<00:02, 123.22it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2984/3286 [00:34<00:02, 107.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 3003/3286 [00:34<00:02, 100.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3019/3286 [00:35<00:02, 96.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 3033/3286 [00:35<00:02, 90.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 3045/3286 [00:35<00:02, 89.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 3056/3286 [00:35<00:02, 85.00it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3066/3286 [00:35<00:02, 84.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3076/3286 [00:35<00:02, 83.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3085/3286 [00:36<00:02, 83.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3094/3286 [00:36<00:02, 79.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3103/3286 [00:36<00:02, 80.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3112/3286 [00:36<00:02, 81.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3121/3286 [00:36<00:02, 80.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3130/3286 [00:36<00:02, 77.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3139/3286 [00:36<00:01, 79.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3148/3286 [00:36<00:01, 78.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3156/3286 [00:36<00:01, 74.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3166/3286 [00:37<00:01, 80.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3175/3286 [00:37<00:01, 82.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3184/3286 [00:37<00:01, 80.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3194/3286 [00:37<00:01, 83.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3203/3286 [00:37<00:00, 83.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3212/3286 [00:37<00:00, 81.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3223/3286 [00:37<00:00, 86.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3233/3286 [00:37<00:00, 89.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3243/3286 [00:37<00:00, 88.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3253/3286 [00:38<00:00, 89.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3264/3286 [00:38<00:00, 91.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3275/3286 [00:38<00:00, 94.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3285/3286 [00:38<00:00, 94.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3286/3286 [00:38<00:00, 85.58it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.3649
Epoch 1 Step 51 Train Loss: 0.2620
Epoch 1 Step 101 Train Loss: 0.2833
Epoch 1 Step 151 Train Loss: 0.2841
Epoch 1 Step 201 Train Loss: 0.3297
Epoch 1 Step 251 Train Loss: 0.2400
Epoch 1 Step 301 Train Loss: 0.3325
Epoch 1 Step 351 Train Loss: 0.1691
Epoch 1 Step 401 Train Loss: 0.2647
Epoch 1 Step 451 Train Loss: 0.2644
Epoch 1 Step 501 Train Loss: 0.2746
Epoch 1 Step 551 Train Loss: 0.2550
Epoch 1 Step 601 Train Loss: 0.1611
Epoch 1 Step 651 Train Loss: 0.2572
Epoch 1 Step 701 Train Loss: 0.3487
Epoch 1 Step 751 Train Loss: 0.2747
Epoch 1 Step 801 Train Loss: 0.2206
Epoch 1 Step 851 Train Loss: 0.2408
Epoch 1 Step 901 Train Loss: 0.2716
Epoch 1 Step 951 Train Loss: 0.3287
Epoch 1 Step 1001 Train Loss: 0.2606
Epoch 1 Step 1051 Train Loss: 0.3088
Epoch 1 Step 1101 Train Loss: 0.2807
Epoch 1 Step 1151 Train Loss: 0.3348
Epoch 1 Step 1201 Train Loss: 0.3433
Epoch 1 Step 1251 Train Loss: 0.2577
Epoch 1 Step 1301 Train Loss: 0.2737
Epoch 1 Step 1351 Train Loss: 0.2643
Epoch 1 Step 1401 Train Loss: 0.2610
Epoch 1: Train Overall MSE: 0.0026 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0141 Validation Top 20 DE MSE: 0.0107. 
Epoch 2 Step 1 Train Loss: 0.2755
Epoch 2 Step 51 Train Loss: 0.2425
Epoch 2 Step 101 Train Loss: 0.2266
Epoch 2 Step 151 Train Loss: 0.2953
Epoch 2 Step 201 Train Loss: 0.2614
Epoch 2 Step 251 Train Loss: 0.2471
Epoch 2 Step 301 Train Loss: 0.2501
Epoch 2 Step 351 Train Loss: 0.1710
Epoch 2 Step 401 Train Loss: 0.2933
Epoch 2 Step 451 Train Loss: 0.2302
Epoch 2 Step 501 Train Loss: 0.2444
Epoch 2 Step 551 Train Loss: 0.3656
Epoch 2 Step 601 Train Loss: 0.2321
Epoch 2 Step 651 Train Loss: 0.1996
Epoch 2 Step 701 Train Loss: 0.3213
Epoch 2 Step 751 Train Loss: 0.3335
Epoch 2 Step 801 Train Loss: 0.2368
Epoch 2 Step 851 Train Loss: 0.1752
Epoch 2 Step 901 Train Loss: 0.3089
Epoch 2 Step 951 Train Loss: 0.2928
Epoch 2 Step 1001 Train Loss: 0.1853
Epoch 2 Step 1051 Train Loss: 0.2650
Epoch 2 Step 1101 Train Loss: 0.2489
Epoch 2 Step 1151 Train Loss: 0.2771
Epoch 2 Step 1201 Train Loss: 0.2227
Epoch 2 Step 1251 Train Loss: 0.2221
Epoch 2 Step 1301 Train Loss: 0.2303
Epoch 2 Step 1351 Train Loss: 0.2991
Epoch 2 Step 1401 Train Loss: 0.2654
Epoch 2: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0087. 
Epoch 3 Step 1 Train Loss: 0.1943
Epoch 3 Step 51 Train Loss: 0.1766
Epoch 3 Step 101 Train Loss: 0.2678
Epoch 3 Step 151 Train Loss: 0.2494
Epoch 3 Step 201 Train Loss: 0.2430
Epoch 3 Step 251 Train Loss: 0.1922
Epoch 3 Step 301 Train Loss: 0.2602
Epoch 3 Step 351 Train Loss: 0.2984
Epoch 3 Step 401 Train Loss: 0.1289
Epoch 3 Step 451 Train Loss: 0.2952
Epoch 3 Step 501 Train Loss: 0.2306
Epoch 3 Step 551 Train Loss: 0.2354
Epoch 3 Step 601 Train Loss: 0.2679
Epoch 3 Step 651 Train Loss: 0.2329
Epoch 3 Step 701 Train Loss: 0.2119
Epoch 3 Step 751 Train Loss: 0.2603
Epoch 3 Step 801 Train Loss: 0.2406
Epoch 3 Step 851 Train Loss: 0.2131
Epoch 3 Step 901 Train Loss: 0.2904
Epoch 3 Step 951 Train Loss: 0.1868
Epoch 3 Step 1001 Train Loss: 0.2153
Epoch 3 Step 1051 Train Loss: 0.2203
Epoch 3 Step 1101 Train Loss: 0.2982
Epoch 3 Step 1151 Train Loss: 0.2651
Epoch 3 Step 1201 Train Loss: 0.1547
Epoch 3 Step 1251 Train Loss: 0.2479
Epoch 3 Step 1301 Train Loss: 0.2296
Epoch 3 Step 1351 Train Loss: 0.2868
Epoch 3 Step 1401 Train Loss: 0.2668
Epoch 3: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0069. 
Epoch 4 Step 1 Train Loss: 0.2913
Epoch 4 Step 51 Train Loss: 0.2865
Epoch 4 Step 101 Train Loss: 0.2550
Epoch 4 Step 151 Train Loss: 0.2639
Epoch 4 Step 201 Train Loss: 0.2047
Epoch 4 Step 251 Train Loss: 0.2277
Epoch 4 Step 301 Train Loss: 0.2958
Epoch 4 Step 351 Train Loss: 0.2292
Epoch 4 Step 401 Train Loss: 0.2452
Epoch 4 Step 451 Train Loss: 0.2425
Epoch 4 Step 501 Train Loss: 0.2540
Epoch 4 Step 551 Train Loss: 0.2122
Epoch 4 Step 601 Train Loss: 0.2347
Epoch 4 Step 651 Train Loss: 0.2961
Epoch 4 Step 701 Train Loss: 0.2973
Epoch 4 Step 751 Train Loss: 0.2395
Epoch 4 Step 801 Train Loss: 0.2396
Epoch 4 Step 851 Train Loss: 0.2304
Epoch 4 Step 901 Train Loss: 0.3170
Epoch 4 Step 951 Train Loss: 0.2558
Epoch 4 Step 1001 Train Loss: 0.2406
Epoch 4 Step 1051 Train Loss: 0.2642
Epoch 4 Step 1101 Train Loss: 0.2891
Epoch 4 Step 1151 Train Loss: 0.2539
Epoch 4 Step 1201 Train Loss: 0.2718
Epoch 4 Step 1251 Train Loss: 0.2936
Epoch 4 Step 1301 Train Loss: 0.2697
Epoch 4 Step 1351 Train Loss: 0.2616
Epoch 4 Step 1401 Train Loss: 0.2643
Epoch 4: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.0077. 
Epoch 5 Step 1 Train Loss: 0.2051
Epoch 5 Step 51 Train Loss: 0.2076
Epoch 5 Step 101 Train Loss: 0.2477
Epoch 5 Step 151 Train Loss: 0.2317
Epoch 5 Step 201 Train Loss: 0.3140
Epoch 5 Step 251 Train Loss: 0.3058
Epoch 5 Step 301 Train Loss: 0.2288
Epoch 5 Step 351 Train Loss: 0.3059
Epoch 5 Step 401 Train Loss: 0.2064
Epoch 5 Step 451 Train Loss: 0.2239
Epoch 5 Step 501 Train Loss: 0.2770
Epoch 5 Step 551 Train Loss: 0.2976
Epoch 5 Step 601 Train Loss: 0.2590
Epoch 5 Step 651 Train Loss: 0.2177
Epoch 5 Step 701 Train Loss: 0.3521
Epoch 5 Step 751 Train Loss: 0.2094
Epoch 5 Step 801 Train Loss: 0.2792
Epoch 5 Step 851 Train Loss: 0.2271
Epoch 5 Step 901 Train Loss: 0.2051
Epoch 5 Step 951 Train Loss: 0.3276
Epoch 5 Step 1001 Train Loss: 0.3025
Epoch 5 Step 1051 Train Loss: 0.2826
Epoch 5 Step 1101 Train Loss: 0.3680
Epoch 5 Step 1151 Train Loss: 0.2651
Epoch 5 Step 1201 Train Loss: 0.2161
Epoch 5 Step 1251 Train Loss: 0.2359
Epoch 5 Step 1301 Train Loss: 0.2355
Epoch 5 Step 1351 Train Loss: 0.2632
Epoch 5 Step 1401 Train Loss: 0.2990
Epoch 5: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.0106. 
Epoch 6 Step 1 Train Loss: 0.2288
Epoch 6 Step 51 Train Loss: 0.4159
Epoch 6 Step 101 Train Loss: 0.2476
Epoch 6 Step 151 Train Loss: 0.1748
Epoch 6 Step 201 Train Loss: 0.2705
Epoch 6 Step 251 Train Loss: 0.2863
Epoch 6 Step 301 Train Loss: 0.2241
Epoch 6 Step 351 Train Loss: 0.2044
Epoch 6 Step 401 Train Loss: 0.3523
Epoch 6 Step 451 Train Loss: 0.2833
Epoch 6 Step 501 Train Loss: 0.2997
Epoch 6 Step 551 Train Loss: 0.2037
Epoch 6 Step 601 Train Loss: 0.2293
Epoch 6 Step 651 Train Loss: 0.3057
Epoch 6 Step 701 Train Loss: 0.2465
Epoch 6 Step 751 Train Loss: 0.2269
Epoch 6 Step 801 Train Loss: 0.2998
Epoch 6 Step 851 Train Loss: 0.2442
Epoch 6 Step 901 Train Loss: 0.2126
Epoch 6 Step 951 Train Loss: 0.2354
Epoch 6 Step 1001 Train Loss: 0.3272
Epoch 6 Step 1051 Train Loss: 0.3098
Epoch 6 Step 1101 Train Loss: 0.2522
Epoch 6 Step 1151 Train Loss: 0.2290
Epoch 6 Step 1201 Train Loss: 0.2445
Epoch 6 Step 1251 Train Loss: 0.2002
Epoch 6 Step 1301 Train Loss: 0.2634
Epoch 6 Step 1351 Train Loss: 0.2553
Epoch 6 Step 1401 Train Loss: 0.3346
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0113 Validation Top 20 DE MSE: 0.0081. 
Epoch 7 Step 1 Train Loss: 0.3919
Epoch 7 Step 51 Train Loss: 0.2131
Epoch 7 Step 101 Train Loss: 0.2554
Epoch 7 Step 151 Train Loss: 0.2569
Epoch 7 Step 201 Train Loss: 0.2560
Epoch 7 Step 251 Train Loss: 0.2567
Epoch 7 Step 301 Train Loss: 0.1863
Epoch 7 Step 351 Train Loss: 0.2783
Epoch 7 Step 401 Train Loss: 0.3028
Epoch 7 Step 451 Train Loss: 0.2833
Epoch 7 Step 501 Train Loss: 0.2158
Epoch 7 Step 551 Train Loss: 0.2449
Epoch 7 Step 601 Train Loss: 0.2995
Epoch 7 Step 651 Train Loss: 0.2370
Epoch 7 Step 701 Train Loss: 0.2329
Epoch 7 Step 751 Train Loss: 0.2764
Epoch 7 Step 801 Train Loss: 0.2146
Epoch 7 Step 851 Train Loss: 0.2687
Epoch 7 Step 901 Train Loss: 0.3261
Epoch 7 Step 951 Train Loss: 0.2892
Epoch 7 Step 1001 Train Loss: 0.2204
Epoch 7 Step 1051 Train Loss: 0.2827
Epoch 7 Step 1101 Train Loss: 0.3139
Epoch 7 Step 1151 Train Loss: 0.2607
Epoch 7 Step 1201 Train Loss: 0.2770
Epoch 7 Step 1251 Train Loss: 0.2277
Epoch 7 Step 1301 Train Loss: 0.2491
Epoch 7 Step 1351 Train Loss: 0.2641
Epoch 7 Step 1401 Train Loss: 0.2300
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0078. 
Epoch 8 Step 1 Train Loss: 0.2676
Epoch 8 Step 51 Train Loss: 0.2534
Epoch 8 Step 101 Train Loss: 0.3202
Epoch 8 Step 151 Train Loss: 0.2774
Epoch 8 Step 201 Train Loss: 0.2357
Epoch 8 Step 251 Train Loss: 0.2008
Epoch 8 Step 301 Train Loss: 0.2668
Epoch 8 Step 351 Train Loss: 0.2321
Epoch 8 Step 401 Train Loss: 0.2226
Epoch 8 Step 451 Train Loss: 0.2877
Epoch 8 Step 501 Train Loss: 0.2972
Epoch 8 Step 551 Train Loss: 0.2579
Epoch 8 Step 601 Train Loss: 0.2941
Epoch 8 Step 651 Train Loss: 0.2353
Epoch 8 Step 701 Train Loss: 0.3333
Epoch 8 Step 751 Train Loss: 0.2188
Epoch 8 Step 801 Train Loss: 0.2317
Epoch 8 Step 851 Train Loss: 0.2723
Epoch 8 Step 901 Train Loss: 0.4038
Epoch 8 Step 951 Train Loss: 0.2817
Epoch 8 Step 1001 Train Loss: 0.2047
Epoch 8 Step 1051 Train Loss: 0.2884
Epoch 8 Step 1101 Train Loss: 0.2646
Epoch 8 Step 1151 Train Loss: 0.2318
Epoch 8 Step 1201 Train Loss: 0.2759
Epoch 8 Step 1251 Train Loss: 0.2378
Epoch 8 Step 1301 Train Loss: 0.2942
Epoch 8 Step 1351 Train Loss: 0.2572
Epoch 8 Step 1401 Train Loss: 0.2511
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0124 Validation Top 20 DE MSE: 0.0082. 
Epoch 9 Step 1 Train Loss: 0.2786
Epoch 9 Step 51 Train Loss: 0.2350
Epoch 9 Step 101 Train Loss: 0.3155
Epoch 9 Step 151 Train Loss: 0.2379
Epoch 9 Step 201 Train Loss: 0.1966
Epoch 9 Step 251 Train Loss: 0.2202
Epoch 9 Step 301 Train Loss: 0.2950
Epoch 9 Step 351 Train Loss: 0.2373
Epoch 9 Step 401 Train Loss: 0.2440
Epoch 9 Step 451 Train Loss: 0.2952
Epoch 9 Step 501 Train Loss: 0.2707
Epoch 9 Step 551 Train Loss: 0.2904
Epoch 9 Step 601 Train Loss: 0.2340
Epoch 9 Step 651 Train Loss: 0.2012
Epoch 9 Step 701 Train Loss: 0.2556
Epoch 9 Step 751 Train Loss: 0.2202
Epoch 9 Step 801 Train Loss: 0.2705
Epoch 9 Step 851 Train Loss: 0.2319
Epoch 9 Step 901 Train Loss: 0.2757
Epoch 9 Step 951 Train Loss: 0.3130
Epoch 9 Step 1001 Train Loss: 0.2168
Epoch 9 Step 1051 Train Loss: 0.2707
Epoch 9 Step 1101 Train Loss: 0.2312
Epoch 9 Step 1151 Train Loss: 0.2024
Epoch 9 Step 1201 Train Loss: 0.2656
Epoch 9 Step 1251 Train Loss: 0.2805
Epoch 9 Step 1301 Train Loss: 0.2357
Epoch 9 Step 1351 Train Loss: 0.2560
Epoch 9 Step 1401 Train Loss: 0.2661
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0076. 
Epoch 10 Step 1 Train Loss: 0.3036
Epoch 10 Step 51 Train Loss: 0.2292
Epoch 10 Step 101 Train Loss: 0.2611
Epoch 10 Step 151 Train Loss: 0.2562
Epoch 10 Step 201 Train Loss: 0.2326
Epoch 10 Step 251 Train Loss: 0.3021
Epoch 10 Step 301 Train Loss: 0.2851
Epoch 10 Step 351 Train Loss: 0.2438
Epoch 10 Step 401 Train Loss: 0.2428
Epoch 10 Step 451 Train Loss: 0.2839
Epoch 10 Step 501 Train Loss: 0.3441
Epoch 10 Step 551 Train Loss: 0.2175
Epoch 10 Step 601 Train Loss: 0.2934
Epoch 10 Step 651 Train Loss: 0.2505
Epoch 10 Step 701 Train Loss: 0.1901
Epoch 10 Step 751 Train Loss: 0.2778
Epoch 10 Step 801 Train Loss: 0.3253
Epoch 10 Step 851 Train Loss: 0.2610
Epoch 10 Step 901 Train Loss: 0.2158
Epoch 10 Step 951 Train Loss: 0.2527
Epoch 10 Step 1001 Train Loss: 0.2175
Epoch 10 Step 1051 Train Loss: 0.2885
Epoch 10 Step 1101 Train Loss: 0.2716
Epoch 10 Step 1151 Train Loss: 0.2661
Epoch 10 Step 1201 Train Loss: 0.2604
Epoch 10 Step 1251 Train Loss: 0.3595
Epoch 10 Step 1301 Train Loss: 0.2633
Epoch 10 Step 1351 Train Loss: 0.2450
Epoch 10 Step 1401 Train Loss: 0.2327
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0074. 
Epoch 11 Step 1 Train Loss: 0.2979
Epoch 11 Step 51 Train Loss: 0.2304
Epoch 11 Step 101 Train Loss: 0.3001
Epoch 11 Step 151 Train Loss: 0.2143
Epoch 11 Step 201 Train Loss: 0.2960
Epoch 11 Step 251 Train Loss: 0.2667
Epoch 11 Step 301 Train Loss: 0.2992
Epoch 11 Step 351 Train Loss: 0.2480
Epoch 11 Step 401 Train Loss: 0.2665
Epoch 11 Step 451 Train Loss: 0.2459
Epoch 11 Step 501 Train Loss: 0.2537
Epoch 11 Step 551 Train Loss: 0.2096
Epoch 11 Step 601 Train Loss: 0.2442
Epoch 11 Step 651 Train Loss: 0.3080
Epoch 11 Step 701 Train Loss: 0.2949
Epoch 11 Step 751 Train Loss: 0.2126
Epoch 11 Step 801 Train Loss: 0.2789
Epoch 11 Step 851 Train Loss: 0.2510
Epoch 11 Step 901 Train Loss: 0.2863
Epoch 11 Step 951 Train Loss: 0.2817
Epoch 11 Step 1001 Train Loss: 0.2935
Epoch 11 Step 1051 Train Loss: 0.2318
Epoch 11 Step 1101 Train Loss: 0.3014
Epoch 11 Step 1151 Train Loss: 0.2633
Epoch 11 Step 1201 Train Loss: 0.3096
Epoch 11 Step 1251 Train Loss: 0.2457
Epoch 11 Step 1301 Train Loss: 0.2844
Epoch 11 Step 1351 Train Loss: 0.2717
Epoch 11 Step 1401 Train Loss: 0.2791
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0079. 
Epoch 12 Step 1 Train Loss: 0.2410
Epoch 12 Step 51 Train Loss: 0.2494
Epoch 12 Step 101 Train Loss: 0.3014
Epoch 12 Step 151 Train Loss: 0.2392
Epoch 12 Step 201 Train Loss: 0.2600
Epoch 12 Step 251 Train Loss: 0.2957
Epoch 12 Step 301 Train Loss: 0.2840
Epoch 12 Step 351 Train Loss: 0.3385
Epoch 12 Step 401 Train Loss: 0.2329
Epoch 12 Step 451 Train Loss: 0.3606
Epoch 12 Step 501 Train Loss: 0.2553
Epoch 12 Step 551 Train Loss: 0.2768
Epoch 12 Step 601 Train Loss: 0.4285
Epoch 12 Step 651 Train Loss: 0.2429
Epoch 12 Step 701 Train Loss: 0.2614
Epoch 12 Step 751 Train Loss: 0.2602
Epoch 12 Step 801 Train Loss: 0.2589
Epoch 12 Step 851 Train Loss: 0.4410
Epoch 12 Step 901 Train Loss: 0.2404
Epoch 12 Step 951 Train Loss: 0.2909
Epoch 12 Step 1001 Train Loss: 0.3352
Epoch 12 Step 1051 Train Loss: 0.3152
Epoch 12 Step 1101 Train Loss: 0.3053
Epoch 12 Step 1151 Train Loss: 0.2815
Epoch 12 Step 1201 Train Loss: 0.3123
Epoch 12 Step 1251 Train Loss: 0.2835
Epoch 12 Step 1301 Train Loss: 0.2810
Epoch 12 Step 1351 Train Loss: 0.2132
Epoch 12 Step 1401 Train Loss: 0.2368
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0075. 
Epoch 13 Step 1 Train Loss: 0.2858
Epoch 13 Step 51 Train Loss: 0.2311
Epoch 13 Step 101 Train Loss: 0.2790
Epoch 13 Step 151 Train Loss: 0.1987
Epoch 13 Step 201 Train Loss: 0.1881
Epoch 13 Step 251 Train Loss: 0.2648
Epoch 13 Step 301 Train Loss: 0.2840
Epoch 13 Step 351 Train Loss: 0.1995
Epoch 13 Step 401 Train Loss: 0.2813
Epoch 13 Step 451 Train Loss: 0.2596
Epoch 13 Step 501 Train Loss: 0.2499
Epoch 13 Step 551 Train Loss: 0.2363
Epoch 13 Step 601 Train Loss: 0.3039
Epoch 13 Step 651 Train Loss: 0.2736
Epoch 13 Step 701 Train Loss: 0.2204
Epoch 13 Step 751 Train Loss: 0.2017
Epoch 13 Step 801 Train Loss: 0.3024
Epoch 13 Step 851 Train Loss: 0.3020
Epoch 13 Step 901 Train Loss: 0.2298
Epoch 13 Step 951 Train Loss: 0.2698
Epoch 13 Step 1001 Train Loss: 0.3757
Epoch 13 Step 1051 Train Loss: 0.3272
Epoch 13 Step 1101 Train Loss: 0.3056
Epoch 13 Step 1151 Train Loss: 0.2540
Epoch 13 Step 1201 Train Loss: 0.2783
Epoch 13 Step 1251 Train Loss: 0.2994
Epoch 13 Step 1301 Train Loss: 0.1944
Epoch 13 Step 1351 Train Loss: 0.2760
Epoch 13 Step 1401 Train Loss: 0.3066
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0075. 
Epoch 14 Step 1 Train Loss: 0.2631
Epoch 14 Step 51 Train Loss: 0.2523
Epoch 14 Step 101 Train Loss: 0.2895
Epoch 14 Step 151 Train Loss: 0.2817
Epoch 14 Step 201 Train Loss: 0.2975
Epoch 14 Step 251 Train Loss: 0.3151
Epoch 14 Step 301 Train Loss: 0.2339
Epoch 14 Step 351 Train Loss: 0.3435
Epoch 14 Step 401 Train Loss: 0.2961
Epoch 14 Step 451 Train Loss: 0.2406
Epoch 14 Step 501 Train Loss: 0.2269
Epoch 14 Step 551 Train Loss: 0.2172
Epoch 14 Step 601 Train Loss: 0.2428
Epoch 14 Step 651 Train Loss: 0.2802
Epoch 14 Step 701 Train Loss: 0.2966
Epoch 14 Step 751 Train Loss: 0.2498
Epoch 14 Step 801 Train Loss: 0.1915
Epoch 14 Step 851 Train Loss: 0.2488
Epoch 14 Step 901 Train Loss: 0.3283
Epoch 14 Step 951 Train Loss: 0.2518
Epoch 14 Step 1001 Train Loss: 0.3401
Epoch 14 Step 1051 Train Loss: 0.2846
Epoch 14 Step 1101 Train Loss: 0.2459
Epoch 14 Step 1151 Train Loss: 0.2320
Epoch 14 Step 1201 Train Loss: 0.2810
Epoch 14 Step 1251 Train Loss: 0.2386
Epoch 14 Step 1301 Train Loss: 0.2107
Epoch 14 Step 1351 Train Loss: 0.2347
Epoch 14 Step 1401 Train Loss: 0.3532
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0078. 
Epoch 15 Step 1 Train Loss: 0.2812
Epoch 15 Step 51 Train Loss: 0.2331
Epoch 15 Step 101 Train Loss: 0.2049
Epoch 15 Step 151 Train Loss: 0.2566
Epoch 15 Step 201 Train Loss: 0.2313
Epoch 15 Step 251 Train Loss: 0.2427
Epoch 15 Step 301 Train Loss: 0.2807
Epoch 15 Step 351 Train Loss: 0.2656
Epoch 15 Step 401 Train Loss: 0.2435
Epoch 15 Step 451 Train Loss: 0.3167
Epoch 15 Step 501 Train Loss: 0.2120
Epoch 15 Step 551 Train Loss: 0.2245
Epoch 15 Step 601 Train Loss: 0.1854
Epoch 15 Step 651 Train Loss: 0.3524
Epoch 15 Step 701 Train Loss: 0.3097
Epoch 15 Step 751 Train Loss: 0.2788
Epoch 15 Step 801 Train Loss: 0.2668
Epoch 15 Step 851 Train Loss: 0.1997
Epoch 15 Step 901 Train Loss: 0.1871
Epoch 15 Step 951 Train Loss: 0.2597
Epoch 15 Step 1001 Train Loss: 0.2175
Epoch 15 Step 1051 Train Loss: 0.2736
Epoch 15 Step 1101 Train Loss: 0.2219
Epoch 15 Step 1151 Train Loss: 0.2665
Epoch 15 Step 1201 Train Loss: 0.2144
Epoch 15 Step 1251 Train Loss: 0.2091
Epoch 15 Step 1301 Train Loss: 0.3055
Epoch 15 Step 1351 Train Loss: 0.2867
Epoch 15 Step 1401 Train Loss: 0.2732
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0072. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0095
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0013779525
test_unseen_single_pearson: 0.993294105057451
test_unseen_single_mse_de: 0.009461616
test_unseen_single_pearson_de: 0.9976767203198967
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.8837168667233797
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.0
test_unseen_single_frac_sigma_below_1_non_dropout: 0.93
test_unseen_single_mse_top20_de_non_dropout: 0.010682968
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.033 MB uploadedwandb: | 0.007 MB of 0.033 MB uploadedwandb: / 0.007 MB of 0.033 MB uploadedwandb: - 0.033 MB of 0.033 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:                                             train_de_pearson ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:                                                    train_mse ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ
wandb:                                               val_de_pearson ‚ñÖ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00946
wandb:                                              test_de_pearson 0.99768
wandb:               test_frac_opposite_direction_top20_non_dropout 0.0
wandb:                          test_frac_sigma_below_1_non_dropout 0.93
wandb:                                                     test_mse 0.00138
wandb:                                test_mse_top20_de_non_dropout 0.01068
wandb:                                                 test_pearson 0.99329
wandb:                                           test_pearson_delta 0.88372
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.0
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.93
wandb:                                       test_unseen_single_mse 0.00138
wandb:                                    test_unseen_single_mse_de 0.00946
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01068
wandb:                                   test_unseen_single_pearson 0.99329
wandb:                                test_unseen_single_pearson_de 0.99768
wandb:                             test_unseen_single_pearson_delta 0.88372
wandb:                                                 train_de_mse 0.00905
wandb:                                             train_de_pearson 0.99794
wandb:                                                    train_mse 0.00117
wandb:                                                train_pearson 0.99467
wandb:                                                training_loss 0.3141
wandb:                                                   val_de_mse 0.00719
wandb:                                               val_de_pearson 0.85225
wandb:                                                      val_mse 0.00128
wandb:                                                  val_pearson 0.99416
wandb: 
wandb: üöÄ View run scbert_ShifrutMarson2018_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/w6ceez1w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_124354-w6ceez1w/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_130842-misbmfij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_ShifrutMarson2018_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/misbmfij
wandb: WARNING Serializing object of type ndarray that is 8012928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3048
Epoch 1 Step 51 Train Loss: 0.3281
Epoch 1 Step 101 Train Loss: 0.2334
Epoch 1 Step 151 Train Loss: 0.2813
Epoch 1 Step 201 Train Loss: 0.3001
Epoch 1 Step 251 Train Loss: 0.2562
Epoch 1 Step 301 Train Loss: 0.1834
Epoch 1 Step 351 Train Loss: 0.2984
Epoch 1 Step 401 Train Loss: 0.2742
Epoch 1 Step 451 Train Loss: 0.2565
Epoch 1 Step 501 Train Loss: 0.2736
Epoch 1 Step 551 Train Loss: 0.2098
Epoch 1 Step 601 Train Loss: 0.2863
Epoch 1 Step 651 Train Loss: 0.2661
Epoch 1 Step 701 Train Loss: 0.2637
Epoch 1 Step 751 Train Loss: 0.2658
Epoch 1 Step 801 Train Loss: 0.2301
Epoch 1 Step 851 Train Loss: 0.2341
Epoch 1 Step 901 Train Loss: 0.2729
Epoch 1 Step 951 Train Loss: 0.2690
Epoch 1 Step 1001 Train Loss: 0.2393
Epoch 1 Step 1051 Train Loss: 0.1862
Epoch 1 Step 1101 Train Loss: 0.2957
Epoch 1 Step 1151 Train Loss: 0.2516
Epoch 1 Step 1201 Train Loss: 0.2562
Epoch 1 Step 1251 Train Loss: 0.2503
Epoch 1 Step 1301 Train Loss: 0.2475
Epoch 1 Step 1351 Train Loss: 0.2546
Epoch 1 Step 1401 Train Loss: 0.2590
Epoch 1: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0156 Validation Top 20 DE MSE: 0.0243. 
Epoch 2 Step 1 Train Loss: 0.1867
Epoch 2 Step 51 Train Loss: 0.1914
Epoch 2 Step 101 Train Loss: 0.3153
Epoch 2 Step 151 Train Loss: 0.2055
Epoch 2 Step 201 Train Loss: 0.2483
Epoch 2 Step 251 Train Loss: 0.2560
Epoch 2 Step 301 Train Loss: 0.2254
Epoch 2 Step 351 Train Loss: 0.2982
Epoch 2 Step 401 Train Loss: 0.2410
Epoch 2 Step 451 Train Loss: 0.3234
Epoch 2 Step 501 Train Loss: 0.2094
Epoch 2 Step 551 Train Loss: 0.2756
Epoch 2 Step 601 Train Loss: 0.3453
Epoch 2 Step 651 Train Loss: 0.2781
Epoch 2 Step 701 Train Loss: 0.3244
Epoch 2 Step 751 Train Loss: 0.2601
Epoch 2 Step 801 Train Loss: 0.3084
Epoch 2 Step 851 Train Loss: 0.2250
Epoch 2 Step 901 Train Loss: 0.3565
Epoch 2 Step 951 Train Loss: 0.2582
Epoch 2 Step 1001 Train Loss: 0.2856
Epoch 2 Step 1051 Train Loss: 0.2443
Epoch 2 Step 1101 Train Loss: 0.2980
Epoch 2 Step 1151 Train Loss: 0.2687
Epoch 2 Step 1201 Train Loss: 0.1906
Epoch 2 Step 1251 Train Loss: 0.3383
Epoch 2 Step 1301 Train Loss: 0.3152
Epoch 2 Step 1351 Train Loss: 0.2235
Epoch 2 Step 1401 Train Loss: 0.2977
Epoch 2: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0183 Validation Top 20 DE MSE: 0.0224. 
Epoch 3 Step 1 Train Loss: 0.2029
Epoch 3 Step 51 Train Loss: 0.3216
Epoch 3 Step 101 Train Loss: 0.2406
Epoch 3 Step 151 Train Loss: 0.2458
Epoch 3 Step 201 Train Loss: 0.2920
Epoch 3 Step 251 Train Loss: 0.2693
Epoch 3 Step 301 Train Loss: 0.2034
Epoch 3 Step 351 Train Loss: 0.3538
Epoch 3 Step 401 Train Loss: 0.2680
Epoch 3 Step 451 Train Loss: 0.3533
Epoch 3 Step 501 Train Loss: 0.2460
Epoch 3 Step 551 Train Loss: 0.1942
Epoch 3 Step 601 Train Loss: 0.2861
Epoch 3 Step 651 Train Loss: 0.2172
Epoch 3 Step 701 Train Loss: 0.3068
Epoch 3 Step 751 Train Loss: 0.2126
Epoch 3 Step 801 Train Loss: 0.2236
Epoch 3 Step 851 Train Loss: 0.2368
Epoch 3 Step 901 Train Loss: 0.1961
Epoch 3 Step 951 Train Loss: 0.2140
Epoch 3 Step 1001 Train Loss: 0.1874
Epoch 3 Step 1051 Train Loss: 0.2763
Epoch 3 Step 1101 Train Loss: 0.1999
Epoch 3 Step 1151 Train Loss: 0.2065
Epoch 3 Step 1201 Train Loss: 0.2587
Epoch 3 Step 1251 Train Loss: 0.2789
Epoch 3 Step 1301 Train Loss: 0.2365
Epoch 3 Step 1351 Train Loss: 0.3019
Epoch 3 Step 1401 Train Loss: 0.3267
Epoch 3: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.0219. 
Epoch 4 Step 1 Train Loss: 0.2648
Epoch 4 Step 51 Train Loss: 0.3016
Epoch 4 Step 101 Train Loss: 0.2586
Epoch 4 Step 151 Train Loss: 0.2189
Epoch 4 Step 201 Train Loss: 0.2437
Epoch 4 Step 251 Train Loss: 0.2754
Epoch 4 Step 301 Train Loss: 0.2685
Epoch 4 Step 351 Train Loss: 0.2730
Epoch 4 Step 401 Train Loss: 0.2489
Epoch 4 Step 451 Train Loss: 0.2990
Epoch 4 Step 501 Train Loss: 0.2547
Epoch 4 Step 551 Train Loss: 0.2215
Epoch 4 Step 601 Train Loss: 0.3540
Epoch 4 Step 651 Train Loss: 0.2426
Epoch 4 Step 701 Train Loss: 0.2628
Epoch 4 Step 751 Train Loss: 0.1688
Epoch 4 Step 801 Train Loss: 0.2959
Epoch 4 Step 851 Train Loss: 0.3139
Epoch 4 Step 901 Train Loss: 0.2282
Epoch 4 Step 951 Train Loss: 0.2622
Epoch 4 Step 1001 Train Loss: 0.1940
Epoch 4 Step 1051 Train Loss: 0.3176
Epoch 4 Step 1101 Train Loss: 0.2664
Epoch 4 Step 1151 Train Loss: 0.2820
Epoch 4 Step 1201 Train Loss: 0.2816
Epoch 4 Step 1251 Train Loss: 0.2967
Epoch 4 Step 1301 Train Loss: 0.2724
Epoch 4 Step 1351 Train Loss: 0.2591
Epoch 4 Step 1401 Train Loss: 0.2477
Epoch 4: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0182. 
Epoch 5 Step 1 Train Loss: 0.2777
Epoch 5 Step 51 Train Loss: 0.2567
Epoch 5 Step 101 Train Loss: 0.2645
Epoch 5 Step 151 Train Loss: 0.2512
Epoch 5 Step 201 Train Loss: 0.3086
Epoch 5 Step 251 Train Loss: 0.2648
Epoch 5 Step 301 Train Loss: 0.2177
Epoch 5 Step 351 Train Loss: 0.2261
Epoch 5 Step 401 Train Loss: 0.1727
Epoch 5 Step 451 Train Loss: 0.3032
Epoch 5 Step 501 Train Loss: 0.2217
Epoch 5 Step 551 Train Loss: 0.2893
Epoch 5 Step 601 Train Loss: 0.2893
Epoch 5 Step 651 Train Loss: 0.2591
Epoch 5 Step 701 Train Loss: 0.3019
Epoch 5 Step 751 Train Loss: 0.2521
Epoch 5 Step 801 Train Loss: 0.2375
Epoch 5 Step 851 Train Loss: 0.2572
Epoch 5 Step 901 Train Loss: 0.2595
Epoch 5 Step 951 Train Loss: 0.1973
Epoch 5 Step 1001 Train Loss: 0.1832
Epoch 5 Step 1051 Train Loss: 0.3108
Epoch 5 Step 1101 Train Loss: 0.2494
Epoch 5 Step 1151 Train Loss: 0.2437
Epoch 5 Step 1201 Train Loss: 0.2685
Epoch 5 Step 1251 Train Loss: 0.3052
Epoch 5 Step 1301 Train Loss: 0.2235
Epoch 5 Step 1351 Train Loss: 0.2476
Epoch 5 Step 1401 Train Loss: 0.1936
Epoch 5: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0101 Validation Top 20 DE MSE: 0.0228. 
Epoch 6 Step 1 Train Loss: 0.2242
Epoch 6 Step 51 Train Loss: 0.2412
Epoch 6 Step 101 Train Loss: 0.2398
Epoch 6 Step 151 Train Loss: 0.2900
Epoch 6 Step 201 Train Loss: 0.2795
Epoch 6 Step 251 Train Loss: 0.2756
Epoch 6 Step 301 Train Loss: 0.3114
Epoch 6 Step 351 Train Loss: 0.2761
Epoch 6 Step 401 Train Loss: 0.2086
Epoch 6 Step 451 Train Loss: 0.3099
Epoch 6 Step 501 Train Loss: 0.2298
Epoch 6 Step 551 Train Loss: 0.2272
Epoch 6 Step 601 Train Loss: 0.2285
Epoch 6 Step 651 Train Loss: 0.2964
Epoch 6 Step 701 Train Loss: 0.3641
Epoch 6 Step 751 Train Loss: 0.2109
Epoch 6 Step 801 Train Loss: 0.3424
Epoch 6 Step 851 Train Loss: 0.2991
Epoch 6 Step 901 Train Loss: 0.2101
Epoch 6 Step 951 Train Loss: 0.2836
Epoch 6 Step 1001 Train Loss: 0.2244
Epoch 6 Step 1051 Train Loss: 0.3329
Epoch 6 Step 1101 Train Loss: 0.2434
Epoch 6 Step 1151 Train Loss: 0.2153
Epoch 6 Step 1201 Train Loss: 0.2360
Epoch 6 Step 1251 Train Loss: 0.2141
Epoch 6 Step 1301 Train Loss: 0.2660
Epoch 6 Step 1351 Train Loss: 0.2532
Epoch 6 Step 1401 Train Loss: 0.2761
Epoch 6: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0208. 
Epoch 7 Step 1 Train Loss: 0.2670
Epoch 7 Step 51 Train Loss: 0.2442
Epoch 7 Step 101 Train Loss: 0.2613
Epoch 7 Step 151 Train Loss: 0.2773
Epoch 7 Step 201 Train Loss: 0.2119
Epoch 7 Step 251 Train Loss: 0.2854
Epoch 7 Step 301 Train Loss: 0.2360
Epoch 7 Step 351 Train Loss: 0.3209
Epoch 7 Step 401 Train Loss: 0.3180
Epoch 7 Step 451 Train Loss: 0.2648
Epoch 7 Step 501 Train Loss: 0.2411
Epoch 7 Step 551 Train Loss: 0.2638
Epoch 7 Step 601 Train Loss: 0.2146
Epoch 7 Step 651 Train Loss: 0.2642
Epoch 7 Step 701 Train Loss: 0.2535
Epoch 7 Step 751 Train Loss: 0.3059
Epoch 7 Step 801 Train Loss: 0.2982
Epoch 7 Step 851 Train Loss: 0.2409
Epoch 7 Step 901 Train Loss: 0.2849
Epoch 7 Step 951 Train Loss: 0.1953
Epoch 7 Step 1001 Train Loss: 0.2580
Epoch 7 Step 1051 Train Loss: 0.2757
Epoch 7 Step 1101 Train Loss: 0.2900
Epoch 7 Step 1151 Train Loss: 0.2486
Epoch 7 Step 1201 Train Loss: 0.2112
Epoch 7 Step 1251 Train Loss: 0.2159
Epoch 7 Step 1301 Train Loss: 0.2646
Epoch 7 Step 1351 Train Loss: 0.2839
Epoch 7 Step 1401 Train Loss: 0.3456
Epoch 7: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0235. 
Epoch 8 Step 1 Train Loss: 0.3050
Epoch 8 Step 51 Train Loss: 0.1630
Epoch 8 Step 101 Train Loss: 0.2581
Epoch 8 Step 151 Train Loss: 0.2826
Epoch 8 Step 201 Train Loss: 0.2520
Epoch 8 Step 251 Train Loss: 0.2841
Epoch 8 Step 301 Train Loss: 0.2519
Epoch 8 Step 351 Train Loss: 0.2566
Epoch 8 Step 401 Train Loss: 0.2616
Epoch 8 Step 451 Train Loss: 0.2298
Epoch 8 Step 501 Train Loss: 0.2056
Epoch 8 Step 551 Train Loss: 0.3325
Epoch 8 Step 601 Train Loss: 0.2575
Epoch 8 Step 651 Train Loss: 0.2765
Epoch 8 Step 701 Train Loss: 0.2054
Epoch 8 Step 751 Train Loss: 0.2238
Epoch 8 Step 801 Train Loss: 0.3609
Epoch 8 Step 851 Train Loss: 0.1958
Epoch 8 Step 901 Train Loss: 0.1954
Epoch 8 Step 951 Train Loss: 0.2319
Epoch 8 Step 1001 Train Loss: 0.2732
Epoch 8 Step 1051 Train Loss: 0.2788
Epoch 8 Step 1101 Train Loss: 0.2771
Epoch 8 Step 1151 Train Loss: 0.2313
Epoch 8 Step 1201 Train Loss: 0.2718
Epoch 8 Step 1251 Train Loss: 0.2683
Epoch 8 Step 1301 Train Loss: 0.2348
Epoch 8 Step 1351 Train Loss: 0.3127
Epoch 8 Step 1401 Train Loss: 0.2630
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0102 Validation Top 20 DE MSE: 0.0227. 
Epoch 9 Step 1 Train Loss: 0.2295
Epoch 9 Step 51 Train Loss: 0.1504
Epoch 9 Step 101 Train Loss: 0.2867
Epoch 9 Step 151 Train Loss: 0.2483
Epoch 9 Step 201 Train Loss: 0.3216
Epoch 9 Step 251 Train Loss: 0.2528
Epoch 9 Step 301 Train Loss: 0.2826
Epoch 9 Step 351 Train Loss: 0.2440
Epoch 9 Step 401 Train Loss: 0.2060
Epoch 9 Step 451 Train Loss: 0.0495
Epoch 9 Step 501 Train Loss: 0.2457
Epoch 9 Step 551 Train Loss: 0.3469
Epoch 9 Step 601 Train Loss: 0.2564
Epoch 9 Step 651 Train Loss: 0.2421
Epoch 9 Step 701 Train Loss: 0.2658
Epoch 9 Step 751 Train Loss: 0.3309
Epoch 9 Step 801 Train Loss: 0.2798
Epoch 9 Step 851 Train Loss: 0.2888
Epoch 9 Step 901 Train Loss: 0.3233
Epoch 9 Step 951 Train Loss: 0.2449
Epoch 9 Step 1001 Train Loss: 0.2496
Epoch 9 Step 1051 Train Loss: 0.2413
Epoch 9 Step 1101 Train Loss: 0.2469
Epoch 9 Step 1151 Train Loss: 0.2515
Epoch 9 Step 1201 Train Loss: 0.3099
Epoch 9 Step 1251 Train Loss: 0.2779
Epoch 9 Step 1301 Train Loss: 0.3574
Epoch 9 Step 1351 Train Loss: 0.1957
Epoch 9 Step 1401 Train Loss: 0.2649
Epoch 9: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0109 Validation Top 20 DE MSE: 0.0236. 
Epoch 10 Step 1 Train Loss: 0.2847
Epoch 10 Step 51 Train Loss: 0.2523
Epoch 10 Step 101 Train Loss: 0.2317
Epoch 10 Step 151 Train Loss: 0.3377
Epoch 10 Step 201 Train Loss: 0.2589
Epoch 10 Step 251 Train Loss: 0.2501
Epoch 10 Step 301 Train Loss: 0.2594
Epoch 10 Step 351 Train Loss: 0.2817
Epoch 10 Step 401 Train Loss: 0.2484
Epoch 10 Step 451 Train Loss: 0.2739
Epoch 10 Step 501 Train Loss: 0.3027
Epoch 10 Step 551 Train Loss: 0.2258
Epoch 10 Step 601 Train Loss: 0.2553
Epoch 10 Step 651 Train Loss: 0.2024
Epoch 10 Step 701 Train Loss: 0.2862
Epoch 10 Step 751 Train Loss: 0.2434
Epoch 10 Step 801 Train Loss: 0.2043
Epoch 10 Step 851 Train Loss: 0.1830
Epoch 10 Step 901 Train Loss: 0.2472
Epoch 10 Step 951 Train Loss: 0.3476
Epoch 10 Step 1001 Train Loss: 0.3146
Epoch 10 Step 1051 Train Loss: 0.2498
Epoch 10 Step 1101 Train Loss: 0.2109
Epoch 10 Step 1151 Train Loss: 0.2473
Epoch 10 Step 1201 Train Loss: 0.2594
Epoch 10 Step 1251 Train Loss: 0.2119
Epoch 10 Step 1301 Train Loss: 0.3444
Epoch 10 Step 1351 Train Loss: 0.3005
Epoch 10 Step 1401 Train Loss: 0.2548
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0235. 
Epoch 11 Step 1 Train Loss: 0.2355
Epoch 11 Step 51 Train Loss: 0.3838
Epoch 11 Step 101 Train Loss: 0.2822
Epoch 11 Step 151 Train Loss: 0.2401
Epoch 11 Step 201 Train Loss: 0.3278
Epoch 11 Step 251 Train Loss: 0.1977
Epoch 11 Step 301 Train Loss: 0.2612
Epoch 11 Step 351 Train Loss: 0.2680
Epoch 11 Step 401 Train Loss: 0.3123
Epoch 11 Step 451 Train Loss: 0.2847
Epoch 11 Step 501 Train Loss: 0.2402
Epoch 11 Step 551 Train Loss: 0.2733
Epoch 11 Step 601 Train Loss: 0.2870
Epoch 11 Step 651 Train Loss: 0.2570
Epoch 11 Step 701 Train Loss: 0.2424
Epoch 11 Step 751 Train Loss: 0.2737
Epoch 11 Step 801 Train Loss: 0.2219
Epoch 11 Step 851 Train Loss: 0.2135
Epoch 11 Step 901 Train Loss: 0.3066
Epoch 11 Step 951 Train Loss: 0.2153
Epoch 11 Step 1001 Train Loss: 0.2460
Epoch 11 Step 1051 Train Loss: 0.2249
Epoch 11 Step 1101 Train Loss: 0.2011
Epoch 11 Step 1151 Train Loss: 0.2972
Epoch 11 Step 1201 Train Loss: 0.2315
Epoch 11 Step 1251 Train Loss: 0.2446
Epoch 11 Step 1301 Train Loss: 0.2416
Epoch 11 Step 1351 Train Loss: 0.2366
Epoch 11 Step 1401 Train Loss: 0.2293
Epoch 11: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0108 Validation Top 20 DE MSE: 0.0234. 
Epoch 12 Step 1 Train Loss: 0.2392
Epoch 12 Step 51 Train Loss: 0.2049
Epoch 12 Step 101 Train Loss: 0.2165
Epoch 12 Step 151 Train Loss: 0.2809
Epoch 12 Step 201 Train Loss: 0.2251
Epoch 12 Step 251 Train Loss: 0.2124
Epoch 12 Step 301 Train Loss: 0.2352
Epoch 12 Step 351 Train Loss: 0.2976
Epoch 12 Step 401 Train Loss: 0.2868
Epoch 12 Step 451 Train Loss: 0.2971
Epoch 12 Step 501 Train Loss: 0.2031
Epoch 12 Step 551 Train Loss: 0.2125
Epoch 12 Step 601 Train Loss: 0.2784
Epoch 12 Step 651 Train Loss: 0.2413
Epoch 12 Step 701 Train Loss: 0.2599
Epoch 12 Step 751 Train Loss: 0.2232
Epoch 12 Step 801 Train Loss: 0.2470
Epoch 12 Step 851 Train Loss: 0.1699
Epoch 12 Step 901 Train Loss: 0.2787
Epoch 12 Step 951 Train Loss: 0.2238
Epoch 12 Step 1001 Train Loss: 0.2716
Epoch 12 Step 1051 Train Loss: 0.2690
Epoch 12 Step 1101 Train Loss: 0.2949
Epoch 12 Step 1151 Train Loss: 0.2464
Epoch 12 Step 1201 Train Loss: 0.2957
Epoch 12 Step 1251 Train Loss: 0.2986
Epoch 12 Step 1301 Train Loss: 0.3102
Epoch 12 Step 1351 Train Loss: 0.2016
Epoch 12 Step 1401 Train Loss: 0.2952
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0114 Validation Top 20 DE MSE: 0.0241. 
Epoch 13 Step 1 Train Loss: 0.2753
Epoch 13 Step 51 Train Loss: 0.2097
Epoch 13 Step 101 Train Loss: 0.1966
Epoch 13 Step 151 Train Loss: 0.3167
Epoch 13 Step 201 Train Loss: 0.2421
Epoch 13 Step 251 Train Loss: 0.2432
Epoch 13 Step 301 Train Loss: 0.2218
Epoch 13 Step 351 Train Loss: 0.2805
Epoch 13 Step 401 Train Loss: 0.2655
Epoch 13 Step 451 Train Loss: 0.2174
Epoch 13 Step 501 Train Loss: 0.3036
Epoch 13 Step 551 Train Loss: 0.2384
Epoch 13 Step 601 Train Loss: 0.2487
Epoch 13 Step 651 Train Loss: 0.2375
Epoch 13 Step 701 Train Loss: 0.2948
Epoch 13 Step 751 Train Loss: 0.2485
Epoch 13 Step 801 Train Loss: 0.1962
Epoch 13 Step 851 Train Loss: 0.1940
Epoch 13 Step 901 Train Loss: 0.2364
Epoch 13 Step 951 Train Loss: 0.2848
Epoch 13 Step 1001 Train Loss: 0.2609
Epoch 13 Step 1051 Train Loss: 0.2770
Epoch 13 Step 1101 Train Loss: 0.1670
Epoch 13 Step 1151 Train Loss: 0.2426
Epoch 13 Step 1201 Train Loss: 0.2566
Epoch 13 Step 1251 Train Loss: 0.2477
Epoch 13 Step 1301 Train Loss: 0.2395
Epoch 13 Step 1351 Train Loss: 0.2542
Epoch 13 Step 1401 Train Loss: 0.2736
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0233. 
Epoch 14 Step 1 Train Loss: 0.2311
Epoch 14 Step 51 Train Loss: 0.3070
Epoch 14 Step 101 Train Loss: 0.2156
Epoch 14 Step 151 Train Loss: 0.2742
Epoch 14 Step 201 Train Loss: 0.2122
Epoch 14 Step 251 Train Loss: 0.2500
Epoch 14 Step 301 Train Loss: 0.2625
Epoch 14 Step 351 Train Loss: 0.3003
Epoch 14 Step 401 Train Loss: 0.3239
Epoch 14 Step 451 Train Loss: 0.1744
Epoch 14 Step 501 Train Loss: 0.2826
Epoch 14 Step 551 Train Loss: 0.2623
Epoch 14 Step 601 Train Loss: 0.2264
Epoch 14 Step 651 Train Loss: 0.2319
Epoch 14 Step 701 Train Loss: 0.1892
Epoch 14 Step 751 Train Loss: 0.2320
Epoch 14 Step 801 Train Loss: 0.2278
Epoch 14 Step 851 Train Loss: 0.2335
Epoch 14 Step 901 Train Loss: 0.2841
Epoch 14 Step 951 Train Loss: 0.3081
Epoch 14 Step 1001 Train Loss: 0.2804
Epoch 14 Step 1051 Train Loss: 0.1404
Epoch 14 Step 1101 Train Loss: 0.2762
Epoch 14 Step 1151 Train Loss: 0.2444
Epoch 14 Step 1201 Train Loss: 0.2569
Epoch 14 Step 1251 Train Loss: 0.2934
Epoch 14 Step 1301 Train Loss: 0.2765
Epoch 14 Step 1351 Train Loss: 0.2774
Epoch 14 Step 1401 Train Loss: 0.2647
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0230. 
Epoch 15 Step 1 Train Loss: 0.2888
Epoch 15 Step 51 Train Loss: 0.2294
Epoch 15 Step 101 Train Loss: 0.2367
Epoch 15 Step 151 Train Loss: 0.2034
Epoch 15 Step 201 Train Loss: 0.3062
Epoch 15 Step 251 Train Loss: 0.2344
Epoch 15 Step 301 Train Loss: 0.2214
Epoch 15 Step 351 Train Loss: 0.2152
Epoch 15 Step 401 Train Loss: 0.3017
Epoch 15 Step 451 Train Loss: 0.2579
Epoch 15 Step 501 Train Loss: 0.2186
Epoch 15 Step 551 Train Loss: 0.2440
Epoch 15 Step 601 Train Loss: 0.2341
Epoch 15 Step 651 Train Loss: 0.1791
Epoch 15 Step 701 Train Loss: 0.2221
Epoch 15 Step 751 Train Loss: 0.2632
Epoch 15 Step 801 Train Loss: 0.2087
Epoch 15 Step 851 Train Loss: 0.2043
Epoch 15 Step 901 Train Loss: 0.2289
Epoch 15 Step 951 Train Loss: 0.2825
Epoch 15 Step 1001 Train Loss: 0.2516
Epoch 15 Step 1051 Train Loss: 0.2423
Epoch 15 Step 1101 Train Loss: 0.2968
Epoch 15 Step 1151 Train Loss: 0.2369
Epoch 15 Step 1201 Train Loss: 0.3179
Epoch 15 Step 1251 Train Loss: 0.2548
Epoch 15 Step 1301 Train Loss: 0.2787
Epoch 15 Step 1351 Train Loss: 0.2343
Epoch 15 Step 1401 Train Loss: 0.2679
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0105 Validation Top 20 DE MSE: 0.0232. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0114
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0015115396
test_unseen_single_pearson: 0.9928662397384531
test_unseen_single_mse_de: 0.011442062
test_unseen_single_pearson_de: 0.9969300726373099
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.8714460305813695
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.0
test_unseen_single_frac_sigma_below_1_non_dropout: 0.96
test_unseen_single_mse_top20_de_non_dropout: 0.015619509
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.033 MB uploadedwandb: | 0.003 MB of 0.033 MB uploadedwandb: / 0.027 MB of 0.033 MB uploadedwandb: - 0.027 MB of 0.033 MB uploadedwandb: \ 0.033 MB of 0.033 MB uploadedwandb: | 0.033 MB of 0.033 MB uploadedwandb: / 0.033 MB of 0.033 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá
wandb:                                                    train_mse ‚ñà‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÇ
wandb:                                                   val_de_mse ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá
wandb:                                               val_de_pearson ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ
wandb:                                                      val_mse ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01144
wandb:                                              test_de_pearson 0.99693
wandb:               test_frac_opposite_direction_top20_non_dropout 0.0
wandb:                          test_frac_sigma_below_1_non_dropout 0.96
wandb:                                                     test_mse 0.00151
wandb:                                test_mse_top20_de_non_dropout 0.01562
wandb:                                                 test_pearson 0.99287
wandb:                                           test_pearson_delta 0.87145
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.0
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.96
wandb:                                       test_unseen_single_mse 0.00151
wandb:                                    test_unseen_single_mse_de 0.01144
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01562
wandb:                                   test_unseen_single_pearson 0.99287
wandb:                                test_unseen_single_pearson_de 0.99693
wandb:                             test_unseen_single_pearson_delta 0.87145
wandb:                                                 train_de_mse 0.01048
wandb:                                             train_de_pearson 0.97759
wandb:                                                    train_mse 0.00108
wandb:                                                train_pearson 0.99496
wandb:                                                training_loss 0.27301
wandb:                                                   val_de_mse 0.02315
wandb:                                               val_de_pearson 0.99556
wandb:                                                      val_mse 0.00115
wandb:                                                  val_pearson 0.99473
wandb: 
wandb: üöÄ View run scbert_ShifrutMarson2018_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/misbmfij
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_130842-misbmfij/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_133057-fr862ayk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_ShifrutMarson2018_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/fr862ayk
wandb: WARNING Serializing object of type ndarray that is 8012928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3007
Epoch 1 Step 51 Train Loss: 0.3578
Epoch 1 Step 101 Train Loss: 0.3013
Epoch 1 Step 151 Train Loss: 0.2659
Epoch 1 Step 201 Train Loss: 0.2911
Epoch 1 Step 251 Train Loss: 0.2625
Epoch 1 Step 301 Train Loss: 0.2038
Epoch 1 Step 351 Train Loss: 0.2111
Epoch 1 Step 401 Train Loss: 0.2950
Epoch 1 Step 451 Train Loss: 0.3217
Epoch 1 Step 501 Train Loss: 0.3019
Epoch 1 Step 551 Train Loss: 0.3201
Epoch 1 Step 601 Train Loss: 0.2189
Epoch 1 Step 651 Train Loss: 0.2485
Epoch 1 Step 701 Train Loss: 0.2595
Epoch 1 Step 751 Train Loss: 0.2534
Epoch 1 Step 801 Train Loss: 0.4087
Epoch 1 Step 851 Train Loss: 0.2688
Epoch 1 Step 901 Train Loss: 0.2295
Epoch 1 Step 951 Train Loss: 0.2591
Epoch 1 Step 1001 Train Loss: 0.3113
Epoch 1 Step 1051 Train Loss: 0.2747
Epoch 1 Step 1101 Train Loss: 0.2893
Epoch 1 Step 1151 Train Loss: 0.1843
Epoch 1 Step 1201 Train Loss: 0.2941
Epoch 1 Step 1251 Train Loss: 0.3505
Epoch 1 Step 1301 Train Loss: 0.2824
Epoch 1 Step 1351 Train Loss: 0.2520
Epoch 1: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0025. 
Train Top 20 DE MSE: 0.0404 Validation Top 20 DE MSE: 0.0459. 
Epoch 2 Step 1 Train Loss: 0.1775
Epoch 2 Step 51 Train Loss: 0.2258
Epoch 2 Step 101 Train Loss: 0.2428
Epoch 2 Step 151 Train Loss: 0.2474
Epoch 2 Step 201 Train Loss: 0.2315
Epoch 2 Step 251 Train Loss: 0.2794
Epoch 2 Step 301 Train Loss: 0.3057
Epoch 2 Step 351 Train Loss: 0.1875
Epoch 2 Step 401 Train Loss: 0.2903
Epoch 2 Step 451 Train Loss: 0.2502
Epoch 2 Step 501 Train Loss: 0.2323
Epoch 2 Step 551 Train Loss: 0.3335
Epoch 2 Step 601 Train Loss: 0.1770
Epoch 2 Step 651 Train Loss: 0.2498
Epoch 2 Step 701 Train Loss: 0.2221
Epoch 2 Step 751 Train Loss: 0.3485
Epoch 2 Step 801 Train Loss: 0.2431
Epoch 2 Step 851 Train Loss: 0.1864
Epoch 2 Step 901 Train Loss: 0.2448
Epoch 2 Step 951 Train Loss: 0.2591
Epoch 2 Step 1001 Train Loss: 0.2727
Epoch 2 Step 1051 Train Loss: 0.3169
Epoch 2 Step 1101 Train Loss: 0.2251
Epoch 2 Step 1151 Train Loss: 0.2342
Epoch 2 Step 1201 Train Loss: 0.2840
Epoch 2 Step 1251 Train Loss: 0.2732
Epoch 2 Step 1301 Train Loss: 0.2623
Epoch 2 Step 1351 Train Loss: 0.2187
Epoch 2: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0078. 
Epoch 3 Step 1 Train Loss: 0.2063
Epoch 3 Step 51 Train Loss: 0.1771
Epoch 3 Step 101 Train Loss: 0.1910
Epoch 3 Step 151 Train Loss: 0.2418
Epoch 3 Step 201 Train Loss: 0.2803
Epoch 3 Step 251 Train Loss: 0.2905
Epoch 3 Step 301 Train Loss: 0.1941
Epoch 3 Step 351 Train Loss: 0.2639
Epoch 3 Step 401 Train Loss: 0.2025
Epoch 3 Step 451 Train Loss: 0.2803
Epoch 3 Step 501 Train Loss: 0.2599
Epoch 3 Step 551 Train Loss: 0.2868
Epoch 3 Step 601 Train Loss: 0.2210
Epoch 3 Step 651 Train Loss: 0.2730
Epoch 3 Step 701 Train Loss: 0.2138
Epoch 3 Step 751 Train Loss: 0.2269
Epoch 3 Step 801 Train Loss: 0.2680
Epoch 3 Step 851 Train Loss: 0.2859
Epoch 3 Step 901 Train Loss: 0.2527
Epoch 3 Step 951 Train Loss: 0.2042
Epoch 3 Step 1001 Train Loss: 0.3725
Epoch 3 Step 1051 Train Loss: 0.2397
Epoch 3 Step 1101 Train Loss: 0.3122
Epoch 3 Step 1151 Train Loss: 0.2062
Epoch 3 Step 1201 Train Loss: 0.1590
Epoch 3 Step 1251 Train Loss: 0.2219
Epoch 3 Step 1301 Train Loss: 0.2980
Epoch 3 Step 1351 Train Loss: 0.2178
Epoch 3: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0193 Validation Top 20 DE MSE: 0.0203. 
Epoch 4 Step 1 Train Loss: 0.3121
Epoch 4 Step 51 Train Loss: 0.1686
Epoch 4 Step 101 Train Loss: 0.2170
Epoch 4 Step 151 Train Loss: 0.2682
Epoch 4 Step 201 Train Loss: 0.2467
Epoch 4 Step 251 Train Loss: 0.2345
Epoch 4 Step 301 Train Loss: 0.2791
Epoch 4 Step 351 Train Loss: 0.2500
Epoch 4 Step 401 Train Loss: 0.2490
Epoch 4 Step 451 Train Loss: 0.2729
Epoch 4 Step 501 Train Loss: 0.2475
Epoch 4 Step 551 Train Loss: 0.3293
Epoch 4 Step 601 Train Loss: 0.2437
Epoch 4 Step 651 Train Loss: 0.2993
Epoch 4 Step 701 Train Loss: 0.2355
Epoch 4 Step 751 Train Loss: 0.2841
Epoch 4 Step 801 Train Loss: 0.2216
Epoch 4 Step 851 Train Loss: 0.2795
Epoch 4 Step 901 Train Loss: 0.2796
Epoch 4 Step 951 Train Loss: 0.2650
Epoch 4 Step 1001 Train Loss: 0.2704
Epoch 4 Step 1051 Train Loss: 0.2494
Epoch 4 Step 1101 Train Loss: 0.2367
Epoch 4 Step 1151 Train Loss: 0.2269
Epoch 4 Step 1201 Train Loss: 0.3051
Epoch 4 Step 1251 Train Loss: 0.2120
Epoch 4 Step 1301 Train Loss: 0.2905
Epoch 4 Step 1351 Train Loss: 0.2432
Epoch 4: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0119 Validation Top 20 DE MSE: 0.0131. 
Epoch 5 Step 1 Train Loss: 0.2392
Epoch 5 Step 51 Train Loss: 0.2874
Epoch 5 Step 101 Train Loss: 0.2398
Epoch 5 Step 151 Train Loss: 0.2660
Epoch 5 Step 201 Train Loss: 0.3211
Epoch 5 Step 251 Train Loss: 0.2586
Epoch 5 Step 301 Train Loss: 0.2245
Epoch 5 Step 351 Train Loss: 0.2468
Epoch 5 Step 401 Train Loss: 0.3338
Epoch 5 Step 451 Train Loss: 0.1999
Epoch 5 Step 501 Train Loss: 0.1685
Epoch 5 Step 551 Train Loss: 0.2569
Epoch 5 Step 601 Train Loss: 0.2513
Epoch 5 Step 651 Train Loss: 0.2647
Epoch 5 Step 701 Train Loss: 0.2246
Epoch 5 Step 751 Train Loss: 0.3465
Epoch 5 Step 801 Train Loss: 0.2026
Epoch 5 Step 851 Train Loss: 0.2950
Epoch 5 Step 901 Train Loss: 0.2324
Epoch 5 Step 951 Train Loss: 0.2672
Epoch 5 Step 1001 Train Loss: 0.3247
Epoch 5 Step 1051 Train Loss: 0.2551
Epoch 5 Step 1101 Train Loss: 0.2323
Epoch 5 Step 1151 Train Loss: 0.2646
Epoch 5 Step 1201 Train Loss: 0.2907
Epoch 5 Step 1251 Train Loss: 0.3084
Epoch 5 Step 1301 Train Loss: 0.2626
Epoch 5 Step 1351 Train Loss: 0.2335
Epoch 5: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0077. 
Epoch 6 Step 1 Train Loss: 0.2444
Epoch 6 Step 51 Train Loss: 0.2592
Epoch 6 Step 101 Train Loss: 0.3387
Epoch 6 Step 151 Train Loss: 0.2861
Epoch 6 Step 201 Train Loss: 0.2374
Epoch 6 Step 251 Train Loss: 0.2174
Epoch 6 Step 301 Train Loss: 0.2534
Epoch 6 Step 351 Train Loss: 0.2356
Epoch 6 Step 401 Train Loss: 0.2473
Epoch 6 Step 451 Train Loss: 0.3248
Epoch 6 Step 501 Train Loss: 0.2693
Epoch 6 Step 551 Train Loss: 0.2362
Epoch 6 Step 601 Train Loss: 0.2808
Epoch 6 Step 651 Train Loss: 0.2064
Epoch 6 Step 701 Train Loss: 0.2588
Epoch 6 Step 751 Train Loss: 0.2647
Epoch 6 Step 801 Train Loss: 0.2858
Epoch 6 Step 851 Train Loss: 0.1633
Epoch 6 Step 901 Train Loss: 0.1919
Epoch 6 Step 951 Train Loss: 0.2178
Epoch 6 Step 1001 Train Loss: 0.2683
Epoch 6 Step 1051 Train Loss: 0.2807
Epoch 6 Step 1101 Train Loss: 0.2336
Epoch 6 Step 1151 Train Loss: 0.2410
Epoch 6 Step 1201 Train Loss: 0.2697
Epoch 6 Step 1251 Train Loss: 0.2356
Epoch 6 Step 1301 Train Loss: 0.3212
Epoch 6 Step 1351 Train Loss: 0.2677
Epoch 6: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0117 Validation Top 20 DE MSE: 0.0134. 
Epoch 7 Step 1 Train Loss: 0.2173
Epoch 7 Step 51 Train Loss: 0.2726
Epoch 7 Step 101 Train Loss: 0.2475
Epoch 7 Step 151 Train Loss: 0.1770
Epoch 7 Step 201 Train Loss: 0.2224
Epoch 7 Step 251 Train Loss: 0.2397
Epoch 7 Step 301 Train Loss: 0.2767
Epoch 7 Step 351 Train Loss: 0.2492
Epoch 7 Step 401 Train Loss: 0.2440
Epoch 7 Step 451 Train Loss: 0.3009
Epoch 7 Step 501 Train Loss: 0.2691
Epoch 7 Step 551 Train Loss: 0.2337
Epoch 7 Step 601 Train Loss: 0.2925
Epoch 7 Step 651 Train Loss: 0.2789
Epoch 7 Step 701 Train Loss: 0.2724
Epoch 7 Step 751 Train Loss: 0.2239
Epoch 7 Step 801 Train Loss: 0.2757
Epoch 7 Step 851 Train Loss: 0.2596
Epoch 7 Step 901 Train Loss: 0.2426
Epoch 7 Step 951 Train Loss: 0.2152
Epoch 7 Step 1001 Train Loss: 0.2190
Epoch 7 Step 1051 Train Loss: 0.1953
Epoch 7 Step 1101 Train Loss: 0.2588
Epoch 7 Step 1151 Train Loss: 0.2103
Epoch 7 Step 1201 Train Loss: 0.2706
Epoch 7 Step 1251 Train Loss: 0.2913
Epoch 7 Step 1301 Train Loss: 0.1891
Epoch 7 Step 1351 Train Loss: 0.3351
Epoch 7: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0125. 
Epoch 8 Step 1 Train Loss: 0.2319
Epoch 8 Step 51 Train Loss: 0.2247
Epoch 8 Step 101 Train Loss: 0.2496
Epoch 8 Step 151 Train Loss: 0.2755
Epoch 8 Step 201 Train Loss: 0.3398
Epoch 8 Step 251 Train Loss: 0.2852
Epoch 8 Step 301 Train Loss: 0.2329
Epoch 8 Step 351 Train Loss: 0.3803
Epoch 8 Step 401 Train Loss: 0.2146
Epoch 8 Step 451 Train Loss: 0.2942
Epoch 8 Step 501 Train Loss: 0.2292
Epoch 8 Step 551 Train Loss: 0.2601
Epoch 8 Step 601 Train Loss: 0.3087
Epoch 8 Step 651 Train Loss: 0.2686
Epoch 8 Step 701 Train Loss: 0.2479
Epoch 8 Step 751 Train Loss: 0.3471
Epoch 8 Step 801 Train Loss: 0.2974
Epoch 8 Step 851 Train Loss: 0.3054
Epoch 8 Step 901 Train Loss: 0.2719
Epoch 8 Step 951 Train Loss: 0.2940
Epoch 8 Step 1001 Train Loss: 0.2835
Epoch 8 Step 1051 Train Loss: 0.2549
Epoch 8 Step 1101 Train Loss: 0.2553
Epoch 8 Step 1151 Train Loss: 0.2500
Epoch 8 Step 1201 Train Loss: 0.3016
Epoch 8 Step 1251 Train Loss: 0.2895
Epoch 8 Step 1301 Train Loss: 0.3167
Epoch 8 Step 1351 Train Loss: 0.2327
Epoch 8: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0095. 
Epoch 9 Step 1 Train Loss: 0.2325
Epoch 9 Step 51 Train Loss: 0.2798
Epoch 9 Step 101 Train Loss: 0.2367
Epoch 9 Step 151 Train Loss: 0.2420
Epoch 9 Step 201 Train Loss: 0.2653
Epoch 9 Step 251 Train Loss: 0.3118
Epoch 9 Step 301 Train Loss: 0.2655
Epoch 9 Step 351 Train Loss: 0.2502
Epoch 9 Step 401 Train Loss: 0.2638
Epoch 9 Step 451 Train Loss: 0.2522
Epoch 9 Step 501 Train Loss: 0.1976
Epoch 9 Step 551 Train Loss: 0.2912
Epoch 9 Step 601 Train Loss: 0.3439
Epoch 9 Step 651 Train Loss: 0.3278
Epoch 9 Step 701 Train Loss: 0.2583
Epoch 9 Step 751 Train Loss: 0.2881
Epoch 9 Step 801 Train Loss: 0.2452
Epoch 9 Step 851 Train Loss: 0.1747
Epoch 9 Step 901 Train Loss: 0.2246
Epoch 9 Step 951 Train Loss: 0.2110
Epoch 9 Step 1001 Train Loss: 0.3086
Epoch 9 Step 1051 Train Loss: 0.2008
Epoch 9 Step 1101 Train Loss: 0.2556
Epoch 9 Step 1151 Train Loss: 0.2669
Epoch 9 Step 1201 Train Loss: 0.2267
Epoch 9 Step 1251 Train Loss: 0.2326
Epoch 9 Step 1301 Train Loss: 0.3124
Epoch 9 Step 1351 Train Loss: 0.2103
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0095 Validation Top 20 DE MSE: 0.0102. 
Epoch 10 Step 1 Train Loss: 0.3441
Epoch 10 Step 51 Train Loss: 0.2951
Epoch 10 Step 101 Train Loss: 0.2587
Epoch 10 Step 151 Train Loss: 0.2634
Epoch 10 Step 201 Train Loss: 0.2524
Epoch 10 Step 251 Train Loss: 0.2487
Epoch 10 Step 301 Train Loss: 0.2080
Epoch 10 Step 351 Train Loss: 0.2525
Epoch 10 Step 401 Train Loss: 0.2812
Epoch 10 Step 451 Train Loss: 0.2230
Epoch 10 Step 501 Train Loss: 0.2270
Epoch 10 Step 551 Train Loss: 0.2357
Epoch 10 Step 601 Train Loss: 0.2364
Epoch 10 Step 651 Train Loss: 0.2816
Epoch 10 Step 701 Train Loss: 0.2440
Epoch 10 Step 751 Train Loss: 0.2751
Epoch 10 Step 801 Train Loss: 0.2393
Epoch 10 Step 851 Train Loss: 0.2683
Epoch 10 Step 901 Train Loss: 0.2230
Epoch 10 Step 951 Train Loss: 0.2810
Epoch 10 Step 1001 Train Loss: 0.3396
Epoch 10 Step 1051 Train Loss: 0.3069
Epoch 10 Step 1101 Train Loss: 0.2913
Epoch 10 Step 1151 Train Loss: 0.2671
Epoch 10 Step 1201 Train Loss: 0.3145
Epoch 10 Step 1251 Train Loss: 0.2290
Epoch 10 Step 1301 Train Loss: 0.2773
Epoch 10 Step 1351 Train Loss: 0.2961
Epoch 10: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0092. 
Epoch 11 Step 1 Train Loss: 0.2715
Epoch 11 Step 51 Train Loss: 0.1989
Epoch 11 Step 101 Train Loss: 0.2704
Epoch 11 Step 151 Train Loss: 0.3091
Epoch 11 Step 201 Train Loss: 0.2164
Epoch 11 Step 251 Train Loss: 0.3129
Epoch 11 Step 301 Train Loss: 0.2397
Epoch 11 Step 351 Train Loss: 0.2369
Epoch 11 Step 401 Train Loss: 0.2185
Epoch 11 Step 451 Train Loss: 0.2257
Epoch 11 Step 501 Train Loss: 0.2695
Epoch 11 Step 551 Train Loss: 0.2944
Epoch 11 Step 601 Train Loss: 0.2395
Epoch 11 Step 651 Train Loss: 0.2962
Epoch 11 Step 701 Train Loss: 0.2696
Epoch 11 Step 751 Train Loss: 0.2632
Epoch 11 Step 801 Train Loss: 0.3548
Epoch 11 Step 851 Train Loss: 0.2119
Epoch 11 Step 901 Train Loss: 0.2289
Epoch 11 Step 951 Train Loss: 0.2389
Epoch 11 Step 1001 Train Loss: 0.2251
Epoch 11 Step 1051 Train Loss: 0.2637
Epoch 11 Step 1101 Train Loss: 0.2779
Epoch 11 Step 1151 Train Loss: 0.3374
Epoch 11 Step 1201 Train Loss: 0.3179
Epoch 11 Step 1251 Train Loss: 0.2562
Epoch 11 Step 1301 Train Loss: 0.2862
Epoch 11 Step 1351 Train Loss: 0.2767
Epoch 11: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0015. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0088. 
Epoch 12 Step 1 Train Loss: 0.2168
Epoch 12 Step 51 Train Loss: 0.3283
Epoch 12 Step 101 Train Loss: 0.2666
Epoch 12 Step 151 Train Loss: 0.2927
Epoch 12 Step 201 Train Loss: 0.2830
Epoch 12 Step 251 Train Loss: 0.3373
Epoch 12 Step 301 Train Loss: 0.2061
Epoch 12 Step 351 Train Loss: 0.2518
Epoch 12 Step 401 Train Loss: 0.2356
Epoch 12 Step 451 Train Loss: 0.2717
Epoch 12 Step 501 Train Loss: 0.2190
Epoch 12 Step 551 Train Loss: 0.3063
Epoch 12 Step 601 Train Loss: 0.2141
Epoch 12 Step 651 Train Loss: 0.2477
Epoch 12 Step 701 Train Loss: 0.2762
Epoch 12 Step 751 Train Loss: 0.2584
Epoch 12 Step 801 Train Loss: 0.3550
Epoch 12 Step 851 Train Loss: 0.2968
Epoch 12 Step 901 Train Loss: 0.3042
Epoch 12 Step 951 Train Loss: 0.2847
Epoch 12 Step 1001 Train Loss: 0.2419
Epoch 12 Step 1051 Train Loss: 0.2090
Epoch 12 Step 1101 Train Loss: 0.2990
Epoch 12 Step 1151 Train Loss: 0.2410
Epoch 12 Step 1201 Train Loss: 0.2074
Epoch 12 Step 1251 Train Loss: 0.2447
Epoch 12 Step 1301 Train Loss: 0.3007
Epoch 12 Step 1351 Train Loss: 0.2723
Epoch 12: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0091. 
Epoch 13 Step 1 Train Loss: 0.2375
Epoch 13 Step 51 Train Loss: 0.2160
Epoch 13 Step 101 Train Loss: 0.3096
Epoch 13 Step 151 Train Loss: 0.2429
Epoch 13 Step 201 Train Loss: 0.2794
Epoch 13 Step 251 Train Loss: 0.1870
Epoch 13 Step 301 Train Loss: 0.2150
Epoch 13 Step 351 Train Loss: 0.2957
Epoch 13 Step 401 Train Loss: 0.2655
Epoch 13 Step 451 Train Loss: 0.2701
Epoch 13 Step 501 Train Loss: 0.2226
Epoch 13 Step 551 Train Loss: 0.2542
Epoch 13 Step 601 Train Loss: 0.2488
Epoch 13 Step 651 Train Loss: 0.2531
Epoch 13 Step 701 Train Loss: 0.3983
Epoch 13 Step 751 Train Loss: 0.2377
Epoch 13 Step 801 Train Loss: 0.2320
Epoch 13 Step 851 Train Loss: 0.2980
Epoch 13 Step 901 Train Loss: 0.2534
Epoch 13 Step 951 Train Loss: 0.2590
Epoch 13 Step 1001 Train Loss: 0.3014
Epoch 13 Step 1051 Train Loss: 0.3120
Epoch 13 Step 1101 Train Loss: 0.2802
Epoch 13 Step 1151 Train Loss: 0.2758
Epoch 13 Step 1201 Train Loss: 0.2894
Epoch 13 Step 1251 Train Loss: 0.2815
Epoch 13 Step 1301 Train Loss: 0.2811
Epoch 13 Step 1351 Train Loss: 0.2330
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0096. 
Epoch 14 Step 1 Train Loss: 0.2131
Epoch 14 Step 51 Train Loss: 0.3083
Epoch 14 Step 101 Train Loss: 0.2363
Epoch 14 Step 151 Train Loss: 0.2712
Epoch 14 Step 201 Train Loss: 0.2172
Epoch 14 Step 251 Train Loss: 0.2821
Epoch 14 Step 301 Train Loss: 0.2931
Epoch 14 Step 351 Train Loss: 0.2556
Epoch 14 Step 401 Train Loss: 0.2874
Epoch 14 Step 451 Train Loss: 0.2952
Epoch 14 Step 501 Train Loss: 0.2276
Epoch 14 Step 551 Train Loss: 0.2990
Epoch 14 Step 601 Train Loss: 0.2664
Epoch 14 Step 651 Train Loss: 0.2645
Epoch 14 Step 701 Train Loss: 0.2374
Epoch 14 Step 751 Train Loss: 0.2296
Epoch 14 Step 801 Train Loss: 0.2736
Epoch 14 Step 851 Train Loss: 0.2263
Epoch 14 Step 901 Train Loss: 0.2432
Epoch 14 Step 951 Train Loss: 0.2504
Epoch 14 Step 1001 Train Loss: 0.2507
Epoch 14 Step 1051 Train Loss: 0.3611
Epoch 14 Step 1101 Train Loss: 0.2585
Epoch 14 Step 1151 Train Loss: 0.3503
Epoch 14 Step 1201 Train Loss: 0.2470
Epoch 14 Step 1251 Train Loss: 0.2298
Epoch 14 Step 1301 Train Loss: 0.2890
Epoch 14 Step 1351 Train Loss: 0.2745
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0102. 
Epoch 15 Step 1 Train Loss: 0.2846
Epoch 15 Step 51 Train Loss: 0.2691
Epoch 15 Step 101 Train Loss: 0.3486
Epoch 15 Step 151 Train Loss: 0.1902
Epoch 15 Step 201 Train Loss: 0.2318
Epoch 15 Step 251 Train Loss: 0.2043
Epoch 15 Step 301 Train Loss: 0.2143
Epoch 15 Step 351 Train Loss: 0.3005
Epoch 15 Step 401 Train Loss: 0.2773
Epoch 15 Step 451 Train Loss: 0.1853
Epoch 15 Step 501 Train Loss: 0.1969
Epoch 15 Step 551 Train Loss: 0.2012
Epoch 15 Step 601 Train Loss: 0.2855
Epoch 15 Step 651 Train Loss: 0.2439
Epoch 15 Step 701 Train Loss: 0.2062
Epoch 15 Step 751 Train Loss: 0.2939
Epoch 15 Step 801 Train Loss: 0.2601
Epoch 15 Step 851 Train Loss: 0.2529
Epoch 15 Step 901 Train Loss: 0.2199
Epoch 15 Step 951 Train Loss: 0.2111
Epoch 15 Step 1001 Train Loss: 0.2891
Epoch 15 Step 1051 Train Loss: 0.3024
Epoch 15 Step 1101 Train Loss: 0.1900
Epoch 15 Step 1151 Train Loss: 0.2534
Epoch 15 Step 1201 Train Loss: 0.2856
Epoch 15 Step 1251 Train Loss: 0.2866
Epoch 15 Step 1301 Train Loss: 0.2464
Epoch 15 Step 1351 Train Loss: 0.2838
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0096. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0084
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0014844647
test_unseen_single_pearson: 0.9932832848145068
test_unseen_single_mse_de: 0.008363677
test_unseen_single_pearson_de: 0.9981454268816133
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.893099557497673
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.0
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9400000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.009260565
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.032 MB uploadedwandb: / 0.001 MB of 0.032 MB uploadedwandb: - 0.032 MB of 0.032 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÑ‚ñÅ‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ
wandb:                                                    train_mse ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:                                                      val_mse ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                                                  val_pearson ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.00836
wandb:                                              test_de_pearson 0.99815
wandb:               test_frac_opposite_direction_top20_non_dropout 0.0
wandb:                          test_frac_sigma_below_1_non_dropout 0.94
wandb:                                                     test_mse 0.00148
wandb:                                test_mse_top20_de_non_dropout 0.00926
wandb:                                                 test_pearson 0.99328
wandb:                                           test_pearson_delta 0.8931
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.0
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.94
wandb:                                       test_unseen_single_mse 0.00148
wandb:                                    test_unseen_single_mse_de 0.00836
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.00926
wandb:                                   test_unseen_single_pearson 0.99328
wandb:                                test_unseen_single_pearson_de 0.99815
wandb:                             test_unseen_single_pearson_delta 0.8931
wandb:                                                 train_de_mse 0.00928
wandb:                                             train_de_pearson 0.97547
wandb:                                                    train_mse 0.00118
wandb:                                                train_pearson 0.99472
wandb:                                                training_loss 0.23575
wandb:                                                   val_de_mse 0.00961
wandb:                                               val_de_pearson 0.99776
wandb:                                                      val_mse 0.00137
wandb:                                                  val_pearson 0.99403
wandb: 
wandb: üöÄ View run scbert_ShifrutMarson2018_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/fr862ayk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_133057-fr862ayk/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_135535-rezyylae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_ShifrutMarson2018_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/rezyylae
wandb: WARNING Serializing object of type ndarray that is 8012928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3924
Epoch 1 Step 51 Train Loss: 0.3465
Epoch 1 Step 101 Train Loss: 0.2969
Epoch 1 Step 151 Train Loss: 0.3040
Epoch 1 Step 201 Train Loss: 0.2727
Epoch 1 Step 251 Train Loss: 0.3307
Epoch 1 Step 301 Train Loss: 0.3998
Epoch 1 Step 351 Train Loss: 0.2732
Epoch 1 Step 401 Train Loss: 0.2559
Epoch 1 Step 451 Train Loss: 0.2521
Epoch 1 Step 501 Train Loss: 0.2259
Epoch 1 Step 551 Train Loss: 0.2702
Epoch 1 Step 601 Train Loss: 0.2043
Epoch 1 Step 651 Train Loss: 0.2572
Epoch 1 Step 701 Train Loss: 0.2432
Epoch 1 Step 751 Train Loss: 0.3000
Epoch 1 Step 801 Train Loss: 0.3562
Epoch 1 Step 851 Train Loss: 0.2305
Epoch 1 Step 901 Train Loss: 0.1659
Epoch 1 Step 951 Train Loss: 0.2308
Epoch 1 Step 1001 Train Loss: 0.2783
Epoch 1 Step 1051 Train Loss: 0.2799
Epoch 1 Step 1101 Train Loss: 0.3737
Epoch 1 Step 1151 Train Loss: 0.2488
Epoch 1 Step 1201 Train Loss: 0.2743
Epoch 1 Step 1251 Train Loss: 0.2377
Epoch 1 Step 1301 Train Loss: 0.2393
Epoch 1 Step 1351 Train Loss: 0.2037
Epoch 1: Train Overall MSE: 0.0044 Validation Overall MSE: 0.0043. 
Train Top 20 DE MSE: 0.0210 Validation Top 20 DE MSE: 0.0203. 
Epoch 2 Step 1 Train Loss: 0.1932
Epoch 2 Step 51 Train Loss: 0.2288
Epoch 2 Step 101 Train Loss: 0.2236
Epoch 2 Step 151 Train Loss: 0.2334
Epoch 2 Step 201 Train Loss: 0.2809
Epoch 2 Step 251 Train Loss: 0.1966
Epoch 2 Step 301 Train Loss: 0.2513
Epoch 2 Step 351 Train Loss: 0.2417
Epoch 2 Step 401 Train Loss: 0.2455
Epoch 2 Step 451 Train Loss: 0.2192
Epoch 2 Step 501 Train Loss: 0.2718
Epoch 2 Step 551 Train Loss: 0.2061
Epoch 2 Step 601 Train Loss: 0.2121
Epoch 2 Step 651 Train Loss: 0.2329
Epoch 2 Step 701 Train Loss: 0.2202
Epoch 2 Step 751 Train Loss: 0.2476
Epoch 2 Step 801 Train Loss: 0.2503
Epoch 2 Step 851 Train Loss: 0.2996
Epoch 2 Step 901 Train Loss: 0.3015
Epoch 2 Step 951 Train Loss: 0.3209
Epoch 2 Step 1001 Train Loss: 0.2575
Epoch 2 Step 1051 Train Loss: 0.2377
Epoch 2 Step 1101 Train Loss: 0.2257
Epoch 2 Step 1151 Train Loss: 0.2961
Epoch 2 Step 1201 Train Loss: 0.1482
Epoch 2 Step 1251 Train Loss: 0.3625
Epoch 2 Step 1301 Train Loss: 0.2632
Epoch 2 Step 1351 Train Loss: 0.2223
Epoch 2: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0094. 
Epoch 3 Step 1 Train Loss: 0.2740
Epoch 3 Step 51 Train Loss: 0.2115
Epoch 3 Step 101 Train Loss: 0.2398
Epoch 3 Step 151 Train Loss: 0.3191
Epoch 3 Step 201 Train Loss: 0.2539
Epoch 3 Step 251 Train Loss: 0.2795
Epoch 3 Step 301 Train Loss: 0.2596
Epoch 3 Step 351 Train Loss: 0.3552
Epoch 3 Step 401 Train Loss: 0.2082
Epoch 3 Step 451 Train Loss: 0.2007
Epoch 3 Step 501 Train Loss: 0.2947
Epoch 3 Step 551 Train Loss: 0.2067
Epoch 3 Step 601 Train Loss: 0.2458
Epoch 3 Step 651 Train Loss: 0.1980
Epoch 3 Step 701 Train Loss: 0.2983
Epoch 3 Step 751 Train Loss: 0.2229
Epoch 3 Step 801 Train Loss: 0.1456
Epoch 3 Step 851 Train Loss: 0.2218
Epoch 3 Step 901 Train Loss: 0.2445
Epoch 3 Step 951 Train Loss: 0.2309
Epoch 3 Step 1001 Train Loss: 0.2385
Epoch 3 Step 1051 Train Loss: 0.2792
Epoch 3 Step 1101 Train Loss: 0.3185
Epoch 3 Step 1151 Train Loss: 0.2703
Epoch 3 Step 1201 Train Loss: 0.2745
Epoch 3 Step 1251 Train Loss: 0.1867
Epoch 3 Step 1301 Train Loss: 0.2951
Epoch 3 Step 1351 Train Loss: 0.3013
Epoch 3: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0107 Validation Top 20 DE MSE: 0.0089. 
Epoch 4 Step 1 Train Loss: 0.2369
Epoch 4 Step 51 Train Loss: 0.2833
Epoch 4 Step 101 Train Loss: 0.2600
Epoch 4 Step 151 Train Loss: 0.2161
Epoch 4 Step 201 Train Loss: 0.2157
Epoch 4 Step 251 Train Loss: 0.0389
Epoch 4 Step 301 Train Loss: 0.2589
Epoch 4 Step 351 Train Loss: 0.2335
Epoch 4 Step 401 Train Loss: 0.2587
Epoch 4 Step 451 Train Loss: 0.2939
Epoch 4 Step 501 Train Loss: 0.2489
Epoch 4 Step 551 Train Loss: 0.2043
Epoch 4 Step 601 Train Loss: 0.2822
Epoch 4 Step 651 Train Loss: 0.2760
Epoch 4 Step 701 Train Loss: 0.2944
Epoch 4 Step 751 Train Loss: 0.2771
Epoch 4 Step 801 Train Loss: 0.2348
Epoch 4 Step 851 Train Loss: 0.2089
Epoch 4 Step 901 Train Loss: 0.3315
Epoch 4 Step 951 Train Loss: 0.2328
Epoch 4 Step 1001 Train Loss: 0.2791
Epoch 4 Step 1051 Train Loss: 0.2321
Epoch 4 Step 1101 Train Loss: 0.2679
Epoch 4 Step 1151 Train Loss: 0.1714
Epoch 4 Step 1201 Train Loss: 0.2469
Epoch 4 Step 1251 Train Loss: 0.2435
Epoch 4 Step 1301 Train Loss: 0.2444
Epoch 4 Step 1351 Train Loss: 0.2363
Epoch 4: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0031. 
Train Top 20 DE MSE: 0.0116 Validation Top 20 DE MSE: 0.0161. 
Epoch 5 Step 1 Train Loss: 0.2853
Epoch 5 Step 51 Train Loss: 0.3803
Epoch 5 Step 101 Train Loss: 0.2642
Epoch 5 Step 151 Train Loss: 0.2124
Epoch 5 Step 201 Train Loss: 0.2811
Epoch 5 Step 251 Train Loss: 0.3412
Epoch 5 Step 301 Train Loss: 0.2798
Epoch 5 Step 351 Train Loss: 0.2804
Epoch 5 Step 401 Train Loss: 0.2321
Epoch 5 Step 451 Train Loss: 0.3162
Epoch 5 Step 501 Train Loss: 0.2699
Epoch 5 Step 551 Train Loss: 0.2343
Epoch 5 Step 601 Train Loss: 0.2319
Epoch 5 Step 651 Train Loss: 0.1874
Epoch 5 Step 701 Train Loss: 0.1774
Epoch 5 Step 751 Train Loss: 0.2275
Epoch 5 Step 801 Train Loss: 0.2100
Epoch 5 Step 851 Train Loss: 0.2057
Epoch 5 Step 901 Train Loss: 0.2950
Epoch 5 Step 951 Train Loss: 0.1704
Epoch 5 Step 1001 Train Loss: 0.2256
Epoch 5 Step 1051 Train Loss: 0.2667
Epoch 5 Step 1101 Train Loss: 0.2871
Epoch 5 Step 1151 Train Loss: 0.2021
Epoch 5 Step 1201 Train Loss: 0.2634
Epoch 5 Step 1251 Train Loss: 0.2942
Epoch 5 Step 1301 Train Loss: 0.2607
Epoch 5 Step 1351 Train Loss: 0.3253
Epoch 5: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0104 Validation Top 20 DE MSE: 0.0087. 
Epoch 6 Step 1 Train Loss: 0.3432
Epoch 6 Step 51 Train Loss: 0.1740
Epoch 6 Step 101 Train Loss: 0.2214
Epoch 6 Step 151 Train Loss: 0.2921
Epoch 6 Step 201 Train Loss: 0.1996
Epoch 6 Step 251 Train Loss: 0.3362
Epoch 6 Step 301 Train Loss: 0.2622
Epoch 6 Step 351 Train Loss: 0.4198
Epoch 6 Step 401 Train Loss: 0.2322
Epoch 6 Step 451 Train Loss: 0.2132
Epoch 6 Step 501 Train Loss: 0.2409
Epoch 6 Step 551 Train Loss: 0.2236
Epoch 6 Step 601 Train Loss: 0.2780
Epoch 6 Step 651 Train Loss: 0.2943
Epoch 6 Step 701 Train Loss: 0.2553
Epoch 6 Step 751 Train Loss: 0.1732
Epoch 6 Step 801 Train Loss: 0.2394
Epoch 6 Step 851 Train Loss: 0.3459
Epoch 6 Step 901 Train Loss: 0.2150
Epoch 6 Step 951 Train Loss: 0.2560
Epoch 6 Step 1001 Train Loss: 0.2768
Epoch 6 Step 1051 Train Loss: 0.3146
Epoch 6 Step 1101 Train Loss: 0.2634
Epoch 6 Step 1151 Train Loss: 0.2754
Epoch 6 Step 1201 Train Loss: 0.2904
Epoch 6 Step 1251 Train Loss: 0.2432
Epoch 6 Step 1301 Train Loss: 0.1998
Epoch 6 Step 1351 Train Loss: 0.2111
Epoch 6: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0082. 
Epoch 7 Step 1 Train Loss: 0.2674
Epoch 7 Step 51 Train Loss: 0.2818
Epoch 7 Step 101 Train Loss: 0.2698
Epoch 7 Step 151 Train Loss: 0.2671
Epoch 7 Step 201 Train Loss: 0.2279
Epoch 7 Step 251 Train Loss: 0.3186
Epoch 7 Step 301 Train Loss: 0.3170
Epoch 7 Step 351 Train Loss: 0.2456
Epoch 7 Step 401 Train Loss: 0.2657
Epoch 7 Step 451 Train Loss: 0.4009
Epoch 7 Step 501 Train Loss: 0.3357
Epoch 7 Step 551 Train Loss: 0.2541
Epoch 7 Step 601 Train Loss: 0.2619
Epoch 7 Step 651 Train Loss: 0.3518
Epoch 7 Step 701 Train Loss: 0.2618
Epoch 7 Step 751 Train Loss: 0.2964
Epoch 7 Step 801 Train Loss: 0.2969
Epoch 7 Step 851 Train Loss: 0.3019
Epoch 7 Step 901 Train Loss: 0.2994
Epoch 7 Step 951 Train Loss: 0.3117
Epoch 7 Step 1001 Train Loss: 0.2816
Epoch 7 Step 1051 Train Loss: 0.2839
Epoch 7 Step 1101 Train Loss: 0.3049
Epoch 7 Step 1151 Train Loss: 0.3539
Epoch 7 Step 1201 Train Loss: 0.1993
Epoch 7 Step 1251 Train Loss: 0.2312
Epoch 7 Step 1301 Train Loss: 0.2489
Epoch 7 Step 1351 Train Loss: 0.2200
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0014. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0082. 
Epoch 8 Step 1 Train Loss: 0.2443
Epoch 8 Step 51 Train Loss: 0.2147
Epoch 8 Step 101 Train Loss: 0.2267
Epoch 8 Step 151 Train Loss: 0.1888
Epoch 8 Step 201 Train Loss: 0.2619
Epoch 8 Step 251 Train Loss: 0.2687
Epoch 8 Step 301 Train Loss: 0.2039
Epoch 8 Step 351 Train Loss: 0.2415
Epoch 8 Step 401 Train Loss: 0.1750
Epoch 8 Step 451 Train Loss: 0.2357
Epoch 8 Step 501 Train Loss: 0.2489
Epoch 8 Step 551 Train Loss: 0.2530
Epoch 8 Step 601 Train Loss: 0.2521
Epoch 8 Step 651 Train Loss: 0.2536
Epoch 8 Step 701 Train Loss: 0.2804
Epoch 8 Step 751 Train Loss: 0.3117
Epoch 8 Step 801 Train Loss: 0.2692
Epoch 8 Step 851 Train Loss: 0.3386
Epoch 8 Step 901 Train Loss: 0.2473
Epoch 8 Step 951 Train Loss: 0.2487
Epoch 8 Step 1001 Train Loss: 0.2252
Epoch 8 Step 1051 Train Loss: 0.2744
Epoch 8 Step 1101 Train Loss: 0.1717
Epoch 8 Step 1151 Train Loss: 0.2809
Epoch 8 Step 1201 Train Loss: 0.3245
Epoch 8 Step 1251 Train Loss: 0.2636
Epoch 8 Step 1301 Train Loss: 0.3152
Epoch 8 Step 1351 Train Loss: 0.2787
Epoch 8: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0087 Validation Top 20 DE MSE: 0.0092. 
Epoch 9 Step 1 Train Loss: 0.3147
Epoch 9 Step 51 Train Loss: 0.2215
Epoch 9 Step 101 Train Loss: 0.2630
Epoch 9 Step 151 Train Loss: 0.2373
Epoch 9 Step 201 Train Loss: 0.3069
Epoch 9 Step 251 Train Loss: 0.2272
Epoch 9 Step 301 Train Loss: 0.2382
Epoch 9 Step 351 Train Loss: 0.2517
Epoch 9 Step 401 Train Loss: 0.2760
Epoch 9 Step 451 Train Loss: 0.2188
Epoch 9 Step 501 Train Loss: 0.2243
Epoch 9 Step 551 Train Loss: 0.2675
Epoch 9 Step 601 Train Loss: 0.2467
Epoch 9 Step 651 Train Loss: 0.3287
Epoch 9 Step 701 Train Loss: 0.2471
Epoch 9 Step 751 Train Loss: 0.2696
Epoch 9 Step 801 Train Loss: 0.2480
Epoch 9 Step 851 Train Loss: 0.1850
Epoch 9 Step 901 Train Loss: 0.3350
Epoch 9 Step 951 Train Loss: 0.2570
Epoch 9 Step 1001 Train Loss: 0.2693
Epoch 9 Step 1051 Train Loss: 0.2207
Epoch 9 Step 1101 Train Loss: 0.2883
Epoch 9 Step 1151 Train Loss: 0.3019
Epoch 9 Step 1201 Train Loss: 0.2660
Epoch 9 Step 1251 Train Loss: 0.2567
Epoch 9 Step 1301 Train Loss: 0.3039
Epoch 9 Step 1351 Train Loss: 0.3294
Epoch 9: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0087. 
Epoch 10 Step 1 Train Loss: 0.2869
Epoch 10 Step 51 Train Loss: 0.1398
Epoch 10 Step 101 Train Loss: 0.2183
Epoch 10 Step 151 Train Loss: 0.2346
Epoch 10 Step 201 Train Loss: 0.2339
Epoch 10 Step 251 Train Loss: 0.2588
Epoch 10 Step 301 Train Loss: 0.2764
Epoch 10 Step 351 Train Loss: 0.3278
Epoch 10 Step 401 Train Loss: 0.3128
Epoch 10 Step 451 Train Loss: 0.2426
Epoch 10 Step 501 Train Loss: 0.2432
Epoch 10 Step 551 Train Loss: 0.2988
Epoch 10 Step 601 Train Loss: 0.3179
Epoch 10 Step 651 Train Loss: 0.2054
Epoch 10 Step 701 Train Loss: 0.2513
Epoch 10 Step 751 Train Loss: 0.3314
Epoch 10 Step 801 Train Loss: 0.2923
Epoch 10 Step 851 Train Loss: 0.3106
Epoch 10 Step 901 Train Loss: 0.2326
Epoch 10 Step 951 Train Loss: 0.2172
Epoch 10 Step 1001 Train Loss: 0.2367
Epoch 10 Step 1051 Train Loss: 0.2484
Epoch 10 Step 1101 Train Loss: 0.2642
Epoch 10 Step 1151 Train Loss: 0.2759
Epoch 10 Step 1201 Train Loss: 0.2181
Epoch 10 Step 1251 Train Loss: 0.2273
Epoch 10 Step 1301 Train Loss: 0.2226
Epoch 10 Step 1351 Train Loss: 0.2310
Epoch 10: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0086. 
Epoch 11 Step 1 Train Loss: 0.2345
Epoch 11 Step 51 Train Loss: 0.2562
Epoch 11 Step 101 Train Loss: 0.2465
Epoch 11 Step 151 Train Loss: 0.2756
Epoch 11 Step 201 Train Loss: 0.2498
Epoch 11 Step 251 Train Loss: 0.2522
Epoch 11 Step 301 Train Loss: 0.3073
Epoch 11 Step 351 Train Loss: 0.3116
Epoch 11 Step 401 Train Loss: 0.2643
Epoch 11 Step 451 Train Loss: 0.2398
Epoch 11 Step 501 Train Loss: 0.3034
Epoch 11 Step 551 Train Loss: 0.3023
Epoch 11 Step 601 Train Loss: 0.2577
Epoch 11 Step 651 Train Loss: 0.2329
Epoch 11 Step 701 Train Loss: 0.2581
Epoch 11 Step 751 Train Loss: 0.2496
Epoch 11 Step 801 Train Loss: 0.3306
Epoch 11 Step 851 Train Loss: 0.3770
Epoch 11 Step 901 Train Loss: 0.3340
Epoch 11 Step 951 Train Loss: 0.2202
Epoch 11 Step 1001 Train Loss: 0.3019
Epoch 11 Step 1051 Train Loss: 0.2687
Epoch 11 Step 1101 Train Loss: 0.2479
Epoch 11 Step 1151 Train Loss: 0.2446
Epoch 11 Step 1201 Train Loss: 0.2258
Epoch 11 Step 1251 Train Loss: 0.2695
Epoch 11 Step 1301 Train Loss: 0.2560
Epoch 11 Step 1351 Train Loss: 0.2271
Epoch 11: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0090 Validation Top 20 DE MSE: 0.0092. 
Epoch 12 Step 1 Train Loss: 0.3192
Epoch 12 Step 51 Train Loss: 0.2761
Epoch 12 Step 101 Train Loss: 0.2294
Epoch 12 Step 151 Train Loss: 0.2484
Epoch 12 Step 201 Train Loss: 0.2675
Epoch 12 Step 251 Train Loss: 0.2052
Epoch 12 Step 301 Train Loss: 0.1943
Epoch 12 Step 351 Train Loss: 0.2283
Epoch 12 Step 401 Train Loss: 0.2842
Epoch 12 Step 451 Train Loss: 0.3296
Epoch 12 Step 501 Train Loss: 0.2349
Epoch 12 Step 551 Train Loss: 0.1950
Epoch 12 Step 601 Train Loss: 0.1673
Epoch 12 Step 651 Train Loss: 0.2453
Epoch 12 Step 701 Train Loss: 0.2309
Epoch 12 Step 751 Train Loss: 0.2722
Epoch 12 Step 801 Train Loss: 0.2755
Epoch 12 Step 851 Train Loss: 0.3474
Epoch 12 Step 901 Train Loss: 0.2377
Epoch 12 Step 951 Train Loss: 0.1816
Epoch 12 Step 1001 Train Loss: 0.2377
Epoch 12 Step 1051 Train Loss: 0.2661
Epoch 12 Step 1101 Train Loss: 0.3055
Epoch 12 Step 1151 Train Loss: 0.2713
Epoch 12 Step 1201 Train Loss: 0.2902
Epoch 12 Step 1251 Train Loss: 0.2720
Epoch 12 Step 1301 Train Loss: 0.2643
Epoch 12 Step 1351 Train Loss: 0.2558
Epoch 12: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0089. 
Epoch 13 Step 1 Train Loss: 0.1907
Epoch 13 Step 51 Train Loss: 0.2545
Epoch 13 Step 101 Train Loss: 0.3142
Epoch 13 Step 151 Train Loss: 0.2833
Epoch 13 Step 201 Train Loss: 0.2727
Epoch 13 Step 251 Train Loss: 0.2314
Epoch 13 Step 301 Train Loss: 0.2801
Epoch 13 Step 351 Train Loss: 0.2433
Epoch 13 Step 401 Train Loss: 0.3324
Epoch 13 Step 451 Train Loss: 0.1980
Epoch 13 Step 501 Train Loss: 0.2825
Epoch 13 Step 551 Train Loss: 0.2446
Epoch 13 Step 601 Train Loss: 0.2630
Epoch 13 Step 651 Train Loss: 0.2484
Epoch 13 Step 701 Train Loss: 0.3291
Epoch 13 Step 751 Train Loss: 0.2691
Epoch 13 Step 801 Train Loss: 0.2819
Epoch 13 Step 851 Train Loss: 0.2235
Epoch 13 Step 901 Train Loss: 0.2509
Epoch 13 Step 951 Train Loss: 0.2685
Epoch 13 Step 1001 Train Loss: 0.3227
Epoch 13 Step 1051 Train Loss: 0.2698
Epoch 13 Step 1101 Train Loss: 0.3424
Epoch 13 Step 1151 Train Loss: 0.2801
Epoch 13 Step 1201 Train Loss: 0.2674
Epoch 13 Step 1251 Train Loss: 0.1564
Epoch 13 Step 1301 Train Loss: 0.2293
Epoch 13 Step 1351 Train Loss: 0.2371
Epoch 13: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0085. 
Epoch 14 Step 1 Train Loss: 0.2410
Epoch 14 Step 51 Train Loss: 0.3384
Epoch 14 Step 101 Train Loss: 0.3042
Epoch 14 Step 151 Train Loss: 0.3349
Epoch 14 Step 201 Train Loss: 0.2876
Epoch 14 Step 251 Train Loss: 0.3429
Epoch 14 Step 301 Train Loss: 0.2567
Epoch 14 Step 351 Train Loss: 0.3451
Epoch 14 Step 401 Train Loss: 0.1985
Epoch 14 Step 451 Train Loss: 0.2183
Epoch 14 Step 501 Train Loss: 0.2099
Epoch 14 Step 551 Train Loss: 0.2798
Epoch 14 Step 601 Train Loss: 0.2874
Epoch 14 Step 651 Train Loss: 0.2550
Epoch 14 Step 701 Train Loss: 0.2807
Epoch 14 Step 751 Train Loss: 0.2629
Epoch 14 Step 801 Train Loss: 0.2817
Epoch 14 Step 851 Train Loss: 0.2414
Epoch 14 Step 901 Train Loss: 0.3303
Epoch 14 Step 951 Train Loss: 0.1779
Epoch 14 Step 1001 Train Loss: 0.2854
Epoch 14 Step 1051 Train Loss: 0.3369
Epoch 14 Step 1101 Train Loss: 0.3072
Epoch 14 Step 1151 Train Loss: 0.2638
Epoch 14 Step 1201 Train Loss: 0.2348
Epoch 14 Step 1251 Train Loss: 0.2513
Epoch 14 Step 1301 Train Loss: 0.3095
Epoch 14 Step 1351 Train Loss: 0.2023
Epoch 14: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0091 Validation Top 20 DE MSE: 0.0087. 
Epoch 15 Step 1 Train Loss: 0.2752
Epoch 15 Step 51 Train Loss: 0.2542
Epoch 15 Step 101 Train Loss: 0.2933
Epoch 15 Step 151 Train Loss: 0.3105
Epoch 15 Step 201 Train Loss: 0.3106
Epoch 15 Step 251 Train Loss: 0.2930
Epoch 15 Step 301 Train Loss: 0.2472
Epoch 15 Step 351 Train Loss: 0.2618
Epoch 15 Step 401 Train Loss: 0.2506
Epoch 15 Step 451 Train Loss: 0.3742
Epoch 15 Step 501 Train Loss: 0.2662
Epoch 15 Step 551 Train Loss: 0.2050
Epoch 15 Step 601 Train Loss: 0.2602
Epoch 15 Step 651 Train Loss: 0.1829
Epoch 15 Step 701 Train Loss: 0.3594
Epoch 15 Step 751 Train Loss: 0.3212
Epoch 15 Step 801 Train Loss: 0.3512
Epoch 15 Step 851 Train Loss: 0.2228
Epoch 15 Step 901 Train Loss: 0.3070
Epoch 15 Step 951 Train Loss: 0.3253
Epoch 15 Step 1001 Train Loss: 0.3633
Epoch 15 Step 1051 Train Loss: 0.2467
Epoch 15 Step 1101 Train Loss: 0.2586
Epoch 15 Step 1151 Train Loss: 0.2979
Epoch 15 Step 1201 Train Loss: 0.2478
Epoch 15 Step 1251 Train Loss: 0.2175
Epoch 15 Step 1301 Train Loss: 0.2792
Epoch 15 Step 1351 Train Loss: 0.2439
Epoch 15: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0016. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0084. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0120
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0011789113
test_unseen_single_pearson: 0.9945729804495429
test_unseen_single_mse_de: 0.012020823
test_unseen_single_pearson_de: 0.9966554104655163
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.9023697316069065
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.0
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9400000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.011992665
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.032 MB uploadedwandb: / 0.001 MB of 0.032 MB uploadedwandb: - 0.003 MB of 0.032 MB uploadedwandb: \ 0.003 MB of 0.032 MB uploadedwandb: | 0.032 MB of 0.032 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñÜ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà
wandb:                                                    train_mse ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñà‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÅ‚ñá‚ñÅ‚ñÉ‚ñá‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñá‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01202
wandb:                                              test_de_pearson 0.99666
wandb:               test_frac_opposite_direction_top20_non_dropout 0.0
wandb:                          test_frac_sigma_below_1_non_dropout 0.94
wandb:                                                     test_mse 0.00118
wandb:                                test_mse_top20_de_non_dropout 0.01199
wandb:                                                 test_pearson 0.99457
wandb:                                           test_pearson_delta 0.90237
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.0
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.94
wandb:                                       test_unseen_single_mse 0.00118
wandb:                                    test_unseen_single_mse_de 0.01202
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01199
wandb:                                   test_unseen_single_pearson 0.99457
wandb:                                test_unseen_single_pearson_de 0.99666
wandb:                             test_unseen_single_pearson_delta 0.90237
wandb:                                                 train_de_mse 0.00941
wandb:                                             train_de_pearson 0.97399
wandb:                                                    train_mse 0.00121
wandb:                                                train_pearson 0.99445
wandb:                                                training_loss 0.21191
wandb:                                                   val_de_mse 0.00843
wandb:                                               val_de_pearson 0.99852
wandb:                                                      val_mse 0.00155
wandb:                                                  val_pearson 0.99287
wandb: 
wandb: üöÄ View run scbert_ShifrutMarson2018_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/rezyylae
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_135535-rezyylae/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:5
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_141712-z3qmkc1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_ShifrutMarson2018_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/z3qmkc1m
wandb: WARNING Serializing object of type ndarray that is 8012928 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3677
Epoch 1 Step 51 Train Loss: 0.3347
Epoch 1 Step 101 Train Loss: 0.3577
Epoch 1 Step 151 Train Loss: 0.2367
Epoch 1 Step 201 Train Loss: 0.2570
Epoch 1 Step 251 Train Loss: 0.2830
Epoch 1 Step 301 Train Loss: 0.2744
Epoch 1 Step 351 Train Loss: 0.2454
Epoch 1 Step 401 Train Loss: 0.2603
Epoch 1 Step 451 Train Loss: 0.2757
Epoch 1 Step 501 Train Loss: 0.3500
Epoch 1 Step 551 Train Loss: 0.2040
Epoch 1 Step 601 Train Loss: 0.3009
Epoch 1 Step 651 Train Loss: 0.2607
Epoch 1 Step 701 Train Loss: 0.2516
Epoch 1 Step 751 Train Loss: 0.2651
Epoch 1 Step 801 Train Loss: 0.3192
Epoch 1 Step 851 Train Loss: 0.2751
Epoch 1 Step 901 Train Loss: 0.3758
Epoch 1 Step 951 Train Loss: 0.2822
Epoch 1 Step 1001 Train Loss: 0.2313
Epoch 1 Step 1051 Train Loss: 0.2550
Epoch 1 Step 1101 Train Loss: 0.2394
Epoch 1 Step 1151 Train Loss: 0.2003
Epoch 1 Step 1201 Train Loss: 0.3266
Epoch 1 Step 1251 Train Loss: 0.2621
Epoch 1 Step 1301 Train Loss: 0.2945
Epoch 1 Step 1351 Train Loss: 0.2072
Epoch 1 Step 1401 Train Loss: 0.3808
Epoch 1: Train Overall MSE: 0.0047 Validation Overall MSE: 0.0041. 
Train Top 20 DE MSE: 0.0126 Validation Top 20 DE MSE: 0.0091. 
Epoch 2 Step 1 Train Loss: 0.2702
Epoch 2 Step 51 Train Loss: 0.2854
Epoch 2 Step 101 Train Loss: 0.2877
Epoch 2 Step 151 Train Loss: 0.2171
Epoch 2 Step 201 Train Loss: 0.2421
Epoch 2 Step 251 Train Loss: 0.2568
Epoch 2 Step 301 Train Loss: 0.2261
Epoch 2 Step 351 Train Loss: 0.3344
Epoch 2 Step 401 Train Loss: 0.2262
Epoch 2 Step 451 Train Loss: 0.2896
Epoch 2 Step 501 Train Loss: 0.2051
Epoch 2 Step 551 Train Loss: 0.2094
Epoch 2 Step 601 Train Loss: 0.2339
Epoch 2 Step 651 Train Loss: 0.2608
Epoch 2 Step 701 Train Loss: 0.2280
Epoch 2 Step 751 Train Loss: 0.2387
Epoch 2 Step 801 Train Loss: 0.2803
Epoch 2 Step 851 Train Loss: 0.2433
Epoch 2 Step 901 Train Loss: 0.2421
Epoch 2 Step 951 Train Loss: 0.2989
Epoch 2 Step 1001 Train Loss: 0.2945
Epoch 2 Step 1051 Train Loss: 0.2903
Epoch 2 Step 1101 Train Loss: 0.2122
Epoch 2 Step 1151 Train Loss: 0.2320
Epoch 2 Step 1201 Train Loss: 0.2745
Epoch 2 Step 1251 Train Loss: 0.2874
Epoch 2 Step 1301 Train Loss: 0.2842
Epoch 2 Step 1351 Train Loss: 0.2283
Epoch 2 Step 1401 Train Loss: 0.2291
Epoch 2: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0017. 
Train Top 20 DE MSE: 0.0110 Validation Top 20 DE MSE: 0.0078. 
Epoch 3 Step 1 Train Loss: 0.2315
Epoch 3 Step 51 Train Loss: 0.2641
Epoch 3 Step 101 Train Loss: 0.2957
Epoch 3 Step 151 Train Loss: 0.2316
Epoch 3 Step 201 Train Loss: 0.1590
Epoch 3 Step 251 Train Loss: 0.2774
Epoch 3 Step 301 Train Loss: 0.2927
Epoch 3 Step 351 Train Loss: 0.2944
Epoch 3 Step 401 Train Loss: 0.2103
Epoch 3 Step 451 Train Loss: 0.2780
Epoch 3 Step 501 Train Loss: 0.3207
Epoch 3 Step 551 Train Loss: 0.3481
Epoch 3 Step 601 Train Loss: 0.3124
Epoch 3 Step 651 Train Loss: 0.3009
Epoch 3 Step 701 Train Loss: 0.2728
Epoch 3 Step 751 Train Loss: 0.1904
Epoch 3 Step 801 Train Loss: 0.2488
Epoch 3 Step 851 Train Loss: 0.2732
Epoch 3 Step 901 Train Loss: 0.2080
Epoch 3 Step 951 Train Loss: 0.2605
Epoch 3 Step 1001 Train Loss: 0.2214
Epoch 3 Step 1051 Train Loss: 0.2300
Epoch 3 Step 1101 Train Loss: 0.2418
Epoch 3 Step 1151 Train Loss: 0.2646
Epoch 3 Step 1201 Train Loss: 0.3064
Epoch 3 Step 1251 Train Loss: 0.2351
Epoch 3 Step 1301 Train Loss: 0.2928
Epoch 3 Step 1351 Train Loss: 0.2284
Epoch 3 Step 1401 Train Loss: 0.2380
Epoch 3: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0162 Validation Top 20 DE MSE: 0.0076. 
Epoch 4 Step 1 Train Loss: 0.2632
Epoch 4 Step 51 Train Loss: 0.2892
Epoch 4 Step 101 Train Loss: 0.3474
Epoch 4 Step 151 Train Loss: 0.2755
Epoch 4 Step 201 Train Loss: 0.3070
Epoch 4 Step 251 Train Loss: 0.2835
Epoch 4 Step 301 Train Loss: 0.2249
Epoch 4 Step 351 Train Loss: 0.2330
Epoch 4 Step 401 Train Loss: 0.2202
Epoch 4 Step 451 Train Loss: 0.2444
Epoch 4 Step 501 Train Loss: 0.2173
Epoch 4 Step 551 Train Loss: 0.3028
Epoch 4 Step 601 Train Loss: 0.2682
Epoch 4 Step 651 Train Loss: 0.2586
Epoch 4 Step 701 Train Loss: 0.2687
Epoch 4 Step 751 Train Loss: 0.2280
Epoch 4 Step 801 Train Loss: 0.2180
Epoch 4 Step 851 Train Loss: 0.3071
Epoch 4 Step 901 Train Loss: 0.2344
Epoch 4 Step 951 Train Loss: 0.2238
Epoch 4 Step 1001 Train Loss: 0.1737
Epoch 4 Step 1051 Train Loss: 0.2268
Epoch 4 Step 1101 Train Loss: 0.2700
Epoch 4 Step 1151 Train Loss: 0.1906
Epoch 4 Step 1201 Train Loss: 0.2544
Epoch 4 Step 1251 Train Loss: 0.2377
Epoch 4 Step 1301 Train Loss: 0.2577
Epoch 4 Step 1351 Train Loss: 0.2619
Epoch 4 Step 1401 Train Loss: 0.2046
Epoch 4: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0073. 
Epoch 5 Step 1 Train Loss: 0.2119
Epoch 5 Step 51 Train Loss: 0.2751
Epoch 5 Step 101 Train Loss: 0.2692
Epoch 5 Step 151 Train Loss: 0.2388
Epoch 5 Step 201 Train Loss: 0.3367
Epoch 5 Step 251 Train Loss: 0.3069
Epoch 5 Step 301 Train Loss: 0.2449
Epoch 5 Step 351 Train Loss: 0.2434
Epoch 5 Step 401 Train Loss: 0.2930
Epoch 5 Step 451 Train Loss: 0.2706
Epoch 5 Step 501 Train Loss: 0.2588
Epoch 5 Step 551 Train Loss: 0.2209
Epoch 5 Step 601 Train Loss: 0.2269
Epoch 5 Step 651 Train Loss: 0.3090
Epoch 5 Step 701 Train Loss: 0.2380
Epoch 5 Step 751 Train Loss: 0.2866
Epoch 5 Step 801 Train Loss: 0.2836
Epoch 5 Step 851 Train Loss: 0.2385
Epoch 5 Step 901 Train Loss: 0.2219
Epoch 5 Step 951 Train Loss: 0.2437
Epoch 5 Step 1001 Train Loss: 0.2272
Epoch 5 Step 1051 Train Loss: 0.1643
Epoch 5 Step 1101 Train Loss: 0.3243
Epoch 5 Step 1151 Train Loss: 0.2472
Epoch 5 Step 1201 Train Loss: 0.2871
Epoch 5 Step 1251 Train Loss: 0.2648
Epoch 5 Step 1301 Train Loss: 0.0461
Epoch 5 Step 1351 Train Loss: 0.1883
Epoch 5 Step 1401 Train Loss: 0.2530
Epoch 5: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0103 Validation Top 20 DE MSE: 0.0064. 
Epoch 6 Step 1 Train Loss: 0.3189
Epoch 6 Step 51 Train Loss: 0.2458
Epoch 6 Step 101 Train Loss: 0.2162
Epoch 6 Step 151 Train Loss: 0.3419
Epoch 6 Step 201 Train Loss: 0.2506
Epoch 6 Step 251 Train Loss: 0.2682
Epoch 6 Step 301 Train Loss: 0.2840
Epoch 6 Step 351 Train Loss: 0.3456
Epoch 6 Step 401 Train Loss: 0.2760
Epoch 6 Step 451 Train Loss: 0.1999
Epoch 6 Step 501 Train Loss: 0.2396
Epoch 6 Step 551 Train Loss: 0.2591
Epoch 6 Step 601 Train Loss: 0.2801
Epoch 6 Step 651 Train Loss: 0.2299
Epoch 6 Step 701 Train Loss: 0.2943
Epoch 6 Step 751 Train Loss: 0.2130
Epoch 6 Step 801 Train Loss: 0.2841
Epoch 6 Step 851 Train Loss: 0.2431
Epoch 6 Step 901 Train Loss: 0.2763
Epoch 6 Step 951 Train Loss: 0.2886
Epoch 6 Step 1001 Train Loss: 0.3032
Epoch 6 Step 1051 Train Loss: 0.2496
Epoch 6 Step 1101 Train Loss: 0.1900
Epoch 6 Step 1151 Train Loss: 0.2624
Epoch 6 Step 1201 Train Loss: 0.3343
Epoch 6 Step 1251 Train Loss: 0.2424
Epoch 6 Step 1301 Train Loss: 0.2284
Epoch 6 Step 1351 Train Loss: 0.2560
Epoch 6 Step 1401 Train Loss: 0.2725
Epoch 6: Train Overall MSE: 0.0012 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0111 Validation Top 20 DE MSE: 0.0066. 
Epoch 7 Step 1 Train Loss: 0.3082
Epoch 7 Step 51 Train Loss: 0.2368
Epoch 7 Step 101 Train Loss: 0.2593
Epoch 7 Step 151 Train Loss: 0.2500
Epoch 7 Step 201 Train Loss: 0.2234
Epoch 7 Step 251 Train Loss: 0.2378
Epoch 7 Step 301 Train Loss: 0.2484
Epoch 7 Step 351 Train Loss: 0.2833
Epoch 7 Step 401 Train Loss: 0.2678
Epoch 7 Step 451 Train Loss: 0.2383
Epoch 7 Step 501 Train Loss: 0.2662
Epoch 7 Step 551 Train Loss: 0.2568
Epoch 7 Step 601 Train Loss: 0.2477
Epoch 7 Step 651 Train Loss: 0.2695
Epoch 7 Step 701 Train Loss: 0.2916
Epoch 7 Step 751 Train Loss: 0.2570
Epoch 7 Step 801 Train Loss: 0.3412
Epoch 7 Step 851 Train Loss: 0.2929
Epoch 7 Step 901 Train Loss: 0.2948
Epoch 7 Step 951 Train Loss: 0.3161
Epoch 7 Step 1001 Train Loss: 0.3020
Epoch 7 Step 1051 Train Loss: 0.2482
Epoch 7 Step 1101 Train Loss: 0.2358
Epoch 7 Step 1151 Train Loss: 0.3162
Epoch 7 Step 1201 Train Loss: 0.2481
Epoch 7 Step 1251 Train Loss: 0.1633
Epoch 7 Step 1301 Train Loss: 0.2798
Epoch 7 Step 1351 Train Loss: 0.2726
Epoch 7 Step 1401 Train Loss: 0.2687
Epoch 7: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0065. 
Epoch 8 Step 1 Train Loss: 0.2851
Epoch 8 Step 51 Train Loss: 0.2440
Epoch 8 Step 101 Train Loss: 0.1990
Epoch 8 Step 151 Train Loss: 0.2475
Epoch 8 Step 201 Train Loss: 0.2725
Epoch 8 Step 251 Train Loss: 0.2210
Epoch 8 Step 301 Train Loss: 0.2444
Epoch 8 Step 351 Train Loss: 0.2874
Epoch 8 Step 401 Train Loss: 0.2134
Epoch 8 Step 451 Train Loss: 0.2706
Epoch 8 Step 501 Train Loss: 0.2552
Epoch 8 Step 551 Train Loss: 0.2829
Epoch 8 Step 601 Train Loss: 0.1941
Epoch 8 Step 651 Train Loss: 0.1351
Epoch 8 Step 701 Train Loss: 0.2725
Epoch 8 Step 751 Train Loss: 0.0607
Epoch 8 Step 801 Train Loss: 0.2832
Epoch 8 Step 851 Train Loss: 0.3053
Epoch 8 Step 901 Train Loss: 0.2682
Epoch 8 Step 951 Train Loss: 0.3319
Epoch 8 Step 1001 Train Loss: 0.2870
Epoch 8 Step 1051 Train Loss: 0.2690
Epoch 8 Step 1101 Train Loss: 0.1838
Epoch 8 Step 1151 Train Loss: 0.2836
Epoch 8 Step 1201 Train Loss: 0.2915
Epoch 8 Step 1251 Train Loss: 0.3758
Epoch 8 Step 1301 Train Loss: 0.3159
Epoch 8 Step 1351 Train Loss: 0.2671
Epoch 8 Step 1401 Train Loss: 0.2694
Epoch 8: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0094 Validation Top 20 DE MSE: 0.0065. 
Epoch 9 Step 1 Train Loss: 0.2498
Epoch 9 Step 51 Train Loss: 0.2218
Epoch 9 Step 101 Train Loss: 0.2226
Epoch 9 Step 151 Train Loss: 0.2217
Epoch 9 Step 201 Train Loss: 0.2072
Epoch 9 Step 251 Train Loss: 0.3151
Epoch 9 Step 301 Train Loss: 0.2568
Epoch 9 Step 351 Train Loss: 0.3022
Epoch 9 Step 401 Train Loss: 0.2681
Epoch 9 Step 451 Train Loss: 0.2332
Epoch 9 Step 501 Train Loss: 0.2382
Epoch 9 Step 551 Train Loss: 0.2650
Epoch 9 Step 601 Train Loss: 0.2554
Epoch 9 Step 651 Train Loss: 0.2230
Epoch 9 Step 701 Train Loss: 0.2688
Epoch 9 Step 751 Train Loss: 0.3153
Epoch 9 Step 801 Train Loss: 0.3201
Epoch 9 Step 851 Train Loss: 0.2413
Epoch 9 Step 901 Train Loss: 0.2931
Epoch 9 Step 951 Train Loss: 0.3681
Epoch 9 Step 1001 Train Loss: 0.2485
Epoch 9 Step 1051 Train Loss: 0.2093
Epoch 9 Step 1101 Train Loss: 0.2739
Epoch 9 Step 1151 Train Loss: 0.3440
Epoch 9 Step 1201 Train Loss: 0.2929
Epoch 9 Step 1251 Train Loss: 0.3257
Epoch 9 Step 1301 Train Loss: 0.3228
Epoch 9 Step 1351 Train Loss: 0.3009
Epoch 9 Step 1401 Train Loss: 0.2257
Epoch 9: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0096 Validation Top 20 DE MSE: 0.0064. 
Epoch 10 Step 1 Train Loss: 0.2757
Epoch 10 Step 51 Train Loss: 0.2258
Epoch 10 Step 101 Train Loss: 0.2802
Epoch 10 Step 151 Train Loss: 0.3162
Epoch 10 Step 201 Train Loss: 0.2733
Epoch 10 Step 251 Train Loss: 0.3037
Epoch 10 Step 301 Train Loss: 0.2158
Epoch 10 Step 351 Train Loss: 0.2673
Epoch 10 Step 401 Train Loss: 0.2981
Epoch 10 Step 451 Train Loss: 0.2392
Epoch 10 Step 501 Train Loss: 0.4738
Epoch 10 Step 551 Train Loss: 0.2304
Epoch 10 Step 601 Train Loss: 0.2386
Epoch 10 Step 651 Train Loss: 0.2781
Epoch 10 Step 701 Train Loss: 0.2087
Epoch 10 Step 751 Train Loss: 0.2546
Epoch 10 Step 801 Train Loss: 0.2582
Epoch 10 Step 851 Train Loss: 0.2193
Epoch 10 Step 901 Train Loss: 0.2027
Epoch 10 Step 951 Train Loss: 0.2572
Epoch 10 Step 1001 Train Loss: 0.2812
Epoch 10 Step 1051 Train Loss: 0.3118
Epoch 10 Step 1101 Train Loss: 0.2724
Epoch 10 Step 1151 Train Loss: 0.2555
Epoch 10 Step 1201 Train Loss: 0.2165
Epoch 10 Step 1251 Train Loss: 0.2573
Epoch 10 Step 1301 Train Loss: 0.2182
Epoch 10 Step 1351 Train Loss: 0.2744
Epoch 10 Step 1401 Train Loss: 0.2376
Epoch 10: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0092 Validation Top 20 DE MSE: 0.0066. 
Epoch 11 Step 1 Train Loss: 0.2951
Epoch 11 Step 51 Train Loss: 0.2480
Epoch 11 Step 101 Train Loss: 0.2376
Epoch 11 Step 151 Train Loss: 0.2424
Epoch 11 Step 201 Train Loss: 0.2499
Epoch 11 Step 251 Train Loss: 0.2544
Epoch 11 Step 301 Train Loss: 0.1764
Epoch 11 Step 351 Train Loss: 0.2984
Epoch 11 Step 401 Train Loss: 0.1584
Epoch 11 Step 451 Train Loss: 0.2583
Epoch 11 Step 501 Train Loss: 0.2312
Epoch 11 Step 551 Train Loss: 0.2417
Epoch 11 Step 601 Train Loss: 0.2215
Epoch 11 Step 651 Train Loss: 0.2340
Epoch 11 Step 701 Train Loss: 0.2621
Epoch 11 Step 751 Train Loss: 0.3451
Epoch 11 Step 801 Train Loss: 0.2168
Epoch 11 Step 851 Train Loss: 0.2710
Epoch 11 Step 901 Train Loss: 0.2221
Epoch 11 Step 951 Train Loss: 0.2468
Epoch 11 Step 1001 Train Loss: 0.2683
Epoch 11 Step 1051 Train Loss: 0.2398
Epoch 11 Step 1101 Train Loss: 0.3047
Epoch 11 Step 1151 Train Loss: 0.2303
Epoch 11 Step 1201 Train Loss: 0.2617
Epoch 11 Step 1251 Train Loss: 0.2449
Epoch 11 Step 1301 Train Loss: 0.2530
Epoch 11 Step 1351 Train Loss: 0.2631
Epoch 11 Step 1401 Train Loss: 0.2469
Epoch 11: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0012. 
Train Top 20 DE MSE: 0.0098 Validation Top 20 DE MSE: 0.0064. 
Epoch 12 Step 1 Train Loss: 0.2181
Epoch 12 Step 51 Train Loss: 0.2864
Epoch 12 Step 101 Train Loss: 0.2099
Epoch 12 Step 151 Train Loss: 0.2348
Epoch 12 Step 201 Train Loss: 0.2103
Epoch 12 Step 251 Train Loss: 0.3562
Epoch 12 Step 301 Train Loss: 0.2560
Epoch 12 Step 351 Train Loss: 0.2664
Epoch 12 Step 401 Train Loss: 0.2990
Epoch 12 Step 451 Train Loss: 0.2703
Epoch 12 Step 501 Train Loss: 0.2934
Epoch 12 Step 551 Train Loss: 0.2691
Epoch 12 Step 601 Train Loss: 0.2408
Epoch 12 Step 651 Train Loss: 0.2932
Epoch 12 Step 701 Train Loss: 0.2035
Epoch 12 Step 751 Train Loss: 0.1596
Epoch 12 Step 801 Train Loss: 0.2677
Epoch 12 Step 851 Train Loss: 0.2203
Epoch 12 Step 901 Train Loss: 0.3139
Epoch 12 Step 951 Train Loss: 0.2824
Epoch 12 Step 1001 Train Loss: 0.3064
Epoch 12 Step 1051 Train Loss: 0.2609
Epoch 12 Step 1101 Train Loss: 0.2711
Epoch 12 Step 1151 Train Loss: 0.2253
Epoch 12 Step 1201 Train Loss: 0.2487
Epoch 12 Step 1251 Train Loss: 0.2994
Epoch 12 Step 1301 Train Loss: 0.2368
Epoch 12 Step 1351 Train Loss: 0.2526
Epoch 12 Step 1401 Train Loss: 0.2432
Epoch 12: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0065. 
Epoch 13 Step 1 Train Loss: 0.4397
Epoch 13 Step 51 Train Loss: 0.2569
Epoch 13 Step 101 Train Loss: 0.2240
Epoch 13 Step 151 Train Loss: 0.2897
Epoch 13 Step 201 Train Loss: 0.2738
Epoch 13 Step 251 Train Loss: 0.2895
Epoch 13 Step 301 Train Loss: 0.2965
Epoch 13 Step 351 Train Loss: 0.2488
Epoch 13 Step 401 Train Loss: 0.3277
Epoch 13 Step 451 Train Loss: 0.2981
Epoch 13 Step 501 Train Loss: 0.2649
Epoch 13 Step 551 Train Loss: 0.2247
Epoch 13 Step 601 Train Loss: 0.2810
Epoch 13 Step 651 Train Loss: 0.2993
Epoch 13 Step 701 Train Loss: 0.2622
Epoch 13 Step 751 Train Loss: 0.2480
Epoch 13 Step 801 Train Loss: 0.3299
Epoch 13 Step 851 Train Loss: 0.2939
Epoch 13 Step 901 Train Loss: 0.2482
Epoch 13 Step 951 Train Loss: 0.3616
Epoch 13 Step 1001 Train Loss: 0.2680
Epoch 13 Step 1051 Train Loss: 0.2981
Epoch 13 Step 1101 Train Loss: 0.3323
Epoch 13 Step 1151 Train Loss: 0.2538
Epoch 13 Step 1201 Train Loss: 0.2780
Epoch 13 Step 1251 Train Loss: 0.2923
Epoch 13 Step 1301 Train Loss: 0.2772
Epoch 13 Step 1351 Train Loss: 0.2822
Epoch 13 Step 1401 Train Loss: 0.3032
Epoch 13: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0065. 
Epoch 14 Step 1 Train Loss: 0.2025
Epoch 14 Step 51 Train Loss: 0.3702
Epoch 14 Step 101 Train Loss: 0.2370
Epoch 14 Step 151 Train Loss: 0.2421
Epoch 14 Step 201 Train Loss: 0.2794
Epoch 14 Step 251 Train Loss: 0.1649
Epoch 14 Step 301 Train Loss: 0.3122
Epoch 14 Step 351 Train Loss: 0.3047
Epoch 14 Step 401 Train Loss: 0.2766
Epoch 14 Step 451 Train Loss: 0.3045
Epoch 14 Step 501 Train Loss: 0.3153
Epoch 14 Step 551 Train Loss: 0.2236
Epoch 14 Step 601 Train Loss: 0.1879
Epoch 14 Step 651 Train Loss: 0.2710
Epoch 14 Step 701 Train Loss: 0.1725
Epoch 14 Step 751 Train Loss: 0.2639
Epoch 14 Step 801 Train Loss: 0.2694
Epoch 14 Step 851 Train Loss: 0.2833
Epoch 14 Step 901 Train Loss: 0.3252
Epoch 14 Step 951 Train Loss: 0.2073
Epoch 14 Step 1001 Train Loss: 0.2519
Epoch 14 Step 1051 Train Loss: 0.3389
Epoch 14 Step 1101 Train Loss: 0.2069
Epoch 14 Step 1151 Train Loss: 0.2491
Epoch 14 Step 1201 Train Loss: 0.2720
Epoch 14 Step 1251 Train Loss: 0.2876
Epoch 14 Step 1301 Train Loss: 0.2735
Epoch 14 Step 1351 Train Loss: 0.2778
Epoch 14 Step 1401 Train Loss: 0.2455
Epoch 14: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0066. 
Epoch 15 Step 1 Train Loss: 0.3014
Epoch 15 Step 51 Train Loss: 0.3392
Epoch 15 Step 101 Train Loss: 0.3361
Epoch 15 Step 151 Train Loss: 0.2986
Epoch 15 Step 201 Train Loss: 0.3010
Epoch 15 Step 251 Train Loss: 0.2684
Epoch 15 Step 301 Train Loss: 0.2743
Epoch 15 Step 351 Train Loss: 0.2607
Epoch 15 Step 401 Train Loss: 0.2690
Epoch 15 Step 451 Train Loss: 0.2822
Epoch 15 Step 501 Train Loss: 0.2026
Epoch 15 Step 551 Train Loss: 0.2272
Epoch 15 Step 601 Train Loss: 0.2810
Epoch 15 Step 651 Train Loss: 0.2770
Epoch 15 Step 701 Train Loss: 0.2550
Epoch 15 Step 751 Train Loss: 0.2958
Epoch 15 Step 801 Train Loss: 0.2123
Epoch 15 Step 851 Train Loss: 0.1925
Epoch 15 Step 901 Train Loss: 0.3389
Epoch 15 Step 951 Train Loss: 0.4054
Epoch 15 Step 1001 Train Loss: 0.2427
Epoch 15 Step 1051 Train Loss: 0.2383
Epoch 15 Step 1101 Train Loss: 0.3216
Epoch 15 Step 1151 Train Loss: 0.3191
Epoch 15 Step 1201 Train Loss: 0.2439
Epoch 15 Step 1251 Train Loss: 0.2396
Epoch 15 Step 1301 Train Loss: 0.4220
Epoch 15 Step 1351 Train Loss: 0.2545
Epoch 15 Step 1401 Train Loss: 0.3021
Epoch 15: Train Overall MSE: 0.0011 Validation Overall MSE: 0.0013. 
Train Top 20 DE MSE: 0.0093 Validation Top 20 DE MSE: 0.0065. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0112
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0013047891
test_unseen_single_pearson: 0.9940917206909845
test_unseen_single_mse_de: 0.011179151
test_unseen_single_pearson_de: 0.9369999605704484
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.8968587189001717
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.0
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9400000000000001
test_unseen_single_mse_top20_de_non_dropout: 0.014349771
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.033 MB uploadedwandb: | 0.001 MB of 0.033 MB uploadedwandb: / 0.003 MB of 0.033 MB uploadedwandb: - 0.023 MB of 0.033 MB uploadedwandb: \ 0.033 MB of 0.033 MB uploadedwandb: | 0.033 MB of 0.033 MB uploadedwandb: / 0.033 MB of 0.033 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.01118
wandb:                                              test_de_pearson 0.937
wandb:               test_frac_opposite_direction_top20_non_dropout 0.0
wandb:                          test_frac_sigma_below_1_non_dropout 0.94
wandb:                                                     test_mse 0.0013
wandb:                                test_mse_top20_de_non_dropout 0.01435
wandb:                                                 test_pearson 0.99409
wandb:                                           test_pearson_delta 0.89686
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.0
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.94
wandb:                                       test_unseen_single_mse 0.0013
wandb:                                    test_unseen_single_mse_de 0.01118
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.01435
wandb:                                   test_unseen_single_pearson 0.99409
wandb:                                test_unseen_single_pearson_de 0.937
wandb:                             test_unseen_single_pearson_delta 0.89686
wandb:                                                 train_de_mse 0.00928
wandb:                                             train_de_pearson 0.99799
wandb:                                                    train_mse 0.00111
wandb:                                                train_pearson 0.99497
wandb:                                                training_loss 0.29573
wandb:                                                   val_de_mse 0.0065
wandb:                                               val_de_pearson 0.99785
wandb:                                                      val_mse 0.00127
wandb:                                                  val_pearson 0.99415
wandb: 
wandb: üöÄ View run scbert_ShifrutMarson2018_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/z3qmkc1m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_141712-z3qmkc1m/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_144202-y5bhg5lb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/y5bhg5lb
wandb: WARNING Serializing object of type ndarray that is 8000128 bytes
  0%|                                                                                       | 0/4744 [00:00<?, ?it/s]  0%|                                                                               | 5/4744 [00:00<01:45, 44.73it/s]  0%|‚ñè                                                                             | 11/4744 [00:00<01:36, 48.82it/s]  0%|‚ñé                                                                             | 17/4744 [00:00<01:33, 50.56it/s]  1%|‚ñç                                                                             | 24/4744 [00:00<01:31, 51.86it/s]  1%|‚ñå                                                                             | 31/4744 [00:00<01:22, 57.14it/s]  1%|‚ñå                                                                             | 37/4744 [00:00<01:22, 56.77it/s]  1%|‚ñã                                                                             | 43/4744 [00:00<01:22, 56.70it/s]  1%|‚ñä                                                                             | 49/4744 [00:00<01:22, 56.89it/s]  1%|‚ñâ                                                                             | 55/4744 [00:00<01:21, 57.33it/s]  1%|‚ñà                                                                             | 61/4744 [00:01<01:21, 57.20it/s]  1%|‚ñà                                                                             | 67/4744 [00:01<01:21, 57.32it/s]  2%|‚ñà‚ñè                                                                            | 73/4744 [00:01<01:21, 57.17it/s]  2%|‚ñà‚ñé                                                                            | 79/4744 [00:01<01:20, 57.73it/s]  2%|‚ñà‚ñç                                                                            | 85/4744 [00:01<01:21, 57.41it/s]  2%|‚ñà‚ñç                                                                            | 91/4744 [00:01<01:27, 53.27it/s]  2%|‚ñà‚ñå                                                                            | 97/4744 [00:01<01:35, 48.53it/s]  2%|‚ñà‚ñã                                                                           | 102/4744 [00:01<01:40, 46.11it/s]  2%|‚ñà‚ñã                                                                           | 107/4744 [00:02<01:42, 45.35it/s]  2%|‚ñà‚ñä                                                                           | 113/4744 [00:02<01:34, 48.96it/s]  3%|‚ñà‚ñâ                                                                           | 119/4744 [00:02<01:29, 51.95it/s]  3%|‚ñà‚ñà                                                                           | 125/4744 [00:02<01:25, 53.94it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 132/4744 [00:02<01:22, 55.97it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 138/4744 [00:02<01:20, 56.90it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 144/4744 [00:02<01:42, 44.84it/s]  3%|‚ñà‚ñà‚ñå                                                                          | 155/4744 [00:02<01:16, 60.38it/s]  3%|‚ñà‚ñà‚ñã                                                                          | 162/4744 [00:02<01:13, 62.32it/s]  4%|‚ñà‚ñà‚ñã                                                                          | 169/4744 [00:03<01:14, 61.29it/s]  4%|‚ñà‚ñà‚ñä                                                                          | 176/4744 [00:03<01:15, 60.75it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 183/4744 [00:03<01:16, 59.62it/s]  4%|‚ñà‚ñà‚ñà                                                                          | 190/4744 [00:03<01:16, 59.42it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 197/4744 [00:03<01:16, 59.42it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 204/4744 [00:03<01:16, 59.59it/s]  4%|‚ñà‚ñà‚ñà‚ñç                                                                         | 211/4744 [00:03<01:16, 59.09it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 217/4744 [00:03<01:16, 58.96it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 223/4744 [00:04<01:16, 59.06it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 229/4744 [00:04<01:19, 56.47it/s]  5%|‚ñà‚ñà‚ñà‚ñä                                                                         | 235/4744 [00:04<01:29, 50.25it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 241/4744 [00:04<01:35, 47.12it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 246/4744 [00:04<01:37, 46.09it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 251/4744 [00:04<01:39, 45.28it/s]  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                        | 256/4744 [00:04<02:04, 35.96it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 264/4744 [00:04<01:42, 43.66it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 269/4744 [00:05<01:44, 42.89it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 274/4744 [00:05<01:50, 40.44it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 280/4744 [00:05<01:40, 44.42it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 287/4744 [00:05<01:31, 48.83it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                        | 293/4744 [00:05<01:32, 48.25it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                        | 300/4744 [00:05<01:24, 52.37it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 306/4744 [00:05<01:26, 51.35it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 312/4744 [00:05<01:26, 51.27it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 318/4744 [00:06<01:26, 51.44it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 324/4744 [00:06<01:25, 51.95it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 331/4744 [00:06<01:19, 55.48it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 337/4744 [00:06<01:20, 55.04it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 343/4744 [00:06<01:20, 54.91it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 349/4744 [00:06<01:20, 54.67it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 355/4744 [00:06<01:22, 53.28it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 361/4744 [00:06<01:25, 51.50it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 367/4744 [00:06<01:23, 52.22it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 373/4744 [00:07<01:21, 53.92it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 379/4744 [00:07<01:21, 53.37it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 385/4744 [00:07<01:53, 38.35it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 390/4744 [00:07<01:46, 40.73it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 396/4744 [00:07<01:40, 43.26it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 401/4744 [00:07<01:43, 42.09it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 406/4744 [00:07<01:38, 43.97it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 412/4744 [00:08<01:30, 48.04it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 418/4744 [00:08<01:29, 48.48it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 424/4744 [00:08<01:28, 48.95it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 430/4744 [00:08<01:25, 50.25it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 436/4744 [00:08<01:25, 50.46it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 442/4744 [00:08<01:25, 50.39it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 448/4744 [00:08<01:24, 50.57it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 454/4744 [00:08<01:25, 50.35it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 460/4744 [00:08<01:24, 50.65it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 466/4744 [00:09<01:23, 51.24it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 472/4744 [00:09<01:21, 52.26it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 478/4744 [00:09<01:24, 50.35it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 485/4744 [00:09<01:19, 53.67it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 491/4744 [00:09<01:18, 54.36it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 497/4744 [00:09<01:17, 54.85it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 503/4744 [00:09<01:19, 53.13it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 510/4744 [00:09<01:19, 53.58it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 517/4744 [00:09<01:15, 56.18it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 523/4744 [00:10<01:15, 55.85it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 529/4744 [00:10<01:17, 54.22it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 535/4744 [00:10<01:18, 53.74it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 541/4744 [00:10<01:17, 54.02it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 547/4744 [00:10<01:17, 53.85it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 553/4744 [00:10<01:21, 51.64it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 560/4744 [00:10<01:16, 54.77it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 566/4744 [00:10<01:17, 53.93it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 572/4744 [00:11<01:18, 53.41it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 578/4744 [00:11<01:18, 53.13it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 584/4744 [00:11<01:17, 53.92it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 590/4744 [00:11<01:17, 53.44it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 596/4744 [00:11<01:17, 53.79it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 602/4744 [00:11<01:16, 53.86it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 608/4744 [00:11<01:19, 51.88it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 615/4744 [00:11<01:16, 54.32it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 621/4744 [00:11<01:17, 53.50it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 627/4744 [00:12<01:17, 53.05it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 633/4744 [00:12<01:15, 54.49it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 639/4744 [00:12<01:15, 54.03it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 645/4744 [00:12<01:15, 54.15it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 651/4744 [00:12<01:15, 53.96it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 657/4744 [00:12<01:14, 54.99it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 663/4744 [00:12<01:15, 54.22it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 669/4744 [00:12<01:15, 53.79it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 675/4744 [00:12<01:16, 53.49it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 681/4744 [00:13<01:14, 54.83it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 687/4744 [00:13<01:14, 54.61it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 693/4744 [00:13<01:14, 54.35it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 699/4744 [00:13<01:13, 54.78it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 705/4744 [00:13<01:17, 52.45it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 712/4744 [00:13<01:12, 55.40it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 718/4744 [00:13<01:13, 54.67it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 724/4744 [00:13<01:13, 54.34it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 730/4744 [00:13<01:13, 54.74it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 736/4744 [00:14<01:12, 55.12it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                 | 742/4744 [00:14<01:13, 54.58it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 748/4744 [00:14<01:12, 54.81it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 754/4744 [00:14<01:12, 55.05it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 760/4744 [00:14<01:11, 55.57it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 766/4744 [00:14<01:12, 54.62it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 772/4744 [00:14<01:12, 54.74it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 778/4744 [00:14<01:13, 53.86it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 784/4744 [00:14<01:14, 53.23it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 790/4744 [00:15<01:15, 52.67it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 796/4744 [00:15<01:15, 52.17it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 802/4744 [00:15<01:16, 51.52it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 808/4744 [00:15<01:18, 50.40it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 814/4744 [00:15<01:19, 49.32it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 819/4744 [00:15<01:19, 49.09it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 824/4744 [00:15<01:19, 49.02it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 829/4744 [00:15<01:19, 49.29it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 835/4744 [00:15<01:18, 49.81it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 841/4744 [00:16<01:17, 50.35it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 847/4744 [00:16<01:17, 50.45it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 853/4744 [00:16<01:16, 51.02it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 859/4744 [00:16<01:13, 52.56it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 865/4744 [00:16<01:12, 53.18it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 871/4744 [00:16<01:12, 53.79it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 877/4744 [00:16<01:11, 54.40it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 883/4744 [00:16<01:10, 54.90it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 889/4744 [00:16<01:09, 55.44it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 895/4744 [00:17<01:09, 55.47it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 901/4744 [00:17<01:09, 55.60it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 907/4744 [00:17<01:08, 55.68it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 913/4744 [00:17<01:08, 55.78it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 919/4744 [00:17<01:11, 53.27it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 926/4744 [00:17<01:07, 56.78it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 932/4744 [00:17<01:06, 56.94it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 938/4744 [00:17<01:07, 56.80it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 944/4744 [00:17<01:06, 56.78it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 950/4744 [00:18<01:07, 56.23it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 956/4744 [00:18<01:07, 56.38it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 962/4744 [00:18<01:06, 56.51it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 968/4744 [00:18<01:10, 53.20it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 975/4744 [00:18<01:06, 56.30it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 981/4744 [00:18<01:06, 56.95it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 987/4744 [00:18<01:06, 56.86it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 993/4744 [00:18<01:06, 56.18it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                            | 999/4744 [00:18<01:07, 55.40it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 1005/4744 [00:19<01:07, 55.76it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 1011/4744 [00:19<01:07, 55.59it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 1017/4744 [00:19<01:10, 52.52it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 1024/4744 [00:19<01:06, 55.72it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 1030/4744 [00:19<01:05, 56.41it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 1036/4744 [00:19<01:05, 56.41it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 1042/4744 [00:19<01:06, 55.91it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 1048/4744 [00:19<01:06, 55.91it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 1054/4744 [00:19<01:05, 56.20it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 1060/4744 [00:20<01:05, 56.21it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 1066/4744 [00:20<01:06, 55.32it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 1072/4744 [00:20<01:06, 55.37it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 1078/4744 [00:20<01:06, 55.51it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 1084/4744 [00:20<01:05, 55.80it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                          | 1090/4744 [00:20<01:05, 55.39it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 1096/4744 [00:20<01:06, 55.25it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 1102/4744 [00:20<01:05, 56.00it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 1108/4744 [00:20<01:07, 53.63it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 1115/4744 [00:21<01:04, 56.57it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 1121/4744 [00:21<01:04, 56.12it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 1127/4744 [00:21<01:04, 55.89it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 1133/4744 [00:21<01:04, 56.09it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 1139/4744 [00:21<01:04, 55.57it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 1145/4744 [00:21<01:04, 55.41it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 1151/4744 [00:21<01:04, 55.42it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 1157/4744 [00:21<01:04, 55.64it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 1163/4744 [00:21<01:04, 55.57it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 1169/4744 [00:21<01:04, 55.20it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 1175/4744 [00:22<01:04, 54.97it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                         | 1181/4744 [00:22<01:04, 55.64it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 1187/4744 [00:22<01:04, 55.30it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 1193/4744 [00:22<01:04, 55.36it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                        | 1199/4744 [00:22<01:03, 55.55it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 1205/4744 [00:22<01:03, 55.84it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                        | 1211/4744 [00:22<01:03, 55.61it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                        | 1217/4744 [00:22<01:06, 53.40it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 1223/4744 [00:22<01:07, 52.27it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 1229/4744 [00:23<01:08, 51.67it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 1235/4744 [00:23<01:06, 52.63it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 1241/4744 [00:23<01:05, 53.21it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 1247/4744 [00:23<01:05, 53.28it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 1253/4744 [00:23<01:04, 53.98it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1259/4744 [00:23<01:03, 54.90it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 1265/4744 [00:23<01:03, 55.04it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 1271/4744 [00:23<01:08, 50.51it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 1279/4744 [00:24<01:02, 55.42it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 1286/4744 [00:24<00:58, 58.64it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 1292/4744 [00:24<00:59, 58.34it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                       | 1298/4744 [00:24<01:00, 56.55it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 1304/4744 [00:24<01:02, 54.81it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 1310/4744 [00:24<01:04, 53.39it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                       | 1316/4744 [00:24<01:05, 52.29it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 1322/4744 [00:24<01:06, 51.41it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                      | 1328/4744 [00:24<01:05, 51.89it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                      | 1334/4744 [00:25<01:04, 52.52it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 1340/4744 [00:25<01:03, 53.28it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 1346/4744 [00:25<01:03, 53.84it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 1352/4744 [00:25<01:02, 53.90it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 1358/4744 [00:25<01:05, 51.80it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 1365/4744 [00:25<01:01, 55.37it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 1371/4744 [00:25<01:01, 55.03it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1377/4744 [00:25<01:01, 55.20it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 1383/4744 [00:25<01:00, 55.81it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1389/4744 [00:26<01:00, 55.53it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1395/4744 [00:26<01:00, 55.54it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1401/4744 [00:26<01:00, 55.03it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 1407/4744 [00:26<01:03, 52.16it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1414/4744 [00:26<00:59, 55.77it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1420/4744 [00:26<01:00, 55.27it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1426/4744 [00:26<00:59, 55.70it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                     | 1432/4744 [00:26<00:59, 55.58it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1438/4744 [00:26<01:01, 53.94it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1444/4744 [00:27<01:02, 53.12it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1450/4744 [00:27<01:02, 52.36it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1456/4744 [00:27<01:03, 51.64it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1462/4744 [00:27<01:01, 53.33it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 1468/4744 [00:27<01:02, 52.05it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1475/4744 [00:27<00:58, 56.14it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1481/4744 [00:27<00:57, 56.60it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1487/4744 [00:27<00:56, 57.16it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 1493/4744 [00:27<00:56, 57.56it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1499/4744 [00:28<00:56, 57.59it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1505/4744 [00:28<00:59, 54.32it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1511/4744 [00:28<01:04, 49.87it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1517/4744 [00:28<01:08, 47.06it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1522/4744 [00:28<01:11, 44.91it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1527/4744 [00:28<01:14, 43.21it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1532/4744 [00:28<01:13, 43.47it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1537/4744 [00:28<01:13, 43.88it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1542/4744 [00:29<01:12, 43.89it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1548/4744 [00:29<01:08, 46.42it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1554/4744 [00:29<01:04, 49.15it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1560/4744 [00:29<01:02, 51.07it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1566/4744 [00:29<01:00, 52.43it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1572/4744 [00:29<01:00, 52.69it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 1578/4744 [00:29<00:58, 53.91it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1584/4744 [00:29<00:57, 54.82it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1590/4744 [00:29<00:57, 54.86it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1596/4744 [00:30<00:57, 54.89it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 1602/4744 [00:30<00:59, 52.95it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1609/4744 [00:30<00:55, 56.63it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1615/4744 [00:30<00:55, 56.07it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1621/4744 [00:30<00:56, 55.64it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1627/4744 [00:30<00:55, 56.48it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1633/4744 [00:30<00:54, 56.71it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1639/4744 [00:30<00:54, 56.60it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1645/4744 [00:30<00:54, 56.37it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1651/4744 [00:31<00:54, 56.46it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1657/4744 [00:31<00:57, 53.56it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1664/4744 [00:31<00:54, 56.40it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1670/4744 [00:31<00:56, 54.09it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1676/4744 [00:31<00:57, 53.08it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 1682/4744 [00:31<00:58, 52.34it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1689/4744 [00:31<00:54, 56.48it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 1695/4744 [00:31<00:53, 57.07it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1701/4744 [00:31<00:53, 57.25it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1707/4744 [00:32<00:55, 55.01it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 1713/4744 [00:32<00:56, 53.43it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1719/4744 [00:32<00:57, 52.32it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1725/4744 [00:32<01:00, 49.95it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1732/4744 [00:32<00:55, 54.37it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 1738/4744 [00:32<00:54, 54.96it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1744/4744 [00:32<00:54, 55.11it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1750/4744 [00:32<00:53, 55.56it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1756/4744 [00:32<00:54, 55.30it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1762/4744 [00:33<00:53, 55.26it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1768/4744 [00:33<00:53, 55.14it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1774/4744 [00:33<00:56, 52.67it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 1781/4744 [00:33<00:52, 56.52it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1787/4744 [00:33<00:52, 56.78it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1793/4744 [00:33<00:51, 56.79it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1799/4744 [00:33<00:53, 54.55it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 1805/4744 [00:33<00:53, 55.28it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1812/4744 [00:33<00:50, 58.33it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1818/4744 [00:34<00:50, 57.96it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1824/4744 [00:34<00:53, 54.99it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1831/4744 [00:34<00:49, 58.50it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 1837/4744 [00:34<00:50, 57.78it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1843/4744 [00:34<00:50, 57.47it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1849/4744 [00:34<00:50, 57.40it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                              | 1855/4744 [00:34<00:52, 54.84it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1862/4744 [00:34<00:49, 57.79it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 1868/4744 [00:34<00:50, 57.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1874/4744 [00:35<00:52, 54.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1881/4744 [00:35<00:49, 57.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1887/4744 [00:35<00:49, 57.56it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                             | 1893/4744 [00:35<00:50, 56.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1899/4744 [00:35<00:50, 56.64it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 1905/4744 [00:35<00:52, 53.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1912/4744 [00:35<00:49, 56.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1918/4744 [00:35<00:49, 56.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1924/4744 [00:35<00:50, 56.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1930/4744 [00:36<00:50, 56.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 1936/4744 [00:36<01:38, 28.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 1961/4744 [00:36<00:42, 64.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1972/4744 [00:37<01:10, 39.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1996/4744 [00:37<00:42, 64.18it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 2009/4744 [00:37<00:57, 47.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 2026/4744 [00:37<00:43, 62.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 2038/4744 [00:38<00:44, 60.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 2048/4744 [00:38<00:45, 59.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 2057/4744 [00:38<00:46, 58.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 2065/4744 [00:38<00:46, 57.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 2072/4744 [00:38<01:14, 36.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 2095/4744 [00:39<00:42, 62.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 2105/4744 [00:39<00:44, 59.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 2114/4744 [00:39<00:45, 58.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 2122/4744 [00:39<00:45, 57.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 2129/4744 [00:39<00:45, 57.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 2136/4744 [00:39<00:46, 56.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 2143/4744 [00:39<00:46, 56.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 2150/4744 [00:40<00:46, 55.48it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 2156/4744 [00:40<00:46, 55.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 2162/4744 [00:40<00:47, 54.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 2168/4744 [00:40<00:48, 53.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 2174/4744 [00:40<00:47, 54.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 2180/4744 [00:40<00:46, 55.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 2186/4744 [00:40<00:45, 56.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 2192/4744 [00:41<01:24, 30.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 2198/4744 [00:41<01:58, 21.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 2217/4744 [00:41<01:08, 37.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 2242/4744 [00:42<00:51, 49.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 2266/4744 [00:42<00:34, 72.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 2277/4744 [00:42<00:37, 66.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 2286/4744 [00:42<00:39, 62.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 2294/4744 [00:42<00:40, 59.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 2301/4744 [00:43<01:06, 36.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 2307/4744 [00:43<01:03, 38.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 2313/4744 [00:43<01:00, 40.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 2336/4744 [00:43<00:33, 71.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 2346/4744 [00:44<00:56, 42.23it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 2355/4744 [00:44<00:56, 42.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 2380/4744 [00:44<00:33, 69.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 2391/4744 [00:44<00:36, 63.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 2401/4744 [00:45<00:38, 60.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 2409/4744 [00:45<00:40, 57.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 2416/4744 [00:45<00:41, 56.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 2423/4744 [00:45<00:41, 55.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 2430/4744 [00:45<00:41, 55.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 2436/4744 [00:45<00:41, 55.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 2442/4744 [00:45<00:41, 55.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 2448/4744 [00:45<00:41, 55.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 2454/4744 [00:45<00:41, 55.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 2460/4744 [00:46<00:41, 55.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 2466/4744 [00:46<00:41, 55.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 2472/4744 [00:46<00:41, 55.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 2478/4744 [00:46<00:40, 55.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 2484/4744 [00:46<00:42, 53.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 2490/4744 [00:46<00:42, 52.78it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 2496/4744 [00:46<00:43, 51.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 2502/4744 [00:47<01:15, 29.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 2519/4744 [00:47<00:42, 52.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 2527/4744 [00:47<00:46, 47.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 2534/4744 [00:47<00:42, 51.54it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 2541/4744 [00:47<00:42, 51.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 2548/4744 [00:48<01:02, 35.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 2558/4744 [00:48<01:01, 35.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 2582/4744 [00:48<00:33, 65.01it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 2592/4744 [00:48<00:33, 64.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 2601/4744 [00:49<00:49, 43.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 2619/4744 [00:49<00:34, 60.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 2628/4744 [00:49<00:38, 54.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 2636/4744 [00:49<00:38, 54.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 2643/4744 [00:49<00:41, 50.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 2649/4744 [00:49<00:42, 49.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 2655/4744 [00:50<00:41, 50.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 2661/4744 [00:50<00:40, 51.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 2667/4744 [00:50<00:39, 52.35it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 2673/4744 [00:50<00:38, 53.16it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 2679/4744 [00:50<00:38, 53.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 2685/4744 [00:50<00:37, 54.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 2691/4744 [00:50<00:37, 55.11it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 2697/4744 [00:50<00:37, 55.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2703/4744 [00:50<00:36, 55.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 2709/4744 [00:50<00:36, 55.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 2715/4744 [00:51<00:36, 55.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 2721/4744 [00:51<00:36, 55.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2727/4744 [00:51<00:36, 55.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 2733/4744 [00:51<01:07, 30.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 2754/4744 [00:51<00:32, 60.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2763/4744 [00:51<00:33, 59.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2771/4744 [00:52<00:35, 56.15it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 2778/4744 [00:52<00:33, 57.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 2785/4744 [00:52<00:34, 57.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2792/4744 [00:52<00:34, 56.81it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 2799/4744 [00:52<00:34, 56.23it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 2805/4744 [00:52<00:34, 56.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 2811/4744 [00:52<00:34, 56.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 2817/4744 [00:52<00:34, 55.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 2823/4744 [00:53<00:35, 54.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2829/4744 [00:53<00:35, 53.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 2835/4744 [00:53<00:36, 52.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2841/4744 [00:53<00:35, 52.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2847/4744 [00:53<00:35, 53.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2853/4744 [00:53<00:35, 53.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 2859/4744 [00:53<00:34, 54.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2865/4744 [00:53<00:34, 54.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2871/4744 [00:53<00:34, 54.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2877/4744 [00:54<00:34, 53.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 2883/4744 [00:54<00:34, 54.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2889/4744 [00:54<00:34, 54.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2895/4744 [00:54<00:34, 53.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2901/4744 [00:54<00:34, 53.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 2907/4744 [00:54<00:33, 54.29it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2913/4744 [00:54<00:33, 54.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2919/4744 [00:54<00:33, 54.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2925/4744 [00:54<00:33, 54.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 2931/4744 [00:55<00:33, 54.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2937/4744 [00:55<00:33, 54.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2943/4744 [00:55<01:00, 29.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2964/4744 [00:55<00:29, 60.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 2973/4744 [00:55<00:30, 58.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2981/4744 [00:56<00:30, 57.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2989/4744 [00:56<00:30, 57.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2996/4744 [00:56<00:30, 56.69it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 3003/4744 [00:56<00:30, 56.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 3010/4744 [00:56<00:31, 55.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 3016/4744 [00:56<00:30, 55.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 3022/4744 [00:56<00:31, 55.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 3028/4744 [00:56<00:30, 55.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 3034/4744 [00:57<00:30, 55.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 3040/4744 [00:57<00:30, 55.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 3046/4744 [00:57<00:30, 55.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 3052/4744 [00:57<00:30, 55.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 3058/4744 [00:57<00:30, 55.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 3064/4744 [00:57<00:30, 55.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 3070/4744 [00:57<00:29, 55.87it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 3076/4744 [00:57<00:29, 55.61it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 3082/4744 [00:57<00:29, 56.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 3088/4744 [00:57<00:29, 56.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 3094/4744 [00:58<00:29, 56.36it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 3100/4744 [00:58<00:29, 55.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 3106/4744 [00:58<00:29, 56.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 3112/4744 [00:58<00:28, 56.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 3118/4744 [00:58<00:28, 56.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 3124/4744 [00:58<00:28, 56.16it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 3130/4744 [00:58<00:30, 53.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 3137/4744 [00:58<00:28, 57.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 3143/4744 [00:58<00:27, 57.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 3149/4744 [00:59<00:27, 57.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 3155/4744 [00:59<00:29, 54.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 3162/4744 [00:59<00:27, 57.58it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 3168/4744 [00:59<00:27, 57.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 3174/4744 [00:59<00:27, 56.74it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 3180/4744 [00:59<00:28, 54.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 3187/4744 [00:59<00:27, 57.66it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 3193/4744 [00:59<00:26, 57.65it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 3199/4744 [00:59<00:27, 56.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 3205/4744 [01:00<00:28, 54.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 3211/4744 [01:00<00:27, 55.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 3218/4744 [01:00<00:26, 58.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 3224/4744 [01:00<00:26, 57.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 3230/4744 [01:00<00:26, 57.59it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 3236/4744 [01:00<00:26, 57.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 3242/4744 [01:00<00:26, 57.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 3248/4744 [01:00<00:26, 57.50it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 3254/4744 [01:00<00:25, 57.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 3260/4744 [01:00<00:25, 57.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 3266/4744 [01:01<00:25, 57.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 3272/4744 [01:01<00:26, 56.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 3278/4744 [01:01<00:26, 54.50it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 3284/4744 [01:01<00:27, 53.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 3290/4744 [01:01<00:27, 52.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 3296/4744 [01:01<00:27, 52.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 3302/4744 [01:01<00:27, 52.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 3308/4744 [01:01<00:27, 52.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 3314/4744 [01:02<00:26, 53.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 3320/4744 [01:02<00:26, 53.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 3326/4744 [01:02<00:26, 54.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 3332/4744 [01:02<00:26, 53.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 3338/4744 [01:02<00:26, 53.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 3344/4744 [01:02<00:25, 54.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 3350/4744 [01:02<00:25, 54.54it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 3356/4744 [01:02<00:25, 53.94it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 3362/4744 [01:02<00:26, 52.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 3368/4744 [01:03<00:25, 53.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 3374/4744 [01:03<00:25, 53.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 3380/4744 [01:03<00:44, 30.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 3399/4744 [01:03<00:22, 59.30it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 3408/4744 [01:03<00:23, 55.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 3416/4744 [01:03<00:24, 54.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 3423/4744 [01:04<00:23, 55.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 3430/4744 [01:04<00:23, 56.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 3437/4744 [01:04<00:23, 56.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 3444/4744 [01:04<00:23, 55.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 3450/4744 [01:04<00:23, 55.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 3456/4744 [01:04<00:22, 56.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 3462/4744 [01:04<00:23, 55.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 3468/4744 [01:04<00:23, 53.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 3474/4744 [01:05<00:24, 52.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 3480/4744 [01:05<00:24, 51.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 3486/4744 [01:05<00:24, 52.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 3492/4744 [01:05<00:23, 52.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 3498/4744 [01:05<00:23, 53.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 3504/4744 [01:05<00:22, 54.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 3510/4744 [01:05<00:22, 55.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 3516/4744 [01:05<00:22, 55.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 3522/4744 [01:05<00:21, 56.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 3528/4744 [01:05<00:21, 56.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 3534/4744 [01:06<00:21, 56.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 3540/4744 [01:06<00:21, 57.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 3546/4744 [01:06<00:20, 57.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 3552/4744 [01:06<00:20, 57.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 3558/4744 [01:06<00:20, 56.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 3564/4744 [01:06<00:21, 54.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 3571/4744 [01:06<00:20, 58.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 3577/4744 [01:06<00:20, 57.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 3583/4744 [01:06<00:20, 57.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 3589/4744 [01:07<00:19, 57.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 3595/4744 [01:07<00:21, 53.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 3601/4744 [01:07<00:22, 50.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 3607/4744 [01:07<00:22, 51.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 3613/4744 [01:07<00:23, 49.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 3618/4744 [01:07<00:23, 47.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 3624/4744 [01:07<00:23, 48.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3630/4744 [01:07<00:21, 50.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3636/4744 [01:08<00:21, 52.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 3642/4744 [01:08<00:20, 53.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3648/4744 [01:08<00:20, 54.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 3654/4744 [01:08<00:19, 54.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3660/4744 [01:08<00:19, 55.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3666/4744 [01:08<00:19, 54.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3672/4744 [01:08<00:19, 53.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 3678/4744 [01:08<00:20, 52.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3684/4744 [01:08<00:20, 52.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3690/4744 [01:09<00:19, 53.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3696/4744 [01:09<00:19, 53.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3702/4744 [01:09<00:19, 53.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3708/4744 [01:09<00:19, 54.16it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3714/4744 [01:09<00:18, 54.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3720/4744 [01:09<00:18, 55.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3726/4744 [01:09<00:18, 54.83it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3732/4744 [01:09<00:18, 55.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3738/4744 [01:09<00:18, 54.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3744/4744 [01:10<00:18, 53.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3750/4744 [01:10<00:19, 52.19it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3756/4744 [01:10<00:19, 51.50it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3762/4744 [01:10<00:18, 52.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3768/4744 [01:10<00:18, 52.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3774/4744 [01:10<00:18, 53.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3780/4744 [01:10<00:17, 53.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3786/4744 [01:10<00:17, 54.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3792/4744 [01:10<00:17, 54.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3798/4744 [01:11<00:17, 54.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3804/4744 [01:11<00:17, 54.39it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3810/4744 [01:11<00:17, 54.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3816/4744 [01:11<00:16, 54.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3822/4744 [01:11<00:16, 54.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3828/4744 [01:11<00:16, 54.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3834/4744 [01:11<00:16, 55.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3840/4744 [01:11<00:16, 55.52it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3846/4744 [01:11<00:16, 54.96it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3852/4744 [01:12<00:16, 54.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3858/4744 [01:12<00:16, 54.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3864/4744 [01:12<00:16, 54.98it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3870/4744 [01:12<00:16, 54.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3876/4744 [01:12<00:16, 53.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 3882/4744 [01:12<00:16, 53.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3888/4744 [01:12<00:15, 54.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3894/4744 [01:12<00:15, 54.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3900/4744 [01:12<00:15, 55.16it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3906/4744 [01:12<00:15, 55.13it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3912/4744 [01:13<00:14, 55.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3918/4744 [01:13<00:14, 55.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3924/4744 [01:13<00:14, 55.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3930/4744 [01:13<00:14, 55.69it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3936/4744 [01:13<00:14, 55.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3942/4744 [01:13<00:14, 55.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3948/4744 [01:13<00:14, 55.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3954/4744 [01:13<00:14, 55.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3960/4744 [01:13<00:13, 56.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3966/4744 [01:14<00:13, 55.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3972/4744 [01:14<00:13, 55.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3978/4744 [01:14<00:13, 55.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3984/4744 [01:14<00:13, 56.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3990/4744 [01:14<00:13, 56.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 3996/4744 [01:14<00:13, 55.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 4002/4744 [01:14<00:13, 56.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 4008/4744 [01:14<00:13, 55.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 4014/4744 [01:14<00:13, 55.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 4020/4744 [01:15<00:13, 55.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 4026/4744 [01:15<00:12, 55.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 4032/4744 [01:15<00:12, 55.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 4038/4744 [01:15<00:12, 55.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 4044/4744 [01:15<00:12, 55.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 4050/4744 [01:15<00:12, 55.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 4056/4744 [01:15<00:12, 55.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 4062/4744 [01:15<00:12, 55.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 4068/4744 [01:15<00:12, 54.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4074/4744 [01:16<00:12, 55.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4080/4744 [01:16<00:11, 55.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4086/4744 [01:16<00:11, 55.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 4092/4744 [01:16<00:11, 55.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 4098/4744 [01:16<00:11, 55.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 4104/4744 [01:16<00:11, 54.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4110/4744 [01:16<00:11, 54.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4116/4744 [01:16<00:11, 54.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 4122/4744 [01:16<00:11, 54.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4128/4744 [01:16<00:11, 54.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4134/4744 [01:17<00:11, 54.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4140/4744 [01:17<00:10, 55.00it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4146/4744 [01:17<00:10, 55.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4152/4744 [01:17<00:10, 55.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4158/4744 [01:17<00:10, 54.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4164/4744 [01:17<00:10, 54.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4170/4744 [01:17<00:10, 54.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4176/4744 [01:17<00:10, 54.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4182/4744 [01:17<00:10, 54.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4188/4744 [01:18<00:10, 54.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4194/4744 [01:18<00:10, 54.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4200/4744 [01:18<00:10, 53.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4206/4744 [01:18<00:09, 54.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4212/4744 [01:18<00:09, 55.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4218/4744 [01:18<00:09, 55.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4224/4744 [01:18<00:09, 55.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4230/4744 [01:18<00:09, 55.32it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4236/4744 [01:18<00:09, 54.39it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4242/4744 [01:19<00:09, 53.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4248/4744 [01:19<00:09, 52.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4254/4744 [01:19<00:09, 51.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4260/4744 [01:19<00:09, 52.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4266/4744 [01:19<00:08, 53.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4272/4744 [01:19<00:08, 54.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4278/4744 [01:19<00:08, 54.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4284/4744 [01:19<00:08, 54.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4290/4744 [01:19<00:08, 55.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4296/4744 [01:20<00:08, 54.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4302/4744 [01:20<00:08, 54.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4308/4744 [01:20<00:07, 55.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4314/4744 [01:20<00:08, 51.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4321/4744 [01:20<00:07, 53.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4327/4744 [01:20<00:07, 52.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4333/4744 [01:20<00:07, 53.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4339/4744 [01:20<00:07, 54.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4345/4744 [01:20<00:07, 54.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4351/4744 [01:21<00:07, 54.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4357/4744 [01:21<00:07, 53.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4363/4744 [01:21<00:07, 52.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4369/4744 [01:21<00:07, 52.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4375/4744 [01:21<00:07, 51.27it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4381/4744 [01:21<00:07, 48.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4386/4744 [01:21<00:07, 48.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4391/4744 [01:21<00:07, 46.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4396/4744 [01:22<00:07, 46.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4401/4744 [01:22<00:07, 46.29it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4407/4744 [01:22<00:07, 47.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4413/4744 [01:22<00:06, 48.67it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4419/4744 [01:22<00:06, 49.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4425/4744 [01:22<00:06, 49.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4431/4744 [01:22<00:06, 51.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4437/4744 [01:22<00:05, 52.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4443/4744 [01:22<00:05, 52.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4449/4744 [01:23<00:05, 53.14it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4455/4744 [01:23<00:05, 52.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4461/4744 [01:23<00:05, 51.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4467/4744 [01:23<00:05, 51.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4473/4744 [01:23<00:05, 50.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4479/4744 [01:23<00:05, 47.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4484/4744 [01:23<00:05, 46.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4489/4744 [01:23<00:05, 45.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4495/4744 [01:24<00:05, 46.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4500/4744 [01:24<00:05, 46.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4506/4744 [01:24<00:04, 48.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4511/4744 [01:24<00:04, 48.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4516/4744 [01:24<00:04, 49.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4522/4744 [01:24<00:04, 51.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4528/4744 [01:24<00:04, 52.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4534/4744 [01:24<00:04, 52.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4540/4744 [01:24<00:03, 52.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4546/4744 [01:25<00:03, 53.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4552/4744 [01:25<00:03, 53.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4558/4744 [01:25<00:03, 54.45it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4564/4744 [01:25<00:03, 49.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4570/4744 [01:25<00:03, 47.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4577/4744 [01:25<00:03, 52.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4584/4744 [01:25<00:02, 55.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4591/4744 [01:25<00:02, 58.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4598/4744 [01:25<00:02, 59.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4605/4744 [01:26<00:02, 61.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4612/4744 [01:26<00:02, 62.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4619/4744 [01:26<00:03, 38.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4641/4744 [01:26<00:01, 72.39it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4651/4744 [01:26<00:01, 70.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4660/4744 [01:26<00:01, 68.11it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4668/4744 [01:27<00:01, 67.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4676/4744 [01:27<00:01, 66.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4684/4744 [01:27<00:00, 63.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4691/4744 [01:27<00:00, 59.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 4698/4744 [01:27<00:00, 58.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 4705/4744 [01:27<00:00, 59.57it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 4712/4744 [01:27<00:00, 60.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4719/4744 [01:27<00:00, 58.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 4727/4744 [01:28<00:00, 61.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4734/4744 [01:28<00:00, 62.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 4741/4744 [01:28<00:00, 60.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4744/4744 [01:28<00:00, 53.72it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.3291
Epoch 1 Step 51 Train Loss: 0.3399
Epoch 1 Step 101 Train Loss: 0.3201
Epoch 1: Train Overall MSE: 0.3752 Validation Overall MSE: 0.4008. 
Train Top 20 DE MSE: 0.8441 Validation Top 20 DE MSE: 0.8447. 
Epoch 2 Step 1 Train Loss: 0.3310
Epoch 2 Step 51 Train Loss: 0.3192
Epoch 2 Step 101 Train Loss: 0.3262
Epoch 2: Train Overall MSE: 0.0680 Validation Overall MSE: 0.0650. 
Train Top 20 DE MSE: 0.1426 Validation Top 20 DE MSE: 0.1073. 
Epoch 3 Step 1 Train Loss: 0.2796
Epoch 3 Step 51 Train Loss: 0.3028
Epoch 3 Step 101 Train Loss: 0.3473
Epoch 3: Train Overall MSE: 0.0143 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0544 Validation Top 20 DE MSE: 0.0089. 
Epoch 4 Step 1 Train Loss: 0.3809
Epoch 4 Step 51 Train Loss: 0.3135
Epoch 4 Step 101 Train Loss: 0.3003
Epoch 4: Train Overall MSE: 0.0183 Validation Overall MSE: 0.0094. 
Train Top 20 DE MSE: 0.0840 Validation Top 20 DE MSE: 0.0186. 
Epoch 5 Step 1 Train Loss: 0.3173
Epoch 5 Step 51 Train Loss: 0.3769
Epoch 5 Step 101 Train Loss: 0.3021
Epoch 5: Train Overall MSE: 0.0149 Validation Overall MSE: 0.0067. 
Train Top 20 DE MSE: 0.0910 Validation Top 20 DE MSE: 0.0319. 
Epoch 6 Step 1 Train Loss: 0.3019
Epoch 6 Step 51 Train Loss: 0.3034
Epoch 6 Step 101 Train Loss: 0.3726
Epoch 6: Train Overall MSE: 0.0218 Validation Overall MSE: 0.0158. 
Train Top 20 DE MSE: 0.1140 Validation Top 20 DE MSE: 0.0431. 
Epoch 7 Step 1 Train Loss: 0.2782
Epoch 7 Step 51 Train Loss: 0.3202
Epoch 7 Step 101 Train Loss: 0.2783
Epoch 7: Train Overall MSE: 0.0088 Validation Overall MSE: 0.0018. 
Train Top 20 DE MSE: 0.0468 Validation Top 20 DE MSE: 0.0110. 
Epoch 8 Step 1 Train Loss: 0.3012
Epoch 8 Step 51 Train Loss: 0.3057
Epoch 8 Step 101 Train Loss: 0.3214
Epoch 8: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0022. 
Train Top 20 DE MSE: 0.0366 Validation Top 20 DE MSE: 0.0553. 
Epoch 9 Step 1 Train Loss: 0.3048
Epoch 9 Step 51 Train Loss: 0.3058
Epoch 9 Step 101 Train Loss: 0.3228
Epoch 9: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0371 Validation Top 20 DE MSE: 0.0644. 
Epoch 10 Step 1 Train Loss: 0.2978
Epoch 10 Step 51 Train Loss: 0.2966
Epoch 10 Step 101 Train Loss: 0.3213
Epoch 10: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0372 Validation Top 20 DE MSE: 0.0638. 
Epoch 11 Step 1 Train Loss: 0.3256
Epoch 11 Step 51 Train Loss: 0.2833
Epoch 11 Step 101 Train Loss: 0.3066
Epoch 11: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0363 Validation Top 20 DE MSE: 0.0711. 
Epoch 12 Step 1 Train Loss: 0.3267
Epoch 12 Step 51 Train Loss: 0.3154
Epoch 12 Step 101 Train Loss: 0.3254
Epoch 12: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0362 Validation Top 20 DE MSE: 0.0649. 
Epoch 13 Step 1 Train Loss: 0.2916
Epoch 13 Step 51 Train Loss: 0.3186
Epoch 13 Step 101 Train Loss: 0.2809
Epoch 13: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0369 Validation Top 20 DE MSE: 0.0729. 
Epoch 14 Step 1 Train Loss: 0.3147
Epoch 14 Step 51 Train Loss: 0.3245
Epoch 14 Step 101 Train Loss: 0.3136
Epoch 14: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0371 Validation Top 20 DE MSE: 0.0743. 
Epoch 15 Step 1 Train Loss: 0.2881
Epoch 15 Step 51 Train Loss: 0.3213
Epoch 15 Step 101 Train Loss: 0.2825
Epoch 15: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0023. 
Train Top 20 DE MSE: 0.0367 Validation Top 20 DE MSE: 0.0696. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.7397
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.012984408
test_unseen_single_pearson: 0.9563124025721079
test_unseen_single_mse_de: 0.73970485
test_unseen_single_pearson_de: 0.8814776087885068
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.26066812164399566
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.25
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5
test_unseen_single_mse_top20_de_non_dropout: 0.73970485
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.020 MB uploadedwandb: | 0.001 MB of 0.020 MB uploadedwandb: / 0.020 MB of 0.020 MB uploadedwandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.020 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.7397
wandb:                                              test_de_pearson 0.88148
wandb:               test_frac_opposite_direction_top20_non_dropout 0.25
wandb:                          test_frac_sigma_below_1_non_dropout 0.5
wandb:                                                     test_mse 0.01298
wandb:                                test_mse_top20_de_non_dropout 0.7397
wandb:                                                 test_pearson 0.95631
wandb:                                           test_pearson_delta 0.26067
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.25
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.5
wandb:                                       test_unseen_single_mse 0.01298
wandb:                                    test_unseen_single_mse_de 0.7397
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.7397
wandb:                                   test_unseen_single_pearson 0.95631
wandb:                                test_unseen_single_pearson_de 0.88148
wandb:                             test_unseen_single_pearson_delta 0.26067
wandb:                                                 train_de_mse 0.03672
wandb:                                             train_de_pearson 0.79902
wandb:                                                    train_mse 0.00789
wandb:                                                train_pearson 0.97466
wandb:                                                training_loss 0.30883
wandb:                                                   val_de_mse 0.06964
wandb:                                               val_de_pearson 0.98348
wandb:                                                      val_mse 0.00235
wandb:                                                  val_pearson 0.99247
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/y5bhg5lb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_144202-y5bhg5lb/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_144736-fzjhymz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/fzjhymz4
wandb: WARNING Serializing object of type ndarray that is 8000128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3411
Epoch 1 Step 51 Train Loss: 0.3610
Epoch 1 Step 101 Train Loss: 0.3343
Epoch 1: Train Overall MSE: 5.2613 Validation Overall MSE: 5.4307. 
Train Top 20 DE MSE: 18.2881 Validation Top 20 DE MSE: 20.5450. 
Epoch 2 Step 1 Train Loss: 0.3705
Epoch 2 Step 51 Train Loss: 0.3222
Epoch 2 Step 101 Train Loss: 0.3179
Epoch 2: Train Overall MSE: 0.8797 Validation Overall MSE: 0.9232. 
Train Top 20 DE MSE: 2.8967 Validation Top 20 DE MSE: 3.4888. 
Epoch 3 Step 1 Train Loss: 0.3069
Epoch 3 Step 51 Train Loss: 0.3091
Epoch 3 Step 101 Train Loss: 0.3450
Epoch 3: Train Overall MSE: 2.8815 Validation Overall MSE: 2.9473. 
Train Top 20 DE MSE: 9.5834 Validation Top 20 DE MSE: 8.1771. 
Epoch 4 Step 1 Train Loss: 0.3151
Epoch 4 Step 51 Train Loss: 0.3200
Epoch 4 Step 101 Train Loss: 0.3247
Epoch 4: Train Overall MSE: 0.1437 Validation Overall MSE: 0.1479. 
Train Top 20 DE MSE: 1.6100 Validation Top 20 DE MSE: 0.9327. 
Epoch 5 Step 1 Train Loss: 0.3053
Epoch 5 Step 51 Train Loss: 0.2849
Epoch 5 Step 101 Train Loss: 0.2897
Epoch 5: Train Overall MSE: 0.0691 Validation Overall MSE: 0.0712. 
Train Top 20 DE MSE: 0.9192 Validation Top 20 DE MSE: 0.5534. 
Epoch 6 Step 1 Train Loss: 0.2822
Epoch 6 Step 51 Train Loss: 0.3095
Epoch 6 Step 101 Train Loss: 0.3233
Epoch 6: Train Overall MSE: 0.0352 Validation Overall MSE: 0.0314. 
Train Top 20 DE MSE: 0.7376 Validation Top 20 DE MSE: 0.5378. 
Epoch 7 Step 1 Train Loss: 0.3110
Epoch 7 Step 51 Train Loss: 0.2991
Epoch 7 Step 101 Train Loss: 0.3236
Epoch 7: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0835 Validation Top 20 DE MSE: 0.2522. 
Epoch 8 Step 1 Train Loss: 0.3025
Epoch 8 Step 51 Train Loss: 0.2952
Epoch 8 Step 101 Train Loss: 0.2863
Epoch 8: Train Overall MSE: 0.0075 Validation Overall MSE: 0.0042. 
Train Top 20 DE MSE: 0.0610 Validation Top 20 DE MSE: 0.1850. 
Epoch 9 Step 1 Train Loss: 0.3082
Epoch 9 Step 51 Train Loss: 0.3445
Epoch 9 Step 101 Train Loss: 0.2917
Epoch 9: Train Overall MSE: 0.0070 Validation Overall MSE: 0.0038. 
Train Top 20 DE MSE: 0.0506 Validation Top 20 DE MSE: 0.1451. 
Epoch 10 Step 1 Train Loss: 0.3223
Epoch 10 Step 51 Train Loss: 0.3203
Epoch 10 Step 101 Train Loss: 0.3033
Epoch 10: Train Overall MSE: 0.0072 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0463 Validation Top 20 DE MSE: 0.1461. 
Epoch 11 Step 1 Train Loss: 0.3140
Epoch 11 Step 51 Train Loss: 0.3308
Epoch 11 Step 101 Train Loss: 0.3046
Epoch 11: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0479 Validation Top 20 DE MSE: 0.1380. 
Epoch 12 Step 1 Train Loss: 0.3368
Epoch 12 Step 51 Train Loss: 0.2840
Epoch 12 Step 101 Train Loss: 0.3048
Epoch 12: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0497 Validation Top 20 DE MSE: 0.1500. 
Epoch 13 Step 1 Train Loss: 0.2942
Epoch 13 Step 51 Train Loss: 0.2971
Epoch 13 Step 101 Train Loss: 0.2957
Epoch 13: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0035. 
Train Top 20 DE MSE: 0.0505 Validation Top 20 DE MSE: 0.1404. 
Epoch 14 Step 1 Train Loss: 0.2794
Epoch 14 Step 51 Train Loss: 0.2795
Epoch 14 Step 101 Train Loss: 0.3151
Epoch 14: Train Overall MSE: 0.0073 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0486 Validation Top 20 DE MSE: 0.1453. 
Epoch 15 Step 1 Train Loss: 0.2942
Epoch 15 Step 51 Train Loss: 0.3132
Epoch 15 Step 101 Train Loss: 0.2834
Epoch 15: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0036. 
Train Top 20 DE MSE: 0.0545 Validation Top 20 DE MSE: 0.1556. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0701
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0022773163
test_unseen_single_pearson: 0.9928879803388955
test_unseen_single_mse_de: 0.07014046
test_unseen_single_pearson_de: 0.9701938034761644
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.5737969671763108
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.1
test_unseen_single_frac_sigma_below_1_non_dropout: 1.0
test_unseen_single_mse_top20_de_non_dropout: 0.07014046
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.005 MB of 0.019 MB uploadedwandb: / 0.005 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.07014
wandb:                                              test_de_pearson 0.97019
wandb:               test_frac_opposite_direction_top20_non_dropout 0.1
wandb:                          test_frac_sigma_below_1_non_dropout 1.0
wandb:                                                     test_mse 0.00228
wandb:                                test_mse_top20_de_non_dropout 0.07014
wandb:                                                 test_pearson 0.99289
wandb:                                           test_pearson_delta 0.5738
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.1
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 1.0
wandb:                                       test_unseen_single_mse 0.00228
wandb:                                    test_unseen_single_mse_de 0.07014
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.07014
wandb:                                   test_unseen_single_pearson 0.99289
wandb:                                test_unseen_single_pearson_de 0.97019
wandb:                             test_unseen_single_pearson_delta 0.5738
wandb:                                                 train_de_mse 0.05454
wandb:                                             train_de_pearson 0.79688
wandb:                                                    train_mse 0.00738
wandb:                                                train_pearson 0.97558
wandb:                                                training_loss 0.29387
wandb:                                                   val_de_mse 0.15563
wandb:                                               val_de_pearson 0.94552
wandb:                                                      val_mse 0.00359
wandb:                                                  val_pearson 0.98774
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/fzjhymz4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_144736-fzjhymz4/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_145027-hv0je6kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/hv0je6kr
wandb: WARNING Serializing object of type ndarray that is 8000128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3335
Epoch 1 Step 51 Train Loss: 0.3072
Epoch 1 Step 101 Train Loss: 0.3338
Epoch 1: Train Overall MSE: 0.1286 Validation Overall MSE: 0.1510. 
Train Top 20 DE MSE: 1.7066 Validation Top 20 DE MSE: 0.3279. 
Epoch 2 Step 1 Train Loss: 0.3267
Epoch 2 Step 51 Train Loss: 0.3211
Epoch 2 Step 101 Train Loss: 0.3365
Epoch 2: Train Overall MSE: 0.0066 Validation Overall MSE: 0.0421. 
Train Top 20 DE MSE: 0.2641 Validation Top 20 DE MSE: 0.1514. 
Epoch 3 Step 1 Train Loss: 0.3102
Epoch 3 Step 51 Train Loss: 0.3254
Epoch 3 Step 101 Train Loss: 0.3515
Epoch 3: Train Overall MSE: 0.0248 Validation Overall MSE: 0.0639. 
Train Top 20 DE MSE: 0.5857 Validation Top 20 DE MSE: 0.2609. 
Epoch 4 Step 1 Train Loss: 0.3134
Epoch 4 Step 51 Train Loss: 0.3194
Epoch 4 Step 101 Train Loss: 0.3214
Epoch 4: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0419. 
Train Top 20 DE MSE: 0.3080 Validation Top 20 DE MSE: 0.1680. 
Epoch 5 Step 1 Train Loss: 0.3332
Epoch 5 Step 51 Train Loss: 0.3426
Epoch 5 Step 101 Train Loss: 0.3602
Epoch 5: Train Overall MSE: 0.0051 Validation Overall MSE: 0.0417. 
Train Top 20 DE MSE: 0.2766 Validation Top 20 DE MSE: 0.1680. 
Epoch 6 Step 1 Train Loss: 0.3298
Epoch 6 Step 51 Train Loss: 0.3122
Epoch 6 Step 101 Train Loss: 0.3076
Epoch 6: Train Overall MSE: 0.0050 Validation Overall MSE: 0.0426. 
Train Top 20 DE MSE: 0.3521 Validation Top 20 DE MSE: 0.1784. 
Epoch 7 Step 1 Train Loss: 0.3257
Epoch 7 Step 51 Train Loss: 0.3200
Epoch 7 Step 101 Train Loss: 0.3323
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0454. 
Train Top 20 DE MSE: 0.0573 Validation Top 20 DE MSE: 0.1534. 
Epoch 8 Step 1 Train Loss: 0.3093
Epoch 8 Step 51 Train Loss: 0.2970
Epoch 8 Step 101 Train Loss: 0.3466
Epoch 8: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0426. 
Train Top 20 DE MSE: 0.0939 Validation Top 20 DE MSE: 0.1562. 
Epoch 9 Step 1 Train Loss: 0.3713
Epoch 9 Step 51 Train Loss: 0.3105
Epoch 9 Step 101 Train Loss: 0.3671
Epoch 9: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0492. 
Train Top 20 DE MSE: 0.0254 Validation Top 20 DE MSE: 0.1491. 
Epoch 10 Step 1 Train Loss: 0.3313
Epoch 10 Step 51 Train Loss: 0.3242
Epoch 10 Step 101 Train Loss: 0.3468
Epoch 10: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0483. 
Train Top 20 DE MSE: 0.0223 Validation Top 20 DE MSE: 0.1499. 
Epoch 11 Step 1 Train Loss: 0.3087
Epoch 11 Step 51 Train Loss: 0.3369
Epoch 11 Step 101 Train Loss: 0.2875
Epoch 11: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0494. 
Train Top 20 DE MSE: 0.0251 Validation Top 20 DE MSE: 0.1495. 
Epoch 12 Step 1 Train Loss: 0.3326
Epoch 12 Step 51 Train Loss: 0.3161
Epoch 12 Step 101 Train Loss: 0.3146
Epoch 12: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0505. 
Train Top 20 DE MSE: 0.0175 Validation Top 20 DE MSE: 0.1488. 
Epoch 13 Step 1 Train Loss: 0.3275
Epoch 13 Step 51 Train Loss: 0.3844
Epoch 13 Step 101 Train Loss: 0.3071
Epoch 13: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0508. 
Train Top 20 DE MSE: 0.0198 Validation Top 20 DE MSE: 0.1494. 
Epoch 14 Step 1 Train Loss: 0.3187
Epoch 14 Step 51 Train Loss: 0.3525
Epoch 14 Step 101 Train Loss: 0.3289
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0508. 
Train Top 20 DE MSE: 0.0176 Validation Top 20 DE MSE: 0.1489. 
Epoch 15 Step 1 Train Loss: 0.3106
Epoch 15 Step 51 Train Loss: 0.3024
Epoch 15 Step 101 Train Loss: 0.3281
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0493. 
Train Top 20 DE MSE: 0.0238 Validation Top 20 DE MSE: 0.1499. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.0234
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0020337182
test_unseen_single_pearson: 0.993923446229514
test_unseen_single_mse_de: 0.023431052
test_unseen_single_pearson_de: 0.9904361578020622
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.5557572449458799
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.05
test_unseen_single_frac_sigma_below_1_non_dropout: 0.975
test_unseen_single_mse_top20_de_non_dropout: 0.023431052
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.001 MB uploadedwandb: | 0.001 MB of 0.001 MB uploadedwandb: / 0.003 MB of 0.019 MB uploadedwandb: - 0.014 MB of 0.019 MB uploadedwandb: \ 0.014 MB of 0.019 MB uploadedwandb: | 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.02343
wandb:                                              test_de_pearson 0.99044
wandb:               test_frac_opposite_direction_top20_non_dropout 0.05
wandb:                          test_frac_sigma_below_1_non_dropout 0.975
wandb:                                                     test_mse 0.00203
wandb:                                test_mse_top20_de_non_dropout 0.02343
wandb:                                                 test_pearson 0.99392
wandb:                                           test_pearson_delta 0.55576
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.05
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.975
wandb:                                       test_unseen_single_mse 0.00203
wandb:                                    test_unseen_single_mse_de 0.02343
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.02343
wandb:                                   test_unseen_single_pearson 0.99392
wandb:                                test_unseen_single_pearson_de 0.99044
wandb:                             test_unseen_single_pearson_delta 0.55576
wandb:                                                 train_de_mse 0.02382
wandb:                                             train_de_pearson 0.99524
wandb:                                                    train_mse 0.00174
wandb:                                                train_pearson 0.99483
wandb:                                                training_loss 0.29985
wandb:                                                   val_de_mse 0.1499
wandb:                                               val_de_pearson 0.0
wandb:                                                      val_mse 0.04935
wandb:                                                  val_pearson 0.83074
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/hv0je6kr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_145027-hv0je6kr/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_145256-w0l0zy95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/w0l0zy95
wandb: WARNING Serializing object of type ndarray that is 8000128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3770
Epoch 1 Step 51 Train Loss: 0.3180
Epoch 1: Train Overall MSE: 0.5883 Validation Overall MSE: 0.6587. 
Train Top 20 DE MSE: 6.3594 Validation Top 20 DE MSE: 4.2815. 
Epoch 2 Step 1 Train Loss: 0.3483
Epoch 2 Step 51 Train Loss: 0.3367
Epoch 2: Train Overall MSE: 0.1611 Validation Overall MSE: 0.1819. 
Train Top 20 DE MSE: 1.3278 Validation Top 20 DE MSE: 1.7767. 
Epoch 3 Step 1 Train Loss: 0.3543
Epoch 3 Step 51 Train Loss: 0.3331
Epoch 3: Train Overall MSE: 0.0254 Validation Overall MSE: 0.0332. 
Train Top 20 DE MSE: 0.1348 Validation Top 20 DE MSE: 1.1313. 
Epoch 4 Step 1 Train Loss: 0.3085
Epoch 4 Step 51 Train Loss: 0.3674
Epoch 4: Train Overall MSE: 0.0207 Validation Overall MSE: 0.0232. 
Train Top 20 DE MSE: 0.2111 Validation Top 20 DE MSE: 1.3408. 
Epoch 5 Step 1 Train Loss: 0.3026
Epoch 5 Step 51 Train Loss: 0.3136
Epoch 5: Train Overall MSE: 0.0140 Validation Overall MSE: 0.0192. 
Train Top 20 DE MSE: 0.1075 Validation Top 20 DE MSE: 1.2861. 
Epoch 6 Step 1 Train Loss: 0.3232
Epoch 6 Step 51 Train Loss: 0.2924
Epoch 6: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0143. 
Train Top 20 DE MSE: 0.0612 Validation Top 20 DE MSE: 1.3735. 
Epoch 7 Step 1 Train Loss: 0.3445
Epoch 7 Step 51 Train Loss: 0.3202
Epoch 7: Train Overall MSE: 0.0080 Validation Overall MSE: 0.0158. 
Train Top 20 DE MSE: 0.0473 Validation Top 20 DE MSE: 1.3266. 
Epoch 8 Step 1 Train Loss: 0.3229
Epoch 8 Step 51 Train Loss: 0.3148
Epoch 8: Train Overall MSE: 0.0074 Validation Overall MSE: 0.0148. 
Train Top 20 DE MSE: 0.0457 Validation Top 20 DE MSE: 1.3616. 
Epoch 9 Step 1 Train Loss: 0.3012
Epoch 9 Step 51 Train Loss: 0.2933
Epoch 9: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0150. 
Train Top 20 DE MSE: 0.0410 Validation Top 20 DE MSE: 1.3335. 
Epoch 10 Step 1 Train Loss: 0.3387
Epoch 10 Step 51 Train Loss: 0.3134
Epoch 10: Train Overall MSE: 0.0077 Validation Overall MSE: 0.0152. 
Train Top 20 DE MSE: 0.0403 Validation Top 20 DE MSE: 1.3288. 
Epoch 11 Step 1 Train Loss: 0.3121
Epoch 11 Step 51 Train Loss: 0.2913
Epoch 11: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0149. 
Train Top 20 DE MSE: 0.0416 Validation Top 20 DE MSE: 1.3450. 
Epoch 12 Step 1 Train Loss: 0.3053
Epoch 12 Step 51 Train Loss: 0.3511
Epoch 12: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0150. 
Train Top 20 DE MSE: 0.0402 Validation Top 20 DE MSE: 1.3368. 
Epoch 13 Step 1 Train Loss: 0.3517
Epoch 13 Step 51 Train Loss: 0.3092
Epoch 13: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0151. 
Train Top 20 DE MSE: 0.0386 Validation Top 20 DE MSE: 1.3338. 
Epoch 14 Step 1 Train Loss: 0.2918
Epoch 14 Step 51 Train Loss: 0.3453
Epoch 14: Train Overall MSE: 0.0079 Validation Overall MSE: 0.0149. 
Train Top 20 DE MSE: 0.0409 Validation Top 20 DE MSE: 1.3409. 
Epoch 15 Step 1 Train Loss: 0.3049
Epoch 15 Step 51 Train Loss: 0.3071
Epoch 15: Train Overall MSE: 0.0078 Validation Overall MSE: 0.0151. 
Train Top 20 DE MSE: 0.0383 Validation Top 20 DE MSE: 1.3310. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1135
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.021176541
test_unseen_single_pearson: 0.9315617622906478
test_unseen_single_mse_de: 0.11352816
test_unseen_single_pearson_de: 0.9523797823981319
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3967426470764247
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.05
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8999999999999999
test_unseen_single_mse_top20_de_non_dropout: 0.11352816
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.006 MB of 0.019 MB uploadedwandb: / 0.006 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÉ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.11353
wandb:                                              test_de_pearson 0.95238
wandb:               test_frac_opposite_direction_top20_non_dropout 0.05
wandb:                          test_frac_sigma_below_1_non_dropout 0.9
wandb:                                                     test_mse 0.02118
wandb:                                test_mse_top20_de_non_dropout 0.11353
wandb:                                                 test_pearson 0.93156
wandb:                                           test_pearson_delta 0.39674
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.05
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.9
wandb:                                       test_unseen_single_mse 0.02118
wandb:                                    test_unseen_single_mse_de 0.11353
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.11353
wandb:                                   test_unseen_single_pearson 0.93156
wandb:                                test_unseen_single_pearson_de 0.95238
wandb:                             test_unseen_single_pearson_delta 0.39674
wandb:                                                 train_de_mse 0.03832
wandb:                                             train_de_pearson 0.79785
wandb:                                                    train_mse 0.00784
wandb:                                                train_pearson 0.97445
wandb:                                                training_loss 0.30669
wandb:                                                   val_de_mse 1.33102
wandb:                                               val_de_pearson 0.80759
wandb:                                                      val_mse 0.01513
wandb:                                                  val_pearson 0.94434
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/w0l0zy95
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_145256-w0l0zy95/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:2
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_145512-bkfud6iz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/bkfud6iz
wandb: WARNING Serializing object of type ndarray that is 8000128 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.3967
Epoch 1 Step 51 Train Loss: 0.3725
Epoch 1 Step 101 Train Loss: 0.3902
Epoch 1: Train Overall MSE: 0.0249 Validation Overall MSE: 0.0715. 
Train Top 20 DE MSE: 0.1316 Validation Top 20 DE MSE: 0.2244. 
Epoch 2 Step 1 Train Loss: 0.3777
Epoch 2 Step 51 Train Loss: 0.3918
Epoch 2 Step 101 Train Loss: 0.3304
Epoch 2: Train Overall MSE: 0.0509 Validation Overall MSE: 0.1022. 
Train Top 20 DE MSE: 0.1808 Validation Top 20 DE MSE: 0.3983. 
Epoch 3 Step 1 Train Loss: 0.3513
Epoch 3 Step 51 Train Loss: 0.3783
Epoch 3 Step 101 Train Loss: 0.3174
Epoch 3: Train Overall MSE: 0.0219 Validation Overall MSE: 0.0699. 
Train Top 20 DE MSE: 0.2718 Validation Top 20 DE MSE: 0.4136. 
Epoch 4 Step 1 Train Loss: 0.3245
Epoch 4 Step 51 Train Loss: 0.3085
Epoch 4 Step 101 Train Loss: 0.3021
Epoch 4: Train Overall MSE: 0.0033 Validation Overall MSE: 0.0466. 
Train Top 20 DE MSE: 0.1176 Validation Top 20 DE MSE: 0.2306. 
Epoch 5 Step 1 Train Loss: 0.3555
Epoch 5 Step 51 Train Loss: 0.3078
Epoch 5 Step 101 Train Loss: 0.3499
Epoch 5: Train Overall MSE: 0.0039 Validation Overall MSE: 0.0487. 
Train Top 20 DE MSE: 0.0758 Validation Top 20 DE MSE: 0.2120. 
Epoch 6 Step 1 Train Loss: 0.3556
Epoch 6 Step 51 Train Loss: 0.3203
Epoch 6 Step 101 Train Loss: 0.3375
Epoch 6: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0468. 
Train Top 20 DE MSE: 0.0645 Validation Top 20 DE MSE: 0.2197. 
Epoch 7 Step 1 Train Loss: 0.3042
Epoch 7 Step 51 Train Loss: 0.3116
Epoch 7 Step 101 Train Loss: 0.3054
Epoch 7: Train Overall MSE: 0.0009 Validation Overall MSE: 0.0411. 
Train Top 20 DE MSE: 0.0097 Validation Top 20 DE MSE: 0.1748. 
Epoch 8 Step 1 Train Loss: 0.3002
Epoch 8 Step 51 Train Loss: 0.3339
Epoch 8 Step 101 Train Loss: 0.3412
Epoch 8: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0409. 
Train Top 20 DE MSE: 0.0135 Validation Top 20 DE MSE: 0.1739. 
Epoch 9 Step 1 Train Loss: 0.3145
Epoch 9 Step 51 Train Loss: 0.3185
Epoch 9 Step 101 Train Loss: 0.3349
Epoch 9: Train Overall MSE: 0.0010 Validation Overall MSE: 0.0422. 
Train Top 20 DE MSE: 0.0087 Validation Top 20 DE MSE: 0.1862. 
Epoch 10 Step 1 Train Loss: 0.3441
Epoch 10 Step 51 Train Loss: 0.3187
Epoch 10 Step 101 Train Loss: 0.3133
Epoch 10: Train Overall MSE: 0.0013 Validation Overall MSE: 0.0419. 
Train Top 20 DE MSE: 0.0086 Validation Top 20 DE MSE: 0.1834. 
Epoch 11 Step 1 Train Loss: 0.3117
Epoch 11 Step 51 Train Loss: 0.3467
Epoch 11 Step 101 Train Loss: 0.3513
Epoch 11: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0418. 
Train Top 20 DE MSE: 0.0081 Validation Top 20 DE MSE: 0.1814. 
Epoch 12 Step 1 Train Loss: 0.3530
Epoch 12 Step 51 Train Loss: 0.3303
Epoch 12 Step 101 Train Loss: 0.3283
Epoch 12: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0415. 
Train Top 20 DE MSE: 0.0056 Validation Top 20 DE MSE: 0.1785. 
Epoch 13 Step 1 Train Loss: 0.3047
Epoch 13 Step 51 Train Loss: 0.3270
Epoch 13 Step 101 Train Loss: 0.3111
Epoch 13: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0416. 
Train Top 20 DE MSE: 0.0100 Validation Top 20 DE MSE: 0.1796. 
Epoch 14 Step 1 Train Loss: 0.3306
Epoch 14 Step 51 Train Loss: 0.3157
Epoch 14 Step 101 Train Loss: 0.3186
Epoch 14: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0418. 
Train Top 20 DE MSE: 0.0076 Validation Top 20 DE MSE: 0.1818. 
Epoch 15 Step 1 Train Loss: 0.3304
Epoch 15 Step 51 Train Loss: 0.3015
Epoch 15 Step 101 Train Loss: 0.3561
Epoch 15: Train Overall MSE: 0.0014 Validation Overall MSE: 0.0416. 
Train Top 20 DE MSE: 0.0077 Validation Top 20 DE MSE: 0.1796. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.7401
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.007824486
test_unseen_single_pearson: 0.9722941190549836
test_unseen_single_mse_de: 0.74011403
test_unseen_single_pearson_de: 0.8957183613487028
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.45420570734086946
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.175
test_unseen_single_frac_sigma_below_1_non_dropout: 0.5
test_unseen_single_mse_top20_de_non_dropout: 0.74011403
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.019 MB uploadedwandb: | 0.005 MB of 0.019 MB uploadedwandb: / 0.019 MB of 0.019 MB uploadedwandb: - 0.019 MB of 0.019 MB uploadedwandb: \ 0.019 MB of 0.019 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÉ
wandb:                                                   val_de_mse ‚ñÇ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                      val_mse ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.74011
wandb:                                              test_de_pearson 0.89572
wandb:               test_frac_opposite_direction_top20_non_dropout 0.175
wandb:                          test_frac_sigma_below_1_non_dropout 0.5
wandb:                                                     test_mse 0.00782
wandb:                                test_mse_top20_de_non_dropout 0.74011
wandb:                                                 test_pearson 0.97229
wandb:                                           test_pearson_delta 0.45421
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.175
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.5
wandb:                                       test_unseen_single_mse 0.00782
wandb:                                    test_unseen_single_mse_de 0.74011
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.74011
wandb:                                   test_unseen_single_pearson 0.97229
wandb:                                test_unseen_single_pearson_de 0.89572
wandb:                             test_unseen_single_pearson_delta 0.45421
wandb:                                                 train_de_mse 0.00768
wandb:                                             train_de_pearson 0.99721
wandb:                                                    train_mse 0.00145
wandb:                                                train_pearson 0.99581
wandb:                                                training_loss 0.3485
wandb:                                                   val_de_mse 0.1796
wandb:                                               val_de_pearson 0.0
wandb:                                                      val_mse 0.04163
wandb:                                                  val_pearson 0.86166
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_arrayed_RNA_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/bkfud6iz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_145512-bkfud6iz/logs
Seed set to 42
Found local copy...
These perturbations are not in the GO graph and their perturbation can thus not be predicted
[]
Local copy of pyg dataset is detected. Loading...
Done!
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:6
Done!
Creating dataloaders....
Done!
wandb: Currently logged in as: zhoumin1130. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_145829-hntc77ns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_RNA_split1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/hntc77ns
wandb: WARNING Serializing object of type ndarray that is 8011328 bytes
  0%|                                                                                       | 0/4752 [00:00<?, ?it/s]  0%|                                                                               | 4/4752 [00:00<02:04, 38.28it/s]  0%|‚ñè                                                                              | 9/4752 [00:00<01:46, 44.74it/s]  0%|‚ñè                                                                             | 14/4752 [00:00<01:41, 46.64it/s]  0%|‚ñé                                                                             | 19/4752 [00:00<01:39, 47.49it/s]  1%|‚ñç                                                                             | 24/4752 [00:00<01:37, 48.27it/s]  1%|‚ñå                                                                             | 31/4752 [00:00<01:29, 52.94it/s]  1%|‚ñå                                                                             | 37/4752 [00:00<01:28, 53.07it/s]  1%|‚ñã                                                                             | 43/4752 [00:00<01:28, 52.96it/s]  1%|‚ñä                                                                             | 49/4752 [00:00<01:28, 52.92it/s]  1%|‚ñâ                                                                             | 55/4752 [00:01<01:28, 52.88it/s]  1%|‚ñà                                                                             | 61/4752 [00:01<01:28, 53.01it/s]  1%|‚ñà                                                                             | 67/4752 [00:01<01:28, 53.04it/s]  2%|‚ñà‚ñè                                                                            | 73/4752 [00:01<01:28, 53.08it/s]  2%|‚ñà‚ñé                                                                            | 79/4752 [00:01<01:28, 52.86it/s]  2%|‚ñà‚ñç                                                                            | 85/4752 [00:01<01:28, 52.81it/s]  2%|‚ñà‚ñç                                                                            | 91/4752 [00:01<01:28, 52.90it/s]  2%|‚ñà‚ñå                                                                            | 97/4752 [00:01<01:27, 53.02it/s]  2%|‚ñà‚ñã                                                                           | 103/4752 [00:01<01:27, 52.91it/s]  2%|‚ñà‚ñä                                                                           | 109/4752 [00:02<01:27, 52.82it/s]  2%|‚ñà‚ñä                                                                           | 115/4752 [00:02<01:27, 52.90it/s]  3%|‚ñà‚ñâ                                                                           | 121/4752 [00:02<01:27, 53.09it/s]  3%|‚ñà‚ñà                                                                           | 127/4752 [00:02<01:27, 53.10it/s]  3%|‚ñà‚ñà‚ñè                                                                          | 133/4752 [00:02<01:27, 52.90it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 139/4752 [00:02<01:27, 52.93it/s]  3%|‚ñà‚ñà‚ñé                                                                          | 145/4752 [00:02<01:26, 52.97it/s]  3%|‚ñà‚ñà‚ñç                                                                          | 151/4752 [00:02<01:26, 52.92it/s]  3%|‚ñà‚ñà‚ñå                                                                          | 157/4752 [00:03<01:26, 52.84it/s]  3%|‚ñà‚ñà‚ñã                                                                          | 163/4752 [00:03<01:26, 52.90it/s]  4%|‚ñà‚ñà‚ñã                                                                          | 169/4752 [00:03<01:26, 53.07it/s]  4%|‚ñà‚ñà‚ñä                                                                          | 175/4752 [00:03<01:26, 53.05it/s]  4%|‚ñà‚ñà‚ñâ                                                                          | 181/4752 [00:03<01:26, 52.68it/s]  4%|‚ñà‚ñà‚ñà                                                                          | 187/4752 [00:03<01:26, 52.90it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 193/4752 [00:03<01:26, 52.90it/s]  4%|‚ñà‚ñà‚ñà‚ñè                                                                         | 199/4752 [00:03<01:25, 53.04it/s]  4%|‚ñà‚ñà‚ñà‚ñé                                                                         | 205/4752 [00:03<01:25, 52.91it/s]  4%|‚ñà‚ñà‚ñà‚ñç                                                                         | 211/4752 [00:04<01:25, 53.04it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 217/4752 [00:04<01:29, 50.55it/s]  5%|‚ñà‚ñà‚ñà‚ñå                                                                         | 223/4752 [00:04<01:27, 51.92it/s]  5%|‚ñà‚ñà‚ñà‚ñã                                                                         | 229/4752 [00:04<01:26, 52.43it/s]  5%|‚ñà‚ñà‚ñà‚ñä                                                                         | 235/4752 [00:04<01:25, 52.99it/s]  5%|‚ñà‚ñà‚ñà‚ñâ                                                                         | 241/4752 [00:04<01:24, 53.38it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 247/4752 [00:04<01:24, 53.55it/s]  5%|‚ñà‚ñà‚ñà‚ñà                                                                         | 253/4752 [00:04<01:24, 53.52it/s]  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                        | 259/4752 [00:04<01:23, 53.70it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 265/4752 [00:05<01:23, 53.99it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 271/4752 [00:05<01:22, 54.03it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 277/4752 [00:05<01:22, 54.12it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñå                                                                        | 283/4752 [00:05<01:22, 53.95it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñã                                                                        | 289/4752 [00:05<01:22, 54.21it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñä                                                                        | 295/4752 [00:05<01:21, 54.42it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 301/4752 [00:05<01:21, 54.53it/s]  6%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                        | 307/4752 [00:05<01:21, 54.44it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                        | 313/4752 [00:05<01:21, 54.57it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                       | 319/4752 [00:06<01:20, 54.73it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 325/4752 [00:06<01:20, 54.88it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 331/4752 [00:06<01:21, 54.29it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 337/4752 [00:06<01:21, 54.40it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                       | 343/4752 [00:06<01:21, 54.38it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                       | 349/4752 [00:06<01:20, 54.50it/s]  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 355/4752 [00:06<01:20, 54.39it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                       | 361/4752 [00:06<01:20, 54.60it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                       | 367/4752 [00:06<01:20, 54.64it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                       | 373/4752 [00:07<01:20, 54.74it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 379/4752 [00:07<01:20, 54.43it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                      | 385/4752 [00:07<01:20, 54.12it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                      | 391/4752 [00:07<01:20, 54.12it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 397/4752 [00:07<01:20, 54.23it/s]  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 403/4752 [00:07<01:20, 54.25it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 409/4752 [00:07<01:19, 54.30it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                      | 415/4752 [00:07<01:19, 54.51it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                      | 421/4752 [00:07<01:19, 54.58it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                      | 427/4752 [00:08<01:19, 54.51it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 433/4752 [00:08<01:19, 54.28it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                      | 439/4752 [00:08<01:19, 54.24it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                     | 445/4752 [00:08<01:19, 54.21it/s]  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                     | 451/4752 [00:08<01:19, 54.13it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 457/4752 [00:08<01:19, 53.98it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 463/4752 [00:08<01:19, 54.10it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                     | 469/4752 [00:08<01:18, 54.31it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 475/4752 [00:08<01:18, 54.32it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                     | 481/4752 [00:09<01:19, 54.05it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 487/4752 [00:09<01:18, 54.19it/s] 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                     | 493/4752 [00:09<01:18, 54.24it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                     | 499/4752 [00:09<01:17, 54.63it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                    | 505/4752 [00:09<01:17, 54.68it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                    | 511/4752 [00:09<01:16, 55.26it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 517/4752 [00:09<01:16, 55.42it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 523/4752 [00:09<01:16, 55.57it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 529/4752 [00:09<01:16, 55.23it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                    | 535/4752 [00:09<01:16, 55.45it/s] 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 541/4752 [00:10<01:15, 55.74it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                    | 547/4752 [00:10<01:15, 55.74it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                    | 553/4752 [00:10<01:15, 55.61it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                    | 559/4752 [00:10<01:15, 55.21it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                   | 565/4752 [00:10<01:15, 55.13it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 571/4752 [00:10<01:16, 54.94it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                   | 577/4752 [00:10<01:16, 54.72it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 583/4752 [00:10<01:16, 54.37it/s] 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                   | 589/4752 [00:10<01:16, 54.39it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 595/4752 [00:11<01:16, 54.40it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                   | 601/4752 [00:11<01:16, 54.48it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                   | 607/4752 [00:11<01:16, 54.08it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 613/4752 [00:11<01:16, 54.07it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                   | 619/4752 [00:11<01:16, 54.27it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 625/4752 [00:11<01:15, 54.41it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                  | 631/4752 [00:11<01:16, 54.14it/s] 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                  | 637/4752 [00:11<01:15, 54.17it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 643/4752 [00:11<01:15, 54.22it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 649/4752 [00:12<01:15, 54.30it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                  | 655/4752 [00:12<01:15, 54.23it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                  | 661/4752 [00:12<01:15, 54.41it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                  | 667/4752 [00:12<01:15, 54.30it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                  | 673/4752 [00:12<01:14, 54.52it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 679/4752 [00:12<01:15, 54.28it/s] 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                  | 685/4752 [00:12<01:14, 54.31it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 691/4752 [00:12<01:14, 54.49it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                 | 697/4752 [00:12<01:13, 54.82it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 703/4752 [00:13<01:13, 55.09it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 709/4752 [00:13<01:13, 55.26it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                 | 715/4752 [00:13<01:13, 55.20it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                 | 721/4752 [00:13<01:13, 55.18it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 727/4752 [00:13<01:14, 54.20it/s] 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 733/4752 [00:13<01:14, 53.81it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                 | 739/4752 [00:13<01:14, 54.16it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                 | 745/4752 [00:13<01:14, 53.84it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                | 751/4752 [00:13<01:14, 53.42it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 757/4752 [00:14<01:14, 53.34it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                | 763/4752 [00:14<01:14, 53.39it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 769/4752 [00:14<01:14, 53.25it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                | 775/4752 [00:14<01:15, 53.00it/s] 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                | 781/4752 [00:14<01:15, 52.85it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 787/4752 [00:14<01:15, 52.62it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                | 793/4752 [00:14<01:15, 52.52it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                | 799/4752 [00:14<01:15, 52.57it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 805/4752 [00:14<01:15, 52.16it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 811/4752 [00:15<01:15, 52.34it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                               | 817/4752 [00:15<01:15, 52.28it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 823/4752 [00:15<01:14, 52.70it/s] 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 829/4752 [00:15<01:15, 52.30it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                               | 835/4752 [00:15<01:14, 52.38it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 841/4752 [00:15<01:14, 52.25it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                               | 847/4752 [00:15<01:14, 52.71it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                               | 853/4752 [00:15<01:14, 52.26it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                               | 859/4752 [00:16<01:21, 47.90it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 864/4752 [00:16<01:28, 43.95it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                               | 869/4752 [00:16<01:33, 41.44it/s] 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                              | 874/4752 [00:16<01:34, 40.96it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 880/4752 [00:16<01:26, 44.67it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                              | 886/4752 [00:16<01:23, 46.21it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 891/4752 [00:16<01:21, 47.12it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 896/4752 [00:16<01:20, 47.61it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                              | 902/4752 [00:17<01:22, 46.72it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                              | 909/4752 [00:17<01:15, 51.04it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                              | 915/4752 [00:17<01:18, 48.86it/s] 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                              | 922/4752 [00:17<01:13, 52.13it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                              | 928/4752 [00:17<01:12, 52.42it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 934/4752 [00:17<01:12, 52.56it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                             | 940/4752 [00:17<01:12, 52.24it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                             | 946/4752 [00:17<01:13, 52.05it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 952/4752 [00:17<01:17, 49.23it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                             | 958/4752 [00:18<01:15, 49.98it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 965/4752 [00:18<01:11, 52.85it/s] 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                             | 971/4752 [00:18<01:12, 52.47it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                             | 977/4752 [00:18<01:12, 52.26it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                             | 983/4752 [00:18<01:11, 52.44it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 989/4752 [00:18<01:11, 52.72it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                             | 995/4752 [00:18<01:11, 52.61it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 1001/4752 [00:18<01:11, 52.67it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 1007/4752 [00:19<01:10, 52.77it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                           | 1013/4752 [00:19<01:14, 50.30it/s] 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                           | 1019/4752 [00:19<01:21, 45.88it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 1024/4752 [00:19<01:25, 43.46it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                           | 1029/4752 [00:19<01:26, 43.13it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 1034/4752 [00:19<01:29, 41.64it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 1039/4752 [00:19<01:29, 41.29it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                           | 1044/4752 [00:19<01:31, 40.66it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 1049/4752 [00:20<01:32, 39.83it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                           | 1054/4752 [00:20<01:32, 40.11it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 1061/4752 [00:20<01:19, 46.23it/s] 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                           | 1067/4752 [00:20<01:16, 48.18it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                          | 1072/4752 [00:20<01:17, 47.29it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 1079/4752 [00:20<01:10, 51.85it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                          | 1085/4752 [00:20<01:10, 52.18it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                          | 1091/4752 [00:20<01:12, 50.60it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 1097/4752 [00:21<01:13, 49.62it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 1102/4752 [00:21<01:14, 48.92it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                          | 1107/4752 [00:21<01:17, 46.77it/s] 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                          | 1113/4752 [00:21<01:14, 48.71it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                          | 1119/4752 [00:21<01:11, 50.84it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 1126/4752 [00:21<01:06, 54.57it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                          | 1132/4752 [00:21<01:06, 54.31it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                         | 1138/4752 [00:21<01:07, 53.67it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                         | 1144/4752 [00:21<01:08, 52.67it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 1150/4752 [00:22<01:09, 51.90it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                         | 1156/4752 [00:22<01:09, 51.81it/s] 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 1162/4752 [00:22<01:07, 53.26it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                         | 1168/4752 [00:22<01:06, 54.25it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 1174/4752 [00:22<01:06, 54.13it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                         | 1180/4752 [00:22<01:07, 53.30it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                         | 1186/4752 [00:22<01:08, 52.30it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                         | 1192/4752 [00:22<01:08, 52.33it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                        | 1198/4752 [00:22<01:08, 51.58it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 1204/4752 [00:23<01:11, 49.56it/s] 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                        | 1211/4752 [00:23<01:07, 52.67it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                        | 1217/4752 [00:23<01:09, 50.67it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 1223/4752 [00:23<01:07, 52.37it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 1229/4752 [00:23<01:06, 52.92it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 1235/4752 [00:23<01:05, 53.44it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                        | 1241/4752 [00:23<01:04, 54.30it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                        | 1247/4752 [00:23<01:04, 54.62it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                        | 1253/4752 [00:23<01:03, 54.76it/s] 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1259/4752 [00:24<01:04, 54.36it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                       | 1265/4752 [00:24<01:08, 51.18it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 1271/4752 [00:24<01:15, 46.24it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                       | 1277/4752 [00:24<01:11, 48.37it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 1283/4752 [00:24<01:09, 50.20it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 1289/4752 [00:24<01:11, 48.56it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                       | 1296/4752 [00:24<01:05, 52.47it/s] 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                       | 1302/4752 [00:24<01:08, 50.00it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                       | 1309/4752 [00:25<01:03, 53.83it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                       | 1315/4752 [00:25<01:06, 51.58it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                      | 1322/4752 [00:25<01:05, 52.23it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                      | 1329/4752 [00:25<01:02, 54.97it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                      | 1335/4752 [00:25<01:03, 54.03it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                      | 1341/4752 [00:25<01:03, 53.59it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 1347/4752 [00:25<01:03, 53.86it/s] 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 1353/4752 [00:25<01:03, 53.74it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                      | 1359/4752 [00:26<01:09, 48.62it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                      | 1364/4752 [00:26<01:11, 47.29it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                      | 1370/4752 [00:26<01:08, 49.04it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1376/4752 [00:26<01:07, 49.81it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                      | 1382/4752 [00:26<01:06, 50.48it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                     | 1388/4752 [00:26<01:06, 50.42it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                     | 1394/4752 [00:26<01:05, 51.30it/s] 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1400/4752 [00:26<01:05, 51.37it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1406/4752 [00:26<01:04, 51.52it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 1412/4752 [00:27<01:04, 51.81it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                     | 1418/4752 [00:27<01:03, 52.30it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1424/4752 [00:27<01:09, 48.20it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                     | 1429/4752 [00:27<01:13, 45.22it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                     | 1434/4752 [00:27<01:16, 43.60it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1439/4752 [00:27<01:18, 42.23it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                     | 1444/4752 [00:27<01:20, 40.88it/s] 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 1449/4752 [00:27<01:21, 40.40it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1454/4752 [00:28<01:23, 39.49it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                    | 1458/4752 [00:28<01:23, 39.33it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1463/4752 [00:28<01:21, 40.41it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                    | 1468/4752 [00:28<01:20, 40.64it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 1473/4752 [00:28<01:22, 39.98it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1478/4752 [00:28<01:24, 38.80it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 1482/4752 [00:28<01:24, 38.56it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                    | 1488/4752 [00:28<01:15, 43.12it/s] 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 1493/4752 [00:29<01:18, 41.58it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                    | 1498/4752 [00:29<01:18, 41.55it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1503/4752 [00:29<01:16, 42.25it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1510/4752 [00:29<01:07, 47.72it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                   | 1516/4752 [00:29<01:06, 48.97it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                   | 1522/4752 [00:29<01:06, 48.61it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                   | 1528/4752 [00:29<01:02, 51.53it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 1534/4752 [00:29<01:02, 51.54it/s] 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1540/4752 [00:29<01:01, 51.85it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                   | 1546/4752 [00:30<01:02, 51.57it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                   | 1552/4752 [00:30<01:04, 49.36it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1557/4752 [00:30<01:10, 45.00it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                   | 1562/4752 [00:30<01:13, 43.60it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                   | 1567/4752 [00:30<01:14, 42.79it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1572/4752 [00:30<01:17, 40.78it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 1577/4752 [00:30<01:20, 39.45it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                  | 1582/4752 [00:31<01:16, 41.21it/s] 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1588/4752 [00:31<01:11, 44.24it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                  | 1593/4752 [00:31<01:10, 45.09it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 1598/4752 [00:31<01:12, 43.52it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                  | 1604/4752 [00:31<01:11, 44.01it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1611/4752 [00:31<01:04, 48.99it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                  | 1617/4752 [00:31<01:04, 48.33it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 1623/4752 [00:31<01:04, 48.73it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1628/4752 [00:31<01:04, 48.65it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1633/4752 [00:32<01:05, 47.46it/s] 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 1638/4752 [00:32<01:05, 47.51it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1643/4752 [00:32<01:08, 45.38it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                 | 1648/4752 [00:32<01:11, 43.55it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                 | 1653/4752 [00:32<01:11, 43.54it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1658/4752 [00:32<01:12, 42.53it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 1663/4752 [00:32<01:13, 41.75it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                 | 1668/4752 [00:32<01:16, 40.53it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1673/4752 [00:33<01:18, 39.38it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                 | 1678/4752 [00:33<01:16, 40.16it/s] 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                 | 1684/4752 [00:33<01:10, 43.27it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1690/4752 [00:33<01:06, 46.08it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                 | 1696/4752 [00:33<01:03, 48.35it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 1702/4752 [00:33<01:04, 47.10it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                | 1709/4752 [00:33<00:59, 50.81it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                | 1715/4752 [00:33<00:58, 51.56it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 1721/4752 [00:34<01:00, 49.85it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1728/4752 [00:34<00:56, 53.20it/s] 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                | 1734/4752 [00:34<00:56, 53.11it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                | 1740/4752 [00:34<01:01, 49.14it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1745/4752 [00:34<01:05, 46.02it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                | 1750/4752 [00:34<01:06, 45.35it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 1756/4752 [00:34<01:02, 47.83it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 1762/4752 [00:34<01:04, 46.34it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1767/4752 [00:34<01:03, 47.04it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                               | 1772/4752 [00:35<01:06, 44.86it/s] 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                               | 1777/4752 [00:35<01:09, 43.10it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 1782/4752 [00:35<01:08, 43.18it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 1787/4752 [00:35<01:11, 41.62it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                               | 1793/4752 [00:35<01:06, 44.18it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1798/4752 [00:35<01:08, 43.13it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 1803/4752 [00:35<01:08, 43.10it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                               | 1809/4752 [00:35<01:03, 45.99it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1815/4752 [00:36<01:00, 48.22it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                               | 1820/4752 [00:36<01:00, 48.53it/s] 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                              | 1827/4752 [00:36<00:55, 52.82it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 1833/4752 [00:36<00:54, 53.90it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                              | 1839/4752 [00:36<00:56, 51.51it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1845/4752 [00:36<01:01, 47.45it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 1850/4752 [00:36<01:04, 45.25it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                              | 1856/4752 [00:36<01:01, 47.41it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1861/4752 [00:36<01:00, 48.04it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 1866/4752 [00:37<01:03, 45.52it/s] 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                              | 1871/4752 [00:37<01:05, 43.84it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                              | 1878/4752 [00:37<00:59, 48.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1884/4752 [00:37<00:57, 49.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                             | 1890/4752 [00:37<01:01, 46.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                             | 1895/4752 [00:37<01:02, 45.42it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1901/4752 [00:37<00:59, 47.97it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 1907/4752 [00:37<00:57, 49.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 1912/4752 [00:38<00:59, 47.50it/s] 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                             | 1919/4752 [00:38<00:55, 51.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                             | 1925/4752 [00:38<01:00, 46.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1931/4752 [00:38<00:57, 48.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                             | 1936/4752 [00:38<00:59, 47.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                             | 1943/4752 [00:38<00:53, 52.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                            | 1949/4752 [00:38<00:53, 52.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1955/4752 [00:38<00:52, 53.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                            | 1961/4752 [00:39<00:52, 53.28it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 1967/4752 [00:39<00:54, 50.86it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 1973/4752 [00:39<00:55, 50.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1979/4752 [00:39<00:56, 49.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 1984/4752 [00:39<00:57, 48.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                            | 1989/4752 [00:39<00:57, 47.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 1995/4752 [00:39<00:56, 48.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 2000/4752 [00:39<00:56, 48.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                            | 2005/4752 [00:39<00:56, 48.62it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 2010/4752 [00:40<00:56, 48.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 2015/4752 [00:40<00:56, 48.85it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                           | 2020/4752 [00:40<00:55, 48.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 2025/4752 [00:40<00:55, 49.18it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                           | 2030/4752 [00:40<00:55, 49.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                           | 2035/4752 [00:40<00:57, 47.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 2042/4752 [00:40<00:52, 51.77it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 2048/4752 [00:40<00:54, 49.77it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                           | 2054/4752 [00:40<00:53, 50.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 2061/4752 [00:41<00:49, 53.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                           | 2067/4752 [00:41<00:57, 46.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 2073/4752 [00:41<00:56, 47.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                          | 2078/4752 [00:41<01:00, 43.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 2084/4752 [00:41<00:58, 45.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 2090/4752 [00:41<00:56, 47.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 2095/4752 [00:41<00:58, 45.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                          | 2100/4752 [00:41<01:00, 43.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 2105/4752 [00:42<00:58, 44.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 2110/4752 [00:42<01:01, 43.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 2115/4752 [00:42<01:02, 41.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 2120/4752 [00:42<01:02, 41.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                          | 2125/4752 [00:42<01:01, 42.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                          | 2131/4752 [00:42<00:57, 45.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                         | 2136/4752 [00:42<00:58, 44.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 2143/4752 [00:42<00:52, 49.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                         | 2149/4752 [00:42<00:50, 51.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                         | 2155/4752 [00:43<00:48, 53.04it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                         | 2161/4752 [00:43<00:47, 54.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 2167/4752 [00:43<00:47, 54.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 2173/4752 [00:43<00:52, 49.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                         | 2179/4752 [00:43<00:54, 46.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                         | 2184/4752 [00:43<00:58, 43.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 2189/4752 [00:43<00:59, 43.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 2194/4752 [00:43<00:57, 44.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 2199/4752 [00:44<01:00, 42.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                        | 2204/4752 [00:44<00:57, 44.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 2210/4752 [00:44<00:55, 45.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                        | 2216/4752 [00:44<00:53, 47.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 2221/4752 [00:44<00:52, 47.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                        | 2226/4752 [00:44<00:54, 46.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 2231/4752 [00:44<00:55, 45.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 2236/4752 [00:44<00:58, 43.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                        | 2241/4752 [00:45<00:59, 42.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                        | 2246/4752 [00:45<00:59, 41.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 2251/4752 [00:45<00:59, 41.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 2256/4752 [00:45<01:01, 40.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 2261/4752 [00:45<00:58, 42.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 2267/4752 [00:45<00:55, 45.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                       | 2272/4752 [00:45<00:54, 45.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 2277/4752 [00:45<00:53, 46.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 2282/4752 [00:45<00:52, 46.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                       | 2287/4752 [00:46<00:51, 47.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2292/4752 [00:46<00:54, 45.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 2298/4752 [00:46<00:50, 48.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 2303/4752 [00:46<00:50, 48.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 2308/4752 [00:46<00:50, 48.61it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                       | 2313/4752 [00:46<00:50, 48.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 2318/4752 [00:46<00:50, 48.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 2323/4752 [00:46<00:49, 48.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 2328/4752 [00:46<00:49, 48.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                      | 2334/4752 [00:46<00:48, 49.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                      | 2340/4752 [00:47<00:50, 47.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 2347/4752 [00:47<00:47, 51.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 2353/4752 [00:47<00:46, 52.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 2359/4752 [00:47<00:48, 49.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 2365/4752 [00:47<00:47, 49.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 2371/4752 [00:47<00:47, 50.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 2378/4752 [00:47<00:44, 52.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 2384/4752 [00:47<00:44, 52.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 2390/4752 [00:48<00:44, 52.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 2396/4752 [00:48<00:46, 51.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 2402/4752 [00:48<00:45, 51.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 2408/4752 [00:48<00:45, 51.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 2414/4752 [00:48<00:49, 47.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 2420/4752 [00:48<00:46, 50.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                     | 2426/4752 [00:48<00:45, 51.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 2432/4752 [00:48<00:43, 53.27it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 2438/4752 [00:49<00:45, 50.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 2445/4752 [00:49<00:41, 55.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 2451/4752 [00:49<00:41, 54.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 2457/4752 [00:49<00:40, 56.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 2463/4752 [00:49<00:40, 56.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 2469/4752 [00:49<00:40, 56.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 2475/4752 [00:49<00:41, 54.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 2482/4752 [00:49<00:38, 58.29it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                    | 2488/4752 [00:49<00:42, 53.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 2494/4752 [00:50<00:43, 52.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 2500/4752 [00:50<00:47, 47.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 2505/4752 [00:50<00:47, 47.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 2510/4752 [00:50<00:46, 48.15it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 2515/4752 [00:50<00:47, 47.52it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 2520/4752 [00:50<00:49, 45.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 2525/4752 [00:50<00:50, 43.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                   | 2530/4752 [00:50<00:50, 44.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 2535/4752 [00:50<00:52, 42.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                   | 2540/4752 [00:51<00:53, 41.15it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 2545/4752 [00:51<00:53, 41.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 2550/4752 [00:51<00:53, 40.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 2555/4752 [00:51<00:52, 41.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                   | 2560/4752 [00:51<00:52, 41.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2565/4752 [00:51<00:54, 40.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2570/4752 [00:51<00:53, 40.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 2575/4752 [00:51<00:53, 41.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 2580/4752 [00:52<00:50, 42.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 2585/4752 [00:52<00:51, 42.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 2590/4752 [00:52<00:52, 41.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 2595/4752 [00:52<00:52, 40.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 2600/4752 [00:52<00:52, 40.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 2605/4752 [00:52<00:50, 42.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 2610/4752 [00:52<00:49, 43.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 2616/4752 [00:52<00:46, 45.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 2623/4752 [00:53<00:44, 48.34it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 2629/4752 [00:53<00:41, 50.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 2635/4752 [00:53<00:40, 52.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 2641/4752 [00:53<00:39, 53.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 2648/4752 [00:53<00:36, 57.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 2654/4752 [00:53<00:38, 54.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 2661/4752 [00:53<00:37, 55.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 2668/4752 [00:53<00:35, 59.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 2674/4752 [00:53<00:37, 55.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                 | 2680/4752 [00:54<00:36, 56.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 2686/4752 [00:54<00:36, 56.73it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 2693/4752 [00:54<00:35, 58.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 2699/4752 [00:54<00:35, 57.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2706/4752 [00:54<00:34, 58.72it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 2712/4752 [00:54<00:34, 59.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 2718/4752 [00:54<00:35, 57.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 2724/4752 [00:54<00:37, 54.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 2730/4752 [00:54<00:36, 56.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 2736/4752 [00:54<00:35, 57.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 2743/4752 [00:55<00:33, 59.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 2750/4752 [00:55<00:32, 62.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 2757/4752 [00:55<00:33, 59.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 2763/4752 [00:55<00:33, 58.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 2769/4752 [00:55<00:34, 56.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2775/4752 [00:55<00:36, 54.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 2781/4752 [00:55<00:37, 52.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 2787/4752 [00:55<00:37, 51.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 2793/4752 [00:56<00:38, 51.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 2799/4752 [00:56<00:38, 50.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 2805/4752 [00:56<00:38, 50.67it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 2811/4752 [00:56<00:41, 46.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 2816/4752 [00:56<00:41, 46.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 2821/4752 [00:56<00:41, 46.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 2828/4752 [00:56<00:36, 52.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 2834/4752 [00:56<00:35, 53.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 2840/4752 [00:56<00:34, 54.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2846/4752 [00:57<00:34, 55.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 2852/4752 [00:57<00:33, 56.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 2859/4752 [00:57<00:34, 54.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 2866/4752 [00:57<00:32, 57.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 2872/4752 [00:57<00:33, 55.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 2879/4752 [00:57<00:31, 58.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 2885/4752 [00:57<00:31, 58.57it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 2891/4752 [00:57<00:32, 57.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 2898/4752 [00:57<00:31, 58.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 2904/4752 [00:58<00:31, 58.49it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 2910/4752 [00:58<00:31, 58.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2916/4752 [00:58<00:31, 58.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                             | 2922/4752 [00:58<00:32, 56.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 2929/4752 [00:58<00:30, 59.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 2935/4752 [00:58<00:30, 59.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 2941/4752 [00:58<00:30, 59.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2948/4752 [00:58<00:30, 59.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 2954/4752 [00:58<00:33, 53.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 2960/4752 [00:59<00:35, 49.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 2966/4752 [00:59<00:38, 46.03it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2971/4752 [00:59<00:40, 44.04it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 2976/4752 [00:59<00:39, 44.46it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 2981/4752 [00:59<00:39, 45.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2986/4752 [00:59<00:41, 42.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 2991/4752 [00:59<00:43, 40.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 2997/4752 [00:59<00:41, 42.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 3004/4752 [01:00<00:35, 48.69it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 3009/4752 [01:00<00:35, 48.91it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 3017/4752 [01:00<00:31, 55.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 3023/4752 [01:00<00:32, 53.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 3030/4752 [01:00<00:30, 57.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 3036/4752 [01:00<00:29, 57.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 3042/4752 [01:00<00:29, 57.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 3048/4752 [01:00<00:29, 58.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 3054/4752 [01:00<00:29, 57.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 3060/4752 [01:01<00:29, 58.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 3067/4752 [01:01<00:28, 59.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 3073/4752 [01:01<00:29, 56.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 3080/4752 [01:01<00:28, 59.62it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 3086/4752 [01:01<00:27, 59.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 3093/4752 [01:01<00:28, 57.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 3100/4752 [01:01<00:27, 59.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 3106/4752 [01:01<00:29, 56.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 3112/4752 [01:01<00:28, 57.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 3118/4752 [01:02<00:28, 57.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 3124/4752 [01:02<00:31, 51.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 3130/4752 [01:02<00:32, 50.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 3136/4752 [01:02<00:31, 50.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 3142/4752 [01:02<00:31, 50.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 3148/4752 [01:02<00:32, 49.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 3154/4752 [01:02<00:31, 50.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 3160/4752 [01:02<00:31, 49.96it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 3166/4752 [01:03<00:32, 49.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 3171/4752 [01:03<00:32, 48.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 3177/4752 [01:03<00:31, 49.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 3183/4752 [01:03<00:31, 49.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 3189/4752 [01:03<00:31, 49.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 3195/4752 [01:03<00:31, 50.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 3201/4752 [01:03<00:30, 50.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 3207/4752 [01:03<00:30, 50.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 3213/4752 [01:03<00:30, 50.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 3219/4752 [01:04<00:31, 48.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 3226/4752 [01:04<00:28, 52.76it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 3232/4752 [01:04<00:29, 51.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 3239/4752 [01:04<00:27, 55.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 3245/4752 [01:04<00:28, 53.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 3252/4752 [01:04<00:26, 56.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 3258/4752 [01:04<00:26, 55.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 3264/4752 [01:04<00:27, 54.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 3270/4752 [01:05<00:27, 53.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 3276/4752 [01:05<00:28, 52.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 3282/4752 [01:05<00:29, 50.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 3288/4752 [01:05<00:29, 50.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 3294/4752 [01:05<00:30, 47.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 3299/4752 [01:05<00:30, 47.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 3305/4752 [01:05<00:30, 47.19it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 3310/4752 [01:06<01:20, 17.83it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 3327/4752 [01:06<00:49, 28.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 3332/4752 [01:07<00:56, 25.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 3344/4752 [01:07<00:40, 34.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 3350/4752 [01:07<00:43, 31.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 3381/4752 [01:07<00:20, 68.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 3391/4752 [01:07<00:22, 59.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 3400/4752 [01:08<00:24, 54.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 3407/4752 [01:08<00:26, 50.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 3413/4752 [01:08<00:27, 48.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 3419/4752 [01:08<00:28, 47.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 3425/4752 [01:08<00:29, 45.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 3430/4752 [01:08<00:30, 43.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 3435/4752 [01:08<00:30, 42.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 3440/4752 [01:09<00:30, 43.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 3445/4752 [01:09<00:31, 41.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 3450/4752 [01:09<00:31, 41.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 3455/4752 [01:09<00:32, 40.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 3460/4752 [01:09<00:30, 41.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 3466/4752 [01:09<00:28, 44.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 3471/4752 [01:09<00:28, 44.63it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 3478/4752 [01:09<00:25, 50.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 3484/4752 [01:10<00:24, 51.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 3490/4752 [01:10<00:24, 52.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 3496/4752 [01:10<00:23, 53.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 3502/4752 [01:10<00:22, 54.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 3508/4752 [01:10<00:22, 55.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 3514/4752 [01:10<00:22, 55.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 3520/4752 [01:10<00:22, 54.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 3526/4752 [01:10<00:22, 55.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 3532/4752 [01:10<00:21, 55.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 3538/4752 [01:11<00:21, 55.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 3544/4752 [01:11<00:22, 52.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 3551/4752 [01:11<00:21, 55.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 3557/4752 [01:11<00:24, 48.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 3563/4752 [01:11<00:26, 45.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 3568/4752 [01:11<00:26, 44.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 3573/4752 [01:11<00:27, 43.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 3578/4752 [01:11<00:26, 44.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 3584/4752 [01:12<00:25, 46.23it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 3590/4752 [01:12<00:24, 48.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 3595/4752 [01:12<00:24, 47.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 3602/4752 [01:12<00:21, 52.60it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 3608/4752 [01:12<00:21, 53.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 3614/4752 [01:12<00:20, 54.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 3620/4752 [01:12<00:20, 54.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 3626/4752 [01:12<00:20, 55.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 3633/4752 [01:12<00:19, 56.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 3639/4752 [01:13<00:19, 56.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 3645/4752 [01:13<00:19, 56.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 3651/4752 [01:13<00:20, 54.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 3658/4752 [01:13<00:18, 58.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 3664/4752 [01:13<00:20, 53.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 3670/4752 [01:13<00:22, 48.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3675/4752 [01:13<00:23, 45.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 3680/4752 [01:13<00:24, 42.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 3686/4752 [01:13<00:22, 46.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3691/4752 [01:14<00:22, 47.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 3696/4752 [01:14<00:22, 46.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 3701/4752 [01:14<00:22, 46.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3706/4752 [01:14<00:23, 44.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 3711/4752 [01:14<00:26, 39.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 3716/4752 [01:14<00:26, 39.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3721/4752 [01:14<00:25, 40.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 3726/4752 [01:14<00:26, 38.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3730/4752 [01:15<00:26, 38.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 3735/4752 [01:15<00:24, 40.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 3741/4752 [01:15<00:23, 42.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 3748/4752 [01:15<00:20, 48.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 3754/4752 [01:15<00:19, 50.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3760/4752 [01:15<00:19, 51.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 3766/4752 [01:15<00:18, 52.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 3772/4752 [01:15<00:18, 54.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 3779/4752 [01:16<00:18, 53.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 3786/4752 [01:16<00:16, 56.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3792/4752 [01:16<00:16, 56.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 3798/4752 [01:16<00:17, 54.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 3805/4752 [01:16<00:16, 57.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 3811/4752 [01:16<00:17, 52.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 3817/4752 [01:16<00:18, 51.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3823/4752 [01:16<00:18, 50.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 3829/4752 [01:16<00:18, 50.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 3835/4752 [01:17<00:18, 48.79it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3840/4752 [01:17<00:19, 47.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 3845/4752 [01:17<00:21, 41.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 3850/4752 [01:17<00:22, 40.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3855/4752 [01:17<00:22, 39.17it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 3859/4752 [01:17<00:23, 38.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3863/4752 [01:17<00:23, 38.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 3868/4752 [01:17<00:21, 41.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 3875/4752 [01:18<00:19, 45.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 3880/4752 [01:18<00:24, 35.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 3894/4752 [01:18<00:14, 58.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 3901/4752 [01:18<00:14, 58.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3908/4752 [01:18<00:14, 57.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 3915/4752 [01:18<00:14, 58.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 3922/4752 [01:18<00:14, 58.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 3929/4752 [01:18<00:13, 58.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 3936/4752 [01:19<00:14, 58.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 3942/4752 [01:19<00:13, 58.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 3948/4752 [01:19<00:14, 56.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 3956/4752 [01:19<00:13, 57.06it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3963/4752 [01:19<00:13, 57.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 3970/4752 [01:19<00:13, 57.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 3976/4752 [01:19<00:14, 53.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 3982/4752 [01:19<00:14, 51.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 3988/4752 [01:20<00:14, 51.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 3994/4752 [01:20<00:14, 50.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 4000/4752 [01:20<00:14, 50.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 4006/4752 [01:20<00:14, 50.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 4012/4752 [01:20<00:14, 50.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 4018/4752 [01:20<00:14, 49.82it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 4023/4752 [01:20<00:15, 46.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 4028/4752 [01:20<00:15, 45.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 4033/4752 [01:21<00:15, 44.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 4038/4752 [01:21<00:16, 43.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 4043/4752 [01:21<00:16, 43.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 4048/4752 [01:21<00:16, 41.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 4053/4752 [01:21<00:17, 40.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 4058/4752 [01:21<00:17, 40.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 4063/4752 [01:21<00:17, 40.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 4068/4752 [01:21<00:16, 41.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 4073/4752 [01:22<00:17, 39.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 4078/4752 [01:22<00:17, 38.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4082/4752 [01:22<00:17, 38.78it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 4086/4752 [01:22<00:17, 38.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4090/4752 [01:22<00:17, 38.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 4095/4752 [01:22<00:16, 39.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 4099/4752 [01:22<00:16, 38.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 4103/4752 [01:22<00:17, 37.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 4107/4752 [01:22<00:17, 37.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4112/4752 [01:23<00:16, 38.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 4117/4752 [01:23<00:15, 39.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4121/4752 [01:23<00:15, 39.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 4125/4752 [01:23<00:16, 38.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 4129/4752 [01:23<00:16, 38.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 4134/4752 [01:23<00:15, 39.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 4138/4752 [01:23<00:15, 38.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4143/4752 [01:23<00:15, 39.60it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 4147/4752 [01:23<00:15, 38.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4151/4752 [01:24<00:15, 38.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 4156/4752 [01:24<00:14, 40.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 4162/4752 [01:24<00:13, 44.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 4168/4752 [01:24<00:12, 48.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4175/4752 [01:24<00:10, 53.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 4181/4752 [01:24<00:10, 52.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 4187/4752 [01:24<00:10, 51.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4193/4752 [01:24<00:11, 50.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 4199/4752 [01:24<00:10, 50.88it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4205/4752 [01:25<00:10, 50.11it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 4211/4752 [01:25<00:10, 50.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 4217/4752 [01:25<00:11, 48.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4222/4752 [01:25<00:11, 45.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 4227/4752 [01:25<00:11, 44.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 4232/4752 [01:25<00:11, 43.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4238/4752 [01:25<00:11, 46.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 4243/4752 [01:25<00:11, 45.21it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 4248/4752 [01:26<00:10, 45.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 4255/4752 [01:26<00:09, 51.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4261/4752 [01:26<00:09, 52.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 4267/4752 [01:26<00:08, 54.21it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 4273/4752 [01:26<00:09, 52.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 4281/4752 [01:26<00:08, 57.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 4287/4752 [01:26<00:08, 57.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 4293/4752 [01:26<00:08, 57.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4299/4752 [01:26<00:07, 57.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 4306/4752 [01:27<00:07, 58.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 4312/4752 [01:27<00:07, 58.11it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 4318/4752 [01:27<00:07, 57.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 4324/4752 [01:27<00:07, 57.52it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4330/4752 [01:27<00:07, 57.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 4336/4752 [01:27<00:07, 54.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 4343/4752 [01:27<00:07, 57.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 4349/4752 [01:27<00:07, 54.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 4356/4752 [01:27<00:07, 55.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4363/4752 [01:28<00:06, 59.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 4369/4752 [01:28<00:06, 58.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 4375/4752 [01:28<00:06, 58.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 4381/4752 [01:28<00:06, 57.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4387/4752 [01:28<00:06, 55.67it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4393/4752 [01:28<00:06, 56.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 4400/4752 [01:28<00:05, 59.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 4407/4752 [01:28<00:05, 59.42it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 4413/4752 [01:28<00:05, 59.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 4419/4752 [01:29<00:05, 58.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 4425/4752 [01:29<00:05, 58.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4432/4752 [01:29<00:05, 59.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4438/4752 [01:29<00:05, 59.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4444/4752 [01:29<00:05, 58.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4450/4752 [01:29<00:05, 58.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4457/4752 [01:29<00:05, 58.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4463/4752 [01:29<00:04, 58.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4469/4752 [01:29<00:05, 55.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4475/4752 [01:29<00:04, 55.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4481/4752 [01:30<00:04, 56.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4487/4752 [01:30<00:06, 43.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4499/4752 [01:30<00:04, 60.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4506/4752 [01:30<00:04, 60.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4513/4752 [01:30<00:04, 52.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4519/4752 [01:30<00:04, 49.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4525/4752 [01:30<00:04, 48.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4531/4752 [01:31<00:04, 47.50it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4536/4752 [01:31<00:04, 47.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4543/4752 [01:31<00:04, 51.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4549/4752 [01:31<00:04, 50.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4556/4752 [01:31<00:03, 54.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4562/4752 [01:31<00:03, 52.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4569/4752 [01:31<00:03, 56.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4575/4752 [01:31<00:03, 56.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4581/4752 [01:31<00:02, 57.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4587/4752 [01:32<00:02, 55.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4593/4752 [01:32<00:03, 52.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4599/4752 [01:32<00:03, 49.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4605/4752 [01:32<00:02, 51.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4611/4752 [01:32<00:02, 50.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4617/4752 [01:32<00:02, 50.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4623/4752 [01:32<00:02, 50.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4629/4752 [01:32<00:02, 50.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4635/4752 [01:33<00:02, 50.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4641/4752 [01:33<00:02, 48.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4647/4752 [01:33<00:02, 49.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4653/4752 [01:33<00:01, 51.55it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4660/4752 [01:33<00:01, 52.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4667/4752 [01:33<00:01, 55.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4673/4752 [01:33<00:01, 54.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4680/4752 [01:33<00:01, 56.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4686/4752 [01:34<00:01, 56.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4692/4752 [01:34<00:01, 55.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4698/4752 [01:34<00:01, 53.13it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4705/4752 [01:34<00:00, 57.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 4711/4752 [01:34<00:00, 56.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 4717/4752 [01:34<00:00, 56.41it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4723/4752 [01:34<00:00, 56.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 4729/4752 [01:34<00:00, 54.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 4735/4752 [01:34<00:00, 55.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4741/4752 [01:35<00:00, 55.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 4748/4752 [01:35<00:00, 56.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4752/4752 [01:35<00:00, 49.93it/s]
Start Training...
Epoch 1 Step 1 Train Loss: 0.8376
Epoch 1 Step 51 Train Loss: 0.8486
Epoch 1 Step 101 Train Loss: 0.8256
Epoch 1 Step 151 Train Loss: 0.6371
Epoch 1 Step 201 Train Loss: 0.8403
Epoch 1 Step 251 Train Loss: 0.9152
Epoch 1 Step 301 Train Loss: 0.8029
Epoch 1 Step 351 Train Loss: 0.8224
Epoch 1: Train Overall MSE: 5.9602 Validation Overall MSE: 5.8837. 
Train Top 20 DE MSE: 28.1954 Validation Top 20 DE MSE: 15.8364. 
Epoch 2 Step 1 Train Loss: 0.8827
Epoch 2 Step 51 Train Loss: 0.8030
Epoch 2 Step 101 Train Loss: 0.8103
Epoch 2 Step 151 Train Loss: 0.9969
Epoch 2 Step 201 Train Loss: 0.7614
Epoch 2 Step 251 Train Loss: 0.7024
Epoch 2 Step 301 Train Loss: 0.7647
Epoch 2 Step 351 Train Loss: 0.7834
Epoch 2: Train Overall MSE: 0.5746 Validation Overall MSE: 0.5753. 
Train Top 20 DE MSE: 2.7909 Validation Top 20 DE MSE: 1.2788. 
Epoch 3 Step 1 Train Loss: 0.7996
Epoch 3 Step 51 Train Loss: 0.8332
Epoch 3 Step 101 Train Loss: 0.8807
Epoch 3 Step 151 Train Loss: 0.8159
Epoch 3 Step 201 Train Loss: 0.8387
Epoch 3 Step 251 Train Loss: 0.8712
Epoch 3 Step 301 Train Loss: 0.6520
Epoch 3 Step 351 Train Loss: 0.7748
Epoch 3: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0049. 
Train Top 20 DE MSE: 0.1056 Validation Top 20 DE MSE: 0.2499. 
Epoch 4 Step 1 Train Loss: 0.7611
Epoch 4 Step 51 Train Loss: 0.7370
Epoch 4 Step 101 Train Loss: 0.8091
Epoch 4 Step 151 Train Loss: 0.8546
Epoch 4 Step 201 Train Loss: 0.8182
Epoch 4 Step 251 Train Loss: 0.7713
Epoch 4 Step 301 Train Loss: 0.7227
Epoch 4 Step 351 Train Loss: 0.7112
Epoch 4: Train Overall MSE: 0.0025 Validation Overall MSE: 0.0050. 
Train Top 20 DE MSE: 0.0310 Validation Top 20 DE MSE: 0.2249. 
Epoch 5 Step 1 Train Loss: 0.6906
Epoch 5 Step 51 Train Loss: 0.6880
Epoch 5 Step 101 Train Loss: 0.7531
Epoch 5 Step 151 Train Loss: 0.7722
Epoch 5 Step 201 Train Loss: 0.7719
Epoch 5 Step 251 Train Loss: 0.9231
Epoch 5 Step 301 Train Loss: 0.7339
Epoch 5 Step 351 Train Loss: 0.6843
Epoch 5: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0374 Validation Top 20 DE MSE: 0.2513. 
Epoch 6 Step 1 Train Loss: 0.8344
Epoch 6 Step 51 Train Loss: 0.6770
Epoch 6 Step 101 Train Loss: 0.7220
Epoch 6 Step 151 Train Loss: 0.7423
Epoch 6 Step 201 Train Loss: 0.8119
Epoch 6 Step 251 Train Loss: 0.7063
Epoch 6 Step 301 Train Loss: 0.7063
Epoch 6 Step 351 Train Loss: 0.7823
Epoch 6: Train Overall MSE: 0.0028 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.1691 Validation Top 20 DE MSE: 0.2509. 
Epoch 7 Step 1 Train Loss: 0.7928
Epoch 7 Step 51 Train Loss: 0.6813
Epoch 7 Step 101 Train Loss: 0.6843
Epoch 7 Step 151 Train Loss: 0.7992
Epoch 7 Step 201 Train Loss: 0.7676
Epoch 7 Step 251 Train Loss: 0.8256
Epoch 7 Step 301 Train Loss: 0.7271
Epoch 7 Step 351 Train Loss: 0.8235
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0624 Validation Top 20 DE MSE: 0.2522. 
Epoch 8 Step 1 Train Loss: 0.7902
Epoch 8 Step 51 Train Loss: 0.8593
Epoch 8 Step 101 Train Loss: 0.8585
Epoch 8 Step 151 Train Loss: 0.8278
Epoch 8 Step 201 Train Loss: 0.7655
Epoch 8 Step 251 Train Loss: 0.7596
Epoch 8 Step 301 Train Loss: 0.7137
Epoch 8 Step 351 Train Loss: 0.6823
Epoch 8: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0550 Validation Top 20 DE MSE: 0.2505. 
Epoch 9 Step 1 Train Loss: 0.7444
Epoch 9 Step 51 Train Loss: 0.7235
Epoch 9 Step 101 Train Loss: 0.7345
Epoch 9 Step 151 Train Loss: 0.8607
Epoch 9 Step 201 Train Loss: 0.8690
Epoch 9 Step 251 Train Loss: 0.7812
Epoch 9 Step 301 Train Loss: 0.7978
Epoch 9 Step 351 Train Loss: 0.7920
Epoch 9: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0048. 
Train Top 20 DE MSE: 0.0477 Validation Top 20 DE MSE: 0.2501. 
Epoch 10 Step 1 Train Loss: 0.8552
Epoch 10 Step 51 Train Loss: 0.7598
Epoch 10 Step 101 Train Loss: 0.7950
Epoch 10 Step 151 Train Loss: 0.7520
Epoch 10 Step 201 Train Loss: 0.6884
Epoch 10 Step 251 Train Loss: 0.8104
Epoch 10 Step 301 Train Loss: 0.7744
Epoch 10 Step 351 Train Loss: 0.7947
Epoch 10: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0421 Validation Top 20 DE MSE: 0.2496. 
Epoch 11 Step 1 Train Loss: 0.8086
Epoch 11 Step 51 Train Loss: 0.7405
Epoch 11 Step 101 Train Loss: 0.6981
Epoch 11 Step 151 Train Loss: 0.9226
Epoch 11 Step 201 Train Loss: 0.7443
Epoch 11 Step 251 Train Loss: 0.8044
Epoch 11 Step 301 Train Loss: 0.9126
Epoch 11 Step 351 Train Loss: 0.8048
Epoch 11: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0376 Validation Top 20 DE MSE: 0.2490. 
Epoch 12 Step 1 Train Loss: 0.7619
Epoch 12 Step 51 Train Loss: 0.9235
Epoch 12 Step 101 Train Loss: 0.6975
Epoch 12 Step 151 Train Loss: 0.8032
Epoch 12 Step 201 Train Loss: 0.8002
Epoch 12 Step 251 Train Loss: 0.7008
Epoch 12 Step 301 Train Loss: 0.8119
Epoch 12 Step 351 Train Loss: 1.0077
Epoch 12: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0380 Validation Top 20 DE MSE: 0.2491. 
Epoch 13 Step 1 Train Loss: 0.7726
Epoch 13 Step 51 Train Loss: 0.8379
Epoch 13 Step 101 Train Loss: 0.8642
Epoch 13 Step 151 Train Loss: 0.7623
Epoch 13 Step 201 Train Loss: 0.9289
Epoch 13 Step 251 Train Loss: 0.7255
Epoch 13 Step 301 Train Loss: 0.8078
Epoch 13 Step 351 Train Loss: 0.7938
Epoch 13: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0359 Validation Top 20 DE MSE: 0.2492. 
Epoch 14 Step 1 Train Loss: 0.9247
Epoch 14 Step 51 Train Loss: 0.6709
Epoch 14 Step 101 Train Loss: 0.6837
Epoch 14 Step 151 Train Loss: 0.7657
Epoch 14 Step 201 Train Loss: 0.8051
Epoch 14 Step 251 Train Loss: 0.7876
Epoch 14 Step 301 Train Loss: 0.7856
Epoch 14 Step 351 Train Loss: 0.8150
Epoch 14: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0320 Validation Top 20 DE MSE: 0.2485. 
Epoch 15 Step 1 Train Loss: 0.8019
Epoch 15 Step 51 Train Loss: 0.7963
Epoch 15 Step 101 Train Loss: 0.7302
Epoch 15 Step 151 Train Loss: 0.8228
Epoch 15 Step 201 Train Loss: 0.8446
Epoch 15 Step 251 Train Loss: 0.6330
Epoch 15 Step 301 Train Loss: 0.8867
Epoch 15 Step 351 Train Loss: 0.7348
Epoch 15: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0047. 
Train Top 20 DE MSE: 0.0312 Validation Top 20 DE MSE: 0.2495. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.2670
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0052859434
test_unseen_single_pearson: 0.9871237512914025
test_unseen_single_mse_de: 0.2670466
test_unseen_single_pearson_de: 0.9125341645085916
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.345677744376843
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.20833333333333334
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8166666666666665
test_unseen_single_mse_top20_de_non_dropout: 0.27986988
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.001 MB of 0.022 MB uploadedwandb: / 0.016 MB of 0.022 MB uploadedwandb: - 0.019 MB of 0.022 MB uploadedwandb: \ 0.019 MB of 0.022 MB uploadedwandb: | 0.019 MB of 0.022 MB uploadedwandb: / 0.022 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb: \ 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñá‚ñà‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.26705
wandb:                                              test_de_pearson 0.91253
wandb:               test_frac_opposite_direction_top20_non_dropout 0.20833
wandb:                          test_frac_sigma_below_1_non_dropout 0.81667
wandb:                                                     test_mse 0.00529
wandb:                                test_mse_top20_de_non_dropout 0.27987
wandb:                                                 test_pearson 0.98712
wandb:                                           test_pearson_delta 0.34568
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.20833
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.81667
wandb:                                       test_unseen_single_mse 0.00529
wandb:                                    test_unseen_single_mse_de 0.26705
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.27987
wandb:                                   test_unseen_single_pearson 0.98712
wandb:                                test_unseen_single_pearson_de 0.91253
wandb:                             test_unseen_single_pearson_delta 0.34568
wandb:                                                 train_de_mse 0.03119
wandb:                                             train_de_pearson 0.92941
wandb:                                                    train_mse 0.00156
wandb:                                                train_pearson 0.99625
wandb:                                                training_loss 0.78653
wandb:                                                   val_de_mse 0.24947
wandb:                                               val_de_pearson 0.9588
wandb:                                                      val_mse 0.00474
wandb:                                                  val_pearson 0.9887
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_RNA_split1 at: https://wandb.ai/zhoumin1130/New_gears/runs/hntc77ns
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_145829-hntc77ns/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:6
Done!
Creating dataloaders....
Done!
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_151012-5d3c45dz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_RNA_split2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/5d3c45dz
wandb: WARNING Serializing object of type ndarray that is 8011328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.8182
Epoch 1 Step 51 Train Loss: 0.8376
Epoch 1 Step 101 Train Loss: 0.8047
Epoch 1 Step 151 Train Loss: 0.7106
Epoch 1 Step 201 Train Loss: 0.8086
Epoch 1 Step 251 Train Loss: 0.8122
Epoch 1 Step 301 Train Loss: 0.9672
Epoch 1 Step 351 Train Loss: 0.9696
Epoch 1: Train Overall MSE: 0.0206 Validation Overall MSE: 0.0208. 
Train Top 20 DE MSE: 0.0921 Validation Top 20 DE MSE: 0.2248. 
Epoch 2 Step 1 Train Loss: 0.9018
Epoch 2 Step 51 Train Loss: 0.8936
Epoch 2 Step 101 Train Loss: 0.9211
Epoch 2 Step 151 Train Loss: 0.7537
Epoch 2 Step 201 Train Loss: 0.7661
Epoch 2 Step 251 Train Loss: 0.8233
Epoch 2 Step 301 Train Loss: 0.8943
Epoch 2 Step 351 Train Loss: 0.6592
Epoch 2: Train Overall MSE: 1.4533 Validation Overall MSE: 1.4067. 
Train Top 20 DE MSE: 5.9403 Validation Top 20 DE MSE: 12.2061. 
Epoch 3 Step 1 Train Loss: 0.7775
Epoch 3 Step 51 Train Loss: 0.7999
Epoch 3 Step 101 Train Loss: 0.8400
Epoch 3 Step 151 Train Loss: 0.8174
Epoch 3 Step 201 Train Loss: 0.8846
Epoch 3 Step 251 Train Loss: 0.7815
Epoch 3 Step 301 Train Loss: 0.7200
Epoch 3 Step 351 Train Loss: 0.8819
Epoch 3: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0589 Validation Top 20 DE MSE: 0.1679. 
Epoch 4 Step 1 Train Loss: 0.8088
Epoch 4 Step 51 Train Loss: 0.7799
Epoch 4 Step 101 Train Loss: 0.8920
Epoch 4 Step 151 Train Loss: 0.7443
Epoch 4 Step 201 Train Loss: 0.7967
Epoch 4 Step 251 Train Loss: 0.6853
Epoch 4 Step 301 Train Loss: 0.7525
Epoch 4 Step 351 Train Loss: 0.7476
Epoch 4: Train Overall MSE: 0.0388 Validation Overall MSE: 0.0310. 
Train Top 20 DE MSE: 0.2586 Validation Top 20 DE MSE: 0.2549. 
Epoch 5 Step 1 Train Loss: 0.7623
Epoch 5 Step 51 Train Loss: 1.0171
Epoch 5 Step 101 Train Loss: 0.7583
Epoch 5 Step 151 Train Loss: 0.7595
Epoch 5 Step 201 Train Loss: 0.8006
Epoch 5 Step 251 Train Loss: 0.8299
Epoch 5 Step 301 Train Loss: 0.7165
Epoch 5 Step 351 Train Loss: 0.7426
Epoch 5: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0029. 
Train Top 20 DE MSE: 0.0328 Validation Top 20 DE MSE: 0.1646. 
Epoch 6 Step 1 Train Loss: 0.7682
Epoch 6 Step 51 Train Loss: 0.7195
Epoch 6 Step 101 Train Loss: 0.6159
Epoch 6 Step 151 Train Loss: 0.8572
Epoch 6 Step 201 Train Loss: 0.7396
Epoch 6 Step 251 Train Loss: 0.7475
Epoch 6 Step 301 Train Loss: 0.7554
Epoch 6 Step 351 Train Loss: 0.8147
Epoch 6: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0281 Validation Top 20 DE MSE: 0.1645. 
Epoch 7 Step 1 Train Loss: 0.7237
Epoch 7 Step 51 Train Loss: 0.8735
Epoch 7 Step 101 Train Loss: 0.6886
Epoch 7 Step 151 Train Loss: 0.8501
Epoch 7 Step 201 Train Loss: 0.7607
Epoch 7 Step 251 Train Loss: 0.8592
Epoch 7 Step 301 Train Loss: 0.7106
Epoch 7 Step 351 Train Loss: 0.8191
Epoch 7: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0027. 
Train Top 20 DE MSE: 0.0299 Validation Top 20 DE MSE: 0.1695. 
Epoch 8 Step 1 Train Loss: 0.8404
Epoch 8 Step 51 Train Loss: 0.7618
Epoch 8 Step 101 Train Loss: 0.7346
Epoch 8 Step 151 Train Loss: 0.7512
Epoch 8 Step 201 Train Loss: 0.8796
Epoch 8 Step 251 Train Loss: 0.7723
Epoch 8 Step 301 Train Loss: 0.7404
Epoch 8 Step 351 Train Loss: 0.6642
Epoch 8: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0245 Validation Top 20 DE MSE: 0.1655. 
Epoch 9 Step 1 Train Loss: 0.8031
Epoch 9 Step 51 Train Loss: 0.7338
Epoch 9 Step 101 Train Loss: 0.7183
Epoch 9 Step 151 Train Loss: 0.6930
Epoch 9 Step 201 Train Loss: 0.7466
Epoch 9 Step 251 Train Loss: 0.7482
Epoch 9 Step 301 Train Loss: 0.7304
Epoch 9 Step 351 Train Loss: 0.7947
Epoch 9: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0222 Validation Top 20 DE MSE: 0.1664. 
Epoch 10 Step 1 Train Loss: 0.7395
Epoch 10 Step 51 Train Loss: 0.7554
Epoch 10 Step 101 Train Loss: 0.6351
Epoch 10 Step 151 Train Loss: 0.6981
Epoch 10 Step 201 Train Loss: 0.8264
Epoch 10 Step 251 Train Loss: 0.7967
Epoch 10 Step 301 Train Loss: 0.8320
Epoch 10 Step 351 Train Loss: 0.7769
Epoch 10: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0218 Validation Top 20 DE MSE: 0.1662. 
Epoch 11 Step 1 Train Loss: 0.8236
Epoch 11 Step 51 Train Loss: 0.8053
Epoch 11 Step 101 Train Loss: 0.6618
Epoch 11 Step 151 Train Loss: 0.8294
Epoch 11 Step 201 Train Loss: 0.7494
Epoch 11 Step 251 Train Loss: 0.8216
Epoch 11 Step 301 Train Loss: 0.6982
Epoch 11 Step 351 Train Loss: 0.7692
Epoch 11: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0242 Validation Top 20 DE MSE: 0.1660. 
Epoch 12 Step 1 Train Loss: 0.8451
Epoch 12 Step 51 Train Loss: 0.6869
Epoch 12 Step 101 Train Loss: 0.8901
Epoch 12 Step 151 Train Loss: 0.8200
Epoch 12 Step 201 Train Loss: 0.8611
Epoch 12 Step 251 Train Loss: 0.7212
Epoch 12 Step 301 Train Loss: 0.8634
Epoch 12 Step 351 Train Loss: 0.7071
Epoch 12: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0236 Validation Top 20 DE MSE: 0.1662. 
Epoch 13 Step 1 Train Loss: 0.8085
Epoch 13 Step 51 Train Loss: 0.7465
Epoch 13 Step 101 Train Loss: 0.6991
Epoch 13 Step 151 Train Loss: 0.9056
Epoch 13 Step 201 Train Loss: 0.7816
Epoch 13 Step 251 Train Loss: 0.7329
Epoch 13 Step 301 Train Loss: 0.7993
Epoch 13 Step 351 Train Loss: 0.8414
Epoch 13: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0252 Validation Top 20 DE MSE: 0.1669. 
Epoch 14 Step 1 Train Loss: 0.9392
Epoch 14 Step 51 Train Loss: 0.7220
Epoch 14 Step 101 Train Loss: 0.7752
Epoch 14 Step 151 Train Loss: 0.7661
Epoch 14 Step 201 Train Loss: 0.7756
Epoch 14 Step 251 Train Loss: 0.8038
Epoch 14 Step 301 Train Loss: 0.7966
Epoch 14 Step 351 Train Loss: 0.7688
Epoch 14: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0255 Validation Top 20 DE MSE: 0.1679. 
Epoch 15 Step 1 Train Loss: 0.8370
Epoch 15 Step 51 Train Loss: 0.8532
Epoch 15 Step 101 Train Loss: 0.8219
Epoch 15 Step 151 Train Loss: 0.7985
Epoch 15 Step 201 Train Loss: 0.8115
Epoch 15 Step 251 Train Loss: 0.7288
Epoch 15 Step 301 Train Loss: 0.8449
Epoch 15 Step 351 Train Loss: 0.7667
Epoch 15: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.0264 Validation Top 20 DE MSE: 0.1670. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.6134
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.007843766
test_unseen_single_pearson: 0.9810379724322541
test_unseen_single_mse_de: 0.6134124
test_unseen_single_pearson_de: 0.9686618871179397
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.22237026575336868
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3333333333333333
test_unseen_single_frac_sigma_below_1_non_dropout: 0.6666666666666666
test_unseen_single_mse_top20_de_non_dropout: 0.61389685
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.018 MB of 0.022 MB uploadedwandb: / 0.018 MB of 0.022 MB uploadedwandb: - 0.018 MB of 0.022 MB uploadedwandb: \ 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñá‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñà‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ
wandb:                                                   val_de_mse ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñà‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.61341
wandb:                                              test_de_pearson 0.96866
wandb:               test_frac_opposite_direction_top20_non_dropout 0.33333
wandb:                          test_frac_sigma_below_1_non_dropout 0.66667
wandb:                                                     test_mse 0.00784
wandb:                                test_mse_top20_de_non_dropout 0.6139
wandb:                                                 test_pearson 0.98104
wandb:                                           test_pearson_delta 0.22237
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.33333
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.66667
wandb:                                       test_unseen_single_mse 0.00784
wandb:                                    test_unseen_single_mse_de 0.61341
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.6139
wandb:                                   test_unseen_single_pearson 0.98104
wandb:                                test_unseen_single_pearson_de 0.96866
wandb:                             test_unseen_single_pearson_delta 0.22237
wandb:                                                 train_de_mse 0.02641
wandb:                                             train_de_pearson 0.89359
wandb:                                                    train_mse 0.00173
wandb:                                                train_pearson 0.99591
wandb:                                                training_loss 0.83019
wandb:                                                   val_de_mse 0.16698
wandb:                                               val_de_pearson 0.95225
wandb:                                                      val_mse 0.00283
wandb:                                                  val_pearson 0.9933
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_RNA_split2 at: https://wandb.ai/zhoumin1130/New_gears/runs/5d3c45dz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_151012-5d3c45dz/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:6
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_151932-lpsbkpw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_RNA_split3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/lpsbkpw8
wandb: WARNING Serializing object of type ndarray that is 8011328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.8426
Epoch 1 Step 51 Train Loss: 0.8337
Epoch 1 Step 101 Train Loss: 0.8764
Epoch 1 Step 151 Train Loss: 0.8377
Epoch 1 Step 201 Train Loss: 0.7556
Epoch 1 Step 251 Train Loss: 0.7923
Epoch 1 Step 301 Train Loss: 0.9352
Epoch 1 Step 351 Train Loss: 0.7575
Epoch 1: Train Overall MSE: 13.2068 Validation Overall MSE: 13.3266. 
Train Top 20 DE MSE: 49.4838 Validation Top 20 DE MSE: 22.4888. 
Epoch 2 Step 1 Train Loss: 0.8958
Epoch 2 Step 51 Train Loss: 0.8840
Epoch 2 Step 101 Train Loss: 0.8879
Epoch 2 Step 151 Train Loss: 0.8822
Epoch 2 Step 201 Train Loss: 0.8546
Epoch 2 Step 251 Train Loss: 0.6956
Epoch 2 Step 301 Train Loss: 0.7864
Epoch 2 Step 351 Train Loss: 0.6522
Epoch 2: Train Overall MSE: 0.0591 Validation Overall MSE: 0.0652. 
Train Top 20 DE MSE: 0.1706 Validation Top 20 DE MSE: 0.1678. 
Epoch 3 Step 1 Train Loss: 0.7478
Epoch 3 Step 51 Train Loss: 0.9296
Epoch 3 Step 101 Train Loss: 0.7531
Epoch 3 Step 151 Train Loss: 0.8905
Epoch 3 Step 201 Train Loss: 0.7903
Epoch 3 Step 251 Train Loss: 0.8054
Epoch 3 Step 301 Train Loss: 0.8033
Epoch 3 Step 351 Train Loss: 0.8858
Epoch 3: Train Overall MSE: 0.0359 Validation Overall MSE: 0.0409. 
Train Top 20 DE MSE: 0.2797 Validation Top 20 DE MSE: 0.1017. 
Epoch 4 Step 1 Train Loss: 0.9209
Epoch 4 Step 51 Train Loss: 0.7712
Epoch 4 Step 101 Train Loss: 0.6958
Epoch 4 Step 151 Train Loss: 0.7323
Epoch 4 Step 201 Train Loss: 0.8304
Epoch 4 Step 251 Train Loss: 0.8764
Epoch 4 Step 301 Train Loss: 0.7693
Epoch 4 Step 351 Train Loss: 0.7715
Epoch 4: Train Overall MSE: 0.0159 Validation Overall MSE: 0.0182. 
Train Top 20 DE MSE: 0.1824 Validation Top 20 DE MSE: 0.0667. 
Epoch 5 Step 1 Train Loss: 0.6851
Epoch 5 Step 51 Train Loss: 0.7514
Epoch 5 Step 101 Train Loss: 0.8143
Epoch 5 Step 151 Train Loss: 0.8344
Epoch 5 Step 201 Train Loss: 0.7171
Epoch 5 Step 251 Train Loss: 0.7564
Epoch 5 Step 301 Train Loss: 0.8399
Epoch 5 Step 351 Train Loss: 0.7477
Epoch 5: Train Overall MSE: 0.0054 Validation Overall MSE: 0.0065. 
Train Top 20 DE MSE: 0.0500 Validation Top 20 DE MSE: 0.0660. 
Epoch 6 Step 1 Train Loss: 0.7209
Epoch 6 Step 51 Train Loss: 0.8267
Epoch 6 Step 101 Train Loss: 0.7358
Epoch 6 Step 151 Train Loss: 0.7516
Epoch 6 Step 201 Train Loss: 0.7749
Epoch 6 Step 251 Train Loss: 0.8367
Epoch 6 Step 301 Train Loss: 0.8156
Epoch 6 Step 351 Train Loss: 0.7545
Epoch 6: Train Overall MSE: 0.0023 Validation Overall MSE: 0.0024. 
Train Top 20 DE MSE: 0.0465 Validation Top 20 DE MSE: 0.0401. 
Epoch 7 Step 1 Train Loss: 0.7875
Epoch 7 Step 51 Train Loss: 0.8222
Epoch 7 Step 101 Train Loss: 0.8140
Epoch 7 Step 151 Train Loss: 0.7521
Epoch 7 Step 201 Train Loss: 0.8901
Epoch 7 Step 251 Train Loss: 0.8435
Epoch 7 Step 301 Train Loss: 0.6869
Epoch 7 Step 351 Train Loss: 0.8294
Epoch 7: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0021. 
Train Top 20 DE MSE: 0.0435 Validation Top 20 DE MSE: 0.0366. 
Epoch 8 Step 1 Train Loss: 0.7186
Epoch 8 Step 51 Train Loss: 0.7657
Epoch 8 Step 101 Train Loss: 0.8733
Epoch 8 Step 151 Train Loss: 0.7127
Epoch 8 Step 201 Train Loss: 0.7518
Epoch 8 Step 251 Train Loss: 0.8966
Epoch 8 Step 301 Train Loss: 0.7121
Epoch 8 Step 351 Train Loss: 0.7406
Epoch 8: Train Overall MSE: 0.0019 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0234 Validation Top 20 DE MSE: 0.0363. 
Epoch 9 Step 1 Train Loss: 0.6676
Epoch 9 Step 51 Train Loss: 0.7555
Epoch 9 Step 101 Train Loss: 0.9064
Epoch 9 Step 151 Train Loss: 0.7108
Epoch 9 Step 201 Train Loss: 0.8082
Epoch 9 Step 251 Train Loss: 0.7610
Epoch 9 Step 301 Train Loss: 0.7740
Epoch 9 Step 351 Train Loss: 0.8151
Epoch 9: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0276 Validation Top 20 DE MSE: 0.0356. 
Epoch 10 Step 1 Train Loss: 0.7390
Epoch 10 Step 51 Train Loss: 0.8259
Epoch 10 Step 101 Train Loss: 0.7449
Epoch 10 Step 151 Train Loss: 0.8360
Epoch 10 Step 201 Train Loss: 0.8949
Epoch 10 Step 251 Train Loss: 0.7760
Epoch 10 Step 301 Train Loss: 0.7988
Epoch 10 Step 351 Train Loss: 0.8047
Epoch 10: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0232 Validation Top 20 DE MSE: 0.0355. 
Epoch 11 Step 1 Train Loss: 0.8873
Epoch 11 Step 51 Train Loss: 0.8317
Epoch 11 Step 101 Train Loss: 0.7030
Epoch 11 Step 151 Train Loss: 0.7774
Epoch 11 Step 201 Train Loss: 0.6884
Epoch 11 Step 251 Train Loss: 0.9241
Epoch 11 Step 301 Train Loss: 0.9172
Epoch 11 Step 351 Train Loss: 0.7410
Epoch 11: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0166 Validation Top 20 DE MSE: 0.0367. 
Epoch 12 Step 1 Train Loss: 0.9040
Epoch 12 Step 51 Train Loss: 0.8748
Epoch 12 Step 101 Train Loss: 0.7882
Epoch 12 Step 151 Train Loss: 0.7507
Epoch 12 Step 201 Train Loss: 0.8173
Epoch 12 Step 251 Train Loss: 0.7497
Epoch 12 Step 301 Train Loss: 0.7739
Epoch 12 Step 351 Train Loss: 0.9010
Epoch 12: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0234 Validation Top 20 DE MSE: 0.0353. 
Epoch 13 Step 1 Train Loss: 0.8836
Epoch 13 Step 51 Train Loss: 0.7190
Epoch 13 Step 101 Train Loss: 0.8267
Epoch 13 Step 151 Train Loss: 0.8141
Epoch 13 Step 201 Train Loss: 0.7278
Epoch 13 Step 251 Train Loss: 0.8154
Epoch 13 Step 301 Train Loss: 0.9229
Epoch 13 Step 351 Train Loss: 0.7931
Epoch 13: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0231 Validation Top 20 DE MSE: 0.0357. 
Epoch 14 Step 1 Train Loss: 0.8046
Epoch 14 Step 51 Train Loss: 0.7280
Epoch 14 Step 101 Train Loss: 0.7966
Epoch 14 Step 151 Train Loss: 0.7437
Epoch 14 Step 201 Train Loss: 0.7292
Epoch 14 Step 251 Train Loss: 0.7410
Epoch 14 Step 301 Train Loss: 0.7474
Epoch 14 Step 351 Train Loss: 0.8063
Epoch 14: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0215 Validation Top 20 DE MSE: 0.0359. 
Epoch 15 Step 1 Train Loss: 0.9006
Epoch 15 Step 51 Train Loss: 0.7764
Epoch 15 Step 101 Train Loss: 0.8306
Epoch 15 Step 151 Train Loss: 0.7519
Epoch 15 Step 201 Train Loss: 0.7358
Epoch 15 Step 251 Train Loss: 0.7166
Epoch 15 Step 301 Train Loss: 0.7668
Epoch 15 Step 351 Train Loss: 0.6770
Epoch 15: Train Overall MSE: 0.0018 Validation Overall MSE: 0.0019. 
Train Top 20 DE MSE: 0.0265 Validation Top 20 DE MSE: 0.0351. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1476
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0017883778
test_unseen_single_pearson: 0.9956449765392135
test_unseen_single_mse_de: 0.14761607
test_unseen_single_pearson_de: 0.9841791684340618
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.3379884362392165
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3
test_unseen_single_frac_sigma_below_1_non_dropout: 0.8916666666666667
test_unseen_single_mse_top20_de_non_dropout: 0.1478285
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.005 MB of 0.022 MB uploadedwandb: / 0.005 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñá‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.14762
wandb:                                              test_de_pearson 0.98418
wandb:               test_frac_opposite_direction_top20_non_dropout 0.3
wandb:                          test_frac_sigma_below_1_non_dropout 0.89167
wandb:                                                     test_mse 0.00179
wandb:                                test_mse_top20_de_non_dropout 0.14783
wandb:                                                 test_pearson 0.99564
wandb:                                           test_pearson_delta 0.33799
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.3
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.89167
wandb:                                       test_unseen_single_mse 0.00179
wandb:                                    test_unseen_single_mse_de 0.14762
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.14783
wandb:                                   test_unseen_single_pearson 0.99564
wandb:                                test_unseen_single_pearson_de 0.98418
wandb:                             test_unseen_single_pearson_delta 0.33799
wandb:                                                 train_de_mse 0.02655
wandb:                                             train_de_pearson 0.88383
wandb:                                                    train_mse 0.00183
wandb:                                                train_pearson 0.99562
wandb:                                                training_loss 0.74918
wandb:                                                   val_de_mse 0.0351
wandb:                                               val_de_pearson 0.9928
wandb:                                                      val_mse 0.00188
wandb:                                                  val_pearson 0.99557
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_RNA_split3 at: https://wandb.ai/zhoumin1130/New_gears/runs/lpsbkpw8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_151932-lpsbkpw8/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:6
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_152809-mnzby53q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_RNA_split4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/mnzby53q
wandb: WARNING Serializing object of type ndarray that is 8011328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.8359
Epoch 1 Step 51 Train Loss: 0.8158
Epoch 1 Step 101 Train Loss: 0.8128
Epoch 1 Step 151 Train Loss: 0.9114
Epoch 1 Step 201 Train Loss: 0.7775
Epoch 1 Step 251 Train Loss: 0.8965
Epoch 1 Step 301 Train Loss: 0.7653
Epoch 1 Step 351 Train Loss: 0.7906
Epoch 1: Train Overall MSE: 0.1272 Validation Overall MSE: 0.1358. 
Train Top 20 DE MSE: 0.2708 Validation Top 20 DE MSE: 0.8691. 
Epoch 2 Step 1 Train Loss: 0.8400
Epoch 2 Step 51 Train Loss: 0.7772
Epoch 2 Step 101 Train Loss: 0.9391
Epoch 2 Step 151 Train Loss: 0.9209
Epoch 2 Step 201 Train Loss: 0.8216
Epoch 2 Step 251 Train Loss: 0.8619
Epoch 2 Step 301 Train Loss: 0.8241
Epoch 2 Step 351 Train Loss: 0.8807
Epoch 2: Train Overall MSE: 0.0323 Validation Overall MSE: 0.0398. 
Train Top 20 DE MSE: 0.1565 Validation Top 20 DE MSE: 0.9410. 
Epoch 3 Step 1 Train Loss: 0.6964
Epoch 3 Step 51 Train Loss: 0.7026
Epoch 3 Step 101 Train Loss: 0.7229
Epoch 3 Step 151 Train Loss: 0.9070
Epoch 3 Step 201 Train Loss: 0.7364
Epoch 3 Step 251 Train Loss: 0.8121
Epoch 3 Step 301 Train Loss: 0.7296
Epoch 3 Step 351 Train Loss: 0.7341
Epoch 3: Train Overall MSE: 0.0828 Validation Overall MSE: 0.0881. 
Train Top 20 DE MSE: 0.3495 Validation Top 20 DE MSE: 0.8235. 
Epoch 4 Step 1 Train Loss: 0.7372
Epoch 4 Step 51 Train Loss: 0.7263
Epoch 4 Step 101 Train Loss: 0.8585
Epoch 4 Step 151 Train Loss: 0.7852
Epoch 4 Step 201 Train Loss: 0.7326
Epoch 4 Step 251 Train Loss: 0.7647
Epoch 4 Step 301 Train Loss: 0.7482
Epoch 4 Step 351 Train Loss: 0.8018
Epoch 4: Train Overall MSE: 0.0087 Validation Overall MSE: 0.0133. 
Train Top 20 DE MSE: 0.0675 Validation Top 20 DE MSE: 0.8235. 
Epoch 5 Step 1 Train Loss: 0.8067
Epoch 5 Step 51 Train Loss: 0.7633
Epoch 5 Step 101 Train Loss: 0.9111
Epoch 5 Step 151 Train Loss: 0.7695
Epoch 5 Step 201 Train Loss: 0.9160
Epoch 5 Step 251 Train Loss: 0.7435
Epoch 5 Step 301 Train Loss: 0.8631
Epoch 5 Step 351 Train Loss: 0.7621
Epoch 5: Train Overall MSE: 0.0048 Validation Overall MSE: 0.0108. 
Train Top 20 DE MSE: 0.0330 Validation Top 20 DE MSE: 0.6731. 
Epoch 6 Step 1 Train Loss: 0.7166
Epoch 6 Step 51 Train Loss: 0.7957
Epoch 6 Step 101 Train Loss: 0.8688
Epoch 6 Step 151 Train Loss: 0.7544
Epoch 6 Step 201 Train Loss: 0.7904
Epoch 6 Step 251 Train Loss: 0.6861
Epoch 6 Step 301 Train Loss: 0.8221
Epoch 6 Step 351 Train Loss: 0.6819
Epoch 6: Train Overall MSE: 0.0063 Validation Overall MSE: 0.0120. 
Train Top 20 DE MSE: 0.0518 Validation Top 20 DE MSE: 0.8807. 
Epoch 7 Step 1 Train Loss: 0.7408
Epoch 7 Step 51 Train Loss: 0.6698
Epoch 7 Step 101 Train Loss: 0.6887
Epoch 7 Step 151 Train Loss: 0.8624
Epoch 7 Step 201 Train Loss: 0.7514
Epoch 7 Step 251 Train Loss: 0.8468
Epoch 7 Step 301 Train Loss: 0.6972
Epoch 7 Step 351 Train Loss: 0.8173
Epoch 7: Train Overall MSE: 0.0017 Validation Overall MSE: 0.0081. 
Train Top 20 DE MSE: 0.0192 Validation Top 20 DE MSE: 0.8253. 
Epoch 8 Step 1 Train Loss: 0.7121
Epoch 8 Step 51 Train Loss: 0.8198
Epoch 8 Step 101 Train Loss: 0.7364
Epoch 8 Step 151 Train Loss: 0.7861
Epoch 8 Step 201 Train Loss: 0.7298
Epoch 8 Step 251 Train Loss: 0.7420
Epoch 8 Step 301 Train Loss: 0.7138
Epoch 8 Step 351 Train Loss: 0.8266
Epoch 8: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0082. 
Train Top 20 DE MSE: 0.0154 Validation Top 20 DE MSE: 0.8097. 
Epoch 9 Step 1 Train Loss: 0.8309
Epoch 9 Step 51 Train Loss: 0.7127
Epoch 9 Step 101 Train Loss: 0.7525
Epoch 9 Step 151 Train Loss: 0.7585
Epoch 9 Step 201 Train Loss: 0.7821
Epoch 9 Step 251 Train Loss: 0.7965
Epoch 9 Step 301 Train Loss: 0.7085
Epoch 9 Step 351 Train Loss: 0.7076
Epoch 9: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0082. 
Train Top 20 DE MSE: 0.0132 Validation Top 20 DE MSE: 0.8107. 
Epoch 10 Step 1 Train Loss: 0.6338
Epoch 10 Step 51 Train Loss: 0.7280
Epoch 10 Step 101 Train Loss: 0.7572
Epoch 10 Step 151 Train Loss: 0.8769
Epoch 10 Step 201 Train Loss: 0.7212
Epoch 10 Step 251 Train Loss: 0.9177
Epoch 10 Step 301 Train Loss: 0.7787
Epoch 10 Step 351 Train Loss: 0.8259
Epoch 10: Train Overall MSE: 0.0016 Validation Overall MSE: 0.0084. 
Train Top 20 DE MSE: 0.0169 Validation Top 20 DE MSE: 0.8162. 
Epoch 11 Step 1 Train Loss: 0.7229
Epoch 11 Step 51 Train Loss: 0.8649
Epoch 11 Step 101 Train Loss: 0.8228
Epoch 11 Step 151 Train Loss: 0.8336
Epoch 11 Step 201 Train Loss: 0.7342
Epoch 11 Step 251 Train Loss: 0.7207
Epoch 11 Step 301 Train Loss: 0.7468
Epoch 11 Step 351 Train Loss: 0.7509
Epoch 11: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0084. 
Train Top 20 DE MSE: 0.0134 Validation Top 20 DE MSE: 0.8162. 
Epoch 12 Step 1 Train Loss: 0.7509
Epoch 12 Step 51 Train Loss: 0.7589
Epoch 12 Step 101 Train Loss: 0.7821
Epoch 12 Step 151 Train Loss: 0.7243
Epoch 12 Step 201 Train Loss: 0.7949
Epoch 12 Step 251 Train Loss: 0.7558
Epoch 12 Step 301 Train Loss: 0.9164
Epoch 12 Step 351 Train Loss: 0.7003
Epoch 12: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0084. 
Train Top 20 DE MSE: 0.0152 Validation Top 20 DE MSE: 0.8123. 
Epoch 13 Step 1 Train Loss: 0.7147
Epoch 13 Step 51 Train Loss: 0.8288
Epoch 13 Step 101 Train Loss: 0.7817
Epoch 13 Step 151 Train Loss: 0.7396
Epoch 13 Step 201 Train Loss: 0.8178
Epoch 13 Step 251 Train Loss: 0.6949
Epoch 13 Step 301 Train Loss: 0.9112
Epoch 13 Step 351 Train Loss: 0.7293
Epoch 13: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0083. 
Train Top 20 DE MSE: 0.0118 Validation Top 20 DE MSE: 0.8102. 
Epoch 14 Step 1 Train Loss: 0.7171
Epoch 14 Step 51 Train Loss: 0.8203
Epoch 14 Step 101 Train Loss: 0.6487
Epoch 14 Step 151 Train Loss: 0.6992
Epoch 14 Step 201 Train Loss: 0.7935
Epoch 14 Step 251 Train Loss: 0.7779
Epoch 14 Step 301 Train Loss: 0.7561
Epoch 14 Step 351 Train Loss: 0.7069
Epoch 14: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0083. 
Train Top 20 DE MSE: 0.0106 Validation Top 20 DE MSE: 0.8095. 
Epoch 15 Step 1 Train Loss: 0.8956
Epoch 15 Step 51 Train Loss: 0.9379
Epoch 15 Step 101 Train Loss: 0.7846
Epoch 15 Step 151 Train Loss: 0.7684
Epoch 15 Step 201 Train Loss: 0.7553
Epoch 15 Step 251 Train Loss: 0.7070
Epoch 15 Step 301 Train Loss: 0.7732
Epoch 15 Step 351 Train Loss: 0.8075
Epoch 15: Train Overall MSE: 0.0015 Validation Overall MSE: 0.0082. 
Train Top 20 DE MSE: 0.0136 Validation Top 20 DE MSE: 0.8047. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.4176
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.010499499
test_unseen_single_pearson: 0.974560629684445
test_unseen_single_mse_de: 0.41763255
test_unseen_single_pearson_de: 0.9638305533143149
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.11322284253932265
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.4000000000000001
test_unseen_single_frac_sigma_below_1_non_dropout: 0.75
test_unseen_single_mse_top20_de_non_dropout: 0.42188573
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.001 MB of 0.022 MB uploadedwandb: / 0.005 MB of 0.022 MB uploadedwandb: - 0.005 MB of 0.022 MB uploadedwandb: \ 0.005 MB of 0.022 MB uploadedwandb: | 0.010 MB of 0.022 MB uploadedwandb: / 0.010 MB of 0.022 MB uploadedwandb: - 0.010 MB of 0.022 MB uploadedwandb: \ 0.010 MB of 0.022 MB uploadedwandb: | 0.010 MB of 0.022 MB uploadedwandb: / 0.010 MB of 0.022 MB uploadedwandb: - 0.010 MB of 0.022 MB uploadedwandb: \ 0.010 MB of 0.022 MB uploadedwandb: | 0.010 MB of 0.022 MB uploadedwandb: / 0.014 MB of 0.022 MB uploadedwandb: - 0.014 MB of 0.022 MB uploadedwandb: \ 0.014 MB of 0.022 MB uploadedwandb: | 0.014 MB of 0.022 MB uploadedwandb: / 0.014 MB of 0.022 MB uploadedwandb: - 0.014 MB of 0.022 MB uploadedwandb: \ 0.014 MB of 0.022 MB uploadedwandb: | 0.014 MB of 0.022 MB uploadedwandb: / 0.014 MB of 0.022 MB uploadedwandb: - 0.014 MB of 0.022 MB uploadedwandb: \ 0.014 MB of 0.022 MB uploadedwandb: | 0.014 MB of 0.022 MB uploadedwandb: / 0.014 MB of 0.022 MB uploadedwandb: - 0.014 MB of 0.022 MB uploadedwandb: \ 0.014 MB of 0.022 MB uploadedwandb: | 0.014 MB of 0.022 MB uploadedwandb: / 0.014 MB of 0.022 MB uploadedwandb: - 0.014 MB of 0.022 MB uploadedwandb: \ 0.014 MB of 0.022 MB uploadedwandb: | 0.014 MB of 0.022 MB uploadedwandb: / 0.014 MB of 0.022 MB uploadedwandb: - 0.014 MB of 0.022 MB uploadedwandb: \ 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñÜ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñÖ‚ñÇ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñÜ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÖ
wandb:                                                   val_de_mse ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:                                               val_de_pearson ‚ñÅ‚ñÖ‚ñÇ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñÜ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.41763
wandb:                                              test_de_pearson 0.96383
wandb:               test_frac_opposite_direction_top20_non_dropout 0.4
wandb:                          test_frac_sigma_below_1_non_dropout 0.75
wandb:                                                     test_mse 0.0105
wandb:                                test_mse_top20_de_non_dropout 0.42189
wandb:                                                 test_pearson 0.97456
wandb:                                           test_pearson_delta 0.11322
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.4
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.75
wandb:                                       test_unseen_single_mse 0.0105
wandb:                                    test_unseen_single_mse_de 0.41763
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.42189
wandb:                                   test_unseen_single_pearson 0.97456
wandb:                                test_unseen_single_pearson_de 0.96383
wandb:                             test_unseen_single_pearson_delta 0.11322
wandb:                                                 train_de_mse 0.01365
wandb:                                             train_de_pearson 0.89523
wandb:                                                    train_mse 0.00152
wandb:                                                train_pearson 0.99641
wandb:                                                training_loss 0.8162
wandb:                                                   val_de_mse 0.80475
wandb:                                               val_de_pearson 0.94207
wandb:                                                      val_mse 0.00822
wandb:                                                  val_pearson 0.98069
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_RNA_split4 at: https://wandb.ai/zhoumin1130/New_gears/runs/mnzby53q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_152809-mnzby53q/logs
Local copy of split is detected. Loading...
Simulation split test composition:
combo_seen0:0
combo_seen1:0
combo_seen2:0
unseen_single:6
Done!
Creating dataloaders....
Done!
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/share/huadjyin/home/zhoumin3/zhoumin/Gears_change/scbert/scbert/wandb/run-20241029_153756-2xtspw70
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scbert_PapalexiSatija2021_eccite_RNA_split5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zhoumin1130/New_gears
wandb: üöÄ View run at https://wandb.ai/zhoumin1130/New_gears/runs/2xtspw70
wandb: WARNING Serializing object of type ndarray that is 8011328 bytes
Start Training...
Epoch 1 Step 1 Train Loss: 0.9532
Epoch 1 Step 51 Train Loss: 0.8227
Epoch 1 Step 101 Train Loss: 0.8031
Epoch 1 Step 151 Train Loss: 0.8720
Epoch 1 Step 201 Train Loss: 0.8439
Epoch 1 Step 251 Train Loss: 0.7781
Epoch 1 Step 301 Train Loss: 0.7271
Epoch 1 Step 351 Train Loss: 0.8443
Epoch 1: Train Overall MSE: 4.5488 Validation Overall MSE: 4.6009. 
Train Top 20 DE MSE: 10.2881 Validation Top 20 DE MSE: 4.8749. 
Epoch 2 Step 1 Train Loss: 0.8588
Epoch 2 Step 51 Train Loss: 0.7785
Epoch 2 Step 101 Train Loss: 0.7664
Epoch 2 Step 151 Train Loss: 0.8494
Epoch 2 Step 201 Train Loss: 0.7807
Epoch 2 Step 251 Train Loss: 0.7399
Epoch 2 Step 301 Train Loss: 0.6783
Epoch 2 Step 351 Train Loss: 0.8435
Epoch 2: Train Overall MSE: 0.0132 Validation Overall MSE: 0.0059. 
Train Top 20 DE MSE: 0.3555 Validation Top 20 DE MSE: 0.0091. 
Epoch 3 Step 1 Train Loss: 0.7435
Epoch 3 Step 51 Train Loss: 0.8056
Epoch 3 Step 101 Train Loss: 0.8203
Epoch 3 Step 151 Train Loss: 0.7709
Epoch 3 Step 201 Train Loss: 0.8308
Epoch 3 Step 251 Train Loss: 0.7639
Epoch 3 Step 301 Train Loss: 0.9873
Epoch 3 Step 351 Train Loss: 0.7313
Epoch 3: Train Overall MSE: 0.0619 Validation Overall MSE: 0.0705. 
Train Top 20 DE MSE: 0.2520 Validation Top 20 DE MSE: 0.0983. 
Epoch 4 Step 1 Train Loss: 0.8915
Epoch 4 Step 51 Train Loss: 0.7864
Epoch 4 Step 101 Train Loss: 0.8943
Epoch 4 Step 151 Train Loss: 0.7018
Epoch 4 Step 201 Train Loss: 0.7563
Epoch 4 Step 251 Train Loss: 0.7927
Epoch 4 Step 301 Train Loss: 0.7877
Epoch 4 Step 351 Train Loss: 0.6858
Epoch 4: Train Overall MSE: 0.0241 Validation Overall MSE: 0.0191. 
Train Top 20 DE MSE: 0.3757 Validation Top 20 DE MSE: 0.0132. 
Epoch 5 Step 1 Train Loss: 0.7668
Epoch 5 Step 51 Train Loss: 0.8352
Epoch 5 Step 101 Train Loss: 0.7674
Epoch 5 Step 151 Train Loss: 0.8794
Epoch 5 Step 201 Train Loss: 0.7751
Epoch 5 Step 251 Train Loss: 0.7818
Epoch 5 Step 301 Train Loss: 0.7507
Epoch 5 Step 351 Train Loss: 0.7392
Epoch 5: Train Overall MSE: 0.0069 Validation Overall MSE: 0.0028. 
Train Top 20 DE MSE: 0.1984 Validation Top 20 DE MSE: 0.0063. 
Epoch 6 Step 1 Train Loss: 0.8229
Epoch 6 Step 51 Train Loss: 0.7991
Epoch 6 Step 101 Train Loss: 0.7653
Epoch 6 Step 151 Train Loss: 0.9331
Epoch 6 Step 201 Train Loss: 0.6678
Epoch 6 Step 251 Train Loss: 0.7025
Epoch 6 Step 301 Train Loss: 0.8153
Epoch 6 Step 351 Train Loss: 0.7326
Epoch 6: Train Overall MSE: 0.0055 Validation Overall MSE: 0.0037. 
Train Top 20 DE MSE: 0.0482 Validation Top 20 DE MSE: 0.0100. 
Epoch 7 Step 1 Train Loss: 0.7751
Epoch 7 Step 51 Train Loss: 0.7957
Epoch 7 Step 101 Train Loss: 0.7390
Epoch 7 Step 151 Train Loss: 0.8291
Epoch 7 Step 201 Train Loss: 0.8552
Epoch 7 Step 251 Train Loss: 0.7991
Epoch 7 Step 301 Train Loss: 0.7503
Epoch 7 Step 351 Train Loss: 0.8822
Epoch 7: Train Overall MSE: 0.0022 Validation Overall MSE: 0.0008. 
Train Top 20 DE MSE: 0.0280 Validation Top 20 DE MSE: 0.0061. 
Epoch 8 Step 1 Train Loss: 0.6642
Epoch 8 Step 51 Train Loss: 0.8236
Epoch 8 Step 101 Train Loss: 0.7905
Epoch 8 Step 151 Train Loss: 0.7642
Epoch 8 Step 201 Train Loss: 0.7501
Epoch 8 Step 251 Train Loss: 0.6740
Epoch 8 Step 301 Train Loss: 0.7249
Epoch 8 Step 351 Train Loss: 0.8122
Epoch 8: Train Overall MSE: 0.0030 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0417 Validation Top 20 DE MSE: 0.0064. 
Epoch 9 Step 1 Train Loss: 0.7808
Epoch 9 Step 51 Train Loss: 0.7164
Epoch 9 Step 101 Train Loss: 0.7844
Epoch 9 Step 151 Train Loss: 0.6973
Epoch 9 Step 201 Train Loss: 0.8377
Epoch 9 Step 251 Train Loss: 0.8586
Epoch 9 Step 301 Train Loss: 0.7872
Epoch 9 Step 351 Train Loss: 0.7786
Epoch 9: Train Overall MSE: 0.0021 Validation Overall MSE: 0.0008. 
Train Top 20 DE MSE: 0.0377 Validation Top 20 DE MSE: 0.0063. 
Epoch 10 Step 1 Train Loss: 0.7709
Epoch 10 Step 51 Train Loss: 0.8418
Epoch 10 Step 101 Train Loss: 0.7020
Epoch 10 Step 151 Train Loss: 0.6731
Epoch 10 Step 201 Train Loss: 0.8353
Epoch 10 Step 251 Train Loss: 0.7785
Epoch 10 Step 301 Train Loss: 0.7965
Epoch 10 Step 351 Train Loss: 0.7813
Epoch 10: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0314 Validation Top 20 DE MSE: 0.0060. 
Epoch 11 Step 1 Train Loss: 0.7881
Epoch 11 Step 51 Train Loss: 0.7691
Epoch 11 Step 101 Train Loss: 0.7899
Epoch 11 Step 151 Train Loss: 0.7283
Epoch 11 Step 201 Train Loss: 0.7498
Epoch 11 Step 251 Train Loss: 0.8653
Epoch 11 Step 301 Train Loss: 0.7762
Epoch 11 Step 351 Train Loss: 0.7887
Epoch 11: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0009. 
Train Top 20 DE MSE: 0.0331 Validation Top 20 DE MSE: 0.0059. 
Epoch 12 Step 1 Train Loss: 0.8006
Epoch 12 Step 51 Train Loss: 0.7104
Epoch 12 Step 101 Train Loss: 0.7790
Epoch 12 Step 151 Train Loss: 0.8239
Epoch 12 Step 201 Train Loss: 0.8165
Epoch 12 Step 251 Train Loss: 0.6592
Epoch 12 Step 301 Train Loss: 0.7173
Epoch 12 Step 351 Train Loss: 0.7290
Epoch 12: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0415 Validation Top 20 DE MSE: 0.0064. 
Epoch 13 Step 1 Train Loss: 0.8013
Epoch 13 Step 51 Train Loss: 0.8742
Epoch 13 Step 101 Train Loss: 0.6768
Epoch 13 Step 151 Train Loss: 0.7373
Epoch 13 Step 201 Train Loss: 0.7108
Epoch 13 Step 251 Train Loss: 0.7370
Epoch 13 Step 301 Train Loss: 0.8669
Epoch 13 Step 351 Train Loss: 0.7095
Epoch 13: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0389 Validation Top 20 DE MSE: 0.0066. 
Epoch 14 Step 1 Train Loss: 0.7300
Epoch 14 Step 51 Train Loss: 0.8150
Epoch 14 Step 101 Train Loss: 0.7306
Epoch 14 Step 151 Train Loss: 0.7347
Epoch 14 Step 201 Train Loss: 0.7663
Epoch 14 Step 251 Train Loss: 0.7051
Epoch 14 Step 301 Train Loss: 0.8813
Epoch 14 Step 351 Train Loss: 0.7765
Epoch 14: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0011. 
Train Top 20 DE MSE: 0.0424 Validation Top 20 DE MSE: 0.0065. 
Epoch 15 Step 1 Train Loss: 0.7404
Epoch 15 Step 51 Train Loss: 0.8086
Epoch 15 Step 101 Train Loss: 0.8136
Epoch 15 Step 151 Train Loss: 0.7323
Epoch 15 Step 201 Train Loss: 0.7276
Epoch 15 Step 251 Train Loss: 0.8749
Epoch 15 Step 301 Train Loss: 0.7647
Epoch 15 Step 351 Train Loss: 0.8020
Epoch 15: Train Overall MSE: 0.0020 Validation Overall MSE: 0.0010. 
Train Top 20 DE MSE: 0.0336 Validation Top 20 DE MSE: 0.0061. 
Done!
Start Testing...
Best performing model: Test Top 20 DE MSE: 0.1380
Start doing subgroup analysis for simulation split...
test_combo_seen0_mse: nan
test_combo_seen0_pearson: nan
test_combo_seen0_mse_de: nan
test_combo_seen0_pearson_de: nan
test_combo_seen1_mse: nan
test_combo_seen1_pearson: nan
test_combo_seen1_mse_de: nan
test_combo_seen1_pearson_de: nan
test_combo_seen2_mse: nan
test_combo_seen2_pearson: nan
test_combo_seen2_mse_de: nan
test_combo_seen2_pearson_de: nan
test_unseen_single_mse: 0.0027771646
test_unseen_single_pearson: 0.9933982425499748
test_unseen_single_mse_de: 0.13796642
test_unseen_single_pearson_de: 0.9688121190502677
test_combo_seen0_pearson_delta: nan
test_combo_seen0_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen0_frac_sigma_below_1_non_dropout: nan
test_combo_seen0_mse_top20_de_non_dropout: nan
test_combo_seen1_pearson_delta: nan
test_combo_seen1_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen1_frac_sigma_below_1_non_dropout: nan
test_combo_seen1_mse_top20_de_non_dropout: nan
test_combo_seen2_pearson_delta: nan
test_combo_seen2_frac_opposite_direction_top20_non_dropout: nan
test_combo_seen2_frac_sigma_below_1_non_dropout: nan
test_combo_seen2_mse_top20_de_non_dropout: nan
test_unseen_single_pearson_delta: 0.18528430800729398
test_unseen_single_frac_opposite_direction_top20_non_dropout: 0.3416666666666666
test_unseen_single_frac_sigma_below_1_non_dropout: 0.9166666666666666
test_unseen_single_mse_top20_de_non_dropout: 0.13839765
Done!
wandb: - 0.001 MB of 0.001 MB uploadedwandb: \ 0.001 MB of 0.022 MB uploadedwandb: | 0.005 MB of 0.022 MB uploadedwandb: / 0.005 MB of 0.022 MB uploadedwandb: - 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                                  test_de_mse ‚ñÅ
wandb:                                              test_de_pearson ‚ñÅ
wandb:               test_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:                          test_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                                     test_mse ‚ñÅ
wandb:                                test_mse_top20_de_non_dropout ‚ñÅ
wandb:                                                 test_pearson ‚ñÅ
wandb:                                           test_pearson_delta ‚ñÅ
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout ‚ñÅ
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout ‚ñÅ
wandb:                                       test_unseen_single_mse ‚ñÅ
wandb:                                    test_unseen_single_mse_de ‚ñÅ
wandb:                  test_unseen_single_mse_top20_de_non_dropout ‚ñÅ
wandb:                                   test_unseen_single_pearson ‚ñÅ
wandb:                                test_unseen_single_pearson_de ‚ñÅ
wandb:                             test_unseen_single_pearson_delta ‚ñÅ
wandb:                                                 train_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train_de_pearson ‚ñÅ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                    train_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                train_pearson ‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                training_loss ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ
wandb:                                                   val_de_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                               val_de_pearson ‚ñÅ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                                      val_mse ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                  val_pearson ‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   test_combo_seen0_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen0_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen0_mse nan
wandb:                                      test_combo_seen0_mse_de nan
wandb:                    test_combo_seen0_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen0_pearson nan
wandb:                                  test_combo_seen0_pearson_de nan
wandb:                               test_combo_seen0_pearson_delta nan
wandb:   test_combo_seen1_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen1_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen1_mse nan
wandb:                                      test_combo_seen1_mse_de nan
wandb:                    test_combo_seen1_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen1_pearson nan
wandb:                                  test_combo_seen1_pearson_de nan
wandb:                               test_combo_seen1_pearson_delta nan
wandb:   test_combo_seen2_frac_opposite_direction_top20_non_dropout nan
wandb:              test_combo_seen2_frac_sigma_below_1_non_dropout nan
wandb:                                         test_combo_seen2_mse nan
wandb:                                      test_combo_seen2_mse_de nan
wandb:                    test_combo_seen2_mse_top20_de_non_dropout nan
wandb:                                     test_combo_seen2_pearson nan
wandb:                                  test_combo_seen2_pearson_de nan
wandb:                               test_combo_seen2_pearson_delta nan
wandb:                                                  test_de_mse 0.13797
wandb:                                              test_de_pearson 0.96881
wandb:               test_frac_opposite_direction_top20_non_dropout 0.34167
wandb:                          test_frac_sigma_below_1_non_dropout 0.91667
wandb:                                                     test_mse 0.00278
wandb:                                test_mse_top20_de_non_dropout 0.1384
wandb:                                                 test_pearson 0.9934
wandb:                                           test_pearson_delta 0.18528
wandb: test_unseen_single_frac_opposite_direction_top20_non_dropout 0.34167
wandb:            test_unseen_single_frac_sigma_below_1_non_dropout 0.91667
wandb:                                       test_unseen_single_mse 0.00278
wandb:                                    test_unseen_single_mse_de 0.13797
wandb:                  test_unseen_single_mse_top20_de_non_dropout 0.1384
wandb:                                   test_unseen_single_pearson 0.9934
wandb:                                test_unseen_single_pearson_de 0.96881
wandb:                             test_unseen_single_pearson_delta 0.18528
wandb:                                                 train_de_mse 0.03364
wandb:                                             train_de_pearson 0.88178
wandb:                                                    train_mse 0.00195
wandb:                                                train_pearson 0.99529
wandb:                                                training_loss 0.87129
wandb:                                                   val_de_mse 0.00611
wandb:                                               val_de_pearson 0.9972
wandb:                                                      val_mse 0.00103
wandb:                                                  val_pearson 0.99758
wandb: 
wandb: üöÄ View run scbert_PapalexiSatija2021_eccite_RNA_split5 at: https://wandb.ai/zhoumin1130/New_gears/runs/2xtspw70
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/zhoumin1130/New_gears
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241029_153756-2xtspw70/logs
